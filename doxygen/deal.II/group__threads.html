<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<link rel="canonical" href="https://www.dealii.org/current/doxygen/deal.II/group__threads.html" />
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>The deal.II Library: Parallel computing with multiple processors accessing shared memory</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link rel="SHORTCUT ICON" href="deal.ico"></link>
<script type="text/javascript" src="custom.js"></script>
<meta name="author" content="The deal.II Authors <authors@dealii.org>"></meta>
<meta name="copyright" content="Copyright (C) 1998 - 2021 by the deal.II authors"></meta>
<meta name="deal.II-version" content="10.0.0-pre"></meta>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo200.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">Reference documentation for deal.II version 10.0.0-pre</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!--Extra macros for MathJax:-->
<div style="display:none">
\(\newcommand{\dealvcentcolon}{\mathrel{\mathop{:}}}\)
\(\newcommand{\dealcoloneq}{\dealvcentcolon\mathrel{\mkern-1.2mu}=}\)
\(\newcommand{\jump}[1]{\left[\!\left[ #1 \right]\!\right]}\)
\(\newcommand{\average}[1]{\left\{\!\left\{ #1 \right\}\!\right\}}\)
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#namespaces">Namespaces</a> &#124;
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">Parallel computing with multiple processors accessing shared memory<div class="ingroups"><a class="el" href="group__Parallel.html">Parallel computing</a></div></div>  </div>
</div><!--header-->
<div class="contents">

<p>A module discussing the use of parallelism on shared memory machines. See the detailed documentation and <a class="el" href="group__threads.html#MTToC">Table of Contents</a> below the lengthy list of members of this module.  
<a href="#details">More...</a></p>
<div class="dynheader">
Collaboration diagram for Parallel computing with multiple processors accessing shared memory:</div>
<div class="dyncontent">
<center><table><tr><td><div class="center"><iframe scrolling="no" frameborder="0" src="group__threads.svg" width="598" height="67"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe>
</div>
</td></tr></table></center>
</div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="namespaces"></a>
Namespaces</h2></td></tr>
<tr class="memitem:namespaceparallel"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceparallel.html">parallel</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:namespaceThreads"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceThreads.html">Threads</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:namespaceWorkStream"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceWorkStream.html">WorkStream</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMultithreadInfo.html">MultithreadInfo</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classThreads_1_1Thread.html">Threads::Thread&lt; RT &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classThreads_1_1ThreadGroup.html">Threads::ThreadGroup&lt; RT &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classThreads_1_1Task.html">Threads::Task&lt; RT &gt;</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga86c4f26c4dacddd38ee225dd1796d7e1"><td class="memTemplParams" colspan="2">template&lt;typename ForwardIterator &gt; </td></tr>
<tr class="memitem:ga86c4f26c4dacddd38ee225dd1796d7e1"><td class="memTemplItemLeft" align="right" valign="top">std::vector&lt; std::pair&lt; ForwardIterator, ForwardIterator &gt; &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__threads.html#ga86c4f26c4dacddd38ee225dd1796d7e1">Threads::split_range</a> (const ForwardIterator &amp;begin, const ForwardIterator &amp;end, const unsigned <a class="el" href="classint.html">int</a> n_intervals)</td></tr>
<tr class="separator:ga86c4f26c4dacddd38ee225dd1796d7e1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga76d508b069d429d014135b59d20cc74a"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::pair&lt; unsigned <a class="el" href="classint.html">int</a>, unsigned <a class="el" href="classint.html">int</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__threads.html#ga76d508b069d429d014135b59d20cc74a">Threads::split_interval</a> (const unsigned <a class="el" href="classint.html">int</a> begin, const unsigned <a class="el" href="classint.html">int</a> end, const unsigned <a class="el" href="classint.html">int</a> n_intervals)</td></tr>
<tr class="separator:ga76d508b069d429d014135b59d20cc74a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2003df2a027b3e716c290108ddeb558a"><td class="memTemplParams" colspan="2">template&lt;typename RT &gt; </td></tr>
<tr class="memitem:ga2003df2a027b3e716c290108ddeb558a"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classThreads_1_1Thread.html">Thread</a>&lt; RT &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__threads.html#ga2003df2a027b3e716c290108ddeb558a">Threads::new_thread</a> (const std::function&lt; RT()&gt; &amp;function)</td></tr>
<tr class="separator:ga2003df2a027b3e716c290108ddeb558a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga64c1f1a34730909ce48e01077620f877"><td class="memTemplParams" colspan="2">template&lt;typename RT , typename... Args&gt; </td></tr>
<tr class="memitem:ga64c1f1a34730909ce48e01077620f877"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classThreads_1_1Thread.html">Thread</a>&lt; RT &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__threads.html#ga64c1f1a34730909ce48e01077620f877">Threads::new_thread</a> (RT(*fun_ptr)(Args...), typename <a class="el" href="structidentity.html">identity</a>&lt; Args &gt;::type... args)</td></tr>
<tr class="separator:ga64c1f1a34730909ce48e01077620f877"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae29abb16b55e0f4c1630aa2fd166e1d1"><td class="memTemplParams" colspan="2">template&lt;typename RT , typename C , typename... Args&gt; </td></tr>
<tr class="memitem:gae29abb16b55e0f4c1630aa2fd166e1d1"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classThreads_1_1Thread.html">Thread</a>&lt; RT &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__threads.html#gae29abb16b55e0f4c1630aa2fd166e1d1">Threads::new_thread</a> (RT(C::*fun_ptr)(Args...), typename <a class="el" href="structidentity.html">identity</a>&lt; C &gt;::type &amp;c, typename <a class="el" href="structidentity.html">identity</a>&lt; Args &gt;::type... args)</td></tr>
<tr class="separator:gae29abb16b55e0f4c1630aa2fd166e1d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga9be703f998235b42c4fe86ed03e848db"><td class="memTemplParams" colspan="2">template&lt;typename RT , typename C , typename... Args&gt; </td></tr>
<tr class="memitem:ga9be703f998235b42c4fe86ed03e848db"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classThreads_1_1Thread.html">Thread</a>&lt; RT &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__threads.html#ga9be703f998235b42c4fe86ed03e848db">Threads::new_thread</a> (RT(C::*fun_ptr)(Args...) const, typename <a class="el" href="structidentity.html">identity</a>&lt; const C &gt;::type &amp;c, typename <a class="el" href="structidentity.html">identity</a>&lt; Args &gt;::type... args)</td></tr>
<tr class="separator:ga9be703f998235b42c4fe86ed03e848db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8c1e15b84e1bb58a8029fc6d6ddf3cbf"><td class="memTemplParams" colspan="2">template&lt;typename RT &gt; </td></tr>
<tr class="memitem:ga8c1e15b84e1bb58a8029fc6d6ddf3cbf"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classThreads_1_1Task.html">Task</a>&lt; RT &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__threads.html#ga8c1e15b84e1bb58a8029fc6d6ddf3cbf">Threads::new_task</a> (const std::function&lt; RT()&gt; &amp;function)</td></tr>
<tr class="separator:ga8c1e15b84e1bb58a8029fc6d6ddf3cbf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa9634848d075456afaf092e15848d5e6"><td class="memTemplParams" colspan="2">template&lt;typename RT , typename... Args&gt; </td></tr>
<tr class="memitem:gaa9634848d075456afaf092e15848d5e6"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classThreads_1_1Task.html">Task</a>&lt; RT &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__threads.html#gaa9634848d075456afaf092e15848d5e6">Threads::new_task</a> (RT(*fun_ptr)(Args...), typename <a class="el" href="structidentity.html">identity</a>&lt; Args &gt;::type... args)</td></tr>
<tr class="separator:gaa9634848d075456afaf092e15848d5e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae34fcb2cea316e52c99b4adec8be3ad4"><td class="memTemplParams" colspan="2">template&lt;typename RT , typename C , typename... Args&gt; </td></tr>
<tr class="memitem:gae34fcb2cea316e52c99b4adec8be3ad4"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classThreads_1_1Task.html">Task</a>&lt; RT &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__threads.html#gae34fcb2cea316e52c99b4adec8be3ad4">Threads::new_task</a> (RT(C::*fun_ptr)(Args...), typename <a class="el" href="structidentity.html">identity</a>&lt; C &gt;::type &amp;c, typename <a class="el" href="structidentity.html">identity</a>&lt; Args &gt;::type... args)</td></tr>
<tr class="separator:gae34fcb2cea316e52c99b4adec8be3ad4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae8ec93a716a57a11db00d87a8409b722"><td class="memTemplParams" colspan="2">template&lt;typename RT , typename C , typename... Args&gt; </td></tr>
<tr class="memitem:gae8ec93a716a57a11db00d87a8409b722"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classThreads_1_1Task.html">Task</a>&lt; RT &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group__threads.html#gae8ec93a716a57a11db00d87a8409b722">Threads::new_task</a> (RT(C::*fun_ptr)(Args...) const, typename <a class="el" href="structidentity.html">identity</a>&lt; const C &gt;::type &amp;c, typename <a class="el" href="structidentity.html">identity</a>&lt; Args &gt;::type... args)</td></tr>
<tr class="separator:gae8ec93a716a57a11db00d87a8409b722"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<p>A module discussing the use of parallelism on shared memory machines. See the detailed documentation and <a class="el" href="group__threads.html#MTToC">Table of Contents</a> below the lengthy list of members of this module. </p>
<dl class="section note"><dt>Note</dt><dd>The material presented here is also discussed in <a href="http://www.math.colostate.edu/~bangerth/videos.676.39.html">video lecture 39</a>, <a href="http://www.math.colostate.edu/~bangerth/videos.676.40.html">video lecture 40</a>. (All video lectures are also available <a href="http://www.math.colostate.edu/~bangerth/videos.html">here</a>.)</dd></dl>
<p>On machines with more than one processor (or multicore processors), it is often profitable to run several parts of the computations in parallel. For example, one could have several threads running in parallel, each of which assembles the cell matrices of a subset of the triangulation and then writes them into the global matrix. Since assembling matrices is often an expensive operation, this frequently leads to significant savings in compute time on multiprocessor machines.</p>
<p>deal.II supports operations running in parallel on shared-memory (SMP) machines through the functions and classes in the <a class="el" href="namespaceThreads.html">Threads</a> namespace. The <a class="el" href="classMultithreadInfo.html">MultithreadInfo</a> class allows to query certain properties of the system, such as the number of CPUs. These facilities for parallel computing are described in the following. The step-9, step-13, step-14, step-32, step-35 and step-37 tutorial programs also show their use in practice, with the ones starting with step-32 using a more modern style of doing things in which essentially we describe <em>what</em> can be done in parallel, while the older tutorial programs describe <em>how</em> things have to be done in parallel.</p>
<p>On the other hand, programs running on distributed memory machines (i.e. clusters) need a different programming model built on top of MPI and PETSc or Trilinos. This is described in the step-17, step-18 and step-32 example programs.</p>
<p><a class="anchor" id="MTToC"></a> </p><table class="tutorial" width="50%">
<tr>
<th><b>Table of contents</b> </th></tr>
<tr>
<td width="100%" valign="top"><ol>
<li>
<a class="el" href="group__threads.html#MTTasks">Task-based parallelism</a> </li>
<li>
<a class="el" href="group__threads.html#MTUsing">Using tasks from within deal.II</a> </li>
<li>
<a class="el" href="group__threads.html#MTHow">How scheduling tasks works and when task-based programming is not efficient</a> </li>
<li>
<a class="el" href="group__threads.html#MTSimpleLoops">Abstractions for tasks: Simple loops</a> </li>
<li>
<a class="el" href="group__threads.html#MTComplexLoops">Abstractions for tasks: More complex loops</a> </li>
<li>
<a class="el" href="group__threads.html#MTWorkStream">Abstractions for tasks: Work streams</a> </li>
<li>
<a class="el" href="group__threads.html#MTTaskSynchronization">Tasks and synchronization</a> </li>
<li>
<a class="el" href="group__threads.html#MTThreads">Thread-based parallelism</a> </li>
<li>
<a class="el" href="group__threads.html#MTTaskThreads">Controlling the number of threads used for tasks</a> </li>
</ol>
</td></tr>
</table>
<p><a class="anchor" id="MTTasks"></a> </p><h3>Task-based parallelism</h3>
<p>The traditional view of parallelism on shared memory machines has been to decompose a program into <em>threads</em>, i.e. running different parts of the program in parallel <em>at the same time</em> (if there are more threads than processor cores on your machine, the operating system will run each thread round-robin for a brief amount of time before switching execution to another thread, thereby simulating that threads run concurrently). deal.II's facilities for threads are described below (see <a class="el" href="group__threads.html#MTThreads">Thread-based parallelism</a>), but we would first like to discuss an abstraction that is often more suitable than threads: <em>tasks</em>.</p>
<p>Tasks are essentially the individual parts of a program. Some of them are independent, whereas others depend on previous tasks to be completed first. By way of example, consider the typical layout of a part of the <code>setup_dofs</code> function that most of the tutorial programs have: </p><div class="fragment"><div class="line">1  dof_handler.distribute_dofs (fe);</div><div class="line">2  <a class="code" href="group__constraints.html#ga3b4ea7dfd313e388d868c4e4aa685799">DoFTools::make_hanging_node_constraints</a> (dof_handler, hanging_node_constraints);</div><div class="line">3  <a class="code" href="group__constraints.html#gaf78e864edbfba7e0a7477457bfb96b26">DoFTools::make_sparsity_pattern</a> (dof_handler, sparsity_pattern);</div><div class="line">4  hanging_node_constraints.condense (sparsity_pattern);</div></div><!-- fragment --><p>Here, each of the operations require a significant amount of computations. But note that not all of them depend on each other: clearly we can not run statements 2-4 before 1, and 4 needs to wait for the completion of statements 2 and 3. But statements 2 and 3 are independent: they could be run in any order, or in parallel. In essence, we have identified four <em>tasks</em>, some of which are dependent on each other, whereas others are independent. In the current example, tasks are identified with individual C++ statements, but often they more generally coincide with entire code blocks.</p>
<p>The point here is this: If we wanted to use threads to exploit the independence of tasks 2 and 3, we would start two threads and run each of tasks 2 and 3 on its own thread; we would then wait for the two threads to finish (an operation called "joining a thread") and go on with statement 4. Code to achieve this would look like this (the actual syntax is explained in more detail below): </p><div class="fragment"><div class="line">dof_handler.distribute_dofs (fe);</div><div class="line"></div><div class="line"><a class="code" href="classThreads_1_1Thread.html">Threads::Thread&lt;void&gt;</a></div><div class="line">  thread_1 = <a class="code" href="group__threads.html#ga2003df2a027b3e716c290108ddeb558a">Threads::new_thread</a> (&amp;<a class="code" href="group__constraints.html#ga3b4ea7dfd313e388d868c4e4aa685799">DoFTools::make_hanging_node_constraints</a>,</div><div class="line">                                  dof_handler, hanging_node_constraints);</div><div class="line"><a class="code" href="classThreads_1_1Thread.html">Threads::Thread&lt;void&gt;</a></div><div class="line">  thread_2 = <a class="code" href="group__threads.html#ga2003df2a027b3e716c290108ddeb558a">Threads::new_thread</a> (&amp;<a class="code" href="group__constraints.html#gaf78e864edbfba7e0a7477457bfb96b26">DoFTools::make_sparsity_pattern</a>,</div><div class="line">                                  dof_handler, sparsity_pattern);</div><div class="line">thread_1.<a class="code" href="classThreads_1_1Thread.html#a1d5e3a7d251c2fdedfd29d313f5d636a">join</a>();</div><div class="line">thread_2.<a class="code" href="classThreads_1_1Thread.html#a1d5e3a7d251c2fdedfd29d313f5d636a">join</a>();</div><div class="line">hanging_node_constraints.condense (sparsity_pattern);</div></div><!-- fragment --><p>But what if your computer has only one processor core, or if we have two but there is already a different part of the program running in parallel to the code above? In that case, the code above would still start new threads, but the program is not going to run faster since no additional compute resources are available; rather, the program will run slower since threads have to be created and destroyed, and the operating system has to schedule threads to oversubscribed compute resources.</p>
<p>A better scheme would identify independent tasks and then hand them off to a scheduler that maps tasks to available compute resources. This way, the program could, for example, start one thread per processor core and then let threads work on tasks. Tasks would run to completion, rather than concurrently, avoiding the overhead of interrupting threads to run a different thread. In this model, if two processor cores are available, tasks 2 and 3 above would run in parallel; if only one is available, the scheduler would first completely execute task 2 before doing task 3, or the other way around. This model is able to execute much more efficiently in particular if a large number of tasks is available for execution, see for example the discussion below in section <a class="el" href="group__threads.html#MTWorkStream">Abstractions for tasks: Work streams</a>. In essence, tasks are a high-level description of what needs to be done, whereas threads are a low-level way of implementing how these tasks can be completed. As in many other instances, being able to use a high-level description allows to find efficient low-level implementations; in this vein, it often pays off to use tasks, rather than threads, in a program.</p>
<p>deal.II does not implement scheduling tasks to threads itself. For this, we use the <a href="http://www.threadingbuildingblocks.org" target="_top">Threading Building Blocks (TBB) library</a> for which we provide simple wrappers. TBB abstracts the details of how to start or stop threads, start tasks on individual threads, etc, and provides interfaces that are portable across many different systems.</p>
<p><a class="anchor" id="MTUsing"></a> </p><h3>Using tasks from within deal.II</h3>
<p>Ideally, the syntax to start tasks (and similarly for threads, for that matter), would be something like this for the example above: </p><div class="fragment"><div class="line"><a class="code" href="classThreads_1_1Task.html">Threads::Task&lt;void&gt;</a></div><div class="line">  thread</div><div class="line">  = <a class="code" href="group__threads.html#ga8c1e15b84e1bb58a8029fc6d6ddf3cbf">new_task</a> <a class="code" href="group__constraints.html#ga3b4ea7dfd313e388d868c4e4aa685799">DoFTools::make_hanging_node_constraints</a> (dof_handler,</div><div class="line">                                                      hanging_node_constraints);</div></div><!-- fragment --><p> In other words, we would like to indicate the fact that the function call should be run on a separate task by simply prefixing the call with a keyword (such as <code>new_task</code> here, with a similar keyword <code>new_thread</code> for threads). Prefixing a call would return a handle for the task that we can use to wait for the task's completion and that we may use to query the return value of the function called (unless it is void, as it is here).</p>
<p>Since C++ does not support the creation of new keywords, we have to be a bit more creative. The way chosen is to introduce a function <code>new_task</code> that takes as arguments the function to call as well as the arguments to the call. The <code>new_task</code> function is overloaded to accommodate starting tasks with functions that take no, one, two, and up to 9 arguments. In deal.II, these functions live in the <a class="el" href="namespaceThreads.html">Threads</a> namespace. Consequently, the actual code for what we try to do above looks like this: </p><div class="fragment"><div class="line"><a class="code" href="classThreads_1_1Task.html">Threads::Task&lt;void&gt;</a></div><div class="line">  thread</div><div class="line">  = <a class="code" href="group__threads.html#ga8c1e15b84e1bb58a8029fc6d6ddf3cbf">Threads::new_task</a> (&amp;<a class="code" href="group__constraints.html#ga3b4ea7dfd313e388d868c4e4aa685799">DoFTools::make_hanging_node_constraints</a>,</div><div class="line">                       dof_handler,</div><div class="line">                       hanging_node_constraints);</div></div><!-- fragment --><p>Similarly, if we want to call a member function on a different task, we can do so by specifying the object on which to call the function as first argument after the function pointer: </p><div class="fragment"><div class="line"><span class="keyword">class </span>C {</div><div class="line">  <span class="keyword">public</span>:</div><div class="line">    <span class="keywordtype">double</span> f(<span class="keywordtype">int</span>);</div><div class="line">};</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main () {</div><div class="line">  C c;</div><div class="line"></div><div class="line">  <span class="comment">// call f(13) as usual, i.e. using the current processor:</span></div><div class="line">  c.f(13);</div><div class="line"></div><div class="line">  <span class="comment">// call f(42) as a separate task, to be scheduled</span></div><div class="line">  <span class="comment">// whenever processor resources become available:</span></div><div class="line">  <a class="code" href="classThreads_1_1Task.html">Threads::Task&lt;double&gt;</a></div><div class="line">    task = <a class="code" href="group__threads.html#ga8c1e15b84e1bb58a8029fc6d6ddf3cbf">Threads::new_task</a> (&amp;C::f, c, 42);</div><div class="line"></div><div class="line">  <span class="comment">// do something else in between:</span></div><div class="line">  ...;</div><div class="line"></div><div class="line">  <span class="comment">// having finished our other business, wait until the task</span></div><div class="line">  <span class="comment">// above has terminated and get the value returns by c.f(42):</span></div><div class="line">  <span class="keywordtype">double</span> result = task.<a class="code" href="classThreads_1_1Task.html#a96fcdeb8b68a762ed3f50594689b9b58">return_value</a>();</div></div><!-- fragment --><p> Here, note first how we pass the object <code>c</code> (i.e. the <code>this</code> pointer the function <code>C::f</code> will see) as if it was the first argument to the function. Secondly, note how we can acquire the value returned by the function on the separate task by calling <a class="el" href="classThreads_1_1Task.html#a96fcdeb8b68a762ed3f50594689b9b58">Threads::Task::return_value()</a>. This function implies waiting for the completion of the task, i.e. the last line is completely equivalent to </p><div class="fragment"><div class="line">task.<a class="code" href="classThreads_1_1Task.html#a9aed8f99d2b88bd0d6cfff95e38c3ac7">join</a> ();</div><div class="line"><span class="keywordtype">double</span> result = task.<a class="code" href="classThreads_1_1Task.html#a96fcdeb8b68a762ed3f50594689b9b58">return_value</a>();</div></div><!-- fragment --><p>Note also that it is entirely valid if <code>C::f</code> wants to start tasks of its own: </p><div class="fragment"><div class="line"><span class="keyword">class </span>C {</div><div class="line">  <span class="keyword">public</span>:</div><div class="line">    <span class="keywordtype">double</span> f(<span class="keywordtype">int</span>);</div><div class="line">  <span class="keyword">private</span>:</div><div class="line">    <span class="keywordtype">double</span> f1(<span class="keywordtype">int</span>);</div><div class="line">    <span class="keywordtype">double</span> f2(<span class="keywordtype">int</span>);</div><div class="line">};</div><div class="line"></div><div class="line"><span class="keywordtype">double</span> C::f (<span class="keywordtype">int</span> i) {</div><div class="line">  <a class="code" href="classThreads_1_1Task.html">Threads::Task&lt;double&gt;</a> t1 = <a class="code" href="group__threads.html#ga8c1e15b84e1bb58a8029fc6d6ddf3cbf">Threads::new_task</a> (&amp;C::f1, *<span class="keyword">this</span>, i);</div><div class="line">  <a class="code" href="classThreads_1_1Task.html">Threads::Task&lt;double&gt;</a> t2 = <a class="code" href="group__threads.html#ga8c1e15b84e1bb58a8029fc6d6ddf3cbf">Threads::new_task</a> (&amp;C::f2, *<span class="keyword">this</span>, i);</div><div class="line">  <span class="keywordflow">return</span> t1.<a class="code" href="classThreads_1_1Task.html#a96fcdeb8b68a762ed3f50594689b9b58">return_value</a>() + t2.<a class="code" href="classThreads_1_1Task.html#a96fcdeb8b68a762ed3f50594689b9b58">return_value</a>();</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main () {</div><div class="line">  C c;</div><div class="line"></div><div class="line">  <a class="code" href="classThreads_1_1Task.html">Threads::Task&lt;double&gt;</a></div><div class="line">    task = <a class="code" href="group__threads.html#ga8c1e15b84e1bb58a8029fc6d6ddf3cbf">Threads::new_task</a> (&amp;C::f, c, 42);</div><div class="line"></div><div class="line">  <span class="comment">// do something else in between:</span></div><div class="line">  ...;</div><div class="line"></div><div class="line">  <span class="keywordtype">double</span> result = task.<a class="code" href="classThreads_1_1Task.html#a96fcdeb8b68a762ed3f50594689b9b58">return_value</a>();</div></div><!-- fragment --><p> Here, we let <code>C::f</code> compute its return value as <code>c.f1(i)+c.f2(i)</code>. If sufficient CPU resources are available, then the two parts of the addition as well as the other things in <code>main()</code> will all run in parallel. If not, then we will eventually block at one of the places where the return value is needed, thereby freeing up the CPU resources necessary to run all those spawned tasks to completion.</p>
<p>In many cases, such as the introductory example of the <code>setup_dofs</code> function outlined above, one can identify several independent jobs that can be run as tasks, but will have to wait for all of them to finish at one point. One can do so by storing the returned object from all the <a class="el" href="group__threads.html#ga8c1e15b84e1bb58a8029fc6d6ddf3cbf">Threads::new_task()</a> calls, and calling <a class="el" href="classThreads_1_1Task.html#a9aed8f99d2b88bd0d6cfff95e38c3ac7">Threads::Task::join()</a> on each one of them. A simpler way to do this is to put all of these task objects into a <a class="el" href="classThreads_1_1TaskGroup.html">Threads::TaskGroup</a> object and waiting for all of them at once. The code would then look like this: </p><div class="fragment"><div class="line">dof_handler.distribute_dofs (fe);</div><div class="line"></div><div class="line"><a class="code" href="classThreads_1_1TaskGroup.html">Threads::TaskGroup&lt;void&gt;</a> task_group;</div><div class="line">task_group += <a class="code" href="group__threads.html#ga8c1e15b84e1bb58a8029fc6d6ddf3cbf">Threads::new_task</a> (&amp;<a class="code" href="group__constraints.html#ga3b4ea7dfd313e388d868c4e4aa685799">DoFTools::make_hanging_node_constraints</a>,</div><div class="line">                                 dof_handler, hanging_node_constraints);</div><div class="line">task_group += <a class="code" href="group__threads.html#ga8c1e15b84e1bb58a8029fc6d6ddf3cbf">Threads::new_task</a> (&amp;<a class="code" href="group__constraints.html#gaf78e864edbfba7e0a7477457bfb96b26">DoFTools::make_sparsity_pattern</a>,</div><div class="line">                                 dof_handler, sparsity_pattern);</div><div class="line">task_group.<a class="code" href="classThreads_1_1TaskGroup.html#a2917c607a567538f8e560c849fa88ac6">join_all</a> ();</div><div class="line">hanging_node_constraints.condense (sparsity_pattern);</div></div><!-- fragment --><p><a class="anchor" id="MTHow"></a> </p><h3>How scheduling tasks works and when task-based programming is not efficient</h3>
<p>The exact details of how tasks are scheduled to run are internal to the Threading Building Blocks (TBB) library that deal.II uses for tasks. The documentation of TBB gives a detailed description of how tasks are scheduled to threads but is rather quiet on how many threads are actually used. However, a reasonable guess is probably to assume that TBB creates as many threads as there are processor cores on your system. This way, it is able to fully utilize the entire system, without having too many threads that the operating system will then have to interrupt regularly so that other threads can run on the available processor cores.</p>
<p>The point then is that the TBB scheduler takes tasks and lets threads execute them. Threads execute tasks completely, i.e. the TBB scheduler does not interrupt a task half way through to make some halfway progress with another task. This makes sure that caches are always hot, for example, and avoids the overhead of preemptive interrupts.</p>
<p>The downside is that the CPU cores are only fully utilized if the threads are actually doing something, and that means that (i) there must be enough tasks available, and (ii) these tasks are actually doing something. Note that both conditions must be met; in particular, this means that CPU cores are underutilized if we have identified a sufficient number of tasks but if some of them twiddle thumbs, for example because a task is writing data to disk (a process where the CPU frequently has to wait for the disk to complete a transaction) or is waiting for input. Other cases are where tasks block on other external events, for example synchronising with other tasks or threads through a mutex. In such cases, the scheduler would let a task run on a thread, but doesn't notice that that thread doesn't fully utilize the CPU core.</p>
<p>In cases like these, it <em>does</em> make sense to create a new thread (see <a class="el" href="group__threads.html#MTThreads">Thread-based parallelism</a> below) that the operating system can put on hold while they are waiting for something external, and let a different thread (for example one running a task scheduled by TBB) use the CPU at the same time.</p>
<p><a class="anchor" id="MTSimpleLoops"></a> </p><h3>Abstractions for tasks: Simple loops</h3>
<p>Some loops execute bodies on data that is completely independent and that can therefore be executed in parallel. Rather than a priori split the loop into a fixed number of chunks and executing them on tasks or threads, the TBB library uses the following concept: the range over which the loop iterates is split into a certain number of sub-ranges (for example two or three times as many as there are CPU cores) and are equally distributed among threads; threads then execute sub-ranges and, if they are done with their work, steal entire or parts of sub-ranges from other threads to keep busy. This way, work is load-balanced even if not every loop iteration takes equally much work, or if some of the CPU cores fall behind because the operating system interrupted them for some other work.</p>
<p>The TBB library primitives for this are a bit clumsy so deal.II has wrapper routines for the most frequently used operations. The simplest one is akin to what the std::transform does: it takes one or more ranges of input operators, one output iterator, and a function object. A typical implementation of std::transform would look like this: </p><div class="fragment"><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> InputIterator1, <span class="keyword">typename</span> InputIterator,</div><div class="line">          <span class="keyword">typename</span> OutputIterator, <span class="keyword">typename</span> FunctionObject&gt;</div><div class="line"><span class="keywordtype">void</span> <a class="code" href="namespaceparallel.html#acff5a80eecf505943d8abbec0658ae93">transform</a> (<span class="keyword">const</span> InputIterator1 &amp;begin_in_1,</div><div class="line">                <span class="keyword">const</span> InputIterator1 &amp;end_in_1,</div><div class="line">                <span class="keyword">const</span> InputIterator2 &amp;begin_in_2,</div><div class="line">                <span class="keyword">const</span> OutputIterator &amp;begin_out,</div><div class="line">                FunctionObject       &amp;<span class="keyword">function</span>)</div><div class="line">{</div><div class="line">  InputIterator1 in_1 = begin_in_1;</div><div class="line">  InputIterator2 in_2 = begin_in_2;</div><div class="line">  OutputIterator out  = begin_out;</div><div class="line"></div><div class="line">  <span class="keywordflow">for</span> (; in_1 != end_in_1; ++in_1, ++in_2, ++out)</div><div class="line">    *out = <span class="keyword">function</span>(*in_1, *in_2);</div><div class="line">}</div></div><!-- fragment --><p>In many cases, <code>function</code> has no state, and so we can split this loop into several sub-ranges as explained above. Consequently, deal.II has a set of functions <a class="el" href="namespaceparallel.html#acff5a80eecf505943d8abbec0658ae93">parallel::transform</a> that look like the one above but that do their work in parallel (there are several versions with one, two, and more input iterators for function objects that take one, two, or more arguments). The only difference in calling these functions is that they take an additional last argument that denotes the minimum size of sub-ranges of <code>[begin_in_1,end_in_1)</code>; it should be big enough so that we don't spend more time on scheduling sub-ranges to processors but small enough that processors can be efficiently load balanced. A rule of thumb appears to be that a sub-range is too small if it takes less than 2000 instructions to execute it.</p>
<p>An example of how to use these functions are vector operations like the addition in \(z = x+y\) where all three objects are of type <a class="el" href="classLinearAlgebra_1_1distributed_1_1Vector.html">Vector&lt;Number&gt;</a>: </p><div class="fragment"><div class="line"><a class="code" href="namespaceparallel.html#acff5a80eecf505943d8abbec0658ae93">parallel::transform</a> (x.begin(), x.end(),</div><div class="line">                     y.begin(),</div><div class="line">                     z.begin(),</div><div class="line">                     [](<span class="keyword">const</span> Number first, <span class="keyword">const</span> Number second)</div><div class="line">                     {</div><div class="line">                       <span class="keywordflow">return</span> first+second;</div><div class="line">                     },</div><div class="line">                     1000);</div></div><!-- fragment --><p>In this example, we used a <em>lambda expression</em> to construct, on the fly, a function object that takes two arguments and returns the sum of the two. This is exactly what we needed when we want to add the individual elements of vectors \(x\) and \(y\) and write the sum of the two into the elements of \(z\). The function object that we get here is completely known to the compiler and when it expands the loop that results from <a class="el" href="namespaceparallel.html#acff5a80eecf505943d8abbec0658ae93">parallel::transform</a> will be as if we had written the loop in its obvious form: </p><div class="fragment"><div class="line">InputIterator1 in_1 = x.begin();</div><div class="line">InputIterator2 in_2 = y.begin();</div><div class="line">OutputIterator out  = z.begin();</div><div class="line"></div><div class="line"><span class="keywordflow">for</span> (; in_1 != x.end(); ++in_1, ++in_2, ++out)</div><div class="line">  *out = *in_1 + *in_2;</div></div><!-- fragment --><p>Note also that we have made sure that no CPU ever gets a chunk of the whole loop that is smaller than 1000 iterations (unless the whole range is smaller).</p>
<p><a class="anchor" id="MTComplexLoops"></a> </p><h3>Abstractions for tasks: More complex loops</h3>
<p>The scheme shown in the previous section is effective if the operation done in each iteration is such that it does not require significant setup costs and can be inlined by the compiler. <em>Lambda expressions</em> are exactly of this kind, thereby eliminating the overhead of calling an external function. However, there are cases where it is inefficient to call some object or function within each iteration.</p>
<p>An example for this case is sparse matrix-vector multiplication. If you know how data is stored in compressed row format like in the <a class="el" href="classSparseMatrix.html">SparseMatrix</a> class, then a matrix-vector product function looks like this: </p><div class="fragment"><div class="line"><span class="keywordtype">void</span> <a class="code" href="classSparseMatrix.html#a7706b5f721efc5ea1966f5a5cdaad0e6">SparseMatrix::vmult</a> (<span class="keyword">const</span> <a class="code" href="classVector.html">Vector</a> &amp;src,</div><div class="line">                          <a class="code" href="classVector.html">Vector</a>       &amp;dst)<span class="keyword"> const</span></div><div class="line"><span class="keyword"></span>{</div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">double</span>       *val_ptr    = &amp;<a class="code" href="namespaceEvaluationFlags.html#a9b7c6d689cb76386839d0d13640f59aeaf9825c682f693a6a200094641a0d6a58">values</a>[0];</div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> *colnum_ptr = &amp;colnums[0];</div><div class="line">  <a class="code" href="classVector.html#acb8006e49918faaffeccd151669d0934">Vector::iterator</a> dst_ptr = dst.<a class="code" href="classVector.html#af34b888fe493ef2ed188179de69ad7ed">begin</a>();</div><div class="line"></div><div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> row=0; row&lt;n_rows; ++row, ++dst_ptr)</div><div class="line">    {</div><div class="line">      <span class="keywordtype">double</span> s = 0.;</div><div class="line">      <span class="keyword">const</span> <span class="keywordtype">double</span> *<span class="keyword">const</span> val_end_of_row = &amp;<a class="code" href="namespaceEvaluationFlags.html#a9b7c6d689cb76386839d0d13640f59aeaf9825c682f693a6a200094641a0d6a58">values</a>[rowstart[row+1]];</div><div class="line">      <span class="keywordflow">while</span> (val_ptr != val_end_of_row)</div><div class="line">        s += *val_ptr++ * src(*colnum_ptr++);</div><div class="line">      *dst_ptr = s;</div><div class="line">    }</div><div class="line">}</div></div><!-- fragment --><p> Inside the for loop, we compute the dot product of a single row of the matrix with the right hand side vector <code>src</code> and write it into the corresponding element of the <code>dst</code> vector. The code is made more efficient by utilizing that the elements of the <em>next</em> row follow the ones of the current row <em>immediately</em>, i.e. at the beginning of the loop body we do not have to re-set the pointers that point to the values and column numbers of each row.</p>
<p>Using the <a class="el" href="namespaceparallel.html#acff5a80eecf505943d8abbec0658ae93">parallel::transform</a> function above, we could in principle write this code as follows: </p><div class="fragment"><div class="line"><span class="keywordtype">void</span> SparseMatrix::vmult_one_row (<span class="keyword">const</span> <a class="code" href="classVector.html">Vector</a>     &amp;src,</div><div class="line">                                  <a class="code" href="classVector.html">Vector</a>           &amp;dst,</div><div class="line">                                  <a class="code" href="classVector.html#acb8006e49918faaffeccd151669d0934">Vector::iterator</a> &amp;dst_row)<span class="keyword"> const</span></div><div class="line"><span class="keyword"></span>{</div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>  row = (dst_row - dst.<a class="code" href="classVector.html#af34b888fe493ef2ed188179de69ad7ed">begin</a>());</div><div class="line"></div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">double</span>       *val_ptr    = &amp;<a class="code" href="namespaceEvaluationFlags.html#a9b7c6d689cb76386839d0d13640f59aeaf9825c682f693a6a200094641a0d6a58">values</a>[rowstart[row]];</div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> *colnum_ptr = &amp;colnums[rowstart[row]];</div><div class="line"></div><div class="line">  <span class="keywordtype">double</span> s = 0.;</div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">double</span> *<span class="keyword">const</span> val_end_of_row = &amp;<a class="code" href="namespaceEvaluationFlags.html#a9b7c6d689cb76386839d0d13640f59aeaf9825c682f693a6a200094641a0d6a58">values</a>[rowstart[row+1]];</div><div class="line">  <span class="keywordflow">while</span> (val_ptr != val_end_of_row)</div><div class="line">    s += *val_ptr++ * src(*colnum_ptr++);</div><div class="line">  *dst_row = s;</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">void</span> <a class="code" href="classSparseMatrix.html#a7706b5f721efc5ea1966f5a5cdaad0e6">SparseMatrix::vmult</a> (<span class="keyword">const</span> <a class="code" href="classVector.html">Vector</a> &amp;src,</div><div class="line">                          <a class="code" href="classVector.html">Vector</a>       &amp;dst)<span class="keyword"> const</span></div><div class="line"><span class="keyword"></span>{</div><div class="line">  <a class="code" href="namespaceparallel.html#acff5a80eecf505943d8abbec0658ae93">parallel::transform</a> (dst.<a class="code" href="classVector.html#af34b888fe493ef2ed188179de69ad7ed">begin</a>(), dst.<a class="code" href="classVector.html#a7a2a770cb19d3e5b0b69b08ffc88184f">end</a>(),</div><div class="line">                       std::bind (&amp;SparseMatrix::vmult_one_row,</div><div class="line">                                  <span class="keyword">this</span>,</div><div class="line">                                  std::cref(src),</div><div class="line">                                  std::ref(dst),</div><div class="line">                                  std::_1),</div><div class="line">                       200);</div><div class="line">}</div></div><!-- fragment --><p> Note how we use <code>std::bind</code> to <em>bind</em> certain arguments to the <code>vmult_one_row</code> function, leaving one argument open and thus allowing the <a class="el" href="namespaceparallel.html#acff5a80eecf505943d8abbec0658ae93">parallel::transform</a> function to consider the passed function argument as unary. Also note that we need to make the source and destination vectors as (const) references to prevent <code>std::bind</code> from passing them by value (implying a copy for <code>src</code> and writing the result into a temporary copy of <code>dst</code>, neither of which is what we desired). Finally, notice the grainsize of a minimum of 200 rows of a matrix that should be processed by an individual CPU core.</p>
<p>The point is that while this is correct, it is not efficient: we have to set up the <code>row, val_ptr, colnum_ptr</code> variables in each iteration of the loop. Furthermore, since now the function object to be called on each row is not a simple <em>lambda expression</em> any more, there is an implicit function call including argument passing in each iteration of the loop.</p>
<p>A more efficient way is to let TBB split the original range into sub-ranges, and then call a target function not on each individual element of the loop, but on the entire range. This is facilitated by the <a class="el" href="namespaceparallel.html#aa860d510323b29ede22a7f69f5dc41ad">parallel::apply_to_subranges</a> function: </p><div class="fragment"><div class="line"><span class="keywordtype">void</span></div><div class="line">SparseMatrix::vmult_on_subrange (<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>  begin_row,</div><div class="line">                                 <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>  end_row,</div><div class="line">                                 <span class="keyword">const</span> <a class="code" href="classVector.html">Vector</a>     &amp;src,</div><div class="line">                                 <a class="code" href="classVector.html">Vector</a>           &amp;dst)</div><div class="line">{</div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">double</span>       *val_ptr    = &amp;<a class="code" href="namespaceEvaluationFlags.html#a9b7c6d689cb76386839d0d13640f59aeaf9825c682f693a6a200094641a0d6a58">values</a>[rowstart[begin_row]];</div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> *colnum_ptr = &amp;colnums[rowstart[begin_row]];</div><div class="line">  <a class="code" href="classVector.html#acb8006e49918faaffeccd151669d0934">Vector::iterator</a> dst_ptr = dst.<a class="code" href="classVector.html#af34b888fe493ef2ed188179de69ad7ed">begin</a>() + begin_row;</div><div class="line"></div><div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> row=begin_row; row&lt;end_row; ++row, ++dst_ptr)</div><div class="line">    {</div><div class="line">      <span class="keywordtype">double</span> s = 0.;</div><div class="line">      <span class="keyword">const</span> <span class="keywordtype">double</span> *<span class="keyword">const</span> val_end_of_row = &amp;<a class="code" href="namespaceEvaluationFlags.html#a9b7c6d689cb76386839d0d13640f59aeaf9825c682f693a6a200094641a0d6a58">values</a>[rowstart[row+1]];</div><div class="line">      <span class="keywordflow">while</span> (val_ptr != val_end_of_row)</div><div class="line">        s += *val_ptr++ * src(*colnum_ptr++);</div><div class="line">      *dst_ptr = s;</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">void</span> <a class="code" href="classSparseMatrix.html#a7706b5f721efc5ea1966f5a5cdaad0e6">SparseMatrix::vmult</a> (<span class="keyword">const</span> <a class="code" href="classVector.html">Vector</a> &amp;src,</div><div class="line">                          <a class="code" href="classVector.html">Vector</a>       &amp;dst)<span class="keyword"> const</span></div><div class="line"><span class="keyword"></span>{</div><div class="line">   <a class="code" href="namespaceparallel.html#aa860d510323b29ede22a7f69f5dc41ad">parallel::apply_to_subranges</a> (0, n_rows(),</div><div class="line">                                 std::bind (vmult_on_subrange,</div><div class="line">                                            <span class="keyword">this</span>,</div><div class="line">                                            std::_1, std::_2,</div><div class="line">                                            std::cref(src),</div><div class="line">                                            std::ref(dst)),</div><div class="line">                                 200);</div><div class="line">}</div></div><!-- fragment --><p> Here, we call the <code>vmult_on_subrange</code> function on sub-ranges of at least 200 elements each, so that the initial setup cost can amortize.</p>
<p>A related operation is when the loops over elements each produce a result that must then be accumulated (other reduction operations than addition of numbers would work as well). An example is to form the matrix norm \(x^T M x\) (it really is only a norm if \(M\) is positive definite, but let's assume for a moment that it is). A sequential implementation would look like this for sparse matrices: </p><div class="fragment"><div class="line"><span class="keywordtype">double</span> SparseMatrix::mat_norm (<span class="keyword">const</span> <a class="code" href="classVector.html">Vector</a> &amp;x)<span class="keyword"> const</span></div><div class="line"><span class="keyword"></span>{</div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">double</span>       *val_ptr    = &amp;<a class="code" href="namespaceEvaluationFlags.html#a9b7c6d689cb76386839d0d13640f59aeaf9825c682f693a6a200094641a0d6a58">values</a>[0];</div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> *colnum_ptr = &amp;colnums[0];</div><div class="line"></div><div class="line">  <span class="keywordtype">double</span> norm_sqr = 0;</div><div class="line"></div><div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> row=0; row&lt;n_rows; ++row, ++dst_ptr)</div><div class="line">    {</div><div class="line">      <span class="keywordtype">double</span> s = 0.;</div><div class="line">      <span class="keyword">const</span> <span class="keywordtype">double</span> *<span class="keyword">const</span> val_end_of_row = &amp;<a class="code" href="namespaceEvaluationFlags.html#a9b7c6d689cb76386839d0d13640f59aeaf9825c682f693a6a200094641a0d6a58">values</a>[rowstart[row+1]];</div><div class="line">      <span class="keywordflow">while</span> (val_ptr != val_end_of_row)</div><div class="line">        s += *val_ptr++ * x(*colnum_ptr++);</div><div class="line">      norm_sqr += x(row) * s;</div><div class="line">    }</div><div class="line"></div><div class="line">  <span class="keywordflow">return</span> <a class="code" href="vectorization_8h.html#a303f564e3c189251976da401ee2e44fa">std::sqrt</a> (norm_sqr);</div><div class="line">}</div></div><!-- fragment --><p>It would be nice if we could split this operation over several sub-ranges of rows, each of which compute their part of the square of the norm, add results together from the various sub-ranges, and then take the square root of the result. This is what the <a class="el" href="namespaceparallel.html#a7ffe536c55823d2dd1f60d12d2ca6afe">parallel::accumulate_from_subranges</a> function does (note that you have to specify the result type as a template argument and that, as usual, the minimum number of elements of the outer loop that can be scheduled on a single CPU core is given as the last argument): </p><div class="fragment"><div class="line"><span class="keywordtype">double</span></div><div class="line">SparseMatrix::mat_norm_sqr_on_subrange (<span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>  begin_row,</div><div class="line">                                        <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>  end_row,</div><div class="line">                                        <span class="keyword">const</span> <a class="code" href="classVector.html">Vector</a>     &amp;x)</div><div class="line">{</div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">double</span>       *val_ptr    = &amp;<a class="code" href="namespaceEvaluationFlags.html#a9b7c6d689cb76386839d0d13640f59aeaf9825c682f693a6a200094641a0d6a58">values</a>[rowstart[begin_row]];</div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> *colnum_ptr = &amp;colnums[rowstart[begin_row]];</div><div class="line">  <a class="code" href="classVector.html#acb8006e49918faaffeccd151669d0934">Vector::iterator</a> dst_ptr = dst.<a class="code" href="classVector.html#af34b888fe493ef2ed188179de69ad7ed">begin</a>() + begin_row;</div><div class="line"></div><div class="line">  <span class="keywordtype">double</span> norm_sqr = 0;</div><div class="line"></div><div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> row=begin_row; row&lt;end_row; ++row, ++dst_ptr)</div><div class="line">    {</div><div class="line">      <span class="keywordtype">double</span> s = 0.;</div><div class="line">      <span class="keyword">const</span> <span class="keywordtype">double</span> *<span class="keyword">const</span> val_end_of_row = &amp;<a class="code" href="namespaceEvaluationFlags.html#a9b7c6d689cb76386839d0d13640f59aeaf9825c682f693a6a200094641a0d6a58">values</a>[rowstart[row+1]];</div><div class="line">      <span class="keywordflow">while</span> (val_ptr != val_end_of_row)</div><div class="line">        s += *val_ptr++ * x(*colnum_ptr++);</div><div class="line">      norm_sqr += x(row) * s;</div><div class="line">    }</div><div class="line"></div><div class="line">  <span class="keywordflow">return</span> norm_sqr;</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">double</span> SparseMatrix::mat_norm (<span class="keyword">const</span> <a class="code" href="classVector.html">Vector</a> &amp;x)<span class="keyword"> const</span></div><div class="line"><span class="keyword"></span>{</div><div class="line">  <span class="keywordflow">return</span></div><div class="line">    <a class="code" href="vectorization_8h.html#a303f564e3c189251976da401ee2e44fa">std::sqrt</a></div><div class="line">    (<a class="code" href="namespaceparallel.html#a7ffe536c55823d2dd1f60d12d2ca6afe">parallel::accumulate_from_subranges</a> (0, n_rows(),</div><div class="line">                                          std::bind (mat_norm_sqr_on_subrange,</div><div class="line">                                                     <span class="keyword">this</span>,</div><div class="line">                                                     std::_1, std::_2,</div><div class="line">                                                     std::cref(x)),</div><div class="line">                                          200));</div><div class="line">}</div></div><!-- fragment --><p><a class="anchor" id="MTWorkStream"></a> </p><h3>Abstractions for tasks: Work streams</h3>
<p>In the examples shown in the introduction we had identified a number of functions that can be run as independent tasks. Ideally, this number of tasks is larger than the number of CPU cores (to keep them busy) but is also not exceedingly huge (so as not to inundate the scheduler with millions of tasks that will then have to be distributed to 2 or 4 cores, for example). There are, however, cases where we have many thousands or even millions of relatively independent jobs: for example, assembling local contributions to the global linear system on each cell of a mesh; evaluating an error estimator on each cell; or postprocessing on each cell computed data for output fall into this class. These cases can be treated using a software design pattern we call <a class="el" href="namespaceWorkStream.html">WorkStream</a>. In the following, we will walk through the rationale for this pattern and its implementation; more details as well as examples for the speedup that can be achieved with it are given in the <a class="el" href="DEALGlossary.html#workstream_paper">WorkStream paper</a>.</p>
<p>Code like this could then be written like this: </p><div class="fragment"><div class="line"><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> dim&gt;</div><div class="line"><span class="keywordtype">void</span> MyClass&lt;dim&gt;::assemble_on_one_cell (<span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classDoFHandler.html">DoFHandler&lt;dim&gt;::active_cell_iterator</a> &amp;cell)</div><div class="line">{ ... }</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> dim&gt;</div><div class="line"><span class="keywordtype">void</span> MyClass&lt;dim&gt;::assemble_system ()</div><div class="line">{</div><div class="line">  <a class="code" href="classThreads_1_1TaskGroup.html">Threads::TaskGroup&lt;void&gt;</a> task_group;</div><div class="line">  <span class="keywordflow">for</span> (<span class="keyword">typename</span> <a class="code" href="classDoFHandler.html">DoFHandler&lt;dim&gt;::active_cell_iterator</a></div><div class="line">         cell = dof_handler.<a class="code" href="classDoFHandler.html#a9a3bef554c6d22abe312e10e9475eecf">begin_active</a>();</div><div class="line">       cell != dof_handler.end(); ++cell)</div><div class="line">    task_group += <a class="code" href="group__threads.html#ga8c1e15b84e1bb58a8029fc6d6ddf3cbf">Threads::new_task</a> (&amp;MyClass&lt;dim&gt;::assemble_on_one_cell,</div><div class="line">                                     *<span class="keyword">this</span>,</div><div class="line">                                     cell);</div><div class="line">  task_group.<a class="code" href="classThreads_1_1TaskGroup.html#a2917c607a567538f8e560c849fa88ac6">join_all</a> ();</div><div class="line">}</div></div><!-- fragment --><p> On a big mesh, with maybe a million cells, this would create a massive number of tasks; while it would keep all CPU cores busy for a while, the overhead of first creating so many tasks, scheduling them, and then waiting for them would probably not lead to efficient code. A better strategy would be if the scheduler could somehow indicate that it has available resources, at which point we would feed it another newly created task, and we would do so until we run out of tasks and the ones that were created have been worked on.</p>
<p>This is essentially what the <a class="el" href="namespaceWorkStream.html#ab8ceb010811941c351803b671a19fb73">WorkStream::run</a> function does: You give it an iterator range from which it can draw objects to work on (in the above case it is the interval given by <code>dof_handler.begin_active()</code> to <code><a class="el" href="namespaceTrilinosWrappers_1_1internal.html#aee42c8e3004e2e81eac3c3356d3ec46b">dof_handler.end()</a></code>), and a function that would do the work on each item (the function <code>MyClass::assemble_on_one_cell</code>) together with an object if it is a member function.</p>
<p>In the following, let us lay out a rationale for why the functions in the <a class="el" href="namespaceWorkStream.html">WorkStream</a> namespace are implemented the way they are. More information on their implementation can be found in the <a class="el" href="DEALGlossary.html#workstream_paper">WorkStream paper</a>. To see the <a class="el" href="namespaceWorkStream.html">WorkStream</a> class used in practice on tasks like the ones outlined above, take a look at the step-9, step-13, step-14, step-32, step-35 or step-37 tutorial programs.</p>
<p>To begin with, given the brief description above, the way the <code>MyClass::assemble_system</code> function could then be written is like this (note that this is not quite the correct syntax, as will be described below): </p><div class="fragment"><div class="line"><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> dim&gt;</div><div class="line"><span class="keywordtype">void</span> MyClass&lt;dim&gt;::assemble_on_one_cell (<span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classDoFHandler.html">DoFHandler&lt;dim&gt;::active_cell_iterator</a> &amp;cell)</div><div class="line">{ ... }</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> dim&gt;</div><div class="line"><span class="keywordtype">void</span> MyClass&lt;dim&gt;::assemble_system ()</div><div class="line">{</div><div class="line">  <a class="code" href="namespaceWorkStream.html#ab8ceb010811941c351803b671a19fb73">WorkStream::run</a> (dof_handler.begin_active(),</div><div class="line">                   dof_handler.end(),</div><div class="line">                   *<span class="keyword">this</span>,</div><div class="line">                   &amp;MyClass&lt;dim&gt;::assemble_on_one_cell);</div><div class="line">}</div></div><!-- fragment --><p>There are at least three problems with this, however: </p><ul>
<li>
<p class="startli">First, let us take a look at how the <code>MyClass::assemble_on_one_cell</code> function likely looks: </p><div class="fragment"><div class="line"><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> dim&gt;</div><div class="line"><span class="keywordtype">void</span> MyClass&lt;dim&gt;::assemble_on_one_cell (<span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classDoFHandler.html">DoFHandler&lt;dim&gt;::active_cell_iterator</a> &amp;cell)</div><div class="line">{</div><div class="line">  <a class="code" href="classFEValues.html">FEValues&lt;dim&gt;</a> fe_values (...);</div><div class="line">  <a class="code" href="classFullMatrix.html">FullMatrix&lt;double&gt;</a> <a class="code" href="namespaceLocalIntegrators_1_1Advection.html#a8bc7b8136646134f73a4193adefe15f8">cell_matrix</a> (...);</div><div class="line">  <a class="code" href="classVector.html">Vector&lt;double&gt;</a>     cell_rhs (...);</div><div class="line"></div><div class="line">  <span class="comment">// assemble local contributions</span></div><div class="line">  fe_values.reinit (cell);</div><div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i=0; i&lt;fe.dofs_per_cell; ++i)</div><div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j=0; j&lt;fe.dofs_per_cell; ++j)</div><div class="line">      <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> q=0; q&lt;fe_values.n_quadrature_points; ++q)</div><div class="line">        <a class="code" href="namespaceLocalIntegrators_1_1Advection.html#a8bc7b8136646134f73a4193adefe15f8">cell_matrix</a>(i,j) += ...;</div><div class="line">  ...same <span class="keywordflow">for</span> cell_rhs...</div><div class="line"></div><div class="line">  <span class="comment">// now copy results into global system</span></div><div class="line">  std::vector&lt;unsigned int&gt; dof_indices (...);</div><div class="line">  cell-&gt;get_dof_indices (dof_indices);</div><div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i=0; i&lt;fe.dofs_per_cell; ++i)</div><div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j=0; j&lt;fe.dofs_per_cell; ++j)</div><div class="line">      system_matrix.add (dof_indices[i], dof_indices[j],</div><div class="line">                         <a class="code" href="namespaceLocalIntegrators_1_1Advection.html#a8bc7b8136646134f73a4193adefe15f8">cell_matrix</a>(i,j));</div><div class="line">  ...same <span class="keywordflow">for</span> rhs...</div><div class="line">}</div></div><!-- fragment --><p>The problem here is that several tasks, each running <code>MyClass::assemble_on_one_cell</code>, could potentially try to write into the object <code>MyClass::system_matrix</code> <em>at the same time</em>. This could be avoided by explicit synchronisation using a <a class="el" href="classThreads_1_1Mutex.html">Threads::Mutex</a>, for example, and would look like this: </p><div class="fragment"><div class="line">  <span class="comment">// now copy results into global system</span></div><div class="line">  std::vector&lt;unsigned int&gt; dof_indices (...);</div><div class="line">  cell-&gt;get_dof_indices (dof_indices);</div><div class="line"></div><div class="line">  <span class="keyword">static</span> <a class="code" href="classThreads_1_1Mutex.html">Threads::Mutex</a> mutex;</div><div class="line">  mutex.acquire ();</div><div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i=0; i&lt;fe.dofs_per_cell; ++i)</div><div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j=0; j&lt;fe.dofs_per_cell; ++j)</div><div class="line">      system_matrix.add (dof_indices[i], dof_indices[j],</div><div class="line">                         <a class="code" href="namespaceLocalIntegrators_1_1Advection.html#a8bc7b8136646134f73a4193adefe15f8">cell_matrix</a>(i,j));</div><div class="line">  ...same <span class="keywordflow">for</span> rhs...</div><div class="line">  mutex.release ();</div><div class="line">}</div></div><!-- fragment --><p>By making the mutex a static variable, it exists only once globally (i.e. once for all tasks that may be running in parallel) and only one of the tasks can enter the region protected by the acquire/release calls on the mutex. As an aside, a better way to write this code would be like this, ensuring that the mutex is released even in case an exception is thrown, and without the need to remember to write the call to Threads::Mutex::release(): </p><div class="fragment"><div class="line">  <span class="comment">// now copy results into global system</span></div><div class="line">  <span class="keyword">static</span> <a class="code" href="classThreads_1_1Mutex.html">Threads::Mutex</a> mutex;</div><div class="line">  Threads::Mutex::ScopedLock lock (mutex);</div><div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i=0; i&lt;fe.dofs_per_cell; ++i)</div><div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j=0; j&lt;fe.dofs_per_cell; ++j)</div><div class="line">      system_matrix.add (dof_indices[i], dof_indices[j],</div><div class="line">                         <a class="code" href="namespaceLocalIntegrators_1_1Advection.html#a8bc7b8136646134f73a4193adefe15f8">cell_matrix</a>(i,j));</div><div class="line">  ...same <span class="keywordflow">for</span> rhs...</div><div class="line">}</div></div><!-- fragment --><p> Here, the mutex remains locked from the time the ScopedLock is created to where it is destroyed, at the end of the code block.</p>
<p>Note that although we now avoid the race condition that multiple threads could be writing to the same object, this code is not very efficient: mutexes are expensive on multicore machines, and we also block threads some of the time which is inefficient with tasks as explained above in the section on <a class="el" href="group__threads.html#MTHow">How scheduling tasks works and when task-based programming is not efficient</a>.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">A second correctness problem is that even if we do lock the global matrix and right hand side objects using a mutex, we do so in a more or less random order: while tasks are created in the order in which we traverse cells normally, there is no guarantee that by the time we get to the point where we want to copy the local into the global contributions the order is still as if we computed things sequentially. In other words, it may happen that we add the contributions of cell 1 before those of cell 0. That may seem harmless because addition is commutative and associative, but in fact it is not if done in floating point arithmetic: \(a+b+c \neq a+c+b\) &ndash; take for example \(a=1, b=-1, c=10^{-20}\) (because \(1+10^{-20}=1\) in floating point arithmetic, using double precision).</p>
<p>As a consequence, the exact values that end up in the global matrix and right hand side will be close but may differ by amounts close to round-off depending on the order in which tasks happened to finish their job. That's not a desirable outcome, since results will not be reproducible this way.</p>
<p>As a consequence, the way the <a class="el" href="namespaceWorkStream.html">WorkStream</a> class is designed is to use two functions: the <code>MyClass::assemble_on_one_cell</code> computes the local contributions and stores them somewhere (we'll get to that next), and a second function, say <code>MyClass::copy_local_to_global</code>, that copies the results computed on each cell into the global objects. The trick implemented in the <a class="el" href="namespaceWorkStream.html">WorkStream</a> class is that (i) the <code>MyClass::copy_local_to_global</code> never runs more than once in parallel, so we do not need to synchronise execution through a mutex, and (ii) it runs in exactly the same order on cells as they appear in the iterator range, i.e. we add elements into the global matrix the same way <em>every time, independently of when the computation of these element finishes</em>.</p>
<p>We now only have to discuss how the <code>MyClass::assemble_on_one_cell</code> communicates to <code>MyClass::copy_local_to_global</code> what it has computed. The way this is done is to use an object that holds all temporary data: </p><div class="fragment"><div class="line"><span class="keyword">struct </span>PerTaskData {</div><div class="line">  <a class="code" href="classFullMatrix.html">FullMatrix&lt;double&gt;</a>        <a class="code" href="namespaceLocalIntegrators_1_1Advection.html#a8bc7b8136646134f73a4193adefe15f8">cell_matrix</a>;</div><div class="line">  <a class="code" href="classVector.html">Vector&lt;double&gt;</a>            cell_rhs;</div><div class="line">  std::vector&lt;unsigned int&gt; dof_indices;</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> dim&gt;</div><div class="line"><span class="keywordtype">void</span> MyClass&lt;dim&gt;::assemble_on_one_cell (<span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classDoFHandler.html">DoFHandler&lt;dim&gt;::active_cell_iterator</a> &amp;cell,</div><div class="line">                                         PerTaskData &amp;data)</div><div class="line">{</div><div class="line">  <a class="code" href="classFEValues.html">FEValues&lt;dim&gt;</a> fe_values (...);</div><div class="line"></div><div class="line">  data.cell_matrix = 0;</div><div class="line">  data.cell_rhs    = 0;</div><div class="line"></div><div class="line">  <span class="comment">// assemble local contributions</span></div><div class="line">  fe_values.reinit (cell);</div><div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i=0; i&lt;fe.dofs_per_cell; ++i)</div><div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j=0; j&lt;fe.dofs_per_cell; ++j)</div><div class="line">      <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> q=0; q&lt;fe_values.n_quadrature_points; ++q)</div><div class="line">        data.cell_matrix(i,j) += ...;</div><div class="line">  ...same <span class="keywordflow">for</span> cell_rhs...</div><div class="line"></div><div class="line">  cell-&gt;get_dof_indices (data.dof_indices);</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> dim&gt;</div><div class="line"><span class="keywordtype">void</span> MyClass&lt;dim&gt;::copy_local_to_global (<span class="keyword">const</span> PerTaskData &amp;data)</div><div class="line">{</div><div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i=0; i&lt;fe.dofs_per_cell; ++i)</div><div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> j=0; j&lt;fe.dofs_per_cell; ++j)</div><div class="line">      system_matrix.add (data.dof_indices[i], data.dof_indices[j],</div><div class="line">                         data.cell_matrix(i,j));</div><div class="line">  ...same <span class="keywordflow">for</span> rhs...</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> dim&gt;</div><div class="line"><span class="keywordtype">void</span> MyClass&lt;dim&gt;::assemble_system ()</div><div class="line">{</div><div class="line">  PerTaskData per_task_data;</div><div class="line">  ...<a class="code" href="classDoFHandler.html#aeca4a4af5c4d7f7c68a4def9ae87bc7b">initialize</a> members of per_task_data to the correct sizes...</div><div class="line"></div><div class="line">  <a class="code" href="namespaceWorkStream.html#ab8ceb010811941c351803b671a19fb73">WorkStream::run</a> (dof_handler.begin_active(),</div><div class="line">                   dof_handler.end(),</div><div class="line">                   *<span class="keyword">this</span>,</div><div class="line">                   &amp;MyClass&lt;dim&gt;::assemble_on_one_cell,</div><div class="line">                   &amp;MyClass&lt;dim&gt;::copy_local_to_global,</div><div class="line">                   per_task_data);</div><div class="line">}</div></div><!-- fragment --><p>The way this works is that we create a sample <code>per_task_data</code> object that the work stream object will replicate once per task that runs in parallel. For each task, this object will be passed first to one of possibly several instances of <code>MyClass::assemble_on_one_cell</code> running in parallel which fills it with the data obtained on a single cell, and then to a sequentially running <code>MyClass::copy_local_to_global</code> that copies data into the global object. In practice, of course, we will not generate millions of <code>per_task_data</code> objects if we have millions of cells; rather, we recycle these objects after they have been used by <code>MyClass::copy_local_to_global</code> and feed them back into another instance of <code>MyClass::assemble_on_one_cell</code>; this means that the number of such objects we actually do create is a small multiple of the number of threads the scheduler uses, which is typically about as many as there are CPU cores on a system.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">The last issue that is worth addressing is that the way we wrote the <code>MyClass::assemble_on_one_cell</code> function above, we create and destroy an <a class="el" href="classFEValues.html">FEValues</a> object every time the function is called, i.e. once for each cell in the triangulation. That's an immensely expensive operation because the <a class="el" href="classFEValues.html">FEValues</a> class tries to do a lot of work in its constructor in an attempt to reduce the number of operations we have to do on each cell (i.e. it increases the constant in the \({\cal O}(1)\) effort to initialize such an object in order to reduce the constant in the \({\cal O}(N)\) operations to call <a class="el" href="classFEValues.html#a21f914e63d588e2652a9514620653d77">FEValues::reinit</a> on the \(N\) cells of a triangulation). Creating and destroying an <a class="el" href="classFEValues.html">FEValues</a> object on each cell invalidates this effort.</p>
<p>The way to avoid this is to put the <a class="el" href="classFEValues.html">FEValues</a> object into a second structure that will hold scratch data, and initialize it in the constructor: </p><div class="fragment"><div class="line"><span class="keyword">struct </span>PerTaskData {</div><div class="line">  <a class="code" href="classFullMatrix.html">FullMatrix&lt;double&gt;</a>        <a class="code" href="namespaceLocalIntegrators_1_1Advection.html#a8bc7b8136646134f73a4193adefe15f8">cell_matrix</a>;</div><div class="line">  <a class="code" href="classVector.html">Vector&lt;double&gt;</a>            cell_rhs;</div><div class="line">  std::vector&lt;unsigned int&gt; dof_indices;</div><div class="line"></div><div class="line">  PerTaskData (<span class="keyword">const</span> <a class="code" href="classFiniteElement.html">FiniteElement&lt;dim&gt;</a> &amp;fe)</div><div class="line">             :</div><div class="line">             cell_matrix (fe.dofs_per_cell, fe.dofs_per_cell),</div><div class="line">             cell_rhs (fe.dofs_per_cell),</div><div class="line">             dof_indices (fe.dofs_per_cell)</div><div class="line">    {}</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">struct </span>ScratchData {</div><div class="line">  <a class="code" href="classFEValues.html">FEValues&lt;dim&gt;</a>             fe_values;</div><div class="line"></div><div class="line">  ScratchData (<span class="keyword">const</span> <a class="code" href="classFiniteElement.html">FiniteElement&lt;dim&gt;</a> &amp;fe,</div><div class="line">               <span class="keyword">const</span> <a class="code" href="classQuadrature.html">Quadrature&lt;dim&gt;</a>    &amp;quadrature,</div><div class="line">               <span class="keyword">const</span> <a class="code" href="group__feaccess.html#gaa94b67d2fdcc390690c523f28019e52f">UpdateFlags</a>         update_flags)</div><div class="line">             :</div><div class="line">             fe_values (fe, quadrature, update_flags)</div><div class="line">    {}</div><div class="line"></div><div class="line">  ScratchData (<span class="keyword">const</span> ScratchData &amp;scratch)</div><div class="line">             :</div><div class="line">             fe_values (scratch.fe_values.get_fe(),</div><div class="line">                        scratch.fe_values.get_quadrature(),</div><div class="line">                        scratch.fe_values.get_update_flags())</div><div class="line">    {}</div><div class="line">}</div></div><!-- fragment --><p> and then use this <a class="el" href="classFEValues.html">FEValues</a> object in the assemble function: </p><div class="fragment"><div class="line"><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> dim&gt;</div><div class="line"><span class="keywordtype">void</span> MyClass&lt;dim&gt;::assemble_on_one_cell (<span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classDoFHandler.html">DoFHandler&lt;dim&gt;::active_cell_iterator</a> &amp;cell,</div><div class="line">                                         ScratchData &amp;scratch,</div><div class="line">                                         PerTaskData &amp;data)</div><div class="line">{</div><div class="line">  scratch.fe_values.reinit (cell);</div><div class="line">  ...</div><div class="line">}</div></div><!-- fragment --><p> Just as for the <code>PerTaskData</code> structure, we will create a sample <code>ScratchData</code> object and pass it to the work stream object, which will replicate it as many times as necessary. For this to work <code>ScratchData</code> structures need to copyable. Since <a class="el" href="classFEValues.html">FEValues</a> objects are rather complex and cannot be copied implicitly, we provided our own copy constructor for the <code>ScratchData</code> structure.</p>
<p>The same approach, putting things into the <code>ScratchData</code> data structure, should be used for everything that is expensive to construct. This holds, in particular, for everything that needs to allocate memory upon construction; for example, if the values of a function need to be evaluated at quadrature points, then this is expensive: </p><div class="fragment"><div class="line"><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> dim&gt;</div><div class="line"><span class="keywordtype">void</span> MyClass&lt;dim&gt;::assemble_on_one_cell (<span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classDoFHandler.html">DoFHandler&lt;dim&gt;::active_cell_iterator</a> &amp;cell,</div><div class="line">                                         ScratchData &amp;scratch,</div><div class="line">                                         PerTaskData &amp;data)</div><div class="line">{</div><div class="line">  std::vector&lt;double&gt; rhs_values (fe_values.n_quadrature_points);</div><div class="line">  rhs_function.value_list (data.fe_values.get_quadrature_points,</div><div class="line">                           rhs_values)</div><div class="line">  ...</div><div class="line">}</div></div><!-- fragment --><p> whereas this is a much cheaper way: </p><div class="fragment"><div class="line"><span class="keyword">struct </span>ScratchData {</div><div class="line">  std::vector&lt;double&gt;       rhs_values;</div><div class="line">  <a class="code" href="classFEValues.html">FEValues&lt;dim&gt;</a>             fe_values;</div><div class="line"></div><div class="line">  ScratchData (<span class="keyword">const</span> <a class="code" href="classFiniteElement.html">FiniteElement&lt;dim&gt;</a> &amp;fe,</div><div class="line">               <span class="keyword">const</span> <a class="code" href="classQuadrature.html">Quadrature&lt;dim&gt;</a>    &amp;quadrature,</div><div class="line">               <span class="keyword">const</span> <a class="code" href="group__feaccess.html#gaa94b67d2fdcc390690c523f28019e52f">UpdateFlags</a>         update_flags)</div><div class="line">             :</div><div class="line">             rhs_values (quadrature.size()),</div><div class="line">             fe_values (fe, quadrature, update_flags)</div><div class="line">    {}</div><div class="line"></div><div class="line">   ScratchData (<span class="keyword">const</span> ScratchData &amp;scratch)</div><div class="line">             :</div><div class="line">             rhs_values (scratch.rhs_values),</div><div class="line">             fe_values (scratch.fe_values.get_fe(),</div><div class="line">                        scratch.fe_values.get_quadrature(),</div><div class="line">                        scratch.fe_values.get_update_flags())</div><div class="line">    {}</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> dim&gt;</div><div class="line"><span class="keywordtype">void</span> MyClass&lt;dim&gt;::assemble_on_one_cell (<span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classDoFHandler.html">DoFHandler&lt;dim&gt;::active_cell_iterator</a> &amp;cell,</div><div class="line">                                         ScratchData &amp;scratch,</div><div class="line">                                         PerTaskData &amp;data)</div><div class="line">{</div><div class="line">  rhs_function.value_list (scratch.fe_values.get_quadrature_points,</div><div class="line">                           scratch.rhs_values)</div><div class="line">  ...</div><div class="line">}</div></div><!-- fragment --><p class="endli"></p>
</li>
</ul>
<p>As a final point: What if, for some reason, my assembler and copier function do not match the above signature with three and one argument, respectively? That's not a problem either. The <a class="el" href="namespaceWorkStream.html">WorkStream</a> namespace offers two versions of the <a class="el" href="namespaceWorkStream.html#ab8ceb010811941c351803b671a19fb73">WorkStream::run()</a> function: one that takes an object and the addresses of two member functions, and one that simply takes two function objects that can be called with three and one argument, respectively. So, in other words, the following two calls are exactly identical: </p><div class="fragment"><div class="line"><a class="code" href="namespaceWorkStream.html#ab8ceb010811941c351803b671a19fb73">WorkStream::run</a> (dof_handler.begin_active(),</div><div class="line">                 dof_handler.end(),</div><div class="line">                 *<span class="keyword">this</span>,</div><div class="line">                 &amp;MyClass&lt;dim&gt;::assemble_on_one_cell,</div><div class="line">                 &amp;MyClass&lt;dim&gt;::copy_local_to_global,</div><div class="line">                 per_task_data);</div><div class="line"><span class="comment">// ...is the same as:</span></div><div class="line"><a class="code" href="namespaceWorkStream.html#ab8ceb010811941c351803b671a19fb73">WorkStream::run</a> (dof_handler.begin_active(),</div><div class="line">                 dof_handler.end(),</div><div class="line">                 std::bind(&amp;MyClass&lt;dim&gt;::assemble_on_one_cell,</div><div class="line">                           *<span class="keyword">this</span>,</div><div class="line">                           std::_1,</div><div class="line">                           std::_2,</div><div class="line">                           std::_3),</div><div class="line">                 std::bind(&amp;MyClass&lt;dim&gt;::copy_local_to_global,</div><div class="line">                           *<span class="keyword">this</span>,</div><div class="line">                           std::_1),</div><div class="line">                 per_task_data);</div></div><!-- fragment --><p> Note how <code>std::bind</code> produces a function object that takes three arguments by binding the member function to the <code>*this</code> object. <code>std::_1, std::_2</code> and <code>std::_3</code> are placeholders for the first, second and third argument that can be specified later on. In other words, for example if <code>p</code> is the result of the first call to <code>std::bind</code>, then the call <code>p(cell, scratch_data, per_task_data)</code> will result in executing <code>this-&gt;assemble_on_one_cell (cell, scratch_data, per_task_data)</code>, i.e. <code>std::bind</code> has bound the object to the function pointer but left the three arguments open for later.</p>
<p>Similarly, let us assume that <code>MyClass::assemble_on_one_cell</code> has the following signature in the solver of a nonlinear, time-dependent problem: </p><div class="fragment"><div class="line"><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> dim&gt;</div><div class="line"><span class="keywordtype">void</span></div><div class="line">MyClass&lt;dim&gt;::assemble_on_one_cell (<span class="keyword">const</span> <a class="code" href="classVector.html">Vector&lt;double&gt;</a> &amp;linearization_point,</div><div class="line">                                    <span class="keyword">const</span> <span class="keyword">typename</span> <a class="code" href="classDoFHandler.html">DoFHandler&lt;dim&gt;::active_cell_iterator</a> &amp;cell,</div><div class="line">                                    ScratchData &amp;scratch,</div><div class="line">                                    PerTaskData &amp;data,</div><div class="line">                                    <span class="keyword">const</span> <span class="keywordtype">double</span> current_time)</div><div class="line">{ ... }</div></div><!-- fragment --><p> Because <a class="el" href="namespaceWorkStream.html">WorkStream</a> expects to be able to call the worker function with just three arguments, the first of which is the iterator and the second and third the ScratchData and PerTaskData objects, we need to pass the following to it: </p><div class="fragment"><div class="line"><a class="code" href="namespaceWorkStream.html#ab8ceb010811941c351803b671a19fb73">WorkStream::run</a> (dof_handler.begin_active(),</div><div class="line">                 dof_handler.end(),</div><div class="line">                 std::bind(&amp;MyClass&lt;dim&gt;::assemble_on_one_cell,</div><div class="line">                           *<span class="keyword">this</span>,</div><div class="line">                           current_solution,</div><div class="line">                           std::_1,</div><div class="line">                           std::_2,</div><div class="line">                           std::_3,</div><div class="line">                           previous_time+time_step),</div><div class="line">                 std::bind(&amp;MyClass&lt;dim&gt;::copy_local_to_global,</div><div class="line">                           *<span class="keyword">this</span>,</div><div class="line">                           std::_1),</div><div class="line">                 per_task_data);</div></div><!-- fragment --><p> Here, we bind the object, the linearization point argument, and the current time argument to the function before we hand it off to <a class="el" href="namespaceWorkStream.html#ab8ceb010811941c351803b671a19fb73">WorkStream::run()</a>. <a class="el" href="namespaceWorkStream.html#ab8ceb010811941c351803b671a19fb73">WorkStream::run()</a> will then simply call the function with the cell and scratch and per task objects which will be filled in at the positions indicated by <code>std::_1, std::_2</code> and <code>std::_3</code>.</p>
<p>There are refinements to the <a class="el" href="namespaceWorkStream.html#ab8ceb010811941c351803b671a19fb73">WorkStream::run</a> function shown above. For example, one may realize that the basic idea above can only scale if the copy-local-to-global function is much quicker than the local assembly function because the former has to run sequentially. This limitation can only be improved upon by scheduling more work in parallel. This leads to the notion of coloring the graph of cells (or, more generally, iterators) we work on by recording which write operations conflict with each other. Consequently, there is a third version of <a class="el" href="namespaceWorkStream.html#ab8ceb010811941c351803b671a19fb73">WorkStream::run</a> that doesn't just take a range of iterators, but instead a vector of vectors consisting of elements that can be worked on at the same time. This concept is explained in great detail in the <a class="el" href="DEALGlossary.html#workstream_paper">WorkStream paper</a>, along with performance evaluations for common examples.</p>
<p><a class="anchor" id="MTTaskSynchronization"></a> </p><h3>Tasks and synchronization</h3>
<p>Tasks are powerful but they do have their limitation: to make things efficient, the task scheduler never interrupts tasks by itself. With the exception of the situation where one calls the <a class="el" href="classThreads_1_1Task.html#a9aed8f99d2b88bd0d6cfff95e38c3ac7">Threads::Task::join</a> function to wait for another task to finish, the task scheduler always runs a task to completion. The downside is that the scheduler does not see if a task is actually idling, for example if it waits for something else to happen (file IO to finish, input from the keyboard, etc). In cases like this, the task scheduler could in principle run a different task, but since it doesn't know what tasks are doing it doesn't. <a class="el" href="namespaceFunctions.html">Functions</a> that do wait for external events to happen are therefore not good candidates for tasks and should use threads (see below).</p>
<p>However, there are cases where tasks are not only a bad abstraction for a job but can actually not be used: As a matter of principle, tasks can not synchronize with other tasks through the use of a mutex or a condition variable (see the <a class="el" href="classThreads_1_1Mutex.html">Threads::Mutex</a> and Threads::ConditionVariable classes). The reason is that if task A needs to wait for task B to finish something, then this is only going to work if there is a guarantee that task B will eventually be able to run and finish the task. Now imagine that you have 2 processors, and tasks A1 and A2 are currently running; let's assume that they have queued tasks B1 and B2, and are now waiting with a mutex for these queued tasks to finish (part of) their work. Since the machine has only two processors, the task scheduler will only start B1 or B2 once either A1 or A2 are done &ndash; but this isn't happening since they are waiting using operating system resources (a mutex) rather than task scheduler resources. The result is a deadlock.</p>
<p>The bottom line is that tasks can not use mutexes or condition variables to synchronize with other tasks. If communication between tasks is necessary, you need to use threads because the operating system makes sure that all threads eventually get to run, independent of the total number of threads. Note however that the same is not true if you only use a Thread::Mutex on each task separately to protect access to a variable that the tasks may write to: this use of mutexes is ok; tasks may simply not want to wait for another task to do something.</p>
<p><a class="anchor" id="MTThreads"></a> </p><h3>Thread-based parallelism</h3>
<p>Even though tasks are a higher-level way to describe things, there are cases that are poorly suited to a task (for a discussion of some of these cases see <a class="el" href="group__threads.html#MTHow">How scheduling tasks works and when task-based programming is not efficient</a> above). Generally, jobs that are not able to fully utilize the CPU are bad fits for tasks and good fits for threads.</p>
<p>In a case like this, you can resort to explicitly start threads, rather than tasks, using pretty much the same syntax as above. For example, if you had a function in your application that generates graphical output and then estimates the error to refine the mesh for the next iteration of an adaptive mesh scheme, it could look like this: </p><div class="fragment"><div class="line"><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> dim&gt;</div><div class="line"><span class="keywordtype">void</span> MyClass&lt;dim&gt;::output_and_estimate_error ()<span class="keyword"> const</span></div><div class="line"><span class="keyword"></span>{</div><div class="line">  <a class="code" href="classDataOut.html">DataOut&lt;dim&gt;</a> data_out;</div><div class="line">  data_out.<a class="code" href="classDataOut__DoFData.html#a6ed7c846331069f406b8c9933c37fda4">attach_dof_handler</a> (dof_handler);</div><div class="line">  data_out.<a class="code" href="classDataOut__DoFData.html#a79cbe2f02f8dfb85026c71d783dbb703">add_data_vector</a> (solution, <span class="stringliteral">&quot;solution&quot;</span>);</div><div class="line">  data_out.<a class="code" href="classDataOut.html#ab6b584c378c08f9b7ee4ca474405fed0">build_patches</a> ();</div><div class="line"></div><div class="line">  std::ofstream output (<span class="stringliteral">&quot;solution.vtk&quot;</span>);</div><div class="line"></div><div class="line">  <a class="code" href="classThreads_1_1Thread.html">Threads::Thread&lt;void&gt;</a></div><div class="line">    thread = <a class="code" href="group__threads.html#ga2003df2a027b3e716c290108ddeb558a">Threads::new_thread</a> (&amp;<a class="code" href="classDataOut.html">DataOut&lt;dim&gt;::write_vtk</a>, data_out, output);</div><div class="line"></div><div class="line">  <a class="code" href="classVector.html">Vector&lt;float&gt;</a> error_per_cell (triangulation.<a class="code" href="classTriangulation.html#a5ea5c9957dbb566a562bbe2c0f3971e9">n_active_cells</a>());</div><div class="line">  <a class="code" href="classKellyErrorEstimator.html#ae2269e1c9903e9d863b7abd54948af00">KellyErrorEstimator&lt;dim&gt;::estimate</a> (dof_handler,</div><div class="line">                                     <a class="code" href="classQGauss.html">QGauss&lt;dim-1&gt;</a>(3),</div><div class="line">                                     <span class="keyword">typename</span> FunctionMap&lt;dim&gt;::type(),</div><div class="line">                                     solution,</div><div class="line">                                     estimated_error_per_cell);</div><div class="line">  thread.<a class="code" href="classThreads_1_1Thread.html#a1d5e3a7d251c2fdedfd29d313f5d636a">join</a> ();</div></div><!-- fragment --><p>Here, <a class="el" href="group__threads.html#ga2003df2a027b3e716c290108ddeb558a">Threads::new_thread</a> starts the given function that writes to the output file on a new thread that can run in parallel to everything else: In parallel to the <a class="el" href="classKellyErrorEstimator.html#ae2269e1c9903e9d863b7abd54948af00">KellyErrorEstimator::estimate()</a> function, the <a class="el" href="classDataOutInterface.html#acad99726038e4fca7f605fdffb3317e4">DataOut::write_vtk()</a> function will run on a separate thread. This execution is independent of the scheduler that takes care of tasks, but that is not a problem because writing lots of data to a file is not something that will keep a CPU very busy.</p>
<p>Creating threads works pretty much the same way as tasks, i.e. you can wait for the termination of a thread using <a class="el" href="classThreads_1_1Thread.html#a1d5e3a7d251c2fdedfd29d313f5d636a">Threads::Thread::join()</a>, query the return value of a finished thread using <a class="el" href="classThreads_1_1Thread.html#a20d2f275646e2355660a1b22234ee3db">Threads::Thread::return_value()</a>, and you can group threads into a <a class="el" href="classThreads_1_1ThreadGroup.html">Threads::ThreadGroup</a> object and wait for all of them to finish.</p>
<p><a class="anchor" id="MTTaskThreads"></a> </p><h3>Controlling the number of threads used for tasks</h3>
<p>As mentioned earlier, deal.II does not implement scheduling tasks to threads or even starting threads itself. The TBB library does a good job at deciding how many threads to use and they do not recommend setting the number of threads explicitly. However, on large symmetric multiprocessing (SMP) machines, especially ones with a resource/job manager or on systems on which access to some parts of the memory is possible but very expensive for processors far away (e.g. very large NUMA SMP machines), it may be necessary to explicitly set the number of threads to prevent the TBB from using too many CPUs. Another use case is if you run multiple MPI jobs on a single machine and each job should only use a subset of the available processor cores.</p>
<p>Setting the number of threads explicitly is done by calling <a class="el" href="classMultithreadInfo.html#ae253b8ff679c4119f9c5bff4439fe606">MultithreadInfo::set_thread_limit()</a> before any other calls to functions that may create threads. In practice, it should be one of the first functions you call in <code>main()</code>.</p>
<p>If you run your program with MPI, then you can use the optional third argument to the constructor of the MPI_InitFinalize class to achieve the same goal.</p>
<dl class="section note"><dt>Note</dt><dd>A small number of places inside deal.II also uses thread-based parallelism explicitly, for example for running background tasks that have to wait for input or output to happen and consequently do not consume much CPU time. Such threads do not run under the control of the TBB task scheduler and, therefore, are not affected by the procedure above. Under some circumstances, deal.II also calls the BLAS library which may sometimes also start threads of its own. You will have to consult the documentation of your BLAS installation to determine how to set the number of threads for these operations. </dd></dl>
<h2 class="groupheader">Function Documentation</h2>
<a id="ga86c4f26c4dacddd38ee225dd1796d7e1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga86c4f26c4dacddd38ee225dd1796d7e1">&#9670;&nbsp;</a></span>split_range()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename ForwardIterator &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::pair&lt;ForwardIterator, ForwardIterator&gt; &gt; Threads::split_range </td>
          <td>(</td>
          <td class="paramtype">const ForwardIterator &amp;&#160;</td>
          <td class="paramname"><em>begin</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const ForwardIterator &amp;&#160;</td>
          <td class="paramname"><em>end</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const unsigned <a class="el" href="classint.html">int</a>&#160;</td>
          <td class="paramname"><em>n_intervals</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Split the range <code>[begin,end)</code> into <code>n_intervals</code> subintervals of equal size. The last interval will be a little bit larger, if the number of elements in the whole range is not exactly divisible by <code>n_intervals</code>. The type of the iterators has to fulfill the requirements of a forward iterator, i.e. <code>operator++</code> must be available, and of course it must be assignable.</p>
<p>A list of subintervals is returned as a vector of pairs of iterators, where each pair denotes the range <code>[begin[i],end[i])</code>. </p>

</div>
</div>
<a id="ga76d508b069d429d014135b59d20cc74a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga76d508b069d429d014135b59d20cc74a">&#9670;&nbsp;</a></span>split_interval()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; std::pair&lt; unsigned <a class="el" href="classint.html">int</a>, unsigned <a class="el" href="classint.html">int</a> &gt; &gt; Threads::split_interval </td>
          <td>(</td>
          <td class="paramtype">const unsigned <a class="el" href="classint.html">int</a>&#160;</td>
          <td class="paramname"><em>begin</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const unsigned <a class="el" href="classint.html">int</a>&#160;</td>
          <td class="paramname"><em>end</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const unsigned <a class="el" href="classint.html">int</a>&#160;</td>
          <td class="paramname"><em>n_intervals</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Split the interval <code>[begin,end)</code> into subintervals of (almost) equal size. This function works mostly as the one before, with the difference that instead of iterators, now values are taken that define the whole interval. </p>

<p class="definition">Definition at line <a class="el" href="thread__management_8cc_source.html#l00109">109</a> of file <a class="el" href="thread__management_8cc_source.html">thread_management.cc</a>.</p>

</div>
</div>
<a id="ga2003df2a027b3e716c290108ddeb558a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2003df2a027b3e716c290108ddeb558a">&#9670;&nbsp;</a></span>new_thread() <span class="overload">[1/4]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename RT &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classThreads_1_1Thread.html">Thread</a>&lt;RT&gt; Threads::new_thread </td>
          <td>(</td>
          <td class="paramtype">const std::function&lt; RT()&gt; &amp;&#160;</td>
          <td class="paramname"><em>function</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Overload of the new_thread function for objects that can be converted to std::function&lt;RT ()&gt;, i.e. anything that can be called like a function object without arguments and returning an object of type RT (or void). </p>

<p class="definition">Definition at line <a class="el" href="thread__management_8h_source.html#l00757">757</a> of file <a class="el" href="thread__management_8h_source.html">thread_management.h</a>.</p>

</div>
</div>
<a id="ga64c1f1a34730909ce48e01077620f877"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga64c1f1a34730909ce48e01077620f877">&#9670;&nbsp;</a></span>new_thread() <span class="overload">[2/4]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename RT , typename... Args&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classThreads_1_1Thread.html">Thread</a>&lt;RT&gt; Threads::new_thread </td>
          <td>(</td>
          <td class="paramtype">RT(*)(Args...)&#160;</td>
          <td class="paramname"><em>fun_ptr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">typename <a class="el" href="structidentity.html">identity</a>&lt; Args &gt;::type...&#160;</td>
          <td class="paramname"><em>args</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Overload of the new_thread function for non-member or static member functions. </p>

<p class="definition">Definition at line <a class="el" href="thread__management_8h_source.html#l00847">847</a> of file <a class="el" href="thread__management_8h_source.html">thread_management.h</a>.</p>

</div>
</div>
<a id="gae29abb16b55e0f4c1630aa2fd166e1d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae29abb16b55e0f4c1630aa2fd166e1d1">&#9670;&nbsp;</a></span>new_thread() <span class="overload">[3/4]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename RT , typename C , typename... Args&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classThreads_1_1Thread.html">Thread</a>&lt;RT&gt; Threads::new_thread </td>
          <td>(</td>
          <td class="paramtype">RT(C::*)(Args...)&#160;</td>
          <td class="paramname"><em>fun_ptr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">typename <a class="el" href="structidentity.html">identity</a>&lt; C &gt;::type &amp;&#160;</td>
          <td class="paramname"><em>c</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">typename <a class="el" href="structidentity.html">identity</a>&lt; Args &gt;::type...&#160;</td>
          <td class="paramname"><em>args</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Overload of the non-const new_thread function for member functions. </p>

<p class="definition">Definition at line <a class="el" href="thread__management_8h_source.html#l00863">863</a> of file <a class="el" href="thread__management_8h_source.html">thread_management.h</a>.</p>

</div>
</div>
<a id="ga9be703f998235b42c4fe86ed03e848db"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga9be703f998235b42c4fe86ed03e848db">&#9670;&nbsp;</a></span>new_thread() <span class="overload">[4/4]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename RT , typename C , typename... Args&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classThreads_1_1Thread.html">Thread</a>&lt;RT&gt; Threads::new_thread </td>
          <td>(</td>
          <td class="paramtype">RT(C::*)(Args...) const&#160;</td>
          <td class="paramname"><em>fun_ptr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">typename <a class="el" href="structidentity.html">identity</a>&lt; const C &gt;::type &amp;&#160;</td>
          <td class="paramname"><em>c</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">typename <a class="el" href="structidentity.html">identity</a>&lt; Args &gt;::type...&#160;</td>
          <td class="paramname"><em>args</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Overload of the new_thread function for const member functions. </p>

<p class="definition">Definition at line <a class="el" href="thread__management_8h_source.html#l00879">879</a> of file <a class="el" href="thread__management_8h_source.html">thread_management.h</a>.</p>

</div>
</div>
<a id="ga8c1e15b84e1bb58a8029fc6d6ddf3cbf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga8c1e15b84e1bb58a8029fc6d6ddf3cbf">&#9670;&nbsp;</a></span>new_task() <span class="overload">[1/4]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename RT &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classThreads_1_1Task.html">Task</a>&lt;RT&gt; Threads::new_task </td>
          <td>(</td>
          <td class="paramtype">const std::function&lt; RT()&gt; &amp;&#160;</td>
          <td class="paramname"><em>function</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Overload of the new_task function for objects that can be converted to std::function&lt;RT ()&gt;, i.e. anything that can be called like a function object without arguments and returning an object of type RT (or void).</p>
<dl class="section note"><dt>Note</dt><dd>When <a class="el" href="classMultithreadInfo.html#ad0b84ae105b385b88bdd4bfc0c530995">MultithreadInfo::n_threads()</a> returns 1, i.e., if the deal.II runtime system has been configured to only use one thread, then this function just executes the given function object immediately and stores the return value in the <a class="el" href="classThreads_1_1Task.html">Task</a> object returned by this function.</dd>
<dd>
<a class="el" href="group__threads.html#ga8c1e15b84e1bb58a8029fc6d6ddf3cbf">Threads::new_task()</a> is, in essence, equivalent to calling <code>std::async(std::launch::async, ...)</code> in that it runs the given task in the background. See <a href="https://en.cppreference.com/w/cpp/thread/async">https://en.cppreference.com/w/cpp/thread/async</a> for more information. </dd></dl>

<p class="definition">Definition at line <a class="el" href="thread__management_8h_source.html#l01328">1328</a> of file <a class="el" href="thread__management_8h_source.html">thread_management.h</a>.</p>

</div>
</div>
<a id="gaa9634848d075456afaf092e15848d5e6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa9634848d075456afaf092e15848d5e6">&#9670;&nbsp;</a></span>new_task() <span class="overload">[2/4]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename RT , typename... Args&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classThreads_1_1Task.html">Task</a>&lt;RT&gt; Threads::new_task </td>
          <td>(</td>
          <td class="paramtype">RT(*)(Args...)&#160;</td>
          <td class="paramname"><em>fun_ptr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">typename <a class="el" href="structidentity.html">identity</a>&lt; Args &gt;::type...&#160;</td>
          <td class="paramname"><em>args</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Overload of the new_task function for non-member or static member functions. See the other functions of same name for more information. </p>

<p class="definition">Definition at line <a class="el" href="thread__management_8h_source.html#l01430">1430</a> of file <a class="el" href="thread__management_8h_source.html">thread_management.h</a>.</p>

</div>
</div>
<a id="gae34fcb2cea316e52c99b4adec8be3ad4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae34fcb2cea316e52c99b4adec8be3ad4">&#9670;&nbsp;</a></span>new_task() <span class="overload">[3/4]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename RT , typename C , typename... Args&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classThreads_1_1Task.html">Task</a>&lt;RT&gt; Threads::new_task </td>
          <td>(</td>
          <td class="paramtype">RT(C::*)(Args...)&#160;</td>
          <td class="paramname"><em>fun_ptr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">typename <a class="el" href="structidentity.html">identity</a>&lt; C &gt;::type &amp;&#160;</td>
          <td class="paramname"><em>c</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">typename <a class="el" href="structidentity.html">identity</a>&lt; Args &gt;::type...&#160;</td>
          <td class="paramname"><em>args</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Overload of the non-const new_task function. See the other functions of same name for more information. </p>

<p class="definition">Definition at line <a class="el" href="thread__management_8h_source.html#l01447">1447</a> of file <a class="el" href="thread__management_8h_source.html">thread_management.h</a>.</p>

</div>
</div>
<a id="gae8ec93a716a57a11db00d87a8409b722"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae8ec93a716a57a11db00d87a8409b722">&#9670;&nbsp;</a></span>new_task() <span class="overload">[4/4]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename RT , typename C , typename... Args&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classThreads_1_1Task.html">Task</a>&lt;RT&gt; Threads::new_task </td>
          <td>(</td>
          <td class="paramtype">RT(C::*)(Args...) const&#160;</td>
          <td class="paramname"><em>fun_ptr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">typename <a class="el" href="structidentity.html">identity</a>&lt; const C &gt;::type &amp;&#160;</td>
          <td class="paramname"><em>c</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">typename <a class="el" href="structidentity.html">identity</a>&lt; Args &gt;::type...&#160;</td>
          <td class="paramname"><em>args</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Overload of the new_task function. See the other functions of same name for more information. </p>

<p class="definition">Definition at line <a class="el" href="thread__management_8h_source.html#l01464">1464</a> of file <a class="el" href="thread__management_8h_source.html">thread_management.h</a>.</p>

</div>
</div>
</div><!-- contents -->
<!-- HTML footer for doxygen 1.8.13-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
