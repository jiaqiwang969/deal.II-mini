<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<link rel="canonical" href="https://www.dealii.org/current/doxygen/deal.II/namespaceUtilities_1_1MPI.html" />
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>The deal.II Library: Utilities::MPI Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link rel="SHORTCUT ICON" href="deal.ico"></link>
<script type="text/javascript" src="custom.js"></script>
<meta name="author" content="The deal.II Authors <authors@dealii.org>"></meta>
<meta name="copyright" content="Copyright (C) 1998 - 2021 by the deal.II authors"></meta>
<meta name="deal.II-version" content="10.0.0-pre"></meta>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logo200.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">Reference documentation for deal.II version 10.0.0-pre</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!--Extra macros for MathJax:-->
<div style="display:none">
\(\newcommand{\dealvcentcolon}{\mathrel{\mathop{:}}}\)
\(\newcommand{\dealcoloneq}{\dealvcentcolon\mathrel{\mkern-1.2mu}=}\)
\(\newcommand{\jump}[1]{\left[\!\left[ #1 \right]\!\right]}\)
\(\newcommand{\average}[1]{\left\{\!\left\{ #1 \right\}\!\right\}}\)
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceUtilities.html">Utilities</a></li><li class="navelem"><a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#namespaces">Namespaces</a> &#124;
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">Utilities::MPI Namespace Reference<div class="ingroups"><a class="el" href="group__utilities.html">Utility functions and classes</a></div></div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="namespaces"></a>
Namespaces</h2></td></tr>
<tr class="memitem:namespaceUtilities_1_1MPI_1_1ConsensusAlgorithms"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI_1_1ConsensusAlgorithms.html">ConsensusAlgorithms</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:namespaceUtilities_1_1MPI_1_1internal"><td class="memItemLeft" align="right" valign="top"> &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI_1_1internal.html">internal</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1CollectiveMutex.html">CollectiveMutex</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1CommunicationPatternBase.html">CommunicationPatternBase</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1DuplicatedCommunicator.html">DuplicatedCommunicator</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structUtilities_1_1MPI_1_1MinMaxAvg.html">MinMaxAvg</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1MPI__InitFinalize.html">MPI_InitFinalize</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1NoncontiguousPartitioner.html">NoncontiguousPartitioner</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1Partitioner.html">Partitioner</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1ProcessGrid.html">ProcessGrid</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classUtilities_1_1MPI_1_1RemotePointEvaluation.html">RemotePointEvaluation</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ac26de0c059200523177bb1d92cc25d00"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="classint.html">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#ac26de0c059200523177bb1d92cc25d00">n_mpi_processes</a> (const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator)</td></tr>
<tr class="separator:ac26de0c059200523177bb1d92cc25d00"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a895dcd8223a0ee6f0e6a80b80e2d5982"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="classint.html">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a895dcd8223a0ee6f0e6a80b80e2d5982">this_mpi_process</a> (const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator)</td></tr>
<tr class="separator:a895dcd8223a0ee6f0e6a80b80e2d5982"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd4ad9a11431f676413e44c4db6e7998"><td class="memItemLeft" align="right" valign="top">const std::vector&lt; unsigned <a class="el" href="classint.html">int</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#abd4ad9a11431f676413e44c4db6e7998">mpi_processes_within_communicator</a> (const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm_large, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm_small)</td></tr>
<tr class="separator:abd4ad9a11431f676413e44c4db6e7998"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89b9a3309dffffe1447758157a33dbb6"><td class="memItemLeft" align="right" valign="top">std::vector&lt; unsigned <a class="el" href="classint.html">int</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a89b9a3309dffffe1447758157a33dbb6">compute_point_to_point_communication_pattern</a> (const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_comm, const std::vector&lt; unsigned <a class="el" href="classint.html">int</a> &gt; &amp;destinations)</td></tr>
<tr class="separator:a89b9a3309dffffe1447758157a33dbb6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a78909ee75d2de673a70554e356c833b2"><td class="memItemLeft" align="right" valign="top">unsigned <a class="el" href="classint.html">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a78909ee75d2de673a70554e356c833b2">compute_n_point_to_point_communications</a> (const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_comm, const std::vector&lt; unsigned <a class="el" href="classint.html">int</a> &gt; &amp;destinations)</td></tr>
<tr class="separator:a78909ee75d2de673a70554e356c833b2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa94c66b4997bb4b8cc67022baefcc08c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classMPI__Comm.html">MPI_Comm</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#aa94c66b4997bb4b8cc67022baefcc08c">duplicate_communicator</a> (const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator)</td></tr>
<tr class="separator:aa94c66b4997bb4b8cc67022baefcc08c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1994cd0f2168ced4026e601eabda0f82"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a1994cd0f2168ced4026e601eabda0f82">free_communicator</a> (<a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator)</td></tr>
<tr class="separator:a1994cd0f2168ced4026e601eabda0f82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af71d4b9497936fedf1398c0b6fba2ee7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classint.html">int</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#af71d4b9497936fedf1398c0b6fba2ee7">create_group</a> (const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm, const MPI_Group &amp;group, const <a class="el" href="classint.html">int</a> tag, <a class="el" href="classMPI__Comm.html">MPI_Comm</a> *new_comm)</td></tr>
<tr class="separator:af71d4b9497936fedf1398c0b6fba2ee7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7af3310f5e0246f93c75f60805ca9089"><td class="memItemLeft" align="right" valign="top">std::vector&lt; <a class="el" href="classIndexSet.html">IndexSet</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a7af3310f5e0246f93c75f60805ca9089">create_ascending_partitioning</a> (const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm, const <a class="el" href="classIndexSet.html#afd0c161cdaaa0600f22339af5900ac77">IndexSet::size_type</a> locally_owned_size)</td></tr>
<tr class="separator:a7af3310f5e0246f93c75f60805ca9089"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a810a7bbb660da1347eca2d01364bf6f8"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classIndexSet.html">IndexSet</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a810a7bbb660da1347eca2d01364bf6f8">create_evenly_distributed_partitioning</a> (const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm, const <a class="el" href="classIndexSet.html#afd0c161cdaaa0600f22339af5900ac77">IndexSet::size_type</a> total_size)</td></tr>
<tr class="separator:a810a7bbb660da1347eca2d01364bf6f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a02e3d15595d7880f5facf4bbfc2bd669"><td class="memTemplParams" colspan="2">template&lt;class Iterator , typename Number  = long double&gt; </td></tr>
<tr class="memitem:a02e3d15595d7880f5facf4bbfc2bd669"><td class="memTemplItemLeft" align="right" valign="top">std::pair&lt; Number, typename <a class="el" href="structnumbers_1_1NumberTraits.html">numbers::NumberTraits</a>&lt; Number &gt;::real_type &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a02e3d15595d7880f5facf4bbfc2bd669">mean_and_standard_deviation</a> (const Iterator begin, const Iterator end, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm)</td></tr>
<tr class="separator:a02e3d15595d7880f5facf4bbfc2bd669"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab544a3bf3301a6dd3e705ee352c5551b"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:ab544a3bf3301a6dd3e705ee352c5551b"><td class="memTemplItemLeft" align="right" valign="top">T&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#ab544a3bf3301a6dd3e705ee352c5551b">sum</a> (const T &amp;t, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator)</td></tr>
<tr class="separator:ab544a3bf3301a6dd3e705ee352c5551b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a45adfbc2f2e3b9bdf41db0c923062878"><td class="memTemplParams" colspan="2">template&lt;typename T , typename U &gt; </td></tr>
<tr class="memitem:a45adfbc2f2e3b9bdf41db0c923062878"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a45adfbc2f2e3b9bdf41db0c923062878">sum</a> (const T &amp;values, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator, U &amp;sums)</td></tr>
<tr class="separator:a45adfbc2f2e3b9bdf41db0c923062878"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afaf69c2cc054b615707da05e05239b1c"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:afaf69c2cc054b615707da05e05239b1c"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#afaf69c2cc054b615707da05e05239b1c">sum</a> (const <a class="el" href="classArrayView.html">ArrayView</a>&lt; const T &gt; &amp;values, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator, const <a class="el" href="classArrayView.html">ArrayView</a>&lt; T &gt; &amp;sums)</td></tr>
<tr class="separator:afaf69c2cc054b615707da05e05239b1c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add36cb2862973c06be029415bc72c524"><td class="memTemplParams" colspan="2">template&lt;int rank, int dim, typename Number &gt; </td></tr>
<tr class="memitem:add36cb2862973c06be029415bc72c524"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classSymmetricTensor.html">SymmetricTensor</a>&lt; rank, dim, Number &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#add36cb2862973c06be029415bc72c524">sum</a> (const <a class="el" href="classSymmetricTensor.html">SymmetricTensor</a>&lt; rank, dim, Number &gt; &amp;local, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator)</td></tr>
<tr class="separator:add36cb2862973c06be029415bc72c524"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc189f054cee2690962d6a76eb62eb35"><td class="memTemplParams" colspan="2">template&lt;int rank, int dim, typename Number &gt; </td></tr>
<tr class="memitem:adc189f054cee2690962d6a76eb62eb35"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; rank, dim, Number &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#adc189f054cee2690962d6a76eb62eb35">sum</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; rank, dim, Number &gt; &amp;local, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator)</td></tr>
<tr class="separator:adc189f054cee2690962d6a76eb62eb35"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22d907910113b680b91b8374edcbb41a"><td class="memTemplParams" colspan="2">template&lt;typename Number &gt; </td></tr>
<tr class="memitem:a22d907910113b680b91b8374edcbb41a"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a22d907910113b680b91b8374edcbb41a">sum</a> (const <a class="el" href="classSparseMatrix.html">SparseMatrix</a>&lt; Number &gt; &amp;local, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator, <a class="el" href="classSparseMatrix.html">SparseMatrix</a>&lt; Number &gt; &amp;global)</td></tr>
<tr class="separator:a22d907910113b680b91b8374edcbb41a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad2f716b789abe53715d6659f38aa7815"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:ad2f716b789abe53715d6659f38aa7815"><td class="memTemplItemLeft" align="right" valign="top">T&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#ad2f716b789abe53715d6659f38aa7815">max</a> (const T &amp;t, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator)</td></tr>
<tr class="separator:ad2f716b789abe53715d6659f38aa7815"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a483afd638220cc834b4bdd8015e19b81"><td class="memTemplParams" colspan="2">template&lt;typename T , typename U &gt; </td></tr>
<tr class="memitem:a483afd638220cc834b4bdd8015e19b81"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a483afd638220cc834b4bdd8015e19b81">max</a> (const T &amp;values, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator, U &amp;maxima)</td></tr>
<tr class="separator:a483afd638220cc834b4bdd8015e19b81"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8cc6e56338671db4b65dd9e2e811f6a6"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a8cc6e56338671db4b65dd9e2e811f6a6"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a8cc6e56338671db4b65dd9e2e811f6a6">max</a> (const <a class="el" href="classArrayView.html">ArrayView</a>&lt; const T &gt; &amp;values, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator, const <a class="el" href="classArrayView.html">ArrayView</a>&lt; T &gt; &amp;maxima)</td></tr>
<tr class="separator:a8cc6e56338671db4b65dd9e2e811f6a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ac5275c3c74902f8a9d6e7bdb514179"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a9ac5275c3c74902f8a9d6e7bdb514179"><td class="memTemplItemLeft" align="right" valign="top">T&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a9ac5275c3c74902f8a9d6e7bdb514179">min</a> (const T &amp;t, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator)</td></tr>
<tr class="separator:a9ac5275c3c74902f8a9d6e7bdb514179"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62a7c0e2d38176841a2ea95eb334ab7e"><td class="memTemplParams" colspan="2">template&lt;typename T , typename U &gt; </td></tr>
<tr class="memitem:a62a7c0e2d38176841a2ea95eb334ab7e"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a62a7c0e2d38176841a2ea95eb334ab7e">min</a> (const T &amp;values, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator, U &amp;minima)</td></tr>
<tr class="separator:a62a7c0e2d38176841a2ea95eb334ab7e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3354767069b32a6827a5c9e5212babae"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a3354767069b32a6827a5c9e5212babae"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a3354767069b32a6827a5c9e5212babae">min</a> (const <a class="el" href="classArrayView.html">ArrayView</a>&lt; const T &gt; &amp;values, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator, const <a class="el" href="classArrayView.html">ArrayView</a>&lt; T &gt; &amp;minima)</td></tr>
<tr class="separator:a3354767069b32a6827a5c9e5212babae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a32879e6c2f20242f7fa2b4f16ebf674a"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a32879e6c2f20242f7fa2b4f16ebf674a"><td class="memTemplItemLeft" align="right" valign="top">T&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a32879e6c2f20242f7fa2b4f16ebf674a">logical_or</a> (const T &amp;t, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator)</td></tr>
<tr class="separator:a32879e6c2f20242f7fa2b4f16ebf674a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9b046a6551d0ad156a2ec6c140562440"><td class="memTemplParams" colspan="2">template&lt;typename T , typename U &gt; </td></tr>
<tr class="memitem:a9b046a6551d0ad156a2ec6c140562440"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a9b046a6551d0ad156a2ec6c140562440">logical_or</a> (const T &amp;values, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator, U &amp;results)</td></tr>
<tr class="separator:a9b046a6551d0ad156a2ec6c140562440"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a274f8c95bfdbbf4c7fee1213706fb62b"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a274f8c95bfdbbf4c7fee1213706fb62b"><td class="memTemplItemLeft" align="right" valign="top">void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a274f8c95bfdbbf4c7fee1213706fb62b">logical_or</a> (const <a class="el" href="classArrayView.html">ArrayView</a>&lt; const T &gt; &amp;values, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator, const <a class="el" href="classArrayView.html">ArrayView</a>&lt; T &gt; &amp;results)</td></tr>
<tr class="separator:a274f8c95bfdbbf4c7fee1213706fb62b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac99815842a50d26e069a62fd01212c41"><td class="memItemLeft" align="right" valign="top"><a class="el" href="structUtilities_1_1MPI_1_1MinMaxAvg.html">MinMaxAvg</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#ac99815842a50d26e069a62fd01212c41">min_max_avg</a> (const <a class="el" href="classdouble.html">double</a> my_value, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator)</td></tr>
<tr class="separator:ac99815842a50d26e069a62fd01212c41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad857b6e771a00fd962803b62486edb81"><td class="memItemLeft" align="right" valign="top">std::vector&lt; <a class="el" href="structUtilities_1_1MPI_1_1MinMaxAvg.html">MinMaxAvg</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#ad857b6e771a00fd962803b62486edb81">min_max_avg</a> (const std::vector&lt; <a class="el" href="classdouble.html">double</a> &gt; &amp;my_value, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator)</td></tr>
<tr class="separator:ad857b6e771a00fd962803b62486edb81"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06db7b273e3a952c8a55133ed77d0340"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a06db7b273e3a952c8a55133ed77d0340">min_max_avg</a> (const <a class="el" href="classArrayView.html">ArrayView</a>&lt; const <a class="el" href="classdouble.html">double</a> &gt; &amp;my_values, const <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="structUtilities_1_1MPI_1_1MinMaxAvg.html">MinMaxAvg</a> &gt; &amp;result, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;mpi_communicator)</td></tr>
<tr class="separator:a06db7b273e3a952c8a55133ed77d0340"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8e632a701db5e1ba05c4656a914e82b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classbool.html">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#aa8e632a701db5e1ba05c4656a914e82b">job_supports_mpi</a> ()</td></tr>
<tr class="separator:aa8e632a701db5e1ba05c4656a914e82b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0acdfd4af3a4d9d8fe0067a1e604cd80"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a0acdfd4af3a4d9d8fe0067a1e604cd80"><td class="memTemplItemLeft" align="right" valign="top">std::map&lt; unsigned <a class="el" href="classint.html">int</a>, T &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a0acdfd4af3a4d9d8fe0067a1e604cd80">some_to_some</a> (const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm, const std::map&lt; unsigned <a class="el" href="classint.html">int</a>, T &gt; &amp;objects_to_send)</td></tr>
<tr class="separator:a0acdfd4af3a4d9d8fe0067a1e604cd80"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5a7433f594a19070add2afa0f769efb"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:ac5a7433f594a19070add2afa0f769efb"><td class="memTemplItemLeft" align="right" valign="top">std::vector&lt; T &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#ac5a7433f594a19070add2afa0f769efb">all_gather</a> (const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm, const T &amp;object_to_send)</td></tr>
<tr class="separator:ac5a7433f594a19070add2afa0f769efb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d4560fb9a0712a910b9e613591ffedc"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a1d4560fb9a0712a910b9e613591ffedc"><td class="memTemplItemLeft" align="right" valign="top">std::vector&lt; T &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a1d4560fb9a0712a910b9e613591ffedc">gather</a> (const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm, const T &amp;object_to_send, const unsigned <a class="el" href="classint.html">int</a> root_process=0)</td></tr>
<tr class="separator:a1d4560fb9a0712a910b9e613591ffedc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a128aed5c46be49d692bbbc3a23424c36"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a128aed5c46be49d692bbbc3a23424c36"><td class="memTemplItemLeft" align="right" valign="top">T&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a128aed5c46be49d692bbbc3a23424c36">broadcast</a> (const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm, const T &amp;object_to_send, const unsigned <a class="el" href="classint.html">int</a> root_process=0)</td></tr>
<tr class="separator:a128aed5c46be49d692bbbc3a23424c36"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e963546bd81b0cdd88e1840cfa8f227"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a9e963546bd81b0cdd88e1840cfa8f227"><td class="memTemplItemLeft" align="right" valign="top">T&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a9e963546bd81b0cdd88e1840cfa8f227">reduce</a> (const T &amp;local_value, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm, const std::function&lt; T(const T &amp;, const T &amp;)&gt; &amp;combiner, const unsigned <a class="el" href="classint.html">int</a> root_process=0)</td></tr>
<tr class="separator:a9e963546bd81b0cdd88e1840cfa8f227"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7973dfb3b425cd551dcb12085e8b4cfb"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a7973dfb3b425cd551dcb12085e8b4cfb"><td class="memTemplItemLeft" align="right" valign="top">T&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a7973dfb3b425cd551dcb12085e8b4cfb">all_reduce</a> (const T &amp;local_value, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm, const std::function&lt; T(const T &amp;, const T &amp;)&gt; &amp;combiner)</td></tr>
<tr class="separator:a7973dfb3b425cd551dcb12085e8b4cfb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a19d5bdd546cc6440259a4df6f945f3d9"><td class="memItemLeft" align="right" valign="top">std::vector&lt; unsigned <a class="el" href="classint.html">int</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a19d5bdd546cc6440259a4df6f945f3d9">compute_index_owner</a> (const <a class="el" href="classIndexSet.html">IndexSet</a> &amp;owned_indices, const <a class="el" href="classIndexSet.html">IndexSet</a> &amp;indices_to_look_up, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm)</td></tr>
<tr class="separator:a19d5bdd546cc6440259a4df6f945f3d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a58671b36907e18de1a24efa3aea12f45"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a58671b36907e18de1a24efa3aea12f45"><td class="memTemplItemLeft" align="right" valign="top">std::vector&lt; T &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a58671b36907e18de1a24efa3aea12f45">compute_set_union</a> (const std::vector&lt; T &gt; &amp;vec, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm)</td></tr>
<tr class="separator:a58671b36907e18de1a24efa3aea12f45"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7835fa8da9f189681b62287b5c1481d7"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a7835fa8da9f189681b62287b5c1481d7"><td class="memTemplItemLeft" align="right" valign="top">std::set&lt; T &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="namespaceUtilities_1_1MPI.html#a7835fa8da9f189681b62287b5c1481d7">compute_set_union</a> (const std::set&lt; T &gt; &amp;set, const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;comm)</td></tr>
<tr class="separator:a7835fa8da9f189681b62287b5c1481d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>A namespace for utility functions that abstract certain operations using the Message Passing Interface (<a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>) or provide fallback operations in case deal.II is configured not to use <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> at all. </p>
</div><h2 class="groupheader">Function Documentation</h2>
<a id="ac26de0c059200523177bb1d92cc25d00"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac26de0c059200523177bb1d92cc25d00">&#9670;&nbsp;</a></span>n_mpi_processes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="classint.html">int</a> Utilities::MPI::n_mpi_processes </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the number of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> processes there exist in the given <a class="el" href="DEALGlossary.html#GlossMPICommunicator">communicator</a> object. If this is a sequential job (i.e., the program is not using <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> at all, or is using <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> but has been started with only one <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> process), then the communicator necessarily involves only one process and the function returns 1. </p>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00117">117</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="a895dcd8223a0ee6f0e6a80b80e2d5982"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a895dcd8223a0ee6f0e6a80b80e2d5982">&#9670;&nbsp;</a></span>this_mpi_process()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="classint.html">int</a> Utilities::MPI::this_mpi_process </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the <a class="el" href="DEALGlossary.html#GlossMPIRank">rank of the present MPI process</a> in the space of processes described by the given <a class="el" href="DEALGlossary.html#GlossMPICommunicator">communicator</a>. This will be a unique value for each process between zero and (less than) the number of all processes (given by <a class="el" href="namespaceUtilities_1_1Trilinos.html#a533f1af4c8ce78331055554880899ae6">get_n_mpi_processes()</a>). </p>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00128">128</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="abd4ad9a11431f676413e44c4db6e7998"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd4ad9a11431f676413e44c4db6e7998">&#9670;&nbsp;</a></span>mpi_processes_within_communicator()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const std::vector&lt; unsigned <a class="el" href="classint.html">int</a> &gt; Utilities::MPI::mpi_processes_within_communicator </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm_large</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm_small</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return a vector of the ranks (within <code>comm_large</code>) of a subset of processes specified by <code>comm_small</code>. </p>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00140">140</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="a89b9a3309dffffe1447758157a33dbb6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a89b9a3309dffffe1447758157a33dbb6">&#9670;&nbsp;</a></span>compute_point_to_point_communication_pattern()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; unsigned <a class="el" href="classint.html">int</a> &gt; Utilities::MPI::compute_point_to_point_communication_pattern </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; unsigned <a class="el" href="classint.html">int</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>destinations</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Consider an unstructured communication pattern where every process in an <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> universe wants to send some data to a subset of the other processors. To do that, the other processors need to know who to expect messages from. This function computes this information.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">mpi_comm</td><td>A <a class="el" href="DEALGlossary.html#GlossMPICommunicator">communicator</a> that describes the processors that are going to communicate with each other.</td></tr>
    <tr><td class="paramname">destinations</td><td>The list of processors the current process wants to send information to. This list need not be sorted in any way. If it contains duplicate entries that means that multiple messages are intended for a given destination.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A list of processors that have indicated that they want to send something to the current processor. The resulting list is not sorted. It may contain duplicate entries if processors enter the same destination more than once in their destinations list. </dd></dl>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00299">299</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="a78909ee75d2de673a70554e356c833b2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a78909ee75d2de673a70554e356c833b2">&#9670;&nbsp;</a></span>compute_n_point_to_point_communications()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">unsigned <a class="el" href="classint.html">int</a> Utilities::MPI::compute_n_point_to_point_communications </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; unsigned <a class="el" href="classint.html">int</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>destinations</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Simplified (for efficiency) version of the <a class="el" href="namespaceUtilities_1_1MPI.html#a89b9a3309dffffe1447758157a33dbb6">compute_point_to_point_communication_pattern()</a> which only computes the number of processes in an <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> universe to expect communication from.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">mpi_comm</td><td>A <a class="el" href="DEALGlossary.html#GlossMPICommunicator">communicator</a> that describes the processors that are going to communicate with each other.</td></tr>
    <tr><td class="paramname">destinations</td><td>The list of processors the current process wants to send information to. This list need not be sorted in any way. If it contains duplicate entries that means that multiple messages are intended for a given destination.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A number of processors that want to send something to the current processor. </dd></dl>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00436">436</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="aa94c66b4997bb4b8cc67022baefcc08c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa94c66b4997bb4b8cc67022baefcc08c">&#9670;&nbsp;</a></span>duplicate_communicator()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classMPI__Comm.html">MPI_Comm</a> Utilities::MPI::duplicate_communicator </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Given a <a class="el" href="DEALGlossary.html#GlossMPICommunicator">communicator</a>, generate a new communicator that contains the same set of processors but that has a different, unique identifier.</p>
<p>This functionality can be used to ensure that different objects, such as distributed matrices, each have unique communicators over which they can interact without interfering with each other.</p>
<p>When no longer needed, the communicator created here needs to be destroyed using <a class="el" href="namespaceUtilities_1_1MPI.html#a1994cd0f2168ced4026e601eabda0f82">free_communicator()</a>.</p>
<p>This function is equivalent to calling <code>MPI_Comm_dup(mpi_communicator, &amp;return_value);</code>. </p>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00160">160</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="a1994cd0f2168ced4026e601eabda0f82"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1994cd0f2168ced4026e601eabda0f82">&#9670;&nbsp;</a></span>free_communicator()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::free_communicator </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Free the given <a class="el" href="DEALGlossary.html#GlossMPICommunicator">communicator</a> <code>mpi_communicator</code> that was duplicated using <a class="el" href="namespaceUtilities_1_1MPI.html#aa94c66b4997bb4b8cc67022baefcc08c">duplicate_communicator()</a>.</p>
<p>The argument is passed by reference and will be invalidated and set to the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> null handle. This function is equivalent to calling <code>MPI_Comm_free(&amp;mpi_communicator);</code>. </p>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00171">171</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="af71d4b9497936fedf1398c0b6fba2ee7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af71d4b9497936fedf1398c0b6fba2ee7">&#9670;&nbsp;</a></span>create_group()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classint.html">int</a> Utilities::MPI::create_group </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const MPI_Group &amp;&#160;</td>
          <td class="paramname"><em>group</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classint.html">int</a>&#160;</td>
          <td class="paramname"><em>tag</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classMPI__Comm.html">MPI_Comm</a> *&#160;</td>
          <td class="paramname"><em>new_comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>If <code>comm</code> is an intracommunicator, this function returns a new communicator <code>newcomm</code> with communication group defined by the <code>group</code> argument. The function is only collective over the group of processes that actually want to create the communicator, i.e., that are named in the <code>group</code> argument. If multiple threads at a given process perform concurrent <a class="el" href="namespaceUtilities_1_1MPI.html#af71d4b9497936fedf1398c0b6fba2ee7">create_group()</a> operations, the user must distinguish these operations by providing different <code>tag</code> or <code>comm</code> arguments.</p>
<p>This function was introduced in the MPI-3.0 standard. If available, the corresponding function in the provided <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> implementation is used. Otherwise, the implementation follows the one described in the following publication: </p><div class="fragment"><div class="line">@inproceedings{dinan2011noncollective,</div><div class="line">  title        = {Noncollective communicator creation in MPI},</div><div class="line">  author       = {Dinan, James and Krishnamoorthy, Sriram and Balaji,</div><div class="line">                  Pavan and Hammond, Jeff R and Krishnan, Manojkumar and</div><div class="line">                  Tipparaju, Vinod and Vishnu, Abhinav},</div><div class="line">  booktitle    = {European MPI Users&#39; Group Meeting},</div><div class="line">  pages        = {282--291},</div><div class="line">  year         = {2011},</div><div class="line">  organization = {Springer}</div><div class="line">}</div></div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00181">181</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="a7af3310f5e0246f93c75f60805ca9089"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7af3310f5e0246f93c75f60805ca9089">&#9670;&nbsp;</a></span>create_ascending_partitioning()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; <a class="el" href="classIndexSet.html">IndexSet</a> &gt; Utilities::MPI::create_ascending_partitioning </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classIndexSet.html#afd0c161cdaaa0600f22339af5900ac77">IndexSet::size_type</a>&#160;</td>
          <td class="paramname"><em>locally_owned_size</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Given the number of locally owned elements <code>locally_owned_size</code>, create a 1:1 partitioning of the of elements across the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator <code>comm</code>. The total size of elements is the sum of <code>locally_owned_size</code> across the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator. Each process will store contiguous subset of indices, and the index set on process p+1 starts at the index one larger than the last one stored on process p. </p>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00263">263</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="a810a7bbb660da1347eca2d01364bf6f8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a810a7bbb660da1347eca2d01364bf6f8">&#9670;&nbsp;</a></span>create_evenly_distributed_partitioning()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classIndexSet.html">IndexSet</a> Utilities::MPI::create_evenly_distributed_partitioning </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classIndexSet.html#afd0c161cdaaa0600f22339af5900ac77">IndexSet::size_type</a>&#160;</td>
          <td class="paramname"><em>total_size</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Given the total number of elements <code>total_size</code>, create an evenly distributed 1:1 partitioning of the elements across the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator <code>comm</code>. Uses <code>comm</code> to determine number of partitions and processor ID to call the <code><a class="el" href="namespaceUtilities_1_1MPI.html#a810a7bbb660da1347eca2d01364bf6f8">create_evenly_distributed_partitioning()</a></code> function above. </p>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00285">285</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="a02e3d15595d7880f5facf4bbfc2bd669"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a02e3d15595d7880f5facf4bbfc2bd669">&#9670;&nbsp;</a></span>mean_and_standard_deviation()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;class Iterator , typename Number  = long double&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::pair&lt;Number, typename <a class="el" href="structnumbers_1_1NumberTraits.html">numbers::NumberTraits</a>&lt;Number&gt;::real_type&gt; Utilities::MPI::mean_and_standard_deviation </td>
          <td>(</td>
          <td class="paramtype">const Iterator&#160;</td>
          <td class="paramname"><em>begin</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const Iterator&#160;</td>
          <td class="paramname"><em>end</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Calculate mean and standard deviation across the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator <code>comm</code> for values provided as a range <code>[begin,end)</code>. The mean is computed as \(\bar x=\frac 1N \sum x_k\) where the \(x_k\) are the elements pointed to by the <code>begin</code> and <code>end</code> iterators on all processors (i.e., each processor's <code>[begin,end)</code> range points to a subset of the overall number of elements). The standard deviation is calculated as \(\sigma=\sqrt{\frac {1}{N-1} \sum |x_k -\bar x|^2}\), which is known as unbiased sample variance.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">Number</td><td>specifies the type to store the mean value. The standard deviation is stored as the corresponding real type. This allows, for example, to calculate statistics from integer input values. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ab544a3bf3301a6dd3e705ee352c5551b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab544a3bf3301a6dd3e705ee352c5551b">&#9670;&nbsp;</a></span>sum() <span class="overload">[1/6]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">T Utilities::MPI::sum </td>
          <td>(</td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>t</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the sum over all processors of the value <code>t</code>. This function is collective over all processors given in the <a class="el" href="DEALGlossary.html#GlossMPICommunicator">communicator</a>. If deal.II is not configured for use of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>, this function simply returns the value of <code>t</code>. This function corresponds to the <code>MPI_Allreduce</code> function, i.e. all processors receive the result of this operation.</p>
<dl class="section note"><dt>Note</dt><dd>Sometimes, not all processors need a result and in that case one would call the <code>MPI_Reduce</code> function instead of the <code>MPI_Allreduce</code> function. The latter is at most twice as expensive, so if you are concerned about performance, it may be worthwhile investigating whether your algorithm indeed needs the result everywhere.</dd>
<dd>
This function is only implemented for certain template arguments <code>T</code>, namely <code>float, double, int, unsigned int</code>. </dd></dl>

</div>
</div>
<a id="a45adfbc2f2e3b9bdf41db0c923062878"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a45adfbc2f2e3b9bdf41db0c923062878">&#9670;&nbsp;</a></span>sum() <span class="overload">[2/6]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , typename U &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::sum </td>
          <td>(</td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">U &amp;&#160;</td>
          <td class="paramname"><em>sums</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Like the previous function, but take the sums over the elements of an array of type T. In other words, the i-th element of the results array is the sum over the i-th entries of the input arrays from each processor. T and U must decay to the same type, e.g. they just differ by one of them having a const type qualifier and the other not.</p>
<p>Input and output arrays may be the same. </p>

</div>
</div>
<a id="afaf69c2cc054b615707da05e05239b1c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afaf69c2cc054b615707da05e05239b1c">&#9670;&nbsp;</a></span>sum() <span class="overload">[3/6]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::sum </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classArrayView.html">ArrayView</a>&lt; const T &gt; &amp;&#160;</td>
          <td class="paramname"><em>values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classArrayView.html">ArrayView</a>&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>sums</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Like the previous function, but take the sums over the elements of an array as specified by the <a class="el" href="classArrayView.html">ArrayView</a> arguments. In other words, the i-th element of the results array is the sum over the i-th entries of the input arrays from each processor.</p>
<p>Input and output arrays may be the same. </p>

</div>
</div>
<a id="add36cb2862973c06be029415bc72c524"></a>
<h2 class="memtitle"><span class="permalink"><a href="#add36cb2862973c06be029415bc72c524">&#9670;&nbsp;</a></span>sum() <span class="overload">[4/6]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;int rank, int dim, typename Number &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classSymmetricTensor.html">SymmetricTensor</a>&lt; rank, dim, Number &gt; Utilities::MPI::sum </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classSymmetricTensor.html">SymmetricTensor</a>&lt; rank, dim, Number &gt; &amp;&#160;</td>
          <td class="paramname"><em>local</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Perform an <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> sum of the entries of a symmetric tensor. </p>

</div>
</div>
<a id="adc189f054cee2690962d6a76eb62eb35"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc189f054cee2690962d6a76eb62eb35">&#9670;&nbsp;</a></span>sum() <span class="overload">[5/6]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;int rank, int dim, typename Number &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; rank, dim, Number &gt; Utilities::MPI::sum </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; rank, dim, Number &gt; &amp;&#160;</td>
          <td class="paramname"><em>local</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Perform an <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> sum of the entries of a tensor. </p>

</div>
</div>
<a id="a22d907910113b680b91b8374edcbb41a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a22d907910113b680b91b8374edcbb41a">&#9670;&nbsp;</a></span>sum() <span class="overload">[6/6]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Number &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::sum </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classSparseMatrix.html">SparseMatrix</a>&lt; Number &gt; &amp;&#160;</td>
          <td class="paramname"><em>local</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classSparseMatrix.html">SparseMatrix</a>&lt; Number &gt; &amp;&#160;</td>
          <td class="paramname"><em>global</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Perform an <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> sum of the entries of a <a class="el" href="classSparseMatrix.html">SparseMatrix</a>.</p>
<dl class="section note"><dt>Note</dt><dd><code>local</code> and <code>global</code> should have the same sparsity pattern and it should be the same for all <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> processes. </dd></dl>

</div>
</div>
<a id="ad2f716b789abe53715d6659f38aa7815"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad2f716b789abe53715d6659f38aa7815">&#9670;&nbsp;</a></span>max() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">T Utilities::MPI::max </td>
          <td>(</td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>t</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the maximum over all processors of the value <code>t</code>. This function is collective over all processors given in the <a class="el" href="DEALGlossary.html#GlossMPICommunicator">communicator</a>. If deal.II is not configured for use of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>, this function simply returns the value of <code>t</code>. This function corresponds to the <code>MPI_Allreduce</code> function, i.e. all processors receive the result of this operation.</p>
<dl class="section note"><dt>Note</dt><dd>Sometimes, not all processors need a result and in that case one would call the <code>MPI_Reduce</code> function instead of the <code>MPI_Allreduce</code> function. The latter is at most twice as expensive, so if you are concerned about performance, it may be worthwhile investigating whether your algorithm indeed needs the result everywhere.</dd>
<dd>
This function is only implemented for certain template arguments <code>T</code>, namely <code>float, double, int, unsigned int</code>. </dd></dl>

</div>
</div>
<a id="a483afd638220cc834b4bdd8015e19b81"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a483afd638220cc834b4bdd8015e19b81">&#9670;&nbsp;</a></span>max() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , typename U &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::max </td>
          <td>(</td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">U &amp;&#160;</td>
          <td class="paramname"><em>maxima</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Like the previous function, but take the maximum over the elements of an array of type T. In other words, the i-th element of the results array is the maximum over the i-th entries of the input arrays from each processor. T and U must decay to the same type, e.g. they just differ by one of them having a const type qualifier and the other not.</p>
<p>Input and output vectors may be the same. </p>

</div>
</div>
<a id="a8cc6e56338671db4b65dd9e2e811f6a6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8cc6e56338671db4b65dd9e2e811f6a6">&#9670;&nbsp;</a></span>max() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::max </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classArrayView.html">ArrayView</a>&lt; const T &gt; &amp;&#160;</td>
          <td class="paramname"><em>values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classArrayView.html">ArrayView</a>&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>maxima</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Like the previous function, but take the maximum over the elements of an array as specified by the <a class="el" href="classArrayView.html">ArrayView</a> arguments. In other words, the i-th element of the results array is the maximum over the i-th entries of the input arrays from each processor.</p>
<p>Input and output arrays may be the same. </p>

</div>
</div>
<a id="a9ac5275c3c74902f8a9d6e7bdb514179"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9ac5275c3c74902f8a9d6e7bdb514179">&#9670;&nbsp;</a></span>min() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">T Utilities::MPI::min </td>
          <td>(</td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>t</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return the minimum over all processors of the value <code>t</code>. This function is collective over all processors given in the <a class="el" href="DEALGlossary.html#GlossMPICommunicator">communicator</a>. If deal.II is not configured for use of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>, this function simply returns the value of <code>t</code>. This function corresponds to the <code>MPI_Allreduce</code> function, i.e. all processors receive the result of this operation.</p>
<dl class="section note"><dt>Note</dt><dd>Sometimes, not all processors need a result and in that case one would call the <code>MPI_Reduce</code> function instead of the <code>MPI_Allreduce</code> function. The latter is at most twice as expensive, so if you are concerned about performance, it may be worthwhile investigating whether your algorithm indeed needs the result everywhere.</dd>
<dd>
This function is only implemented for certain template arguments <code>T</code>, namely <code>float, double, int, unsigned int</code>. </dd></dl>

</div>
</div>
<a id="a62a7c0e2d38176841a2ea95eb334ab7e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a62a7c0e2d38176841a2ea95eb334ab7e">&#9670;&nbsp;</a></span>min() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , typename U &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::min </td>
          <td>(</td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">U &amp;&#160;</td>
          <td class="paramname"><em>minima</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Like the previous function, but take the minima over the elements of an array of type T. In other words, the i-th element of the results array is the minimum of the i-th entries of the input arrays from each processor. T and U must decay to the same type, e.g. they just differ by one of them having a const type qualifier and the other not.</p>
<p>Input and output arrays may be the same. </p>

</div>
</div>
<a id="a3354767069b32a6827a5c9e5212babae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3354767069b32a6827a5c9e5212babae">&#9670;&nbsp;</a></span>min() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::min </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classArrayView.html">ArrayView</a>&lt; const T &gt; &amp;&#160;</td>
          <td class="paramname"><em>values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classArrayView.html">ArrayView</a>&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>minima</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Like the previous function, but take the minimum over the elements of an array as specified by the <a class="el" href="classArrayView.html">ArrayView</a> arguments. In other words, the i-th element of the results array is the minimum over the i-th entries of the input arrays from each processor.</p>
<p>Input and output arrays may be the same. </p>

</div>
</div>
<a id="a32879e6c2f20242f7fa2b4f16ebf674a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a32879e6c2f20242f7fa2b4f16ebf674a">&#9670;&nbsp;</a></span>logical_or() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">T Utilities::MPI::logical_or </td>
          <td>(</td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>t</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Performs a <em>logical or</em> operation over all processors of the value <code>t</code>. The <em>logical or</em> operator <code>||</code> returns the boolean value <code>true</code> if either or all operands are <code>true</code> and returns <code>false</code> otherwise. If the provided value <code>t</code> corresponds to <code>0</code> in its associated data type <code>T</code>, it will be interpreted as <code>false</code>, and <code>true</code> otherwise. Data type <code>T</code> must be of type <code>integral</code>, i.e., <code>bool</code>, <code>char</code>, <code>short</code>, <code>int</code>, <code>long</code>, or any of their variations.</p>
<p>This function is collective over all processors given in the <a class="el" href="DEALGlossary.html#GlossMPICommunicator">communicator</a>. If deal.II is not configured for use of <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>, this function simply returns the value of <code>value</code>. This function corresponds to the <code>MPI_Allreduce</code> function, i.e., all processors receive the result of this operation.</p>
<dl class="section note"><dt>Note</dt><dd>Sometimes, not all processors need a result and in that case one would call the <code>MPI_Reduce</code> function instead of the <code>MPI_Allreduce</code> function. The latter is at most twice as expensive, so if you are concerned about performance, it may be worthwhile investigating whether your algorithm indeed needs the result everywhere. </dd></dl>

</div>
</div>
<a id="a9b046a6551d0ad156a2ec6c140562440"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9b046a6551d0ad156a2ec6c140562440">&#9670;&nbsp;</a></span>logical_or() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , typename U &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::logical_or </td>
          <td>(</td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">U &amp;&#160;</td>
          <td class="paramname"><em>results</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Like the previous function, but performs the <em>logical or</em> operation on each element of an array. In other words, the i-th element of the results array is the result of the <em>logical or</em> operation applied on the i-th entries of the input arrays from each processor. T and U must decay to the same type, e.g., they just differ by one of them having a const type qualifier and the other not.</p>
<p>Input and output arrays may be the same.</p>
<dl class="section note"><dt>Note</dt><dd>Depending on your standard library, this function may not work with specializations of <code>std::vector</code> for the data type <code>bool</code>. In that case, use a different container or data type. </dd></dl>

</div>
</div>
<a id="a274f8c95bfdbbf4c7fee1213706fb62b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a274f8c95bfdbbf4c7fee1213706fb62b">&#9670;&nbsp;</a></span>logical_or() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::logical_or </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classArrayView.html">ArrayView</a>&lt; const T &gt; &amp;&#160;</td>
          <td class="paramname"><em>values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classArrayView.html">ArrayView</a>&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>results</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Like the previous function, but performs the <em>logical or</em> operation on each element of an array as specified by the <a class="el" href="classArrayView.html">ArrayView</a> arguments. In other words, the i-th element of the results array is the result of the <em>logical or</em> operation applied on the i-th entries of the input arrays from each processor.</p>
<p>Input and output arrays may be the same. </p>

</div>
</div>
<a id="ac99815842a50d26e069a62fd01212c41"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac99815842a50d26e069a62fd01212c41">&#9670;&nbsp;</a></span>min_max_avg() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structUtilities_1_1MPI_1_1MinMaxAvg.html">MinMaxAvg</a> Utilities::MPI::min_max_avg </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classdouble.html">double</a>&#160;</td>
          <td class="paramname"><em>my_value</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return sum, average, minimum, maximum, processor id of minimum and maximum as a collective operation of on the given <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> <a class="el" href="DEALGlossary.html#GlossMPICommunicator">communicator</a> <code>mpi_communicator</code>. Each processor's value is given in <code>my_value</code> and the result will be returned. The result is available on all machines.</p>
<dl class="section note"><dt>Note</dt><dd>Sometimes, not all processors need a result and in that case one would call the <code>MPI_Reduce</code> function instead of the <code>MPI_Allreduce</code> function. The latter is at most twice as expensive, so if you are concerned about performance, it may be worthwhile investigating whether your algorithm indeed needs the result everywhere. </dd></dl>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00091">91</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="ad857b6e771a00fd962803b62486edb81"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad857b6e771a00fd962803b62486edb81">&#9670;&nbsp;</a></span>min_max_avg() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; <a class="el" href="structUtilities_1_1MPI_1_1MinMaxAvg.html">MinMaxAvg</a> &gt; Utilities::MPI::min_max_avg </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; <a class="el" href="classdouble.html">double</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>my_value</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Same as above but returning the sum, average, minimum, maximum, process id of minimum and maximum as a collective operation on the given <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> <a class="el" href="DEALGlossary.html#GlossMPICommunicator">communicator</a> <code>mpi_communicator</code> for each entry of the vector.</p>
<dl class="section note"><dt>Note</dt><dd>This function performs a single reduction sweep.</dd></dl>
<dl class="section pre"><dt>Precondition</dt><dd>Size of the input vector has to be the same on all processes. </dd></dl>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00104">104</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="a06db7b273e3a952c8a55133ed77d0340"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a06db7b273e3a952c8a55133ed77d0340">&#9670;&nbsp;</a></span>min_max_avg() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Utilities::MPI::min_max_avg </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classArrayView.html">ArrayView</a>&lt; const <a class="el" href="classdouble.html">double</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>my_values</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classArrayView.html">ArrayView</a>&lt; <a class="el" href="structUtilities_1_1MPI_1_1MinMaxAvg.html">MinMaxAvg</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>result</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>mpi_communicator</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Same as above but returning the sum, average, minimum, maximum, process id of minimum and maximum as a collective operation on the given <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> <a class="el" href="DEALGlossary.html#GlossMPICommunicator">communicator</a> <code>mpi_communicator</code> for each entry of the <a class="el" href="classArrayView.html">ArrayView</a>.</p>
<dl class="section note"><dt>Note</dt><dd>This function performs a single reduction sweep.</dd></dl>
<dl class="section pre"><dt>Precondition</dt><dd>Size of the input <a class="el" href="classArrayView.html">ArrayView</a> has to be the same on all processes and the input and output ArrayVew have to have the same size. </dd></dl>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00492">492</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="aa8e632a701db5e1ba05c4656a914e82b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa8e632a701db5e1ba05c4656a914e82b">&#9670;&nbsp;</a></span>job_supports_mpi()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classbool.html">bool</a> Utilities::MPI::job_supports_mpi </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Return whether (i) deal.II has been compiled to support <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> (for example by compiling with <code>CXX=mpiCC</code>) and if so whether (ii) <code>MPI_Init()</code> has been called (for example using the <a class="el" href="classUtilities_1_1MPI_1_1MPI__InitFinalize.html">Utilities::MPI::MPI_InitFinalize</a> class). In other words, the result indicates whether the current job is running under <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>.</p>
<dl class="section note"><dt>Note</dt><dd>The function does not take into account whether an <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> job actually runs on more than one processor or is, in fact, a single-node job that happens to run under <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a>. </dd></dl>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l00985">985</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="a0acdfd4af3a4d9d8fe0067a1e604cd80"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0acdfd4af3a4d9d8fe0067a1e604cd80">&#9670;&nbsp;</a></span>some_to_some()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::map&lt;unsigned <a class="el" href="classint.html">int</a>, T&gt; Utilities::MPI::some_to_some </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::map&lt; unsigned <a class="el" href="classint.html">int</a>, T &gt; &amp;&#160;</td>
          <td class="paramname"><em>objects_to_send</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Initiate a some-to-some communication, and exchange arbitrary objects (the class T should be serializable using boost::serialize) between processors.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">comm</td><td><a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator.</td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">objects_to_send</td><td>A map from the rank (unsigned int) of the process meant to receive the data and the object to send (the type <code>T</code> must be serializable for this function to work properly). If this map contains an entry with a key equal to the rank of the current process (i.e., an instruction to a process to send data to itself), then this data item is simply copied to the returned object.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A map from the rank (unsigned int) of the process which sent the data and object received. </dd></dl>

</div>
</div>
<a id="ac5a7433f594a19070add2afa0f769efb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac5a7433f594a19070add2afa0f769efb">&#9670;&nbsp;</a></span>all_gather()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;T&gt; Utilities::MPI::all_gather </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>object_to_send</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>A generalization of the classic MPI_Allgather function, that accepts arbitrary data types T, as long as boost::serialize accepts T as an argument.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">comm</td><td><a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">object_to_send</td><td>An object to send to all other processes</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A vector of objects, with size equal to the number of processes in the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator. Each entry contains the object received from the processor with the corresponding rank within the communicator. </dd></dl>

</div>
</div>
<a id="a1d4560fb9a0712a910b9e613591ffedc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d4560fb9a0712a910b9e613591ffedc">&#9670;&nbsp;</a></span>gather()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;T&gt; Utilities::MPI::gather </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>object_to_send</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const unsigned <a class="el" href="classint.html">int</a>&#160;</td>
          <td class="paramname"><em>root_process</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>A generalization of the classic MPI_Gather function, that accepts arbitrary data types T, as long as boost::serialize accepts T as an argument.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">comm</td><td><a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">object_to_send</td><td>an object to send to the root process </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">root_process</td><td>The process, which receives the objects from all processes. By default the process with rank 0 is the root process.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The <code>root_process</code> receives a vector of objects, with size equal to the number of processes in the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator. Each entry contains the object received from the processor with the corresponding rank within the communicator. All other processes receive an empty vector. </dd></dl>

</div>
</div>
<a id="a128aed5c46be49d692bbbc3a23424c36"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a128aed5c46be49d692bbbc3a23424c36">&#9670;&nbsp;</a></span>broadcast()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">T Utilities::MPI::broadcast </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>object_to_send</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const unsigned <a class="el" href="classint.html">int</a>&#160;</td>
          <td class="paramname"><em>root_process</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Sends an object <code>object_to_send</code> from the process <code>root_process</code> to all other processes.</p>
<p>A generalization of the classic <code>MPI_Bcast</code> function that accepts arbitrary data types <code>T</code>, as long as <a class="el" href="namespaceUtilities.html#a1ebf9e8745b1c1c0f314d24a1ec90921">Utilities::pack()</a> (which in turn uses <code>boost::serialize</code>, see in <a class="el" href="namespaceUtilities.html#a1ebf9e8745b1c1c0f314d24a1ec90921">Utilities::pack()</a> for details) accepts <code>T</code> as an argument.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">comm</td><td><a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">object_to_send</td><td>An object to send to all processes. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">root_process</td><td>The process that sends the object to all processes. By default the process with rank 0 is the root process.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>On the root process, return a copy of <code>object_to_send</code>. On every other process, return a copy of the object sent by the <code>root_process</code>. </dd></dl>

</div>
</div>
<a id="a9e963546bd81b0cdd88e1840cfa8f227"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9e963546bd81b0cdd88e1840cfa8f227">&#9670;&nbsp;</a></span>reduce()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">T Utilities::MPI::reduce </td>
          <td>(</td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>local_value</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::function&lt; T(const T &amp;, const T &amp;)&gt; &amp;&#160;</td>
          <td class="paramname"><em>combiner</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const unsigned <a class="el" href="classint.html">int</a>&#160;</td>
          <td class="paramname"><em>root_process</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>A function that combines values <code>local_value</code> from all processes via a user-specified binary operation <code>combiner</code> on the <code>root_process</code>. As such this function is similar to MPI_Reduce (and <a class="el" href="namespaceUtilities_1_1MPI.html#a9ac5275c3c74902f8a9d6e7bdb514179">Utilities::MPI::min</a>/max()): however on the one hand due to the user-specified binary operation it is slower for built-in types but on the other hand general object types, including ones that store variable amounts of data, can be handled.</p>
<p>In contrast to all_reduce, the result will be only available on a single rank. On all other processes, the returned value is undefined. </p>

</div>
</div>
<a id="a7973dfb3b425cd551dcb12085e8b4cfb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7973dfb3b425cd551dcb12085e8b4cfb">&#9670;&nbsp;</a></span>all_reduce()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">T Utilities::MPI::all_reduce </td>
          <td>(</td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>local_value</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::function&lt; T(const T &amp;, const T &amp;)&gt; &amp;&#160;</td>
          <td class="paramname"><em>combiner</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>A function that combines values <code>local_value</code> from all processes via a user-specified binary operation <code>combiner</code> and distributes the result back to all processes. As such this function is similar to MPI_Allreduce (if it were implemented by a global reduction followed by a broadcast step) but due to the user-specified binary operation also general object types, including ones that store variable amounts of data, can be handled. </p>

</div>
</div>
<a id="a19d5bdd546cc6440259a4df6f945f3d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a19d5bdd546cc6440259a4df6f945f3d9">&#9670;&nbsp;</a></span>compute_index_owner()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; unsigned <a class="el" href="classint.html">int</a> &gt; Utilities::MPI::compute_index_owner </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>owned_indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classIndexSet.html">IndexSet</a> &amp;&#160;</td>
          <td class="paramname"><em>indices_to_look_up</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Given a partitioned index set space, compute the owning <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> process rank of each element of a second index set according to the partitioned index set. A natural usage of this function is to compute for each ghosted degree of freedom the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> rank of the process owning that index.</p>
<p>One might think: "But we know which rank a ghost DoF belongs to based on
the subdomain id of the cell it is on". But this heuristic fails for DoFs on interfaces between ghost cells with different subdomain_ids, or between a ghost cell and an artificial cell. Furthermore, this function enables a completely abstract exchange of information without the help of the mesh in terms of neighbors.</p>
<p>The first argument passed to this function, <code>owned_indices</code>, must uniquely partition an index space between all processes. Otherwise, there are no limitations on this argument: In particular, there is no need in partitioning the index space into contiguous subsets. Furthermore, there are no limitations on the second index set <code>indices_to_look_up</code> as long as the size matches the first one. It can be chosen arbitrarily and independently on each process. In the case that the second index set also contains locally owned indices, these indices will be treated correctly and the rank of this process is returned for those entries.</p>
<dl class="section note"><dt>Note</dt><dd>This is a collective operation: all processes within the given communicator have to call this function. Since this function does not use MPI_Alltoall or MPI_Allgather, but instead uses non-blocking point-to-point communication instead, and only a single non-blocking barrier, it reduces the memory consumption significantly. This function is suited for large-scale simulations with &gt;100k <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> ranks.</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">owned_indices</td><td>Index set with indices locally owned by this process. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">indices_to_look_up</td><td>Index set containing indices of which the user is interested the rank of the owning process. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">comm</td><td><a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>List containing the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> process rank for each entry in the index set <code>indices_to_look_up</code>. The order coincides with the order within the ElementIterator. </dd></dl>

<p class="definition">Definition at line <a class="el" href="mpi_8cc_source.html#l01001">1001</a> of file <a class="el" href="mpi_8cc_source.html">mpi.cc</a>.</p>

</div>
</div>
<a id="a58671b36907e18de1a24efa3aea12f45"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a58671b36907e18de1a24efa3aea12f45">&#9670;&nbsp;</a></span>compute_set_union() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;T&gt; Utilities::MPI::compute_set_union </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>vec</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Compute the union of the input vectors <code>vec</code> of all processes in the <a class="el" href="namespaceUtilities_1_1MPI.html">MPI</a> communicator <code>comm</code>.</p>
<dl class="section note"><dt>Note</dt><dd>This is a collective operation. The result will available on all processes. </dd></dl>

</div>
</div>
<a id="a7835fa8da9f189681b62287b5c1481d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7835fa8da9f189681b62287b5c1481d7">&#9670;&nbsp;</a></span>compute_set_union() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::set&lt;T&gt; Utilities::MPI::compute_set_union </td>
          <td>(</td>
          <td class="paramtype">const std::set&lt; T &gt; &amp;&#160;</td>
          <td class="paramname"><em>set</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classMPI__Comm.html">MPI_Comm</a> &amp;&#160;</td>
          <td class="paramname"><em>comm</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>The same as above but for std::set. </p>

</div>
</div>
</div><!-- contents -->
<!-- HTML footer for doxygen 1.8.13-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
