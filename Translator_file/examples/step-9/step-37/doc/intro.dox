examples/step-37/doc/intro.dox

 <br> 

<i>
This program was contributed by Katharina Kormann and Martin
Kronbichler.


The algorithm for the matrix-vector product is based on the article <a
href="http://dx.doi.org/10.1016/j.compfluid.2012.04.012">A generic interface
for parallel cell-based finite element operator application</a><a
href="http://dx.doi.org/10.1016/j.compfluid.2012.04.012">A generic interface
for parallel cell-based finite element operator application</a> by Martin
Kronbichler and Katharina Kormann, Computers and Fluids 63:135&ndash;147,
2012, and the paper &quot;Parallel finite element operator application: Graph
partitioning and coloring&quot; by Katharina Kormann and Martin Kronbichler
in: Proceedings of the 7th IEEE International Conference on e-Science, 2011.


This work was partly supported by the German Research Foundation (DFG) through
the project "High-order discontinuous Galerkin for the exa-scale" (ExaDG)
within the priority program "Software for Exascale Computing" (SPPEXA). The
large-scale computations shown in the results section of this tutorial program
were supported by Gauss Centre for Supercomputing e.V. (www.gauss-centre.eu)
by providing computing time on the GCS Supercomputer SuperMUC at Leibniz
Supercomputing Centre (LRZ, www.lrz.de) through project id pr83te. </i> 。

<a name="Intro"></a>

<h1>Introduction</h1>

这个例子展示了如何在超立方体上实现一个无矩阵的方法，即不明确存储矩阵元素的方法，用于具有可变系数的二阶泊松方程。该线性系统将用多网格方法求解，并使用MPI的大规模并行性。

无矩阵方法的主要动机是，在今天的处理器上，对主内存的访问（即对不适合缓存的对象）已经成为许多偏微分方程求解器的瓶颈。为了执行基于矩阵的矩阵-向量乘积，现代CPU花在等待数据从内存到达的时间远远多于实际进行浮点乘法和加法的时间。因此，如果我们可以通过重新计算矩阵元素来代替在内存中查找矩阵元素，或者更确切地说，这些条目所代表的运算符&mdash;，我们可能会在整体运行时间方面获胜，即使这需要大量的额外浮点运算。也就是说，用一个微不足道的实现来实现这一点是不够的，我们需要真正关注细节来获得性能。这个教程程序和上面提到的论文展示了如何实现这样一个方案，并演示了可以获得的速度提升。




<h3>The test case</h3>

在这个例子中，我们考虑泊松问题@f{eqnarray*} -
\nabla \cdot a(\mathbf x) \nabla u &=& 1, \\ u &=& 0 \quad \text{on}\
\partial \Omega @f}，其中 $a(\mathbf x)$ 是一个可变系数。下面，我们将解释如何在不明确形成矩阵的情况下实现这个问题的矩阵-向量乘积。当然，对于其他方程也可以用类似的方法进行构造。

我们选择 $\Omega=[0,1]^3$ 和 $a(\mathbf x)=\frac{1}{0.05 +
2\|\mathbf x\|^2}$ 作为域。由于系数是围绕原点对称的，但域却不是，我们最终会得到一个非对称的解决方案。




<h3>Matrix-vector product implementation</h3>

为了找出我们如何编写一个执行矩阵-向量乘积的代码，但不需要存储矩阵元素，让我们先看看一个有限元矩阵<i>A</i>是如何组装起来的。

@f{eqnarray*}
A = \sum_{\mathrm{cell}=1}^{\mathrm{n\_cells}}
P_{\mathrm{cell,{loc-glob}}}^T A_{\mathrm{cell}} P_{\mathrm{cell,{loc-glob}}}.


@f}

在这个公式中，矩阵<i>P</i><sub>cell,loc-glob</sub>是一个矩形矩阵，定义了从当前单元的局部自由度到全局自由度的索引映射。可以建立这个算子的信息通常被编码在 <code>local_dof_indices</code> 变量中，并在deal.II中用于汇编调用填充矩阵。这里，<i>A</i><sub>cell</sub>表示与<i>A</i>相关的单元矩阵。

如果我们要进行矩阵-向量乘积，因此我们可以使用

@f{eqnarray*}
y &=& A\cdot u = \left(\sum_{\text{cell}=1}^{\mathrm{n\_cells}} P_\mathrm{cell,{loc-glob}}^T
A_\mathrm{cell} P_\mathrm{cell,{loc-glob}}\right) \cdot u
\\
&=& \sum_{\mathrm{cell}=1}^{\mathrm{n\_cells}} P_\mathrm{cell,{loc-glob}}^T
A_\mathrm{cell} u_\mathrm{cell}
\\
&=& \sum_{\mathrm{cell}=1}^{\mathrm{n\_cells}} P_\mathrm{cell,{loc-glob}}^T
v_\mathrm{cell},


@f}

其中<i>u</i><sub>cell</sub>是<i>u</i>在各单元自由度处的值，而<i>v</i><sub>cell</sub>=<i>A</i><sub>cell</sub><i>u</i><sub>cell</sub>相应为结果。因此，实现拉普拉斯的局部作用的一个天真尝试是使用以下代码。

@code
Matrixfree<dim>::vmult (Vector<double>       &dst,
                        const Vector<double> &src) const
{
  dst = 0;


  QGauss<dim>  quadrature_formula(fe.degree+1);
  FEValues<dim> fe_values (fe, quadrature_formula,
                           update_gradients | update_JxW_values|
                           update_quadrature_points);


  const unsigned int   dofs_per_cell = fe.n_dofs_per_cell();
  const unsigned int   n_q_points    = quadrature_formula.size();


  FullMatrix<double>   cell_matrix (dofs_per_cell, dofs_per_cell);
  Vector<double>       cell_src (dofs_per_cell),
                       cell_dst (dofs_per_cell);
  const Coefficient<dim> coefficient;
  std::vector<double> coefficient_values(n_q_points);


  std::vector<unsigned int> local_dof_indices (dofs_per_cell);


  for (const auto & cell : dof_handler.active_cell_iterators())
    {
      cell_matrix = 0;
      fe_values.reinit (cell);
      coefficient.value_list(fe_values.get_quadrature_points(),
                             coefficient_values);


      for (unsigned int q=0; q<n_q_points; ++q)
        for (unsigned int i=0; i<dofs_per_cell; ++i)
          for (unsigned int j=0; j<dofs_per_cell; ++j)
            cell_matrix(i,j) += (fe_values.shape_grad(i,q) *
                                 fe_values.shape_grad(j,q) *
                                 fe_values.JxW(q)*
                                 coefficient_values[q]);


      cell->get_dof_indices (local_dof_indices);


      for (unsigned int i=0; i<dofs_per_cell; ++i)
        cell_src(i) = src(local_dof_indices(i));


      cell_matrix.vmult (cell_dst, cell_src);


      for (unsigned int i=0; i<dofs_per_cell; ++i)
        dst(local_dof_indices(i)) += cell_dst;
    }
}
@endcode



在这里，我们忽略了边界条件以及我们可能有的任何悬空节点，尽管使用AffineConstraints类来包括这两者都不是很困难。请注意，我们首先以通常的方式生成局部矩阵，作为每个局部矩阵项的所有正交点的总和。为了形成上述公式中表达的实际乘积，我们提取细胞相关自由度的 <code>src</code> 的值（<i>P</i><sub>cell,loc-glob</sub>的作用），乘以局部矩阵（<i>A</i><sub>cell</sub>），最后把结果加到目标向量 <code>dst</code> （<i>P</i><sub>cell,loc-glob</sub><sup>T</sup>的动作，加在所有元素上）。原则上不会比这更难。

虽然这段代码是完全正确的，但它非常慢。对于每个单元，我们生成一个局部矩阵，这需要三个嵌套循环，循环长度等于局部自由度的数量来计算。然后，乘法本身是由两个嵌套循环完成的，这意味着它要便宜得多。

改善这一点的一个方法是认识到，从概念上讲，局部矩阵可以被认为是三个矩阵的乘积。

@f{eqnarray*}
A_\mathrm{cell} = B_\mathrm{cell}^T D_\mathrm{cell} B_\mathrm{cell},


@f}

对于拉普拉斯算子的例子，<i>q</i>*dim+<i>d,i</i>的第1个元素<sub>cell</sub>是由 <code>fe_values.shape_grad(i,q)[d]</code> 给出。这个矩阵由 <code>dim*n_q_points</code> 行和 @p dofs_per_cell 列组成。矩阵<i>D</i><sub>cell</sub>是对角线，包含了 <code>fe_values.JxW(q) * coefficient_values[q]</code> 的值（或者说， @p 这些值中每一个的dim副本）。这种有限元矩阵的表示方法经常可以在工程文献中找到。

当单元格矩阵被应用于一个矢量时。

@f{eqnarray*}
A_\mathrm{cell}\cdot u_\mathrm{cell} = B_\mathrm{cell}^T
D_\mathrm{cell} B_\mathrm{cell} \cdot u_\mathrm{cell},


@f}

这样就不会形成矩阵-矩阵乘积，而是每次用一个矩阵与一个矢量从右到左相乘，这样就只形成三个连续的矩阵-矢量乘积。这种方法去掉了局部矩阵计算中的三个嵌套循环，从而将一个单元格的工作复杂度从类似 $\mathcal
{O}(\mathrm{dofs\_per\_cell}^3)$ 降低到 $\mathcal
{O}(\mathrm{dofs\_per\_cell}^2)$  。对这种算法的解释是，我们首先将本地DoF上的值向量转换为正交点上的梯度向量。在第二个循环中，我们把这些梯度乘以积分权重和系数。第三次循环应用第二个梯度（转置形式），这样我们就得到了单元斗室上的（拉普拉斯）值矢量。

上述代码的瓶颈是对每一个 FEValues::reinit 的调用所做的操作，其花费的时间和其他步骤加起来差不多（至少如果网格是非结构化的；deal.II可以识别结构化网格上的梯度往往是不变的）。这当然不理想，我们希望能做得更好。reinit函数所做的是计算实空间的梯度，使用从实空间到参考单元的转换的Jacobian来转换参考单元上的梯度。这是为单元格上的每个基函数和每个正交点进行的。雅各布系数并不取决于基函数，但它在不同的正交点上通常是不同的。如果你只建立一次矩阵，就像我们在以前所有的教程程序中所做的那样，没有什么需要优化的，因为 FEValues::reinit 需要在每个单元上调用。在这个过程中，转换是在计算局部矩阵元素时应用的。

然而，在一个无矩阵的实现中，我们会经常计算这些积分，因为迭代求解器在求解过程中会多次应用矩阵。因此，我们需要考虑是否可以缓存一些在运算器应用中被重用的数据，也就是积分计算。另一方面，我们意识到我们不能缓存太多的数据，否则我们又回到了内存访问成为主导因素的情况。因此，我们不会在矩阵<i>B</i>中存储转换后的梯度，因为一般来说，对于曲线网格的每个基函数和每个元素上的正交点，它们都是不同的。

诀窍是去掉雅各布变换的因素，首先只在参考单元上应用梯度。这个操作将本地道夫上的值向量插值到正交点上的（单位坐标）梯度向量。在这里，我们首先应用我们从梯度中分解出来的雅各布，然后应用正交点的权重，最后应用转置的雅各布来准备第三个循环，通过单元格上的梯度测试并对正交点求和。

让我们再次用矩阵的方式来写。让矩阵<i>B</i><sub>cell</sub>表示与单元有关的梯度矩阵，每一行包含正交点上的值。它由矩阵与矩阵的乘积构成@f{eqnarray*} B_\mathrm{cell} =
J_\mathrm{cell}^{-\mathrm T} B_\mathrm{ref\_cell}, @f}，其中<i>B</i><sub>ref_cell</sub>表示参考单元的梯度，<i>J</i><sup>-T</sup><sub>cell</sub>表示从单位到实数单元的变换的反转置Jacobian（在变换的语言中，由<i>J</i><sup>-T</sup><sub>cell</sub>表示协变变换的操作）。<i>J</i><sup>-T</sup><sub>cell</sub>是块对角线的，块的大小等于问题的维度。每个对角线块都是雅各布变换，从参考单元到实际单元。

把事情放在一起，我们发现

@f{eqnarray*}
A_\mathrm{cell} = B_\mathrm{cell}^T D B_\mathrm{cell}
                = B_\mathrm{ref\_cell}^T J_\mathrm{cell}^{-1}
                  D_\mathrm{cell}
                  J_\mathrm{cell}^{-\mathrm T} B_\mathrm{ref\_cell},


@f}

所以我们要计算积（从右边开始计算局部积）。

@f{eqnarray*}
v_\mathrm{cell} = B_\mathrm{ref\_cell}^T J_\mathrm{cell}^{-1} D J_\mathrm{cell}^{-\mathrm T}
B_\mathrm{ref\_cell} u_\mathrm{cell}, \quad
v = \sum_{\mathrm{cell}=1}^{\mathrm{n\_cells}} P_\mathrm{cell,{loc-glob}}^T
v_\mathrm{cell}.


@f}



@code
  FEValues<dim> fe_values_reference (fe, quadrature_formula,
                                     update_gradients);
  Triangulation<dim> reference_cell;
  GridGenerator::hyper_cube(reference_cell, 0., 1.);
  fe_values_reference.reinit (reference_cell.begin());


  FEValues<dim> fe_values (fe, quadrature_formula,
                           update_inverse_jacobians | update_JxW_values |
                           update_quadrature_points);


  for (const auto & cell : dof_handler.active_cell_iterators())
    {
      fe_values.reinit (cell);
      coefficient.value_list(fe_values.get_quadrature_points(),
                             coefficient_values);


      cell->get_dof_indices (local_dof_indices);


      for (unsigned int i=0; i<dofs_per_cell; ++i)
        cell_src(i) = src(local_dof_indices(i));


      temp_vector = 0;
      for (unsigned int q=0; q<n_q_points; ++q)
        for (unsigned int d=0; d<dim; ++d)
          for (unsigned int i=0; i<dofs_per_cell; ++i)
            temp_vector(q*dim+d) +=
              fe_values_reference.shape_grad(i,q)[d] * cell_src(i);


      for (unsigned int q=0; q<n_q_points; ++q)
        {
          // apply the transposed inverse Jacobian of the mapping
          Tensor<1,dim> temp;
          for (unsigned int d=0; d<dim; ++d)
            temp[d] = temp_vector(q*dim+d);
          for (unsigned int d=0; d<dim; ++d)
            {
              double sum = 0;
              for (unsigned int e=0; e<dim; ++e)
                sum += fe_values.inverse_jacobian(q)[e][d] *
                               temp[e];
              temp_vector(q*dim+d) = sum;
            }


          // multiply by coefficient and integration weight
          for (unsigned int d=0; d<dim; ++d)
            temp_vector(q*dim+d) *= fe_values.JxW(q) * coefficient_values[q];


          // apply the inverse Jacobian of the mapping
          for (unsigned int d=0; d<dim; ++d)
            temp[d] = temp_vector(q*dim+d);
          for (unsigned int d=0; d<dim; ++d)
            {
              double sum = 0;
              for (unsigned int e=0; e<dim; ++e)
                sum += fe_values.inverse_jacobian(q)[d][e] *
                       temp[e];
              temp_vector(q*dim+d) = sum;
            }
        }


      cell_dst = 0;
      for (unsigned int i=0; i<dofs_per_cell; ++i)
        for (unsigned int q=0; q<n_q_points; ++q)
          for (unsigned int d=0; d<dim; ++d)
            cell_dst(i) += fe_values_reference.shape_grad(i,q)[d] *
                                   temp_vector(q*dim+d);


      for (unsigned int i=0; i<dofs_per_cell; ++i)
        dst(local_dof_indices(i)) += cell_dst(i);
    }
}
@endcode



注意我们如何为参考单元梯度创建一个额外的FEValues对象，以及如何将其初始化为参考单元。然后，实际的导数数据是由反的、转置的Jacobian（deal.II将Jacobian矩阵从实单元到单位单元称为inverse_jacobian，因为正向转换是从单位单元到实单元）应用的。因子 $J_\mathrm{cell}^{-1} D_\mathrm{cell} J_\mathrm{cell}^{-\mathrm T}$ 是块对角线超过正交的。在这种形式下，人们意识到可变系数（可能通过张量表示）和一般网格拓扑结构的雅各布变换对变换单元格导数的系数有类似的影响。

在这一点上，人们可能会想，为什么我们要分别存储矩阵 $J_\mathrm{cell}^{-\mathrm T}$ 和系数，而不是只存储完整的因子 $J_\mathrm{cell}^{-1} D_\mathrm{cell}
J_\mathrm{cell}^{-\mathrm T}$  。后者会使用更少的内存，因为张量是对称的，在三维中具有六个独立的值，而对于前者，我们需要九个条目用于反转雅各布系数，一个用于正交权重和雅各布行列式，一个用于系数，总共是11个双数。原因是前者允许通过一个共同的缓存数据框架来实现通用的微分算子，而后者则专门存储拉普拉斯的系数。如果应用需要，这种专门化可能会得到回报，值得考虑。请注意，deal.II中的实现足够聪明，可以检测笛卡尔或仿生几何，其中雅各布系数在整个单元中是恒定的，不需要为每个单元存储（实际上在不同的单元中也常常是相同的）。

从操作数的角度来看，最后的优化是利用基函数中的张量积结构，这是最为关键的。这是可能的，因为我们已经从<i>B</i><sub>ref_cell</sub>描述的参考单元操作中剔除了梯度，即对参考单元的完全规则的数据域进行插值操作。我们举例说明在两个空间维度上降低复杂度的过程，但是同样的技术也可以用在更高的维度上。在参考单元上，基函数是张量积形式的  $\phi(x,y,z) = \varphi_i(x) \varphi_j(y)$  。矩阵<i>B</i><sub>ref_cell</sub>计算第一分量的部分具有 $B_\mathrm{sub\_cell}^x = B_\mathrm{grad,x} \otimes B_\mathrm{val,y}$ 的形式，其中<i>B</i><sub>grad,x</sub>和<i>B</i><sub>val,y</sub>包含所有一维正交点上所有一维基函数的评价。用含有属于基函数 $\varphi_i(x) \varphi_j(y)$ 的系数的<i>U</i>组成矩阵<i>U(j,i)</i>，我们得到 $(B_\mathrm{grad,x} \otimes
B_\mathrm{val,y})u_\mathrm{cell} = B_\mathrm{val,y} U B_\mathrm{grad,x}$ 。这就把计算这个乘积的复杂度从 $p^4$ 降低到 $2 p^3$ ，其中<i>p</i>-1是有限元的度数（即，等价地，<i>p</i>是每个坐标方向上的形状函数的数量），或者一般来说 $p^{2d}$ 到 $d p^{d+1}$ 。我们之所以用多项式度数来看复杂度，是因为我们希望能够到高度数，可能会增加多项式度数<i>p</i>而不是网格分辨率。像这里使用的中等度数的好算法是独立于维度的多项式度数的线性算法，而不是基于矩阵的方案或通过FEValues的天真评价。在deal.II的实现中所使用的技术自20世纪80年代以来就已经在谱元界建立起来。

实现一个无矩阵和基于单元的有限元算子，与以前的教程程序中显示的通常的矩阵装配代码相比，需要一个有点不同的程序设计。做到这一点的数据结构是MatrixFree类和FEEvaluation类，前者收集所有数据并在所有单元上发出一个（并行）循环，后者利用张量积结构评估有限元基函数。

本教程中展示的无矩阵的矩阵-向量乘积的实现比使用稀疏矩阵的线性元素的矩阵-向量乘积要慢，但由于张量乘积结构降低了复杂度，并且在计算过程中减少了内存传输，所以对所有高阶元素来说速度更快。当在一个多核处理器上工作时，减少内存传输的影响特别有利，因为在这个处理器上有几个处理单元共享内存的访问。在这种情况下，一个受计算约束的算法将显示出几乎完美的并行加速（除了可能通过涡轮模式改变处理器的时钟频率，这取决于有多少个核心在工作），而一个受内存传输约束的算法可能无法实现类似的加速（即使工作是完全并行的，我们可以期待像稀疏矩阵-向量产品那样的完美缩放）。这种实现方式的另一个好处是，我们不必建立稀疏矩阵本身，这也可能是相当昂贵的，这取决于基础微分方程。此外，上述框架可以简单地推广到非线性运算，正如我们在步骤48中所展示的那样。




<h3>Combination with multigrid</h3>

上面，我们花了很大的力气来实现一个不实际存储矩阵元素的矩阵-向量积。然而，在许多用户代码中，人们想要的不仅仅是做一些矩阵-向量乘积&mdash；在求解线性系统时，人们希望尽可能少做这些操作。理论上，我们可以使用CG方法，而不需要预处理；然而，这对拉普拉斯的效率并不高。相反，预调节器是用来提高收敛速度的。不幸的是，大多数比较常用的预处理方法，如SSOR、ILU或代数多网格（AMG）不能在这里使用，因为它们的实现需要了解系统矩阵的元素。

一个解决方案是使用几何多网格方法，如步骤16所示。众所周知，它们的速度非常快，而且适合我们的目的，因为所有的成分，包括不同网格层之间的转移，都可以用与单元格集合相关的矩阵-向量产品来表示。我们需要做的就是找到一个基于矩阵-向量乘积而不是所有矩阵条目的平滑器。一个这样的候选方法是阻尼雅可比迭代，它需要访问矩阵对角线，但它在阻尼所有高频误差方面往往不够好。雅可比方法的特性可以通过所谓的切比雪夫迭代进行几次改进。切比雪夫迭代由矩阵-向量乘积的多项式表达式描述，其中的系数可以被选择来实现某些特性，在这种情况下，可以平滑误差的高频成分，这些误差与雅可比预处理矩阵的特征值相关。在零度时，具有最佳阻尼参数的雅可比方法被检索出来，而高阶修正被用来改善平滑特性。切比雪夫平滑法在多网格中的有效性已经被证明，例如在文章<a href="http://www.sciencedirect.com/science/article/pii/S0021999103001943">
<i>M. Adams, M. Brezina, J. Hu, R. Tuminaro. Parallel multigrid smoothers:
polynomial versus Gauss&ndash;Seidel, J. Comput. Phys. 188:593&ndash;610,
2003</i><i>M. Adams, M. Brezina, J. Hu, R. Tuminaro. Parallel multigrid smoothers:
polynomial versus Gauss&ndash;Seidel, J. Comput. Phys. 188:593&ndash;610,
2003</i></a>中。这篇文章还指出了我们在这里利用的切比雪夫平滑器的另一个优势，即它们很容易并行化，而SOR/Gauss&ndash;Seidel平滑依赖于替换，对于这种替换，天真的并行化在矩阵的对角线子块上工作，从而降低了效率（更多细节见例如Y. Saad, Iterative Methods for Sparse Linear Systems, SIAM, 2nd edition, 2003, chapters 11 & 12）。

然后，在多网格框架中的实现就很简单了。本程序中的多网格实现与step-16类似，包括自适应性。




<h3>Using CPU-dependent instructions (vectorization)</h3>

FEEvaluation中的计算内核是以优化使用计算资源的方式来编写的。为了达到这个目的，他们不对双倍数据类型进行操作，而是对我们称之为VectorizedArray的东西进行操作（例如，查看 FEEvaluationBase::get_value, 的返回类型，对于标量元素是VectorizedArray，对于矢量有限元素是Tensor of VectorizedArray）。VectorizedArray是一个双数或浮点数的短阵列，其长度取决于使用的特定计算机系统。例如，基于x86-64的系统支持流式SIMD扩展（SSE），处理器的矢量单元可以通过一条CPU指令处理两个双数（或四个单精度浮点数）。较新的处理器（大约从2012年起）支持所谓的高级向量扩展（AVX），有256位操作数，可以分别使用四个双数和八个浮点数。矢量化是一个单指令/多数据（SIMD）的概念，也就是说，一条CPU指令被用来同时处理多个数据值。通常情况下，有限元程序不会明确使用矢量化，因为这个概念的好处只体现在算术密集型操作中。大部分典型的有限元工作负载都受到内存带宽的限制（对稀疏矩阵和向量的操作），在这种情况下，额外的计算能力是无用的。

不过，在幕后，优化的BLAS包可能严重依赖矢量化。另外，优化的编译器可能会自动将涉及标准代码的循环转化为更有效的矢量化形式（deal.II在矢量更新的常规循环中使用OpenMP SIMD pragmas）。然而，数据流必须非常有规律，才能让编译器产生高效的代码。例如，受益于矢量化的原型操作（矩阵-矩阵乘积）的自动矢量化在大多数编译器上都失败了（截至2012年初编写本教程并在2016年底更新时，gcc和英特尔编译器都无法为 FullMatrix::mmult 函数，甚至在更简单的情况下也不行，即矩阵边界是编译时常量而不是 FullMatrix::mmult). 中的运行时常量。此外，有可能被一起处理的数据可能没有以连续的方式布置在内存中，或者没有对处理器需要的地址边界进行必要的对齐。或者编译器可能无法证明数据阵列在一次加载几个元素时不会重叠。

因此，在deal.II的无矩阵实现中，我们选择在最适合于有限元计算的层次上应用矢量化。所有单元的计算通常是完全相同的（除了从向量读写时使用的间接寻址中的索引），因此SIMD可以用来一次处理几个单元。在下面的所有内容中，你可以考虑用一个向量数组来保存几个单元的数据。记住，它与空间维度和元素数量无关，例如在Tensor或Point中。

请注意，矢量化取决于代码运行的CPU，以及代码的编译对象。为了给你的计算机生成最快的FEEvaluation内核，你应该用所谓的<i>native</i>处理器变体编译deal.II。当使用gcc编译器时，可以通过在cmake构建设置中设置变量<tt>CMAKE_CXX_FLAGS</tt>为<tt>"-march=native"</tt>来启用它（在命令行中，指定<tt>-DCMAKE_CXX_FLAGS="-march=native"</tt>，更多信息见deal.II阅读手册）。其他编译器也有类似的选项。我们在本例的run()函数中输出当前的矢量化长度。




<h3>Running multigrid on large-scale parallel computers</h3>

如上所述，无矩阵框架中的所有组件都可以通过MPI使用领域分解轻松实现并行化。由于在deal.II中通过p4est（详见step-40）可以很容易地访问大规模的并行网格，而且基于单元格的循环与无矩阵评估<i>only</i>需要在每个处理器上将网格分解成大小基本相同的块，因此编写一个使用分布式内存工作的并行程序所需的工作相对较少。虽然其他使用MPI的教程程序依赖于PETSc或Trilinos，但这个程序使用deal.II自己的并行向量设施。

deal.II并行向量类， LinearAlgebra::distributed::Vector, 持有解决方案的处理器本地部分以及重影自由度的数据字段，即由远程处理器拥有的自由度，但由当前处理器拥有的单元访问。在 @ref GlossLocallyActiveDof "术语表 "中，这些自由度被称为本地活动自由度。函数 MatrixFree::initialize_dof_vector() 提供了一个设置这种设计的方法。请注意，悬挂节点可以与额外的重影自由度有关，这些自由度必须包括在分布式矢量中，但不属于 @ref
GlossLocallyActiveDof "词汇表 "意义上的本地活动自由度。此外，分布式向量持有本地拥有但其他处理器需要的DoF的MPI元数据。这个向量类设计的一个好处是对重影项的访问方式。在向量的存储方案中，数据阵列延伸到解决方案的处理器本地部分之外，有更多的向量条目可用于重影自由度。这为所有本地活动自由度提供了一个连续的索引范围。(注意，索引范围取决于网格的具体配置。)由于无矩阵操作可以被认为是在做性能关键的线性代数，而性能关键的代码不能把时间浪费在做MPI全局到MPI局部的索引转换上，一个MPI等级的局部索引空间的可用性是很重要的。这里访问事物的方式是直接数组访问。这是通过 LinearAlgebra::distributed::Vector::local_element(), 提供的，但实际上很少需要，因为所有这些都发生在FEEvaluation的内部。

 LinearAlgebra::distributed::Vector 的设计与我们之前在step-40和step-32中使用的 PETScWrappers::MPI::Vector 和 TrilinosWrappers::MPI::Vector 数据类型类似，但由于我们不需要这些库的其他并行功能，所以我们使用deal.II的 LinearAlgebra::distributed::Vector 类来代替在本教程程序中链接另一个大型库。还要注意的是，PETSc和Trilinos向量不提供对直接数组访问的幽灵条目的细粒度控制，因为它们抽象出了必要的实现细节。


