examples/step-6/doc/intro.dox

<a name="Intro"></a>

<h1>Introduction</h1>

 @dealiiVideoLecture{15,16,17,17.25,17.5,17.75} 

这个程序最后是关于deal.II的主要特征之一：使用自适应（局部）细化网格。这个程序仍然是基于步骤4和步骤5的，而且，正如你将看到的，实际上不需要花太多的代码来实现自适应性。事实上，虽然我们做了大量的解释，但自适应网格可以被添加到一个现有的程序中，几乎不需要十几行额外的代码。该程序显示了这些行是什么，以及自适应网格细化（AMR）的另一个重要成分：一个标准，可以用来确定是否有必要细化一个单元，因为它上面的误差很大，是否可以粗化这个单元，因为它上面的误差特别小，或者我们是否应该让这个单元保持原样。我们将在下文中讨论所有这些问题。




<h3> What adaptively refined meshes look like </h3>

有许多方法可以自适应地细化网格。整个算法的基本结构总是相同的，由以下步骤的循环组成。

- 在当前网格上求解PDE。

- 用一些能说明误差的标准来估计每个单元格的误差。

- 把那些误差大的单元格标记为细化，把那些误差特别小的单元格标记为粗化，其余的就不用管了。

- 细化和粗化如此标记的单元，得到一个新的网格。

- 在新的网格上重复上述步骤，直到整体误差足够小。

由于一些可能被历史遗忘的原因（也许是这些函数过去是用FORTRAN语言实现的，这种语言并不关心某个东西是用小写字母还是大写字母拼写的，程序员经常习惯性地选择大写字母），上述循环在关于网格适应性的出版物中经常被称为SOLVE-ESTIMATE-MARK-REFINE循环（用这种拼法）。

然而，在这个结构之外，有多种方法可以实现这一点。从根本上说，它们的区别在于究竟如何从前一个网格中生成一个网格。

如果要使用三角形（deal.II没有这样做），那么就有两种基本的可能性。

- 最长边细化。在这个策略中，通过从最长边的中点到对面的顶点引入一条新的边，将一个标记为细化的三角形切成两段。当然，来自最长边的中点必须以某种方式通过*也*完善该边另一侧的单元格（如果有的话）来平衡。如果有问题的边也是相邻单元的最长边，那么我们可以直接运行一条新的边穿过相邻单元到对面的顶点；否则就需要一个稍微复杂的结构，在相邻单元的至少一条其他边上增加更多的新顶点，然后可能传播到相邻单元的邻居，直到算法终止。这很难用语言描述，而且因为deal.II不使用三角形，不值得在这里花时间。   但如果你很好奇，你可以随时在本介绍顶部显示的链接中观看视频讲座15。

- 红-绿细化。另一个选择是所谓的 "红绿细化"。   这种策略甚至更难描述（但在视频讲座中也讨论过），其优点是细化不会传播到我们想要细化的单元的近邻之外。然而，它的实施难度要大得多。

这些方法还有其他的变化，但重要的一点是，它们总是产生一个网格，其中两个单元的接触线是两个相邻单元的整个边缘。只要稍加努力，这种策略就可以很容易地适用于由四面体构成的三维网格。

这两种方法对2D的四边形和3D的六面体都不起作用，或者至少不容易。原因是要精化的四边形单元的四边形邻居所产生的过渡元素将是三角形，而我们不希望这样。因此，在deal.II中选择的适应性方法是使用网格，其中相邻的单元在细化水平上可能相差一个。这就导致在单元的界面上出现属于一方的节点，但在另一方是不平衡的。这些节点的通用术语是&ldquo;悬挂节点&rdquo;，这些网格在非常简单的情况下看起来是这样的。

 @image html hanging_nodes.png "A simple mesh with hanging nodes" 

一个更复杂的二维网格看起来是这样的（并在下面的 "结果 "部分讨论）。

<img src="https://www.dealii.org/images/steps/developer/step_6_grid_5_ladutenko.svg" alt="第五个自适应细化的拉杜腾科网格：单元格沿着内圈聚拢。" width="300" height="300">

最后，这里展示了一个具有这种悬挂节点的三维网格（来自步骤-43）。

<img src="https://www.dealii.org/images/steps/developer/step-43.3d.mesh.png" alt="" width="300" height="300">

第一个和第三个网格当然是基于一个正方形和一个立方体，但正如第二个网格所显示的，这不是必要的。重要的一点是，我们可以独立于其邻居来细化一个网格（受制于一个单元只能比其邻居多细化一次的约束），但如果我们这样做，最终会出现这些&ldquo;悬空节点&rdquo;。




<h3> Why adapatively refined meshes? </h3>

现在你已经看到了这些自适应细化网格的样子，你应该问<i>why</i>我们为什么要这样做。毕竟，我们从理论上知道，如果我们对网格进行全局细化，误差会下降到零，因为

@f{align*}{
  \|\nabla(u-u_h)\|_{\Omega} \le C h_\text{max}^p \| \nabla^{p+1} u \|_{\Omega},


@f}

其中 $C$ 是独立于 $h$ 和 $u$ 的一些常数， $p$ 是使用中的有限元的多项式程度， $h_\text{max}$ 是最大单元的直径。那么，如果<i>largest</i>单元很重要，那么为什么我们要在域的某些部分将网格做得很细，而不是全部？

答案在于观察到上面的公式不是最佳的。事实上，一些更多的工作表明，以下是一个更好的估计（你应该与上述估计的平方进行比较）。

@f{align*}{
  \|\nabla(u-u_h)\|_{\Omega}^2 \le C \sum_K h_K^{2p} \| \nabla^{p+1} u \|^2_K.


@f}

(因为 $h_K\le h_\text{max}$ ，如果你只是把网格大小从总和中拉出来，这个公式立即暗示了前一个公式)。这个公式所暗示的是，没有必要把<i>largest</i>单元格做得很小，而单元格真正只需要做小的<i>where $\| \nabla^{p+1} u \|_K$ is large</i>!换句话说。网格实际上只需要在解有较大变化的地方做得很细，正如 $p+1$ st导数所表明的。这是有直观意义的：例如，如果我们使用一个线性元素 $p=1$ ，那么即使网格很粗，那些解几乎是线性的地方（如 $\nabla^2 u$ 所示的小地方）也会被很好地解决。只有那些二阶导数大的地方才会被大元素解决得很差，因此我们应该把网格做得很小。

当然，这个<i>a priori estimate</i>在实践中不是很有用，因为我们不知道问题的精确解 $u$ ，因此，我们不能计算 $\nabla^{p+1}u$  。但是，这也是通常采取的方法，我们可以只根据之前计算的离散解 $u_h$ 来计算 $\nabla^{p+1}u$ 的数值近似值。我们将在下面稍微详细地讨论这个问题。这将有助于我们确定哪些单元具有较大的 $p+1$ st导数，然后这些单元将成为细化网格的候选单元。




<h3> How to deal with hanging nodes in theory </h3>

上面提到的使用三角形网格的方法，都是为了确保每个顶点都是所有相邻单元的顶点--也就是说，没有悬空节点。这就自动确保了我们能够以这样的方式定义形状函数，即它们是全局连续的（如果我们使用到目前为止在教程程序中一直使用的常见的 $Q_p$ 拉格朗日有限元方法，如FE_Q类所代表的）。

另一方面，如果我们在有悬挂节点的网格上定义形状函数，我们最终可能得到不连续的形状函数。要看到这一点，请想一下上面的情况，即右上角的单元没有被细化，并考虑一下使用双线性有限元的情况。在这种情况下，与悬挂节点相关的形状函数是以明显的方式定义在与每个悬挂节点相邻的两个小单元上。但我们如何将它们扩展到相邻的大单元呢？显然，函数对大单元的扩展不能是双线性的，因为那样的话，它需要沿着大单元的每条边线性化，这意味着它在整条边上需要为零，因为它需要在大单元的两个顶点上为零。但从小单元一侧看，它在悬挂节点本身并不是零--所以它不是连续的。下面三幅图显示了沿着有关边缘的三个形状函数，当以通常的方式简单地根据它们相邻的单元格来定义时，这些形状函数变成了不连续的。

<div class="threecolumn" style="width: 80%"> <div class="parent"> <div class="img" align="center">  @image html hanging_nodes_shape_functions_1.png "A discontinuous shape function adjacent to a hanging node"  </div> </div> <div class="parent"> <div class="img" align="center">  @image html hanging_nodes_shape_functions_2.png "A discontinuous shape function at a hanging node"  </div> </div> <div class="parent"> <div class="img" align="center">  @image html hanging_nodes_shape_functions_3.png "A discontinuous shape function adjacent to a hanging node"  </div> </div></div>


但我们确实希望有限元解是连续的，这样我们就有了&ldquo;符合要求的有限元方法&rdquo;，其中离散有限元空间是我们寻求拉普拉斯方程解的 $H^1$ 函数空间的一个适当子集。为了保证全局解在这些节点上也是连续的，我们必须对这些节点上的解的值提出一些额外的约束。诀窍是要认识到，虽然上面显示的形状函数是不连续的（因此它们的<i>arbitrary</i>线性组合也是不连续的），但形状函数加起来为 $u_h(\mathbf x)=\sum_j U_j \varphi_j(\mathbf x)$ 的线性组合可以是连续的<i>if the coefficients $U_j$ satisfy certain relationships</i>。换句话说，系数 $U_j$ 不能任意选择，而必须满足某些约束条件，这样，函数 $u_h$ 实际上是连续的。这些约束条件在概念上相对容易理解，但在软件中的实现却很复杂，需要几千行的代码。另一方面，在用户代码中，在处理挂起的节点时，你只需要添加大约半打的行。

在下面的程序中，我们将展示如何从deal.II中获得这些约束，以及如何在线性方程组的求解中使用它们。在了解下面程序的细节之前，你可能想看看 @ref constraints 文件模块，它解释了这些约束如何计算以及deal.II中哪些类对它们起作用。




<h3> How to deal with hanging nodes in practice </h3>

悬挂节点约束的实践比我们上面概述的理论更简单。实际上，你只需要在step-4这样的程序中增加半打额外的代码，就可以使它在有悬挂节点的自适应网格中工作。有趣的是，这与你要解决的方程完全无关。这些约束的代数性质与方程无关，只取决于对有限元的选择。因此，处理这些约束的代码完全包含在deal.II库本身，你不需要担心细节问题。

你需要使其发挥作用的步骤基本上是这样的。

- 你必须创建一个AffineConstraints对象，（顾名思义）它将存储有限元空间的所有约束。在目前的情况下，这些约束是由于我们希望保持解空间的连续，甚至在有悬空节点的情况下。(下面我们还将简要地提到，我们还将把边界值放到这个对象中，但这是一个单独的问题)。

- 你必须使用函数 DoFTools::make_hanging_node_constraints() 来填充这个对象，以确保有限元空间的元素的连续性。

- 当你通过使用 AffineConstraints::distribute_local_to_global(). 将矩阵和右手边的局部贡献复制到全局对象时，你必须使用这个对象。 到目前为止，我们已经自己完成了这个工作，但现在有了约束，这就是神奇的地方，我们将约束应用到线性系统中。这个函数所做的是确保位于悬空节点的自由度事实上不是真正的自由。相反，通过将它们的行和列设置为零，并在对角线上放置一些东西以确保矩阵保持可反转，它们实际上被从线性系统中消除了。   对于我们在这里解决的拉普拉斯方程来说，这个过程产生的矩阵仍然是对称和正定的，所以我们可以继续使用共轭梯度法来解决。

- 然后你像往常一样求解线性系统，但在这一步结束时，你需要确保位于悬挂节点上的 "自由度 "得到正确的（约束的）值，这样你随后可视化的或以其他方式评估的解决方案实际上是连续的。这可以通过在求解后立即调用 AffineConstraints::distribute() 来实现。

这四个步骤实际上是所有必要的--从用户的角度来看就是这么简单。事实上，在上面提到的函数调用中，你将运行几千行并不复杂的代码，这一点完全不重要。在用户代码中，实际上只有四个额外的步骤。




<h3> How we obtain locally refined meshes </h3>

下一个问题是，既然我们知道如何<i>deal</i>处理有这些悬挂节点的网格，那么我们如何<i>obtain</i>它们。

一个简单的方法已经在步骤1中展示过了：如果你<i>know</i>哪里需要细化网格，那么你可以手工创建一个。但是在现实中，我们并不知道这些。我们不知道PDE的解在前面（因为，如果我们知道，我们就不必使用有限元方法），因此，我们不知道哪里需要增加局部网格细化来更好地解决解有强烈变化的区域。但是上面的讨论表明，也许我们可以用一个网格上的离散解 $u_h$ 来估计导数 $\nabla^{p+1} u$ ，然后用这个来确定哪些单元太大，哪些已经足够小。然后，我们可以使用局部网格细化技术从当前的网格中生成一个新的网格。如果有必要，这个步骤会重复进行，直到我们对我们的数值解决方案感到满意--或者，更常见的是，直到我们耗尽了计算资源或耐心。

所以这正是我们要做的。局部细化网格是使用一个<i>error estimator</i>产生的，它可以估计拉普拉斯算子的数值解的能量误差。由于它是由Kelly和他的同事开发的，我们经常在库、文档和邮件列表中把它称为&ldquo;Kelly细化指标&rdquo;。实现它的类被称为KellyErrorEstimator，在该类的文档中可以找到大量的信息，这里不需要重复。然而，总结起来就是，该类计算出一个具有与 @ref GlossActive "活动单元 "一样多的条目的向量，其中每个条目包含对该单元的误差估计。这个估计值然后被用来细化网格的单元：那些有大误差的单元将被标记为细化，那些有特别小估计值的单元将被标记为粗化。我们不需要用手去做这些。一旦我们获得了误差估计矢量，命名空间GridRefinement中的函数将为我们完成这一切。

值得注意的是，虽然Kelly误差估计器是为拉普拉斯方程开发的，但它已被证明是为广泛的方程生成局部细化网格的合适工具，甚至不限于只针对椭圆问题。尽管它对其他方程会产生非最优网格，但它往往是快速产生网格的好方法，能很好地适应解的特征，如大变化区域或不连续性。




<h3> Boundary conditions </h3>

事实证明，人们可以把迪里希特边界条件看作是对自由度的另一种约束。这的确是一个特别简单的约束。如果 $j$ 是边界上的一个自由度，其位置为 $\mathbf x_j$ ，那么在 $\partial\Omega$ 上施加边界条件 $u=g$ 就会产生约束 $U_j=g({\mathbf x}_j)$  。

AffineConstraints类也可以处理这样的约束，这使得我们可以方便地让我们用于悬挂节点约束的同一个对象也处理这些Dirichlet边界条件。这样一来，我们就不需要在装配后应用边界条件（就像我们在前面的步骤中做的那样）。所有需要的是我们调用 VectorTools::interpolate_boundary_values() 的变体，该变体在AffineConstraints对象中返回其信息，而不是我们在以前的教程程序中使用的 `std::map` 。


<h3> Other things this program shows </h3>


由于用于局部细化网格的概念非常重要，我们在这个例子中没有展示很多其他材料。最重要的例外是，我们展示了如何使用双二次元而不是之前所有例子中使用的双线性元素。事实上，使用高阶元素只需替换程序中的三行，即在本程序主类的构造函数中初始化 <code>fe</code> 成员变量，以及在两个地方使用适当的正交公式。程序的其他部分没有变化。

其他唯一的新东西是在 <code>main</code> 函数中捕捉异常的方法，以便在程序因某种原因崩溃时输出一些信息。下面将详细讨论这个问题。


