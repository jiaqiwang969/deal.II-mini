examples/step-76/doc/intro.dox



 <br> 

<i>
This program was contributed by Martin Kronbichler, Peter Munch, and David
Schneider. Many of the features shown here have been added to deal.II during
and for the development of the deal.II-based, efficient, matrix-free
finite-element library for high-dimensional partial differential equations
hyper.deal (see https://github.com/hyperdeal/hyperdeal). For more details and
for applications of the presented features in slightly different contexts
(high-dimensional advection equation and Vlasov-Poisson equations) see the release
paper @cite munch2020hyperdeal.


This work was partly supported by the German Research Foundation (DFG) through
the project "High-order discontinuous Galerkin for the exa-scale" (ExaDG)
within the priority program "Software for Exascale Computing" (SPPEXA) and
by the Bavarian government through the project "High-order matrix-free finite
element implementations with hybrid parallelization and improved data locality"
within the KONWIHR program.
</i>

<a name="Intro"></a>

<h1>Introduction</h1>

本教程程序求解流体力学的欧拉方程，使用显式时间积分器和无矩阵框架应用于空间的高阶非连续Galerkin离散化。这里使用的数值方法与step-67中使用的相同，但是，我们利用不同的高级MatrixFree技术来达到更高的吞吐量。

本教程的两个主要特点是。

- 使用MPI-3.0中的共享内存特性和

- 使用以单元为中心的循环，它只允许向全局向量写入一次，因此，是使用共享内存的理想选择。

我们在本教程中讨论的其他主题是模板参数VectorizedArrayType的用法和好处（而不是简单地使用VectorizedArray<Number>），以及向MatrixFree循环传递lambdas的可能性。

关于数字的细节，我们参考步骤-67的文件。我们在这里只集中讨论关键的差异。

<h3>Shared-memory and hybrid parallelization with MPI-3.0</h3>

<h4>Motivation</h4>

存在许多基于线程的共享内存库，如TBB、OpenMP或TaskFlow。将这些库集成到现有的MPI程序中，就可以使用共享内存。然而，这些库对程序员来说有一定的开销，因为所有可并行的代码部分都必须根据所使用的库进行查找和转换，包括当一些第三方数值库，如迭代求解器包，只依赖MPI时的困难。

考虑到一个纯粹的MPI并行化的有限元应用，我们可以发现，使用共享内存的主要时间和内存优势来自于访问同一计算节点上的进程所拥有的解决方案矢量的部分，而不需要进行明确的复制和缓冲。因此，MPI-3.0提供了基于所谓窗口的共享内存功能，进程可以直接访问同一共享内存域中的邻居的数据。

<h4>Basic MPI-3.0 commands</h4>

有几个相关的MPI-3.0命令值得详细讨论。一个新的MPI通信器 <code>comm_sm</code>  ，由通信器 <code>comm</code> 的进程组成，这些进程可以访问相同的共享内存，可以通过以下方式创建。

@code
MPI_Comm_split_type(comm, MPI_COMM_TYPE_SHARED, rank, MPI_INFO_NULL, &comm_sm);
@endcode



下面的代码片断显示了共享内存的简化分配例程，包括值类型  <code>T</code>  和大小  <code>local_size</code>  ，以及如何查询属于同一共享内存域的进程的数据指针。

@code
MPI_Win          win;         // window
T *              data_this;   // pointer to locally-owned data
std::vector<T *> data_others; // pointers to shared data


// configure shared memory
MPI_Info info;
MPI_Info_create(&info);
MPI_Info_set(info, "alloc_shared_noncontig", "true");


// allocate shared memory
MPI_Win_allocate_shared(local_size * sizeof(T), sizeof(T), info, comm_sm, &data_this, &win);


// get pointers to the shared data owned by the processes in the same sm domain
data_others.resize(size_sm);
int disp_unit = 0; // displacement size - an output parameter we don't need right now
MPI_Aint ssize = 0; // window size - an output parameter we don't need right now
for (int i = 0; i < size_sm; ++i)
  MPI_Win_shared_query(win, i, &ssize, &disp_unit, &data_others[i]);


Assert(data_this == data_others[rank_sm], ExcMessage("Something went wrong!"));
@endcode



一旦不再需要这些数据，窗口就必须被释放，这也释放了本地拥有的数据。

@code
MPI_Win_free(&win);
@endcode



<h4>MPI-3.0 and LinearAlgebra::distributed::Vector</h4>

上一节提到的命令被整合到了 LinearAlgebra::distributed::Vector 中，如果为reinit()函数提供了可选的（第二个）通信器，那么这些命令就被用来分配共享内存。

例如，可以用一个分区器（包含全局通信器）和一个子通信器（包含同一计算节点上的进程）来设置一个向量。

@code
vec.reinit(partitioner, comm_sm);
@endcode



本地拥有的值和幽灵值可以像往常一样被处理。然而，现在用户也可以通过该函数读取共享内存邻居的值。

@code
const std::vector<ArrayView<const Number>> &
LinearAlgebra::distributed::Vector::shared_vector_data() const;
@endcode



<h4>MPI-3.0 and MatrixFree</h4>

虽然 LinearAlgebra::distributed::Vector 提供了分配共享内存和以协调的方式访问相邻进程的共享内存值的选项，但它实际上并没有利用共享内存的使用本身的好处。

然而，MatrixFree的基础设施确实如此。

- 一方面，在无矩阵循环 MatrixFree::loop(),  MatrixFree::cell_loop(), 和 MatrixFree::loop_cell_centric(), 中，只有需要更新的幽灵值 <em> 被 </em> 更新。来自共享内存邻居的幽灵值可以被直接访问，这使得缓冲，即把值复制到矢量的幽灵区域可能是多余的。   为了处理可能的竞赛条件，在MatrixFree中进行了必要的同步。在数值必须被缓冲的情况下，数值被直接从邻近的共享内存进程中复制，绕过了基于  <code>MPI_ISend</code>  和  <code>MPI_IRecv</code>  的更昂贵的MPI操作。

- 另一方面，像FEEvaluation和FEFaceEvaluation这样的类可以直接从共享内存中读取，所以在某些情况下确实不需要缓冲值。

为了能够使用MatrixFree的共享内存功能，MatrixFree必须通过提供用户创建的子通信器进行适当的配置。

@code
typename MatrixFree<dim, Number>::AdditionalData additional_data;


// set flags as usual (not shown)


additional_data.communicator_sm = comm_sm;


data.reinit(mapping, dof_handler, constraint, quadrature, additional_data);
@endcode






<h3>Cell-centric loops</h3>

<h4>Motivation: FCL vs. CCL</h4>

"以面为中心的循环"（简称FCL）在单独的循环中访问单元和面（内部和边界的）。因此，每个实体只被访问一次，单元之间的通量只被评估一次。如何在 MatrixFree::loop() 的帮助下，通过提供三个函数（一个用于细胞积分，一个用于内部，一个用于边界面）来执行以面为中心的循环，已经在步骤59和步骤67中提出。

与此相反，"以单元为中心的循环"（在hyper.deal发布的论文中简称CCL或ECL（代表以元素为中心的循环），处理一个单元并直接连续处理其所有面（即访问所有面两次）。在文献 @cite KronbichlerKormann2019 中，它们的好处对于现代CPU处理器架构来说已经很清楚了，尽管这种循环意味着通量必须被计算两次（对于内部面的每一面）。CCL有两个主要优点。

- 一方面，在CCL的情况下，解向量中的条目正好被写回主内存一次，而在FCL的情况下，尽管高速缓存有效地调度了单元和面环，但由于高速缓存容量的错过，至少有一次。

- 另一方面，由于解向量的每个条目只被访问一次，在CCL的情况下，访问解向量时不需要线程间的同步。在写入目标向量的过程中不存在竞赛条件，这使得CCL特别适用于共享内存并行化。

我们还应该注意到，尽管在CCL的情况下通量被计算了两次，但这并不自动转化为计算量的翻倍，因为已经内插到单元正交点的值可以用简单的一维内插法内插到一个面上。

<h4>Cell-centric loops and MatrixFree</h4>

对于以单元为中心的循环实现，可以使用函数 MatrixFree::loop_cell_centric() ，用户可以向其传递一个应该在每个单元上执行的函数。

为了得出一个适当的函数，可以在 MatrixFree::loop_cell_centric(), 中传递，原则上可以转换/合并以下三个函数，它们可以传递给 MatrixFree::loop(): 。

@code
matrix_free.template loop<VectorType, VectorType>(
  [&](const auto &data, auto &dst, const auto &src, const auto range) {
    // operation performed on cells


    FEEvaluation<dim, degree, degree + 1, 1, Number> phi(data);
    for (unsigned int cell = range.first; cell < range.second; ++cell)
      {
        phi.reinit(cell);
        phi.gather_evaluate(src, cell_evaluation_flags);


        // some operations on the cell quadrature points


        phi.integrate_scatter(cell_evaluation_flags, dst);
      }
  },
  [&](const auto &data, auto &dst, const auto &src, const auto range) {
    // operation performed inner faces


    FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_m(data, /*is_interior_face=*/true);
    FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_p(data, /*is_interior_face=*/false);


    for (unsigned int face = range.first; face < range.second; ++face)
      {
        phi_m.reinit(face);
        phi_m.gather_evaluate(src, face_evaluation_flags);
        phi_p.reinit(face);
        phi_p.gather_evaluate(src, face_evaluation_flags);


        // some operations on the face quadrature points


        phi_m.integrate_scatter(face_evaluation_flags, dst);
        phi_p.integrate_scatter(face_evaluation_flags, dst);
      }
  },
  [&](const auto &data, auto &dst, const auto &src, const auto range) {
    // operation performed boundary faces


    FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_m(data, /*is_interior_face=*/true);


    for (unsigned int face = range.first; face < range.second; ++face)
      {
        phi_m.reinit(face);
        phi_m.gather_evaluate(src, face_evaluation_flags);


        // some operations on the face quadrature points


        phi_m.integrate_scatter(face_evaluation_flags, dst);
      }
  },
  dst,
  src);
@endcode



以下列方式进行。

@code
matrix_free.template loop_cell_centric<VectorType, VectorType>(
  [&](const auto &data, auto &dst, const auto &src, const auto range) {
    FEEvaluation<dim, degree, degree + 1, 1, Number>     phi(data);
    FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_m(data, /*is_interior_face=*/true);
    FEFaceEvaluation<dim, degree, degree + 1, 1, Number> phi_p(data, /*is_interior_face=*/false);


    for (unsigned int cell = range.first; cell < range.second; ++cell)
      {
        phi.reinit(cell);
        phi.gather_evaluate(src, cell_evaluation_flags);


        // some operations on the cell quadrature points


        phi.integrate_scatter(cell_evaluation_flags, dst);


        // loop over all faces of cell
        for (unsigned int face = 0; face < GeometryInfo<dim>::faces_per_cell; ++face)
          {
            if (data.get_faces_by_cells_boundary_id(cell, face)[0] ==
                numbers::internal_face_boundary_id)
              {
                // internal face
                phi_m.reinit(cell, face);
                phi_m.gather_evaluate(src, face_evaluation_flags);
                phi_p.reinit(cell, face);
                phi_p.gather_evaluate(src, face_evaluation_flags);


                // some operations on the face quadrature points


                phi_m.integrate_scatter(face_evaluation_flags, dst);
              }
            else
              {
                // boundary face
                phi_m.reinit(cell, face);
                phi_m.gather_evaluate(src, face_evaluation_flags);


                // some operations on the face quadrature points


                phi_m.integrate_scatter(face_evaluation_flags, dst);
              }
          }
      }
  },
  dst,
  src);
@endcode



应该注意的是，FEFaceEvaluation现在是用两个数字初始化的，即单元号和本地面孔号。给出的例子只是强调了如何将以面为中心的循环转化为以单元为中心的循环，而且绝非高效，因为数据要从全局向量中多次读写，而且计算也是重复进行的。下面，我们将讨论针对这些问题的高级技术。

为了能够使用 MatrixFree::loop_cell_centric(), ，必须启用 MatrixFree::AdditionalData 的下列标志。

@code
typename MatrixFree<dim, Number>::AdditionalData additional_data;


// set flags as usual (not shown)


additional_data.hold_all_faces_to_owned_cells       = true;
additional_data.mapping_update_flags_faces_by_cells =
  additional_data.mapping_update_flags_inner_faces |
  additional_data.mapping_update_flags_boundary_faces;


data.reinit(mapping, dof_handler, constraint, quadrature, additional_data);
@endcode



特别是，这些标志使内部数据结构能够为所有单元格的面设置。

目前，deal.II中以单元为中心的循环只适用于均匀细化的网格，并且不应用任何约束条件（这是通常使用的DG的标准情况）。




<h3>Providing lambdas to MatrixFree loops</h3>

上面给出的例子已经使用了lambdas，它已经被提供给无矩阵循环。下面的简短例子介绍了如何在使用类和指向其方法之一的指针的版本和利用lambdas的变体之间转换函数。

在下面的代码中，一个类和它的一个方法的指针被传递给了 MatrixFree::loop(): ，这个方法应该被解释为单元格积分。

@code
void
local_apply_cell(const MatrixFree<dim, Number> &              data,
                 VectorType &                                 dst,
                 const VectorType &                           src,
                 const std::pair<unsigned int, unsigned int> &range) const
{
  FEEvaluation<dim, degree, degree + 1, 1, Number> phi(data);
  for (unsigned int cell = range.first; cell < range.second; ++cell)
    {
      phi.reinit(cell);
      phi.gather_evaluate(src, cell_evaluation_flags);


      // some operations on the quadrature points


      phi.integrate_scatter(cell_evaluation_flags, dst);
    }
}
@endcode



@code
matrix_free.cell_loop(&Operator::local_apply_cell, this, dst, src);
@endcode



然而，也可以通过lambda函数传递匿名函数，结果是一样的。

@code
matrix_free.template cell_loop<VectorType, VectorType>(
  [&](const auto &data, auto &dst, const auto &src, const auto range) {
    FEEvaluation<dim, degree, degree + 1, 1, Number> phi(data);
    for (unsigned int cell = range.first; cell < range.second; ++cell)
      {
        phi.reinit(cell);
        phi.gather_evaluate(src, cell_evaluation_flags);


        // some operations on the quadrature points


        phi.integrate_scatter(cell_evaluation_flags, dst);
      }
  },
  dst,
  src);
@endcode



<h3>VectorizedArrayType</h3>

VectorizedArray<Number>类是实现deal.II中无矩阵算法的高节点级性能的一个关键组件。它是一个围绕Number类型的 $n$ 条目的短向量的包装类，并通过内在函数将算术操作映射到适当的单指令/多数据（SIMD）概念。向量的长度可以通过 VectorizedArray::size() 查询，其底层数字类型可以通过 VectorizedArray::value_type. 查询。

在默认情况下（ <code>VectorizedArray<Number></code> ），向量长度在库的编译时被设置为与给定的处理器架构所支持的最高值相匹配。然而，也可以指定第二个可选的模板参数，如 <code>VectorizedArray<Number, size></code>, where <code>size</code> 明确控制特定指令集能力范围内的向量长度。下表列出了支持的向量长度的完整列表。

 <table align="center" class="doxtable">
  <tr>
   <th>double</th>
   <th>float</th>
   <th>ISA</th>
  </tr>
  <tr>
   <td><code>VectorizedArray<double, 1></code></td>
   <td><code>VectorizedArray<float, 1></code></td>
   <td>(auto-vectorization)</td>
  </tr>
  <tr>
   <td><code>VectorizedArray<double, 2></code></td>
   <td><code>VectorizedArray<float, 4></code></td>
   <td>SSE2/AltiVec</td>
  </tr>
  <tr>
   <td><code>VectorizedArray<double, 4></code></td>
   <td><code>VectorizedArray<float, 8></code></td>
   <td>AVX/AVX2</td>
  </tr>
  <tr>
   <td><code>VectorizedArray<double, 8></code></td>
   <td><code>VectorizedArray<float, 16></code></td>
   <td>AVX-512</td>
  </tr>
</table> 

这允许用户选择矢量长度/ISA，因此，在无矩阵算子评估中一次处理的单元数，可能会减少对缓存的压力，这对非常高的度数（和尺寸）来说是一个严重的问题。

减少填充通道数量的另一个可能的原因是为了简化调试：不用看例如8个单元，而是可以集中在一个单元上。

VectorizedArray的接口也能够被任何具有匹配接口的类型所替代。具体来说，这为deal.II准备了 <code>std::simd</code> 类，它计划成为C++23标准的一部分。下表比较了deal.II特定的SIMD类和相应的C++23类。


 <table align="center" class="doxtable">
  <tr>
   <th>VectorizedArray (deal.II)</th>
   <th>std::simd (C++23)</th>
  </tr>
  <tr>
   <td><code>VectorizedArray<Number></code></td>
   <td><code>std::experimental::native_simd<Number></code></td>
  </tr>
  <tr>
   <td><code>VectorizedArray<Number, size></code></td>
   <td><code>std::experimental::fixed_size_simd<Number, size></code></td>
  </tr>
</table> 


