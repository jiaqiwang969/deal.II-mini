//
//
[0.x.0] 
[0.x.1] 
[0.x.2] 
[0.x.3] 
[0.x.4] 
[0.x.5] 
[0.x.6] 
[0.x.7] 
[0.x.8] 
[0.x.9] 
[0.x.10] 
[0.x.11] 
[0.x.12] 
[0.x.13] 
//
[0.x.14] 
//[2.x.0] 
//
// The most fundamental class in the library is the Triangulation class, which is declared here:
//
[0.x.15] 
//
// Here are some functions to generate standard grids:
//
[0.x.16] 
//
// Output of grids in various graphics formats:
//
[0.x.17] 
//
// This is needed for C++ output:
//
[0.x.18] 
[0.x.19] 
//
// And this for the declarations of the  [2.x.1]  and  [2.x.2]  functions:
//
[0.x.20] 
//
// The final step in importing deal.II is this: All deal.II functions and classes are in a namespace  [2.x.3] , to make sure they don't clash with symbols from other libraries you may want to use in conjunction with deal.II. One could use these functions and classes by prefixing every use of these names by  [2.x.4] , but that would quickly become cumbersome and annoying. Rather, we simply import the entire deal.II namespace for general use:
//
[0.x.21] 
//[2.x.5] 
//
// In the following, first function, we simply use the unit square as domain and produce a globally refined grid from it.
//
[0.x.22] 
[0.x.23] 
//
// The first thing to do is to define an object for a triangulation of a two-dimensional domain:
//
[0.x.24] 
//
// Here and in many following cases, the string "<2>" after a class name indicates that this is an object that shall work in two space dimensions. Likewise, there are versions of the triangulation class that are working in one ("<1>") and three ("<3>") space dimensions. The way this works is through some template magic that we will investigate in some more detail in later example programs; there, we will also see how to write programs in an essentially dimension independent way.
//
// Next, we want to fill the triangulation with a single cell for a square domain. The triangulation is the refined four times, to yield  [2.x.6]  cells in total:
//
[0.x.25] 
[0.x.26] 
//
// Now we want to write a graphical representation of the mesh to an output file. The GridOut class of deal.II can do that in a number of different output formats; here, we choose scalable vector graphics (SVG) format that you can visualize using the web browser of your choice:
//
[0.x.27] 
[0.x.28] 
[0.x.29] 
[0.x.30] 
[0.x.31] 
//
//  [2.x.7] 
//
// The grid in the following, second function is slightly more complicated in that we use a ring domain and refine the result once globally.
//
[0.x.32] 
[0.x.33] 
//
// We start again by defining an object for a triangulation of a two-dimensional domain:
//
[0.x.34] 
//
// We then fill it with a ring domain. The center of the ring shall be the point (1,0), and inner and outer radius shall be 0.5 and 1. The number of circumferential cells could be adjusted automatically by this function, but we choose to set it explicitly to 10 as the last argument:
//
[0.x.35] 
[0.x.36] 
[0.x.37] 
[0.x.38] 
//
// By default, the triangulation assumes that all boundaries are straight lines, and all cells are bi-linear quads or tri-linear hexes, and that they are defined by the cells of the coarse grid (which we just created). Unless we do something special, when new points need to be introduced the domain is assumed to be delineated by the straight lines of the coarse mesh, and new points will simply be in the middle of the surrounding ones. Here, however, we know that the domain is curved, and we would like to have the Triangulation place new points according to the underlying geometry. Fortunately, some good soul implemented an object which describes a spherical domain, of which the ring is a section; it only needs the center of the ring and automatically figures out how to instruct the Triangulation where to place the new points. The way this works in deal.II is that you tag parts of the triangulation you want to be curved with a number that is usually referred to as "manifold indicator" and then tell the triangulation to use a particular "manifold object" for all places with this manifold indicator. How exactly this works is not important at this point (you can read up on it in  [2.x.8]  and  [2.x.9] ). The functions in GridGenerator handle this for us in most circumstances: they attach the correct manifold to a domain so that when the triangulation is refined new cells are placed in the correct places. In the present case  [2.x.10]  attaches a SphericalManifold to all cells: this causes cells to be refined with calculations in spherical coordinates (so new cells have edges that are either radial or lie along concentric circles around the origin).
//
// By default (i.e., for a Triangulation created by hand or without a call to a GridGenerator function like  [2.x.11]  or  [2.x.12]  all cells and faces of the Triangulation have their manifold_id set to  [2.x.13]  which is the default if you want a manifold that produces straight edges, but you can change this number for individual cells and faces. In that case, the curved manifold thus associated with number zero will not apply to those parts with a non-zero manifold indicator, but other manifold description objects can be associated with those non-zero indicators. If no manifold description is associated with a particular manifold indicator, a manifold that produces straight edges is implied. (Manifold indicators are a slightly complicated topic; if you're confused about what exactly is happening here, you may want to look at the  [2.x.14]  "glossary entry on this topic".) Since the default chosen by  [2.x.15]  is reasonable we leave things alone.
//
// In order to demonstrate how to write a loop over all cells, we will refine the grid in five steps towards the inner circle of the domain:
//
[0.x.39] 
[0.x.40] 
//
// Next, we need to loop over the active cells of the triangulation. You can think of a triangulation as a collection of cells. If it were an array, you would just get a pointer that you increment from one element to the next using the operator `++`. The cells of a triangulation aren't stored as a simple array, but the concept of an [1.x.0] generalizes how pointers work to arbitrary collections of objects (see [1.x.1] for more information). Typically, any container type in C++ will return an iterator pointing to the start of the collection with a method called `begin`, and an iterator point to 1 past the end of the collection with a method called `end`. We can increment an iterator `it` with the operator `++it`, dereference it to get the underlying data with `*it`, and check to see if we're done by comparing `it != collection.end()`.
//
// The second important piece is that we only need the active cells. Active cells are those that are not further refined, and the only ones that can be marked for further refinement. deal.II provides iterator categories that allow us to iterate over [1.x.2] cells (including the parent cells of active ones) or only over the active cells. Because we want the latter, we need to call the method  [2.x.16] 
//
// Putting all of this together, we can loop over all the active cells of a triangulation with [1.x.3] In the initializer of this loop, we've used the `auto` keyword for the type of the iterator `it`. The `auto` keyword means that the type of the object being declared will be inferred from the context. This keyword is useful when the actual type names are long or possibly even redundant. If you're unsure of what the type is and want to look up what operations the result supports, you can go to the documentation for the method  [2.x.17]  In this case, the type of `it` is  [2.x.18] 
//
// While the `auto` keyword can save us from having to type out long names of data types, we still have to type a lot of redundant declarations about the start and end iterator and how to increment it. Instead of doing that, we'll use [1.x.4], which wrap up all of the syntax shown above into a much shorter form:
//
[0.x.41] 
[0.x.42] 
//[2.x.19]  See  [2.x.20]  for more information about the iterator classes used in deal.II, and  [2.x.21]  for more information about range-based for loops and the `auto` keyword.
//
// Next, we loop over all vertices of the cells. For that purpose we query an iterator over the vertex indices (in 2d, this is an array that contains the elements `{0,1,2,3}`, but since `cell->vertex_indices()` knows the dimension the cell lives in, the array so returned is correct in all dimensions and this enables this code to be correct whether we run it in 2d or 3d, i.e., it enables "dimension-independent programming" -- a big part of what we will discuss in  [2.x.22] ).
//
[0.x.43] 
[0.x.44] 
//
//     If this cell is at the inner boundary, then at least one of its     vertices must sit on the inner ring and therefore have a radial     distance from the center of exactly 0.5, up to floating point     accuracy. So we compute this distance, and if we find a vertex     with this property, we flag this cell for later refinement. We     can then also break the loop over all vertices and move on to     the next cell.         Because the distance from the center is computed as a floating     point number, we have to expect that whatever we compute is     only accurate to within     [round-off](https:en.wikipedia.org/wiki/Round-off_error). As     a consequence, we can never expect to compare the distance     with the inner radius by equality: A statement such as     `if (distance_from_center == inner_radius)` will fail     unless we get exceptionally lucky. Rather, we need to do this     comparison with a certain tolerance, and the usual way to do     this is to write it as `if  [2.x.23] 
//
// -     inner_radius) <= tolerance)`     where `tolerance` is some small number larger     than round-off. The question is how to choose it: We could just     pick, say, `1e-10`, but this is only appropriate if the objects     we compare are of size one. If we had created a mesh with cells     of size `1e+10`, then `1e-10` would be far lower than round-off     and, as before, the comparison will only succeed if we get     exceptionally lucky. Rather, it is almost always useful to make     the tolerance *relative* to a typical "scale" of the objects     being compared. Here, the "scale" would be the inner radius, or     maybe the diameter of cells. We choose the former and set the     tolerance equal to  [2.x.24]  times the inner radius of the     annulus.
//
[0.x.45] 
[0.x.46] 
//
[0.x.47] 
[0.x.48] 
[0.x.49] 
[0.x.50] 
[0.x.51] 
[0.x.52] 
[0.x.53] 
[0.x.54] 
//
// Now that we have marked all the cells that we want refined, we let the triangulation actually do this refinement. The function that does so owes its long name to the fact that one can also mark cells for coarsening, and the function does coarsening and refinement all at once:
//
[0.x.55] 
[0.x.56] 
//
// Finally, after these five iterations of refinement, we want to again write the resulting mesh to a file, again in SVG format. This works just as above:
//
[0.x.57] 
[0.x.58] 
[0.x.59] 
//
[0.x.60] 
[0.x.61] 
//
//  [2.x.25] 
//
// Finally, the main function. There isn't much to do here, only to call the two subfunctions, which produce the two grids.
//
[0.x.62] 
[0.x.63] 
[0.x.64] 
[0.x.65] 
[0.x.66] 
[0.x.67] 
[0.x.68] 
[0.x.69] 
[0.x.70] 
[0.x.71] 
[0.x.72] 
[0.x.73] 
[0.x.74] 
[0.x.75] 
[0.x.76] 
[0.x.77] 
[0.x.78] 
[0.x.79] 
[0.x.80] 
//
[0.x.81] 
[0.x.82] 
[0.x.83] 
//
// The first of the following include files are probably well-known by now and need no further explanation.
//
[0.x.84] 
[0.x.85] 
[0.x.86] 
[0.x.87] 
[0.x.88] 
[0.x.89] 
[0.x.90] 
[0.x.91] 
//
// This include file is new. Even if we are not solving a PDE in this tutorial, we want to use a dummy finite element with zero degrees of freedoms provided by the FE_Nothing class.
//
[0.x.92] 
//
// The following header file is also new: in it, we declare the MappingQ class which we will use for polynomial mappings of arbitrary order:
//
[0.x.93] 
//
// And this again is C++:
//
[0.x.94] 
[0.x.95] 
[0.x.96] 
//
// The last step is as in previous programs:
//
[0.x.97] 
[0.x.98] 
[0.x.99] 
//
// Now, as we want to compute the value of  [2.x.26] , we have to compare to something. These are the first few digits of  [2.x.27] , which we define beforehand for later use. Since we would like to compute the difference between two numbers which are quite accurate, with the accuracy of the computed approximation to  [2.x.28]  being in the range of the number of digits which a double variable can hold, we rather declare the reference value as a  [2.x.29]  and give it a number of extra digits:
//
[0.x.100] 
//
// Then, the first task will be to generate some output. Since this program is so small, we do not employ object oriented techniques in it and do not declare classes (although, of course, we use the object oriented features of the library). Rather, we just pack the functionality into separate functions. We make these functions templates on the number of space dimensions to conform to usual practice when using deal.II, although we will only use them for two space dimensions and throw an exception when attempted to use for any other spatial dimension.
//
// The first of these functions just generates a triangulation of a circle (hyperball) and outputs the  [2.x.30]  mapping of its cells for different values of  [2.x.31] . Then, we refine the grid once and do so again.
//
[0.x.101] 
[0.x.102] 
[0.x.103] 
[0.x.104] 
[0.x.105] 
//
// So first generate a coarse triangulation of the circle and associate a suitable boundary description to it. By default,  [2.x.32]  attaches a SphericalManifold to the boundary (and uses FlatManifold for the interior) so we simply call that function and move on:
//
[0.x.106] 
[0.x.107] 
//
// Then alternate between generating output on the current mesh for  [2.x.33] ,  [2.x.34] , and  [2.x.35]  mappings, and (at the end of the loop body) refining the mesh once globally.
//
[0.x.108] 
[0.x.109] 
[0.x.110] 
//
[0.x.111] 
//
[0.x.112] 
[0.x.113] 
[0.x.114] 
//
//   For this, first set up an object describing the mapping. This   is done using the MappingQ class, which takes as   argument to the constructor the polynomial degree which it   shall use.
//
[0.x.115] 
//
//   As a side note, for a piecewise linear mapping, you   could give a value of  [2.x.36]  to the constructor   of MappingQ, but there is also a class MappingQ1 that   achieves the same effect. Historically, it did a lot of   things in a simpler way than MappingQ but is today just   a wrapper around the latter. It is, however, still the   class that is used implicitly in many places of the   library if you do not specify another mapping   explicitly.
//
//   In order to actually write out the present grid with this   mapping, we set up an object which we will use for output. We   will generate Gnuplot output, which consists of a set of lines   describing the mapped triangulation. By default, only one line   is drawn for each face of the triangulation, but since we want   to explicitly see the effect of the mapping, we want to have   the faces in more detail. This can be done by passing the   output object a structure which contains some flags. In the   present case, since Gnuplot can only draw straight lines, we   output a number of additional points on the faces so that each   face is drawn by 30 small lines instead of only one. This is   sufficient to give us the impression of seeing a curved line,   rather than a set of straight lines.
//
[0.x.116] 
[0.x.117] 
[0.x.118] 
//
//   Finally, generate a filename and a file for output:
//
[0.x.119] 
[0.x.120] 
[0.x.121] 
//
//   Then write out the triangulation to this file. The last   argument of the function is a pointer to a mapping object. This   argument has a default value, and if no value is given a simple   MappingQ1 object is taken, which we briefly   described above. This would then result in a piecewise linear   approximation of the true boundary in the output.
//
[0.x.122] 
[0.x.123] 
[0.x.124] 
//
// At the end of the loop, refine the mesh globally.
//
[0.x.125] 
[0.x.126] 
[0.x.127] 
//
// Now we proceed with the main part of the code, the approximation of  [2.x.37] . The area of a circle is of course given by  [2.x.38] , so having a circle of radius 1, the area represents just the number that is searched for. The numerical computation of the area is performed by integrating the constant function of value 1 over the whole computational domain, i.e. by computing the areas  [2.x.39] , where the sum extends over all quadrature points on all active cells in the triangulation, with  [2.x.40]  being the weight of quadrature point  [2.x.41] . The integrals on each cell are approximated by numerical quadrature, hence the only additional ingredient we need is to set up a FEValues object that provides the corresponding `JxW` values of each cell. (Note that `JxW` is meant to abbreviate [1.x.5]; since in numerical quadrature the two factors always occur at the same places, we only offer the combined quantity, rather than two separate ones.) We note that here we won't use the FEValues object in its original purpose, i.e. for the computation of values of basis functions of a specific finite element at certain quadrature points. Rather, we use it only to gain the `JxW` at the quadrature points, irrespective of the (dummy) finite element we will give to the constructor of the FEValues object. The actual finite element given to the FEValues object is not used at all, so we could give any.
//
[0.x.128] 
[0.x.129] 
[0.x.130] 
[0.x.131] 
[0.x.132] 
//
// For the numerical quadrature on all cells we employ a quadrature rule of sufficiently high degree. We choose QGauss that is of order 8 (4 points), to be sure that the errors due to numerical quadrature are of higher order than the order (maximal 6) that will occur due to the order of the approximation of the boundary, i.e. the order of the mappings employed. Note that the integrand, the Jacobian determinant, is not a polynomial function (rather, it is a rational one), so we do not use Gauss quadrature in order to get the exact value of the integral as done often in finite element computations, but could as well have used any quadrature formula of like order instead.
//
[0.x.133] 
//
// Now start by looping over polynomial mapping degrees=1..4:
//
[0.x.134] 
[0.x.135] 
[0.x.136] 
//
// First generate the triangulation, the boundary and the mapping object as already seen.
//
[0.x.137] 
[0.x.138] 
//
[0.x.139] 
//
// We now create a finite element. Unlike the rest of the example programs, we do not actually need to do any computations with shape functions; we only need the `JxW` values from an FEValues object. Hence we use the special finite element class FE_Nothing which has exactly zero degrees of freedom per cell (as the name implies, the local basis on each cell is the empty set). A more typical usage of FE_Nothing is shown in  [2.x.42] .
//
[0.x.140] 
//
// Likewise, we need to create a DoFHandler object. We do not actually use it, but it will provide us with `active_cell_iterators` that are needed to reinitialize the FEValues object on each cell of the triangulation.
//
[0.x.141] 
//
// Now we set up the FEValues object, giving the Mapping, the dummy finite element and the quadrature object to the constructor, together with the update flags asking for the `JxW` values at the quadrature points only. This tells the FEValues object that it needs not compute other quantities upon calling the  [2.x.43]  function, thus saving computation time.
//
// The most important difference in the construction of the FEValues object compared to previous example programs is that we pass a mapping object as first argument, which is to be used in the computation of the mapping from unit to real cell. In previous examples, this argument was omitted, resulting in the implicit use of an object of type MappingQ1.
//
[0.x.142] 
//
// We employ an object of the ConvergenceTable class to store all important data like the approximated values for  [2.x.44]  and the error with respect to the true value of  [2.x.45] . We will also use functions provided by the ConvergenceTable class to compute convergence rates of the approximations to  [2.x.46] .
//
[0.x.143] 
//
// Now we loop over several refinement steps of the triangulation.
//
[0.x.144] 
[0.x.145] 
[0.x.146] 
//
//   In this loop we first add the number of active cells of the   current triangulation to the table. This function automatically   creates a table column with superscription `cells`, in case   this column was not created before.
//
[0.x.147] 
//
//   Then we distribute the degrees of freedom for the dummy finite   element. Strictly speaking we do not need this function call in   our special case but we call it to make the DoFHandler happy --   otherwise it would throw an assertion in the  [2.x.47]    function below.
//
[0.x.148] 
//
//   We define the variable area as `long double` like we did for   the `pi` variable before.
//
[0.x.149] 
//
//   Now we loop over all cells, reinitialize the FEValues object   for each cell, and add up all the `JxW` values for this cell to   `area`...
//
[0.x.150] 
[0.x.151] 
[0.x.152] 
[0.x.153] 
[0.x.154] 
[0.x.155] 
//
//   ...and store the resulting area values and the errors in the   table. We need a static cast to double as there is no   add_value(string, long double) function implemented. Note that   this also concerns the second call as the  [2.x.48]    function in the  [2.x.49]  namespace is overloaded on its   argument types, so there exists a version taking and returning   a  [2.x.50] , in contrast to the global namespace   where only one such function is declared (which takes and   returns a double).
//
[0.x.156] 
[0.x.157] 
[0.x.158] 
//
// We want to compute the convergence rates of the `error` column. Therefore we need to omit the other columns from the convergence rate evaluation before calling `evaluate_all_convergence_rates`
//
[0.x.159] 
[0.x.160] 
[0.x.161] 
[0.x.162] 
//
// Finally we set the precision and scientific mode for output of some of the quantities...
//
[0.x.163] 
[0.x.164] 
//
// ...and write the whole table to  [2.x.51] 
[0.x.165] 
//
[0.x.166] 
[0.x.167] 
[0.x.168] 
//
// The following, second function also computes an approximation of  [2.x.52]  but this time via the perimeter  [2.x.53]  of the domain instead of the area. This function is only a variation of the previous function. So we will mainly give documentation for the differences.
//
[0.x.169] 
[0.x.170] 
[0.x.171] 
[0.x.172] 
[0.x.173] 
//
// We take the same order of quadrature but this time a `dim-1` dimensional quadrature as we will integrate over (boundary) lines rather than over cells.
//
[0.x.174] 
//
// We loop over all degrees, create the triangulation, the boundary, the mapping, the dummy finite element and the DoFHandler object as seen before.
//
[0.x.175] 
[0.x.176] 
[0.x.177] 
[0.x.178] 
[0.x.179] 
//
[0.x.180] 
[0.x.181] 
//
[0.x.182] 
//
// Then we create a FEFaceValues object instead of a FEValues object as in the previous function. Again, we pass a mapping as first argument.
//
[0.x.183] 
[0.x.184] 
[0.x.185] 
[0.x.186] 
[0.x.187] 
//
[0.x.188] 
[0.x.189] 
[0.x.190] 
[0.x.191] 
//
[0.x.192] 
//
//   Now we run over all cells and over all faces of each cell. Only   the contributions of the `JxW` values on boundary faces are   added to the long double variable `perimeter`.
//
[0.x.193] 
[0.x.194] 
[0.x.195] 
[0.x.196] 
[0.x.197] 
//
//           We reinit the FEFaceValues object with the cell           iterator and the number of the face.
//
[0.x.198] 
[0.x.199] 
[0.x.200] 
[0.x.201] 
[0.x.202] 
[0.x.203] 
[0.x.204] 
//
//   Then store the evaluated values in the table...
//
[0.x.205] 
[0.x.206] 
[0.x.207] 
[0.x.208] 
//
// ...and end this function as we did in the previous one:
//
[0.x.209] 
[0.x.210] 
[0.x.211] 
[0.x.212] 
//
[0.x.213] 
[0.x.214] 
//
[0.x.215] 
//
[0.x.216] 
[0.x.217] 
[0.x.218] 
[0.x.219] 
//
// The following main function just calls the above functions in the order of their appearance. Apart from this, it looks just like the main functions of previous tutorial programs.
//
[0.x.220] 
[0.x.221] 
[0.x.222] 
[0.x.223] 
[0.x.224] 
//
[0.x.225] 
//
[0.x.226] 
//
[0.x.227] 
[0.x.228] 
[0.x.229] 
[0.x.230] 
[0.x.231] 
[0.x.232] 
[0.x.233] 
[0.x.234] 
[0.x.235] 
[0.x.236] 
[0.x.237] 
[0.x.238] 
[0.x.239] 
[0.x.240] 
//
[0.x.241] 
[0.x.242] 
[0.x.243] 
[0.x.244] 
[0.x.245] 
[0.x.246] 
[0.x.247] 
[0.x.248] 
[0.x.249] 
[0.x.250] 
[0.x.251] 
[0.x.252] 
[0.x.253] 
[0.x.254] 
//
[0.x.255] 
[0.x.256] 
[0.x.257] 
[0.x.258] 
[0.x.259] 
[0.x.260] 
[0.x.261] 
[0.x.262] 
[0.x.263] 
[0.x.264] 
[0.x.265] 
[0.x.266] 
[0.x.267] 
[0.x.268] 
[0.x.269] 
[0.x.270] 
//
[0.x.271] 
[0.x.272] 
[0.x.273] 
//
// As usual, the program starts with a rather long list of include files which you are probably already used to by now:
//
[0.x.274] 
[0.x.275] 
[0.x.276] 
[0.x.277] 
[0.x.278] 
[0.x.279] 
[0.x.280] 
[0.x.281] 
[0.x.282] 
[0.x.283] 
[0.x.284] 
[0.x.285] 
[0.x.286] 
[0.x.287] 
[0.x.288] 
[0.x.289] 
[0.x.290] 
[0.x.291] 
[0.x.292] 
//
// Just this one is new: it declares a class DynamicSparsityPattern, which we will use and explain further down below.
//
[0.x.293] 
//
// We will make use of the  [2.x.54]  algorithm of the C++ standard library, so we have to include the following file for its declaration:
//
[0.x.294] 
[0.x.295] 
[0.x.296] 
[0.x.297] 
//
// The last step is as in all previous programs:
//
[0.x.298] 
[0.x.299] 
[0.x.300] 
//
// Then we declare a class which represents the solution of a Laplace problem. As this example program is based on  [2.x.55] , the class looks rather the same, with the sole structural difference that the functions  [2.x.56]  itself, and is thus called  [2.x.57] , and that the output function was dropped since the solution function is so boring that it is not worth being viewed.
//
// The only other noteworthy change is that the constructor takes a value representing the polynomial degree of the mapping to be used later on, and that it has another member variable representing exactly this mapping. In general, this variable will occur in real applications at the same places where the finite element is declared or used.
//
[0.x.301] 
[0.x.302] 
[0.x.303] 
[0.x.304] 
[0.x.305] 
[0.x.306] 
//
[0.x.307] 
[0.x.308] 
[0.x.309] 
[0.x.310] 
[0.x.311] 
//
[0.x.312] 
[0.x.313] 
[0.x.314] 
[0.x.315] 
//
[0.x.316] 
[0.x.317] 
[0.x.318] 
//
[0.x.319] 
[0.x.320] 
//
[0.x.321] 
[0.x.322] 
//
// Construct such an object, by initializing the variables. Here, we use linear finite elements (the argument to the  [2.x.58]  variable denotes the polynomial degree), and mappings of given order. Print to screen what we are about to do.
//
[0.x.323] 
[0.x.324] 
[0.x.325] 
[0.x.326] 
[0.x.327] 
[0.x.328] 
[0.x.329] 
[0.x.330] 
[0.x.331] 
[0.x.332] 
//
// The first task is to set up the variables for this problem. This includes generating a valid  [2.x.59]  object, as well as the sparsity patterns for the matrix, and the object representing the constraints that the mean value of the degrees of freedom on the boundary be zero.
//
[0.x.333] 
[0.x.334] 
[0.x.335] 
//
// The first task is trivial: generate an enumeration of the degrees of freedom, and initialize solution and right hand side vector to their correct sizes:
//
[0.x.336] 
[0.x.337] 
[0.x.338] 
//
// The next task is to construct the object representing the constraint that the mean value of the degrees of freedom on the boundary shall be zero. For this, we first want a list of those nodes that are actually at the boundary. The  [2.x.60]  namespace has a function that returns an IndexSet object that contains the indices of all those degrees of freedom that are at the boundary.
//
// Once we have this index set, we wanted to know which is the first index corresponding to a degree of freedom on the boundary. We need this because we wanted to constrain one of the nodes on the boundary by the values of all other DoFs on the boundary. To get the index of this "first" degree of freedom is easy enough using the IndexSet class:
//
[0.x.339] 
//
[0.x.340] 
[0.x.341] 
//
// Then generate a constraints object with just this one constraint. First clear all previous content (which might reside there from the previous computation on a once coarser grid), then add this one line constraining the  [2.x.61]  to the sum of other boundary DoFs each with weight -1. Finally, close the constraints object, i.e. do some internal bookkeeping on it for faster processing of what is to come later:
//
[0.x.342] 
[0.x.343] 
[0.x.344] 
[0.x.345] 
[0.x.346] 
[0.x.347] 
//
// Next task is to generate a sparsity pattern. This is indeed a tricky task here. Usually, we just call  [2.x.62]  and condense the result using the hanging node constraints. We have no hanging node constraints here (since we only refine globally in this example), but we have this global constraint on the boundary. This poses one severe problem in this context: the  [2.x.63]  class wants us to state beforehand the maximal number of entries per row, either for all rows or for each row separately. There are functions in the library which can tell you this number in case you just have hanging node constraints (namely  [2.x.64]  but how is this for the present case? The difficulty arises because the elimination of the constrained degree of freedom requires a number of additional entries in the matrix at places that are not so simple to determine. We would therefore have a problem had we to give a maximal number of entries per row here.
//
// Since this can be so difficult that no reasonable answer can be given that allows allocation of only a reasonable amount of memory, there is a class DynamicSparsityPattern, that can help us out here. It does not require that we know in advance how many entries rows could have, but allows just about any length. It is thus significantly more flexible in case you do not have good estimates of row lengths, however at the price that building up such a pattern is also significantly more expensive than building up a pattern for which you had information in advance. Nevertheless, as we have no other choice here, we'll just build such an object by initializing it with the dimensions of the matrix and calling another function  [2.x.65]  to get the sparsity pattern due to the differential operator, then condense it with the constraints object which adds those positions in the sparsity pattern that are required for the elimination of the constraint.
//
[0.x.348] 
[0.x.349] 
[0.x.350] 
//
// Finally, once we have the full pattern, we can initialize an object of type  [2.x.66]  from it and in turn initialize the matrix with it. Note that this is actually necessary, since the DynamicSparsityPattern is so inefficient compared to the  [2.x.67]  class due to the more flexible data structures it has to use, that we can impossibly base the sparse matrix class on it, but rather need an object of type  [2.x.68] , which we generate by copying from the intermediate object.
//
// As a further sidenote, you will notice that we do not explicitly have to  [2.x.69]  the sparsity pattern here. This, of course, is due to the fact that the  [2.x.70]  function generates a compressed object right from the start, to which you cannot add new entries anymore. The  [2.x.71]  call is therefore implicit in the  [2.x.72]  call.
//
[0.x.351] 
[0.x.352] 
[0.x.353] 
//
// The next function then assembles the linear system of equations, solves it, and evaluates the solution. This then makes three actions, and we will put them into eight true statements (excluding declaration of variables, and handling of temporary vectors). Thus, this function is something for the very lazy. Nevertheless, the functions called are rather powerful, and through them this function uses a good deal of the whole library. But let's look at each of the steps.
//
[0.x.354] 
[0.x.355] 
[0.x.356] 
//
// First, we have to assemble the matrix and the right hand side. In all previous examples, we have investigated various ways how to do this manually. However, since the Laplace matrix and simple right hand sides appear so frequently in applications, the library provides functions for actually doing this for you, i.e. they perform the loop over all cells, setting up the local matrices and vectors, and putting them together for the end result.
//
// The following are the two most commonly used ones: creation of the Laplace matrix and creation of a right hand side vector from body or boundary forces. They take the mapping object, the  [2.x.73]  object representing the degrees of freedom and the finite element in use, a quadrature formula to be used, and the output object. The function that creates a right hand side vector also has to take a function object describing the (continuous) right hand side function.
//
// Let us look at the way the matrix and body forces are integrated:
//
[0.x.357] 
[0.x.358] 
[0.x.359] 
[0.x.360] 
[0.x.361] 
[0.x.362] 
[0.x.363] 
[0.x.364] 
[0.x.365] 
[0.x.366] 
[0.x.367] 
[0.x.368] 
[0.x.369] 
//
// That's quite simple, right?
//
// Two remarks are in order, though: First, these functions are used in a lot of contexts. Maybe you want to create a Laplace or mass matrix for a vector values finite element; or you want to use the default Q1 mapping; or you want to assembled the matrix with a coefficient in the Laplace operator. For this reason, there are quite a large number of variants of these functions in the  [2.x.74]  and  [2.x.75]  namespaces. Whenever you need a slightly different version of these functions than the ones called above, it is certainly worthwhile to take a look at the documentation and to check whether something fits your needs.
//
// The second remark concerns the quadrature formula we use: we want to integrate over bilinear shape functions, so we know that we have to use at least an order two Gauss quadrature formula. On the other hand, we want the quadrature rule to have at least the order of the boundary approximation. Since the order of Gauss rule with  [2.x.76]  points is  [2.x.77] , and the order of the boundary approximation using polynomials of degree  [2.x.78]  is  [2.x.79] , we know that  [2.x.80] . Since r has to be an integer and (as mentioned above) has to be at least  [2.x.81] , this makes up for the formula above computing  [2.x.82] .
//
// Since the generation of the body force contributions to the right hand side vector was so simple, we do that all over again for the boundary forces as well: allocate a vector of the right size and call the right function. The boundary function has constant values, so we can generate an object from the library on the fly, and we use the same quadrature formula as above, but this time of lower dimension since we integrate over faces now instead of cells:
//
[0.x.370] 
[0.x.371] 
[0.x.372] 
[0.x.373] 
[0.x.374] 
[0.x.375] 
[0.x.376] 
//
// Then add the contributions from the boundary to those from the interior of the domain:
//
[0.x.377] 
//
// For assembling the right hand side, we had to use two different vector objects, and later add them together. The reason we had to do so is that the  [2.x.83]  and  [2.x.84]  functions first clear the output vector, rather than adding up their results to previous contents. This can reasonably be called a design flaw in the library made in its infancy, but unfortunately things are as they are for some time now and it is difficult to change such things that silently break existing code, so we have to live with that.
//
// Now, the linear system is set up, so we can eliminate the one degree of freedom which we constrained to the other DoFs on the boundary for the mean value constraint from matrix and right hand side vector, and solve the system. After that, distribute the constraints again, which in this case means setting the constrained degree of freedom to its proper value
//
[0.x.378] 
[0.x.379] 
//
[0.x.380] 
[0.x.381] 
//
// Finally, evaluate what we got as solution. As stated in the introduction, we are interested in the H1 semi-norm of the solution. Here, as well, we have a function in the library that does this, although in a slightly non-obvious way: the  [2.x.85]  function integrates the norm of the difference between a finite element function and a continuous function. If we therefore want the norm of a finite element field, we just put the continuous function to zero. Note that this function, just as so many other ones in the library as well, has at least two versions, one which takes a mapping as argument (which we make us of here), and the one which we have used in previous examples which implicitly uses  [2.x.86] .  Also note that we take a quadrature formula of one degree higher, in order to avoid superconvergence effects where the solution happens to be especially close to the exact solution at certain points (we don't know whether this might be the case here, but there are cases known of this, and we just want to make sure):
//
[0.x.382] 
[0.x.383] 
[0.x.384] 
[0.x.385] 
[0.x.386] 
[0.x.387] 
[0.x.388] 
[0.x.389] 
//
// Then, the function just called returns its results as a vector of values each of which denotes the norm on one cell. To get the global norm, we do the following:
//
[0.x.390] 
[0.x.391] 
[0.x.392] 
[0.x.393] 
//
// Last task -- generate output:
//
[0.x.394] 
[0.x.395] 
[0.x.396] 
[0.x.397] 
[0.x.398] 
//
// The following function solving the linear system of equations is copied from  [2.x.87]  and is explained there in some detail:
//
[0.x.399] 
[0.x.400] 
[0.x.401] 
[0.x.402] 
[0.x.403] 
//
[0.x.404] 
[0.x.405] 
//
[0.x.406] 
[0.x.407] 
//
// Next, we write the solution as well as the material ids to a VTU file. This is similar to what was done in many other tutorial programs. The new ingredient presented in this tutorial program is that we want to ensure that the data written to the file used for visualization is actually a faithful representation of what is used internally by deal.II. That is because most of the visualization data formats only represent cells by their vertex coordinates, but have no way of representing the curved boundaries that are used in deal.II when using higher order mappings -- in other words, what you see in the visualization tool is not actually what you are computing on. (The same, incidentally, is true when using higher order shape functions: Most visualization tools only render bilinear/trilinear representations. This is discussed in detail in  [2.x.88] 
//
// So we need to ensure that a high-order representation is written to the file. We need to consider two particular topics. Firstly, we tell the DataOut object via the  [2.x.89]  that we intend to interpret the subdivisions of the elements as a high-order Lagrange polynomial rather than a collection of bilinear patches. Recent visualization programs, like ParaView version 5.5 or newer, can then render a high-order solution (see a [1.x.6] for more details). Secondly, we need to make sure that the mapping is passed to the  [2.x.90]  method. Finally, the DataOut class only prints curved faces for [1.x.7] cells by default, so we need to ensure that also inner cells are printed in a curved representation via the mapping.
//
[0.x.408] 
[0.x.409] 
[0.x.410] 
[0.x.411] 
//
[0.x.412] 
[0.x.413] 
[0.x.414] 
//
[0.x.415] 
[0.x.416] 
//
[0.x.417] 
[0.x.418] 
[0.x.419] 
//
[0.x.420] 
[0.x.421] 
//
[0.x.422] 
[0.x.423] 
//
// Finally the main function controlling the different steps to be performed. Its content is rather straightforward, generating a triangulation of a circle, associating a boundary to it, and then doing several cycles on subsequently finer grids. Note again that we have put mesh refinement into the loop header; this may be something for a test program, but for real applications you should consider that this implies that the mesh is refined after the loop is executed the last time since the increment clause (the last part of the three-parted loop header) is executed before the comparison part (the second one), which may be rather costly if the mesh is already quite refined. In that case, you should arrange code such that the mesh is not further refined after the last loop run (or you should do it at the beginning of each run except for the first one).
//
[0.x.424] 
[0.x.425] 
[0.x.426] 
[0.x.427] 
//
[0.x.428] 
[0.x.429] 
[0.x.430] 
[0.x.431] 
[0.x.432] 
//
[0.x.433] 
[0.x.434] 
//
// After all the data is generated, write a table of results to the screen:
//
[0.x.435] 
[0.x.436] 
[0.x.437] 
[0.x.438] 
[0.x.439] 
[0.x.440] 
//
// Finally the main function. It's structure is the same as that used in several of the previous examples, so probably needs no more explanation.
//
[0.x.441] 
[0.x.442] 
[0.x.443] 
[0.x.444] 
[0.x.445] 
//
// This is the main loop, doing the computations with mappings of linear through cubic mappings. Note that since we need the object of type  [2.x.91]  only once, we do not even name it, but create an unnamed such object and call the  [2.x.92]  function of it, subsequent to which it is immediately destroyed again.
//
[0.x.446] 
[0.x.447] 
[0.x.448] 
[0.x.449] 
[0.x.450] 
[0.x.451] 
[0.x.452] 
[0.x.453] 
[0.x.454] 
[0.x.455] 
[0.x.456] 
[0.x.457] 
[0.x.458] 
[0.x.459] 
[0.x.460] 
[0.x.461] 
[0.x.462] 
[0.x.463] 
[0.x.464] 
[0.x.465] 
[0.x.466] 
[0.x.467] 
[0.x.468] 
[0.x.469] 
[0.x.470] 
[0.x.471] 
[0.x.472] 
[0.x.473] 
[0.x.474] 
//
[0.x.475] 
[0.x.476] 
[0.x.477] 
[0.x.478] 
[0.x.479] 
[0.x.480] 
[0.x.481] 
[0.x.482] 
[0.x.483] 
[0.x.484] 
[0.x.485] 
[0.x.486] 
[0.x.487] 
[0.x.488] 
[0.x.489] 
[0.x.490] 
//
[0.x.491] 
[0.x.492] 
[0.x.493] 
[0.x.494] 
//
// The first few files have already been covered in previous examples and will thus not be further commented on:
//
[0.x.495] 
[0.x.496] 
[0.x.497] 
[0.x.498] 
[0.x.499] 
[0.x.500] 
[0.x.501] 
[0.x.502] 
[0.x.503] 
[0.x.504] 
[0.x.505] 
[0.x.506] 
[0.x.507] 
[0.x.508] 
[0.x.509] 
//
// Here the discontinuous finite elements are defined. They are used in the same way as all other finite elements, though -- as you have seen in previous tutorial programs -- there isn't much user interaction with finite element classes at all: they are passed to  [2.x.93]  and  [2.x.94]  objects, and that is about it.
//
[0.x.510] 
//
// This header is needed for FEInterfaceValues to compute integrals on interfaces:
//
[0.x.511] 
//
// We are going to use the simplest possible solver, called Richardson iteration, that represents a simple defect correction. This, in combination with a block SSOR preconditioner (defined in precondition_block.h), that uses the special block matrix structure of system matrices arising from DG discretizations.
//
[0.x.512] 
[0.x.513] 
//
// We are going to use gradients as refinement indicator.
//
[0.x.514] 
//
// Finally, the new include file for using the mesh_loop from the MeshWorker framework
//
[0.x.515] 
//
// Like in all programs, we finish this section by including the needed C++ headers and declaring we want to use objects in the dealii namespace without prefix.
//
[0.x.516] 
[0.x.517] 
//
[0.x.518] 
[0.x.519] 
[0.x.520] 
//[2.x.95] 
//
// First, we define a class describing the inhomogeneous boundary data. Since only its values are used, we implement value_list(), but leave all other functions of Function undefined.
//
[0.x.521] 
[0.x.522] 
[0.x.523] 
[0.x.524] 
[0.x.525] 
[0.x.526] 
[0.x.527] 
[0.x.528] 
[0.x.529] 
//
// Given the flow direction, the inflow boundary of the unit square  [2.x.96]  are the right and the lower boundaries. We prescribe discontinuous boundary values 1 and 0 on the x-axis and value 0 on the right boundary. The values of this function on the outflow boundaries will not be used within the DG scheme.
//
[0.x.530] 
[0.x.531] 
[0.x.532] 
[0.x.533] 
[0.x.534] 
[0.x.535] 
[0.x.536] 
[0.x.537] 
[0.x.538] 
//
[0.x.539] 
[0.x.540] 
[0.x.541] 
[0.x.542] 
[0.x.543] 
[0.x.544] 
[0.x.545] 
[0.x.546] 
//
// Finally, a function that computes and returns the wind field  [2.x.97] . As explained in the introduction, we will use a rotational field around the origin in 2d. In 3d, we simply leave the  [2.x.98] -component unset (i.e., at zero), whereas the function can not be used in 1d in its current implementation:
//
[0.x.547] 
[0.x.548] 
[0.x.549] 
[0.x.550] 
//
[0.x.551] 
[0.x.552] 
[0.x.553] 
//
[0.x.554] 
[0.x.555] 
//
[0.x.556] 
[0.x.557] 
//[2.x.99] 
//
// The following objects are the scratch and copy objects we use in the call to  [2.x.100]  The new object is the FEInterfaceValues object, that works similar to FEValues or FEFacesValues, except that it acts on an interface between two cells and allows us to assemble the interface terms in our weak form.
//
[0.x.558] 
[0.x.559] 
[0.x.560] 
[0.x.561] 
[0.x.562] 
[0.x.563] 
[0.x.564] 
[0.x.565] 
[0.x.566] 
[0.x.567] 
[0.x.568] 
[0.x.569] 
[0.x.570] 
[0.x.571] 
[0.x.572] 
[0.x.573] 
[0.x.574] 
[0.x.575] 
[0.x.576] 
[0.x.577] 
//
[0.x.578] 
[0.x.579] 
[0.x.580] 
[0.x.581] 
[0.x.582] 
[0.x.583] 
[0.x.584] 
[0.x.585] 
[0.x.586] 
[0.x.587] 
//
[0.x.588] 
[0.x.589] 
[0.x.590] 
//
[0.x.591] 
[0.x.592] 
[0.x.593] 
[0.x.594] 
[0.x.595] 
//
[0.x.596] 
[0.x.597] 
[0.x.598] 
[0.x.599] 
[0.x.600] 
[0.x.601] 
//
[0.x.602] 
[0.x.603] 
[0.x.604] 
[0.x.605] 
[0.x.606] 
//
[0.x.607] 
[0.x.608] 
[0.x.609] 
[0.x.610] 
//[2.x.101] 
//
// After this preparations, we proceed with the main class of this program, called AdvectionProblem.
//
// This should all be pretty familiar to you. Interesting details will only come up in the implementation of the assemble function.
//
[0.x.611] 
[0.x.612] 
[0.x.613] 
[0.x.614] 
[0.x.615] 
[0.x.616] 
//
[0.x.617] 
[0.x.618] 
[0.x.619] 
[0.x.620] 
[0.x.621] 
[0.x.622] 
//
[0.x.623] 
[0.x.624] 
//
// Furthermore we want to use DG elements.
//
[0.x.625] 
[0.x.626] 
//
[0.x.627] 
[0.x.628] 
//
// The next four members represent the linear system to be solved.  [2.x.102]  are generated by  [2.x.103]  is computed in  [2.x.104]  is used to determine the location of nonzero elements in  [2.x.105] .
//
[0.x.629] 
[0.x.630] 
//
[0.x.631] 
[0.x.632] 
[0.x.633] 
//
// We start with the constructor. The 1 in the constructor call of  [2.x.106]  is the polynomial degree.
//
[0.x.634] 
[0.x.635] 
[0.x.636] 
[0.x.637] 
[0.x.638] 
[0.x.639] 
[0.x.640] 
[0.x.641] 
//
[0.x.642] 
[0.x.643] 
[0.x.644] 
//
// In the function that sets up the usual finite element data structures, we first need to distribute the DoFs.
//
[0.x.645] 
//
// We start by generating the sparsity pattern. To this end, we first fill an intermediate object of type DynamicSparsityPattern with the couplings appearing in the system. After building the pattern, this object is copied to  [2.x.107]  and can be discarded.
//
// To build the sparsity pattern for DG discretizations, we can call the function analogue to  [2.x.108]  which is called  [2.x.109] 
[0.x.646] 
[0.x.647] 
[0.x.648] 
//
// Finally, we set up the structure of all components of the linear system.
//
[0.x.649] 
[0.x.650] 
[0.x.651] 
[0.x.652] 
//[2.x.110] 
//
// Here we see the major difference to assembling by hand. Instead of writing loops over cells and faces, the logic is contained in the call to  [2.x.111]  and we only need to specify what should happen on each cell, each boundary face, and each interior face. These three tasks are handled by the lambda functions inside the function below.
//
[0.x.653] 
[0.x.654] 
[0.x.655] 
[0.x.656] 
[0.x.657] 
//
// This is the function that will be executed for each cell.
//
[0.x.658] 
[0.x.659] 
[0.x.660] 
[0.x.661] 
[0.x.662] 
[0.x.663] 
[0.x.664] 
//
[0.x.665] 
//
[0.x.666] 
[0.x.667] 
//
// We solve a homogeneous equation, thus no right hand side shows up in the cell term.  What's left is integrating the matrix entries.
//
[0.x.668] 
[0.x.669] 
[0.x.670] 
[0.x.671] 
[0.x.672] 
[0.x.673] 
[0.x.674] 
[0.x.675] 
[0.x.676] 
[0.x.677] 
[0.x.678] 
[0.x.679] 
[0.x.680] 
[0.x.681] 
//
// This is the function called for boundary faces and consists of a normal integration using FEFaceValues. New is the logic to decide if the term goes into the system matrix (outflow) or the right-hand side (inflow).
//
[0.x.682] 
[0.x.683] 
[0.x.684] 
[0.x.685] 
[0.x.686] 
[0.x.687] 
[0.x.688] 
//
[0.x.689] 
//
[0.x.690] 
[0.x.691] 
[0.x.692] 
//
[0.x.693] 
[0.x.694] 
//
[0.x.695] 
[0.x.696] 
[0.x.697] 
//
[0.x.698] 
[0.x.699] 
[0.x.700] 
[0.x.701] 
[0.x.702] 
[0.x.703] 
[0.x.704] 
[0.x.705] 
[0.x.706] 
[0.x.707] 
[0.x.708] 
[0.x.709] 
[0.x.710] 
[0.x.711] 
[0.x.712] 
[0.x.713] 
[0.x.714] 
[0.x.715] 
//
// This is the function called on interior faces. The arguments specify cells, face and subface indices (for adaptive refinement). We just pass them along to the reinit() function of FEInterfaceValues.
//
[0.x.716] 
[0.x.717] 
[0.x.718] 
[0.x.719] 
[0.x.720] 
[0.x.721] 
[0.x.722] 
[0.x.723] 
[0.x.724] 
[0.x.725] 
[0.x.726] 
//
[0.x.727] 
[0.x.728] 
//
[0.x.729] 
[0.x.730] 
//
[0.x.731] 
//
[0.x.732] 
[0.x.733] 
//
[0.x.734] 
[0.x.735] 
[0.x.736] 
[0.x.737] 
[0.x.738] 
[0.x.739] 
[0.x.740] 
[0.x.741] 
[0.x.742] 
[0.x.743] 
[0.x.744] 
[0.x.745] 
[0.x.746] 
//
// The following lambda function will handle copying the data from the cell and face assembly into the global matrix and right-hand side.
//
// While we would not need an AffineConstraints object, because there are no hanging node constraints in DG discretizations, we use an empty object here as this allows us to use its `copy_local_to_global` functionality.
//
[0.x.747] 
//
[0.x.748] 
[0.x.749] 
[0.x.750] 
[0.x.751] 
[0.x.752] 
[0.x.753] 
//
[0.x.754] 
[0.x.755] 
[0.x.756] 
[0.x.757] 
[0.x.758] 
[0.x.759] 
[0.x.760] 
//
[0.x.761] 
[0.x.762] 
//
// Here, we finally handle the assembly. We pass in ScratchData and CopyData objects, the lambda functions from above, an specify that we want to assemble interior faces once.
//
[0.x.763] 
[0.x.764] 
[0.x.765] 
[0.x.766] 
[0.x.767] 
[0.x.768] 
[0.x.769] 
[0.x.770] 
[0.x.771] 
[0.x.772] 
[0.x.773] 
[0.x.774] 
//[2.x.112] 
//
// For this simple problem we use the simplest possible solver, called Richardson iteration, that represents a simple defect correction. This, in combination with a block SSOR preconditioner, that uses the special block matrix structure of system matrices arising from DG discretizations. The size of these blocks are the number of DoFs per cell. Here, we use a SSOR preconditioning as we have not renumbered the DoFs according to the flow field. If the DoFs are renumbered in the downstream direction of the flow, then a block Gauss-Seidel preconditioner (see the PreconditionBlockSOR class with relaxation=1) does a much better job.
//
[0.x.775] 
[0.x.776] 
[0.x.777] 
[0.x.778] 
[0.x.779] 
//
// Here we create the preconditioner,
//
[0.x.780] 
//
// then assign the matrix to it and set the right block size:
//
[0.x.781] 
//
// After these preparations we are ready to start the linear solver.
//
[0.x.782] 
//
[0.x.783] 
[0.x.784] 
[0.x.785] 
//
// We refine the grid according to a very simple refinement criterion, namely an approximation to the gradient of the solution. As here we consider the DG(1) method (i.e. we use piecewise bilinear shape functions) we could simply compute the gradients on each cell. But we do not want to base our refinement indicator on the gradients on each cell only, but want to base them also on jumps of the discontinuous solution function over faces between neighboring cells. The simplest way of doing that is to compute approximative gradients by difference quotients including the cell under consideration and its neighbors. This is done by the  [2.x.113]  class that computes the approximate gradients in a way similar to the  [2.x.114]  described in  [2.x.115]  of this tutorial. In fact, the  [2.x.116]  class was developed following the  [2.x.117]  class of  [2.x.118] . Relating to the discussion in  [2.x.119] , here we consider  [2.x.120] . Furthermore we note that we do not consider approximate second derivatives because solutions to the linear advection equation are in general not in  [2.x.121]  but only in  [2.x.122]  (or, to be more precise: in  [2.x.123] , i.e., the space of functions whose derivatives in direction  [2.x.124]  are square integrable).
//
[0.x.786] 
[0.x.787] 
[0.x.788] 
//
// The  [2.x.125]  class computes the gradients to float precision. This is sufficient as they are approximate and serve as refinement indicators only.
//
[0.x.789] 
//
// Now the approximate gradients are computed
//
[0.x.790] 
[0.x.791] 
[0.x.792] 
[0.x.793] 
//
// and they are cell-wise scaled by the factor  [2.x.126] 
[0.x.794] 
[0.x.795] 
[0.x.796] 
[0.x.797] 
//
// Finally they serve as refinement indicator.
//
[0.x.798] 
[0.x.799] 
[0.x.800] 
[0.x.801] 
//
[0.x.802] 
[0.x.803] 
//
// The output of this program consists of a vtk file of the adaptively refined grids and the numerical solutions. Finally, we also compute the L-infinity norm of the solution using  [2.x.127] 
[0.x.804] 
[0.x.805] 
[0.x.806] 
[0.x.807] 
[0.x.808] 
[0.x.809] 
//
[0.x.810] 
[0.x.811] 
[0.x.812] 
//
[0.x.813] 
//
[0.x.814] 
//
[0.x.815] 
[0.x.816] 
[0.x.817] 
[0.x.818] 
[0.x.819] 
[0.x.820] 
[0.x.821] 
[0.x.822] 
[0.x.823] 
[0.x.824] 
[0.x.825] 
[0.x.826] 
[0.x.827] 
[0.x.828] 
[0.x.829] 
[0.x.830] 
//
// The following  [2.x.128]  function is similar to previous examples.
//
[0.x.831] 
[0.x.832] 
[0.x.833] 
[0.x.834] 
[0.x.835] 
[0.x.836] 
//
[0.x.837] 
[0.x.838] 
[0.x.839] 
[0.x.840] 
[0.x.841] 
[0.x.842] 
[0.x.843] 
//
[0.x.844] 
[0.x.845] 
//
[0.x.846] 
//
[0.x.847] 
[0.x.848] 
//
[0.x.849] 
[0.x.850] 
//
[0.x.851] 
[0.x.852] 
[0.x.853] 
[0.x.854] 
//
// The following  [2.x.129]  function is similar to previous examples as well, and need not be commented on.
//
[0.x.855] 
[0.x.856] 
[0.x.857] 
[0.x.858] 
[0.x.859] 
[0.x.860] 
[0.x.861] 
[0.x.862] 
[0.x.863] 
[0.x.864] 
[0.x.865] 
[0.x.866] 
[0.x.867] 
[0.x.868] 
[0.x.869] 
[0.x.870] 
[0.x.871] 
[0.x.872] 
[0.x.873] 
[0.x.874] 
[0.x.875] 
[0.x.876] 
[0.x.877] 
[0.x.878] 
[0.x.879] 
[0.x.880] 
[0.x.881] 
[0.x.882] 
[0.x.883] 
[0.x.884] 
[0.x.885] 
[0.x.886] 
//
[0.x.887] 
[0.x.888] 
[0.x.889] 
[0.x.890] 
[0.x.891] 
[0.x.892] 
[0.x.893] 
[0.x.894] 
[0.x.895] 
[0.x.896] 
[0.x.897] 
[0.x.898] 
[0.x.899] 
[0.x.900] 
[0.x.901] 
[0.x.902] 
//
[0.x.903] 
[0.x.904] 
[0.x.905] 
//
// The first few files have already been covered in previous examples and will thus not be further commented on:
//
[0.x.906] 
[0.x.907] 
[0.x.908] 
[0.x.909] 
[0.x.910] 
[0.x.911] 
[0.x.912] 
[0.x.913] 
[0.x.914] 
[0.x.915] 
[0.x.916] 
[0.x.917] 
[0.x.918] 
[0.x.919] 
//
// Here the discontinuous finite elements are defined. They are used in the same way as all other finite elements, though -- as you have seen in previous tutorial programs -- there isn't much user interaction with finite element classes at all: they are passed to  [2.x.130]  and  [2.x.131]  objects, and that is about it.
//
[0.x.920] 
//
// We are going to use the simplest possible solver, called Richardson iteration, that represents a simple defect correction. This, in combination with a block SSOR preconditioner (defined in precondition_block.h), that uses the special block matrix structure of system matrices arising from DG discretizations.
//
[0.x.921] 
[0.x.922] 
//
// We are going to use gradients as refinement indicator.
//
[0.x.923] 
//
// Here come the new include files for using the MeshWorker framework. The first contains the class  [2.x.132]  which provides local integrators with a mapping between local and global degrees of freedom. It stores the results of local integrals as well in its base class  [2.x.133]  In the second of these files, we find an object of type  [2.x.134]  which is mostly a wrapper around a group of FEValues objects. The file <tt>meshworker/simple.h</tt> contains classes assembling locally integrated data into a global system containing only a single matrix. Finally, we will need the file that runs the loop over all mesh cells and faces.
//
[0.x.924] 
[0.x.925] 
[0.x.926] 
[0.x.927] 
//
// Like in all programs, we finish this section by including the needed C++ headers and declaring we want to use objects in the dealii namespace without prefix.
//
[0.x.928] 
[0.x.929] 
//
[0.x.930] 
[0.x.931] 
[0.x.932] 
//[2.x.135] 
//
// First, we define a class describing the inhomogeneous boundary data. Since only its values are used, we implement value_list(), but leave all other functions of Function undefined.
//
[0.x.933] 
[0.x.934] 
[0.x.935] 
[0.x.936] 
[0.x.937] 
[0.x.938] 
[0.x.939] 
[0.x.940] 
[0.x.941] 
//
// Given the flow direction, the inflow boundary of the unit square  [2.x.136]  are the right and the lower boundaries. We prescribe discontinuous boundary values 1 and 0 on the x-axis and value 0 on the right boundary. The values of this function on the outflow boundaries will not be used within the DG scheme.
//
[0.x.942] 
[0.x.943] 
[0.x.944] 
[0.x.945] 
[0.x.946] 
[0.x.947] 
[0.x.948] 
[0.x.949] 
[0.x.950] 
//
[0.x.951] 
[0.x.952] 
[0.x.953] 
[0.x.954] 
[0.x.955] 
[0.x.956] 
[0.x.957] 
[0.x.958] 
//
// Finally, a function that computes and returns the wind field  [2.x.137] . As explained in the introduction, we will use a rotational field around the origin in 2d. In 3d, we simply leave the  [2.x.138] -component unset (i.e., at zero), whereas the function can not be used in 1d in its current implementation:
//
[0.x.959] 
[0.x.960] 
[0.x.961] 
[0.x.962] 
//
[0.x.963] 
[0.x.964] 
[0.x.965] 
[0.x.966] 
//
[0.x.967] 
[0.x.968] 
//[2.x.139] 
//
// After this preparations, we proceed with the main class of this program, called AdvectionProblem. It is basically the main class of  [2.x.140] . We do not have an AffineConstraints object, because there are no hanging node constraints in DG discretizations.
//
// Major differences will only come up in the implementation of the assemble functions, since here, we not only need to cover the flux integrals over faces, we also use the MeshWorker interface to simplify the loops involved.
//
[0.x.969] 
[0.x.970] 
[0.x.971] 
[0.x.972] 
[0.x.973] 
[0.x.974] 
//
[0.x.975] 
[0.x.976] 
[0.x.977] 
[0.x.978] 
[0.x.979] 
[0.x.980] 
//
[0.x.981] 
[0.x.982] 
//
// Furthermore we want to use DG elements of degree 1 (but this is only specified in the constructor). If you want to use a DG method of a different degree the whole program stays the same, only replace 1 in the constructor by the desired polynomial degree.
//
[0.x.983] 
[0.x.984] 
//
// The next four members represent the linear system to be solved.  [2.x.141]  are generated by  [2.x.142]  is computed in  [2.x.143]  is used to determine the location of nonzero elements in  [2.x.144] .
//
[0.x.985] 
[0.x.986] 
//
[0.x.987] 
[0.x.988] 
//
// Finally, we have to provide functions that assemble the cell, boundary, and inner face terms. Within the MeshWorker framework, the loop over all cells and much of the setup of operations will be done outside this class, so all we have to provide are these three operations. They will then work on intermediate objects for which first, we here define alias to the info objects handed to the local integration functions in order to make our life easier below.
//
[0.x.989] 
[0.x.990] 
//
// The following three functions are then the ones that get called inside the generic loop over all cells and faces. They are the ones doing the actual integration.
//
// In our code below, these functions do not access member variables of the current class, so we can mark them as  [2.x.145]  and simply pass pointers to these functions to the MeshWorker framework. If, however, these functions would want to access member variables (or needed additional arguments beyond the ones specified below), we could use the facilities of lambda functions to provide the MeshWorker framework with objects that act as if they had the required number and types of arguments, but have in fact other arguments already bound.
//
[0.x.991] 
[0.x.992] 
[0.x.993] 
[0.x.994] 
[0.x.995] 
[0.x.996] 
[0.x.997] 
//
// We start with the constructor. The 1 in the constructor call of  [2.x.146]  is the polynomial degree.
//
[0.x.998] 
[0.x.999] 
[0.x.1000] 
[0.x.1001] 
[0.x.1002] 
[0.x.1003] 
//
[0.x.1004] 
[0.x.1005] 
[0.x.1006] 
//
// In the function that sets up the usual finite element data structures, we first need to distribute the DoFs.
//
[0.x.1007] 
//
// We start by generating the sparsity pattern. To this end, we first fill an intermediate object of type DynamicSparsityPattern with the couplings appearing in the system. After building the pattern, this object is copied to  [2.x.147]  and can be discarded.
//
// To build the sparsity pattern for DG discretizations, we can call the function analogue to  [2.x.148]  which is called  [2.x.149] 
[0.x.1008] 
[0.x.1009] 
[0.x.1010] 
//
// Finally, we set up the structure of all components of the linear system.
//
[0.x.1011] 
[0.x.1012] 
[0.x.1013] 
[0.x.1014] 
//[2.x.150] 
//
// Here we see the major difference to assembling by hand. Instead of writing loops over cells and faces, we leave all this to the MeshWorker framework. In order to do so, we just have to define local integration functions and use one of the classes in namespace  [2.x.151]  to build the global system.
//
[0.x.1015] 
[0.x.1016] 
[0.x.1017] 
//
// This is the magic object, which knows everything about the data structures and local integration.  This is the object doing the work in the function  [2.x.152]  which is implicitly called by  [2.x.153]  below. After the functions to which we provide pointers did the local integration, the  [2.x.154]  object distributes these into the global sparse matrix and the right hand side vector.
//
[0.x.1018] 
//
// First, we initialize the quadrature formulae and the update flags in the worker base class. For quadrature, we play safe and use a QGauss formula with number of points one higher than the polynomial degree used. Since the quadratures for cells, boundary and interior faces can be selected independently, we have to hand over this value three times.
//
[0.x.1019] 
[0.x.1020] 
[0.x.1021] 
[0.x.1022] 
//
// These are the types of values we need for integrating our system. They are added to the flags used on cells, boundary and interior faces, as well as interior neighbor faces, which is forced by the four  [2.x.155]  values.
//
[0.x.1023] 
[0.x.1024] 
[0.x.1025] 
[0.x.1026] 
//
// After preparing all data in <tt>info_box</tt>, we initialize the FEValues objects in there.
//
[0.x.1027] 
//
// The object created so far helps us do the local integration on each cell and face. Now, we need an object which receives the integrated (local) data and forwards them to the assembler.
//
[0.x.1028] 
//
// Now, we have to create the assembler object and tell it, where to put the local data. These will be our system matrix and the right hand side.
//
[0.x.1029] 
[0.x.1030] 
[0.x.1031] 
//
// Finally, the integration loop over all active cells (determined by the first argument, which is an active iterator).
//
// As noted in the discussion when declaring the local integration functions in the class declaration, the arguments expected by the assembling integrator class are not actually function pointers. Rather, they are objects that can be called like functions with a certain number of arguments. Consequently, we could also pass objects with appropriate operator() implementations here, or lambda functions if the local integrators were, for example, non-static member functions.
//
[0.x.1032] 
[0.x.1033] 
[0.x.1034] 
[0.x.1035] 
[0.x.1036] 
[0.x.1037] 
[0.x.1038] 
[0.x.1039] 
[0.x.1040] 
[0.x.1041] 
[0.x.1042] 
[0.x.1043] 
[0.x.1044] 
//[2.x.156] 
//
// These are the functions given to the  [2.x.157]  called just above. They compute the local contributions to the system matrix and right hand side on cells and faces.
//
[0.x.1045] 
[0.x.1046] 
[0.x.1047] 
[0.x.1048] 
//
// First, let us retrieve some of the objects used here from  [2.x.158]  Note that these objects can handle much more complex structures, thus the access here looks more complicated than might seem necessary.
//
[0.x.1049] 
[0.x.1050] 
[0.x.1051] 
//
// With these objects, we continue local integration like always. First, we loop over the quadrature points and compute the advection vector in the current point.
//
[0.x.1052] 
[0.x.1053] 
[0.x.1054] 
[0.x.1055] 
//
// We solve a homogeneous equation, thus no right hand side shows up in the cell term.  What's left is integrating the matrix entries.
//
[0.x.1056] 
[0.x.1057] 
[0.x.1058] 
[0.x.1059] 
[0.x.1060] 
[0.x.1061] 
[0.x.1062] 
[0.x.1063] 
//
// Now the same for the boundary terms. Note that now we use FEValuesBase, the base class for both FEFaceValues and FESubfaceValues, in order to get access to normal vectors.
//
[0.x.1064] 
[0.x.1065] 
[0.x.1066] 
[0.x.1067] 
[0.x.1068] 
[0.x.1069] 
[0.x.1070] 
//
[0.x.1071] 
[0.x.1072] 
[0.x.1073] 
//
[0.x.1074] 
//
[0.x.1075] 
[0.x.1076] 
//
[0.x.1077] 
[0.x.1078] 
[0.x.1079] 
[0.x.1080] 
[0.x.1081] 
[0.x.1082] 
[0.x.1083] 
[0.x.1084] 
[0.x.1085] 
[0.x.1086] 
[0.x.1087] 
[0.x.1088] 
[0.x.1089] 
[0.x.1090] 
[0.x.1091] 
[0.x.1092] 
[0.x.1093] 
[0.x.1094] 
[0.x.1095] 
[0.x.1096] 
//
// Finally, the interior face terms. The difference here is that we receive two info objects, one for each cell adjacent to the face and we assemble four matrices, one for each cell and two for coupling back and forth.
//
[0.x.1097] 
[0.x.1098] 
[0.x.1099] 
[0.x.1100] 
[0.x.1101] 
[0.x.1102] 
//
// For quadrature points, weights, etc., we use the FEValuesBase object of the first argument.
//
[0.x.1103] 
[0.x.1104] 
//
// For additional shape functions, we have to ask the neighbors FEValuesBase.
//
[0.x.1105] 
[0.x.1106] 
[0.x.1107] 
//
// Then we get references to the four local matrices. The letters u and v refer to trial and test functions, respectively. The %numbers indicate the cells provided by info1 and info2. By convention, the two matrices in each info object refer to the test functions on the respective cell. The first matrix contains the interior couplings of that cell, while the second contains the couplings between cells.
//
[0.x.1108] 
[0.x.1109] 
[0.x.1110] 
[0.x.1111] 
//
// Here, following the previous functions, we would have the local right hand side vectors. Fortunately, the interface terms only involve the solution and the right hand side does not receive any contributions.
//
[0.x.1112] 
[0.x.1113] 
[0.x.1114] 
//
[0.x.1115] 
[0.x.1116] 
[0.x.1117] 
[0.x.1118] 
[0.x.1119] 
[0.x.1120] 
[0.x.1121] 
//
//   This term we've already seen:
//
[0.x.1122] 
[0.x.1123] 
[0.x.1124] 
[0.x.1125] 
[0.x.1126] 
[0.x.1127] 
//
//   We additionally assemble the term  [2.x.159] ,
//
[0.x.1128] 
[0.x.1129] 
[0.x.1130] 
[0.x.1131] 
[0.x.1132] 
[0.x.1133] 
[0.x.1134] 
[0.x.1135] 
[0.x.1136] 
[0.x.1137] 
//
//   This one we've already seen, too:
//
[0.x.1138] 
[0.x.1139] 
[0.x.1140] 
[0.x.1141] 
[0.x.1142] 
[0.x.1143] 
[0.x.1144] 
//
//   And this is another new one:  [2.x.160] :
//
[0.x.1145] 
[0.x.1146] 
[0.x.1147] 
[0.x.1148] 
[0.x.1149] 
[0.x.1150] 
[0.x.1151] 
[0.x.1152] 
[0.x.1153] 
[0.x.1154] 
//[2.x.161] 
//
// For this simple problem we use the simplest possible solver, called Richardson iteration, that represents a simple defect correction. This, in combination with a block SSOR preconditioner, that uses the special block matrix structure of system matrices arising from DG discretizations. The size of these blocks are the number of DoFs per cell. Here, we use a SSOR preconditioning as we have not renumbered the DoFs according to the flow field. If the DoFs are renumbered in the downstream direction of the flow, then a block Gauss-Seidel preconditioner (see the PreconditionBlockSOR class with relaxation=1) does a much better job.
//
[0.x.1155] 
[0.x.1156] 
[0.x.1157] 
[0.x.1158] 
[0.x.1159] 
//
// Here we create the preconditioner,
//
[0.x.1160] 
//
// then assign the matrix to it and set the right block size:
//
[0.x.1161] 
//
// After these preparations we are ready to start the linear solver.
//
[0.x.1162] 
[0.x.1163] 
//
// We refine the grid according to a very simple refinement criterion, namely an approximation to the gradient of the solution. As here we consider the DG(1) method (i.e. we use piecewise bilinear shape functions) we could simply compute the gradients on each cell. But we do not want to base our refinement indicator on the gradients on each cell only, but want to base them also on jumps of the discontinuous solution function over faces between neighboring cells. The simplest way of doing that is to compute approximative gradients by difference quotients including the cell under consideration and its neighbors. This is done by the  [2.x.162]  class that computes the approximate gradients in a way similar to the  [2.x.163]  described in  [2.x.164]  of this tutorial. In fact, the  [2.x.165]  class was developed following the  [2.x.166]  class of  [2.x.167] . Relating to the discussion in  [2.x.168] , here we consider  [2.x.169] . Furthermore we note that we do not consider approximate second derivatives because solutions to the linear advection equation are in general not in  [2.x.170]  but only in  [2.x.171]  (or, to be more precise: in  [2.x.172] , i.e., the space of functions whose derivatives in direction  [2.x.173]  are square integrable).
//
[0.x.1164] 
[0.x.1165] 
[0.x.1166] 
//
// The  [2.x.174]  class computes the gradients to float precision. This is sufficient as they are approximate and serve as refinement indicators only.
//
[0.x.1167] 
//
// Now the approximate gradients are computed
//
[0.x.1168] 
[0.x.1169] 
[0.x.1170] 
[0.x.1171] 
//
// and they are cell-wise scaled by the factor  [2.x.175] 
[0.x.1172] 
[0.x.1173] 
[0.x.1174] 
[0.x.1175] 
//
// Finally they serve as refinement indicator.
//
[0.x.1176] 
[0.x.1177] 
[0.x.1178] 
[0.x.1179] 
//
[0.x.1180] 
[0.x.1181] 
//
// The output of this program consists of eps-files of the adaptively refined grids and the numerical solutions given in gnuplot format.
//
[0.x.1182] 
[0.x.1183] 
[0.x.1184] 
//
// First write the grid in eps format.
//
[0.x.1185] 
[0.x.1186] 
[0.x.1187] 
[0.x.1188] 
//
[0.x.1189] 
[0.x.1190] 
[0.x.1191] 
//
// Then output the solution in gnuplot format.
//
[0.x.1192] 
[0.x.1193] 
[0.x.1194] 
[0.x.1195] 
//
[0.x.1196] 
[0.x.1197] 
[0.x.1198] 
//
[0.x.1199] 
//
[0.x.1200] 
[0.x.1201] 
[0.x.1202] 
//
// The following  [2.x.176]  function is similar to previous examples.
//
[0.x.1203] 
[0.x.1204] 
[0.x.1205] 
[0.x.1206] 
[0.x.1207] 
[0.x.1208] 
//
[0.x.1209] 
[0.x.1210] 
[0.x.1211] 
//
[0.x.1212] 
[0.x.1213] 
[0.x.1214] 
[0.x.1215] 
//
[0.x.1216] 
[0.x.1217] 
//
[0.x.1218] 
//
[0.x.1219] 
[0.x.1220] 
//
[0.x.1221] 
[0.x.1222] 
//
[0.x.1223] 
[0.x.1224] 
[0.x.1225] 
[0.x.1226] 
//
// The following  [2.x.177]  function is similar to previous examples as well, and need not be commented on.
//
[0.x.1227] 
[0.x.1228] 
[0.x.1229] 
[0.x.1230] 
[0.x.1231] 
//
[0.x.1232] 
[0.x.1233] 
[0.x.1234] 
[0.x.1235] 
[0.x.1236] 
[0.x.1237] 
[0.x.1238] 
[0.x.1239] 
[0.x.1240] 
[0.x.1241] 
[0.x.1242] 
[0.x.1243] 
[0.x.1244] 
[0.x.1245] 
[0.x.1246] 
[0.x.1247] 
[0.x.1248] 
[0.x.1249] 
[0.x.1250] 
[0.x.1251] 
[0.x.1252] 
[0.x.1253] 
[0.x.1254] 
[0.x.1255] 
[0.x.1256] 
[0.x.1257] 
[0.x.1258] 
[0.x.1259] 
//
[0.x.1260] 
[0.x.1261] 
[0.x.1262] 
[0.x.1263] 
[0.x.1264] 
[0.x.1265] 
[0.x.1266] 
[0.x.1267] 
[0.x.1268] 
[0.x.1269] 
[0.x.1270] 
[0.x.1271] 
[0.x.1272] 
[0.x.1273] 
[0.x.1274] 
[0.x.1275] 
//
[0.x.1276] 
[0.x.1277] 
[0.x.1278] 
//
// As in all programs, we start with a list of include files from the library, and as usual they are in the standard order which is  [2.x.178]  --  [2.x.179]  --  [2.x.180]  (as each of these categories roughly builds upon previous ones), then C++ standard headers:
//
[0.x.1279] 
[0.x.1280] 
[0.x.1281] 
[0.x.1282] 
[0.x.1283] 
[0.x.1284] 
[0.x.1285] 
[0.x.1286] 
[0.x.1287] 
[0.x.1288] 
[0.x.1289] 
[0.x.1290] 
[0.x.1291] 
[0.x.1292] 
[0.x.1293] 
[0.x.1294] 
[0.x.1295] 
[0.x.1296] 
[0.x.1297] 
[0.x.1298] 
[0.x.1299] 
[0.x.1300] 
[0.x.1301] 
[0.x.1302] 
//
// Now for the C++ standard headers:
//
[0.x.1303] 
[0.x.1304] 
[0.x.1305] 
//
// The last step is as in all previous programs:
//
[0.x.1306] 
[0.x.1307] 
[0.x.1308] 
//[2.x.181] 
//
// As for the program itself, we first define classes that evaluate the solutions of a Laplace equation. In fact, they can evaluate every kind of solution, as long as it is described by a  [2.x.182]  object, and a solution vector. We define them here first, even before the classes that actually generate the solution to be evaluated, since we need to declare an abstract base class that the solver classes can refer to.
//
// From an abstract point of view, we declare a pure base class that provides an evaluation operator() which will do the evaluation of the solution (whatever derived classes might consider an  [2.x.183] ). Since this is the only real function of this base class (except for some bookkeeping machinery), one usually terms such a class that only has an  [2.x.184]  a  [2.x.185]  in C++ terminology, since it is used just like a function object.
//
// Objects of this functor type will then later be passed to the solver object, which applies it to the solution just computed. The evaluation objects may then extract any quantity they like from the solution. The advantage of putting these evaluation functions into a separate hierarchy of classes is that by design they cannot use the internals of the solver object and are therefore independent of changes to the way the solver works. Furthermore, it is trivial to write another evaluation class without modifying the solver class, which speeds up programming (not being able to use internals of another class also means that you do not have to worry about them -- programming evaluators is usually a rather quickly done task), as well as compilation (if solver and evaluation classes are put into different files: the solver only needs to see the declaration of the abstract base class, and therefore does not need to be recompiled upon addition of a new evaluation class, or modification of an old one).  On a related note, you can reuse the evaluation classes for other projects, solving different equations.
//
// In order to improve separation of code into different modules, we put the evaluation classes into a namespace of their own. This makes it easier to actually solve different equations in the same program, by assembling it from existing building blocks. The reason for this is that classes for similar purposes tend to have the same name, although they were developed in different contexts. In order to be able to use them together in one program, it is necessary that they are placed in different namespaces. This we do here:
//
[0.x.1309] 
[0.x.1310] 
//
// Now for the abstract base class of evaluation classes: its main purpose is to declare a pure virtual function  [2.x.186]  taking a  [2.x.187]  object, and the solution vector. In order to be able to use pointers to this base class only, it also has to declare a virtual destructor, which however does nothing. Besides this, it only provides for a little bit of bookkeeping: since we usually want to evaluate solutions on subsequent refinement levels, we store the number of the present refinement cycle, and provide a function to change this number.
//
[0.x.1311] 
[0.x.1312] 
[0.x.1313] 
[0.x.1314] 
[0.x.1315] 
//
[0.x.1316] 
//
[0.x.1317] 
[0.x.1318] 
//
[0.x.1319] 
[0.x.1320] 
[0.x.1321] 
//
[0.x.1322] 
[0.x.1323] 
[0.x.1324] 
[0.x.1325] 
[0.x.1326] 
//[2.x.188] 
//
// The next thing is to implement actual evaluation classes. As noted in the introduction, we'd like to extract a point value from the solution, so the first class does this in its  [2.x.189] . The actual point is given to this class through the constructor, as well as a table object into which it will put its findings.
//
// Finding out the value of a finite element field at an arbitrary point is rather difficult, if we cannot rely on knowing the actual finite element used, since then we cannot, for example, interpolate between nodes. For simplicity, we therefore assume here that the point at which we want to evaluate the field is actually a node. If, in the process of evaluating the solution, we find that we did not encounter this point upon looping over all vertices, we then have to throw an exception in order to signal to the calling functions that something has gone wrong, rather than silently ignore this error.
//
// In the  [2.x.190]  example program, we have already seen how such an exception class can be declared, using the  [2.x.191]  macros. We use this mechanism here again.
//
// From this, the actual declaration of this class should be evident. Note that of course even if we do not list a destructor explicitly, an implicit destructor is generated from the compiler, and it is virtual just as the one of the base class.
//
[0.x.1327] 
[0.x.1328] 
[0.x.1329] 
[0.x.1330] 
[0.x.1331] 
[0.x.1332] 
//
[0.x.1333] 
[0.x.1334] 
//
[0.x.1335] 
[0.x.1336] 
[0.x.1337] 
[0.x.1338] 
[0.x.1339] 
//
[0.x.1340] 
[0.x.1341] 
[0.x.1342] 
[0.x.1343] 
//
// As for the definition, the constructor is trivial, just taking data and storing it in object-local ones:
//
[0.x.1344] 
[0.x.1345] 
[0.x.1346] 
[0.x.1347] 
[0.x.1348] 
[0.x.1349] 
[0.x.1350] 
//
// Now for the function that is mainly of interest in this class, the computation of the point value:
//
[0.x.1351] 
[0.x.1352] 
[0.x.1353] 
[0.x.1354] 
[0.x.1355] 
//
// First allocate a variable that will hold the point value. Initialize it with a value that is clearly bogus, so that if we fail to set it to a reasonable value, we will note at once. This may not be necessary in a function as small as this one, since we can easily see all possible paths of execution here, but it proved to be helpful for more complex cases, and so we employ this strategy here as well.
//
[0.x.1356] 
//
// Then loop over all cells and all their vertices, and check whether a vertex matches the evaluation point. If this is the case, then extract the point value, set a flag that we have found the point of interest, and exit the loop.
//
[0.x.1357] 
[0.x.1358] 
[0.x.1359] 
[0.x.1360] 
[0.x.1361] 
[0.x.1362] 
//
//       In order to extract the point value from the global solution       vector, pick that component that belongs to the vertex of       interest, and, in case the solution is vector-valued, take       the first component of it:
//
[0.x.1363] 
//
//       Note that by this we have made an assumption that is not       valid always and should be documented in the class       declaration if this were code for a real application rather       than a tutorial program: we assume that the finite element       used for the solution we try to evaluate actually has degrees       of freedom associated with vertices. This, for example, does       not hold for discontinuous elements, were the support points       for the shape functions happen to be located at the vertices,       but are not associated with the vertices but rather with the       cell interior, since association with vertices would imply       continuity there. It would also not hold for edge oriented       elements, and the like.             Ideally, we would check this at the beginning of the       function, for example by a statement like <code>Assert       (dof_handler.get_fe().dofs_per_vertex  [2.x.192]  0,       ExcNotImplemented())</code>, which should make it quite clear       what is going wrong when the exception is triggered. In this       case, we omit it (which is indeed bad style), but knowing       that that does not hurt here, since the statement        [2.x.193]  would fail if       we asked it to give us the DoF index of a vertex if there       were none.             We stress again that this restriction on the allowed finite       elements should be stated in the class documentation.
//
//       Since we found the right point, we now set the respective       flag and exit the innermost loop. The outer loop will also be       terminated due to the set flag.
//
[0.x.1364] 
[0.x.1365] 
[0.x.1366] 
//
// Finally, we'd like to make sure that we have indeed found the evaluation point, since if that were not so we could not give a reasonable value of the solution there and the rest of the computations were useless anyway. So make sure through the  [2.x.194]  macro already used in the  [2.x.195]  program that we have indeed found this point. If this is not so, the macro throws an exception of the type that is given to it as second argument, but compared to a straightforward  [2.x.196]  statement, it fills the exception object with a set of additional information, for example the source file and line number where the exception was generated, and the condition that failed. If you have a  [2.x.197]  clause in your main function (as this program has), you will catch all exceptions that are not caught somewhere in between and thus already handled, and this additional information will help you find out what happened and where it went wrong.
//
[0.x.1367] 
[0.x.1368] 
//
// Note that we have used the  [2.x.198]  macro in other example programs as well. It differed from the  [2.x.199]  macro used here in that it simply aborts the program, rather than throwing an exception, and that it did so only in debug mode. It was the right macro to use to check about the size of vectors passed as arguments to functions, and the like.
//
// However, here the situation is different: whether we find the evaluation point or not may change from refinement to refinement (for example, if the four cells around point are coarsened away, then the point may vanish after refinement and coarsening). This is something that cannot be predicted from a few number of runs of the program in debug mode, but should be checked always, also in production runs. Thus the use of the  [2.x.200]  macro here.
//
// Now, if we are sure that we have found the evaluation point, we can add the results into the table of results:
//
[0.x.1369] 
[0.x.1370] 
[0.x.1371] 
//
//  [2.x.201] 
//
// A different, maybe slightly odd kind of  [2.x.202]  of a solution is to output it to a file in a graphical format. Since in the evaluation functions we are given a  [2.x.203]  object and the solution vector, we have all we need to do this, so we can do it in an evaluation class. The reason for actually doing so instead of putting it into the class that computed the solution is that this way we have more flexibility: if we choose to only output certain aspects of it, or not output it at all. In any case, we do not need to modify the solver class, we just have to modify one of the modules out of which we build this program. This form of encapsulation, as above, helps us to keep each part of the program rather simple as the interfaces are kept simple, and no access to hidden data is possible.
//
// Since this class which generates the output is derived from the common  [2.x.204]  base class, its main interface is the  [2.x.205]  function. Furthermore, it has a constructor taking a string that will be used as the base part of the file name to which output will be sent (we will augment it by a number indicating the number of the refinement cycle -- the base class has this information at hand --, and a suffix), and the constructor also takes a value that indicates which format is requested, i.e. for which graphics program we shall generate output (from this we will then also generate the suffix of the filename to which we write).
//
// Regarding the output format, the DataOutBase namespace provides an enumeration field  [2.x.206]  which lists names for all supported output formats. At the time of writing of this program, the supported graphics formats are represented by the enum values  [2.x.207] ,  [2.x.208] ,  [2.x.209] ,  [2.x.210] , etc, but this list will certainly grow over time. Now, within various functions of that base class, you can use values of this type to get information about these graphics formats (for example the default suffix used for files of each format), and you can call a generic  [2.x.211]  function, which then branches to the  [2.x.212] , etc functions which we have used in previous examples already, based on the value of a second argument given to it denoting the required output format. This mechanism makes it simple to write an extensible program that can decide which output format to use at runtime, and it also makes it rather simple to write the program in a way such that it takes advantage of newly implemented output formats, without the need to change the application program.
//
// Of these two fields, the base name and the output format descriptor, the constructor takes values and stores them for later use by the actual evaluation function.
//
[0.x.1372] 
[0.x.1373] 
[0.x.1374] 
[0.x.1375] 
[0.x.1376] 
[0.x.1377] 
//
[0.x.1378] 
[0.x.1379] 
//
[0.x.1380] 
[0.x.1381] 
[0.x.1382] 
[0.x.1383] 
//
[0.x.1384] 
[0.x.1385] 
[0.x.1386] 
[0.x.1387] 
[0.x.1388] 
[0.x.1389] 
[0.x.1390] 
//
// Following the description above, the function generating the actual output is now relatively straightforward. The only particularly interesting feature over previous example programs is the use of the  [2.x.213]  function, returning the usual suffix for files of a given format (e.g. ".eps" for encapsulated postscript files, ".gnuplot" for Gnuplot files), and of the generic  [2.x.214]  function with a second argument, which internally branches to the actual output functions for the different graphics formats, based on the value of the format descriptor passed as second argument.
//
// Also note that we have to prefix  [2.x.215]  to access a member variable of the template dependent base class. The reason here, and further down in the program is the same as the one described in the  [2.x.216]  example program (look for  [2.x.217]  there).
//
[0.x.1391] 
[0.x.1392] 
[0.x.1393] 
[0.x.1394] 
[0.x.1395] 
[0.x.1396] 
[0.x.1397] 
[0.x.1398] 
//
[0.x.1399] 
[0.x.1400] 
[0.x.1401] 
//
[0.x.1402] 
[0.x.1403] 
//
//  [2.x.218] 
//
// In practical applications, one would add here a list of other possible evaluation classes, representing quantities that one may be interested in. For this example, that much shall be sufficient, so we close the namespace.
//
[0.x.1404] 
//[2.x.219] 
//
// After defining what we want to know of the solution, we should now care how to get at it. We will pack everything we need into a namespace of its own, for much the same reasons as for the evaluations above.
//
// Since we have discussed Laplace solvers already in considerable detail in previous examples, there is not much new stuff following. Rather, we have to a great extent cannibalized previous examples and put them, in slightly different form, into this example program. We will therefore mostly be concerned with discussing the differences to previous examples.
//
// Basically, as already said in the introduction, the lack of new stuff in this example is deliberate, as it is more to demonstrate software design practices, rather than mathematics. The emphasis in explanations below will therefore be more on the actual implementation.
//
[0.x.1405] 
[0.x.1406] 
//[2.x.220] 
//
// In defining a Laplace solver, we start out by declaring an abstract base class, that has no functionality itself except for taking and storing a pointer to the triangulation to be used later.
//
// This base class is very general, and could as well be used for any other stationary problem. It provides declarations of functions that shall, in derived classes, solve a problem, postprocess the solution with a list of evaluation objects, and refine the grid, respectively. None of these functions actually does something itself in the base class.
//
// Due to the lack of actual functionality, the programming style of declaring very abstract base classes is similar to the style used in Smalltalk or Java programs, where all classes are derived from entirely abstract classes  [2.x.221] , even number representations. The author admits that he does not particularly like the use of such a style in C++, as it puts style over reason. Furthermore, it promotes the use of virtual functions for everything (for example, in Java, all functions are virtual per se), which, however, has proven to be rather inefficient in many applications where functions are often only accessing data, not doing computations, and therefore quickly return; the overhead of virtual functions can then be significant. The opinion of the author is to have abstract base classes wherever at least some part of the code of actual implementations can be shared and thus separated into the base class.
//
// Besides all these theoretical questions, we here have a good reason, which will become clearer to the reader below. Basically, we want to be able to have a family of different Laplace solvers that differ so much that no larger common subset of functionality could be found. We therefore just declare such an abstract base class, taking a pointer to a triangulation in the constructor and storing it henceforth. Since this triangulation will be used throughout all computations, we have to make sure that the triangulation is valid until it is last used. We do this by keeping a  [2.x.222]  to this triangulation, as explained in  [2.x.223] .
//
// Note that while the pointer itself is declared constant (i.e. throughout the lifetime of this object, the pointer points to the same object), it is not declared as a pointer to a constant triangulation. In fact, by this we allow that derived classes refine or coarsen the triangulation within the  [2.x.224]  function.
//
// Finally, we have a function  [2.x.225]  is only a tool for the driver functions to decide whether we want to go on with mesh refinement or not. It returns the number of degrees of freedom the present simulation has.
//
[0.x.1407] 
[0.x.1408] 
[0.x.1409] 
[0.x.1410] 
[0.x.1411] 
[0.x.1412] 
//
[0.x.1413] 
[0.x.1414] 
[0.x.1415] 
[0.x.1416] 
[0.x.1417] 
//
[0.x.1418] 
[0.x.1419] 
[0.x.1420] 
//
// The implementation of the only two non-abstract functions is then rather boring:
//
[0.x.1421] 
[0.x.1422] 
[0.x.1423] 
[0.x.1424] 
//[2.x.226] 
//
// Following now the main class that implements assembling the matrix of the linear system, solving it, and calling the postprocessor objects on the solution. It implements the  [2.x.227]  and  [2.x.228]  functions declared in the base class. It does not, however, implement the  [2.x.229]  method, as mesh refinement will be implemented in a number of derived classes.
//
// It also declares a new abstract virtual function,  [2.x.230] , that needs to be overloaded in subclasses. The reason is that we will implement two different classes that will implement different methods to assemble the right hand side vector. This function might also be interesting in cases where the right hand side depends not simply on a continuous function, but on something else as well, for example the solution of another discretized problem, etc. The latter happens frequently in non-linear problems.
//
// As we mentioned previously, the actual content of this class is not new, but a mixture of various techniques already used in previous examples. We will therefore not discuss them in detail, but refer the reader to these programs.
//
// Basically, in a few words, the constructor of this class takes pointers to a triangulation, a finite element, and a function object representing the boundary values. These are either passed down to the base class's constructor, or are stored and used to generate a  [2.x.231]  object later. Since finite elements and quadrature formula should match, it is also passed a quadrature object.
//
// The  [2.x.232]  sets up the data structures for the actual solution, calls the functions to assemble the linear system, and solves it.
//
// The  [2.x.233]  function finally takes an evaluation object and applies it to the computed solution.
//
// The  [2.x.234]  function finally implements the pure virtual function of the base class.
//
[0.x.1425] 
[0.x.1426] 
[0.x.1427] 
[0.x.1428] 
[0.x.1429] 
[0.x.1430] 
[0.x.1431] 
[0.x.1432] 
[0.x.1433] 
//
[0.x.1434] 
//
[0.x.1435] 
[0.x.1436] 
//
[0.x.1437] 
//
// In the protected section of this class, we first have a number of member variables, of which the use should be clear from the previous examples:
//
[0.x.1438] 
[0.x.1439] 
[0.x.1440] 
[0.x.1441] 
[0.x.1442] 
[0.x.1443] 
//
// Then we declare an abstract function that will be used to assemble the right hand side. As explained above, there are various cases for which this action differs strongly in what is necessary, so we defer this to derived classes:
//
[0.x.1444] 
//
// Next, in the private section, we have a small class which represents an entire linear system, i.e. a matrix, a right hand side, and a solution vector, as well as the constraints that are applied to it, such as those due to hanging nodes. Its constructor initializes the various subobjects, and there is a function that implements a conjugate gradient method as solver.
//
[0.x.1445] 
[0.x.1446] 
[0.x.1447] 
[0.x.1448] 
//
[0.x.1449] 
//
[0.x.1450] 
[0.x.1451] 
[0.x.1452] 
[0.x.1453] 
[0.x.1454] 
//
// Finally, there is a set of functions which will be used to assemble the actual system matrix. The main function of this group,  [2.x.235]  computes the matrix in parallel on multicore systems, using the following two helper functions. The mechanism for doing so is the same as in the  [2.x.236]  example program and follows the WorkStream concept outlined in  [2.x.237]  . The main function also calls the virtual function assembling the right hand side.
//
[0.x.1455] 
[0.x.1456] 
[0.x.1457] 
[0.x.1458] 
[0.x.1459] 
//
[0.x.1460] 
[0.x.1461] 
//
[0.x.1462] 
[0.x.1463] 
[0.x.1464] 
[0.x.1465] 
[0.x.1466] 
//
[0.x.1467] 
//
[0.x.1468] 
[0.x.1469] 
[0.x.1470] 
[0.x.1471] 
//
[0.x.1472] 
[0.x.1473] 
[0.x.1474] 
//
// Now here comes the constructor of the class. It does not do much except store pointers to the objects given, and generate  [2.x.238]  object initialized with the given pointer to a triangulation. This causes the DoF handler to store that pointer, but does not already generate a finite element numbering (we only ask for that in the  [2.x.239]  function).
//
[0.x.1475] 
[0.x.1476] 
[0.x.1477] 
[0.x.1478] 
[0.x.1479] 
[0.x.1480] 
[0.x.1481] 
[0.x.1482] 
[0.x.1483] 
[0.x.1484] 
[0.x.1485] 
//
// The destructor is simple, it only clears the information stored in the DoF handler object to release the memory.
//
[0.x.1486] 
[0.x.1487] 
[0.x.1488] 
[0.x.1489] 
[0.x.1490] 
//
// The next function is the one which delegates the main work in solving the problem: it sets up the DoF handler object with the finite element given to the constructor of this object, the creates an object that denotes the linear system (i.e. the matrix, the right hand side vector, and the solution vector), calls the function to assemble it, and finally solves it:
//
[0.x.1491] 
[0.x.1492] 
[0.x.1493] 
[0.x.1494] 
[0.x.1495] 
//
[0.x.1496] 
[0.x.1497] 
[0.x.1498] 
[0.x.1499] 
//
// As stated above, the  [2.x.240]  function takes an evaluation object, and applies it to the computed solution. This function may be called multiply, once for each evaluation of the solution which the user required.
//
[0.x.1500] 
[0.x.1501] 
[0.x.1502] 
[0.x.1503] 
[0.x.1504] 
[0.x.1505] 
//
// The  [2.x.241]  function should be self-explanatory:
//
[0.x.1506] 
[0.x.1507] 
[0.x.1508] 
[0.x.1509] 
[0.x.1510] 
//
// The following function assembles matrix and right hand side of the linear system to be solved in each step. We will do things in parallel at a couple of levels. First, note that we need to assemble both the matrix and the right hand side. These are independent operations, and we should do this in parallel. To this end, we use the concept of "tasks" that is discussed in the  [2.x.242]  documentation module. In essence, what we want to say "here is something that needs to be worked on, go do it whenever a CPU core is available", then do something else, and when we need the result of the first operation wait for its completion. At the second level, we want to assemble the matrix using the exact same strategy we have already used in  [2.x.243] , namely the WorkStream concept.
//
// While we could consider either assembling the right hand side or assembling the matrix as the thing to do in the background while doing the other, we will opt for the former approach simply because the call to  [2.x.244]  is so much simpler to write than the call to  [2.x.245]  with its many arguments. In any case, the code then looks like this to assemble the entire linear system:
//
[0.x.1511] 
[0.x.1512] 
[0.x.1513] 
[0.x.1514] 
[0.x.1515] 
//
[0.x.1516] 
[0.x.1517] 
[0.x.1518] 
[0.x.1519] 
[0.x.1520] 
[0.x.1521] 
//
[0.x.1522] 
[0.x.1523] 
[0.x.1524] 
//
[0.x.1525] 
[0.x.1526] 
[0.x.1527] 
[0.x.1528] 
[0.x.1529] 
[0.x.1530] 
[0.x.1531] 
//
// The syntax above requires some explanation. There are multiple version of  [2.x.246]  that expect different arguments. In  [2.x.247] , we used one version that took a pair of iterators, a pair of pointers to member functions with very specific argument lists, a pointer or reference to the object on which these member functions have to work, and a scratch and copy data object. This is a bit restrictive since the member functions called this way have to have an argument list that exactly matches what  [2.x.248]  expects: the local assembly function needs to take an iterator, a scratch object and a copy object; and the copy-local-to-global function needs to take exactly a copy object. But, what if we want something that's slightly more general? For example, in the current program, the copy-local-to-global function needs to know which linear system object to write the local contributions into, i.e., it also has to take a  [2.x.249]  argument. That won't work with the approach using member function pointers.
//
// Fortunately, C++ offers a way out. These are called function objects. In essence, what  [2.x.250]  wants to do is not call a member function. It wants to call some function that takes an iterator, a scratch object and a copy object in the first case, and a copy object in the second case. Whether these are member functions, global functions, or something else, is really not of much concern to WorkStream. Consequently, there is a second version of the function that just takes function objects -- objects that have an  [2.x.251]  and that consequently can be called like functions, whatever they really represent. The typical way to generate such function objects is using a [1.x.8] that wraps the function call including the individual arguments with fixed values. All the arguments that are part of the outer function signature are specified as regular function arguments in the lambda function. The fixed values are passed into the lambda function using the capture list (`[...]`). It is possible to use a capture default or to list all the variables that are to be bound to the lambda explicitly. For the sake of clarity we decided to omit the capture default here, but that capture list could equally well be `[&]`, meaning that all used variables are copied into the lambda by reference.
//
// At this point, we have assembled the matrix and condensed it. The right hand side may or may not have been completely assembled, but we would like to condense the right hand side vector next. We can only do this if the assembly of this vector has finished, so we have to wait for the task to finish; in computer science, waiting for a task is typically called "joining" the task, explaining the name of the function we call below.
//
// Since that task may or may not have finished, and since we may have to wait for it to finish, we may as well try to pack other things that need to be done anyway into this gap. Consequently, we first interpolate boundary values before we wait for the right hand side. Of course, another possibility would have been to also interpolate the boundary values on a separate task since doing so is independent of the other things we have done in this function so far. Feel free to find the correct syntax to also create a task for this interpolation and start it at the top of this function, along with the assembly of the right hand side. (You will find that this is slightly more complicated since there are multiple versions of  [2.x.252]  and so simply taking the address  [2.x.253]  produces a set of overloaded functions that can't be passed to  [2.x.254]  right away -- you have to select which element of this overload set you want by casting the address expression to a function pointer type that is specific to the version of the function that you want to call on the task.)
//
[0.x.1532] 
[0.x.1533] 
[0.x.1534] 
[0.x.1535] 
[0.x.1536] 
//
[0.x.1537] 
[0.x.1538] 
//
// Now that we have the complete linear system, we can also treat boundary values, which need to be eliminated from both the matrix and the right hand side:
//
[0.x.1539] 
[0.x.1540] 
[0.x.1541] 
[0.x.1542] 
[0.x.1543] 
//
// The second half of this set of functions deals with the local assembly on each cell and copying local contributions into the global matrix object. This works in exactly the same way as described in  [2.x.255] :
//
[0.x.1544] 
[0.x.1545] 
[0.x.1546] 
[0.x.1547] 
[0.x.1548] 
[0.x.1549] 
//
[0.x.1550] 
[0.x.1551] 
[0.x.1552] 
[0.x.1553] 
[0.x.1554] 
[0.x.1555] 
[0.x.1556] 
//
[0.x.1557] 
[0.x.1558] 
[0.x.1559] 
[0.x.1560] 
[0.x.1561] 
[0.x.1562] 
[0.x.1563] 
[0.x.1564] 
//
[0.x.1565] 
//
[0.x.1566] 
//
[0.x.1567] 
//
[0.x.1568] 
[0.x.1569] 
[0.x.1570] 
[0.x.1571] 
[0.x.1572] 
[0.x.1573] 
[0.x.1574] 
//
[0.x.1575] 
[0.x.1576] 
//
[0.x.1577] 
[0.x.1578] 
[0.x.1579] 
[0.x.1580] 
[0.x.1581] 
[0.x.1582] 
[0.x.1583] 
[0.x.1584] 
[0.x.1585] 
[0.x.1586] 
//
// Now for the functions that implement actions in the linear system class. First, the constructor initializes all data elements to their correct sizes, and sets up a number of additional data structures, such as constraints due to hanging nodes. Since setting up the hanging nodes and finding out about the nonzero elements of the matrix is independent, we do that in parallel (if the library was configured to use concurrency, at least; otherwise, the actions are performed sequentially). Note that we start only one thread, and do the second action in the main thread. Since only one task is generated, we don't use the  [2.x.256]  class here, but rather use the one created task object directly to wait for this particular task's exit.
//
// Note that taking up the address of the  [2.x.257]  function is a little tricky, since there are actually three of them, one for each supported space dimension. Taking addresses of overloaded functions is somewhat complicated in C++, since the address-of operator  [2.x.258]  in that case returns more like a set of values (the addresses of all functions with that name), and selecting the right one is then the next step. If the context dictates which one to take (for example by assigning to a function pointer of known type), then the compiler can do that by itself, but if this set of pointers shall be given as the argument to a function that takes a template, the compiler could choose all without having a preference for one. We therefore have to make it clear to the compiler which one we would like to have; for this, we could use a cast, but for more clarity, we assign it to a temporary  [2.x.259]  (short for <code>pointer to make_hanging_node_constraints</code>) with the right type, and using this pointer instead.
//
[0.x.1587] 
[0.x.1588] 
[0.x.1589] 
[0.x.1590] 
//
[0.x.1591] 
[0.x.1592] 
//
// Start a side task then continue on the main thread
//
[0.x.1593] 
[0.x.1594] 
//
[0.x.1595] 
[0.x.1596] 
//
// Wait for the side task to be done before going further
//
[0.x.1597] 
//
[0.x.1598] 
[0.x.1599] 
[0.x.1600] 
//
// Finally initialize the matrix and right hand side vector
//
[0.x.1601] 
[0.x.1602] 
[0.x.1603] 
//
// The second function of this class simply solves the linear system by a preconditioned conjugate gradient method. This has been extensively discussed before, so we don't dwell into it any more.
//
[0.x.1604] 
[0.x.1605] 
[0.x.1606] 
[0.x.1607] 
[0.x.1608] 
//
[0.x.1609] 
[0.x.1610] 
//
[0.x.1611] 
//
[0.x.1612] 
[0.x.1613] 
//
//  [2.x.260] 
//
// In the previous section, a base class for Laplace solvers was implemented, that lacked the functionality to assemble the right hand side vector, however, for reasons that were explained there. Now we implement a corresponding class that can do this for the case that the right hand side of a problem is given as a function object.
//
// The actions of the class are rather what you have seen already in previous examples already, so a brief explanation should suffice: the constructor takes the same data as does that of the underlying class (to which it passes all information) except for one function object that denotes the right hand side of the problem. A pointer to this object is stored (again as a  [2.x.261] , in order to make sure that the function object is not deleted as long as it is still used by this class).
//
// The only functional part of this class is the  [2.x.262]  method that does what its name suggests.
//
[0.x.1614] 
[0.x.1615] 
[0.x.1616] 
[0.x.1617] 
[0.x.1618] 
[0.x.1619] 
[0.x.1620] 
[0.x.1621] 
[0.x.1622] 
//
[0.x.1623] 
[0.x.1624] 
[0.x.1625] 
[0.x.1626] 
//
// The constructor of this class basically does what it is announced to do above...
//
[0.x.1627] 
[0.x.1628] 
[0.x.1629] 
[0.x.1630] 
[0.x.1631] 
[0.x.1632] 
[0.x.1633] 
[0.x.1634] 
[0.x.1635] 
[0.x.1636] 
//
// ... as does the  [2.x.263]  function. Since this is explained in several of the previous example programs, we leave it at that.
//
[0.x.1637] 
[0.x.1638] 
[0.x.1639] 
[0.x.1640] 
[0.x.1641] 
[0.x.1642] 
[0.x.1643] 
//
[0.x.1644] 
[0.x.1645] 
//
[0.x.1646] 
[0.x.1647] 
[0.x.1648] 
//
[0.x.1649] 
[0.x.1650] 
[0.x.1651] 
[0.x.1652] 
[0.x.1653] 
[0.x.1654] 
//
[0.x.1655] 
[0.x.1656] 
[0.x.1657] 
[0.x.1658] 
[0.x.1659] 
//
[0.x.1660] 
[0.x.1661] 
[0.x.1662] 
[0.x.1663] 
[0.x.1664] 
//[2.x.264] 
//
// By now, all functions of the abstract base class except for the  [2.x.265]  function have been implemented. We will now have two classes that implement this function for the  [2.x.266]  class, one doing global refinement, one a form of local refinement.
//
// The first, doing global refinement, is rather simple: its main function just calls  [2.x.267] , which does all the work.
//
// Note that since the  [2.x.268]  base class of the  [2.x.269]  class is virtual, we have to declare a constructor that initializes the immediate base class as well as the abstract virtual one.
//
// Apart from this technical complication, the class is probably simple enough to be left without further comments.
//
[0.x.1665] 
[0.x.1666] 
[0.x.1667] 
[0.x.1668] 
[0.x.1669] 
[0.x.1670] 
[0.x.1671] 
[0.x.1672] 
[0.x.1673] 
//
[0.x.1674] 
[0.x.1675] 
//
[0.x.1676] 
[0.x.1677] 
[0.x.1678] 
[0.x.1679] 
[0.x.1680] 
[0.x.1681] 
[0.x.1682] 
[0.x.1683] 
[0.x.1684] 
[0.x.1685] 
[0.x.1686] 
[0.x.1687] 
[0.x.1688] 
[0.x.1689] 
//
[0.x.1690] 
[0.x.1691] 
[0.x.1692] 
[0.x.1693] 
[0.x.1694] 
//[2.x.270] 
//
// The second class implementing refinement strategies uses the Kelly refinement indicator used in various example programs before. Since this indicator is already implemented in a class of its own inside the deal.II library, there is not much t do here except cal the function computing the indicator, then using it to select a number of cells for refinement and coarsening, and refinement the mesh accordingly.
//
// Again, this should now be sufficiently standard to allow the omission of further comments.
//
[0.x.1695] 
[0.x.1696] 
[0.x.1697] 
[0.x.1698] 
[0.x.1699] 
[0.x.1700] 
[0.x.1701] 
[0.x.1702] 
[0.x.1703] 
//
[0.x.1704] 
[0.x.1705] 
//
[0.x.1706] 
[0.x.1707] 
[0.x.1708] 
[0.x.1709] 
[0.x.1710] 
[0.x.1711] 
[0.x.1712] 
[0.x.1713] 
[0.x.1714] 
[0.x.1715] 
[0.x.1716] 
[0.x.1717] 
[0.x.1718] 
//
[0.x.1719] 
[0.x.1720] 
[0.x.1721] 
[0.x.1722] 
[0.x.1723] 
[0.x.1724] 
[0.x.1725] 
[0.x.1726] 
[0.x.1727] 
[0.x.1728] 
[0.x.1729] 
[0.x.1730] 
[0.x.1731] 
[0.x.1732] 
[0.x.1733] 
[0.x.1734] 
[0.x.1735] 
//
[0.x.1736] 
//
//  [2.x.271] 
//
// As this is one more academic example, we'd like to compare exact and computed solution against each other. For this, we need to declare function classes representing the exact solution (for comparison and for the Dirichlet boundary values), as well as a class that denotes the right hand side of the equation (this is simply the Laplace operator applied to the exact solution we'd like to recover).
//
// For this example, let us choose as exact solution the function  [2.x.272] . In more than two dimensions, simply repeat the sine-factor with  [2.x.273]  and so on. Given this, the following two classes are probably straightforward from the previous examples.
//
[0.x.1737] 
[0.x.1738] 
[0.x.1739] 
[0.x.1740] 
[0.x.1741] 
[0.x.1742] 
[0.x.1743] 
//
[0.x.1744] 
[0.x.1745] 
[0.x.1746] 
[0.x.1747] 
[0.x.1748] 
[0.x.1749] 
[0.x.1750] 
[0.x.1751] 
[0.x.1752] 
[0.x.1753] 
[0.x.1754] 
[0.x.1755] 
//
[0.x.1756] 
[0.x.1757] 
[0.x.1758] 
[0.x.1759] 
[0.x.1760] 
[0.x.1761] 
[0.x.1762] 
//
[0.x.1763] 
[0.x.1764] 
[0.x.1765] 
[0.x.1766] 
[0.x.1767] 
[0.x.1768] 
[0.x.1769] 
[0.x.1770] 
[0.x.1771] 
[0.x.1772] 
[0.x.1773] 
[0.x.1774] 
[0.x.1775] 
[0.x.1776] 
[0.x.1777] 
[0.x.1778] 
[0.x.1779] 
[0.x.1780] 
[0.x.1781] 
[0.x.1782] 
[0.x.1783] 
//
[0.x.1784] 
[0.x.1785] 
//
//  [2.x.274] 
//
// What is now missing are only the functions that actually select the various options, and run the simulation on successively finer grids to monitor the progress as the mesh is refined.
//
// This we do in the following function: it takes a solver object, and a list of postprocessing (evaluation) objects, and runs them with intermittent mesh refinement:
//
[0.x.1786] 
[0.x.1787] 
[0.x.1788] 
[0.x.1789] 
[0.x.1790] 
//
// We will give an indicator of the step we are presently computing, in order to keep the user informed that something is still happening, and that the program is not in an endless loop. This is the head of this status line:
//
[0.x.1791] 
//
// Then start a loop which only terminates once the number of degrees of freedom is larger than 20,000 (you may of course change this limit, if you need more -- or less -- accuracy from your program).
//
[0.x.1792] 
[0.x.1793] 
//
// Then give the  [2.x.275]  indication for this iteration. Note that the  [2.x.276]  is needed to have the text actually appear on the screen, rather than only in some buffer that is only flushed the next time we issue an end-line.
//
[0.x.1794] 
//
// Now solve the problem on the present grid, and run the evaluators on it. The long type name of iterators into the list is a little annoying, but could be shortened by an alias, if so desired.
//
[0.x.1795] 
//
[0.x.1796] 
[0.x.1797] 
[0.x.1798] 
[0.x.1799] 
[0.x.1800] 
//
// Now check whether more iterations are required, or whether the loop shall be ended:
//
[0.x.1801] 
[0.x.1802] 
[0.x.1803] 
[0.x.1804] 
[0.x.1805] 
//
// Finally end the line in which we displayed status reports:
//
[0.x.1806] 
[0.x.1807] 
//
// The final function is one which takes the name of a solver (presently "kelly" and "global" are allowed), creates a solver object out of it using a coarse grid (in this case the ubiquitous unit square) and a finite element object (here the likewise ubiquitous bilinear one), and uses that solver to ask for the solution of the problem on a sequence of successively refined grids.
//
// The function also sets up two of evaluation functions, one evaluating the solution at the point (0.5,0.5), the other writing out the solution to a file.
//
[0.x.1808] 
[0.x.1809] 
[0.x.1810] 
//
// First minor task: tell the user what is going to happen. Thus write a header line, and a line with all '-' characters of the same length as the first one right below.
//
[0.x.1811] 
[0.x.1812] 
[0.x.1813] 
[0.x.1814] 
//
// Then set up triangulation, finite element, etc.
//
[0.x.1815] 
[0.x.1816] 
[0.x.1817] 
[0.x.1818] 
[0.x.1819] 
[0.x.1820] 
[0.x.1821] 
//
// Create a solver object of the kind indicated by the argument to this function. If the name is not recognized, throw an exception! The respective solver object is stored in a  [2.x.277]  to avoid having to delete the pointer after use.
//
[0.x.1822] 
[0.x.1823] 
[0.x.1824] 
[0.x.1825] 
[0.x.1826] 
[0.x.1827] 
[0.x.1828] 
[0.x.1829] 
[0.x.1830] 
//
// Next create a table object in which the values of the numerical solution at the point (0.5,0.5) will be stored, and create a respective evaluation object:
//
[0.x.1831] 
[0.x.1832] 
[0.x.1833] 
//
// Also generate an evaluator which writes out the solution:
//
[0.x.1834] 
[0.x.1835] 
[0.x.1836] 
//
// Take these two evaluation objects and put them in a list...
//
[0.x.1837] 
[0.x.1838] 
[0.x.1839] 
//
// ... which we can then pass on to the function that actually runs the simulation on successively refined grids:
//
[0.x.1840] 
//
// When this all is done, write out the results of the point evaluations:
//
[0.x.1841] 
//
// And one blank line after all results:
//
[0.x.1842] 
[0.x.1843] 
[0.x.1844] 
//
// There is not much to say about the main function. It follows the same pattern as in all previous examples, with attempts to catch thrown exceptions, and displaying as much information as possible if we should get some. The rest is self-explanatory.
//
[0.x.1845] 
[0.x.1846] 
[0.x.1847] 
[0.x.1848] 
[0.x.1849] 
[0.x.1850] 
[0.x.1851] 
[0.x.1852] 
[0.x.1853] 
[0.x.1854] 
[0.x.1855] 
[0.x.1856] 
[0.x.1857] 
[0.x.1858] 
[0.x.1859] 
[0.x.1860] 
[0.x.1861] 
[0.x.1862] 
[0.x.1863] 
[0.x.1864] 
[0.x.1865] 
[0.x.1866] 
[0.x.1867] 
[0.x.1868] 
[0.x.1869] 
[0.x.1870] 
[0.x.1871] 
[0.x.1872] 
[0.x.1873] 
[0.x.1874] 
[0.x.1875] 
[0.x.1876] 
//
[0.x.1877] 
[0.x.1878] 
[0.x.1879] 
[0.x.1880] 
[0.x.1881] 
[0.x.1882] 
[0.x.1883] 
[0.x.1884] 
[0.x.1885] 
[0.x.1886] 
[0.x.1887] 
[0.x.1888] 
[0.x.1889] 
[0.x.1890] 
[0.x.1891] 
[0.x.1892] 
//
[0.x.1893] 
[0.x.1894] 
[0.x.1895] 
//
// Start out with well known things...
//
[0.x.1896] 
[0.x.1897] 
[0.x.1898] 
[0.x.1899] 
[0.x.1900] 
[0.x.1901] 
[0.x.1902] 
[0.x.1903] 
[0.x.1904] 
[0.x.1905] 
[0.x.1906] 
[0.x.1907] 
[0.x.1908] 
[0.x.1909] 
[0.x.1910] 
[0.x.1911] 
[0.x.1912] 
[0.x.1913] 
[0.x.1914] 
[0.x.1915] 
[0.x.1916] 
[0.x.1917] 
[0.x.1918] 
[0.x.1919] 
[0.x.1920] 
//
[0.x.1921] 
[0.x.1922] 
[0.x.1923] 
[0.x.1924] 
[0.x.1925] 
[0.x.1926] 
//
// The last step is as in all previous programs:
//
[0.x.1927] 
[0.x.1928] 
[0.x.1929] 
//[2.x.278] 
//
// As mentioned in the introduction, significant parts of the program have simply been taken over from the  [2.x.279]  example program. We therefore only comment on those things that are new.
//
// First, the framework for evaluation of solutions is unchanged, i.e. the base class is the same, and the class to evaluate the solution at a grid point is unchanged:
//
[0.x.1930] 
[0.x.1931] 
//[2.x.280] 
[0.x.1932] 
[0.x.1933] 
[0.x.1934] 
[0.x.1935] 
[0.x.1936] 
//
[0.x.1937] 
//
[0.x.1938] 
[0.x.1939] 
//
[0.x.1940] 
[0.x.1941] 
[0.x.1942] 
//
[0.x.1943] 
[0.x.1944] 
[0.x.1945] 
[0.x.1946] 
[0.x.1947] 
//[2.x.281] 
[0.x.1948] 
[0.x.1949] 
[0.x.1950] 
[0.x.1951] 
[0.x.1952] 
//
[0.x.1953] 
[0.x.1954] 
//
[0.x.1955] 
[0.x.1956] 
[0.x.1957] 
[0.x.1958] 
[0.x.1959] 
//
[0.x.1960] 
[0.x.1961] 
[0.x.1962] 
//
[0.x.1963] 
[0.x.1964] 
[0.x.1965] 
[0.x.1966] 
[0.x.1967] 
//
[0.x.1968] 
[0.x.1969] 
[0.x.1970] 
[0.x.1971] 
[0.x.1972] 
[0.x.1973] 
//
[0.x.1974] 
[0.x.1975] 
[0.x.1976] 
[0.x.1977] 
[0.x.1978] 
[0.x.1979] 
[0.x.1980] 
[0.x.1981] 
//
[0.x.1982] 
[0.x.1983] 
[0.x.1984] 
//
[0.x.1985] 
[0.x.1986] 
//
[0.x.1987] 
[0.x.1988] 
//[2.x.282] 
//
// Besides the class implementing the evaluation of the solution at one point, we here provide one which evaluates the gradient at a grid point. Since in general the gradient of a finite element function is not continuous at a vertex, we have to be a little bit more careful here. What we do is to loop over all cells, even if we have found the point already on one cell, and use the mean value of the gradient at the vertex taken from all adjacent cells.
//
// Given the interface of the  [2.x.283]  class, the declaration of this class provides little surprise, and neither does the constructor:
//
[0.x.1989] 
[0.x.1990] 
[0.x.1991] 
[0.x.1992] 
[0.x.1993] 
//
[0.x.1994] 
[0.x.1995] 
//
[0.x.1996] 
[0.x.1997] 
[0.x.1998] 
[0.x.1999] 
[0.x.2000] 
//
[0.x.2001] 
[0.x.2002] 
[0.x.2003] 
//
[0.x.2004] 
[0.x.2005] 
[0.x.2006] 
[0.x.2007] 
[0.x.2008] 
//
// The more interesting things happen inside the function doing the actual evaluation:
//
[0.x.2009] 
[0.x.2010] 
[0.x.2011] 
[0.x.2012] 
[0.x.2013] 
//
// This time initialize the return value with something useful, since we will have to add up a number of contributions and take the mean value afterwards...
//
[0.x.2014] 
//
// ...then have some objects of which the meaning will become clear below...
//
[0.x.2015] 
[0.x.2016] 
[0.x.2017] 
[0.x.2018] 
[0.x.2019] 
//
// ...and next loop over all cells and their vertices, and count how often the vertex has been found:
//
[0.x.2020] 
[0.x.2021] 
[0.x.2022] 
[0.x.2023] 
[0.x.2024] 
//
//     Things are now no more as simple, since we can't get the     gradient of the finite element field as before, where we     simply had to pick one degree of freedom at a vertex.         Rather, we have to evaluate the finite element field on this     cell, and at a certain point. As you know, evaluating finite     element fields at certain points is done through the      [2.x.284]  class, so we use that. The question is:     the  [2.x.285]  object needs to be a given a     quadrature formula and can then compute the values of finite     element quantities at the quadrature points. Here, we don't     want to do quadrature, we simply want to specify some points!         Nevertheless, the same way is chosen: use a special     quadrature rule with points at the vertices, since these are     what we are interested in. The appropriate rule is the     trapezoidal rule, so that is the reason why we used that one     above.         Thus: initialize the  [2.x.286]  object on this     cell,
//
[0.x.2025] 
//
//     and extract the gradients of the solution vector at the     vertices:
//
[0.x.2026] 
//
//     Now we have the gradients at all vertices, so pick out that     one which belongs to the evaluation point (note that the     order of vertices is not necessarily the same as that of the     quadrature points):
//
[0.x.2027] 
[0.x.2028] 
[0.x.2029] 
[0.x.2030] 
//
//     Check that the evaluation point was indeed found,
//
[0.x.2031] 
//
//     and if so take the x-derivative of the gradient there as the     value which we are interested in, and increase the counter     indicating how often we have added to that variable:
//
[0.x.2032] 
[0.x.2033] 
//
//     Finally break out of the innermost loop iterating over the     vertices of the present cell, since if we have found the     evaluation point at one vertex it cannot be at a following     vertex as well:
//
[0.x.2034] 
[0.x.2035] 
//
// Now we have looped over all cells and vertices, so check whether the point was found:
//
[0.x.2036] 
[0.x.2037] 
//
// We have simply summed up the contributions of all adjacent cells, so we still have to compute the mean value. Once this is done, report the status:
//
[0.x.2038] 
[0.x.2039] 
[0.x.2040] 
//
//  [2.x.287] 
//
// Since this program has a more difficult structure (it computed a dual solution in addition to a primal one), writing out the solution is no more done by an evaluation object since we want to write both solutions at once into one file, and that requires some more information than available to the evaluation classes.
//
// However, we also want to look at the grids generated. This again can be done with one such class. Its structure is analog to the  [2.x.288]  class of the previous example program, so we do not discuss it here in more detail. Furthermore, everything that is used here has already been used in previous example programs.
//
[0.x.2041] 
[0.x.2042] 
[0.x.2043] 
[0.x.2044] 
[0.x.2045] 
//
[0.x.2046] 
[0.x.2047] 
//
[0.x.2048] 
[0.x.2049] 
[0.x.2050] 
//
[0.x.2051] 
[0.x.2052] 
[0.x.2053] 
[0.x.2054] 
//
[0.x.2055] 
[0.x.2056] 
[0.x.2057] 
[0.x.2058] 
[0.x.2059] 
[0.x.2060] 
[0.x.2061] 
[0.x.2062] 
[0.x.2063] 
//[2.x.289] 
//
// Next are the actual solver classes. Again, we discuss only the differences to the previous program.
//
[0.x.2064] 
[0.x.2065] 
//[2.x.290] 
//
// This class is almost unchanged, with the exception that it declares two more functions:  [2.x.291]  will be used to generate output files from the actual solutions computed by derived classes, and the  [2.x.292]  function by which the testing framework sets the number of the refinement cycle to a local variable in this class; this number is later used to generate filenames for the solution output.
//
[0.x.2066] 
[0.x.2067] 
[0.x.2068] 
[0.x.2069] 
[0.x.2070] 
[0.x.2071] 
//
[0.x.2072] 
[0.x.2073] 
[0.x.2074] 
[0.x.2075] 
[0.x.2076] 
//
[0.x.2077] 
//
[0.x.2078] 
//
[0.x.2079] 
[0.x.2080] 
//
[0.x.2081] 
[0.x.2082] 
//
[0.x.2083] 
[0.x.2084] 
[0.x.2085] 
[0.x.2086] 
[0.x.2087] 
//
[0.x.2088] 
[0.x.2089] 
[0.x.2090] 
[0.x.2091] 
[0.x.2092] 
//[2.x.293] 
//
// Likewise, the  [2.x.294]  class is entirely unchanged and will thus not be discussed.
//
[0.x.2093] 
[0.x.2094] 
[0.x.2095] 
[0.x.2096] 
[0.x.2097] 
[0.x.2098] 
[0.x.2099] 
[0.x.2100] 
[0.x.2101] 
[0.x.2102] 
//
[0.x.2103] 
//
[0.x.2104] 
[0.x.2105] 
//
[0.x.2106] 
//
[0.x.2107] 
[0.x.2108] 
[0.x.2109] 
[0.x.2110] 
[0.x.2111] 
[0.x.2112] 
[0.x.2113] 
//
[0.x.2114] 
//
[0.x.2115] 
[0.x.2116] 
[0.x.2117] 
[0.x.2118] 
//
[0.x.2119] 
//
[0.x.2120] 
[0.x.2121] 
[0.x.2122] 
[0.x.2123] 
[0.x.2124] 
//
// The remainder of the class is essentially a copy of  [2.x.295]  as well, including the data structures and functions necessary to compute the linear system in parallel using the WorkStream framework:
//
[0.x.2125] 
[0.x.2126] 
[0.x.2127] 
[0.x.2128] 
[0.x.2129] 
//
[0.x.2130] 
[0.x.2131] 
//
[0.x.2132] 
[0.x.2133] 
[0.x.2134] 
[0.x.2135] 
[0.x.2136] 
//
[0.x.2137] 
//
[0.x.2138] 
[0.x.2139] 
[0.x.2140] 
[0.x.2141] 
//
[0.x.2142] 
[0.x.2143] 
[0.x.2144] 
//
[0.x.2145] 
[0.x.2146] 
[0.x.2147] 
[0.x.2148] 
[0.x.2149] 
[0.x.2150] 
[0.x.2151] 
[0.x.2152] 
[0.x.2153] 
[0.x.2154] 
[0.x.2155] 
[0.x.2156] 
[0.x.2157] 
//
[0.x.2158] 
[0.x.2159] 
[0.x.2160] 
[0.x.2161] 
[0.x.2162] 
//
[0.x.2163] 
[0.x.2164] 
[0.x.2165] 
[0.x.2166] 
[0.x.2167] 
//
[0.x.2168] 
[0.x.2169] 
[0.x.2170] 
[0.x.2171] 
//
[0.x.2172] 
[0.x.2173] 
[0.x.2174] 
[0.x.2175] 
[0.x.2176] 
[0.x.2177] 
//
[0.x.2178] 
[0.x.2179] 
[0.x.2180] 
[0.x.2181] 
[0.x.2182] 
//
// The following few functions and constructors are verbatim copies taken from  [2.x.296] :
//
[0.x.2183] 
[0.x.2184] 
[0.x.2185] 
[0.x.2186] 
[0.x.2187] 
//
[0.x.2188] 
[0.x.2189] 
[0.x.2190] 
[0.x.2191] 
[0.x.2192] 
[0.x.2193] 
//
[0.x.2194] 
[0.x.2195] 
[0.x.2196] 
//
[0.x.2197] 
[0.x.2198] 
[0.x.2199] 
[0.x.2200] 
[0.x.2201] 
[0.x.2202] 
[0.x.2203] 
//
[0.x.2204] 
[0.x.2205] 
[0.x.2206] 
[0.x.2207] 
[0.x.2208] 
//
[0.x.2209] 
[0.x.2210] 
//
[0.x.2211] 
[0.x.2212] 
[0.x.2213] 
[0.x.2214] 
[0.x.2215] 
//
[0.x.2216] 
[0.x.2217] 
[0.x.2218] 
[0.x.2219] 
[0.x.2220] 
[0.x.2221] 
//
[0.x.2222] 
[0.x.2223] 
[0.x.2224] 
[0.x.2225] 
[0.x.2226] 
[0.x.2227] 
[0.x.2228] 
//
[0.x.2229] 
[0.x.2230] 
[0.x.2231] 
[0.x.2232] 
[0.x.2233] 
[0.x.2234] 
[0.x.2235] 
[0.x.2236] 
//
[0.x.2237] 
//
[0.x.2238] 
//
[0.x.2239] 
//
[0.x.2240] 
[0.x.2241] 
[0.x.2242] 
[0.x.2243] 
[0.x.2244] 
[0.x.2245] 
[0.x.2246] 
//
[0.x.2247] 
[0.x.2248] 
//
[0.x.2249] 
[0.x.2250] 
[0.x.2251] 
[0.x.2252] 
[0.x.2253] 
[0.x.2254] 
[0.x.2255] 
[0.x.2256] 
[0.x.2257] 
[0.x.2258] 
//
// Now for the functions that implement actions in the linear system class. First, the constructor initializes all data elements to their correct sizes, and sets up a number of additional data structures, such as constraints due to hanging nodes. Since setting up the hanging nodes and finding out about the nonzero elements of the matrix is independent, we do that in parallel (if the library was configured to use concurrency, at least; otherwise, the actions are performed sequentially). Note that we start only one thread, and do the second action in the main thread. Since only one thread is generated, we don't use the  [2.x.297]  class here, but rather use the one created task object directly to wait for this particular task's exit. The approach is generally the same as the one we have used in  [2.x.298]  above.
//
// Note that taking the address of the  [2.x.299]  function is a little tricky, since there are actually three functions of this name, one for each supported space dimension. Taking addresses of overloaded functions is somewhat complicated in C++, since the address-of operator  [2.x.300]  in that case returns a set of values (the addresses of all functions with that name), and selecting the right one is then the next step. If the context dictates which one to take (for example by assigning to a function pointer of known type), then the compiler can do that by itself, but if this set of pointers shall be given as the argument to a function that takes a template, the compiler could choose all without having a preference for one. We therefore have to make it clear to the compiler which one we would like to have; for this, we could use a cast, but for more clarity, we assign it to a temporary  [2.x.301]  (short for <code>pointer to make_hanging_node_constraints</code>) with the right type, and using this pointer instead.
//
[0.x.2259] 
[0.x.2260] 
[0.x.2261] 
[0.x.2262] 
//
[0.x.2263] 
[0.x.2264] 
//
// Start a side task then continue on the main thread
//
[0.x.2265] 
[0.x.2266] 
//
[0.x.2267] 
[0.x.2268] 
//
// Wait for the side task to be done before going further
//
[0.x.2269] 
//
[0.x.2270] 
[0.x.2271] 
[0.x.2272] 
//
[0.x.2273] 
[0.x.2274] 
[0.x.2275] 
//
[0.x.2276] 
[0.x.2277] 
[0.x.2278] 
[0.x.2279] 
[0.x.2280] 
//
[0.x.2281] 
[0.x.2282] 
//
[0.x.2283] 
//
[0.x.2284] 
[0.x.2285] 
//
//  [2.x.302] 
//
// The  [2.x.303]  class is also mostly unchanged except for implementing the  [2.x.304]  function. We keep the  [2.x.305]  classes in this program, and they can then rely on the default implementation of this function which simply outputs the primal solution. The class implementing dual weighted error estimators will overload this function itself, to also output the dual solution.
//
[0.x.2286] 
[0.x.2287] 
[0.x.2288] 
[0.x.2289] 
[0.x.2290] 
[0.x.2291] 
[0.x.2292] 
[0.x.2293] 
[0.x.2294] 
[0.x.2295] 
//
[0.x.2296] 
//
[0.x.2297] 
[0.x.2298] 
[0.x.2299] 
[0.x.2300] 
//
[0.x.2301] 
[0.x.2302] 
[0.x.2303] 
[0.x.2304] 
[0.x.2305] 
[0.x.2306] 
[0.x.2307] 
[0.x.2308] 
[0.x.2309] 
[0.x.2310] 
[0.x.2311] 
[0.x.2312] 
[0.x.2313] 
[0.x.2314] 
[0.x.2315] 
//
[0.x.2316] 
[0.x.2317] 
[0.x.2318] 
[0.x.2319] 
[0.x.2320] 
[0.x.2321] 
[0.x.2322] 
//
[0.x.2323] 
[0.x.2324] 
[0.x.2325] 
[0.x.2326] 
//
[0.x.2327] 
[0.x.2328] 
[0.x.2329] 
[0.x.2330] 
[0.x.2331] 
[0.x.2332] 
[0.x.2333] 
//
[0.x.2334] 
[0.x.2335] 
//
[0.x.2336] 
[0.x.2337] 
[0.x.2338] 
//
[0.x.2339] 
[0.x.2340] 
[0.x.2341] 
//
[0.x.2342] 
//
[0.x.2343] 
[0.x.2344] 
//
[0.x.2345] 
[0.x.2346] 
[0.x.2347] 
[0.x.2348] 
[0.x.2349] 
//
[0.x.2350] 
[0.x.2351] 
[0.x.2352] 
[0.x.2353] 
[0.x.2354] 
//[2.x.306] 
//
// For the following two classes, the same applies as for most of the above: the class is taken from the previous example as-is:
//
[0.x.2355] 
[0.x.2356] 
[0.x.2357] 
[0.x.2358] 
[0.x.2359] 
[0.x.2360] 
[0.x.2361] 
[0.x.2362] 
[0.x.2363] 
[0.x.2364] 
//
[0.x.2365] 
[0.x.2366] 
//
[0.x.2367] 
[0.x.2368] 
[0.x.2369] 
[0.x.2370] 
[0.x.2371] 
[0.x.2372] 
[0.x.2373] 
[0.x.2374] 
[0.x.2375] 
[0.x.2376] 
[0.x.2377] 
[0.x.2378] 
[0.x.2379] 
[0.x.2380] 
[0.x.2381] 
[0.x.2382] 
//
[0.x.2383] 
[0.x.2384] 
[0.x.2385] 
[0.x.2386] 
[0.x.2387] 
//
[0.x.2388] 
[0.x.2389] 
[0.x.2390] 
[0.x.2391] 
[0.x.2392] 
[0.x.2393] 
[0.x.2394] 
[0.x.2395] 
[0.x.2396] 
[0.x.2397] 
//
[0.x.2398] 
[0.x.2399] 
//
[0.x.2400] 
[0.x.2401] 
[0.x.2402] 
[0.x.2403] 
[0.x.2404] 
[0.x.2405] 
[0.x.2406] 
[0.x.2407] 
[0.x.2408] 
[0.x.2409] 
[0.x.2410] 
[0.x.2411] 
[0.x.2412] 
[0.x.2413] 
[0.x.2414] 
[0.x.2415] 
//
[0.x.2416] 
[0.x.2417] 
[0.x.2418] 
[0.x.2419] 
[0.x.2420] 
[0.x.2421] 
[0.x.2422] 
[0.x.2423] 
[0.x.2424] 
[0.x.2425] 
[0.x.2426] 
[0.x.2427] 
[0.x.2428] 
[0.x.2429] 
[0.x.2430] 
[0.x.2431] 
[0.x.2432] 
//
//  [2.x.307] 
//
// This class is a variant of the previous one, in that it allows to weight the refinement indicators we get from the library's Kelly indicator by some function. We include this class since the goal of this example program is to demonstrate automatic refinement criteria even for complex output quantities such as point values or stresses. If we did not solve a dual problem and compute the weights thereof, we would probably be tempted to give a hand-crafted weighting to the indicators to account for the fact that we are going to evaluate these quantities. This class accepts such a weighting function as argument to its constructor:
//
[0.x.2433] 
[0.x.2434] 
[0.x.2435] 
[0.x.2436] 
[0.x.2437] 
[0.x.2438] 
[0.x.2439] 
[0.x.2440] 
[0.x.2441] 
[0.x.2442] 
[0.x.2443] 
//
[0.x.2444] 
//
[0.x.2445] 
[0.x.2446] 
[0.x.2447] 
//
[0.x.2448] 
[0.x.2449] 
[0.x.2450] 
[0.x.2451] 
[0.x.2452] 
[0.x.2453] 
[0.x.2454] 
[0.x.2455] 
[0.x.2456] 
[0.x.2457] 
[0.x.2458] 
[0.x.2459] 
[0.x.2460] 
[0.x.2461] 
[0.x.2462] 
[0.x.2463] 
[0.x.2464] 
[0.x.2465] 
//
// Now, here comes the main function, including the weighting:
//
[0.x.2466] 
[0.x.2467] 
[0.x.2468] 
//
// First compute some residual based error indicators for all cells by a method already implemented in the library. What exactly we compute here is described in more detail in the documentation of that class.
//
[0.x.2469] 
[0.x.2470] 
[0.x.2471] 
[0.x.2472] 
[0.x.2473] 
[0.x.2474] 
[0.x.2475] 
[0.x.2476] 
//
// Next weigh each entry in the vector of indicators by the value of the function given to the constructor, evaluated at the cell center. We need to write the result into the vector entry that corresponds to the current cell, which we can obtain by asking the cell what its index among all active cells is using  [2.x.308]  (In reality, this index is zero for the first cell we handle in the loop, one for the second cell, etc., and we could as well just keep track of this index using an integer counter; but using  [2.x.309]  makes this more explicit.)
//
[0.x.2477] 
[0.x.2478] 
[0.x.2479] 
//
[0.x.2480] 
[0.x.2481] 
[0.x.2482] 
[0.x.2483] 
[0.x.2484] 
[0.x.2485] 
//
[0.x.2486] 
//[2.x.310] 
//
// In this example program, we work with the same data sets as in the previous one, but as it may so happen that someone wants to run the program with different boundary values and right hand side functions, or on a different grid, we show a simple technique to do exactly that. For more clarity, we furthermore pack everything that has to do with equation data into a namespace of its own.
//
// The underlying assumption is that this is a research program, and that there we often have a number of test cases that consist of a domain, a right hand side, boundary values, possibly a specified coefficient, and a number of other parameters. They often vary all at the same time when shifting from one example to another. To make handling such sets of problem description parameters simple is the goal of the following.
//
// Basically, the idea is this: let us have a structure for each set of data, in which we pack everything that describes a test case: here, these are two subclasses, one called  [2.x.311]  for the boundary values of the exact solution, and one called  [2.x.312] , and then a way to generate the coarse grid. Since the solution of the previous example program looked like curved ridges, we use this name here for the enclosing class. Note that the names of the two inner classes have to be the same for all enclosing test case classes, and also that we have attached the dimension template argument to the enclosing class rather than to the inner ones, to make further processing simpler.  (From a language viewpoint, a namespace would be better to encapsulate these inner classes, rather than a structure. However, namespaces cannot be given as template arguments, so we use a structure to allow a second object to select from within its given argument. The enclosing structure, of course, has no member variables apart from the classes it declares, and a static function to generate the coarse mesh; it will in general never be instantiated.)
//
// The idea is then the following (this is the right time to also take a brief look at the code below): we can generate objects for boundary values and right hand side by simply giving the name of the outer class as a template argument to a class which we call here  [2.x.313] , and it then creates objects for the inner classes. In this case, to get all that characterizes the curved ridge solution, we would simply generate an instance of  [2.x.314] , and everything we need to know about the solution would be static member variables and functions of that object.
//
// This approach might seem like overkill in this case, but will become very handy once a certain set up is not only characterized by Dirichlet boundary values and a right hand side function, but in addition by material properties, Neumann values, different boundary descriptors, etc. In that case, the  [2.x.315]  class might consist of a dozen or more objects, and each descriptor class (like the  [2.x.316]  class below) would have to provide them. Then, you will be happy to be able to change from one set of data to another by only changing the template argument to the  [2.x.317]  class at one place, rather than at many.
//
// With this framework for different test cases, we are almost finished, but one thing remains: by now we can select statically, by changing one template argument, which data set to choose. In order to be able to do that dynamically, i.e. at run time, we need a base class. This we provide in the obvious way, see below, with virtual abstract functions. It forces us to introduce a second template parameter  [2.x.318]  which we need for the base class (which could be avoided using some template magic, but we omit that), but that's all.
//
// Adding new testcases is now simple, you don't have to touch the framework classes, only a structure like the  [2.x.319]  one is needed.
//
[0.x.2487] 
[0.x.2488] 
//[2.x.320] 
//
// Based on the above description, the  [2.x.321]  class then looks as follows. To allow using the  [2.x.322]  class with this class, we derived from the  [2.x.323]  class.
//
[0.x.2489] 
[0.x.2490] 
[0.x.2491] 
[0.x.2492] 
//
[0.x.2493] 
//
[0.x.2494] 
[0.x.2495] 
[0.x.2496] 
//
// And now for the derived class that takes the template argument as explained above.
//
// Here we pack the data elements into private variables, and allow access to them through the methods of the base class.
//
[0.x.2497] 
[0.x.2498] 
[0.x.2499] 
[0.x.2500] 
//
[0.x.2501] 
//
[0.x.2502] 
[0.x.2503] 
//
[0.x.2504] 
[0.x.2505] 
[0.x.2506] 
[0.x.2507] 
//
// We have to provide definitions for the static member variables of the above class:
//
[0.x.2508] 
[0.x.2509] 
[0.x.2510] 
[0.x.2511] 
//
// And definitions of the member functions:
//
[0.x.2512] 
[0.x.2513] 
[0.x.2514] 
[0.x.2515] 
[0.x.2516] 
//
[0.x.2517] 
[0.x.2518] 
[0.x.2519] 
[0.x.2520] 
[0.x.2521] 
//
[0.x.2522] 
[0.x.2523] 
[0.x.2524] 
[0.x.2525] 
[0.x.2526] 
[0.x.2527] 
//[2.x.324] 
//
// The class that is used to describe the boundary values and right hand side of the  [2.x.325]  problem already used in the  [2.x.326]  example program is then like so:
//
[0.x.2528] 
[0.x.2529] 
[0.x.2530] 
[0.x.2531] 
[0.x.2532] 
[0.x.2533] 
[0.x.2534] 
[0.x.2535] 
[0.x.2536] 
//
[0.x.2537] 
[0.x.2538] 
[0.x.2539] 
[0.x.2540] 
[0.x.2541] 
[0.x.2542] 
//
[0.x.2543] 
[0.x.2544] 
//
[0.x.2545] 
[0.x.2546] 
[0.x.2547] 
[0.x.2548] 
[0.x.2549] 
[0.x.2550] 
[0.x.2551] 
[0.x.2552] 
[0.x.2553] 
[0.x.2554] 
[0.x.2555] 
//
[0.x.2556] 
[0.x.2557] 
[0.x.2558] 
[0.x.2559] 
[0.x.2560] 
[0.x.2561] 
[0.x.2562] 
[0.x.2563] 
[0.x.2564] 
[0.x.2565] 
[0.x.2566] 
[0.x.2567] 
[0.x.2568] 
[0.x.2569] 
[0.x.2570] 
[0.x.2571] 
[0.x.2572] 
[0.x.2573] 
[0.x.2574] 
[0.x.2575] 
//
[0.x.2576] 
[0.x.2577] 
//
[0.x.2578] 
[0.x.2579] 
[0.x.2580] 
[0.x.2581] 
[0.x.2582] 
[0.x.2583] 
//[2.x.327] 
//
// This example program was written while giving practical courses for a lecture on adaptive finite element methods and duality based error estimates. For these courses, we had one exercise, which required to solve the Laplace equation with constant right hand side on a square domain with a square hole in the center, and zero boundary values. Since the implementation of the properties of this problem is so particularly simple here, lets do it. As the number of the exercise was 2.3, we take the liberty to retain this name for the class as well.
//
[0.x.2584] 
[0.x.2585] 
[0.x.2586] 
//
// We need a class to denote the boundary values of the problem. In this case, this is simple: it's the zero function, so don't even declare a class, just an alias:
//
[0.x.2587] 
//
// Second, a class that denotes the right hand side. Since they are constant, just subclass the corresponding class of the library and be done:
//
[0.x.2588] 
[0.x.2589] 
[0.x.2590] 
[0.x.2591] 
[0.x.2592] 
[0.x.2593] 
[0.x.2594] 
//
// Finally a function to generate the coarse grid. This is somewhat more complicated here, see immediately below.
//
[0.x.2595] 
[0.x.2596] 
//
// As stated above, the grid for this example is the square [-1,1]^2 with the square [-1/2,1/2]^2 as hole in it. We create the coarse grid as 4 times 4 cells with the middle four ones missing. To understand how exactly the mesh is going to look, it may be simplest to just look at the "Results" section of this tutorial program first. In general, if you'd like to understand more about creating meshes either from scratch by hand, as we do here, or using other techniques, you should take a look at  [2.x.328] .
//
// Of course, the example has an extension to 3d, but since this function cannot be written in a dimension independent way we choose not to implement this here, but rather only specialize the template for dim=2. If you compile the program for 3d, you'll get a message from the linker that this function is not implemented for 3d, and needs to be provided.
//
// For the creation of this geometry, the library has no predefined method. In this case, the geometry is still simple enough to do the creation by hand, rather than using a mesh generator.
//
[0.x.2597] 
[0.x.2598] 
[0.x.2599] 
//
// We first define the space dimension, to allow those parts of the function that are actually dimension independent to use this variable. That makes it simpler if you later take this as a starting point to implement a 3d version of this mesh. The next step is then to have a list of vertices. Here, they are 24 (5 times 5, with the middle one omitted). It is probably best to draw a sketch here.
//
[0.x.2600] 
//
[0.x.2601] 
[0.x.2602] 
[0.x.2603] 
[0.x.2604] 
[0.x.2605] 
[0.x.2606] 
//
// Next, we have to define the cells and the vertices they contain.
//
[0.x.2607] 
[0.x.2608] 
[0.x.2609] 
[0.x.2610] 
[0.x.2611] 
[0.x.2612] 
[0.x.2613] 
[0.x.2614] 
[0.x.2615] 
[0.x.2616] 
[0.x.2617] 
[0.x.2618] 
[0.x.2619] 
//
[0.x.2620] 
//
// Again, we generate a C++ vector type from this, but this time by looping over the cells (yes, this is boring). Additionally, we set the material indicator to zero for all the cells:
//
[0.x.2621] 
[0.x.2622] 
[0.x.2623] 
[0.x.2624] 
[0.x.2625] 
[0.x.2626] 
[0.x.2627] 
//
// Finally pass all this information to the library to generate a triangulation. The last parameter may be used to pass information about non-zero boundary indicators at certain faces of the triangulation to the library, but we don't want that here, so we give an empty object:
//
[0.x.2628] 
//
// And since we want that the evaluation point (3/4,3/4) in this example is a grid point, we refine once globally:
//
[0.x.2629] 
[0.x.2630] 
[0.x.2631] 
//[2.x.329] 
//
// As you have now read through this framework, you may be wondering why we have not chosen to implement the classes implementing a certain setup (like the  [2.x.330]  class) directly as classes derived from  [2.x.331] . Indeed, we could have done very well so. The only reason is that then we would have to have member variables for the solution and right hand side classes in the  [2.x.332]  class, as well as member functions overloading the abstract functions of the base class giving access to these member variables. The  [2.x.333]  class has the sole reason to relieve us from the need to reiterate these member variables and functions that would be necessary in all such classes. In some way, the template mechanism here only provides a way to have default implementations for a number of functions that depend on external quantities and can thus not be provided using normal virtual functions, at least not without the help of templates.
//
// However, there might be good reasons to actually implement classes derived from  [2.x.334] , for example if the solution or right hand side classes require constructors that take arguments, which the  [2.x.335]  class cannot provide. In that case, subclassing is a worthwhile strategy. Other possibilities for special cases are to derive from  [2.x.336]  where  [2.x.337]  denotes a class, or even to explicitly specialize  [2.x.338] . The latter allows to transparently use the way the  [2.x.339]  class is used for other set-ups, but with special actions taken for special arguments.
//
// A final observation favoring the approach taken here is the following: we have found numerous times that when starting a project, the number of parameters (usually boundary values, right hand side, coarse grid, just as here) was small, and the number of test cases was small as well. One then starts out by handcoding them into a number of  [2.x.340]  statements. Over time, projects grow, and so does the number of test cases. The number of  [2.x.341]  statements grows with that, and their length as well, and one starts to find ways to consider impossible examples where domains, boundary values, and right hand sides do not fit together any more, and starts losing the overview over the whole structure. Encapsulating everything belonging to a certain test case into a structure of its own has proven worthwhile for this, as it keeps everything that belongs to one test case in one place. Furthermore, it allows to put these things all in one or more files that are only devoted to test cases and their data, without having to bring their actual implementation into contact with the rest of the program.
//
//  [2.x.342] 
//
// As with the other components of the program, we put everything we need to describe dual functionals into a namespace of its own, and define an abstract base class that provides the interface the class solving the dual problem needs for its work.
//
// We will then implement two such classes, for the evaluation of a point value and of the derivative of the solution at that point. For these functionals we already have the corresponding evaluation objects, so they are complementary.
//
[0.x.2632] 
[0.x.2633] 
//[2.x.343] 
//
// First start with the base class for dual functionals. Since for linear problems the characteristics of the dual problem play a role only in the right hand side, we only need to provide for a function that assembles the right hand side for a given discretization:
//
[0.x.2634] 
[0.x.2635] 
[0.x.2636] 
[0.x.2637] 
[0.x.2638] 
[0.x.2639] 
[0.x.2640] 
//[2.x.344] 
//
// As a first application, we consider the functional corresponding to the evaluation of the solution's value at a given point which again we assume to be a vertex. Apart from the constructor that takes and stores the evaluation point, this class consists only of the function that implements assembling the right hand side.
//
[0.x.2641] 
[0.x.2642] 
[0.x.2643] 
[0.x.2644] 
[0.x.2645] 
//
[0.x.2646] 
[0.x.2647] 
//
[0.x.2648] 
[0.x.2649] 
[0.x.2650] 
[0.x.2651] 
[0.x.2652] 
//
[0.x.2653] 
[0.x.2654] 
[0.x.2655] 
//
[0.x.2656] 
[0.x.2657] 
[0.x.2658] 
[0.x.2659] 
[0.x.2660] 
//
// As for doing the main purpose of the class, assembling the right hand side, let us first consider what is necessary: The right hand side of the dual problem is a vector of values J(phi_i), where J is the error functional, and phi_i is the i-th shape function. Here, J is the evaluation at the point x0, i.e. J(phi_i)=phi_i(x0).
//
// Now, we have assumed that the evaluation point is a vertex. Thus, for the usual finite elements we might be using in this program, we can take for granted that at such a point exactly one shape function is nonzero, and in particular has the value one. Thus, we set the right hand side vector to all-zeros, then seek for the shape function associated with that point and set the corresponding value of the right hand side vector to one:
//
[0.x.2661] 
[0.x.2662] 
[0.x.2663] 
[0.x.2664] 
[0.x.2665] 
//
// So, first set everything to zeros...
//
[0.x.2666] 
//
// ...then loop over cells and find the evaluation point among the vertices (or very close to a vertex, which may happen due to floating point round-off):
//
[0.x.2667] 
[0.x.2668] 
[0.x.2669] 
[0.x.2670] 
[0.x.2671] 
//
//     Ok, found, so set corresponding entry, and leave function     since we are finished:
//
[0.x.2672] 
[0.x.2673] 
[0.x.2674] 
//
// Finally, a sanity check: if we somehow got here, then we must have missed the evaluation point, so raise an exception unconditionally:
//
[0.x.2675] 
[0.x.2676] 
//[2.x.345] 
//
// As second application, we again consider the evaluation of the x-derivative of the solution at one point. Again, the declaration of the class, and the implementation of its constructor is not too interesting:
//
[0.x.2677] 
[0.x.2678] 
[0.x.2679] 
[0.x.2680] 
[0.x.2681] 
//
[0.x.2682] 
[0.x.2683] 
//
[0.x.2684] 
[0.x.2685] 
[0.x.2686] 
[0.x.2687] 
[0.x.2688] 
//
[0.x.2689] 
[0.x.2690] 
[0.x.2691] 
//
[0.x.2692] 
[0.x.2693] 
[0.x.2694] 
[0.x.2695] 
[0.x.2696] 
//
// What is interesting is the implementation of this functional: here, J(phi_i)=d/dx phi_i(x0).
//
// We could, as in the implementation of the respective evaluation object take the average of the gradients of each shape function phi_i at this evaluation point. However, we take a slightly different approach: we simply take the average over all cells that surround this point. The question which cells  [2.x.346]  the evaluation point is made dependent on the mesh width by including those cells for which the distance of the cell's midpoint to the evaluation point is less than the cell's diameter.
//
// Taking the average of the gradient over the area/volume of these cells leads to a dual solution which is very close to the one which would result from the point evaluation of the gradient. It is simple to justify theoretically that this does not change the method significantly.
//
[0.x.2697] 
[0.x.2698] 
[0.x.2699] 
[0.x.2700] 
[0.x.2701] 
//
// Again, first set all entries to zero:
//
[0.x.2702] 
//
// Initialize a  [2.x.347]  object with a quadrature formula, have abbreviations for the number of quadrature points and shape functions...
//
[0.x.2703] 
[0.x.2704] 
[0.x.2705] 
[0.x.2706] 
[0.x.2707] 
[0.x.2708] 
[0.x.2709] 
//
// ...and have two objects that are used to store the global indices of the degrees of freedom on a cell, and the values of the gradients of the shape functions at the quadrature points:
//
[0.x.2710] 
[0.x.2711] 
//
// Finally have a variable in which we will sum up the area/volume of the cells over which we integrate, by integrating the unit functions on these cells:
//
[0.x.2712] 
//
// Then start the loop over all cells, and select those cells which are close enough to the evaluation point:
//
[0.x.2713] 
[0.x.2714] 
[0.x.2715] 
//
//   If we have found such a cell, then initialize the    [2.x.348]  object and integrate the x-component of   the gradient of each shape function, as well as the unit   function for the total area/volume.
//
[0.x.2716] 
[0.x.2717] 
//
[0.x.2718] 
[0.x.2719] 
[0.x.2720] 
[0.x.2721] 
[0.x.2722] 
[0.x.2723] 
[0.x.2724] 
[0.x.2725] 
//
//   If we have the local contributions, distribute them to the   global vector:
//
[0.x.2726] 
[0.x.2727] 
[0.x.2728] 
[0.x.2729] 
//
// After we have looped over all cells, check whether we have found any at all, by making sure that their volume is non-zero. If not, then the results will be botched, as the right hand side should then still be zero, so throw an exception:
//
[0.x.2730] 
[0.x.2731] 
//
// Finally, we have by now only integrated the gradients of the shape functions, not taking their mean value. We fix this by dividing by the measure of the volume over which we have integrated:
//
[0.x.2732] 
[0.x.2733] 
//
[0.x.2734] 
//[2.x.349] 
[0.x.2735] 
[0.x.2736] 
//[2.x.350] 
//
// In the same way as the  [2.x.351]  class above, we now implement a  [2.x.352] . It has all the same features, the only difference is that it does not take a function object denoting a right hand side object, but now takes a  [2.x.353]  object that will assemble the right hand side vector of the dual problem. The rest of the class is rather trivial.
//
// Since both primal and dual solver will use the same triangulation, but different discretizations, it now becomes clear why we have made the  [2.x.354]  class a virtual one: since the final class will be derived from both  [2.x.355]  as well as  [2.x.356]  instances, would we not have marked the inheritance as virtual. Since in many applications the base class would store much more information than just the triangulation which needs to be shared between primal and dual solvers, we do not usually want to use two such base classes.
//
[0.x.2737] 
[0.x.2738] 
[0.x.2739] 
[0.x.2740] 
[0.x.2741] 
[0.x.2742] 
[0.x.2743] 
[0.x.2744] 
[0.x.2745] 
[0.x.2746] 
//
[0.x.2747] 
[0.x.2748] 
[0.x.2749] 
[0.x.2750] 
//
[0.x.2751] 
[0.x.2752] 
//
[0.x.2753] 
[0.x.2754] 
//
[0.x.2755] 
[0.x.2756] 
[0.x.2757] 
[0.x.2758] 
[0.x.2759] 
[0.x.2760] 
[0.x.2761] 
[0.x.2762] 
[0.x.2763] 
[0.x.2764] 
[0.x.2765] 
[0.x.2766] 
[0.x.2767] 
[0.x.2768] 
[0.x.2769] 
//
[0.x.2770] 
[0.x.2771] 
[0.x.2772] 
[0.x.2773] 
[0.x.2774] 
//[2.x.357] 
//
// Here finally comes the main class of this program, the one that implements the dual weighted residual error estimator. It joins the primal and dual solver classes to use them for the computation of primal and dual solutions, and implements the error representation formula for use as error estimate and mesh refinement.
//
// The first few of the functions of this class are mostly overriders of the respective functions of the base class:
//
[0.x.2775] 
[0.x.2776] 
[0.x.2777] 
[0.x.2778] 
[0.x.2779] 
[0.x.2780] 
[0.x.2781] 
[0.x.2782] 
[0.x.2783] 
[0.x.2784] 
[0.x.2785] 
[0.x.2786] 
[0.x.2787] 
//
[0.x.2788] 
//
[0.x.2789] 
[0.x.2790] 
//
[0.x.2791] 
//
[0.x.2792] 
//
[0.x.2793] 
//
[0.x.2794] 
//
// In the private section, we have two functions that are used to call the  [2.x.358]  functions of the primal and dual base classes. These two functions will be called in parallel by the  [2.x.359]  function of this class.
//
[0.x.2795] 
[0.x.2796] 
//
// Then declare abbreviations for active cell iterators, to avoid that we have to write this lengthy name over and over again:
//
[0.x.2797] 
[0.x.2798] 
//
// Next, declare a data type that we will us to store the contribution of faces to the error estimator. The idea is that we can compute the face terms from each of the two cells to this face, as they are the same when viewed from both sides. What we will do is to compute them only once, based on some rules explained below which of the two adjacent cells will be in charge to do so. We then store the contribution of each face in a map mapping faces to their values, and only collect the contributions for each cell by looping over the cells a second time and grabbing the values from the map.
//
// The data type of this map is declared here:
//
[0.x.2799] 
[0.x.2800] 
//
// In the computation of the error estimates on cells and faces, we need a number of helper objects, such as  [2.x.360]  and  [2.x.361]  functions, but also temporary objects storing the values and gradients of primal and dual solutions, for example. These fields are needed in the three functions that do the integration on cells, and regular and irregular faces, respectively.
//
// There are three reasonable ways to provide these fields: first, as local variables in the function that needs them; second, as member variables of this class; third, as arguments passed to that function.
//
// These three alternatives all have drawbacks: the third that their number is not negligible and would make calling these functions a lengthy enterprise. The second has the drawback that it disallows parallelization, since the threads that will compute the error estimate have to have their own copies of these variables each, so member variables of the enclosing class will not work. The first approach, although straightforward, has a subtle but important drawback: we will call these functions over and over again, many thousands of times maybe; it now turns out that allocating vectors and other objects that need memory from the heap is an expensive business in terms of run-time, since memory allocation is expensive when several threads are involved. It is thus significantly better to allocate the memory only once, and recycle the objects as often as possible.
//
// What to do? Our answer is to use a variant of the third strategy. In fact, this is exactly what the WorkStream concept is supposed to do (we have already introduced it above, but see also  [2.x.362] ). To avoid that we have to give these functions a dozen or so arguments, we pack all these variables into two structures, one which is used for the computations on cells, the other doing them on the faces. Both are then joined into the WeightedResidualScratchData class that will serve as the "scratch data" class of the WorkStream concept:
//
[0.x.2801] 
[0.x.2802] 
[0.x.2803] 
[0.x.2804] 
//
[0.x.2805] 
[0.x.2806] 
[0.x.2807] 
[0.x.2808] 
[0.x.2809] 
[0.x.2810] 
[0.x.2811] 
[0.x.2812] 
[0.x.2813] 
//
[0.x.2814] 
[0.x.2815] 
[0.x.2816] 
[0.x.2817] 
[0.x.2818] 
//
[0.x.2819] 
[0.x.2820] 
[0.x.2821] 
[0.x.2822] 
[0.x.2823] 
[0.x.2824] 
[0.x.2825] 
[0.x.2826] 
//
[0.x.2827] 
[0.x.2828] 
[0.x.2829] 
[0.x.2830] 
[0.x.2831] 
[0.x.2832] 
[0.x.2833] 
[0.x.2834] 
[0.x.2835] 
//
[0.x.2836] 
[0.x.2837] 
//
[0.x.2838] 
[0.x.2839] 
[0.x.2840] 
[0.x.2841] 
[0.x.2842] 
//[2.x.363]  generally wants both a scratch object and a copy object. Here, for reasons similar to what we had in  [2.x.364]  when discussing the computation of an approximation of the gradient, we don't actually need a "copy data" structure. Since WorkStream insists on having one of these, we just declare an empty structure that does nothing other than being there.
//
[0.x.2843] 
[0.x.2844] 
//
// Regarding the evaluation of the error estimator, we have one driver function that uses  [2.x.365]  to call the second function on every cell:
//
[0.x.2845] 
//
[0.x.2846] 
[0.x.2847] 
[0.x.2848] 
[0.x.2849] 
[0.x.2850] 
//
// Then we have functions that do the actual integration of the error representation formula. They will treat the terms on the cell interiors, on those faces that have no hanging nodes, and on those faces with hanging nodes, respectively:
//
[0.x.2851] 
[0.x.2852] 
[0.x.2853] 
[0.x.2854] 
[0.x.2855] 
//
[0.x.2856] 
[0.x.2857] 
[0.x.2858] 
[0.x.2859] 
[0.x.2860] 
[0.x.2861] 
[0.x.2862] 
[0.x.2863] 
[0.x.2864] 
[0.x.2865] 
[0.x.2866] 
[0.x.2867] 
[0.x.2868] 
//
// In the implementation of this class, we first have the constructors of the  [2.x.366]  member classes, and the  [2.x.367]  constructor. They only initialize fields to their correct lengths, so we do not have to discuss them in too much detail:
//
[0.x.2869] 
[0.x.2870] 
[0.x.2871] 
[0.x.2872] 
[0.x.2873] 
[0.x.2874] 
[0.x.2875] 
[0.x.2876] 
[0.x.2877] 
[0.x.2878] 
[0.x.2879] 
[0.x.2880] 
[0.x.2881] 
[0.x.2882] 
[0.x.2883] 
//
[0.x.2884] 
[0.x.2885] 
[0.x.2886] 
[0.x.2887] 
[0.x.2888] 
[0.x.2889] 
[0.x.2890] 
[0.x.2891] 
[0.x.2892] 
[0.x.2893] 
[0.x.2894] 
[0.x.2895] 
//
[0.x.2896] 
[0.x.2897] 
[0.x.2898] 
[0.x.2899] 
[0.x.2900] 
[0.x.2901] 
[0.x.2902] 
[0.x.2903] 
[0.x.2904] 
[0.x.2905] 
[0.x.2906] 
[0.x.2907] 
[0.x.2908] 
[0.x.2909] 
[0.x.2910] 
//
[0.x.2911] 
[0.x.2912] 
[0.x.2913] 
[0.x.2914] 
[0.x.2915] 
//
[0.x.2916] 
[0.x.2917] 
[0.x.2918] 
[0.x.2919] 
[0.x.2920] 
[0.x.2921] 
[0.x.2922] 
[0.x.2923] 
[0.x.2924] 
[0.x.2925] 
[0.x.2926] 
[0.x.2927] 
[0.x.2928] 
[0.x.2929] 
[0.x.2930] 
[0.x.2931] 
[0.x.2932] 
[0.x.2933] 
[0.x.2934] 
[0.x.2935] 
//
[0.x.2936] 
[0.x.2937] 
[0.x.2938] 
[0.x.2939] 
[0.x.2940] 
[0.x.2941] 
[0.x.2942] 
[0.x.2943] 
[0.x.2944] 
[0.x.2945] 
[0.x.2946] 
[0.x.2947] 
[0.x.2948] 
[0.x.2949] 
//
[0.x.2950] 
[0.x.2951] 
[0.x.2952] 
[0.x.2953] 
[0.x.2954] 
[0.x.2955] 
[0.x.2956] 
[0.x.2957] 
[0.x.2958] 
//
[0.x.2959] 
[0.x.2960] 
[0.x.2961] 
[0.x.2962] 
[0.x.2963] 
[0.x.2964] 
[0.x.2965] 
[0.x.2966] 
[0.x.2967] 
[0.x.2968] 
[0.x.2969] 
[0.x.2970] 
[0.x.2971] 
[0.x.2972] 
[0.x.2973] 
[0.x.2974] 
[0.x.2975] 
[0.x.2976] 
[0.x.2977] 
[0.x.2978] 
[0.x.2979] 
[0.x.2980] 
[0.x.2981] 
//
// The next five functions are boring, as they simply relay their work to the base classes. The first calls the primal and dual solvers in parallel, while postprocessing the solution and retrieving the number of degrees of freedom is done by the primal class.
//
[0.x.2982] 
[0.x.2983] 
[0.x.2984] 
[0.x.2985] 
[0.x.2986] 
[0.x.2987] 
[0.x.2988] 
[0.x.2989] 
[0.x.2990] 
[0.x.2991] 
//
[0.x.2992] 
[0.x.2993] 
[0.x.2994] 
[0.x.2995] 
[0.x.2996] 
//
[0.x.2997] 
[0.x.2998] 
[0.x.2999] 
[0.x.3000] 
[0.x.3001] 
//
[0.x.3002] 
[0.x.3003] 
[0.x.3004] 
[0.x.3005] 
[0.x.3006] 
[0.x.3007] 
//
[0.x.3008] 
[0.x.3009] 
[0.x.3010] 
[0.x.3011] 
[0.x.3012] 
//
// Now, it is becoming more interesting: the  [2.x.368]  function asks the error estimator to compute the cell-wise error indicators, then uses their absolute values for mesh refinement.
//
[0.x.3013] 
[0.x.3014] 
[0.x.3015] 
//
// First call the function that computes the cell-wise and global error:
//
[0.x.3016] 
[0.x.3017] 
//
// Then note that marking cells for refinement or coarsening only works if all indicators are positive, to allow their comparison. Thus, drop the signs on all these indicators:
//
[0.x.3018] 
[0.x.3019] 
//
// Finally, we can select between different strategies for refinement. The default here is to refine those cells with the largest error indicators that make up for a total of 80 per cent of the error, while we coarsen those with the smallest indicators that make up for the bottom 2 per cent of the error.
//
[0.x.3020] 
[0.x.3021] 
[0.x.3022] 
[0.x.3023] 
[0.x.3024] 
[0.x.3025] 
//
// Since we want to output both the primal and the dual solution, we overload the  [2.x.369]  function. The only interesting feature of this function is that the primal and dual solutions are defined on different finite element spaces, which is not the format the  [2.x.370]  class expects. Thus, we have to transfer them to a common finite element space. Since we want the solutions only to see them qualitatively, we contend ourselves with interpolating the dual solution to the (smaller) primal space. For the interpolation, there is a library function, that takes a AffineConstraints object including the hanging node constraints. The rest is standard.
//
[0.x.3026] 
[0.x.3027] 
[0.x.3028] 
[0.x.3029] 
[0.x.3030] 
[0.x.3031] 
[0.x.3032] 
[0.x.3033] 
[0.x.3034] 
[0.x.3035] 
[0.x.3036] 
[0.x.3037] 
[0.x.3038] 
//
[0.x.3039] 
[0.x.3040] 
//
// Add the data vectors for which we want output. Add them both, the  [2.x.371]  functions can handle as many data vectors as you wish to write to output:
//
[0.x.3041] 
[0.x.3042] 
//
[0.x.3043] 
//
[0.x.3044] 
[0.x.3045] 
[0.x.3046] 
[0.x.3047] 
//[2.x.372] 
//[2.x.373] 
//
// As for the actual computation of error estimates, let's start with the function that drives all this, i.e. calls those functions that actually do the work, and finally collects the results.
//
[0.x.3048] 
[0.x.3049] 
[0.x.3050] 
[0.x.3051] 
//
// The first task in computing the error is to set up vectors that denote the primal solution, and the weights (z-z_h)=(z-I_hz), both in the finite element space for which we have computed the dual solution. For this, we have to interpolate the primal solution to the dual finite element space, and to subtract the interpolation of the computed dual solution to the primal finite element space. Fortunately, the library provides functions for the interpolation into larger or smaller finite element spaces, so this is mostly obvious.
//
// First, let's do that for the primal solution: it is cell-wise interpolated into the finite element space in which we have solved the dual problem: But, again as in the  [2.x.374]  function we first need to create an AffineConstraints object including the hanging node constraints, but this time of the dual finite element space.
//
[0.x.3052] 
[0.x.3053] 
[0.x.3054] 
[0.x.3055] 
[0.x.3056] 
[0.x.3057] 
[0.x.3058] 
[0.x.3059] 
[0.x.3060] 
[0.x.3061] 
//
// Then for computing the interpolation of the numerically approximated dual solution z into the finite element space of the primal solution and subtracting it from z: use the  [2.x.375]  function, that gives (z-I_hz) in the element space of the dual solution.
//
[0.x.3062] 
[0.x.3063] 
[0.x.3064] 
[0.x.3065] 
[0.x.3066] 
[0.x.3067] 
[0.x.3068] 
[0.x.3069] 
[0.x.3070] 
[0.x.3071] 
[0.x.3072] 
//
// Note that this could probably have been more efficient since those constraints have been used previously when assembling matrix and right hand side for the primal problem and writing out the dual solution. We leave the optimization of the program in this respect as an exercise.
//
// Having computed the dual weights we now proceed with computing the cell and face residuals of the primal solution. First we set up a map between face iterators and their jump term contributions of faces to the error estimator. The reason is that we compute the jump terms only once, from one side of the face, and want to collect them only afterwards when looping over all cells a second time.
//
// We initialize this map already with a value of -1e20 for all faces, since this value will stand out in the results if something should go wrong and we fail to compute the value for a face for some reason. Secondly, this initialization already makes the  [2.x.376]  object allocate all objects it may possibly need. This is important since we will write into this structure from parallel threads, and doing so would not be thread-safe if the map needed to allocate memory and thereby reshape its data structures. In other words, the initial initialization relieves us from the necessity to synchronize the threads through a mutex each time they write to (and modify the structure of) this map.
//
[0.x.3073] 
[0.x.3074] 
[0.x.3075] 
[0.x.3076] 
[0.x.3077] 
//
[0.x.3078] 
[0.x.3079] 
[0.x.3080] 
[0.x.3081] 
[0.x.3082] 
[0.x.3083] 
[0.x.3084] 
[0.x.3085] 
//
[0.x.3086] 
[0.x.3087] 
//
// Then hand it all off to  [2.x.377]  to compute the estimators for all cells in parallel:
//
[0.x.3088] 
[0.x.3089] 
[0.x.3090] 
[0.x.3091] 
[0.x.3092] 
[0.x.3093] 
[0.x.3094] 
[0.x.3095] 
[0.x.3096] 
[0.x.3097] 
[0.x.3098] 
[0.x.3099] 
//
// Once the error contributions are computed, sum them up. For this, note that the cell terms are already set, and that only the edge terms need to be collected. Thus, loop over all cells and their faces, make sure that the contributions of each of the faces are there, and add them up. Only take minus one half of the jump term, since the other half will be taken by the neighboring cell.
//
[0.x.3100] 
[0.x.3101] 
[0.x.3102] 
[0.x.3103] 
[0.x.3104] 
[0.x.3105] 
[0.x.3106] 
[0.x.3107] 
[0.x.3108] 
[0.x.3109] 
[0.x.3110] 
[0.x.3111] 
[0.x.3112] 
[0.x.3113] 
[0.x.3114] 
[0.x.3115] 
[0.x.3116] 
[0.x.3117] 
//[2.x.378] 
//
// Next we have the function that is called to estimate the error on a single cell. The function may be called multiple times if the library was configured to use multithreading. Here it goes:
//
[0.x.3118] 
[0.x.3119] 
[0.x.3120] 
[0.x.3121] 
[0.x.3122] 
[0.x.3123] 
[0.x.3124] 
[0.x.3125] 
//
// Because of WorkStream, estimate_on_one_cell requires a CopyData object even if it is no used. The next line silences a warning about this unused variable.
//
[0.x.3126] 
//
// First task on each cell is to compute the cell residual contributions of this cell, and put them into the  [2.x.379]  variable:
//
[0.x.3127] 
[0.x.3128] 
[0.x.3129] 
[0.x.3130] 
[0.x.3131] 
//
// After computing the cell terms, turn to the face terms. For this, loop over all faces of the present cell, and see whether something needs to be computed on it:
//
[0.x.3132] 
[0.x.3133] 
//
// First, if this face is part of the boundary, then there is nothing to do. However, to make things easier when summing up the contributions of the faces of cells, we enter this face into the list of faces with a zero contribution to the error.
//
[0.x.3134] 
[0.x.3135] 
[0.x.3136] 
[0.x.3137] 
[0.x.3138] 
//
// Next, note that since we want to compute the jump terms on each face only once although we access it twice (if it is not at the boundary), we have to define some rules who is responsible for computing on a face:
//
// First, if the neighboring cell is on the same level as this one, i.e. neither further refined not coarser, then the one with the lower index within this level does the work. In other words: if the other one has a lower index, then skip work on this face:
//
[0.x.3139] 
[0.x.3140] 
[0.x.3141] 
[0.x.3142] 
//
// Likewise, we always work from the coarser cell if this and its neighbor differ in refinement. Thus, if the neighboring cell is less refined than the present one, then do nothing since we integrate over the subfaces when we visit the coarse cell.
//
[0.x.3143] 
[0.x.3144] 
[0.x.3145] 
//
// Now we know that we are in charge here, so actually compute the face jump terms. If the face is a regular one, i.e.  the other side's cell is neither coarser not finer than this cell, then call one function, and if the cell on the other side is further refined, then use another function. Note that the case that the cell on the other side is coarser cannot happen since we have decided above that we handle this case when we pass over that other cell.
//
[0.x.3146] 
[0.x.3147] 
[0.x.3148] 
[0.x.3149] 
[0.x.3150] 
[0.x.3151] 
[0.x.3152] 
[0.x.3153] 
[0.x.3154] 
[0.x.3155] 
[0.x.3156] 
[0.x.3157] 
[0.x.3158] 
[0.x.3159] 
[0.x.3160] 
[0.x.3161] 
//[2.x.380] 
//
// As for the actual computation of the error contributions, first turn to the cell terms:
//
[0.x.3162] 
[0.x.3163] 
[0.x.3164] 
[0.x.3165] 
[0.x.3166] 
[0.x.3167] 
[0.x.3168] 
[0.x.3169] 
//
// The tasks to be done are what appears natural from looking at the error estimation formula: first get the right hand side and Laplacian of the numerical solution at the quadrature points for the cell residual,
//
[0.x.3170] 
[0.x.3171] 
[0.x.3172] 
[0.x.3173] 
[0.x.3174] 
//
// ...then get the dual weights...
//
[0.x.3175] 
[0.x.3176] 
//
// ...and finally build the sum over all quadrature points and store it with the present cell:
//
[0.x.3177] 
[0.x.3178] 
[0.x.3179] 
[0.x.3180] 
[0.x.3181] 
[0.x.3182] 
//[2.x.381] 
//
// On the other hand, computation of the edge terms for the error estimate is not so simple. First, we have to distinguish between faces with and without hanging nodes. Because it is the simple case, we first consider the case without hanging nodes on a face (let's call this the `regular' case):
//
[0.x.3183] 
[0.x.3184] 
[0.x.3185] 
[0.x.3186] 
[0.x.3187] 
[0.x.3188] 
[0.x.3189] 
[0.x.3190] 
[0.x.3191] 
[0.x.3192] 
[0.x.3193] 
//
// The first step is to get the values of the gradients at the quadrature points of the finite element field on the present cell. For this, initialize the  [2.x.382]  object corresponding to this side of the face, and extract the gradients using that object.
//
[0.x.3194] 
[0.x.3195] 
[0.x.3196] 
//
// The second step is then to extract the gradients of the finite element solution at the quadrature points on the other side of the face, i.e. from the neighboring cell.
//
// For this, do a sanity check before: make sure that the neighbor actually exists (yes, we should not have come here if the neighbor did not exist, but in complicated software there are bugs, so better check this), and if this is not the case throw an error.
//
[0.x.3197] 
[0.x.3198] 
//
// If we have that, then we need to find out with which face of the neighboring cell we have to work, i.e. the  [2.x.383]  the neighbor the present cell is of the cell behind the present face. For this, there is a function, and we put the result into a variable with the name  [2.x.384] :
//
[0.x.3199] 
[0.x.3200] 
//
// Then define an abbreviation for the neighbor cell, initialize the  [2.x.385]  object on that cell, and extract the gradients on that cell:
//
[0.x.3201] 
[0.x.3202] 
[0.x.3203] 
[0.x.3204] 
//
// Now that we have the gradients on this and the neighboring cell, compute the jump residual by multiplying the jump in the gradient with the normal vector:
//
[0.x.3205] 
[0.x.3206] 
[0.x.3207] 
[0.x.3208] 
//
// Next get the dual weights for this face:
//
[0.x.3209] 
[0.x.3210] 
//
// Finally, we have to compute the sum over jump residuals, dual weights, and quadrature weights, to get the result for this face:
//
[0.x.3211] 
[0.x.3212] 
[0.x.3213] 
[0.x.3214] 
[0.x.3215] 
//
// Double check that the element already exists and that it was not already written to...
//
[0.x.3216] 
[0.x.3217] 
[0.x.3218] 
//
// ...then store computed value at assigned location. Note that the stored value does not contain the factor 1/2 that appears in the error representation. The reason is that the term actually does not have this factor if we loop over all faces in the triangulation, but only appears if we write it as a sum over all cells and all faces of each cell; we thus visit the same face twice. We take account of this by using this factor -1/2 later, when we sum up the contributions for each cell individually.
//
[0.x.3219] 
[0.x.3220] 
//[2.x.386] 
//
// We are still missing the case of faces with hanging nodes. This is what is covered in this function:
//
[0.x.3221] 
[0.x.3222] 
[0.x.3223] 
[0.x.3224] 
[0.x.3225] 
[0.x.3226] 
[0.x.3227] 
[0.x.3228] 
[0.x.3229] 
//
// First again two abbreviations, and some consistency checks whether the function is called only on faces for which it is supposed to be called:
//
[0.x.3230] 
[0.x.3231] 
//
[0.x.3232] 
[0.x.3233] 
[0.x.3234] 
[0.x.3235] 
[0.x.3236] 
[0.x.3237] 
//
// Then find out which neighbor the present cell is of the adjacent cell. Note that we will operate on the children of this adjacent cell, but that their orientation is the same as that of their mother, i.e. the neighbor direction is the same.
//
[0.x.3238] 
[0.x.3239] 
//
// Then simply do everything we did in the previous function for one face for all the sub-faces now:
//
[0.x.3240] 
[0.x.3241] 
[0.x.3242] 
//
// Start with some checks again: get an iterator pointing to the cell behind the present subface and check whether its face is a subface of the one we are considering. If that were not the case, then there would be either a bug in the  [2.x.387]  function called above, or -- worse -- some function in the library did not keep to some underlying assumptions about cells, their children, and their faces. In any case, even though this assertion should not be triggered, it does not harm to be cautious, and in optimized mode computations the assertion will be removed anyway.
//
[0.x.3243] 
[0.x.3244] 
[0.x.3245] 
[0.x.3246] 
[0.x.3247] 
//
// Now start the work by again getting the gradient of the solution first at this side of the interface,
//
[0.x.3248] 
[0.x.3249] 
[0.x.3250] 
//
// then at the other side,
//
[0.x.3251] 
[0.x.3252] 
[0.x.3253] 
[0.x.3254] 
//
// and finally building the jump residuals. Since we take the normal vector from the other cell this time, revert the sign of the first term compared to the other function:
//
[0.x.3255] 
[0.x.3256] 
[0.x.3257] 
[0.x.3258] 
//
// Then get dual weights:
//
[0.x.3259] 
[0.x.3260] 
//
// At last, sum up the contribution of this sub-face, and set it in the global map:
//
[0.x.3261] 
[0.x.3262] 
[0.x.3263] 
[0.x.3264] 
[0.x.3265] 
[0.x.3266] 
[0.x.3267] 
[0.x.3268] 
//
// Once the contributions of all sub-faces are computed, loop over all sub-faces to collect and store them with the mother face for simple use when later collecting the error terms of cells. Again make safety checks that the entries for the sub-faces have been computed and do not carry an invalid value.
//
[0.x.3269] 
[0.x.3270] 
[0.x.3271] 
[0.x.3272] 
[0.x.3273] 
[0.x.3274] 
[0.x.3275] 
[0.x.3276] 
[0.x.3277] 
//
[0.x.3278] 
[0.x.3279] 
//
// Finally store the value with the parent face.
//
[0.x.3280] 
[0.x.3281] 
//
[0.x.3282] 
//[2.x.388] 
//
// In the previous example program, we have had two functions that were used to drive the process of solving on subsequently finer grids. We extend this here to allow for a number of parameters to be passed to these functions, and put all of that into framework class.
//
// You will have noted that this program is built up of a number of small parts (evaluation functions, solver classes implementing various refinement methods, different dual functionals, different problem and data descriptions), which makes the program relatively simple to extend, but also allows to solve a large number of different problems by replacing one part by another. We reflect this flexibility by declaring a structure in the following framework class that holds a number of parameters that may be set to test various combinations of the parts of this program, and which can be used to test it at various problems and discretizations in a simple way.
//
[0.x.3283] 
[0.x.3284] 
[0.x.3285] 
[0.x.3286] 
//
// First, we declare two abbreviations for simple use of the respective data types:
//
[0.x.3287] 
[0.x.3288] 
//
// Then we have the structure which declares all the parameters that may be set. In the default constructor of the structure, these values are all set to default values, for simple use.
//
[0.x.3289] 
[0.x.3290] 
//
// First allow for the degrees of the piecewise polynomials by which the primal and dual problems will be discretized. They default to (bi-, tri-)linear ansatz functions for the primal, and (bi-, tri-)quadratic ones for the dual problem. If a refinement criterion is chosen that does not need the solution of a dual problem, the value of the dual finite element degree is of course ignored.
//
[0.x.3291] 
[0.x.3292] 
//
// Then have an object that describes the problem type, i.e. right hand side, domain, boundary values, etc. The pointer needed here defaults to the Null pointer, i.e. you will have to set it in actual instances of this object to make it useful.
//
[0.x.3293] 
//
// Since we allow to use different refinement criteria (global refinement, refinement by the Kelly error indicator, possibly with a weight, and using the dual estimator), define a number of enumeration values, and subsequently a variable of that type. It will default to  [2.x.389] .
//
[0.x.3294] 
[0.x.3295] 
[0.x.3296] 
[0.x.3297] 
[0.x.3298] 
[0.x.3299] 
[0.x.3300] 
//
[0.x.3301] 
//
// Next, an object that describes the dual functional. It is only needed if the dual weighted residual refinement is chosen, and also defaults to a Null pointer.
//
[0.x.3302] 
[0.x.3303] 
//
// Then a list of evaluation objects. Its default value is empty, i.e. no evaluation objects.
//
[0.x.3304] 
//
// Next to last, a function that is used as a weight to the  [2.x.390]  class. The default value of this pointer is zero, but you have to set it to some other value if you want to use the  [2.x.391]  refinement criterion.
//
[0.x.3305] 
//
// Finally, we have a variable that denotes the maximum number of degrees of freedom we allow for the (primal) discretization. If it is exceeded, we stop the process of solving and intermittent mesh refinement. Its default value is 20,000.
//
[0.x.3306] 
//
// Finally the default constructor of this class:
//
[0.x.3307] 
[0.x.3308] 
//
// The driver framework class only has one method which calls solver and mesh refinement intermittently, and does some other small tasks in between. Since it does not need data besides the parameters given to it, we make it static:
//
[0.x.3309] 
[0.x.3310] 
//
// As for the implementation, first the constructor of the parameter object, setting all values to their defaults:
//
[0.x.3311] 
[0.x.3312] 
[0.x.3313] 
[0.x.3314] 
[0.x.3315] 
[0.x.3316] 
[0.x.3317] 
//
// Then the function which drives the whole process:
//
[0.x.3318] 
[0.x.3319] 
[0.x.3320] 
//
// First create a triangulation from the given data object,
//
[0.x.3321] 
[0.x.3322] 
[0.x.3323] 
//
// then a set of finite elements and appropriate quadrature formula:
//
[0.x.3324] 
[0.x.3325] 
[0.x.3326] 
[0.x.3327] 
//
// Next, select one of the classes implementing different refinement criteria.
//
[0.x.3328] 
[0.x.3329] 
[0.x.3330] 
[0.x.3331] 
[0.x.3332] 
[0.x.3333] 
[0.x.3334] 
[0.x.3335] 
[0.x.3336] 
[0.x.3337] 
[0.x.3338] 
[0.x.3339] 
[0.x.3340] 
[0.x.3341] 
[0.x.3342] 
[0.x.3343] 
//
[0.x.3344] 
[0.x.3345] 
[0.x.3346] 
[0.x.3347] 
[0.x.3348] 
[0.x.3349] 
[0.x.3350] 
[0.x.3351] 
[0.x.3352] 
[0.x.3353] 
[0.x.3354] 
//
[0.x.3355] 
[0.x.3356] 
[0.x.3357] 
[0.x.3358] 
[0.x.3359] 
[0.x.3360] 
[0.x.3361] 
[0.x.3362] 
[0.x.3363] 
[0.x.3364] 
[0.x.3365] 
//
[0.x.3366] 
[0.x.3367] 
[0.x.3368] 
[0.x.3369] 
[0.x.3370] 
[0.x.3371] 
[0.x.3372] 
[0.x.3373] 
[0.x.3374] 
[0.x.3375] 
[0.x.3376] 
[0.x.3377] 
[0.x.3378] 
//
[0.x.3379] 
[0.x.3380] 
[0.x.3381] 
//
// Now that all objects are in place, run the main loop. The stopping criterion is implemented at the bottom of the loop.
//
// In the loop, first set the new cycle number, then solve the problem, output its solution(s), apply the evaluation objects to it, then decide whether we want to refine the mesh further and solve again on this mesh, or jump out of the loop.
//
[0.x.3382] 
[0.x.3383] 
[0.x.3384] 
//
[0.x.3385] 
[0.x.3386] 
[0.x.3387] 
//
[0.x.3388] 
[0.x.3389] 
//
[0.x.3390] 
[0.x.3391] 
[0.x.3392] 
[0.x.3393] 
[0.x.3394] 
//
[0.x.3395] 
[0.x.3396] 
[0.x.3397] 
[0.x.3398] 
[0.x.3399] 
//
// Clean up the screen after the loop has run:
//
[0.x.3400] 
[0.x.3401] 
//
[0.x.3402] 
//
//  [2.x.392] 
//
// Here finally comes the main function. It drives the whole process by specifying a set of parameters to be used for the simulation (polynomial degrees, evaluation and dual functionals, etc), and passes them packed into a structure to the frame work class above.
//
[0.x.3403] 
[0.x.3404] 
[0.x.3405] 
[0.x.3406] 
[0.x.3407] 
//
// Describe the problem we want to solve here by passing a descriptor object to the function doing the rest of the work:
//
[0.x.3408] 
[0.x.3409] 
//
// First set the refinement criterion we wish to use:
//
[0.x.3410] 
[0.x.3411] 
//
// Here, we could as well have used  [2.x.393]  or  [2.x.394] . Note that the information given about dual finite elements, dual functional, etc is only important for the given choice of refinement criterion, and is ignored otherwise.
//
// Then set the polynomial degrees of primal and dual problem. We choose here bi-linear and bi-quadratic ones:
//
[0.x.3412] 
[0.x.3413] 
//
// Then set the description of the test case, i.e. domain, boundary values, and right hand side. These are prepackaged in classes. We take here the description of  [2.x.395] , but you can also use  [2.x.396] :
//
[0.x.3414] 
[0.x.3415] 
//
// Next set first a dual functional, then a list of evaluation objects. We choose as default the evaluation of the value at an evaluation point, represented by the classes  [2.x.397]  in the namespaces of evaluation and dual functional classes. You can also set the  [2.x.398]  classes for the x-derivative instead of the value at the evaluation point.
//
// Note that dual functional and evaluation objects should match. However, you can give as many evaluation functionals as you want, so you can have both point value and derivative evaluated after each step.  One such additional evaluation is to output the grid in each step.
//
[0.x.3416] 
[0.x.3417] 
[0.x.3418] 
[0.x.3419] 
//
[0.x.3420] 
[0.x.3421] 
//
[0.x.3422] 
[0.x.3423] 
//
// Set the maximal number of degrees of freedom after which we want the program to stop refining the mesh further:
//
[0.x.3424] 
//
// Finally pass the descriptor object to a function that runs the entire solution with it:
//
[0.x.3425] 
[0.x.3426] 
//
// Catch exceptions to give information about things that failed:
//
[0.x.3427] 
[0.x.3428] 
[0.x.3429] 
[0.x.3430] 
[0.x.3431] 
[0.x.3432] 
[0.x.3433] 
[0.x.3434] 
[0.x.3435] 
[0.x.3436] 
[0.x.3437] 
[0.x.3438] 
[0.x.3439] 
[0.x.3440] 
[0.x.3441] 
[0.x.3442] 
[0.x.3443] 
[0.x.3444] 
[0.x.3445] 
[0.x.3446] 
[0.x.3447] 
[0.x.3448] 
[0.x.3449] 
[0.x.3450] 
[0.x.3451] 
//
[0.x.3452] 
[0.x.3453] 
[0.x.3454] 
[0.x.3455] 
[0.x.3456] 
[0.x.3457] 
[0.x.3458] 
[0.x.3459] 
[0.x.3460] 
[0.x.3461] 
[0.x.3462] 
[0.x.3463] 
[0.x.3464] 
[0.x.3465] 
[0.x.3466] 
[0.x.3467] 
//
[0.x.3468] 
[0.x.3469] 
[0.x.3470] 
//[2.x.399] 
//
// The first few files have already been covered in previous examples and will thus not be further commented on.
//
[0.x.3471] 
[0.x.3472] 
[0.x.3473] 
//
[0.x.3474] 
[0.x.3475] 
[0.x.3476] 
[0.x.3477] 
[0.x.3478] 
[0.x.3479] 
[0.x.3480] 
//
[0.x.3481] 
[0.x.3482] 
[0.x.3483] 
//
[0.x.3484] 
[0.x.3485] 
//
[0.x.3486] 
[0.x.3487] 
//
[0.x.3488] 
[0.x.3489] 
[0.x.3490] 
[0.x.3491] 
//
[0.x.3492] 
[0.x.3493] 
//
// We will use adaptive mesh refinement between Newton iterations. To do so, we need to be able to work with a solution on the new mesh, although it was computed on the old one. The SolutionTransfer class transfers the solution from the old to the new mesh:
//
[0.x.3494] 
//
// We then open a namespace for this program and import everything from the dealii namespace into it, as in previous programs:
//
[0.x.3495] 
[0.x.3496] 
[0.x.3497] 
//[2.x.400] 
//
// The class template is basically the same as in  [2.x.401] .  Three additions are made:
//
// - There are two solution vectors, one for the Newton update    [2.x.402] , and one for the current iterate  [2.x.403] .
//
// - The  [2.x.404]  function takes an argument that denotes   whether this is the first time it is called or not. The difference is   that the first time around we need to distribute the degrees of freedom   and set the solution vector for  [2.x.405]  to the correct size. The following   times, the function is called after we have already done these steps as   part of refining the mesh in  [2.x.406] .
//
// - We then also need new functions:  [2.x.407]    takes care of setting the boundary values on the solution vector   correctly, as discussed at the end of the   introduction.  [2.x.408]  is a function that computes   the norm of the nonlinear (discrete) residual. We use this function to   monitor convergence of the Newton iteration. The function takes a step   length  [2.x.409]  as argument to compute the residual of  [2.x.410] . This is something one typically needs for step length   control, although we will not use this feature here. Finally,    [2.x.411]  computes the step length  [2.x.412]    in each Newton iteration. As discussed in the introduction, we here use a   fixed step length and leave implementing a better strategy as an   exercise. ( [2.x.413]  does this differently: It simply uses an   external package for the whole solution process, and a good   line search strategy is part of what that package provides.)
//
[0.x.3498] 
[0.x.3499] 
[0.x.3500] 
[0.x.3501] 
[0.x.3502] 
[0.x.3503] 
//
[0.x.3504] 
[0.x.3505] 
[0.x.3506] 
[0.x.3507] 
[0.x.3508] 
[0.x.3509] 
[0.x.3510] 
[0.x.3511] 
[0.x.3512] 
//
[0.x.3513] 
//
[0.x.3514] 
[0.x.3515] 
//
[0.x.3516] 
//
[0.x.3517] 
[0.x.3518] 
//
[0.x.3519] 
[0.x.3520] 
[0.x.3521] 
[0.x.3522] 
//[2.x.414] 
//
// The boundary condition is implemented just like in  [2.x.415] .  It is chosen as  [2.x.416] :
//
[0.x.3523] 
[0.x.3524] 
[0.x.3525] 
[0.x.3526] 
[0.x.3527] 
[0.x.3528] 
[0.x.3529] 
//
[0.x.3530] 
[0.x.3531] 
[0.x.3532] 
[0.x.3533] 
[0.x.3534] 
[0.x.3535] 
//[2.x.417] 
//[2.x.418] 
//
// The constructor and destructor of the class are the same as in the first few tutorials.
//
[0.x.3536] 
[0.x.3537] 
[0.x.3538] 
[0.x.3539] 
[0.x.3540] 
//[2.x.419] 
//
// As always in the setup-system function, we setup the variables of the finite element method. There are same differences to  [2.x.420] , because there we start solving the PDE from scratch in every refinement cycle whereas here we need to take the solution from the previous mesh onto the current mesh. Consequently, we can't just reset solution vectors. The argument passed to this function thus indicates whether we can distributed degrees of freedom (plus compute constraints) and set the solution vector to zero or whether this has happened elsewhere already (specifically, in  [2.x.421] ).
//
[0.x.3541] 
[0.x.3542] 
[0.x.3543] 
[0.x.3544] 
[0.x.3545] 
[0.x.3546] 
[0.x.3547] 
//
[0.x.3548] 
[0.x.3549] 
[0.x.3550] 
[0.x.3551] 
[0.x.3552] 
//
// The remaining parts of the function are the same as in  [2.x.422] .
//
[0.x.3553] 
[0.x.3554] 
//
[0.x.3555] 
[0.x.3556] 
//
[0.x.3557] 
//
[0.x.3558] 
[0.x.3559] 
[0.x.3560] 
//[2.x.423] 
//
// This function does the same as in the previous tutorials except that now, of course, the matrix and right hand side functions depend on the previous iteration's solution. As discussed in the introduction, we need to use zero boundary values for the Newton updates; we compute them at the end of this function.
//
// The top of the function contains the usual boilerplate code, setting up the objects that allow us to evaluate shape functions at quadrature points and temporary storage locations for the local matrices and vectors, as well as for the gradients of the previous solution at the quadrature points. We then start the loop over all cells:
//
[0.x.3561] 
[0.x.3562] 
[0.x.3563] 
[0.x.3564] 
//
[0.x.3565] 
[0.x.3566] 
//
[0.x.3567] 
[0.x.3568] 
[0.x.3569] 
[0.x.3570] 
//
[0.x.3571] 
[0.x.3572] 
//
[0.x.3573] 
[0.x.3574] 
//
[0.x.3575] 
//
[0.x.3576] 
//
[0.x.3577] 
[0.x.3578] 
[0.x.3579] 
[0.x.3580] 
//
[0.x.3581] 
//
// For the assembly of the linear system, we have to obtain the values of the previous solution's gradients at the quadrature points. There is a standard way of doing this: the  [2.x.424]  function takes a vector that represents a finite element field defined on a DoFHandler, and evaluates the gradients of this field at the quadrature points of the cell with which the FEValues object has last been reinitialized. The values of the gradients at all quadrature points are then written into the second argument:
//
[0.x.3582] 
[0.x.3583] 
//
// With this, we can then do the integration loop over all quadrature points and shape functions.  Having just computed the gradients of the old solution in the quadrature points, we are able to compute the coefficients  [2.x.425]  in these points.  The assembly of the system itself then looks similar to what we always do with the exception of the nonlinear terms, as does copying the results from the local objects into the global ones:
//
[0.x.3584] 
[0.x.3585] 
[0.x.3586] 
[0.x.3587] 
[0.x.3588] 
//
[0.x.3589] 
[0.x.3590] 
[0.x.3591] 
[0.x.3592] 
[0.x.3593] 
[0.x.3594] 
[0.x.3595] 
[0.x.3596] 
[0.x.3597] 
[0.x.3598] 
[0.x.3599] 
[0.x.3600] 
[0.x.3601] 
[0.x.3602] 
//
[0.x.3603] 
[0.x.3604] 
[0.x.3605] 
[0.x.3606] 
[0.x.3607] 
[0.x.3608] 
//
[0.x.3609] 
[0.x.3610] 
[0.x.3611] 
[0.x.3612] 
[0.x.3613] 
[0.x.3614] 
[0.x.3615] 
//
[0.x.3616] 
[0.x.3617] 
[0.x.3618] 
//
// Finally, we remove hanging nodes from the system and apply zero boundary values to the linear system that defines the Newton updates  [2.x.426] :
//
[0.x.3619] 
[0.x.3620] 
//
[0.x.3621] 
[0.x.3622] 
[0.x.3623] 
[0.x.3624] 
[0.x.3625] 
[0.x.3626] 
[0.x.3627] 
[0.x.3628] 
[0.x.3629] 
[0.x.3630] 
//
//  [2.x.427] 
//
// The solve function is the same as always. At the end of the solution process we update the current solution by setting  [2.x.428] .
//
[0.x.3631] 
[0.x.3632] 
[0.x.3633] 
[0.x.3634] 
[0.x.3635] 
[0.x.3636] 
//
[0.x.3637] 
[0.x.3638] 
//
[0.x.3639] 
//
[0.x.3640] 
//
[0.x.3641] 
[0.x.3642] 
[0.x.3643] 
//[2.x.429] 
//
// The first part of this function is the same as in  [2.x.430] ... However, after refining the mesh we have to transfer the old solution to the new one which we do with the help of the SolutionTransfer class. The process is slightly convoluted, so let us describe it in detail:
//
[0.x.3644] 
[0.x.3645] 
[0.x.3646] 
[0.x.3647] 
//
[0.x.3648] 
[0.x.3649] 
[0.x.3650] 
[0.x.3651] 
[0.x.3652] 
[0.x.3653] 
//
[0.x.3654] 
[0.x.3655] 
[0.x.3656] 
[0.x.3657] 
//
// Then we need an additional step: if, for example, you flag a cell that is once more refined than its neighbor, and that neighbor is not flagged for refinement, we would end up with a jump of two refinement levels across a cell interface.  To avoid these situations, the library will silently also have to refine the neighbor cell once. It does so by calling the  [2.x.431]  function before actually doing the refinement and coarsening.  This function flags a set of additional cells for refinement or coarsening, to enforce rules like the one-hanging-node rule.  The cells that are flagged for refinement and coarsening after calling this function are exactly the ones that will actually be refined or coarsened. Usually, you don't have to do this by hand  [2.x.432]  does this for you). However, we need to initialize the SolutionTransfer class and it needs to know the final set of cells that will be coarsened or refined in order to store the data from the old mesh and transfer to the new one. Thus, we call the function by hand:
//
[0.x.3658] 
//
// With this out of the way, we initialize a SolutionTransfer object with the present DoFHandler and attach the solution vector to it, followed by doing the actual refinement and distribution of degrees of freedom on the new mesh
//
[0.x.3659] 
[0.x.3660] 
//
[0.x.3661] 
//
[0.x.3662] 
//
// Finally, we retrieve the old solution interpolated to the new mesh. Since the SolutionTransfer function does not actually store the values of the old solution, but rather indices, we need to preserve the old solution vector until we have gotten the new interpolated values. Thus, we have the new values written into a temporary vector, and only afterwards write them into the solution vector object:
//
[0.x.3663] 
[0.x.3664] 
[0.x.3665] 
//
// On the new mesh, there are different hanging nodes, for which we have to compute constraints again, after throwing away previous content of the object. To be on the safe side, we should then also make sure that the current solution's vector entries satisfy the hanging node constraints (see the discussion in the documentation of the SolutionTransfer class for why this is necessary). We could do this by calling `hanging_node_constraints.distribute(current_solution)` explicitly; we omit this step because this will happen at the end of the call to `set_boundary_values()` below, and it is not necessary to do it twice.
//
[0.x.3666] 
//
[0.x.3667] 
[0.x.3668] 
[0.x.3669] 
//
// Once we have the interpolated solution and all information about hanging nodes, we have to make sure that the  [2.x.433]  we now have actually has the correct boundary values. As explained at the end of the introduction, this is not automatically the case even if the solution before refinement had the correct boundary values, and so we have to explicitly make sure that it now has:
//
[0.x.3670] 
//
// We end the function by updating all the remaining data structures, indicating to  [2.x.434]  that this is not the first go-around and that it needs to preserve the content of the solution vector:
//
[0.x.3671] 
[0.x.3672] 
//
//  [2.x.435] 
//
// The next function ensures that the solution vector's entries respect the boundary values for our problem.  Having refined the mesh (or just started computations), there might be new nodal points on the boundary. These have values that are simply interpolated from the previous mesh in `refine_mesh()`, instead of the correct boundary values. This is fixed up by setting all boundary nodes of the current solution vector explicit to the right value.
//
// There is one issue we have to pay attention to, though: If we have a hanging node right next to a new boundary node, then its value must also be adjusted to make sure that the finite element field remains continuous. This is what the call in the last line of this function does.
//
[0.x.3673] 
[0.x.3674] 
[0.x.3675] 
[0.x.3676] 
[0.x.3677] 
[0.x.3678] 
[0.x.3679] 
[0.x.3680] 
[0.x.3681] 
[0.x.3682] 
//
[0.x.3683] 
[0.x.3684] 
//[2.x.436] 
//
// In order to monitor convergence, we need a way to compute the norm of the (discrete) residual, i.e., the norm of the vector  [2.x.437]  with  [2.x.438]  as discussed in the introduction. It turns out that (although we don't use this feature in the current version of the program) one needs to compute the residual  [2.x.439]  when determining optimal step lengths, and so this is what we implement here: the function takes the step length  [2.x.440]  as an argument. The original functionality is of course obtained by passing a zero as argument.
//
// In the function below, we first set up a vector for the residual, and then a vector for the evaluation point  [2.x.441] . This is followed by the same boilerplate code we use for all integration operations:
//
[0.x.3685] 
[0.x.3686] 
[0.x.3687] 
[0.x.3688] 
//
[0.x.3689] 
[0.x.3690] 
[0.x.3691] 
//
[0.x.3692] 
[0.x.3693] 
[0.x.3694] 
[0.x.3695] 
[0.x.3696] 
//
[0.x.3697] 
[0.x.3698] 
//
[0.x.3699] 
[0.x.3700] 
//
[0.x.3701] 
//
[0.x.3702] 
[0.x.3703] 
[0.x.3704] 
[0.x.3705] 
//
// The actual computation is much as in  [2.x.442] . We first evaluate the gradients of  [2.x.443]  at the quadrature points, then compute the coefficient  [2.x.444] , and then plug it all into the formula for the residual:
//
[0.x.3706] 
//
[0.x.3707] 
[0.x.3708] 
[0.x.3709] 
[0.x.3710] 
//
[0.x.3711] 
[0.x.3712] 
[0.x.3713] 
[0.x.3714] 
[0.x.3715] 
[0.x.3716] 
//
[0.x.3717] 
[0.x.3718] 
[0.x.3719] 
[0.x.3720] 
//
// At the end of this function we also have to deal with the hanging node constraints and with the issue of boundary values. With regard to the latter, we have to set to zero the elements of the residual vector for all entries that correspond to degrees of freedom that sit at the boundary. The reason is that because the value of the solution there is fixed, they are of course no "real" degrees of freedom and so, strictly speaking, we shouldn't have assembled entries in the residual vector for them. However, as we always do, we want to do exactly the same thing on every cell and so we didn't not want to deal with the question of whether a particular degree of freedom sits at the boundary in the integration above. Rather, we will simply set to zero these entries after the fact. To this end, we need to determine which degrees of freedom do in fact belong to the boundary and then loop over all of those and set the residual entry to zero. This happens in the following lines which we have already seen used in  [2.x.445] , using the appropriate function from namespace DoFTools:
//
[0.x.3721] 
//
[0.x.3722] 
[0.x.3723] 
[0.x.3724] 
//
// At the end of the function, we return the norm of the residual:
//
[0.x.3725] 
[0.x.3726] 
//
//  [2.x.446] 
//
// As discussed in the introduction, Newton's method frequently does not converge if we always take full steps, i.e., compute  [2.x.447] . Rather, one needs a damping parameter (step length)  [2.x.448]  and set  [2.x.449] . This function is the one called to compute  [2.x.450] .
//
// Here, we simply always return 0.1. This is of course a sub-optimal choice: ideally, what one wants is that the step size goes to one as we get closer to the solution, so that we get to enjoy the rapid quadratic convergence of Newton's method. We will discuss better strategies below in the results section, and  [2.x.451]  also covers this aspect.
//
[0.x.3727] 
[0.x.3728] 
[0.x.3729] 
[0.x.3730] 
[0.x.3731] 
//
//  [2.x.452] 
//
// This last function to be called from `run()` outputs the current solution (and the Newton update) in graphical form as a VTU file. It is entirely the same as what has been used in previous tutorials.
//
[0.x.3732] 
[0.x.3733] 
[0.x.3734] 
[0.x.3735] 
[0.x.3736] 
//
[0.x.3737] 
[0.x.3738] 
[0.x.3739] 
[0.x.3740] 
//
[0.x.3741] 
[0.x.3742] 
[0.x.3743] 
[0.x.3744] 
[0.x.3745] 
//[2.x.453] 
//
// In the run function, we build the first grid and then have the top-level logic for the Newton iteration.
//
// As described in the introduction, the domain is the unit disk around the origin, created in the same way as shown in  [2.x.454] . The mesh is globally refined twice followed later on by several adaptive cycles.
//
// Before starting the Newton loop, we also need to do a bit of setup work: We need to create the basic data structures and ensure that the first Newton iterate already has the correct boundary values, as discussed in the introduction.
//
[0.x.3746] 
[0.x.3747] 
[0.x.3748] 
[0.x.3749] 
[0.x.3750] 
//
[0.x.3751] 
[0.x.3752] 
//
// The Newton iteration starts next. We iterate until the (norm of the) residual computed at the end of the previous iteration is less than  [2.x.455] , as checked at the end of the `do { ... } while` loop that starts here. Because we don't have a reasonable value to initialize the variable, we just use the largest value that can be represented as a `double`.
//
[0.x.3753] 
[0.x.3754] 
[0.x.3755] 
[0.x.3756] 
[0.x.3757] 
//
[0.x.3758] 
[0.x.3759] 
//
// On every mesh we do exactly five Newton steps. We print the initial residual here and then start the iterations on this mesh.
//
// In every Newton step the system matrix and the right hand side have to be computed first, after which we store the norm of the right hand side as the residual to check against when deciding whether to stop the iterations. We then solve the linear system (the function also updates  [2.x.456] ) and output the norm of the residual at the end of this Newton step.
//
// After the end of this loop, we then also output the solution on the current mesh in graphical form and increment the counter for the mesh refinement cycle.
//
[0.x.3760] 
//
[0.x.3761] 
[0.x.3762] 
[0.x.3763] 
[0.x.3764] 
[0.x.3765] 
//
[0.x.3766] 
//
[0.x.3767] 
[0.x.3768] 
//
[0.x.3769] 
//
[0.x.3770] 
[0.x.3771] 
[0.x.3772] 
[0.x.3773] 
[0.x.3774] 
[0.x.3775] 
//[2.x.457] 
//
// Finally the main function. This follows the scheme of all other main functions:
//
[0.x.3776] 
[0.x.3777] 
[0.x.3778] 
[0.x.3779] 
[0.x.3780] 
//
[0.x.3781] 
[0.x.3782] 
[0.x.3783] 
[0.x.3784] 
[0.x.3785] 
[0.x.3786] 
[0.x.3787] 
[0.x.3788] 
[0.x.3789] 
[0.x.3790] 
[0.x.3791] 
[0.x.3792] 
[0.x.3793] 
[0.x.3794] 
//
[0.x.3795] 
[0.x.3796] 
[0.x.3797] 
[0.x.3798] 
[0.x.3799] 
[0.x.3800] 
[0.x.3801] 
[0.x.3802] 
[0.x.3803] 
[0.x.3804] 
[0.x.3805] 
[0.x.3806] 
[0.x.3807] 
[0.x.3808] 
[0.x.3809] 
[0.x.3810] 
[0.x.3811] 
[0.x.3812] 
[0.x.3813] 
[0.x.3814] 
[0.x.3815] 
[0.x.3816] 
[0.x.3817] 
[0.x.3818] 
[0.x.3819] 
[0.x.3820] 
[0.x.3821] 
[0.x.3822] 
[0.x.3823] 
[0.x.3824] 
[0.x.3825] 
[0.x.3826] 
[0.x.3827] 
[0.x.3828] 
[0.x.3829] 
[0.x.3830] 
//[2.x.458] 
//
// Again, the first few include files are already known, so we won't comment on them:
//
[0.x.3831] 
[0.x.3832] 
[0.x.3833] 
[0.x.3834] 
//
[0.x.3835] 
[0.x.3836] 
[0.x.3837] 
[0.x.3838] 
[0.x.3839] 
[0.x.3840] 
//
[0.x.3841] 
[0.x.3842] 
[0.x.3843] 
//
[0.x.3844] 
//
[0.x.3845] 
[0.x.3846] 
//
[0.x.3847] 
[0.x.3848] 
[0.x.3849] 
//
// These, now, are the include necessary for the multilevel methods. The first one declares how to handle Dirichlet boundary conditions on each of the levels of the multigrid method. For the actual description of the degrees of freedom, we do not need any new include file because DoFHandler already has all necessary methods implemented. We will only need to distribute the DoFs for the levels further down.
//
// The rest of the include files deals with the mechanics of multigrid as a linear operator (solver or preconditioner).
//
[0.x.3850] 
[0.x.3851] 
[0.x.3852] 
[0.x.3853] 
[0.x.3854] 
[0.x.3855] 
[0.x.3856] 
//
// We will be using  [2.x.459]  to loop over the cells, so include it here:
//
[0.x.3857] 
//
// This is C++:
//
[0.x.3858] 
[0.x.3859] 
//
[0.x.3860] 
//
[0.x.3861] 
[0.x.3862] 
//[2.x.460] 
//
// We use  [2.x.461]  to assemble our matrices. For this, we need a ScratchData object to store temporary data on each cell (this is just the FEValues object) and a CopyData object that will contain the output of each cell assembly. For more details about the usage of scratch and copy objects, see the WorkStream namespace.
//
[0.x.3863] 
[0.x.3864] 
[0.x.3865] 
[0.x.3866] 
[0.x.3867] 
[0.x.3868] 
[0.x.3869] 
[0.x.3870] 
[0.x.3871] 
//
[0.x.3872] 
[0.x.3873] 
[0.x.3874] 
[0.x.3875] 
[0.x.3876] 
[0.x.3877] 
//
[0.x.3878] 
[0.x.3879] 
//
[0.x.3880] 
[0.x.3881] 
[0.x.3882] 
[0.x.3883] 
[0.x.3884] 
[0.x.3885] 
//
[0.x.3886] 
[0.x.3887] 
[0.x.3888] 
[0.x.3889] 
[0.x.3890] 
//
[0.x.3891] 
[0.x.3892] 
[0.x.3893] 
[0.x.3894] 
[0.x.3895] 
//[2.x.462] 
//
// This main class is similar to the same class in  [2.x.463] . As far as member functions is concerned, the only additions are:
//
// - The  [2.x.464]  function that assembles the matrices that correspond to the discrete operators on intermediate levels.
//
// - The  [2.x.465]  function that assembles our PDE on a single cell.
//
[0.x.3896] 
[0.x.3897] 
[0.x.3898] 
[0.x.3899] 
[0.x.3900] 
[0.x.3901] 
//
[0.x.3902] 
[0.x.3903] 
[0.x.3904] 
[0.x.3905] 
[0.x.3906] 
//
[0.x.3907] 
[0.x.3908] 
[0.x.3909] 
[0.x.3910] 
[0.x.3911] 
[0.x.3912] 
//
[0.x.3913] 
[0.x.3914] 
[0.x.3915] 
//
[0.x.3916] 
[0.x.3917] 
//
[0.x.3918] 
//
[0.x.3919] 
[0.x.3920] 
//
[0.x.3921] 
//
// The following members are the essential data structures for the multigrid method. The first four represent the sparsity patterns and the matrices on individual levels of the multilevel hierarchy, very much like the objects for the global mesh above.
//
// Then we have two new matrices only needed for multigrid methods with local smoothing on adaptive meshes. They convey data between the interior part of the refined region and the refinement edge, as outlined in detail in the  [2.x.466]  "multigrid paper".
//
// The last object stores information about the boundary indices on each level and information about indices lying on a refinement edge between two different refinement levels. It thus serves a similar purpose as AffineConstraints, but on each level.
//
[0.x.3922] 
[0.x.3923] 
//
[0.x.3924] 
[0.x.3925] 
[0.x.3926] 
[0.x.3927] 
//[2.x.467] 
//
// Just one short remark about the constructor of the Triangulation: by convention, all adaptively refined triangulations in deal.II never change by more than one level across a face between cells. For our multigrid algorithms, however, we need a slightly stricter guarantee, namely that the mesh also does not change by more than refinement level across vertices that might connect two cells. In other words, we must prevent the following situation:
//
//  [2.x.468] 
//
// This is achieved by passing the  [2.x.469]  flag to the constructor of the triangulation class.
//
[0.x.3928] 
[0.x.3929] 
[0.x.3930] 
[0.x.3931] 
[0.x.3932] 
[0.x.3933] 
[0.x.3934] 
//
//  [2.x.470] 
//
// In addition to just distributing the degrees of freedom in the DoFHandler, we do the same on each level. Then, we follow the same procedure as before to set up the system on the leaf mesh.
//
[0.x.3935] 
[0.x.3936] 
[0.x.3937] 
[0.x.3938] 
[0.x.3939] 
//
[0.x.3940] 
[0.x.3941] 
[0.x.3942] 
[0.x.3943] 
[0.x.3944] 
[0.x.3945] 
//
[0.x.3946] 
[0.x.3947] 
//
[0.x.3948] 
[0.x.3949] 
//
[0.x.3950] 
[0.x.3951] 
[0.x.3952] 
[0.x.3953] 
[0.x.3954] 
[0.x.3955] 
[0.x.3956] 
[0.x.3957] 
[0.x.3958] 
//
[0.x.3959] 
[0.x.3960] 
[0.x.3961] 
[0.x.3962] 
[0.x.3963] 
[0.x.3964] 
//
// The multigrid constraints have to be initialized. They need to know where Dirichlet boundary conditions are prescribed.
//
[0.x.3965] 
[0.x.3966] 
[0.x.3967] 
[0.x.3968] 
//
// Now for the things that concern the multigrid data structures. First, we resize the multilevel objects to hold matrices and sparsity patterns for every level. The coarse level is zero (this is mandatory right now but may change in a future revision). Note that these functions take a complete, inclusive range here (not a starting index and size), so the finest level is  [2.x.471] . We first have to resize the container holding the SparseMatrix classes, since they have to release their SparsityPattern before the can be destroyed upon resizing.
//
[0.x.3969] 
//
[0.x.3970] 
[0.x.3971] 
[0.x.3972] 
[0.x.3973] 
//
// Now, we have to provide a matrix on each level. To this end, we first use the  [2.x.472]  function to generate a preliminary compressed sparsity pattern on each level (see the  [2.x.473]  module for more information on this topic) and then copy it over to the one we really want. The next step is to initialize the interface matrices with the fitting sparsity pattern.
//
// It may be worth pointing out that the interface matrices only have entries for degrees of freedom that sit at or next to the interface between coarser and finer levels of the mesh. They are therefore even sparser than the matrices on the individual levels of our multigrid hierarchy. Therefore, we use a function specifically build for this purpose to generate it.
//
[0.x.3974] 
[0.x.3975] 
[0.x.3976] 
[0.x.3977] 
[0.x.3978] 
[0.x.3979] 
//
[0.x.3980] 
[0.x.3981] 
[0.x.3982] 
[0.x.3983] 
[0.x.3984] 
[0.x.3985] 
[0.x.3986] 
[0.x.3987] 
[0.x.3988] 
[0.x.3989] 
[0.x.3990] 
[0.x.3991] 
[0.x.3992] 
[0.x.3993] 
[0.x.3994] 
[0.x.3995] 
//[2.x.474] 
//
// The cell_worker function is used to assemble the matrix and right-hand side on the given cell. This function is used for the active cells to generate the system_matrix and on each level to build the level matrices.
//
// Note that we also assemble a right-hand side when called from assemble_multigrid() even though it is not used.
//
[0.x.3996] 
[0.x.3997] 
[0.x.3998] 
[0.x.3999] 
[0.x.4000] 
[0.x.4001] 
[0.x.4002] 
[0.x.4003] 
//
[0.x.4004] 
[0.x.4005] 
//
[0.x.4006] 
//
[0.x.4007] 
//
[0.x.4008] 
[0.x.4009] 
[0.x.4010] 
[0.x.4011] 
//
[0.x.4012] 
[0.x.4013] 
[0.x.4014] 
[0.x.4015] 
[0.x.4016] 
[0.x.4017] 
[0.x.4018] 
[0.x.4019] 
[0.x.4020] 
[0.x.4021] 
[0.x.4022] 
[0.x.4023] 
[0.x.4024] 
//
//  [2.x.475] 
//
// The following function assembles the linear system on the active cells of the mesh. For this, we pass two lambda functions to the mesh_loop() function. The cell_worker function redirects to the class member function of the same name, while the copier is specific to this function and copies local matrix and vector to the corresponding global ones using the constraints.
//
[0.x.4025] 
[0.x.4026] 
[0.x.4027] 
[0.x.4028] 
//
[0.x.4029] 
[0.x.4030] 
[0.x.4031] 
[0.x.4032] 
[0.x.4033] 
[0.x.4034] 
//
[0.x.4035] 
[0.x.4036] 
[0.x.4037] 
[0.x.4038] 
[0.x.4039] 
[0.x.4040] 
[0.x.4041] 
//
[0.x.4042] 
//
[0.x.4043] 
[0.x.4044] 
[0.x.4045] 
[0.x.4046] 
[0.x.4047] 
[0.x.4048] 
//
[0.x.4049] 
[0.x.4050] 
[0.x.4051] 
[0.x.4052] 
[0.x.4053] 
[0.x.4054] 
[0.x.4055] 
[0.x.4056] 
//[2.x.476] 
//
// The next function is the one that builds the matrices that define the multigrid method on each level of the mesh. The integration core is the same as above, but the loop below will go over all existing cells instead of just the active ones, and the results must be entered into the correct level matrices. Fortunately, MeshWorker hides most of that from us, and thus the difference between this function and the previous lies only in the setup of the assembler and the different iterators in the loop.
//
// We generate an AffineConstraints object for each level containing the boundary and interface dofs as constrained entries. The corresponding object is then used to generate the level matrices.
//
[0.x.4057] 
[0.x.4058] 
[0.x.4059] 
[0.x.4060] 
[0.x.4061] 
//
[0.x.4062] 
[0.x.4063] 
[0.x.4064] 
[0.x.4065] 
[0.x.4066] 
[0.x.4067] 
[0.x.4068] 
[0.x.4069] 
[0.x.4070] 
[0.x.4071] 
[0.x.4072] 
[0.x.4073] 
[0.x.4074] 
[0.x.4075] 
//
[0.x.4076] 
[0.x.4077] 
[0.x.4078] 
[0.x.4079] 
[0.x.4080] 
[0.x.4081] 
//
[0.x.4082] 
[0.x.4083] 
[0.x.4084] 
//
[0.x.4085] 
//
// Interface entries are ignored by the boundary_constraints object above when filling the mg_matrices[cd.level]. Instead, we copy these entries into the interface matrix of the current level manually:
//
[0.x.4086] 
[0.x.4087] 
[0.x.4088] 
[0.x.4089] 
[0.x.4090] 
[0.x.4091] 
[0.x.4092] 
[0.x.4093] 
[0.x.4094] 
[0.x.4095] 
//
[0.x.4096] 
//
[0.x.4097] 
[0.x.4098] 
[0.x.4099] 
[0.x.4100] 
[0.x.4101] 
[0.x.4102] 
//
[0.x.4103] 
[0.x.4104] 
[0.x.4105] 
[0.x.4106] 
[0.x.4107] 
[0.x.4108] 
[0.x.4109] 
[0.x.4110] 
//
//  [2.x.477] 
//
// This is the other function that is significantly different in support of the multigrid solver (or, in fact, the preconditioner for which we use the multigrid method).
//
// Let us start out by setting up two of the components of multilevel methods: transfer operators between levels, and a solver on the coarsest level. In finite element methods, the transfer operators are derived from the finite element function spaces involved and can often be computed in a generic way independent of the problem under consideration. In that case, we can use the MGTransferPrebuilt class that, given the constraints of the final linear system and the MGConstrainedDoFs object that knows about the boundary conditions on the each level and the degrees of freedom on interfaces between different refinement level can build the matrices for those transfer operations from a DoFHandler object with level degrees of freedom.
//
// The second part of the following lines deals with the coarse grid solver. Since our coarse grid is very coarse indeed, we decide for a direct solver (a Householder decomposition of the coarsest level matrix), even if its implementation is not particularly sophisticated. If our coarse mesh had many more cells than the five we have here, something better suited would obviously be necessary here.
//
[0.x.4111] 
[0.x.4112] 
[0.x.4113] 
[0.x.4114] 
[0.x.4115] 
//
[0.x.4116] 
[0.x.4117] 
[0.x.4118] 
[0.x.4119] 
//
// The next component of a multilevel solver or preconditioner is that we need a smoother on each level. A common choice for this is to use the application of a relaxation method (such as the SOR, Jacobi or Richardson method) or a small number of iterations of a solver method (such as CG or GMRES). The  [2.x.478]  and MGSmootherPrecondition classes provide support for these two kinds of smoothers. Here, we opt for the application of a single SOR iteration. To this end, we define an appropriate alias and then setup a smoother object.
//
// The last step is to initialize the smoother object with our level matrices and to set some smoothing parameters. The  [2.x.479]  function can optionally take additional arguments that will be passed to the smoother object on each level. In the current case for the SOR smoother, this could, for example, include a relaxation parameter. However, we here leave these at their default values. The call to  [2.x.480]  indicates that we will use two pre- and two post-smoothing steps on each level; to use a variable number of smoother steps on different levels, more options can be set in the constructor call to the  [2.x.481]  object.
//
// The last step results from the fact that we use the SOR method as a smoother
//
// - which is not symmetric
//
// - but we use the conjugate gradient iteration (which requires a symmetric preconditioner) below, we need to let the multilevel preconditioner make sure that we get a symmetric operator even for nonsymmetric smoothers:
//
[0.x.4120] 
[0.x.4121] 
[0.x.4122] 
[0.x.4123] 
[0.x.4124] 
//
// The next preparatory step is that we must wrap our level and interface matrices in an object having the required multiplication functions. We will create two objects for the interface objects going from coarse to fine and the other way around; the multigrid algorithm will later use the transpose operator for the latter operation, allowing us to initialize both up and down versions of the operator with the matrices we already built:
//
[0.x.4125] 
[0.x.4126] 
[0.x.4127] 
//
// Now, we are ready to set up the V-cycle operator and the multilevel preconditioner.
//
[0.x.4128] 
[0.x.4129] 
[0.x.4130] 
//
[0.x.4131] 
[0.x.4132] 
//
// With all this together, we can finally get about solving the linear system in the usual way:
//
[0.x.4133] 
[0.x.4134] 
//
[0.x.4135] 
//
[0.x.4136] 
[0.x.4137] 
[0.x.4138] 
[0.x.4139] 
[0.x.4140] 
[0.x.4141] 
//
//  [2.x.482] 
//
// The following two functions postprocess a solution once it is computed. In particular, the first one refines the mesh at the beginning of each cycle while the second one outputs results at the end of each such cycle. The functions are almost unchanged from those in  [2.x.483] .
//
[0.x.4142] 
[0.x.4143] 
[0.x.4144] 
[0.x.4145] 
//
[0.x.4146] 
[0.x.4147] 
[0.x.4148] 
[0.x.4149] 
[0.x.4150] 
[0.x.4151] 
[0.x.4152] 
[0.x.4153] 
[0.x.4154] 
[0.x.4155] 
[0.x.4156] 
[0.x.4157] 
//
[0.x.4158] 
[0.x.4159] 
[0.x.4160] 
[0.x.4161] 
//
[0.x.4162] 
[0.x.4163] 
[0.x.4164] 
//
[0.x.4165] 
[0.x.4166] 
[0.x.4167] 
//[2.x.484] 
//
// Like several of the functions above, this is almost exactly a copy of the corresponding function in  [2.x.485] . The only difference is the call to  [2.x.486]  that takes care of forming the matrices on every level that we need in the multigrid method.
//
[0.x.4168] 
[0.x.4169] 
[0.x.4170] 
[0.x.4171] 
[0.x.4172] 
[0.x.4173] 
//
[0.x.4174] 
[0.x.4175] 
[0.x.4176] 
[0.x.4177] 
[0.x.4178] 
[0.x.4179] 
[0.x.4180] 
//
[0.x.4181] 
[0.x.4182] 
//
[0.x.4183] 
//
[0.x.4184] 
[0.x.4185] 
//
[0.x.4186] 
[0.x.4187] 
[0.x.4188] 
[0.x.4189] 
[0.x.4190] 
//[2.x.487] 
//
// This is again the same function as in  [2.x.488] :
//
[0.x.4191] 
[0.x.4192] 
[0.x.4193] 
[0.x.4194] 
[0.x.4195] 
//
[0.x.4196] 
[0.x.4197] 
[0.x.4198] 
[0.x.4199] 
[0.x.4200] 
[0.x.4201] 
[0.x.4202] 
[0.x.4203] 
[0.x.4204] 
[0.x.4205] 
[0.x.4206] 
[0.x.4207] 
[0.x.4208] 
[0.x.4209] 
//
[0.x.4210] 
[0.x.4211] 
[0.x.4212] 
[0.x.4213] 
[0.x.4214] 
[0.x.4215] 
[0.x.4216] 
[0.x.4217] 
[0.x.4218] 
[0.x.4219] 
[0.x.4220] 
[0.x.4221] 
[0.x.4222] 
[0.x.4223] 
//
[0.x.4224] 
[0.x.4225] 
[0.x.4226] 
[0.x.4227] 
[0.x.4228] 
[0.x.4229] 
[0.x.4230] 
[0.x.4231] 
[0.x.4232] 
[0.x.4233] 
[0.x.4234] 
[0.x.4235] 
[0.x.4236] 
[0.x.4237] 
[0.x.4238] 
[0.x.4239] 
[0.x.4240] 
[0.x.4241] 
[0.x.4242] 
[0.x.4243] 
[0.x.4244] 
//[2.x.489] 
//
// Again, the first few include files are already known, so we won't comment on them:
//
[0.x.4245] 
[0.x.4246] 
[0.x.4247] 
[0.x.4248] 
//
[0.x.4249] 
[0.x.4250] 
[0.x.4251] 
[0.x.4252] 
[0.x.4253] 
[0.x.4254] 
//
[0.x.4255] 
[0.x.4256] 
[0.x.4257] 
//
[0.x.4258] 
//
[0.x.4259] 
[0.x.4260] 
//
[0.x.4261] 
[0.x.4262] 
[0.x.4263] 
//
// These, now, are the include necessary for the multilevel methods. The first one declares how to handle Dirichlet boundary conditions on each of the levels of the multigrid method. For the actual description of the degrees of freedom, we do not need any new include file because DoFHandler already has all necessary methods implemented. We will only need to distribute the DoFs for the levels further down.
//
// The rest of the include files deals with the mechanics of multigrid as a linear operator (solver or preconditioner).
//
[0.x.4264] 
[0.x.4265] 
[0.x.4266] 
[0.x.4267] 
[0.x.4268] 
[0.x.4269] 
[0.x.4270] 
//
// Finally we include the MeshWorker framework. This framework through its function loop() and integration_loop(), automates loops over cells and assembling of data into vectors, matrices, etc. It obeys constraints automatically. Since we have to build several matrices and have to be aware of several sets of constraints, this will save us a lot of headache.
//
[0.x.4271] 
[0.x.4272] 
[0.x.4273] 
[0.x.4274] 
[0.x.4275] 
//
// In order to save effort, we use the pre-implemented Laplacian found in
//
[0.x.4276] 
[0.x.4277] 
//
// This is C++:
//
[0.x.4278] 
[0.x.4279] 
//
[0.x.4280] 
//
[0.x.4281] 
[0.x.4282] 
//[2.x.490] 
//
// The  [2.x.491]  expects a class that provides functions for integration on cells and boundary and interior faces. This is done by the following class. In the constructor, we tell the loop that cell integrals should be computed (the 'true'), but integrals should not be computed on boundary and interior faces (the two 'false'). Accordingly, we only need a cell function, but none for the faces.
//
[0.x.4283] 
[0.x.4284] 
[0.x.4285] 
[0.x.4286] 
[0.x.4287] 
[0.x.4288] 
[0.x.4289] 
[0.x.4290] 
//
[0.x.4291] 
[0.x.4292] 
[0.x.4293] 
[0.x.4294] 
//
// Next the actual integrator on each cell. We solve a Poisson problem with a coefficient one in the right half plane and one tenth in the left half plane.
//
// The  [2.x.492]  base class of  [2.x.493]  contains objects that can be filled in this local integrator. How many objects are created is determined inside the MeshWorker framework by the assembler class. Here, we test for instance that one matrix is required  [2.x.494]  The matrices are accessed through  [2.x.495]  which takes the number of the matrix as its first argument. The second argument is only used for integrals over faces when there are two matrices for each test function used. Then, a second matrix with indicator 'true' would exist with the same index.
//
//  [2.x.496]  provides one or several FEValues objects, which below are used by  [2.x.497]  or  [2.x.498]  Since we are assembling only a single PDE, there is also only one of these objects with index zero.
//
// In addition, we note that this integrator serves to compute the matrices for the multilevel preconditioner as well as the matrix and the right hand side for the global system. Since the assembler for a system requires an additional vector,  [2.x.499]  is returning a nonzero value. Accordingly, we fill a right hand side vector at the end of this function. Since LocalResults can deal with several BlockVector objects, but we are again in the simplest case here, we enter the information into block zero of vector zero.
//
[0.x.4295] 
[0.x.4296] 
[0.x.4297] 
[0.x.4298] 
[0.x.4299] 
[0.x.4300] 
[0.x.4301] 
//
[0.x.4302] 
[0.x.4303] 
[0.x.4304] 
//
[0.x.4305] 
[0.x.4306] 
[0.x.4307] 
[0.x.4308] 
[0.x.4309] 
[0.x.4310] 
[0.x.4311] 
[0.x.4312] 
//[2.x.500] 
//
// This main class is basically the same class as in  [2.x.501] . As far as member functions is concerned, the only addition is the  [2.x.502]  function that assembles the matrices that correspond to the discrete operators on intermediate levels:
//
[0.x.4313] 
[0.x.4314] 
[0.x.4315] 
[0.x.4316] 
[0.x.4317] 
[0.x.4318] 
//
[0.x.4319] 
[0.x.4320] 
[0.x.4321] 
[0.x.4322] 
[0.x.4323] 
[0.x.4324] 
[0.x.4325] 
//
[0.x.4326] 
[0.x.4327] 
[0.x.4328] 
//
[0.x.4329] 
[0.x.4330] 
//
[0.x.4331] 
//
[0.x.4332] 
[0.x.4333] 
//
[0.x.4334] 
//
// The following members are the essential data structures for the multigrid method. The first two represent the sparsity patterns and the matrices on individual levels of the multilevel hierarchy, very much like the objects for the global mesh above.
//
// Then we have two new matrices only needed for multigrid methods with local smoothing on adaptive meshes. They convey data between the interior part of the refined region and the refinement edge, as outlined in detail in the  [2.x.503]  "multigrid paper".
//
// The last object stores information about the boundary indices on each level and information about indices lying on a refinement edge between two different refinement levels. It thus serves a similar purpose as AffineConstraints, but on each level.
//
[0.x.4335] 
[0.x.4336] 
[0.x.4337] 
[0.x.4338] 
[0.x.4339] 
[0.x.4340] 
//[2.x.504] 
//
// Just one short remark about the constructor of the Triangulation: by convention, all adaptively refined triangulations in deal.II never change by more than one level across a face between cells. For our multigrid algorithms, however, we need a slightly stricter guarantee, namely that the mesh also does not change by more than refinement level across vertices that might connect two cells. In other words, we must prevent the following situation:
//
//  [2.x.505] 
//
// This is achieved by passing the  [2.x.506]  flag to the constructor of the triangulation class.
//
[0.x.4341] 
[0.x.4342] 
[0.x.4343] 
[0.x.4344] 
[0.x.4345] 
[0.x.4346] 
[0.x.4347] 
//
//  [2.x.507] 
//
// In addition to just distributing the degrees of freedom in the DoFHandler, we do the same on each level. Then, we follow the same procedure as before to set up the system on the leaf mesh.
//
[0.x.4348] 
[0.x.4349] 
[0.x.4350] 
[0.x.4351] 
[0.x.4352] 
//
[0.x.4353] 
[0.x.4354] 
[0.x.4355] 
[0.x.4356] 
[0.x.4357] 
[0.x.4358] 
//
[0.x.4359] 
[0.x.4360] 
//
[0.x.4361] 
[0.x.4362] 
//
[0.x.4363] 
[0.x.4364] 
//
[0.x.4365] 
[0.x.4366] 
[0.x.4367] 
[0.x.4368] 
[0.x.4369] 
[0.x.4370] 
[0.x.4371] 
[0.x.4372] 
[0.x.4373] 
[0.x.4374] 
[0.x.4375] 
[0.x.4376] 
//
// The multigrid constraints have to be initialized. They need to know about the boundary values as well, so we pass the  [2.x.508]  here as well.
//
[0.x.4377] 
[0.x.4378] 
[0.x.4379] 
[0.x.4380] 
//
// Now for the things that concern the multigrid data structures. First, we resize the multilevel objects to hold matrices and sparsity patterns for every level. The coarse level is zero (this is mandatory right now but may change in a future revision). Note that these functions take a complete, inclusive range here (not a starting index and size), so the finest level is  [2.x.509] . We first have to resize the container holding the SparseMatrix classes, since they have to release their SparsityPattern before the can be destroyed upon resizing.
//
[0.x.4381] 
//
[0.x.4382] 
[0.x.4383] 
[0.x.4384] 
[0.x.4385] 
[0.x.4386] 
[0.x.4387] 
[0.x.4388] 
//
// Now, we have to provide a matrix on each level. To this end, we first use the  [2.x.510]  function to generate a preliminary compressed sparsity pattern on each level (see the  [2.x.511]  module for more information on this topic) and then copy it over to the one we really want. The next step is to initialize both kinds of level matrices with these sparsity patterns.
//
// It may be worth pointing out that the interface matrices only have entries for degrees of freedom that sit at or next to the interface between coarser and finer levels of the mesh. They are therefore even sparser than the matrices on the individual levels of our multigrid hierarchy. If we were more concerned about memory usage (and possibly the speed with which we can multiply with these matrices), we should use separate and different sparsity patterns for these two kinds of matrices.
//
[0.x.4389] 
[0.x.4390] 
[0.x.4391] 
[0.x.4392] 
[0.x.4393] 
//
[0.x.4394] 
//
[0.x.4395] 
[0.x.4396] 
[0.x.4397] 
[0.x.4398] 
[0.x.4399] 
//[2.x.512] 
//
// The following function assembles the linear system on the finest level of the mesh. Since we want to reuse the code here for the level assembling below, we use the local integrator class LaplaceIntegrator and leave the loops to the MeshWorker framework. Thus, this function first sets up the objects necessary for this framework, namely  
//
// - a  [2.x.513]  object, which will provide all the     required data in quadrature points on the cell. This object can be seen     as an extension of FEValues, providing a lot more useful information,  
//
// - a  [2.x.514]  object, which on the one hand side extends the     functionality of cell iterators, but also provides space for return     values in its base class LocalResults,  
//
// - an assembler, in this case for the whole system. The term 'simple' here     refers to the fact that the global system does not have a block     structure,  
//
// - the local integrator, which implements the actual forms.
//
// After the loop has combined all of these into a matrix and a right hand side, there is one thing left to do: the assemblers leave matrix rows and columns of constrained degrees of freedom untouched. Therefore, we put a one on the diagonal to make the whole system well posed. The value one, or any fixed value has the advantage, that its effect on the spectrum of the matrix is easily understood. Since the corresponding eigenvectors form an invariant subspace, the value chosen does not affect the convergence of Krylov space solvers.
//
[0.x.4400] 
[0.x.4401] 
[0.x.4402] 
[0.x.4403] 
[0.x.4404] 
[0.x.4405] 
[0.x.4406] 
[0.x.4407] 
[0.x.4408] 
//
[0.x.4409] 
//
[0.x.4410] 
[0.x.4411] 
[0.x.4412] 
[0.x.4413] 
//
[0.x.4414] 
[0.x.4415] 
[0.x.4416] 
[0.x.4417] 
[0.x.4418] 
[0.x.4419] 
[0.x.4420] 
//
[0.x.4421] 
[0.x.4422] 
[0.x.4423] 
[0.x.4424] 
//[2.x.515] 
//
// The next function is the one that builds the linear operators (matrices) that define the multigrid method on each level of the mesh. The integration core is the same as above, but the loop below will go over all existing cells instead of just the active ones, and the results must be entered into the correct level matrices. Fortunately, MeshWorker hides most of that from us, and thus the difference between this function and the previous lies only in the setup of the assembler and the different iterators in the loop. Also, fixing up the matrices in the end is a little more complicated.
//
[0.x.4425] 
[0.x.4426] 
[0.x.4427] 
[0.x.4428] 
[0.x.4429] 
[0.x.4430] 
[0.x.4431] 
[0.x.4432] 
[0.x.4433] 
//
[0.x.4434] 
//
[0.x.4435] 
[0.x.4436] 
[0.x.4437] 
[0.x.4438] 
//
[0.x.4439] 
[0.x.4440] 
[0.x.4441] 
[0.x.4442] 
[0.x.4443] 
[0.x.4444] 
[0.x.4445] 
//
[0.x.4446] 
[0.x.4447] 
[0.x.4448] 
[0.x.4449] 
[0.x.4450] 
[0.x.4451] 
[0.x.4452] 
[0.x.4453] 
[0.x.4454] 
//
//  [2.x.516] 
//
// This is the other function that is significantly different in support of the multigrid solver (or, in fact, the preconditioner for which we use the multigrid method).
//
// Let us start out by setting up two of the components of multilevel methods: transfer operators between levels, and a solver on the coarsest level. In finite element methods, the transfer operators are derived from the finite element function spaces involved and can often be computed in a generic way independent of the problem under consideration. In that case, we can use the MGTransferPrebuilt class that, given the constraints of the final linear system and the MGConstrainedDoFs object that knows about the boundary conditions on the each level and the degrees of freedom on interfaces between different refinement level can build the matrices for those transfer operations from a DoFHandler object with level degrees of freedom.
//
// The second part of the following lines deals with the coarse grid solver. Since our coarse grid is very coarse indeed, we decide for a direct solver (a Householder decomposition of the coarsest level matrix), even if its implementation is not particularly sophisticated. If our coarse mesh had many more cells than the five we have here, something better suited would obviously be necessary here.
//
[0.x.4455] 
[0.x.4456] 
[0.x.4457] 
[0.x.4458] 
[0.x.4459] 
//
[0.x.4460] 
[0.x.4461] 
[0.x.4462] 
[0.x.4463] 
//
// The next component of a multilevel solver or preconditioner is that we need a smoother on each level. A common choice for this is to use the application of a relaxation method (such as the SOR, Jacobi or Richardson method) or a small number of iterations of a solver method (such as CG or GMRES). The  [2.x.517]  and MGSmootherPrecondition classes provide support for these two kinds of smoothers. Here, we opt for the application of a single SOR iteration. To this end, we define an appropriate alias and then setup a smoother object.
//
// The last step is to initialize the smoother object with our level matrices and to set some smoothing parameters. The  [2.x.518]  function can optionally take additional arguments that will be passed to the smoother object on each level. In the current case for the SOR smoother, this could, for example, include a relaxation parameter. However, we here leave these at their default values. The call to  [2.x.519]  indicates that we will use two pre- and two post-smoothing steps on each level; to use a variable number of smoother steps on different levels, more options can be set in the constructor call to the  [2.x.520]  object.
//
// The last step results from the fact that we use the SOR method as a smoother
//
// - which is not symmetric
//
// - but we use the conjugate gradient iteration (which requires a symmetric preconditioner) below, we need to let the multilevel preconditioner make sure that we get a symmetric operator even for nonsymmetric smoothers:
//
[0.x.4464] 
[0.x.4465] 
[0.x.4466] 
[0.x.4467] 
[0.x.4468] 
//
// The next preparatory step is that we must wrap our level and interface matrices in an object having the required multiplication functions. We will create two objects for the interface objects going from coarse to fine and the other way around; the multigrid algorithm will later use the transpose operator for the latter operation, allowing us to initialize both up and down versions of the operator with the matrices we already built:
//
[0.x.4469] 
[0.x.4470] 
[0.x.4471] 
//
// Now, we are ready to set up the V-cycle operator and the multilevel preconditioner.
//
[0.x.4472] 
[0.x.4473] 
[0.x.4474] 
//
[0.x.4475] 
[0.x.4476] 
//
// With all this together, we can finally get about solving the linear system in the usual way:
//
[0.x.4477] 
[0.x.4478] 
//
[0.x.4479] 
//
[0.x.4480] 
[0.x.4481] 
[0.x.4482] 
//
//  [2.x.521] 
//
// The following two functions postprocess a solution once it is computed. In particular, the first one refines the mesh at the beginning of each cycle while the second one outputs results at the end of each such cycle. The functions are almost unchanged from those in  [2.x.522] , with the exception of one minor difference: we generate output in VTK format, to use the more modern visualization programs available today compared to those that were available when  [2.x.523]  was written.
//
[0.x.4483] 
[0.x.4484] 
[0.x.4485] 
[0.x.4486] 
//
[0.x.4487] 
[0.x.4488] 
[0.x.4489] 
[0.x.4490] 
[0.x.4491] 
[0.x.4492] 
[0.x.4493] 
[0.x.4494] 
[0.x.4495] 
[0.x.4496] 
[0.x.4497] 
[0.x.4498] 
//
[0.x.4499] 
[0.x.4500] 
[0.x.4501] 
[0.x.4502] 
//
[0.x.4503] 
[0.x.4504] 
[0.x.4505] 
//
[0.x.4506] 
[0.x.4507] 
[0.x.4508] 
//[2.x.524] 
//
// Like several of the functions above, this is almost exactly a copy of the corresponding function in  [2.x.525] . The only difference is the call to  [2.x.526]  that takes care of forming the matrices on every level that we need in the multigrid method.
//
[0.x.4509] 
[0.x.4510] 
[0.x.4511] 
[0.x.4512] 
[0.x.4513] 
[0.x.4514] 
//
[0.x.4515] 
[0.x.4516] 
[0.x.4517] 
[0.x.4518] 
[0.x.4519] 
[0.x.4520] 
[0.x.4521] 
//
[0.x.4522] 
[0.x.4523] 
//
[0.x.4524] 
//
[0.x.4525] 
[0.x.4526] 
//
[0.x.4527] 
[0.x.4528] 
[0.x.4529] 
[0.x.4530] 
[0.x.4531] 
//[2.x.527] 
//
// This is again the same function as in  [2.x.528] :
//
[0.x.4532] 
[0.x.4533] 
[0.x.4534] 
[0.x.4535] 
[0.x.4536] 
//
[0.x.4537] 
//
[0.x.4538] 
[0.x.4539] 
[0.x.4540] 
[0.x.4541] 
[0.x.4542] 
[0.x.4543] 
[0.x.4544] 
[0.x.4545] 
[0.x.4546] 
[0.x.4547] 
[0.x.4548] 
[0.x.4549] 
[0.x.4550] 
[0.x.4551] 
//
[0.x.4552] 
[0.x.4553] 
[0.x.4554] 
[0.x.4555] 
[0.x.4556] 
[0.x.4557] 
[0.x.4558] 
[0.x.4559] 
[0.x.4560] 
[0.x.4561] 
[0.x.4562] 
[0.x.4563] 
[0.x.4564] 
[0.x.4565] 
//
[0.x.4566] 
[0.x.4567] 
[0.x.4568] 
[0.x.4569] 
[0.x.4570] 
[0.x.4571] 
[0.x.4572] 
[0.x.4573] 
[0.x.4574] 
[0.x.4575] 
[0.x.4576] 
[0.x.4577] 
[0.x.4578] 
[0.x.4579] 
[0.x.4580] 
[0.x.4581] 
//
[0.x.4582] 
[0.x.4583] 
[0.x.4584] 
[0.x.4585] 
//[2.x.529] 
//
// First the usual assortment of header files we have already used in previous example programs:
//
[0.x.4586] 
[0.x.4587] 
[0.x.4588] 
[0.x.4589] 
[0.x.4590] 
[0.x.4591] 
[0.x.4592] 
[0.x.4593] 
[0.x.4594] 
[0.x.4595] 
[0.x.4596] 
[0.x.4597] 
[0.x.4598] 
[0.x.4599] 
[0.x.4600] 
[0.x.4601] 
[0.x.4602] 
[0.x.4603] 
[0.x.4604] 
[0.x.4605] 
[0.x.4606] 
//
// And here come the things that we need particularly for this example program and that weren't in  [2.x.530] . First, we replace the standard output  [2.x.531]  which is used in parallel computations for generating output only on one of the MPI processes.
//
[0.x.4607] 
//
// We are going to query the number of processes and the number of the present process by calling the respective functions in the  [2.x.532]  namespace.
//
[0.x.4608] 
//
// Then, we are going to replace all linear algebra components that involve the (global) linear system by classes that wrap interfaces similar to our own linear algebra classes around what PETSc offers (PETSc is a library written in C, and deal.II comes with wrapper classes that provide the PETSc functionality with an interface that is similar to the interface we already had for our own linear algebra classes). In particular, we need vectors and matrices that are distributed across several  [2.x.533]  "processes" in MPI programs (and simply map to sequential, local vectors and matrices if there is only a single process, i.e., if you are running on only one machine, and without MPI support):
//
[0.x.4609] 
[0.x.4610] 
//
// Then we also need interfaces for solvers and preconditioners that PETSc provides:
//
[0.x.4611] 
[0.x.4612] 
//
// And in addition, we need some algorithms for partitioning our meshes so that they can be efficiently distributed across an MPI network. The partitioning algorithm is implemented in the  [2.x.534]  namespace, and we need an additional include file for a function in  [2.x.535]  that allows to sort the indices associated with degrees of freedom so that they are numbered according to the subdomain they are associated with:
//
[0.x.4613] 
[0.x.4614] 
//
// And this is simply C++ again:
//
[0.x.4615] 
[0.x.4616] 
//
// The last step is as in all previous programs:
//
[0.x.4617] 
[0.x.4618] 
[0.x.4619] 
//[2.x.536] 
//
// The first real part of the program is the declaration of the main class.  As mentioned in the introduction, almost all of this has been copied verbatim from  [2.x.537] , so we only comment on the few differences between the two tutorials.  There is one (cosmetic) change in that we let  [2.x.538]  return a value, namely the number of iterations it took to converge, so that we can output this to the screen at the appropriate place.
//
[0.x.4620] 
[0.x.4621] 
[0.x.4622] 
[0.x.4623] 
[0.x.4624] 
[0.x.4625] 
//
[0.x.4626] 
[0.x.4627] 
[0.x.4628] 
[0.x.4629] 
[0.x.4630] 
[0.x.4631] 
//
// The first change is that we have to declare a variable that indicates the  [2.x.539]  "MPI communicator" over which we are supposed to distribute our computations.
//
[0.x.4632] 
//
// Then we have two variables that tell us where in the parallel world we are. The first of the following variables,  [2.x.540] , tells us how many MPI processes there exist in total, while the second one,  [2.x.541] , indicates which is the number of the present process within this space of processes (in MPI language, this corresponds to the  [2.x.542]  "rank" of the process). The latter will have a unique value for each process between zero and (less than)  [2.x.543] . If this program is run on a single machine without MPI support, then their values are  [2.x.544] , respectively.
//
[0.x.4633] 
[0.x.4634] 
//
// Next up is a stream-like variable  [2.x.545] . It is, in essence, just something we use for convenience: in a parallel program, if each process outputs status information, then there quickly is a lot of clutter. Rather, we would want to only have one  [2.x.546]  "process" output everything once, for example the one with  [2.x.547]  "rank" zero. At the same time, it seems silly to prefix [1.x.9] place where we create output with an  [2.x.548]  condition.
//
// To make this simpler, the ConditionalOStream class does exactly this under the hood: it acts as if it were a stream, but only forwards to a real, underlying stream if a flag is set. By setting this condition to  [2.x.549]  (where  [2.x.550]  corresponds to the rank of an MPI process), we make sure that output is only generated from the first process and that we don't get the same lines of output over and over again, once per process. Thus, we can use  [2.x.551]  everywhere and in every process, but on all but one process nothing will ever happen to the information that is piped into the object via  [2.x.552] .
//
[0.x.4635] 
//
// The remainder of the list of member variables is fundamentally the same as in  [2.x.553] . However, we change the declarations of matrix and vector types to use parallel PETSc objects instead. Note that we do not use a separate sparsity pattern, since PETSc manages this internally as part of its matrix data structures.
//
[0.x.4636] 
[0.x.4637] 
[0.x.4638] 
//
[0.x.4639] 
//
[0.x.4640] 
//
[0.x.4641] 
[0.x.4642] 
[0.x.4643] 
//[2.x.554] 
//
// The following is taken from  [2.x.555]  without change:
//
[0.x.4644] 
[0.x.4645] 
[0.x.4646] 
[0.x.4647] 
[0.x.4648] 
[0.x.4649] 
[0.x.4650] 
[0.x.4651] 
[0.x.4652] 
//
[0.x.4653] 
[0.x.4654] 
[0.x.4655] 
//
[0.x.4656] 
[0.x.4657] 
[0.x.4658] 
[0.x.4659] 
[0.x.4660] 
//
[0.x.4661] 
[0.x.4662] 
[0.x.4663] 
[0.x.4664] 
[0.x.4665] 
//
[0.x.4666] 
[0.x.4667] 
[0.x.4668] 
[0.x.4669] 
[0.x.4670] 
//
[0.x.4671] 
[0.x.4672] 
//
[0.x.4673] 
[0.x.4674] 
[0.x.4675] 
[0.x.4676] 
//
//  [2.x.556] 
//[2.x.557] 
//
// The first step in the actual implementation is the constructor of the main class. Apart from initializing the same member variables that we already had in  [2.x.558] , we here initialize the MPI communicator variable we shall use with the global MPI communicator linking all processes together (in more complex applications, one could here use a communicator object that only links a subset of all processes), and call the  [2.x.559]  helper functions to determine the number of processes and where the present one fits into this picture. In addition, we make sure that output is only generated by the (globally) first process. We do so by passing the stream we want to output to  [2.x.560]  and a true/false flag as arguments where the latter is determined by testing whether the process currently executing the constructor call is the first in the MPI universe.
//
[0.x.4677] 
[0.x.4678] 
[0.x.4679] 
[0.x.4680] 
[0.x.4681] 
[0.x.4682] 
[0.x.4683] 
[0.x.4684] 
[0.x.4685] 
//
//  [2.x.561] 
//
// Next, the function in which we set up the various variables for the global linear system to be solved needs to be implemented.
//
// However, before we proceed with this, there is one thing to do for a parallel program: we need to determine which MPI process is responsible for each of the cells. Splitting cells among processes, commonly called "partitioning the mesh", is done by assigning a  [2.x.562]  "subdomain id" to each cell. We do so by calling into the METIS library that does this in a very efficient way, trying to minimize the number of nodes on the interfaces between subdomains. Rather than trying to call METIS directly, we do this by calling the  [2.x.563]  function that does this at a much higher level of programming.
//
//  [2.x.564]  As mentioned in the introduction, we could avoid this manual   partitioning step if we used the  [2.x.565]    class for the triangulation object instead (as we do in  [2.x.566] ).   That class does, in essence, everything a regular triangulation   does, but it then also automatically partitions the mesh after   every mesh creation or refinement operation.
//
// Following partitioning, we need to enumerate all degrees of freedom as usual.  However, we would like to enumerate the degrees of freedom in a way so that all degrees of freedom associated with cells in subdomain zero (which resides on process zero) come before all DoFs associated with cells on subdomain one, before those on cells on process two, and so on. We need this since we have to split the global vectors for right hand side and solution, as well as the matrix into contiguous chunks of rows that live on each of the processors, and we will want to do this in a way that requires minimal communication. This particular enumeration can be obtained by re-ordering degrees of freedom indices using  [2.x.567] 
//
// The final step of this initial setup is that we get ourselves an IndexSet that indicates the subset of the global number of unknowns this process is responsible for. (Note that a degree of freedom is not necessarily owned by the process that owns a cell just because the degree of freedom lives on this cell: some degrees of freedom live on interfaces between subdomains, and are consequently only owned by one of the processes adjacent to this interface.)
//
// Before we move on, let us recall a fact already discussed in the introduction: The triangulation we use here is replicated across all processes, and each process has a complete copy of the entire triangulation, with all cells. Partitioning only provides a way to identify which cells out of all each process "owns", but it knows everything about all of them. Likewise, the DoFHandler object knows everything about every cell, in particular the degrees of freedom that live on each cell, whether it is one that the current process owns or not. This can not scale to large problems because eventually just storing the entire mesh, and everything that is associated with it, on every process will become infeasible if the problem is large enough. On the other hand, if we split the triangulation into parts so that every process stores only those cells it "owns" but nothing else (or, at least a sufficiently small fraction of everything else), then we can solve large problems if only we throw a large enough number of MPI processes at them. This is what we are going to in  [2.x.568] , for example, using the  [2.x.569]  class.  On the other hand, most of the rest of what we demonstrate in the current program will actually continue to work whether we have the entire triangulation available, or only a piece of it.
//
[0.x.4686] 
[0.x.4687] 
[0.x.4688] 
[0.x.4689] 
//
[0.x.4690] 
[0.x.4691] 
//
// We need to initialize the objects denoting hanging node constraints for the present grid. As with the triangulation and DoFHandler objects, we will simply store [1.x.10] constraints on each process; again, this will not scale, but we show in  [2.x.570]  how one can work around this by only storing on each MPI process the constraints for degrees of freedom that actually matter on this particular process.
//
[0.x.4692] 
[0.x.4693] 
[0.x.4694] 
[0.x.4695] 
//
// Now we create the sparsity pattern for the system matrix. Note that we again compute and store all entries and not only the ones relevant to this process (see  [2.x.571]  or  [2.x.572]  for a more efficient way to handle this).
//
[0.x.4696] 
[0.x.4697] 
[0.x.4698] 
[0.x.4699] 
[0.x.4700] 
//
// Now we determine the set of locally owned DoFs and use that to initialize parallel vectors and matrix. Since the matrix and vectors need to work in parallel, we have to pass them an MPI communication object, as well as information about the partitioning contained in the IndexSet  [2.x.573]   The IndexSet contains information about the global size (the [1.x.11] number of degrees of freedom) and also what subset of rows is to be stored locally.  Note that the system matrix needs that partitioning information for the rows and columns. For square matrices, as it is the case here, the columns should be partitioned in the same way as the rows, but in the case of rectangular matrices one has to partition the columns in the same way as vectors are partitioned with which the matrix is multiplied, while rows have to partitioned in the same way as destination vectors of matrix-vector multiplications:
//
[0.x.4701] 
[0.x.4702] 
[0.x.4703] 
[0.x.4704] 
//
[0.x.4705] 
[0.x.4706] 
[0.x.4707] 
[0.x.4708] 
//
[0.x.4709] 
[0.x.4710] 
[0.x.4711] 
//
//  [2.x.574] 
//
// We now assemble the matrix and right hand side of the problem. There are some things worth mentioning before we go into detail. First, we will be assembling the system in parallel, i.e., each process will be responsible for assembling on cells that belong to this particular process. Note that the degrees of freedom are split in a way such that all DoFs in the interior of cells and between cells belonging to the same subdomain belong to the process that  [2.x.575]  the cell. However, even then we sometimes need to assemble on a cell with a neighbor that belongs to a different process, and in these cases when we add up the local contributions into the global matrix or right hand side vector, we have to transfer these entries to the process that owns these elements. Fortunately, we don't have to do this by hand: PETSc does all this for us by caching these elements locally, and sending them to the other processes as necessary when we call the  [2.x.576]  functions on the matrix and vector at the end of this function.
//
// The second point is that once we have handed over matrix and vector contributions to PETSc, it is a) hard, and b) very inefficient to get them back for modifications. This is not only the fault of PETSc, it is also a consequence of the distributed nature of this program: if an entry resides on another processor, then it is necessarily expensive to get it. The consequence of this is that we should not try to first assemble the matrix and right hand side as if there were no hanging node constraints and boundary values, and then eliminate these in a second step (using, for example,  [2.x.577]  Rather, we should try to eliminate hanging node constraints before handing these entries over to PETSc. This is easy: instead of copying elements by hand into the global matrix (as we do in  [2.x.578] ), we use the  [2.x.579]  functions to take care of hanging nodes at the same time. We also already did this in  [2.x.580] . The second step, elimination of boundary nodes, could also be done this way by putting the boundary values into the same AffineConstraints object as hanging nodes (see the way it is done in  [2.x.581] , for example); however, it is not strictly necessary to do this here because eliminating boundary values can be done with only the data stored on each process itself, and consequently we use the approach used before in  [2.x.582] , i.e., via  [2.x.583] 
//
// All of this said, here is the actual implementation starting with the general setup of helper variables.  (Note that we still use the deal.II full matrix and vector types for the local systems as these are small and need not be shared across processes.)
//
[0.x.4712] 
[0.x.4713] 
[0.x.4714] 
[0.x.4715] 
[0.x.4716] 
[0.x.4717] 
[0.x.4718] 
[0.x.4719] 
//
[0.x.4720] 
[0.x.4721] 
//
[0.x.4722] 
[0.x.4723] 
//
[0.x.4724] 
//
[0.x.4725] 
[0.x.4726] 
//
[0.x.4727] 
//
[0.x.4728] 
[0.x.4729] 
//
// The next thing is the loop over all elements. Note that we do not have to do [1.x.12] the work on every process: our job here is only to assemble the system on cells that actually belong to this MPI process, all other cells will be taken care of by other processes. This is what the if-clause immediately after the for-loop takes care of: it queries the subdomain identifier of each cell, which is a number associated with each cell that tells us about the owner process. In more generality, the subdomain id is used to split a domain into several parts (we do this above, at the beginning of  [2.x.584] ), and which allows to identify which subdomain a cell is living on. In this application, we have each process handle exactly one subdomain, so we identify the terms  [2.x.585] .
//
// Apart from this, assembling the local system is relatively uneventful if you have understood how this is done in  [2.x.586] . As mentioned above, distributing local contributions into the global matrix and right hand sides also takes care of hanging node constraints in the same way as is done in  [2.x.587] .
//
[0.x.4730] 
[0.x.4731] 
[0.x.4732] 
[0.x.4733] 
[0.x.4734] 
//
[0.x.4735] 
//
[0.x.4736] 
[0.x.4737] 
//
[0.x.4738] 
[0.x.4739] 
[0.x.4740] 
[0.x.4741] 
//
[0.x.4742] 
[0.x.4743] 
[0.x.4744] 
[0.x.4745] 
//
[0.x.4746] 
[0.x.4747] 
[0.x.4748] 
[0.x.4749] 
[0.x.4750] 
[0.x.4751] 
[0.x.4752] 
[0.x.4753] 
[0.x.4754] 
[0.x.4755] 
[0.x.4756] 
[0.x.4757] 
[0.x.4758] 
[0.x.4759] 
[0.x.4760] 
[0.x.4761] 
[0.x.4762] 
[0.x.4763] 
[0.x.4764] 
//
[0.x.4765] 
[0.x.4766] 
[0.x.4767] 
[0.x.4768] 
[0.x.4769] 
[0.x.4770] 
//
[0.x.4771] 
[0.x.4772] 
[0.x.4773] 
[0.x.4774] 
[0.x.4775] 
//
[0.x.4776] 
[0.x.4777] 
[0.x.4778] 
[0.x.4779] 
[0.x.4780] 
[0.x.4781] 
[0.x.4782] 
//
// The next step is to "compress" the vector and the system matrix. This means that each process sends the additions that were made to those entries of the matrix and vector that the process did not own itself to the process that owns them. After receiving these additions from other processes, each process then adds them to the values it already has. These additions are combining the integral contributions of shape functions living on several cells just as in a serial computation, with the difference that the cells are assigned to different processes.
//
[0.x.4783] 
[0.x.4784] 
//
// The global matrix and right hand side vectors have now been formed. We still have to apply boundary values, in the same way as we did, for example, in  [2.x.588] ,  [2.x.589] , and a number of other programs.
//
// The last argument to the call to  [2.x.590]  below allows for some optimizations. It controls whether we should also delete entries (i.e., set them to zero) in the matrix columns corresponding to boundary nodes, or to keep them (and passing  [2.x.591]  means: yes, do eliminate the columns). If we do eliminate columns, then the resulting matrix will be symmetric again if it was before; if we don't, then it won't. The solution of the resulting system should be the same, though. The only reason why we may want to make the system symmetric again is that we would like to use the CG method, which only works with symmetric matrices. The reason why we may [1.x.13] want to make the matrix symmetric is because this would require us to write into column entries that actually reside on other processes, i.e., it involves communicating data. This is always expensive.
//
// Experience tells us that CG also works (and works almost as well) if we don't remove the columns associated with boundary nodes, which can be explained by the special structure of this particular non-symmetry. To avoid the expense of communication, we therefore do not eliminate the entries in the affected columns.
//
[0.x.4785] 
[0.x.4786] 
[0.x.4787] 
[0.x.4788] 
[0.x.4789] 
[0.x.4790] 
[0.x.4791] 
[0.x.4792] 
//
//  [2.x.592] 
//
// Having assembled the linear system, we next need to solve it. PETSc offers a variety of sequential and parallel solvers, for which we have written wrappers that have almost the same interface as is used for the deal.II solvers used in all previous example programs. The following code should therefore look rather familiar.
//
// At the top of the function, we set up a convergence monitor, and assign it the accuracy to which we would like to solve the linear system. Next, we create an actual solver object using PETSc's CG solver which also works with parallel (distributed) vectors and matrices. And finally a preconditioner; we choose to use a block Jacobi preconditioner which works by computing an incomplete LU decomposition on each diagonal block of the matrix.  (In other words, each MPI process computes an ILU from the rows it stores by throwing away columns that correspond to row indices not stored locally; this yields a square matrix block from which we can compute an ILU. That means that if you run the program with only one process, then you will use an ILU(0) as a preconditioner, while if it is run on many processes, then we will have a number of blocks on the diagonal and the preconditioner is the ILU(0) of each of these blocks. In the extreme case of one degree of freedom per processor, this preconditioner is then simply a Jacobi preconditioner since the diagonal matrix blocks consist of only a single entry. Such a preconditioner is relatively easy to compute because it does not require any kind of communication between processors, but it is in general not very efficient for large numbers of processors.)
//
// Following this kind of setup, we then solve the linear system:
//
[0.x.4793] 
[0.x.4794] 
[0.x.4795] 
[0.x.4796] 
[0.x.4797] 
//
[0.x.4798] 
//
[0.x.4799] 
//
// The next step is to distribute hanging node constraints. This is a little tricky, since to fill in the value of a constrained node you need access to the values of the nodes to which it is constrained (for example, for a Q1 element in 2d, we need access to the two nodes on the big side of a hanging node face, to compute the value of the constrained node in the middle).
//
// The problem is that we have built our vectors (in  [2.x.593] ) in such a way that every process is responsible for storing only those elements of the solution vector that correspond to the degrees of freedom this process "owns". There are, however, cases where in order to compute the value of the vector entry for a constrained degree of freedom on one process, we need to access vector entries that are stored on other processes.  PETSc (and, for that matter, the MPI model on which it is built) does not allow to simply query vector entries stored on other processes, so what we do here is to get a copy of the "distributed" vector where we store all elements locally. This is simple, since the deal.II wrappers have a conversion constructor for the deal.II Vector class. (This conversion of course requires communication, but in essence every process only needs to send its data to every other process once in bulk, rather than having to respond to queries for individual elements):
//
[0.x.4800] 
//
// Of course, as in previous discussions, it is clear that such a step cannot scale very far if you wanted to solve large problems on large numbers of processes, because every process now stores [1.x.14] of the solution vector. (We will show how to do this better in  [2.x.594] .)  On the other hand, distributing hanging node constraints is simple on this local copy, using the usual function  [2.x.595]  In particular, we can compute the values of [1.x.15] constrained degrees of freedom, whether the current process owns them or not:
//
[0.x.4801] 
//
// Then transfer everything back into the global vector. The following operation copies those elements of the localized solution that we store locally in the distributed solution, and does not touch the other ones. Since we do the same operation on all processors, we end up with a distributed vector (i.e., a vector that on every process only stores the vector entries corresponding to degrees of freedom that are owned by this process) that has all the constrained nodes fixed.
//
// We end the function by returning the number of iterations it took to converge, to allow for some output.
//
[0.x.4802] 
//
[0.x.4803] 
[0.x.4804] 
//[2.x.596] 
//
// Using some kind of refinement indicator, the mesh can be refined. The problem is basically the same as with distributing hanging node constraints: in order to compute the error indicator (even if we were just interested in the indicator on the cells the current process owns), we need access to more elements of the solution vector than just those the current processor stores. To make this happen, we do essentially what we did in  [2.x.597]  already, namely get a [1.x.16] copy of the solution vector onto every process, and use that to compute. This is in itself expensive as explained above and it is particular unnecessary since we had just created and then destroyed such a vector in  [2.x.598] , but efficiency is not the point of this program and so let us opt for a design in which every function is as self-contained as possible.
//
// Once we have such a "localized" vector that contains [1.x.17] elements of the solution vector, we can compute the indicators for the cells that belong to the present process. In fact, we could of course compute [1.x.18] refinement indicators since our Triangulation and DoFHandler objects store information about all cells, and since we have a complete copy of the solution vector. But in the interest in showing how to operate in %parallel, let us demonstrate how one would operate if one were to only compute [1.x.19] error indicators and then exchange the remaining ones with the other processes. (Ultimately, each process needs a complete set of refinement indicators because every process needs to refine their mesh, and needs to refine it in exactly the same way as all of the other processes.)
//
// So, to do all of this, we need to:
//
// - First, get a local copy of the distributed solution vector.
//
// - Second, create a vector to store the refinement indicators.
//
// - Third, let the KellyErrorEstimator compute refinement   indicators for all cells belonging to the present   subdomain/process. The last argument of the call indicates   which subdomain we are interested in. The three arguments   before it are various other default arguments that one usually   does not need (and does not state values for, but rather uses the   defaults), but which we have to state here explicitly since we   want to modify the value of a following argument (i.e., the one   indicating the subdomain).
//
[0.x.4805] 
[0.x.4806] 
[0.x.4807] 
[0.x.4808] 
//
[0.x.4809] 
[0.x.4810] 
[0.x.4811] 
[0.x.4812] 
[0.x.4813] 
[0.x.4814] 
[0.x.4815] 
[0.x.4816] 
[0.x.4817] 
[0.x.4818] 
//
// Now all processes have computed error indicators for their own cells and stored them in the respective elements of the  [2.x.599]  vector. The elements of this vector for cells not owned by the present process are zero. However, since all processes have a copy of the entire triangulation and need to keep these copies in sync, they need the values of refinement indicators for all cells of the triangulation. Thus, we need to distribute our results. We do this by creating a distributed vector where each process has its share and sets the elements it has computed. Consequently, when you view this vector as one that lives across all processes, then every element of this vector has been set once. We can then assign this parallel vector to a local, non-parallel vector on each process, making [1.x.20] error indicators available on every process.
//
// So in the first step, we need to set up a parallel vector. For simplicity, every process will own a chunk with as many elements as this process owns cells, so that the first chunk of elements is stored with process zero, the next chunk with process one, and so on. It is important to remark, however, that these elements are not necessarily the ones we will write to. This is a consequence of the order in which cells are arranged, i.e., the order in which the elements of the vector correspond to cells is not ordered according to the subdomain these cells belong to. In other words, if on this process we compute indicators for cells of a certain subdomain, we may write the results to more or less random elements of the distributed vector; in particular, they may not necessarily lie within the chunk of vector we own on the present process. They will subsequently have to be copied into another process' memory space, an operation that PETSc does for us when we call the  [2.x.600]  function. This inefficiency could be avoided with some more code, but we refrain from it since it is not a major factor in the program's total runtime.
//
// So here is how we do it: count how many cells belong to this process, set up a distributed vector with that many elements to be stored locally, copy over the elements we computed locally, and finally compress the result. In fact, we really only copy the elements that are nonzero, so we may miss a few that we computed to zero, but this won't hurt since the original values of the vector are zero anyway.
//
[0.x.4819] 
[0.x.4820] 
[0.x.4821] 
[0.x.4822] 
[0.x.4823] 
//
[0.x.4824] 
[0.x.4825] 
[0.x.4826] 
[0.x.4827] 
//
// So now we have this distributed vector that contains the refinement indicators for all cells. To use it, we need to obtain a local copy and then use it to mark cells for refinement or coarsening, and actually do the refinement and coarsening. It is important to recognize that [1.x.21] process does this to its own copy of the triangulation, and does it in exactly the same way.
//
[0.x.4828] 
//
[0.x.4829] 
[0.x.4830] 
[0.x.4831] 
[0.x.4832] 
[0.x.4833] 
[0.x.4834] 
//[2.x.601] 
//
// The final function of significant interest is the one that creates graphical output. This works the same way as in  [2.x.602] , with two small differences. Before discussing these, let us state the general philosophy this function will work: we intend for all of the data to be generated on a single process, and subsequently written to a file. This is, as many other parts of this program already discussed, not something that will scale. Previously, we had argued that we will get into trouble with triangulations, DoFHandlers, and copies of the solution vector where every process has to store all of the data, and that there will come to be a point where each process simply doesn't have enough memory to store that much data. Here, the situation is different: it's not only the memory, but also the run time that's a problem. If one process is responsible for processing [1.x.22] of the data while all of the other processes do nothing, then this one function will eventually come to dominate the overall run time of the program.  In particular, the time this function takes is going to be proportional to the overall size of the problem (counted in the number of cells, or the number of degrees of freedom), independent of the number of processes we throw at it.
//
// Such situations need to be avoided, and we will show in  [2.x.603]  and  [2.x.604]  how to address this issue. For the current problem, the solution is to have each process generate output data only for its own local cells, and write them to separate files, one file per process. This is how  [2.x.605]  operates. Alternatively, one could simply leave everything in a set of independent files and let the visualization software read all of them (possibly also using multiple processors) and create a single visualization out of all of them; this is the path  [2.x.606] ,  [2.x.607] , and all other parallel programs developed later on take.
//
// More specifically for the current function, all processes call this function, but not all of them need to do the work associated with generating output. In fact, they shouldn't, since we would try to write to the same file multiple times at once. So we let only the first process do this, and all the other ones idle around during this time (or start their work for the next iteration, or simply yield their CPUs to other jobs that happen to run at the same time). The second thing is that we not only output the solution vector, but also a vector that indicates which subdomain each cell belongs to. This will make for some nice pictures of partitioned domains.
//
// To implement this, process zero needs a complete set of solution components in a local vector. Just as with the previous function, the efficient way to do this would be to re-use the vector already created in the  [2.x.608]  function, but to keep things more self-contained, we simply re-create one here from the distributed solution vector.
//
// An important thing to realize is that we do this localization operation on all processes, not only the one that actually needs the data. This can't be avoided, however, with the simplified communication model of MPI we use for vectors in this tutorial program: MPI does not have a way to query data on another process, both sides have to initiate a communication at the same time. So even though most of the processes do not need the localized solution, we have to place the statement converting the distributed into a localized vector so that all processes execute it.
//
// (Part of this work could in fact be avoided. What we do is send the local parts of all processes to all other processes. What we would really need to do is to initiate an operation on all processes where each process simply sends its local chunk of data to process zero, since this is the only one that actually needs it, i.e., we need something like a gather operation. PETSc can do this, but for simplicity's sake we don't attempt to make use of this here. We don't, since what we do is not very expensive in the grand scheme of things: it is one vector communication among all processes, which has to be compared to the number of communications we have to do when solving the linear system, setting up the block-ILU for the preconditioner, and other operations.)
//
[0.x.4835] 
[0.x.4836] 
[0.x.4837] 
[0.x.4838] 
//
// This being done, process zero goes ahead with setting up the output file as in  [2.x.609] , and attaching the (localized) solution vector to the output object.
//
[0.x.4839] 
[0.x.4840] 
[0.x.4841] 
//
[0.x.4842] 
[0.x.4843] 
//
[0.x.4844] 
[0.x.4845] 
[0.x.4846] 
[0.x.4847] 
[0.x.4848] 
[0.x.4849] 
[0.x.4850] 
[0.x.4851] 
[0.x.4852] 
[0.x.4853] 
[0.x.4854] 
[0.x.4855] 
[0.x.4856] 
[0.x.4857] 
[0.x.4858] 
[0.x.4859] 
[0.x.4860] 
[0.x.4861] 
//
[0.x.4862] 
//
// The only other thing we do here is that we also output one value per cell indicating which subdomain (i.e., MPI process) it belongs to. This requires some conversion work, since the data the library provides us with is not the one the output class expects, but this is not difficult. First, set up a vector of integers, one per cell, that is then filled by the subdomain id of each cell.
//
// The elements of this vector are then converted to a floating point vector in a second step, and this vector is added to the DataOut object, which then goes off creating output in VTK format:
//
[0.x.4863] 
[0.x.4864] 
//
[0.x.4865] 
[0.x.4866] 
//
[0.x.4867] 
//
[0.x.4868] 
[0.x.4869] 
[0.x.4870] 
[0.x.4871] 
//[2.x.610] 
//
// Lastly, here is the driver function. It is almost completely unchanged from  [2.x.611] , with the exception that we replace  [2.x.612]  stream. Apart from this, the only other cosmetic change is that we output how many degrees of freedom there are per process, and how many iterations it took for the linear solver to converge:
//
[0.x.4872] 
[0.x.4873] 
[0.x.4874] 
[0.x.4875] 
[0.x.4876] 
[0.x.4877] 
//
[0.x.4878] 
[0.x.4879] 
[0.x.4880] 
[0.x.4881] 
[0.x.4882] 
[0.x.4883] 
[0.x.4884] 
//
[0.x.4885] 
[0.x.4886] 
//
[0.x.4887] 
//
[0.x.4888] 
[0.x.4889] 
[0.x.4890] 
[0.x.4891] 
[0.x.4892] 
[0.x.4893] 
[0.x.4894] 
//
[0.x.4895] 
[0.x.4896] 
//
[0.x.4897] 
[0.x.4898] 
//
[0.x.4899] 
[0.x.4900] 
[0.x.4901] 
[0.x.4902] 
//[2.x.613] 
//
// The  [2.x.614]  works the same way as most of the main functions in the other example programs, i.e., it delegates work to the  [2.x.615]  function of a managing object, and only wraps everything into some code to catch exceptions:
//
[0.x.4903] 
[0.x.4904] 
[0.x.4905] 
[0.x.4906] 
[0.x.4907] 
[0.x.4908] 
//
// Here is the only real difference: MPI and PETSc both require that we initialize these libraries at the beginning of the program, and un-initialize them at the end. The class MPI_InitFinalize takes care of all of that. The trailing argument `1` means that we do want to run each MPI process with a single thread, a prerequisite with the PETSc parallel linear algebra.
//
[0.x.4909] 
//
[0.x.4910] 
[0.x.4911] 
[0.x.4912] 
[0.x.4913] 
[0.x.4914] 
[0.x.4915] 
[0.x.4916] 
[0.x.4917] 
[0.x.4918] 
[0.x.4919] 
[0.x.4920] 
[0.x.4921] 
[0.x.4922] 
[0.x.4923] 
//
[0.x.4924] 
[0.x.4925] 
[0.x.4926] 
[0.x.4927] 
[0.x.4928] 
[0.x.4929] 
[0.x.4930] 
[0.x.4931] 
[0.x.4932] 
[0.x.4933] 
[0.x.4934] 
[0.x.4935] 
[0.x.4936] 
[0.x.4937] 
//
[0.x.4938] 
[0.x.4939] 
[0.x.4940] 
[0.x.4941] 
[0.x.4942] 
[0.x.4943] 
[0.x.4944] 
[0.x.4945] 
[0.x.4946] 
[0.x.4947] 
[0.x.4948] 
[0.x.4949] 
[0.x.4950] 
[0.x.4951] 
[0.x.4952] 
[0.x.4953] 
//
[0.x.4954] 
[0.x.4955] 
[0.x.4956] 
[0.x.4957] 
//
// First the usual list of header files that have already been used in previous example programs:
//
[0.x.4958] 
[0.x.4959] 
[0.x.4960] 
[0.x.4961] 
[0.x.4962] 
[0.x.4963] 
[0.x.4964] 
[0.x.4965] 
[0.x.4966] 
[0.x.4967] 
[0.x.4968] 
[0.x.4969] 
[0.x.4970] 
[0.x.4971] 
[0.x.4972] 
[0.x.4973] 
[0.x.4974] 
[0.x.4975] 
[0.x.4976] 
[0.x.4977] 
[0.x.4978] 
[0.x.4979] 
[0.x.4980] 
[0.x.4981] 
[0.x.4982] 
[0.x.4983] 
[0.x.4984] 
[0.x.4985] 
[0.x.4986] 
[0.x.4987] 
[0.x.4988] 
//
// And here the only three new things among the header files: an include file in which symmetric tensors of rank 2 and 4 are implemented, as introduced in the introduction:
//
[0.x.4989] 
//
// And lastly a header that contains some functions that will help us compute rotaton matrices of the local coordinate systems at specific points in the domain.
//
[0.x.4990] 
//
// This is then simply C++ again:
//
[0.x.4991] 
[0.x.4992] 
[0.x.4993] 
//
// The last step is as in all previous programs:
//
[0.x.4994] 
[0.x.4995] 
[0.x.4996] 
//[2.x.616] 
//
// As was mentioned in the introduction, we have to store the old stress in quadrature point so that we can compute the residual forces at this point during the next time step. This alone would not warrant a structure with only one member, but in more complicated applications, we would have to store more information in quadrature points as well, such as the history variables of plasticity, etc. In essence, we have to store everything that affects the present state of the material here, which in plasticity is determined by the deformation history variables.
//
// We will not give this class any meaningful functionality beyond being able to store data, i.e. there are no constructors, destructors, or other member functions. In such cases of `dumb' classes, we usually opt to declare them as  [2.x.617] , to indicate that they are closer to C-style structures than C++-style classes.
//
[0.x.4997] 
[0.x.4998] 
[0.x.4999] 
[0.x.5000] 
[0.x.5001] 
//[2.x.618] 
//
// Next, we define the linear relationship between the stress and the strain in elasticity. It is given by a tensor of rank 4 that is usually written in the form  [2.x.619] . This tensor maps symmetric tensor of rank 2 to symmetric tensors of rank 2. A function implementing its creation for given values of the Lam&eacute; constants  [2.x.620]  and  [2.x.621]  is straightforward:
//
[0.x.5002] 
[0.x.5003] 
[0.x.5004] 
[0.x.5005] 
[0.x.5006] 
[0.x.5007] 
[0.x.5008] 
[0.x.5009] 
[0.x.5010] 
[0.x.5011] 
[0.x.5012] 
[0.x.5013] 
[0.x.5014] 
[0.x.5015] 
//
// With this function, we will define a static member variable of the main class below that will be used throughout the program as the stress-strain tensor. Note that in more elaborate programs, this will probably be a member variable of some class instead, or a function that returns the stress-strain relationship depending on other input. For example in damage theory models, the Lam&eacute; constants are considered a function of the prior stress/strain history of a point. Conversely, in plasticity the form of the stress-strain tensor is modified if the material has reached the yield stress in a certain point, and possibly also depending on its prior history.
//
// In the present program, however, we assume that the material is completely elastic and linear, and a constant stress-strain tensor is sufficient for our present purposes.
//
//  [2.x.622] 
//
// Before the rest of the program, here are a few functions that we need as tools. These are small functions that are called in inner loops, so we mark them as  [2.x.623] .
//
// The first one computes the symmetric strain tensor for shape function  [2.x.624]  by forming the symmetric gradient of this shape function. We need that when we want to form the matrix, for example.
//
// We should note that in previous examples where we have treated vector-valued problems, we have always asked the finite element object in which of the vector component the shape function is actually non-zero, and thereby avoided to compute any terms that we could prove were zero anyway. For this, we used the  [2.x.625]  function that returns in which component a shape function was zero, and also that the  [2.x.626]  and  [2.x.627]  functions only returned the value and gradient of the single non-zero component of a shape function if this is a vector-valued element.
//
// This was an optimization, and if it isn't terribly time critical, we can get away with a simpler technique: just ask the  [2.x.628]  for the value or gradient of a given component of a given shape function at a given quadrature point. This is what the  [2.x.629]  call does: return the full gradient of the  [2.x.630] th component of shape function  [2.x.631]  at quadrature point  [2.x.632] . If a certain component of a certain shape function is always zero, then this will simply always return zero.
//
// As mentioned, using  [2.x.633]  instead of the combination of  [2.x.634]  and  [2.x.635]  may be less efficient, but its implementation is optimized for such cases and shouldn't be a big slowdown. We demonstrate the technique here since it is so much simpler and straightforward.
//
[0.x.5016] 
[0.x.5017] 
[0.x.5018] 
[0.x.5019] 
[0.x.5020] 
//
// Declare a temporary that will hold the return value:
//
[0.x.5021] 
//
// First, fill diagonal terms which are simply the derivatives in direction  [2.x.636]  component of the vector-valued shape function:
//
[0.x.5022] 
[0.x.5023] 
//
// Then fill the rest of the strain tensor. Note that since the tensor is symmetric, we only have to compute one half (here: the upper right corner) of the off-diagonal elements, and the implementation of the  [2.x.637]  class makes sure that at least to the outside the symmetric entries are also filled (in practice, the class of course stores only one copy). Here, we have picked the upper right half of the tensor, but the lower left one would have been just as good:
//
[0.x.5024] 
[0.x.5025] 
[0.x.5026] 
[0.x.5027] 
[0.x.5028] 
[0.x.5029] 
//
[0.x.5030] 
[0.x.5031] 
//
// The second function does something very similar (and therefore is given the same name): compute the symmetric strain tensor from the gradient of a vector-valued field. If you already have a solution field, the  [2.x.638]  function allows you to extract the gradients of each component of your solution field at a quadrature point. It returns this as a vector of rank-1 tensors: one rank-1 tensor (gradient) per vector component of the solution. From this we have to reconstruct the (symmetric) strain tensor by transforming the data storage format and symmetrization. We do this in the same way as above, i.e. we avoid a few computations by filling first the diagonal and then only one half of the symmetric tensor (the  [2.x.639]  class makes sure that it is sufficient to write only one of the two symmetric components).
//
// Before we do this, though, we make sure that the input has the kind of structure we expect: that is that there are  [2.x.640]  vector components, i.e. one displacement component for each coordinate direction. We test this with the  [2.x.641]  macro that will simply abort our program if the condition is not met.
//
[0.x.5032] 
[0.x.5033] 
[0.x.5034] 
[0.x.5035] 
[0.x.5036] 
//
[0.x.5037] 
[0.x.5038] 
[0.x.5039] 
//
[0.x.5040] 
[0.x.5041] 
[0.x.5042] 
//
[0.x.5043] 
[0.x.5044] 
//
// Finally, below we will need a function that computes the rotation matrix induced by a displacement at a given point. In fact, of course, the displacement at a single point only has a direction and a magnitude, it is the change in direction and magnitude that induces rotations. In effect, the rotation matrix can be computed from the gradients of a displacement, or, more specifically, from the curl.
//
// The formulas by which the rotation matrices are determined are a little awkward, especially in 3d. For 2d, there is a simpler way, so we implement this function twice, once for 2d and once for 3d, so that we can compile and use the program in both space dimensions if so desired -- after all, deal.II is all about dimension independent programming and reuse of algorithm thoroughly tested with cheap computations in 2d, for the more expensive computations in 3d. Here is one case, where we have to implement different algorithms for 2d and 3d, but then can write the rest of the program in a way that is independent of the space dimension.
//
// So, without further ado to the 2d implementation:
//
[0.x.5045] 
[0.x.5046] 
//
// First, compute the curl of the velocity field from the gradients. Note that we are in 2d, so the rotation is a scalar:
//
[0.x.5047] 
//
// From this, compute the angle of rotation:
//
[0.x.5048] 
//
// And from this, build the antisymmetric rotation matrix. We want this rotation matrix to represent the rotation of the local coordinate system with respect to the global Cartesian basis, to we construct it with a negative angle. The rotation matrix therefore represents the rotation required to move from the local to the global coordinate system.
//
[0.x.5049] 
[0.x.5050] 
//
// The 3d case is a little more contrived:
//
[0.x.5051] 
[0.x.5052] 
//
// Again first compute the curl of the velocity field. This time, it is a real vector:
//
[0.x.5053] 
[0.x.5054] 
[0.x.5055] 
//
// From this vector, using its magnitude, compute the tangent of the angle of rotation, and from it the actual angle of rotation with respect to the Cartesian basis:
//
[0.x.5056] 
[0.x.5057] 
//
// Now, here's one problem: if the angle of rotation is too small, that means that there is no rotation going on (for example a translational motion). In that case, the rotation matrix is the identity matrix.
//
// The reason why we stress that is that in this case we have that  [2.x.642] . Further down, we need to divide by that number in the computation of the axis of rotation, and we would get into trouble when dividing doing so. Therefore, let's shortcut this and simply return the identity matrix if the angle of rotation is really small:
//
[0.x.5058] 
[0.x.5059] 
[0.x.5060] 
[0.x.5061] 
[0.x.5062] 
[0.x.5063] 
//
// Otherwise compute the real rotation matrix. For this, again we rely on a predefined function to compute the rotation matrix of the local coordinate system.
//
[0.x.5064] 
[0.x.5065] 
[0.x.5066] 
[0.x.5067] 
//
//  [2.x.643] 
//
// This is the main class of the program. Since the namespace already indicates what problem we are solving, let's call it by what it does: it directs the flow of the program, i.e. it is the toplevel driver.
//
// The member variables of this class are essentially as before, i.e. it has to have a triangulation, a DoF handler and associated objects such as constraints, variables that describe the linear system, etc. There are a good number of more member functions now, which we will explain below.
//
// The external interface of the class, however, is unchanged: it has a public constructor and destructor, and it has a  [2.x.644]  function that initiated all the work.
//
[0.x.5068] 
[0.x.5069] 
[0.x.5070] 
[0.x.5071] 
[0.x.5072] 
[0.x.5073] 
[0.x.5074] 
//
[0.x.5075] 
//
// The private interface is more extensive than in  [2.x.645] . First, we obviously need functions that create the initial mesh, set up the variables that describe the linear system on the present mesh (i.e. matrices and vectors), and then functions that actually assemble the system, direct what has to be solved in each time step, a function that solves the linear system that arises in each timestep (and returns the number of iterations it took), and finally output the solution vector on the correct mesh:
//
[0.x.5076] 
//
[0.x.5077] 
//
[0.x.5078] 
//
[0.x.5079] 
//
[0.x.5080] 
//
[0.x.5081] 
//
// All, except for the first two, of these functions are called in each timestep. Since the first time step is a little special, we have separate functions that describe what has to happen in a timestep: one for the first, and one for all following timesteps:
//
[0.x.5082] 
//
[0.x.5083] 
//
// Then we need a whole bunch of functions that do various things. The first one refines the initial grid: we start on the coarse grid with a pristine state, solve the problem, then look at it and refine the mesh accordingly, and start the same process over again, again with a pristine state. Thus, refining the initial mesh is somewhat simpler than refining a grid between two successive time steps, since it does not involve transferring data from the old to the new triangulation, in particular the history data that is stored in each quadrature point.
//
[0.x.5084] 
//
// At the end of each time step, we want to move the mesh vertices around according to the incremental displacement computed in this time step. This is the function in which this is done:
//
[0.x.5085] 
//
// Next are two functions that handle the history variables stored in each quadrature point. The first one is called before the first timestep to set up a pristine state for the history variables. It only works on those quadrature points on cells that belong to the present processor:
//
[0.x.5086] 
//
// The second one updates the history variables at the end of each timestep:
//
[0.x.5087] 
//
// This is the new shared Triangulation:
//
[0.x.5088] 
//
[0.x.5089] 
//
[0.x.5090] 
//
[0.x.5091] 
//
// One difference of this program is that we declare the quadrature formula in the class declaration. The reason is that in all the other programs, it didn't do much harm if we had used different quadrature formulas when computing the matrix and the right hand side, for example. However, in the present case it does: we store information in the quadrature points, so we have to make sure all parts of the program agree on where they are and how many there are on each cell. Thus, let us first declare the quadrature formula that will be used throughout...
//
[0.x.5092] 
//
// ... and then also have a vector of history objects, one per quadrature point on those cells for which we are responsible (i.e. we don't store history data for quadrature points on cells that are owned by other processors). Note that, instead of storing and managing this data ourself, we could use the CellDataStorage class like is done in  [2.x.646] . However, for the purpose of demonstration, in this case we manage the storage manually.
//
[0.x.5093] 
//
// The way this object is accessed is through a  [2.x.647]  that each cell, face, or edge holds: it is a  [2.x.648]  pointer that can be used by application programs to associate arbitrary data to cells, faces, or edges. What the program actually does with this data is within its own responsibility, the library just allocates some space for these pointers, and application programs can set and read the pointers for each of these objects.
//
// Further: we need the objects of linear systems to be solved, i.e. matrix, right hand side vector, and the solution vector. Since we anticipate solving big problems, we use the same types as in  [2.x.649] , i.e. distributed %parallel matrices and vectors built on top of the PETSc library. Conveniently, they can also be used when running on only a single machine, in which case this machine happens to be the only one in our %parallel universe.
//
// However, as a difference to  [2.x.650] , we do not store the solution vector -- which here is the incremental displacements computed in each time step -- in a distributed fashion. I.e., of course it must be a distributed vector when computing it, but immediately after that we make sure each processor has a complete copy. The reason is that we had already seen in  [2.x.651]  that many functions needed a complete copy. While it is not hard to get it, this requires communication on the network, and is thus slow. In addition, these were repeatedly the same operations, which is certainly undesirable unless the gains of not always having to store the entire vector outweighs it. When writing this program, it turned out that we need a complete copy of the solution in so many places that it did not seem worthwhile to only get it when necessary. Instead, we opted to obtain the complete copy once and for all, and instead get rid of the distributed copy immediately. Thus, note that the declaration of  [2.x.652]  does not denote a distribute vector as would be indicated by the middle namespace  [2.x.653] :
//
[0.x.5094] 
//
[0.x.5095] 
//
[0.x.5096] 
//
// The next block of variables is then related to the time dependent nature of the problem: they denote the length of the time interval which we want to simulate, the present time and number of time step, and length of present timestep:
//
[0.x.5097] 
[0.x.5098] 
[0.x.5099] 
[0.x.5100] 
//
// Then a few variables that have to do with %parallel processing: first, a variable denoting the MPI communicator we use, and then two numbers telling us how many participating processors there are, and where in this world we are. Finally, a stream object that makes sure only one processor is actually generating output to the console. This is all the same as in  [2.x.654] :
//
[0.x.5101] 
//
[0.x.5102] 
//
[0.x.5103] 
//
[0.x.5104] 
//
// We are storing the locally owned and the locally relevant indices:
//
[0.x.5105] 
[0.x.5106] 
//
// Finally, we have a static variable that denotes the linear relationship between the stress and strain. Since it is a constant object that does not depend on any input (at least not in this program), we make it a static variable and will initialize it in the same place where we define the constructor of this class:
//
[0.x.5107] 
[0.x.5108] 
//[2.x.655] 
//
// Before we go on to the main functionality of this program, we have to define what forces will act on the body whose deformation we want to study. These may either be body forces or boundary forces. Body forces are generally mediated by one of the four basic physical types of forces: gravity, strong and weak interaction, and electromagnetism. Unless one wants to consider subatomic objects (for which quasistatic deformation is irrelevant and an inappropriate description anyway), only gravity and electromagnetic forces need to be considered. Let us, for simplicity assume that our body has a certain mass density, but is either non-magnetic and not electrically conducting or that there are no significant electromagnetic fields around. In that case, the body forces are simply  [2.x.656]  is the material density and  [2.x.657]  is a vector in negative z-direction with magnitude 9.81 m/s^2.  Both the density and  [2.x.658]  are defined in the function, and we take as the density 7700 kg/m^3, a value commonly assumed for steel.
//
// To be a little more general and to be able to do computations in 2d as well, we realize that the body force is always a function returning a  [2.x.659]  dimensional vector. We assume that gravity acts along the negative direction of the last, i.e.  [2.x.660] th coordinate. The rest of the implementation of this function should be mostly self-explanatory given similar definitions in previous example programs. Note that the body force is independent of the location; to avoid compiler warnings about unused function arguments, we therefore comment out the name of the first argument of the  [2.x.661]  function:
//
[0.x.5109] 
[0.x.5110] 
[0.x.5111] 
[0.x.5112] 
[0.x.5113] 
//
[0.x.5114] 
[0.x.5115] 
//
[0.x.5116] 
[0.x.5117] 
[0.x.5118] 
[0.x.5119] 
//
[0.x.5120] 
[0.x.5121] 
[0.x.5122] 
[0.x.5123] 
//
[0.x.5124] 
[0.x.5125] 
[0.x.5126] 
[0.x.5127] 
[0.x.5128] 
//
[0.x.5129] 
[0.x.5130] 
//
[0.x.5131] 
[0.x.5132] 
[0.x.5133] 
//
[0.x.5134] 
[0.x.5135] 
[0.x.5136] 
[0.x.5137] 
[0.x.5138] 
[0.x.5139] 
//
[0.x.5140] 
[0.x.5141] 
//
[0.x.5142] 
[0.x.5143] 
[0.x.5144] 
//
//  [2.x.662] 
//
// In addition to body forces, movement can be induced by boundary forces and forced boundary displacement. The latter case is equivalent to forces being chosen in such a way that they induce certain displacement.
//
// For quasistatic displacement, typical boundary forces would be pressure on a body, or tangential friction against another body. We chose a somewhat simpler case here: we prescribe a certain movement of (parts of) the boundary, or at least of certain components of the displacement vector. We describe this by another vector-valued function that, for a given point on the boundary, returns the prescribed displacement.
//
// Since we have a time-dependent problem, the displacement increment of the boundary equals the displacement accumulated during the length of the timestep. The class therefore has to know both the present time and the length of the present time step, and can then approximate the incremental displacement as the present velocity times the present timestep.
//
// For the purposes of this program, we choose a simple form of boundary displacement: we displace the top boundary with constant velocity downwards. The rest of the boundary is either going to be fixed (and is then described using an object of type  [2.x.663] ) or free (Neumann-type, in which case nothing special has to be done).  The implementation of the class describing the constant downward motion should then be obvious using the knowledge we gained through all the previous example programs:
//
[0.x.5145] 
[0.x.5146] 
[0.x.5147] 
[0.x.5148] 
[0.x.5149] 
[0.x.5150] 
//
[0.x.5151] 
[0.x.5152] 
//
[0.x.5153] 
[0.x.5154] 
[0.x.5155] 
//
[0.x.5156] 
[0.x.5157] 
[0.x.5158] 
[0.x.5159] 
[0.x.5160] 
//
[0.x.5161] 
[0.x.5162] 
[0.x.5163] 
[0.x.5164] 
[0.x.5165] 
[0.x.5166] 
[0.x.5167] 
[0.x.5168] 
[0.x.5169] 
//
[0.x.5170] 
[0.x.5171] 
[0.x.5172] 
[0.x.5173] 
[0.x.5174] 
[0.x.5175] 
//
[0.x.5176] 
[0.x.5177] 
[0.x.5178] 
//
[0.x.5179] 
[0.x.5180] 
[0.x.5181] 
[0.x.5182] 
[0.x.5183] 
[0.x.5184] 
//
[0.x.5185] 
[0.x.5186] 
//
[0.x.5187] 
[0.x.5188] 
[0.x.5189] 
//
//  [2.x.664] 
//
// Now for the implementation of the main class. First, we initialize the stress-strain tensor, which we have declared as a static const variable. We chose Lam&eacute; constants that are appropriate for steel:
//
[0.x.5190] 
[0.x.5191] 
[0.x.5192] 
//
//                                  /*mu     =  [2.x.665]  7.617e10);
//
//  [2.x.666] 
//
// The next step is the definition of constructors and destructors. There are no surprises here: we choose linear and continuous finite elements for each of the  [2.x.667]  vector components of the solution, and a Gaussian quadrature formula with 2 points in each coordinate direction. The destructor should be obvious:
//
[0.x.5193] 
[0.x.5194] 
[0.x.5195] 
[0.x.5196] 
[0.x.5197] 
[0.x.5198] 
[0.x.5199] 
[0.x.5200] 
[0.x.5201] 
[0.x.5202] 
[0.x.5203] 
[0.x.5204] 
[0.x.5205] 
[0.x.5206] 
[0.x.5207] 
//
[0.x.5208] 
[0.x.5209] 
[0.x.5210] 
[0.x.5211] 
[0.x.5212] 
//
// The last of the public functions is the one that directs all the work,  [2.x.668] . It initializes the variables that describe where in time we presently are, then runs the first time step, then loops over all the other time steps. Note that for simplicity we use a fixed time step, whereas a more sophisticated program would of course have to choose it in some more reasonable way adaptively:
//
[0.x.5213] 
[0.x.5214] 
[0.x.5215] 
[0.x.5216] 
//
[0.x.5217] 
[0.x.5218] 
[0.x.5219] 
//[2.x.669] 
//
// The next function in the order in which they were declared above is the one that creates the coarse grid from which we start. For this example program, we want to compute the deformation of a cylinder under axial compression. The first step therefore is to generate a mesh for a cylinder of length 3 and with inner and outer radii of 0.8 and 1, respectively. Fortunately, there is a library function for such a mesh.
//
// In a second step, we have to associated boundary conditions with the upper and lower faces of the cylinder. We choose a boundary indicator of 0 for the boundary faces that are characterized by their midpoints having z-coordinates of either 0 (bottom face), an indicator of 1 for z=3 (top face); finally, we use boundary indicator 2 for all faces on the inside of the cylinder shell, and 3 for the outside.
//
[0.x.5220] 
[0.x.5221] 
[0.x.5222] 
[0.x.5223] 
[0.x.5224] 
[0.x.5225] 
[0.x.5226] 
[0.x.5227] 
[0.x.5228] 
[0.x.5229] 
//
[0.x.5230] 
[0.x.5231] 
[0.x.5232] 
[0.x.5233] 
[0.x.5234] 
[0.x.5235] 
[0.x.5236] 
[0.x.5237] 
[0.x.5238] 
[0.x.5239] 
[0.x.5240] 
//
// Once all this is done, we can refine the mesh once globally:
//
[0.x.5241] 
//
// As the final step, we need to set up a clean state of the data that we store in the quadrature points on all cells that are treated on the present processor.
//
[0.x.5242] 
[0.x.5243] 
//
//  [2.x.670] 
//
// The next function is the one that sets up the data structures for a given mesh. This is done in most the same way as in  [2.x.671] : distribute the degrees of freedom, then sort these degrees of freedom in such a way that each processor gets a contiguous chunk of them. Note that subdivisions into chunks for each processor is handled in the functions that create or refine grids, unlike in the previous example program (the point where this happens is mostly a matter of taste; here, we chose to do it when grids are created since in the  [2.x.672]  and  [2.x.673]  functions we want to output the number of cells on each processor at a point where we haven't called the present function yet).
//
[0.x.5244] 
[0.x.5245] 
[0.x.5246] 
[0.x.5247] 
[0.x.5248] 
[0.x.5249] 
//
// The next step is to set up constraints due to hanging nodes. This has been handled many times before:
//
[0.x.5250] 
[0.x.5251] 
[0.x.5252] 
[0.x.5253] 
//
// And then we have to set up the matrix. Here we deviate from  [2.x.674] , in which we simply used PETSc's ability to just know about the size of the matrix and later allocate those nonzero elements that are being written to. While this works just fine from a correctness viewpoint, it is not at all efficient: if we don't give PETSc a clue as to which elements are written to, it is (at least at the time of this writing) unbearably slow when we set the elements in the matrix for the first time (i.e. in the first timestep). Later on, when the elements have been allocated, everything is much faster. In experiments we made, the first timestep can be accelerated by almost two orders of magnitude if we instruct PETSc which elements will be used and which are not.
//
// To do so, we first generate the sparsity pattern of the matrix we are going to work with, and make sure that the condensation of hanging node constraints add the necessary additional entries in the sparsity pattern:
//
[0.x.5254] 
[0.x.5255] 
[0.x.5256] 
[0.x.5257] 
//
//                                    /*keep constrained dofs [2.x.675]  false);
//
[0.x.5258] 
[0.x.5259] 
[0.x.5260] 
[0.x.5261] 
//
// Note that we have used the  [2.x.676]  class here that was already introduced in  [2.x.677] , rather than the  [2.x.678]  class that we have used in all other cases. The reason for this is that for the latter class to work we have to give an initial upper bound for the number of entries in each row, a task that is traditionally done by  [2.x.679] . However, this function suffers from a serious problem: it has to compute an upper bound to the number of nonzero entries in each row, and this is a rather complicated task, in particular in 3d. In effect, while it is quite accurate in 2d, it often comes up with much too large a number in 3d, and in that case the  [2.x.680]  allocates much too much memory at first, often several 100 MBs. This is later corrected when  [2.x.681]  is called and we realize that we don't need all that much memory, but at time it is already too late: for large problems, the temporary allocation of too much memory can lead to out-of-memory situations.
//
// In order to avoid this, we resort to the  [2.x.682]  class that is slower but does not require any up-front estimate on the number of nonzero entries per row. It therefore only ever allocates as much memory as it needs at any given time, and we can build it even for large 3d problems.
//
// It is also worth noting that due to the specifics of  [2.x.683]  the sparsity pattern we construct is global, i.e. comprises all degrees of freedom whether they will be owned by the processor we are on or another one (in case this program is run in %parallel via MPI). This of course is not optimal -- it limits the size of the problems we can solve, since storing the entire sparsity pattern (even if only for a short time) on each processor does not scale well. However, there are several more places in the program in which we do this, for example we always keep the global triangulation and DoF handler objects around, even if we only work on part of them. At present, deal.II does not have the necessary facilities to completely distribute these objects (a task that, indeed, is very hard to achieve with adaptive meshes, since well-balanced subdivisions of a domain tend to become unbalanced as the mesh is adaptively refined).
//
// With this data structure, we can then go to the PETSc sparse matrix and tell it to preallocate all the entries we will later want to write to:
//
[0.x.5262] 
[0.x.5263] 
[0.x.5264] 
[0.x.5265] 
//
// After this point, no further explicit knowledge of the sparsity pattern is required any more and we can let the  [2.x.684]  variable go out of scope without any problem.
//
// The last task in this function is then only to reset the right hand side vector as well as the solution vector to its correct size; remember that the solution vector is a local one, unlike the right hand side that is a distributed %parallel one and therefore needs to know the MPI communicator over which it is supposed to transmit messages:
//
[0.x.5266] 
[0.x.5267] 
[0.x.5268] 
//
//  [2.x.685] 
//
// Again, assembling the system matrix and right hand side follows the same structure as in many example programs before. In particular, it is mostly equivalent to  [2.x.686] , except for the different right hand side that now only has to take into account internal stresses. In addition, assembling the matrix is made significantly more transparent by using the  [2.x.687]  class: note the elegance of forming the scalar products of symmetric tensors of rank 2 and 4. The implementation is also more general since it is independent of the fact that we may or may not be using an isotropic elasticity tensor.
//
// The first part of the assembly routine is as always:
//
[0.x.5269] 
[0.x.5270] 
[0.x.5271] 
[0.x.5272] 
[0.x.5273] 
//
[0.x.5274] 
[0.x.5275] 
[0.x.5276] 
[0.x.5277] 
//
[0.x.5278] 
[0.x.5279] 
//
[0.x.5280] 
[0.x.5281] 
//
[0.x.5282] 
//
[0.x.5283] 
[0.x.5284] 
[0.x.5285] 
//
// As in  [2.x.688] , we only need to loop over all cells that belong to the present processor:
//
[0.x.5286] 
[0.x.5287] 
[0.x.5288] 
[0.x.5289] 
[0.x.5290] 
//
[0.x.5291] 
//
// Then loop over all indices i,j and quadrature points and assemble the system matrix contributions from this cell.  Note how we extract the symmetric gradients (strains) of the shape functions at a given quadrature point from the  [2.x.689]  object, and the elegance with which we form the triple contraction  [2.x.690] ; the latter needs to be compared to the clumsy computations needed in  [2.x.691] , both in the introduction as well as in the respective place in the program:
//
[0.x.5292] 
[0.x.5293] 
[0.x.5294] 
[0.x.5295] 
[0.x.5296] 
[0.x.5297] 
[0.x.5298] 
//
[0.x.5299] 
[0.x.5300] 
[0.x.5301] 
[0.x.5302] 
[0.x.5303] 
[0.x.5304] 
//
// Then also assemble the local right hand side contributions. For this, we need to access the prior stress value in this quadrature point. To get it, we use the user pointer of this cell that points into the global array to the quadrature point data corresponding to the first quadrature point of the present cell, and then add an offset corresponding to the index of the quadrature point we presently consider:
//
[0.x.5305] 
[0.x.5306] 
//
// In addition, we need the values of the external body forces at the quadrature points on this cell:
//
[0.x.5307] 
[0.x.5308] 
//
// Then we can loop over all degrees of freedom on this cell and compute local contributions to the right hand side:
//
[0.x.5309] 
[0.x.5310] 
[0.x.5311] 
[0.x.5312] 
//
[0.x.5313] 
[0.x.5314] 
[0.x.5315] 
[0.x.5316] 
//
[0.x.5317] 
[0.x.5318] 
[0.x.5319] 
[0.x.5320] 
[0.x.5321] 
[0.x.5322] 
[0.x.5323] 
//
// Now that we have the local contributions to the linear system, we need to transfer it into the global objects. This is done exactly as in  [2.x.692] :
//
[0.x.5324] 
//
[0.x.5325] 
[0.x.5326] 
[0.x.5327] 
[0.x.5328] 
[0.x.5329] 
[0.x.5330] 
//
// Now compress the vector and the system matrix:
//
[0.x.5331] 
[0.x.5332] 
//
// The last step is to again fix up boundary values, just as we already did in previous programs. A slight complication is that the  [2.x.693]  function wants to have a solution vector compatible with the matrix and right hand side (i.e. here a distributed %parallel vector, rather than the sequential vector we use in this program) in order to preset the entries of the solution vector with the correct boundary values. We provide such a compatible vector in the form of a temporary vector which we then copy into the sequential one.
//
// We make up for this complication by showing how boundary values can be used flexibly: following the way we create the triangulation, there are three distinct boundary indicators used to describe the domain, corresponding to the bottom and top faces, as well as the inner/outer surfaces. We would like to impose boundary conditions of the following type: The inner and outer cylinder surfaces are free of external forces, a fact that corresponds to natural (Neumann-type) boundary conditions for which we don't have to do anything. At the bottom, we want no movement at all, corresponding to the cylinder being clamped or cemented in at this part of the boundary. At the top, however, we want a prescribed vertical downward motion compressing the cylinder; in addition, we only want to restrict the vertical movement, but not the horizontal ones -- one can think of this situation as a well-greased plate sitting on top of the cylinder pushing it downwards: the atoms of the cylinder are forced to move downward, but they are free to slide horizontally along the plate.
//
// The way to describe this is as follows: for boundary indicator zero (bottom face) we use a dim-dimensional zero function representing no motion in any coordinate direction. For the boundary with indicator 1 (top surface), we use the  [2.x.694]  class, but we specify an additional argument to the  [2.x.695]  function denoting which vector components it should apply to; this is a vector of bools for each vector component and because we only want to restrict vertical motion, it has only its last component set:
//
[0.x.5333] 
[0.x.5334] 
[0.x.5335] 
[0.x.5336] 
[0.x.5337] 
[0.x.5338] 
[0.x.5339] 
[0.x.5340] 
[0.x.5341] 
[0.x.5342] 
[0.x.5343] 
[0.x.5344] 
//
[0.x.5345] 
[0.x.5346] 
[0.x.5347] 
[0.x.5348] 
[0.x.5349] 
//
//  [2.x.696] 
//
// The next function is the one that controls what all has to happen within a timestep. The order of things should be relatively self-explanatory from the function names:
//
[0.x.5350] 
[0.x.5351] 
[0.x.5352] 
[0.x.5353] 
[0.x.5354] 
[0.x.5355] 
//
[0.x.5356] 
//
[0.x.5357] 
[0.x.5358] 
//
[0.x.5359] 
[0.x.5360] 
[0.x.5361] 
[0.x.5362] 
//
//  [2.x.697] 
//
// Solving the linear system again works mostly as before. The only difference is that we want to only keep a complete local copy of the solution vector instead of the distributed one that we get as output from PETSc's solver routines. To this end, we declare a local temporary variable for the distributed vector and initialize it with the contents of the local variable (remember that the  [2.x.698]  function called in  [2.x.699]  preset the values of boundary nodes in this vector), solve with it, and at the end of the function copy it again into the complete local vector that we declared as a member variable. Hanging node constraints are then distributed only on the local copy, i.e. independently of each other on each of the processors:
//
[0.x.5363] 
[0.x.5364] 
[0.x.5365] 
[0.x.5366] 
[0.x.5367] 
[0.x.5368] 
//
[0.x.5369] 
[0.x.5370] 
//
[0.x.5371] 
//
[0.x.5372] 
//
[0.x.5373] 
[0.x.5374] 
[0.x.5375] 
[0.x.5376] 
//
[0.x.5377] 
//
[0.x.5378] 
//
[0.x.5379] 
[0.x.5380] 
//
//  [2.x.700] 
//
// This function generates the graphical output in .vtu format as explained in the introduction. Each process will only work on the cells it owns, and then write the result into a file of its own. Additionally, processor 0 will write the record files the reference all the .vtu files.
//
// The crucial part of this function is to give the  [2.x.701]  class a way to only work on the cells that the present process owns.
//
[0.x.5381] 
[0.x.5382] 
[0.x.5383] 
[0.x.5384] 
[0.x.5385] 
//
// Then, just as in  [2.x.702] , define the names of solution variables (which here are the displacement increments) and queue the solution vector for output. Note in the following switch how we make sure that if the space dimension should be unhandled that we throw an exception saying that we haven't implemented this case yet (another case of defensive programming):
//
[0.x.5386] 
[0.x.5387] 
[0.x.5388] 
[0.x.5389] 
[0.x.5390] 
[0.x.5391] 
[0.x.5392] 
[0.x.5393] 
[0.x.5394] 
[0.x.5395] 
[0.x.5396] 
[0.x.5397] 
[0.x.5398] 
[0.x.5399] 
[0.x.5400] 
[0.x.5401] 
[0.x.5402] 
[0.x.5403] 
//
[0.x.5404] 
//
// The next thing is that we wanted to output something like the average norm of the stresses that we have stored in each cell. This may seem complicated, since on the present processor we only store the stresses in quadrature points on those cells that actually belong to the present process. In other words, it seems as if we can't compute the average stresses for all cells. However, remember that our class derived from  [2.x.703]  only iterates over those cells that actually do belong to the present processor, i.e. we don't have to compute anything for all the other cells as this information would not be touched. The following little loop does this. We enclose the entire block into a pair of braces to make sure that the iterator variables do not remain accidentally visible beyond the end of the block in which they are used:
//
[0.x.5405] 
[0.x.5406] 
//
// Loop over all the cells...
//
[0.x.5407] 
[0.x.5408] 
[0.x.5409] 
//
//   On these cells, add up the stresses over all quadrature   points...
//
[0.x.5410] 
[0.x.5411] 
[0.x.5412] 
[0.x.5413] 
[0.x.5414] 
//
//   ...then write the norm of the average to their destination:
//
[0.x.5415] 
[0.x.5416] 
[0.x.5417] 
//
// And on the cells that we are not interested in, set the respective value in the vector to a bogus value (norms must be positive, and a large negative value should catch your eye) in order to make sure that if we were somehow wrong about our assumption that these elements would not appear in the output file, that we would find out by looking at the graphical output:
//
[0.x.5418] 
[0.x.5419] 
[0.x.5420] 
//
// Finally attach this vector as well to be treated for output:
//
[0.x.5421] 
//
// As a last piece of data, let us also add the partitioning of the domain into subdomains associated with the processors if this is a parallel job. This works in the exact same way as in the  [2.x.704]  program:
//
[0.x.5422] 
[0.x.5423] 
[0.x.5424] 
[0.x.5425] 
[0.x.5426] 
[0.x.5427] 
//
// Finally, with all this data, we can instruct deal.II to munge the information and produce some intermediate data structures that contain all these solution and other data vectors:
//
[0.x.5428] 
//
// Let us call a function that opens the necessary output files and writes the data we have generated into them. The function automatically constructs the file names from the given directory name (the first argument) and file name base (second argument). It augments the resulting string by pieces that result from the time step number and a "piece number" that corresponds to a part of the overall domain that can consist of one or more subdomains.
//
// The function also writes a record files (with suffix `.pvd`) for Paraview that describes how all of these output files combine into the data for this single time step:
//
[0.x.5429] 
[0.x.5430] 
//
// The record files must be written only once and not by each processor, so we do this on processor 0:
//
[0.x.5431] 
[0.x.5432] 
//
// Finally, we write the paraview record, that references all .pvtu files and their respective time. Note that the variable times_and_names is declared static, so it will retain the entries from the previous timesteps.
//
[0.x.5433] 
[0.x.5434] 
[0.x.5435] 
[0.x.5436] 
[0.x.5437] 
[0.x.5438] 
[0.x.5439] 
//
//  [2.x.705] 
//
// This and the next function handle the overall structure of the first and following timesteps, respectively. The first timestep is slightly more involved because we want to compute it multiple times on successively refined meshes, each time starting from a clean state. At the end of these computations, in which we compute the incremental displacements each time, we use the last results obtained for the incremental displacements to compute the resulting stress updates and move the mesh accordingly. On this new mesh, we then output the solution and any additional data we consider important.
//
// All this is interspersed by generating output to the console to update the person watching the screen on what is going on. As in  [2.x.706] , the use of  [2.x.707]  makes sure that only one of the parallel processes is actually writing to the console, without having to explicitly code an if-statement in each place where we generate output:
//
[0.x.5440] 
[0.x.5441] 
[0.x.5442] 
[0.x.5443] 
[0.x.5444] 
[0.x.5445] 
[0.x.5446] 
//
[0.x.5447] 
[0.x.5448] 
[0.x.5449] 
//
[0.x.5450] 
[0.x.5451] 
[0.x.5452] 
[0.x.5453] 
//
[0.x.5454] 
[0.x.5455] 
[0.x.5456] 
[0.x.5457] 
[0.x.5458] 
[0.x.5459] 
[0.x.5460] 
//
[0.x.5461] 
//
[0.x.5462] 
[0.x.5463] 
[0.x.5464] 
[0.x.5465] 
[0.x.5466] 
[0.x.5467] 
[0.x.5468] 
//
[0.x.5469] 
[0.x.5470] 
//
[0.x.5471] 
[0.x.5472] 
//
[0.x.5473] 
[0.x.5474] 
//
//  [2.x.708] 
//
// Subsequent timesteps are simpler, and probably do not require any more documentation given the explanations for the previous function above:
//
[0.x.5475] 
[0.x.5476] 
[0.x.5477] 
[0.x.5478] 
[0.x.5479] 
[0.x.5480] 
[0.x.5481] 
[0.x.5482] 
[0.x.5483] 
[0.x.5484] 
[0.x.5485] 
[0.x.5486] 
//
[0.x.5487] 
//
[0.x.5488] 
[0.x.5489] 
//
[0.x.5490] 
[0.x.5491] 
//[2.x.709] 
//
// The following function is called when solving the first time step on successively refined meshes. After each iteration, it computes a refinement criterion, refines the mesh, and sets up the history variables in each quadrature point again to a clean state.
//
[0.x.5492] 
[0.x.5493] 
[0.x.5494] 
//
// First, let each process compute error indicators for the cells it owns:
//
[0.x.5495] 
[0.x.5496] 
[0.x.5497] 
[0.x.5498] 
[0.x.5499] 
[0.x.5500] 
[0.x.5501] 
[0.x.5502] 
[0.x.5503] 
[0.x.5504] 
[0.x.5505] 
//
// Then set up a global vector into which we merge the local indicators from each of the %parallel processes:
//
[0.x.5506] 
[0.x.5507] 
//
[0.x.5508] 
[0.x.5509] 
//
[0.x.5510] 
[0.x.5511] 
[0.x.5512] 
[0.x.5513] 
//
// Once we have that, copy it back into local copies on all processors and refine the mesh accordingly:
//
[0.x.5514] 
[0.x.5515] 
[0.x.5516] 
[0.x.5517] 
[0.x.5518] 
[0.x.5519] 
//
// Finally, set up quadrature point data again on the new mesh, and only on those cells that we have determined to be ours:
//
[0.x.5520] 
[0.x.5521] 
//
//  [2.x.710] 
//
// At the end of each time step, we move the nodes of the mesh according to the incremental displacements computed in this time step. To do this, we keep a vector of flags that indicate for each vertex whether we have already moved it around, and then loop over all cells and move those vertices of the cell that have not been moved yet. It is worth noting that it does not matter from which of the cells adjacent to a vertex we move this vertex: since we compute the displacement using a continuous finite element, the displacement field is continuous as well and we can compute the displacement of a given vertex from each of the adjacent cells. We only have to make sure that we move each node exactly once, which is why we keep the vector of flags.
//
// There are two noteworthy things in this function. First, how we get the displacement field at a given vertex using the  [2.x.711]  function that returns the index of the  [2.x.712]  of the given cell. In the present case, displacement in the k-th coordinate direction corresponds to the k-th component of the finite element. Using a function like this bears a certain risk, because it uses knowledge of the order of elements that we have taken together for this program in the  [2.x.713]  element. If we decided to add an additional variable, for example a pressure variable for stabilization, and happened to insert it as the first variable of the element, then the computation below will start to produce nonsensical results. In addition, this computation rests on other assumptions: first, that the element we use has, indeed, degrees of freedom that are associated with vertices. This is indeed the case for the present Q1 element, as would be for all Qp elements of polynomial order  [2.x.714] . However, it would not hold for discontinuous elements, or elements for mixed formulations. Secondly, it also rests on the assumption that the displacement at a vertex is determined solely by the value of the degree of freedom associated with this vertex; in other words, all shape functions corresponding to other degrees of freedom are zero at this particular vertex. Again, this is the case for the present element, but is not so for all elements that are presently available in deal.II. Despite its risks, we choose to use this way in order to present a way to query individual degrees of freedom associated with vertices.
//
// In this context, it is instructive to point out what a more general way would be. For general finite elements, the way to go would be to take a quadrature formula with the quadrature points in the vertices of a cell. The  [2.x.715]  formula for the trapezoidal rule does exactly this. With this quadrature formula, we would then initialize an  [2.x.716]  object in each cell, and use the  [2.x.717]  function to obtain the values of the solution function in the quadrature points, i.e. the vertices of the cell. These are the only values that we really need, i.e. we are not at all interested in the weights (or the  [2.x.718]  values) associated with this particular quadrature formula, and this can be specified as the last argument in the constructor to  [2.x.719] . The only point of minor inconvenience in this scheme is that we have to figure out which quadrature point corresponds to the vertex we consider at present, as they may or may not be ordered in the same order.
//
// This inconvenience could be avoided if finite elements have support points on vertices (which the one here has; for the concept of support points, see  [2.x.720]  "support points"). For such a case, one could construct a custom quadrature rule using  [2.x.721]  The first  [2.x.722]  quadrature points will then correspond to the vertices of the cell and are ordered consistent with  [2.x.723] , taking into account that support points for vector elements will be duplicated  [2.x.724]  times.
//
// Another point worth explaining about this short function is the way in which the triangulation class exports information about its vertices: through the  [2.x.725]  function, it advertises how many vertices there are in the triangulation. Not all of them are actually in use all the time -- some are left-overs from cells that have been coarsened previously and remain in existence since deal.II never changes the number of a vertex once it has come into existence, even if vertices with lower number go away. Secondly, the location returned by  [2.x.726]  is not only a read-only object of type  [2.x.727] , but in fact a reference that can be written to. This allows to move around the nodes of a mesh with relative ease, but it is worth pointing out that it is the responsibility of an application program using this feature to make sure that the resulting cells are still useful, i.e. are not distorted so much that the cell is degenerated (indicated, for example, by negative Jacobians). Note that we do not have any provisions in this function to actually ensure this, we just have faith.
//
// After this lengthy introduction, here are the full 20 or so lines of code:
//
[0.x.5522] 
[0.x.5523] 
[0.x.5524] 
[0.x.5525] 
//
[0.x.5526] 
[0.x.5527] 
[0.x.5528] 
[0.x.5529] 
[0.x.5530] 
[0.x.5531] 
//
[0.x.5532] 
[0.x.5533] 
[0.x.5534] 
[0.x.5535] 
//
[0.x.5536] 
[0.x.5537] 
[0.x.5538] 
//[2.x.728] 
//
// At the beginning of our computations, we needed to set up initial values of the history variables, such as the existing stresses in the material, that we store in each quadrature point. As mentioned above, we use the  [2.x.729]  for this that is available in each cell.
//
// To put this into larger perspective, we note that if we had previously available stresses in our model (which we assume do not exist for the purpose of this program), then we would need to interpolate the field of preexisting stresses to the quadrature points. Likewise, if we were to simulate elasto-plastic materials with hardening/softening, then we would have to store additional history variables like the present yield stress of the accumulated plastic strains in each quadrature points. Pre-existing hardening or weakening would then be implemented by interpolating these variables in the present function as well.
//
[0.x.5539] 
[0.x.5540] 
[0.x.5541] 
//
// For good measure, we set all user pointers of all cells, whether ours of not, to the null pointer. This way, if we ever access the user pointer of a cell which we should not have accessed, a segmentation fault will let us know that this should not have happened:
//
[0.x.5542] 
//
// Next, allocate the quadrature objects that are within the responsibility of this processor. This, of course, equals the number of cells that belong to this processor times the number of quadrature points our quadrature formula has on each cell. Since the `resize()` function does not actually shrink the amount of allocated memory if the requested new size is smaller than the old size, we resort to a trick to first free all memory, and then reallocate it: we declare an empty vector as a temporary variable and then swap the contents of the old vector and this temporary variable. This makes sure that the `quadrature_point_history` is now really empty, and we can let the temporary variable that now holds the previous contents of the vector go out of scope and be destroyed. In the next step we can then re-allocate as many elements as we need, with the vector default-initializing the `PointHistory` objects, which includes setting the stress variables to zero.
//
[0.x.5543] 
[0.x.5544] 
[0.x.5545] 
[0.x.5546] 
[0.x.5547] 
[0.x.5548] 
//
// Finally loop over all cells again and set the user pointers from the cells that belong to the present processor to point to the first quadrature point objects corresponding to this cell in the vector of such objects:
//
[0.x.5549] 
[0.x.5550] 
[0.x.5551] 
[0.x.5552] 
[0.x.5553] 
[0.x.5554] 
[0.x.5555] 
//
// At the end, for good measure make sure that our count of elements was correct and that we have both used up all objects we allocated previously, and not point to any objects beyond the end of the vector. Such defensive programming strategies are always good checks to avoid accidental errors and to guard against future changes to this function that forget to update all uses of a variable at the same time. Recall that constructs using the  [2.x.730]  macro are optimized away in optimized mode, so do not affect the run time of optimized runs:
//
[0.x.5556] 
[0.x.5557] 
[0.x.5558] 
//
//  [2.x.731] 
//
// At the end of each time step, we should have computed an incremental displacement update so that the material in its new configuration accommodates for the difference between the external body and boundary forces applied during this time step minus the forces exerted through preexisting internal stresses. In order to have the preexisting stresses available at the next time step, we therefore have to update the preexisting stresses with the stresses due to the incremental displacement computed during the present time step. Ideally, the resulting sum of internal stresses would exactly counter all external forces. Indeed, a simple experiment can make sure that this is so: if we choose boundary conditions and body forces to be time independent, then the forcing terms (the sum of external forces and internal stresses) should be exactly zero. If you make this experiment, you will realize from the output of the norm of the right hand side in each time step that this is almost the case: it is not exactly zero, since in the first time step the incremental displacement and stress updates were computed relative to the undeformed mesh, which was then deformed. In the second time step, we again compute displacement and stress updates, but this time in the deformed mesh -- there, the resulting updates are very small but not quite zero. This can be iterated, and in each such iteration the residual, i.e. the norm of the right hand side vector, is reduced; if one makes this little experiment, one realizes that the norm of this residual decays exponentially with the number of iterations, and after an initial very rapid decline is reduced by roughly a factor of about 3.5 in each iteration (for one testcase I looked at, other testcases, and other numbers of unknowns change the factor, but not the exponential decay).
//
// In a sense, this can then be considered as a quasi-timestepping scheme to resolve the nonlinear problem of solving large-deformation elasticity on a mesh that is moved along in a Lagrangian manner.
//
// Another complication is that the existing (old) stresses are defined on the old mesh, which we will move around after updating the stresses. If this mesh update involves rotations of the cell, then we need to also rotate the updated stress, since it was computed relative to the coordinate system of the old cell.
//
// Thus, what we need is the following: on each cell which the present processor owns, we need to extract the old stress from the data stored with each quadrature point, compute the stress update, add the two together, and then rotate the result together with the incremental rotation computed from the incremental displacement at the present quadrature point. We will detail these steps below:
//
[0.x.5559] 
[0.x.5560] 
[0.x.5561] 
//
// First, set up an  [2.x.732]  object by which we will evaluate the incremental displacements and the gradients thereof at the quadrature points, together with a vector that will hold this information:
//
[0.x.5562] 
[0.x.5563] 
[0.x.5564] 
//
[0.x.5565] 
[0.x.5566] 
//
// Then loop over all cells and do the job in the cells that belong to our subdomain:
//
[0.x.5567] 
[0.x.5568] 
[0.x.5569] 
//
// Next, get a pointer to the quadrature point history data local to the present cell, and, as a defensive measure, make sure that this pointer is within the bounds of the global array:
//
[0.x.5570] 
[0.x.5571] 
[0.x.5572] 
[0.x.5573] 
[0.x.5574] 
[0.x.5575] 
[0.x.5576] 
[0.x.5577] 
//
// Then initialize the  [2.x.733]  object on the present cell, and extract the gradients of the displacement at the quadrature points for later computation of the strains
//
[0.x.5578] 
[0.x.5579] 
[0.x.5580] 
//
// Then loop over the quadrature points of this cell:
//
[0.x.5581] 
[0.x.5582] 
//
//     On each quadrature point, compute the strain increment from     the gradients, and multiply it by the stress-strain tensor to     get the stress update. Then add this update to the already     existing strain at this point:
//
[0.x.5583] 
[0.x.5584] 
[0.x.5585] 
[0.x.5586] 
//
//     Finally, we have to rotate the result. For this, we first     have to compute a rotation matrix at the present quadrature     point from the incremental displacements. In fact, it can be     computed from the gradients, and we already have a function     for that purpose:
//
[0.x.5587] 
[0.x.5588] 
//
//     Note that the result, a rotation matrix, is in general an     antisymmetric tensor of rank 2, so we must store it as a full     tensor.
//
//     With this rotation matrix, we can compute the rotated tensor     by contraction from the left and right, after we expand the     symmetric tensor  [2.x.734]  into a full tensor:
//
[0.x.5589] 
[0.x.5590] 
[0.x.5591] 
//
//     Note that while the result of the multiplication of these     three matrices should be symmetric, it is not due to floating     point round off: we get an asymmetry on the order of 1e-16 of     the off-diagonal elements of the result. When assigning the     result to a  [2.x.735] , the constructor of     that class checks the symmetry and realizes that it isn't     exactly symmetric; it will then raise an exception. To avoid     that, we explicitly symmetrize the result to make it exactly     symmetric.
//
//     The result of all these operations is then written back into     the original place:
//
[0.x.5592] 
[0.x.5593] 
[0.x.5594] 
[0.x.5595] 
[0.x.5596] 
//
// This ends the project specific namespace  [2.x.736] . The rest is as usual and as already shown in  [2.x.737] : A  [2.x.738]  function that initializes and terminates PETSc, calls the classes that do the actual work, and makes sure that we catch all exceptions that propagate up to this point:
//
[0.x.5597] 
//
[0.x.5598] 
[0.x.5599] 
[0.x.5600] 
[0.x.5601] 
[0.x.5602] 
[0.x.5603] 
//
[0.x.5604] 
//
[0.x.5605] 
[0.x.5606] 
[0.x.5607] 
[0.x.5608] 
[0.x.5609] 
[0.x.5610] 
[0.x.5611] 
[0.x.5612] 
[0.x.5613] 
[0.x.5614] 
[0.x.5615] 
[0.x.5616] 
[0.x.5617] 
[0.x.5618] 
//
[0.x.5619] 
[0.x.5620] 
[0.x.5621] 
[0.x.5622] 
[0.x.5623] 
[0.x.5624] 
[0.x.5625] 
[0.x.5626] 
[0.x.5627] 
[0.x.5628] 
[0.x.5629] 
[0.x.5630] 
[0.x.5631] 
[0.x.5632] 
//
[0.x.5633] 
[0.x.5634] 
[0.x.5635] 
[0.x.5636] 
[0.x.5637] 
[0.x.5638] 
[0.x.5639] 
[0.x.5640] 
[0.x.5641] 
[0.x.5642] 
[0.x.5643] 
[0.x.5644] 
[0.x.5645] 
[0.x.5646] 
[0.x.5647] 
[0.x.5648] 
//
[0.x.5649] 
[0.x.5650] 
[0.x.5651] 
//[2.x.739] 
//
// The majority of the include files used in this program are well known from  [2.x.740]  and similar programs:
//
[0.x.5652] 
//
[0.x.5653] 
[0.x.5654] 
[0.x.5655] 
[0.x.5656] 
[0.x.5657] 
[0.x.5658] 
[0.x.5659] 
//
[0.x.5660] 
[0.x.5661] 
//
[0.x.5662] 
[0.x.5663] 
[0.x.5664] 
[0.x.5665] 
//
[0.x.5666] 
[0.x.5667] 
//
[0.x.5668] 
[0.x.5669] 
[0.x.5670] 
//
// The ones that are new are only the following three: The first declares the DiscreteTime class that helps us keep track of time in a time-dependent simulation. The latter two provide all of the particle functionality, namely a way to keep track of particles located on a mesh (the  [2.x.741]  class) and the ability to output these particles' locations and their properties for the purposes of visualization (the  [2.x.742]  class).
//
[0.x.5671] 
[0.x.5672] 
[0.x.5673] 
//
[0.x.5674] 
//
[0.x.5675] 
//[2.x.743] 
//
// As is customary, we put everything that corresponds to the details of the program into a namespace of its own. At the top, we define a few constants for which we would rather use symbolic names than hard-coded numbers.
//
// Specifically, we define numbers for  [2.x.744]  "boundary indicators" for the various parts of the geometry, as well as the physical properties of electrons and other specifics of the setup we use here.
//
// For the boundary indicators, let us start enumerating at some random value 101. The principle here is to use numbers that are *uncommon*. If there are pre-defined boundary indicators previously set by the `GridGenerator` functions, they will likely be small integers starting from zero, but not in this rather randomly chosen range. Using numbers such as those below avoids the possibility for conflicts, and also reduces the temptation to just spell these numbers out in the program (because you will probably never remember which is which, whereas you might have been tempted if they had started at 0).
//
[0.x.5676] 
[0.x.5677] 
[0.x.5678] 
[0.x.5679] 
[0.x.5680] 
[0.x.5681] 
[0.x.5682] 
[0.x.5683] 
[0.x.5684] 
//
[0.x.5685] 
[0.x.5686] 
[0.x.5687] 
[0.x.5688] 
//
[0.x.5689] 
//
[0.x.5690] 
//
[0.x.5691] 
[0.x.5692] 
//[2.x.745] 
//
// The following is then the main class of this program. It has, fundamentally, the same structure as  [2.x.746]  and many other tutorial programs. This includes the majority of the member functions (with the purpose of the rest probably self-explanatory from their names) as well as only a small number of member variables beyond those of  [2.x.747] , all of which are related to dealing with particles.
//
[0.x.5693] 
[0.x.5694] 
[0.x.5695] 
[0.x.5696] 
[0.x.5697] 
//
[0.x.5698] 
//
[0.x.5699] 
[0.x.5700] 
[0.x.5701] 
[0.x.5702] 
[0.x.5703] 
[0.x.5704] 
//
[0.x.5705] 
[0.x.5706] 
[0.x.5707] 
[0.x.5708] 
[0.x.5709] 
//
[0.x.5710] 
[0.x.5711] 
//
[0.x.5712] 
[0.x.5713] 
[0.x.5714] 
[0.x.5715] 
[0.x.5716] 
//
[0.x.5717] 
[0.x.5718] 
//
[0.x.5719] 
[0.x.5720] 
//
[0.x.5721] 
[0.x.5722] 
[0.x.5723] 
[0.x.5724] 
[0.x.5725] 
//
[0.x.5726] 
[0.x.5727] 
//
//  [2.x.748] 
//[2.x.749] 
//
// So then let us get started on the implementation. What the constructor does is really only a straight-forward initialization of all of the member variables at the top. The only two worth mentioning are the `particle_handler`, which is handed a reference to the triangulation on which the particles will live (currently of course still empty, but the particle handler stores the reference and will use it once particles are added -- which happens after the triangulation is built). The other piece of information it gets is how many "properties" each particle needs to store. Here, all we need each particle to remember is its current velocity, i.e., a vector with `dim` components. There are, however, other intrinsic properties that each particle has and that the  [2.x.750]  class automatically and always makes sure are available; in particular, these are the current location of a particle, the cell it is on, it's reference location within that cell, and the particle's ID.
//
// The only other variable of interest is `time`, an object of type DiscreteTime. It keeps track of the current time we are in a time-dependent simulation, and is initialized with the start time (zero) and end time ( [2.x.751] ). We will later set the time step size in `update_timestep_size()`.
//
// The body of the constructor consists of a piece of code we have already discussed in the introduction. Namely, we make sure that the `track_lost_particle()` function is called by the `particle_handler` object every time a particle leaves the domain.
//
[0.x.5728] 
[0.x.5729] 
[0.x.5730] 
[0.x.5731] 
[0.x.5732] 
[0.x.5733] 
[0.x.5734] 
[0.x.5735] 
[0.x.5736] 
[0.x.5737] 
[0.x.5738] 
[0.x.5739] 
[0.x.5740] 
[0.x.5741] 
[0.x.5742] 
[0.x.5743] 
[0.x.5744] 
[0.x.5745] 
//
//  [2.x.752] 
//
// The next function is then responsible for generating the mesh on which we want to solve. Recall how the domain looks like:    [2.x.753]  We subdivide this geometry into a mesh of  [2.x.754]  cells that looks like this: [1.x.23] The way this is done is by first defining where the  [2.x.755]  vertices are located -- here, we say that they are on integer points with the middle one on the left side moved to the right by a value of `delta=0.5`.
//
// In the following, we then have to say which vertices together form the 8 cells. The following code is then entirely equivalent to what we also do in  [2.x.756] :
//
[0.x.5746] 
[0.x.5747] 
[0.x.5748] 
[0.x.5749] 
[0.x.5750] 
//
[0.x.5751] 
[0.x.5752] 
[0.x.5753] 
//
[0.x.5754] 
[0.x.5755] 
[0.x.5756] 
[0.x.5757] 
[0.x.5758] 
[0.x.5759] 
[0.x.5760] 
[0.x.5761] 
[0.x.5762] 
[0.x.5763] 
[0.x.5764] 
[0.x.5765] 
[0.x.5766] 
[0.x.5767] 
[0.x.5768] 
[0.x.5769] 
[0.x.5770] 
//
[0.x.5771] 
[0.x.5772] 
[0.x.5773] 
[0.x.5774] 
[0.x.5775] 
//
[0.x.5776] 
[0.x.5777] 
[0.x.5778] 
[0.x.5779] 
//
// With these arrays out of the way, we can move to slightly higher higher-level data structures. We create a vector of CellData objects that store for each cell to be created the vertices in question as well as the  [2.x.757]  "material id" (which we will here simply set to zero since we don't use it in the program).
//
// This information is then handed to the  [2.x.758]  function, and the mesh is twice globally refined.
//
[0.x.5780] 
[0.x.5781] 
[0.x.5782] 
[0.x.5783] 
[0.x.5784] 
[0.x.5785] 
//
[0.x.5786] 
[0.x.5787] 
[0.x.5788] 
[0.x.5789] 
//
[0.x.5790] 
//
// The remaining part of the function loops over all cells and their faces, and if a face is at the boundary determines which boundary indicator should be applied to it. The various conditions should make sense if you compare the code with the picture of the geometry above.
//
// Once done with this step, we refine the mesh once more globally.
//
[0.x.5791] 
[0.x.5792] 
[0.x.5793] 
[0.x.5794] 
[0.x.5795] 
[0.x.5796] 
[0.x.5797] 
[0.x.5798] 
[0.x.5799] 
[0.x.5800] 
[0.x.5801] 
[0.x.5802] 
[0.x.5803] 
[0.x.5804] 
[0.x.5805] 
//
[0.x.5806] 
[0.x.5807] 
//[2.x.759] 
//
// The next function in this program deals with setting up the various objects related to solving the partial differential equations. It is in essence a copy of the corresponding function in  [2.x.760]  and requires no further discussion.
//
[0.x.5808] 
[0.x.5809] 
[0.x.5810] 
[0.x.5811] 
//
[0.x.5812] 
[0.x.5813] 
//
[0.x.5814] 
[0.x.5815] 
//
[0.x.5816] 
[0.x.5817] 
[0.x.5818] 
[0.x.5819] 
[0.x.5820] 
[0.x.5821] 
[0.x.5822] 
[0.x.5823] 
[0.x.5824] 
[0.x.5825] 
[0.x.5826] 
[0.x.5827] 
[0.x.5828] 
[0.x.5829] 
[0.x.5830] 
[0.x.5831] 
//
[0.x.5832] 
[0.x.5833] 
[0.x.5834] 
[0.x.5835] 
//
//                                    /*keep_constrained_dofs =  [2.x.761]  false);
//
[0.x.5836] 
//
[0.x.5837] 
[0.x.5838] 
//[2.x.762] 
//
// The function that computes the matrix entries is again in essence a copy of the corresponding function in  [2.x.763] :
//
[0.x.5839] 
[0.x.5840] 
[0.x.5841] 
[0.x.5842] 
[0.x.5843] 
//
[0.x.5844] 
//
[0.x.5845] 
[0.x.5846] 
[0.x.5847] 
[0.x.5848] 
//
[0.x.5849] 
//
[0.x.5850] 
[0.x.5851] 
//
[0.x.5852] 
//
[0.x.5853] 
[0.x.5854] 
[0.x.5855] 
[0.x.5856] 
//
[0.x.5857] 
//
[0.x.5858] 
[0.x.5859] 
[0.x.5860] 
[0.x.5861] 
[0.x.5862] 
[0.x.5863] 
[0.x.5864] 
[0.x.5865] 
[0.x.5866] 
//
// The only interesting part of this function is how it forms the right hand side of the linear system. Recall that the right hand side of the PDE is [1.x.24] where we have used  [2.x.764]  to index the particles here to avoid confusion with the shape function  [2.x.765] ;  [2.x.766]  is the position of the  [2.x.767] th particle.
//
// When multiplied by a test function  [2.x.768]  and integrated over the domain results in a right hand side vector [1.x.25] Note that the final line no longer contains an integral, and consequently also no occurrence of  [2.x.769]  which would require the appearance of the `JxW` symbol in our code.
//
// For a given cell  [2.x.770] , this cell's contribution to the right hand side is then [1.x.26] i.e., we only have to worry about those particles that are actually located on the current cell  [2.x.771] .
//
// In practice, what we do here is the following: If there are any particles on the current cell, then we first obtain an iterator range pointing to the first particle of that cell as well as the particle past the last one on this cell (or the end iterator) -- i.e., a half-open range as is common for C++ functions. Knowing now the list of particles, we query their reference locations (with respect to the reference cell), evaluate the shape functions in these reference locations, and compute the force according to the formula above (without any  [2.x.772] 
//[2.x.773]  It is worth pointing out that calling the    [2.x.774]  and    [2.x.775]  functions is not   very efficient on problems with a large number of particles. But it   illustrates the easiest way to write this algorithm, and so we are   willing to incur this cost for the moment for expository purposes.   We discuss the issue in more detail in the   [1.x.27]   below, and use a better approach in  [2.x.776] , for example.
//
[0.x.5867] 
[0.x.5868] 
[0.x.5869] 
[0.x.5870] 
[0.x.5871] 
[0.x.5872] 
[0.x.5873] 
[0.x.5874] 
[0.x.5875] 
[0.x.5876] 
[0.x.5877] 
//
// Finally, we can copy the contributions of this cell into the global matrix and right hand side vector:
//
[0.x.5878] 
[0.x.5879] 
[0.x.5880] 
[0.x.5881] 
[0.x.5882] 
//[2.x.777] 
//
// The function that solves the linear system is then again exactly as in  [2.x.778] :
//
[0.x.5883] 
[0.x.5884] 
[0.x.5885] 
[0.x.5886] 
[0.x.5887] 
//
[0.x.5888] 
[0.x.5889] 
//
[0.x.5890] 
//
[0.x.5891] 
[0.x.5892] 
//[2.x.779] 
//
// The final field-related function is the one that refines the grid. We will call it a number of times in the first time step to obtain a mesh that is well-adapted to the structure of the solution and, in particular, resolves the various singularities in the solution that are due to re-entrant corners and places where the boundary condition type changes. You might want to refer to  [2.x.780]  again for more details:
//
[0.x.5893] 
[0.x.5894] 
[0.x.5895] 
[0.x.5896] 
//
[0.x.5897] 
[0.x.5898] 
[0.x.5899] 
[0.x.5900] 
[0.x.5901] 
//
[0.x.5902] 
[0.x.5903] 
[0.x.5904] 
[0.x.5905] 
//
[0.x.5906] 
[0.x.5907] 
//[2.x.781] 
//
// Let us now turn to the functions that deal with particles. The first one is about the creation of particles. As mentioned in the introduction, we want to create a particle at points of the cathode if the the electric field  [2.x.782]  exceeds a certain threshold, i.e., if  [2.x.783] , and if furthermore the electric field points into the domain (i.e., if  [2.x.784] ). As is common in the finite element method, we evaluate fields (and their derivatives) at specific evaluation points; typically, these are "quadrature points", and so we create a "quadrature formula" that we will use to designate the points at which we want to evaluate the solution. Here, we will simply take QMidpoint implying that we will only check the threshold condition at the midpoints of faces. We then use this to initialize an object of type FEFaceValues to evaluate the solution at these points.
//
// All of this will then be used in a loop over all cells, their faces, and specifically those faces that are at the boundary and, moreover, the cathode part of the boundary.
//
[0.x.5908] 
[0.x.5909] 
[0.x.5910] 
[0.x.5911] 
[0.x.5912] 
[0.x.5913] 
[0.x.5914] 
[0.x.5915] 
//
[0.x.5916] 
[0.x.5917] 
//
[0.x.5918] 
[0.x.5919] 
[0.x.5920] 
[0.x.5921] 
[0.x.5922] 
[0.x.5923] 
//
//   So we have found a face on the cathode. Next, we let the   FEFaceValues object compute the gradient of the solution at each   "quadrature" point, and extract the electric field vector from   the gradient in the form of a Tensor variable through the methods   discussed in the    [2.x.785]  "vector-valued problems" documentation module.
//
[0.x.5924] 
[0.x.5925] 
[0.x.5926] 
[0.x.5927] 
[0.x.5928] 
[0.x.5929] 
[0.x.5930] 
//
//       Electrons can only escape the cathode if the electric field       strength exceeds a threshold and,       crucially, if the electric field points *into* the domain.       Once we have that checked, we create a new        [2.x.786]  object at this location and insert it       into the  [2.x.787]  object with a unique ID.             The only thing that may be not obvious here is that we also       associate with this particle the location in the reference       coordinates of the cell we are currently on. This is done       because we will in downstream functions compute quantities       such as the electric field at the location of the particle       (e.g., to compute the forces that act on it when updating its       position in each time step). Evaluating a finite element       field at arbitrary coordinates is quite an expensive       operation because shape functions are really only defined on       the reference cell, and so when asking for the electric field       at an arbitrary point requires us first to determine what the       reference coordinates of that point are. To avoid having to       do this over and over, we determine these coordinates once       and for all and then store these reference coordinates       directly with the particle.
//
[0.x.5931] 
[0.x.5932] 
[0.x.5933] 
[0.x.5934] 
[0.x.5935] 
//
[0.x.5936] 
[0.x.5937] 
[0.x.5938] 
[0.x.5939] 
[0.x.5940] 
[0.x.5941] 
//
[0.x.5942] 
[0.x.5943] 
[0.x.5944] 
[0.x.5945] 
//
// At the end of all of these insertions, we let the `particle_handler` update some internal statistics about the particles it stores.
//
[0.x.5946] 
[0.x.5947] 
//[2.x.788] 
//
// The second particle-related function is the one that moves the particles in each time step. To do this, we have to loop over all cells, the particles in each cell, and evaluate the electric field at each of the particles' positions.
//
// The approach used here is conceptually the same used in the `assemble_system()` function: We loop over all cells, find the particles located there (with the same caveat about the inefficiency of the algorithm used here to find these particles), and use FEPointEvaluation object to evaluate the gradient at these positions:
//
[0.x.5948] 
[0.x.5949] 
[0.x.5950] 
[0.x.5951] 
//
[0.x.5952] 
[0.x.5953] 
//
[0.x.5954] 
[0.x.5955] 
[0.x.5956] 
[0.x.5957] 
[0.x.5958] 
[0.x.5959] 
//
[0.x.5960] 
[0.x.5961] 
[0.x.5962] 
//
[0.x.5963] 
//
// Then we can ask the FEPointEvaluation object for the gradients of the solution (i.e., the electric field  [2.x.789] ) at these locations and loop over the individual particles:
//
[0.x.5964] 
[0.x.5965] 
[0.x.5966] 
//
[0.x.5967] 
[0.x.5968] 
[0.x.5969] 
[0.x.5970] 
[0.x.5971] 
[0.x.5972] 
[0.x.5973] 
[0.x.5974] 
[0.x.5975] 
//
//       Having now obtained the electric field at the location of one       of the particles, we use this to update first the velocity       and then the position. To do so, let us first get the old       velocity out of the properties stored with the particle,       compute the acceleration, update the velocity, and store this       new velocity again in the properties of the particle. Recall       that this corresponds to the first of the following set of       update equations discussed in the introduction:       [1.x.28]
//
[0.x.5976] 
//
[0.x.5977] 
[0.x.5978] 
//
[0.x.5979] 
[0.x.5980] 
//
[0.x.5981] 
//
//       With the new velocity, we can then also update the location       of the particle and tell the particle about it.
//
[0.x.5982] 
[0.x.5983] 
[0.x.5984] 
[0.x.5985] 
[0.x.5986] 
[0.x.5987] 
//
// Having updated the locations and properties (i.e., velocities) of all particles, we need to make sure that the `particle_handler` again knows which cells they are in, and what their locations in the coordinate system of the reference cell are. The following function does that. (It also makes sure that, in parallel computations, particles are moved from one processor to another processor if a particle moves from the subdomain owned by the former to the subdomain owned by the latter.)
//
[0.x.5988] 
[0.x.5989] 
//[2.x.790] 
//
// The final particle-related function is the one that is called whenever a particle is lost from the simulation. This typically happens if it leaves the domain. If that happens, this function is called both the cell (which we can ask for its new location) and the cell it was previously on. The function then keeps track of updating the number of particles lost in this time step, the total number of lost particles, and then estimates whether the particle left through the hole in the middle of the anode. We do so by first checking whether the cell it was in last had an  [2.x.791]  coordinate to the left of the right boundary (located at  [2.x.792] ) and the particle now has a position to the right of the right boundary. If that is so, we compute a direction vector of its motion that is normalized so that the  [2.x.793]  component of the direction vector is equal to  [2.x.794] . With this direction vector, we can compute where it would have intersected the line  [2.x.795] . If this intersect is between  [2.x.796]  and  [2.x.797] , then we claim that the particle left through the hole and increment a counter.
//
[0.x.5990] 
[0.x.5991] 
[0.x.5992] 
[0.x.5993] 
[0.x.5994] 
[0.x.5995] 
[0.x.5996] 
//
[0.x.5997] 
[0.x.5998] 
//
[0.x.5999] 
[0.x.6000] 
[0.x.6001] 
[0.x.6002] 
[0.x.6003] 
//
[0.x.6004] 
[0.x.6005] 
[0.x.6006] 
[0.x.6007] 
[0.x.6008] 
[0.x.6009] 
[0.x.6010] 
[0.x.6011] 
//
//  [2.x.798] 
//
// As discussed at length in the introduction, we need to respect a time step condition whereby particles can not move further than one cell in one time step. To ensure that this is the case, we again first compute the maximal speed of all particles on each cell, and divide the cell size by that speed. We then compute the next time step size as the minimum of this quantity over all cells, using the safety factor discussed in the introduction, and set this as the desired time step size using the  [2.x.799]  function.
//
[0.x.6012] 
[0.x.6013] 
[0.x.6014] 
[0.x.6015] 
[0.x.6016] 
[0.x.6017] 
//
[0.x.6018] 
[0.x.6019] 
[0.x.6020] 
[0.x.6021] 
//
[0.x.6022] 
//
[0.x.6023] 
[0.x.6024] 
[0.x.6025] 
[0.x.6026] 
[0.x.6027] 
[0.x.6028] 
[0.x.6029] 
//
[0.x.6030] 
[0.x.6031] 
[0.x.6032] 
[0.x.6033] 
[0.x.6034] 
//
[0.x.6035] 
[0.x.6036] 
[0.x.6037] 
[0.x.6038] 
//
// As mentioned in the introduction, we have to treat the very first time step differently since there, particles are not available yet or do not yet have the information associated that we need for the computation of a reasonable step length. The formulas below follow the discussion in the introduction.
//
[0.x.6039] 
[0.x.6040] 
[0.x.6041] 
[0.x.6042] 
//
[0.x.6043] 
//
[0.x.6044] 
//
[0.x.6045] 
[0.x.6046] 
[0.x.6047] 
[0.x.6048] 
//
[0.x.6049] 
[0.x.6050] 
//
[0.x.6051] 
[0.x.6052] 
[0.x.6053] 
//
[0.x.6054] 
[0.x.6055] 
[0.x.6056] 
[0.x.6057] 
[0.x.6058] 
[0.x.6059] 
[0.x.6060] 
//
[0.x.6061] 
[0.x.6062] 
[0.x.6063] 
//
//  [2.x.800] 
//
// The final function implementing pieces of the overall algorithm is the one that generates graphical output. In the current context, we want to output both the electric potential field as well as the particle locations and velocities. But we also want to output the electric field, i.e., the gradient of the solution.
//
// deal.II has a general way how one can compute derived quantities from the solution and output those as well. Here, this is the electric field, but it could also be some other quantity -- say, the norm of the electric field, or in fact anything else one could want to compute from the solution  [2.x.801]  or its derivatives. This general solution uses the DataPostprocessor class and, in cases like the one here where we want to output a quantity that represents a vector field, the DataPostprocessorVector class.
//
// Rather than try and explain how this class works, let us simply refer to the documentation of the DataPostprocessorVector class that has essentially this case as a well-documented example.
//
[0.x.6064] 
[0.x.6065] 
[0.x.6066] 
[0.x.6067] 
[0.x.6068] 
[0.x.6069] 
[0.x.6070] 
//
[0.x.6071] 
[0.x.6072] 
[0.x.6073] 
[0.x.6074] 
[0.x.6075] 
[0.x.6076] 
//
[0.x.6077] 
[0.x.6078] 
[0.x.6079] 
[0.x.6080] 
[0.x.6081] 
[0.x.6082] 
[0.x.6083] 
[0.x.6084] 
//
// With this, the `output_results()` function becomes relatively straightforward: We use the DataOut class as we have in almost every one of the previous tutorial programs to output the solution (the "electric potential") and we use the postprocessor defined above to also output its gradient (the "electric field"). This all is then written into a file in VTU format after also associating the current time and time step number with this file.
//
[0.x.6085] 
[0.x.6086] 
[0.x.6087] 
[0.x.6088] 
[0.x.6089] 
[0.x.6090] 
[0.x.6091] 
[0.x.6092] 
[0.x.6093] 
[0.x.6094] 
//
[0.x.6095] 
[0.x.6096] 
//
[0.x.6097] 
[0.x.6098] 
[0.x.6099] 
[0.x.6100] 
[0.x.6101] 
//
// Output the particle positions and properties is not more complicated. The  [2.x.802]  class plays the role of the DataOut class for particles, and all we have to do is tell that class where to take particles from and how to interpret the `dim` components of the properties -- namely, as a single vector indicating the velocity, rather than as `dim` scalar properties. The rest is then the same as above:
//
[0.x.6102] 
[0.x.6103] 
[0.x.6104] 
[0.x.6105] 
[0.x.6106] 
[0.x.6107] 
[0.x.6108] 
//
[0.x.6109] 
[0.x.6110] 
//
[0.x.6111] 
[0.x.6112] 
[0.x.6113] 
[0.x.6114] 
[0.x.6115] 
[0.x.6116] 
//[2.x.803] 
//
// The last member function of the principal class of this program is then the driver. At the top, it refines the mesh a number of times by solving the problem (with not particles yet created) on a sequence of finer and finer meshes.
//
[0.x.6117] 
[0.x.6118] 
[0.x.6119] 
[0.x.6120] 
//
// do a few refinement cycles up front
//
[0.x.6121] 
[0.x.6122] 
[0.x.6123] 
[0.x.6124] 
[0.x.6125] 
[0.x.6126] 
[0.x.6127] 
[0.x.6128] 
[0.x.6129] 
[0.x.6130] 
//
// Now do the loop over time. The sequence of steps follows closely the outline of the algorithm discussed in the introduction. As discussed in great detail in the documentation of the DiscreteTime class, while we move the field and particle information forward by one time step, the time stored in the `time` variable is not consistent with where (some of) these quantities are (in the diction of DiscreteTime, this is the "update stage"). The call to `time.advance_time()` makes everything consistent again by setting the `time` variable to the time at which the field and particles already are, and once we are in this "consistent stage", we can generate graphical output and write information about the current state of the simulation to screen.
//
[0.x.6131] 
[0.x.6132] 
[0.x.6133] 
[0.x.6134] 
[0.x.6135] 
[0.x.6136] 
//
[0.x.6137] 
[0.x.6138] 
//
[0.x.6139] 
[0.x.6140] 
[0.x.6141] 
//
[0.x.6142] 
[0.x.6143] 
[0.x.6144] 
//
[0.x.6145] 
//
[0.x.6146] 
//
[0.x.6147] 
[0.x.6148] 
[0.x.6149] 
[0.x.6150] 
[0.x.6151] 
[0.x.6152] 
[0.x.6153] 
//
[0.x.6154] 
[0.x.6155] 
[0.x.6156] 
[0.x.6157] 
[0.x.6158] 
[0.x.6159] 
[0.x.6160] 
[0.x.6161] 
[0.x.6162] 
//
//  [2.x.804] 
//
// The final function of the program is then again the `main()` function. It is unchanged in all tutorial programs since  [2.x.805]  and so there is nothing new to discuss:
//
[0.x.6163] 
[0.x.6164] 
[0.x.6165] 
[0.x.6166] 
[0.x.6167] 
[0.x.6168] 
[0.x.6169] 
[0.x.6170] 
[0.x.6171] 
[0.x.6172] 
[0.x.6173] 
[0.x.6174] 
[0.x.6175] 
[0.x.6176] 
[0.x.6177] 
[0.x.6178] 
[0.x.6179] 
[0.x.6180] 
//
[0.x.6181] 
[0.x.6182] 
[0.x.6183] 
[0.x.6184] 
[0.x.6185] 
[0.x.6186] 
[0.x.6187] 
[0.x.6188] 
[0.x.6189] 
[0.x.6190] 
[0.x.6191] 
[0.x.6192] 
[0.x.6193] 
[0.x.6194] 
[0.x.6195] 
[0.x.6196] 
[0.x.6197] 
[0.x.6198] 
[0.x.6199] 
[0.x.6200] 
[0.x.6201] 
[0.x.6202] 
[0.x.6203] 
[0.x.6204] 
[0.x.6205] 
[0.x.6206] 
[0.x.6207] 
[0.x.6208] 
[0.x.6209] 
[0.x.6210] 
//
[0.x.6211] 
[0.x.6212] 
[0.x.6213] 
//
// The first few includes are just like in the previous program, so do not require additional comments:
//
[0.x.6214] 
[0.x.6215] 
//
// However, the next file is new. We need this include file for the association of degrees of freedom ("DoF"s) to vertices, lines, and cells:
//
[0.x.6216] 
//
// The following include contains the description of the bilinear finite element, including the facts that it has one degree of freedom on each vertex of the triangulation, but none on faces and none in the interior of the cells.
//
// (In fact, the file contains the description of Lagrange elements in general, i.e. also the quadratic, cubic, etc versions, and not only for 2d but also 1d and 3d.)
//
[0.x.6217] 
//
// In the following file, several tools for manipulating degrees of freedom can be found:
//
[0.x.6218] 
//
// We will use a sparse matrix to visualize the pattern of nonzero entries resulting from the distribution of degrees of freedom on the grid. That class can be found here:
//
[0.x.6219] 
//
// We will also need to use an intermediate sparsity pattern structure, which is found in this file:
//
[0.x.6220] 
//
// We will want to use a special algorithm to renumber degrees of freedom. It is declared here:
//
[0.x.6221] 
//
// And this is again needed for C++ output:
//
[0.x.6222] 
//
// Finally, as in  [2.x.806] , we import the deal.II namespace into the global scope:
//
[0.x.6223] 
//[2.x.807] 
//
// This is the function that produced the circular grid in the previous  [2.x.808]  example program with fewer refinements steps. The sole difference is that it returns the grid it produces via its argument.
//
[0.x.6224] 
[0.x.6225] 
[0.x.6226] 
[0.x.6227] 
[0.x.6228] 
[0.x.6229] 
//
[0.x.6230] 
[0.x.6231] 
[0.x.6232] 
[0.x.6233] 
[0.x.6234] 
[0.x.6235] 
[0.x.6236] 
//
[0.x.6237] 
[0.x.6238] 
[0.x.6239] 
[0.x.6240] 
[0.x.6241] 
[0.x.6242] 
[0.x.6243] 
//
[0.x.6244] 
[0.x.6245] 
[0.x.6246] 
//[2.x.809] 
//
// Up to now, we only have a grid, i.e. some geometrical (the position of the vertices) and some topological information (how vertices are connected to lines, and lines to cells, as well as which cells neighbor which other cells). To use numerical algorithms, one needs some logic information in addition to that: we would like to associate degree of freedom numbers to each vertex (or line, or cell, in case we were using higher order elements) to later generate matrices and vectors which describe a finite element field on the triangulation.
//
// This function shows how to do this. The object to consider is the  [2.x.810]  class template.  Before we do so, however, we first need something that describes how many degrees of freedom are to be associated to each of these objects. Since this is one aspect of the definition of a finite element space, the finite element base class stores this information. In the present context, we therefore create an object of the derived class  [2.x.811]  that describes Lagrange elements. Its constructor takes one argument that states the polynomial degree of the element, which here is one (indicating a bi-linear element); this then corresponds to one degree of freedom for each vertex, while there are none on lines and inside the quadrilateral. A value of, say, three given to the constructor would instead give us a bi-cubic element with one degree of freedom per vertex, two per line, and four inside the cell. In general,  [2.x.812]  denotes the family of continuous elements with complete polynomials (i.e. tensor-product polynomials) up to the specified order.
//
// We first need to create an object of this class and then pass it on to the  [2.x.813]  object to allocate storage for the degrees of freedom (in deal.II lingo: we [1.x.29]).
//
[0.x.6247] 
[0.x.6248] 
[0.x.6249] 
[0.x.6250] 
//
// Now that we have associated a degree of freedom with a global number to each vertex, we wonder how to visualize this?  There is no simple way to directly visualize the DoF number associated with each vertex. However, such information would hardly ever be truly important, since the numbering itself is more or less arbitrary. There are more important factors, of which we will demonstrate one in the following.
//
// Associated with each vertex of the triangulation is a shape function. Assume we want to solve something like Laplace's equation, then the different matrix entries will be the integrals over the gradient of each pair of such shape functions. Obviously, since the shape functions are nonzero only on the cells adjacent to the vertex they are associated with, matrix entries will be nonzero only if the supports of the shape functions associated to that column and row %numbers intersect. This is only the case for adjacent shape functions, and therefore only for adjacent vertices. Now, since the vertices are numbered more or less randomly by the above function  [2.x.814]  the pattern of nonzero entries in the matrix will be somewhat ragged, and we will take a look at it now.
//
// First we have to create a structure which we use to store the places of nonzero elements. This can then later be used by one or more sparse matrix objects that store the values of the entries in the locations stored by this sparsity pattern. The class that stores the locations is the SparsityPattern class. As it turns out, however, this class has some drawbacks when we try to fill it right away: its data structures are set up in such a way that we need to have an estimate for the maximal number of entries we may wish to have in each row. In two space dimensions, reasonable values for this estimate are available through the  [2.x.815]  function, but in three dimensions the function almost always severely overestimates the true number, leading to a lot of wasted memory, sometimes too much for the machine used, even if the unused memory can be released immediately after computing the sparsity pattern. In order to avoid this, we use an intermediate object of type DynamicSparsityPattern that uses a different %internal data structure and that we can later copy into the SparsityPattern object without much overhead. (Some more information on these data structures can be found in the  [2.x.816]  module.) In order to initialize this intermediate data structure, we have to give it the size of the matrix, which in our case will be square with as many rows and columns as there are degrees of freedom on the grid:
//
[0.x.6251] 
[0.x.6252] 
//
// We then fill this object with the places where nonzero elements will be located given the present numbering of degrees of freedom:
//
[0.x.6253] 
//
// Now we are ready to create the actual sparsity pattern that we could later use for our matrix. It will just contain the data already assembled in the DynamicSparsityPattern.
//
[0.x.6254] 
[0.x.6255] 
//
// With this, we can now write the results to a file:
//
[0.x.6256] 
[0.x.6257] 
//
// The result is stored in an  [2.x.817]  file, where each nonzero entry in the matrix corresponds with a red square in the image. The output will be shown below.
//
// If you look at it, you will note that the sparsity pattern is symmetric. This should not come as a surprise, since we have not given the  [2.x.818]  any information that would indicate that our bilinear form may couple shape functions in a non-symmetric way. You will also note that it has several distinct region, which stem from the fact that the numbering starts from the coarsest cells and moves on to the finer ones; since they are all distributed symmetrically around the origin, this shows up again in the sparsity pattern.
//
[0.x.6258] 
//[2.x.819] 
//
// In the sparsity pattern produced above, the nonzero entries extended quite far off from the diagonal. For some algorithms, for example for incomplete LU decompositions or Gauss-Seidel preconditioners, this is unfavorable, and we will show a simple way how to improve this situation.
//
// Remember that for an entry  [2.x.820]  in the matrix to be nonzero, the supports of the shape functions i and j needed to intersect (otherwise in the integral, the integrand would be zero everywhere since either the one or the other shape function is zero at some point). However, the supports of shape functions intersected only if they were adjacent to each other, so in order to have the nonzero entries clustered around the diagonal (where  [2.x.821]  equals  [2.x.822] ), we would like to have adjacent shape functions to be numbered with indices (DoF numbers) that differ not too much.
//
// This can be accomplished by a simple front marching algorithm, where one starts at a given vertex and gives it the index zero. Then, its neighbors are numbered successively, making their indices close to the original one. Then, their neighbors, if not yet numbered, are numbered, and so on.
//
// One algorithm that adds a little bit of sophistication along these lines is the one by Cuthill and McKee. We will use it in the following function to renumber the degrees of freedom such that the resulting sparsity pattern is more localized around the diagonal. The only interesting part of the function is the first call to  [2.x.823] , the rest is essentially as before:
//
[0.x.6259] 
[0.x.6260] 
[0.x.6261] 
//
[0.x.6262] 
[0.x.6263] 
[0.x.6264] 
//
[0.x.6265] 
[0.x.6266] 
//
[0.x.6267] 
[0.x.6268] 
[0.x.6269] 
//
// Again, the output is shown below. Note that the nonzero entries are clustered far better around the diagonal than before. This effect is even more distinguished for larger matrices (the present one has 1260 rows and columns, but large matrices often have several 100,000s).
//
// It is worth noting that the  [2.x.824]  class offers a number of other algorithms as well to renumber degrees of freedom. For example, it would of course be ideal if all couplings were in the lower or upper triangular part of a matrix, since then solving the linear system would amount to only forward or backward substitution. This is of course unachievable for symmetric sparsity patterns, but in some special situations involving transport equations, this is possible by enumerating degrees of freedom from the inflow boundary along streamlines to the outflow boundary. Not surprisingly,  [2.x.825]  also has algorithms for this.
//
//  [2.x.826] 
//
// Finally, this is the main program. The only thing it does is to allocate and create the triangulation, then create a  [2.x.827]  object and associate it to the triangulation, and finally call above two functions on it:
//
[0.x.6270] 
[0.x.6271] 
[0.x.6272] 
[0.x.6273] 
//
[0.x.6274] 
//
[0.x.6275] 
[0.x.6276] 
[0.x.6277] 
[0.x.6278] 
[0.x.6279] 
[0.x.6280] 
[0.x.6281] 
[0.x.6282] 
[0.x.6283] 
[0.x.6284] 
[0.x.6285] 
[0.x.6286] 
[0.x.6287] 
[0.x.6288] 
[0.x.6289] 
[0.x.6290] 
[0.x.6291] 
[0.x.6292] 
//[2.x.828] 
//
// Since this program is only an adaptation of  [2.x.829] , there is not much new stuff in terms of header files. In deal.II, we usually list include files in the order base-lac-grid-dofs-fe-numerics, followed by C++ standard include files:
//
[0.x.6293] 
[0.x.6294] 
[0.x.6295] 
//
[0.x.6296] 
[0.x.6297] 
[0.x.6298] 
[0.x.6299] 
[0.x.6300] 
//
// The only two new header files that deserve some attention are those for the LinearOperator and PackagedOperation classes:
//
[0.x.6301] 
[0.x.6302] 
//
[0.x.6303] 
[0.x.6304] 
[0.x.6305] 
[0.x.6306] 
[0.x.6307] 
[0.x.6308] 
[0.x.6309] 
[0.x.6310] 
[0.x.6311] 
[0.x.6312] 
[0.x.6313] 
//
[0.x.6314] 
[0.x.6315] 
//
// This is the only significant new header, namely the one in which the Raviart-Thomas finite element is declared:
//
[0.x.6316] 
//
// Finally, as a bonus in this program, we will use a tensorial coefficient. Since it may have a spatial dependence, we consider it a tensor-valued function. The following include file provides the  [2.x.830]  class that offers such functionality:
//
[0.x.6317] 
//
// The last step is as in all previous programs: We put all of the code relevant to this program into a namespace. (This idea was first introduced in  [2.x.831] .)
//
[0.x.6318] 
[0.x.6319] 
[0.x.6320] 
//[2.x.832] 
//
// Again, since this is an adaptation of  [2.x.833] , the main class is almost the same as the one in that tutorial program. In terms of member functions, the main differences are that the constructor takes the degree of the Raviart-Thomas element as an argument (and that there is a corresponding member variable to store this value) and the addition of the  [2.x.834]  function in which, no surprise, we will compute the difference between the exact and the numerical solution to determine convergence of our computations:
//
[0.x.6321] 
[0.x.6322] 
[0.x.6323] 
[0.x.6324] 
[0.x.6325] 
[0.x.6326] 
//
[0.x.6327] 
[0.x.6328] 
[0.x.6329] 
[0.x.6330] 
[0.x.6331] 
[0.x.6332] 
//
[0.x.6333] 
//
[0.x.6334] 
[0.x.6335] 
[0.x.6336] 
//
// The second difference is that the sparsity pattern, the system matrix, and solution and right hand side vectors are now blocked. What this means and what one can do with such objects is explained in the introduction to this program as well as further down below when we explain the linear solvers and preconditioners for this problem:
//
[0.x.6337] 
[0.x.6338] 
//
[0.x.6339] 
[0.x.6340] 
[0.x.6341] 
//[2.x.835] 
//
// Our next task is to define the right hand side of our problem (i.e., the scalar right hand side for the pressure in the original Laplace equation), boundary values for the pressure, and a function that describes both the pressure and the velocity of the exact solution for later computations of the error. Note that these functions have one, one, and  [2.x.836]  components, respectively, and that we pass the number of components down to the  [2.x.837]  base class. For the exact solution, we only declare the function that actually returns the entire solution vector (i.e. all components of it) at once. Here are the respective declarations:
//
[0.x.6342] 
[0.x.6343] 
[0.x.6344] 
[0.x.6345] 
//
[0.x.6346] 
[0.x.6347] 
[0.x.6348] 
[0.x.6349] 
[0.x.6350] 
[0.x.6351] 
[0.x.6352] 
//
[0.x.6353] 
[0.x.6354] 
[0.x.6355] 
//
[0.x.6356] 
[0.x.6357] 
[0.x.6358] 
[0.x.6359] 
[0.x.6360] 
[0.x.6361] 
[0.x.6362] 
//
[0.x.6363] 
[0.x.6364] 
[0.x.6365] 
//
[0.x.6366] 
[0.x.6367] 
[0.x.6368] 
[0.x.6369] 
[0.x.6370] 
[0.x.6371] 
[0.x.6372] 
//
[0.x.6373] 
[0.x.6374] 
[0.x.6375] 
//
// And then we also have to define these respective functions, of course. Given our discussion in the introduction of how the solution should look, the following computations should be straightforward:
//
[0.x.6376] 
[0.x.6377] 
[0.x.6378] 
[0.x.6379] 
[0.x.6380] 
[0.x.6381] 
//
[0.x.6382] 
[0.x.6383] 
[0.x.6384] 
[0.x.6385] 
[0.x.6386] 
[0.x.6387] 
[0.x.6388] 
[0.x.6389] 
//
[0.x.6390] 
[0.x.6391] 
[0.x.6392] 
[0.x.6393] 
[0.x.6394] 
[0.x.6395] 
//
[0.x.6396] 
[0.x.6397] 
[0.x.6398] 
[0.x.6399] 
[0.x.6400] 
//
//  [2.x.838] 
//
// In addition to the other equation data, we also want to use a permeability tensor, or better -- because this is all that appears in the weak form -- the inverse of the permeability tensor,  [2.x.839] . For the purpose of verifying the exactness of the solution and determining convergence orders, this tensor is more in the way than helpful. We will therefore simply set it to the identity matrix.
//
// However, a spatially varying permeability tensor is indispensable in real-life porous media flow simulations, and we would like to use the opportunity to demonstrate the technique to use tensor valued functions.
//
// Possibly unsurprisingly, deal.II also has a base class not only for scalar and generally vector-valued functions (the  [2.x.840]  base class) but also for functions that return tensors of fixed dimension and rank, the  [2.x.841]  template. Here, the function under consideration returns a dim-by-dim matrix, i.e. a tensor of rank 2 and dimension  [2.x.842] . We then choose the template arguments of the base class appropriately.
//
// The interface that the  [2.x.843]  class provides is essentially equivalent to the  [2.x.844]  class. In particular, there exists a  [2.x.845]  function that takes a list of points at which to evaluate the function, and returns the values of the function in the second argument, a list of tensors:
//
[0.x.6401] 
[0.x.6402] 
[0.x.6403] 
[0.x.6404] 
[0.x.6405] 
[0.x.6406] 
[0.x.6407] 
//
[0.x.6408] 
[0.x.6409] 
[0.x.6410] 
[0.x.6411] 
//
// The implementation is less interesting. As in previous examples, we add a check to the beginning of the class to make sure that the sizes of input and output parameters are the same (see  [2.x.846]  for a discussion of this technique). Then we loop over all evaluation points, and for each one set the output tensor to the identity matrix.
//
// There is an oddity at the top of the function (the `(void)points;` statement) that is worth discussing. The values we put into the output `values` array does not actually depend on the `points` arrays of coordinates at which the function is evaluated. In other words, the `points` argument is in fact unused, and we could have just not given it a name if we had wanted. But we want to use the `points` object for checking that the `values` object has the correct size. The problem is that in release mode, `AssertDimension` is defined as a macro that expands to nothing; the compiler will then complain that the `points` object is unused. The idiomatic approach to silencing this warning is to have a statement that evaluates (reads) variable but doesn't actually do anything: That's what `(void)points;` does: It reads from `points`, and then casts the result of the read to `void`, i.e., nothing. This statement is, in other words, completely pointless and implies no actual action except to explain to the compiler that yes, this variable is in fact used even in release mode. (In debug mode, the `AssertDimension` macro expands to something that reads from the variable, and so the funny statement would not be necessary in debug mode.)
//
[0.x.6412] 
[0.x.6413] 
[0.x.6414] 
[0.x.6415] 
[0.x.6416] 
[0.x.6417] 
//
[0.x.6418] 
[0.x.6419] 
[0.x.6420] 
[0.x.6421] 
//
//  [2.x.847] 
//[2.x.848] 
//
// In the constructor of this class, we first store the value that was passed in concerning the degree of the finite elements we shall use (a degree of zero, for example, means to use RT(0) and DG(0)), and then construct the vector valued element belonging to the space  [2.x.849]  described in the introduction. The rest of the constructor is as in the early tutorial programs.
//
// The only thing worth describing here is the constructor call of the  [2.x.850]  class to which this variable belongs has a number of different constructors that all refer to binding simpler elements together into one larger element. In the present case, we want to couple a single RT(degree) element with a single DQ(degree) element. The constructor to  [2.x.851]  that does this requires us to specify first the first base element (the  [2.x.852]  object of given degree) and then the number of copies for this base element, and then similarly the kind and number of  [2.x.853]  elements. Note that the Raviart-Thomas element already has  [2.x.854]  vector components, so that the coupled element will have  [2.x.855]  vector components, the first  [2.x.856]  of which correspond to the velocity variable whereas the last one corresponds to the pressure.
//
// It is also worth comparing the way we constructed this element from its base elements, with the way we have done so in  [2.x.857] : there, we have built it as  [2.x.858] , i.e. we have simply used  [2.x.859]  element, one copy for the displacement in each coordinate direction.
//
[0.x.6422] 
[0.x.6423] 
[0.x.6424] 
[0.x.6425] 
[0.x.6426] 
[0.x.6427] 
//
//  [2.x.860] 
//
// This next function starts out with well-known functions calls that create and refine a mesh, and then associate degrees of freedom with it:
//
[0.x.6428] 
[0.x.6429] 
[0.x.6430] 
[0.x.6431] 
[0.x.6432] 
//
[0.x.6433] 
//
// However, then things become different. As mentioned in the introduction, we want to subdivide the matrix into blocks corresponding to the two different kinds of variables, velocity and pressure. To this end, we first have to make sure that the indices corresponding to velocities and pressures are not intermingled: First all velocity degrees of freedom, then all pressure DoFs. This way, the global matrix separates nicely into a  [2.x.861]  system. To achieve this, we have to renumber degrees of freedom based on their vector component, an operation that conveniently is already implemented:
//
[0.x.6434] 
//
// The next thing is that we want to figure out the sizes of these blocks so that we can allocate an appropriate amount of space. To this end, we call the  [2.x.862]  function that counts how many shape functions are non-zero for a particular vector component. We have  [2.x.863]  vector components, and  [2.x.864]  will count how many shape functions belong to each of these components.
//
// There is one problem here. As described in the documentation of that function, it [1.x.30] to put the number of  [2.x.865] -velocity shape functions into  [2.x.866] , the number of  [2.x.867] -velocity shape functions into  [2.x.868]  (and similar in 3d), and the number of pressure shape functions into  [2.x.869] . But, the Raviart-Thomas element is special in that it is non- [2.x.870]  "primitive", i.e., for Raviart-Thomas elements all velocity shape functions are nonzero in all components. In other words, the function cannot distinguish between  [2.x.871]  and  [2.x.872]  velocity functions because there [1.x.31] no such distinction. It therefore puts the overall number of velocity into each of  [2.x.873] ,  [2.x.874] . On the other hand, the number of pressure variables equals the number of shape functions that are nonzero in the dim-th component.
//
// Using this knowledge, we can get the number of velocity shape functions from any of the first  [2.x.875]  elements of  [2.x.876] , and then use this below to initialize the vector and matrix block sizes, as well as create output.
//
//  [2.x.877]  If you find this concept difficult to understand, you may want to consider using the function  [2.x.878]  instead, as we do in the corresponding piece of code in  [2.x.879] . You might also want to read up on the difference between  [2.x.880]  "blocks" and  [2.x.881]  "components" in the glossary.
//
[0.x.6435] 
[0.x.6436] 
[0.x.6437] 
[0.x.6438] 
//
[0.x.6439] 
[0.x.6440] 
[0.x.6441] 
[0.x.6442] 
[0.x.6443] 
[0.x.6444] 
//
// The next task is to allocate a sparsity pattern for the matrix that we will create. We use a compressed sparsity pattern like in the previous steps, but as  [2.x.882]  is a block matrix we use the class  [2.x.883]  instead of just  [2.x.884] . This block sparsity pattern has four blocks in a  [2.x.885]  pattern. The blocks' sizes depend on  [2.x.886] , which hold the number of velocity and pressure variables. In the second step we have to instruct the block system to update its knowledge about the sizes of the blocks it manages; this happens with the  [2.x.887]  call.
//
[0.x.6445] 
[0.x.6446] 
[0.x.6447] 
[0.x.6448] 
[0.x.6449] 
[0.x.6450] 
[0.x.6451] 
//
// We use the compressed block sparsity pattern in the same way as the non-block version to create the sparsity pattern and then the system matrix:
//
[0.x.6452] 
[0.x.6453] 
//
// Then we have to resize the solution and right hand side vectors in exactly the same way as the block compressed sparsity pattern:
//
[0.x.6454] 
[0.x.6455] 
[0.x.6456] 
[0.x.6457] 
//
[0.x.6458] 
[0.x.6459] 
[0.x.6460] 
[0.x.6461] 
[0.x.6462] 
//[2.x.888] 
//
// Similarly, the function that assembles the linear system has mostly been discussed already in the introduction to this example. At its top, what happens are all the usual steps, with the addition that we do not only allocate quadrature and  [2.x.889]  objects for the cell terms, but also for face terms. After that, we define the usual abbreviations for variables, and the allocate space for the local matrix and right hand side contributions, and the array that holds the global numbers of the degrees of freedom local to the present cell.
//
[0.x.6463] 
[0.x.6464] 
[0.x.6465] 
[0.x.6466] 
[0.x.6467] 
//
[0.x.6468] 
[0.x.6469] 
[0.x.6470] 
[0.x.6471] 
[0.x.6472] 
[0.x.6473] 
[0.x.6474] 
[0.x.6475] 
[0.x.6476] 
//
[0.x.6477] 
[0.x.6478] 
[0.x.6479] 
//
[0.x.6480] 
[0.x.6481] 
//
[0.x.6482] 
//
// The next step is to declare objects that represent the source term, pressure boundary value, and coefficient in the equation. In addition to these objects that represent continuous functions, we also need arrays to hold their values at the quadrature points of individual cells (or faces, for the boundary values). Note that in the case of the coefficient, the array has to be one of matrices.
//
[0.x.6483] 
[0.x.6484] 
[0.x.6485] 
[0.x.6486] 
//
[0.x.6487] 
[0.x.6488] 
[0.x.6489] 
//
// Finally, we need a couple of extractors that we will use to get at the velocity and pressure components of vector-valued shape functions. Their function and use is described in detail in the  [2.x.890]  vector_valued report. Essentially, we will use them as subscripts on the FEValues objects below: the FEValues object describes all vector components of shape functions, while after subscription, it will only refer to the velocities (a set of  [2.x.891]  components starting at component zero) or the pressure (a scalar component located at position  [2.x.892] ):
//
[0.x.6490] 
[0.x.6491] 
//
// With all this in place, we can go on with the loop over all cells. The body of this loop has been discussed in the introduction, and will not be commented any further here:
//
[0.x.6492] 
[0.x.6493] 
[0.x.6494] 
[0.x.6495] 
[0.x.6496] 
//
[0.x.6497] 
[0.x.6498] 
[0.x.6499] 
[0.x.6500] 
//
[0.x.6501] 
[0.x.6502] 
[0.x.6503] 
[0.x.6504] 
[0.x.6505] 
[0.x.6506] 
//
[0.x.6507] 
[0.x.6508] 
[0.x.6509] 
[0.x.6510] 
[0.x.6511] 
[0.x.6512] 
[0.x.6513] 
//
[0.x.6514] 
[0.x.6515] 
[0.x.6516] 
[0.x.6517] 
[0.x.6518] 
[0.x.6519] 
//
[0.x.6520] 
[0.x.6521] 
//
[0.x.6522] 
[0.x.6523] 
[0.x.6524] 
[0.x.6525] 
//
[0.x.6526] 
[0.x.6527] 
//
[0.x.6528] 
[0.x.6529] 
[0.x.6530] 
[0.x.6531] 
[0.x.6532] 
[0.x.6533] 
[0.x.6534] 
//
// The final step in the loop over all cells is to transfer local contributions into the global matrix and right hand side vector. Note that we use exactly the same interface as in previous examples, although we now use block matrices and vectors instead of the regular ones. In other words, to the outside world, block objects have the same interface as matrices and vectors, but they additionally allow to access individual blocks.
//
[0.x.6535] 
[0.x.6536] 
[0.x.6537] 
[0.x.6538] 
[0.x.6539] 
[0.x.6540] 
[0.x.6541] 
[0.x.6542] 
[0.x.6543] 
[0.x.6544] 
//[2.x.893] 
//
// The linear solvers and preconditioners we use in this example have been discussed in significant detail already in the introduction. We will therefore not discuss the rationale for our approach here any more, but rather only comment on some remaining implementational aspects.
//
//  [2.x.894] 
//
// As already outlined in the introduction, the solve function consists essentially of two steps. First, we have to form the first equation involving the Schur complement and solve for the pressure (component 1 of the solution). Then, we can reconstruct the velocities from the second equation (component 0 of the solution).
//
[0.x.6545] 
[0.x.6546] 
[0.x.6547] 
//
// As a first step we declare references to all block components of the matrix, the right hand side and the solution vector that we will need.
//
[0.x.6548] 
[0.x.6549] 
//
[0.x.6550] 
[0.x.6551] 
//
[0.x.6552] 
[0.x.6553] 
//
// Then, we will create corresponding LinearOperator objects and create the  [2.x.895]  operator:
//
[0.x.6554] 
[0.x.6555] 
//
[0.x.6556] 
[0.x.6557] 
[0.x.6558] 
//
[0.x.6559] 
//
[0.x.6560] 
//
// This allows us to declare the Schur complement  [2.x.896]  and the approximate Schur complement  [2.x.897] :
//
[0.x.6561] 
[0.x.6562] 
[0.x.6563] 
//
// We now create a preconditioner out of  [2.x.898]  that applies a fixed number of 30 (inexpensive) CG iterations:
//
[0.x.6564] 
[0.x.6565] 
//
[0.x.6566] 
[0.x.6567] 
//
// Now on to the first equation. The right hand side of it is  [2.x.899] , which is what we compute in the first few lines. We then solve the first equation with a CG solver and the preconditioner we just declared.
//
[0.x.6568] 
//
[0.x.6569] 
[0.x.6570] 
//
[0.x.6571] 
//
[0.x.6572] 
//
[0.x.6573] 
[0.x.6574] 
[0.x.6575] 
//
// After we have the pressure, we can compute the velocity. The equation reads  [2.x.900] , and we solve it by first computing the right hand side, and then multiplying it with the object that represents the inverse of the mass matrix:
//
[0.x.6576] 
[0.x.6577] 
//[2.x.901] 
//[2.x.902] 
//
// After we have dealt with the linear solver and preconditioners, we continue with the implementation of our main class. In particular, the next task is to compute the errors in our numerical solution, in both the pressures as well as velocities.
//
// To compute errors in the solution, we have already introduced the  [2.x.903]  function in  [2.x.904]  and  [2.x.905] . However, there we only dealt with scalar solutions, whereas here we have a vector-valued solution with components that even denote different quantities and may have different orders of convergence (this isn't the case here, by choice of the used finite elements, but is frequently the case in mixed finite element applications). What we therefore have to do is to `mask' the components that we are interested in. This is easily done: the  [2.x.906]  function takes as one of its arguments a pointer to a weight function (the parameter defaults to the null pointer, meaning unit weights). What we have to do is to pass a function object that equals one in the components we are interested in, and zero in the other ones. For example, to compute the pressure error, we should pass a function that represents the constant vector with a unit value in component  [2.x.907] , whereas for the velocity the constant vector should be one in the first  [2.x.908]  components, and zero in the location of the pressure.
//
// In deal.II, the  [2.x.909]  does exactly this: it wants to know how many vector components the function it is to represent should have (in our case this would be  [2.x.910] , for the joint velocity-pressure space) and which individual or range of components should be equal to one. We therefore define two such masks at the beginning of the function, following by an object representing the exact solution and a vector in which we will store the cellwise errors as computed by  [2.x.911] :
//
[0.x.6578] 
[0.x.6579] 
[0.x.6580] 
[0.x.6581] 
[0.x.6582] 
[0.x.6583] 
//
[0.x.6584] 
[0.x.6585] 
//
// As already discussed in  [2.x.912] , we have to realize that it is impossible to integrate the errors exactly. All we can do is approximate this integral using quadrature. This actually presents a slight twist here: if we naively chose an object of type  [2.x.913]  as one may be inclined to do (this is what we used for integrating the linear system), one realizes that the error is very small and does not follow the expected convergence curves at all. What is happening is that for the mixed finite elements used here, the Gauss points happen to be superconvergence points in which the pointwise error is much smaller (and converges with higher order) than anywhere else. These are therefore not particularly good points for integration. To avoid this problem, we simply use a trapezoidal rule and iterate it  [2.x.914]  times in each coordinate direction (again as explained in  [2.x.915] ):
//
[0.x.6586] 
[0.x.6587] 
//
// With this, we can then let the library compute the errors and output them to the screen:
//
[0.x.6588] 
[0.x.6589] 
[0.x.6590] 
[0.x.6591] 
[0.x.6592] 
[0.x.6593] 
[0.x.6594] 
[0.x.6595] 
[0.x.6596] 
[0.x.6597] 
[0.x.6598] 
//
[0.x.6599] 
[0.x.6600] 
[0.x.6601] 
[0.x.6602] 
[0.x.6603] 
[0.x.6604] 
[0.x.6605] 
[0.x.6606] 
[0.x.6607] 
[0.x.6608] 
[0.x.6609] 
//
[0.x.6610] 
[0.x.6611] 
[0.x.6612] 
//[2.x.916] 
//
// The last interesting function is the one in which we generate graphical output. Note that all velocity components get the same solution name "u". Together with using  [2.x.917]  this will cause  [2.x.918]  to generate a vector representation of the individual velocity components, see  [2.x.919]  or the  [2.x.920]  "Generating graphical output" section of the  [2.x.921]  module for more information. Finally, it seems inappropriate for higher order elements to only show a single bilinear quadrilateral per cell in the graphical output. We therefore generate patches of size (degree+1)x(degree+1) to capture the full information content of the solution. See the  [2.x.922]  tutorial program for more information on this.
//
[0.x.6613] 
[0.x.6614] 
[0.x.6615] 
[0.x.6616] 
[0.x.6617] 
[0.x.6618] 
[0.x.6619] 
[0.x.6620] 
[0.x.6621] 
//
[0.x.6622] 
[0.x.6623] 
[0.x.6624] 
[0.x.6625] 
[0.x.6626] 
//
[0.x.6627] 
//
[0.x.6628] 
[0.x.6629] 
[0.x.6630] 
//
//  [2.x.923] 
//
// This is the final function of our main class. It's only job is to call the other functions in their natural order:
//
[0.x.6631] 
[0.x.6632] 
[0.x.6633] 
[0.x.6634] 
[0.x.6635] 
[0.x.6636] 
[0.x.6637] 
[0.x.6638] 
[0.x.6639] 
[0.x.6640] 
//[2.x.924] 
//
// The main function we stole from  [2.x.925]  instead of  [2.x.926] . It is almost equal to the one in  [2.x.927]  (apart from the changed class names, of course), the only exception is that we pass the degree of the finite element space to the constructor of the mixed Laplace problem (here, we use zero-th order elements).
//
[0.x.6641] 
[0.x.6642] 
[0.x.6643] 
[0.x.6644] 
[0.x.6645] 
//
[0.x.6646] 
[0.x.6647] 
[0.x.6648] 
[0.x.6649] 
[0.x.6650] 
[0.x.6651] 
[0.x.6652] 
[0.x.6653] 
[0.x.6654] 
[0.x.6655] 
[0.x.6656] 
[0.x.6657] 
[0.x.6658] 
[0.x.6659] 
[0.x.6660] 
//
[0.x.6661] 
[0.x.6662] 
[0.x.6663] 
[0.x.6664] 
[0.x.6665] 
[0.x.6666] 
[0.x.6667] 
[0.x.6668] 
[0.x.6669] 
[0.x.6670] 
[0.x.6671] 
[0.x.6672] 
[0.x.6673] 
[0.x.6674] 
//
[0.x.6675] 
[0.x.6676] 
[0.x.6677] 
[0.x.6678] 
[0.x.6679] 
[0.x.6680] 
[0.x.6681] 
[0.x.6682] 
[0.x.6683] 
[0.x.6684] 
[0.x.6685] 
[0.x.6686] 
[0.x.6687] 
[0.x.6688] 
[0.x.6689] 
[0.x.6690] 
//
[0.x.6691] 
[0.x.6692] 
[0.x.6693] 
//
// This program is an adaptation of  [2.x.928]  and includes some technique of DG methods from  [2.x.929] . A good part of the program is therefore very similar to  [2.x.930]  and we will not comment again on these parts. Only the new stuff will be discussed in more detail.
//
//  [2.x.931] 
//
// All of these include files have been used before:
//
[0.x.6694] 
[0.x.6695] 
[0.x.6696] 
//
[0.x.6697] 
[0.x.6698] 
[0.x.6699] 
[0.x.6700] 
[0.x.6701] 
[0.x.6702] 
//
[0.x.6703] 
[0.x.6704] 
[0.x.6705] 
//
[0.x.6706] 
[0.x.6707] 
[0.x.6708] 
//
[0.x.6709] 
[0.x.6710] 
[0.x.6711] 
[0.x.6712] 
//
[0.x.6713] 
[0.x.6714] 
[0.x.6715] 
//
[0.x.6716] 
[0.x.6717] 
//
// In this program, we use a tensor-valued coefficient. Since it may have a spatial dependence, we consider it a tensor-valued function. The following include file provides the  [2.x.932]  class that offers such functionality:
//
[0.x.6718] 
//
// Additionally, we use the class  [2.x.933]  to perform operations related to time incrementation.
//
[0.x.6719] 
//
// The last step is as in all previous programs:
//
[0.x.6720] 
[0.x.6721] 
[0.x.6722] 
//[2.x.934] 
//
// This is the main class of the program. It is close to the one of  [2.x.935] , but with a few additional functions:
//
//  [2.x.936] 
//[2.x.937] 
//[2.x.938]  assembles the right hand side of the   saturation equation. As explained in the introduction, this can't be   integrated into  [2.x.939]  since it depends on the   velocity that is computed in the first part of the time step.
//
//    [2.x.940] 
//[2.x.941]  does as its name suggests. This   function is used in the computation of the time step size.
//
//    [2.x.942] 
//[2.x.943]  resets all saturation degrees   of freedom with values less than zero to zero, and all those with   saturations greater than one to one.   [2.x.944] 
//
// The rest of the class should be pretty much obvious. The  [2.x.945]  variable stores the viscosity  [2.x.946]  that enters several of the formulas in the nonlinear equations. The variable  [2.x.947]  keeps track of the time information within the simulation.
//
[0.x.6723] 
[0.x.6724] 
[0.x.6725] 
[0.x.6726] 
[0.x.6727] 
[0.x.6728] 
//
[0.x.6729] 
[0.x.6730] 
[0.x.6731] 
[0.x.6732] 
[0.x.6733] 
[0.x.6734] 
[0.x.6735] 
[0.x.6736] 
//
[0.x.6737] 
//
[0.x.6738] 
[0.x.6739] 
[0.x.6740] 
//
[0.x.6741] 
[0.x.6742] 
//
[0.x.6743] 
//
[0.x.6744] 
[0.x.6745] 
//
[0.x.6746] 
[0.x.6747] 
[0.x.6748] 
[0.x.6749] 
//[2.x.948] 
//[2.x.949] 
//
// At present, the right hand side of the pressure equation is simply the zero function. However, the rest of the program is fully equipped to deal with anything else, if this is desired:
//
[0.x.6750] 
[0.x.6751] 
[0.x.6752] 
[0.x.6753] 
[0.x.6754] 
[0.x.6755] 
[0.x.6756] 
//
[0.x.6757] 
[0.x.6758] 
[0.x.6759] 
[0.x.6760] 
[0.x.6761] 
[0.x.6762] 
//
//  [2.x.950] 
//
// The next are pressure boundary values. As mentioned in the introduction, we choose a linear pressure field:
//
[0.x.6763] 
[0.x.6764] 
[0.x.6765] 
[0.x.6766] 
[0.x.6767] 
[0.x.6768] 
[0.x.6769] 
//
[0.x.6770] 
[0.x.6771] 
[0.x.6772] 
[0.x.6773] 
[0.x.6774] 
[0.x.6775] 
//
//  [2.x.951] 
//
// Then we also need boundary values on the inflow portions of the boundary. The question whether something is an inflow part is decided when assembling the right hand side, we only have to provide a functional description of the boundary values. This is as explained in the introduction:
//
[0.x.6776] 
[0.x.6777] 
[0.x.6778] 
[0.x.6779] 
[0.x.6780] 
[0.x.6781] 
[0.x.6782] 
//
[0.x.6783] 
[0.x.6784] 
[0.x.6785] 
[0.x.6786] 
[0.x.6787] 
[0.x.6788] 
[0.x.6789] 
[0.x.6790] 
[0.x.6791] 
//
//  [2.x.952] 
//
// Finally, we need initial data. In reality, we only need initial data for the saturation, but we are lazy, so we will later, before the first time step, simply interpolate the entire solution for the previous time step from a function that contains all vector components.
//
// We therefore simply create a function that returns zero in all components. We do that by simply forward every function to the  [2.x.953]  class. Why not use that right away in the places of this program where we presently use the  [2.x.954]  class? Because this way it is simpler to later go back and choose a different function for initial values.
//
[0.x.6792] 
[0.x.6793] 
[0.x.6794] 
[0.x.6795] 
[0.x.6796] 
[0.x.6797] 
[0.x.6798] 
//
[0.x.6799] 
[0.x.6800] 
[0.x.6801] 
[0.x.6802] 
[0.x.6803] 
//
[0.x.6804] 
[0.x.6805] 
[0.x.6806] 
[0.x.6807] 
[0.x.6808] 
[0.x.6809] 
//
//  [2.x.955] 
//
// As announced in the introduction, we implement two different permeability tensor fields. Each of them we put into a namespace of its own, so that it will be easy later to replace use of one by the other in the code.
//
//  [2.x.956] 
//
// The first function for the permeability was the one that models a single curving crack. It was already used at the end of  [2.x.957] , and its functional form is given in the introduction of the present tutorial program. As in some previous programs, we have to declare a (seemingly unnecessary) default constructor of the KInverse class to avoid warnings from some compilers:
//
[0.x.6810] 
[0.x.6811] 
[0.x.6812] 
[0.x.6813] 
[0.x.6814] 
[0.x.6815] 
[0.x.6816] 
[0.x.6817] 
[0.x.6818] 
//
[0.x.6819] 
[0.x.6820] 
[0.x.6821] 
[0.x.6822] 
[0.x.6823] 
[0.x.6824] 
//
[0.x.6825] 
[0.x.6826] 
[0.x.6827] 
//
[0.x.6828] 
[0.x.6829] 
//
[0.x.6830] 
[0.x.6831] 
[0.x.6832] 
[0.x.6833] 
//
[0.x.6834] 
[0.x.6835] 
[0.x.6836] 
[0.x.6837] 
[0.x.6838] 
[0.x.6839] 
//[2.x.958] 
//
// This function does as announced in the introduction, i.e. it creates an overlay of exponentials at random places. There is one thing worth considering for this class. The issue centers around the problem that the class creates the centers of the exponentials using a random function. If we therefore created the centers each time we create an object of the present type, we would get a different list of centers each time. That's not what we expect from classes of this type: they should reliably represent the same function.
//
// The solution to this problem is to make the list of centers a static member variable of this class, i.e. there exists exactly one such variable for the entire program, rather than for each object of this type. That's exactly what we are going to do.
//
// The next problem, however, is that we need a way to initialize this variable. Since this variable is initialized at the beginning of the program, we can't use a regular member function for that since there may not be an object of this type around at the time. The C++ standard therefore says that only non-member and static member functions can be used to initialize a static variable. We use the latter possibility by defining a function  [2.x.959]  that computes the list of center points when called.
//
// Note that this class works just fine in both 2d and 3d, with the only difference being that we use more points in 3d: by experimenting we find that we need more exponentials in 3d than in 2d (we have more ground to cover, after all, if we want to keep the distance between centers roughly equal), so we choose 40 in 2d and 100 in 3d. For any other dimension, the function does presently not know what to do so simply throws an exception indicating exactly this.
//
[0.x.6840] 
[0.x.6841] 
[0.x.6842] 
[0.x.6843] 
[0.x.6844] 
[0.x.6845] 
[0.x.6846] 
[0.x.6847] 
[0.x.6848] 
//
[0.x.6849] 
[0.x.6850] 
[0.x.6851] 
[0.x.6852] 
[0.x.6853] 
[0.x.6854] 
//
[0.x.6855] 
[0.x.6856] 
[0.x.6857] 
//
[0.x.6858] 
[0.x.6859] 
[0.x.6860] 
[0.x.6861] 
//
[0.x.6862] 
[0.x.6863] 
//
[0.x.6864] 
[0.x.6865] 
[0.x.6866] 
[0.x.6867] 
//
[0.x.6868] 
[0.x.6869] 
//
[0.x.6870] 
[0.x.6871] 
[0.x.6872] 
[0.x.6873] 
//
[0.x.6874] 
[0.x.6875] 
[0.x.6876] 
[0.x.6877] 
//
[0.x.6878] 
[0.x.6879] 
[0.x.6880] 
//
[0.x.6881] 
[0.x.6882] 
[0.x.6883] 
[0.x.6884] 
//
//  [2.x.960] 
//
// There are two more pieces of data that we need to describe, namely the inverse mobility function and the saturation curve. Their form is also given in the introduction:
//
[0.x.6885] 
[0.x.6886] 
[0.x.6887] 
[0.x.6888] 
//
[0.x.6889] 
[0.x.6890] 
[0.x.6891] 
[0.x.6892] 
//
//  [2.x.961] 
//
// The linear solvers we use are also completely analogous to the ones used in  [2.x.962] . The following classes are therefore copied verbatim from there. Note that the classes here are not only copied from  [2.x.963] , but also duplicate classes in deal.II. In a future version of this example, they should be replaced by an efficient method, though. There is a single change: if the size of a linear system is small, i.e. when the mesh is very coarse, then it is sometimes not sufficient to set a maximum of  [2.x.964]  CG iterations before the solver in the  [2.x.965]  function converges. (This is, of course, a result of numerical round-off, since we know that on paper, the CG method converges in at most  [2.x.966]  steps.) As a consequence, we set the maximum number of iterations equal to the maximum of the size of the linear system and 200.
//
[0.x.6893] 
[0.x.6894] 
[0.x.6895] 
[0.x.6896] 
[0.x.6897] 
[0.x.6898] 
[0.x.6899] 
//
[0.x.6900] 
[0.x.6901] 
[0.x.6902] 
[0.x.6903] 
[0.x.6904] 
//
[0.x.6905] 
//
[0.x.6906] 
[0.x.6907] 
//
[0.x.6908] 
[0.x.6909] 
[0.x.6910] 
//
[0.x.6911] 
[0.x.6912] 
[0.x.6913] 
[0.x.6914] 
[0.x.6915] 
[0.x.6916] 
[0.x.6917] 
[0.x.6918] 
[0.x.6919] 
[0.x.6920] 
//
[0.x.6921] 
[0.x.6922] 
[0.x.6923] 
[0.x.6924] 
[0.x.6925] 
[0.x.6926] 
//
[0.x.6927] 
[0.x.6928] 
[0.x.6929] 
//
[0.x.6930] 
[0.x.6931] 
//
[0.x.6932] 
[0.x.6933] 
[0.x.6934] 
[0.x.6935] 
[0.x.6936] 
[0.x.6937] 
[0.x.6938] 
[0.x.6939] 
//
[0.x.6940] 
[0.x.6941] 
[0.x.6942] 
[0.x.6943] 
[0.x.6944] 
[0.x.6945] 
//
[0.x.6946] 
[0.x.6947] 
//
[0.x.6948] 
[0.x.6949] 
//
//  [2.x.967] 
//
// Here now the implementation of the main class. Much of it is actually copied from  [2.x.968] , so we won't comment on it in much detail. You should try to get familiar with that program first, then most of what is happening here should be mostly clear.
//
//  [2.x.969] 
//
// First for the constructor. We use  [2.x.970]  spaces. For initializing the DiscreteTime object, we don't set the time step size in the constructor because we don't have its value yet. The time step size is initially set to zero, but it will be computed before it is needed to increment time, as described in a subsection of the introduction. The time object internally prevents itself from being incremented when  [2.x.971] , forcing us to set a non-zero desired size for  [2.x.972]  before advancing time.
//
[0.x.6950] 
[0.x.6951] 
[0.x.6952] 
[0.x.6953] 
[0.x.6954] 
[0.x.6955] 
[0.x.6956] 
[0.x.6957] 
[0.x.6958] 
[0.x.6959] 
[0.x.6960] 
[0.x.6961] 
[0.x.6962] 
[0.x.6963] 
//
//  [2.x.973] 
//
// This next function starts out with well-known functions calls that create and refine a mesh, and then associate degrees of freedom with it. It does all the same things as in  [2.x.974] , just now for three components instead of two.
//
[0.x.6964] 
[0.x.6965] 
[0.x.6966] 
[0.x.6967] 
[0.x.6968] 
//
[0.x.6969] 
[0.x.6970] 
//
[0.x.6971] 
[0.x.6972] 
[0.x.6973] 
[0.x.6974] 
[0.x.6975] 
//
[0.x.6976] 
[0.x.6977] 
[0.x.6978] 
[0.x.6979] 
[0.x.6980] 
//
[0.x.6981] 
//
[0.x.6982] 
[0.x.6983] 
[0.x.6984] 
[0.x.6985] 
[0.x.6986] 
[0.x.6987] 
[0.x.6988] 
[0.x.6989] 
[0.x.6990] 
[0.x.6991] 
//
[0.x.6992] 
//
[0.x.6993] 
[0.x.6994] 
//
[0.x.6995] 
//
[0.x.6996] 
[0.x.6997] 
[0.x.6998] 
[0.x.6999] 
[0.x.7000] 
//
[0.x.7001] 
[0.x.7002] 
[0.x.7003] 
[0.x.7004] 
[0.x.7005] 
//
[0.x.7006] 
[0.x.7007] 
[0.x.7008] 
[0.x.7009] 
[0.x.7010] 
[0.x.7011] 
//[2.x.975] 
//
// This is the function that assembles the linear system, or at least everything except the (1,3) block that depends on the still-unknown velocity computed during this time step (we deal with this in  [2.x.976] ). Much of it is again as in  [2.x.977] , but we have to deal with some nonlinearity this time.  However, the top of the function is pretty much as usual (note that we set matrix and right hand side to zero at the beginning &mdash; something we didn't have to do for stationary problems since there we use each matrix object only once and it is empty at the beginning anyway).
//
// Note that in its present form, the function uses the permeability implemented in the  [2.x.978]  class. Switching to the single curved crack permeability function is as simple as just changing the namespace name.
//
[0.x.7012] 
[0.x.7013] 
[0.x.7014] 
[0.x.7015] 
[0.x.7016] 
//
[0.x.7017] 
[0.x.7018] 
//
[0.x.7019] 
[0.x.7020] 
[0.x.7021] 
[0.x.7022] 
[0.x.7023] 
[0.x.7024] 
[0.x.7025] 
[0.x.7026] 
[0.x.7027] 
//
[0.x.7028] 
//
[0.x.7029] 
[0.x.7030] 
//
[0.x.7031] 
[0.x.7032] 
//
[0.x.7033] 
//
[0.x.7034] 
[0.x.7035] 
[0.x.7036] 
//
[0.x.7037] 
[0.x.7038] 
[0.x.7039] 
//
[0.x.7040] 
[0.x.7041] 
[0.x.7042] 
[0.x.7043] 
//
[0.x.7044] 
[0.x.7045] 
[0.x.7046] 
//
[0.x.7047] 
[0.x.7048] 
[0.x.7049] 
[0.x.7050] 
[0.x.7051] 
//
// Here's the first significant difference: We have to get the values of the saturation function of the previous time step at the quadrature points. To this end, we can use the  [2.x.979]  (previously already used in  [2.x.980] ,  [2.x.981]  and  [2.x.982] ), a function that takes a solution vector and returns a list of function values at the quadrature points of the present cell. In fact, it returns the complete vector-valued solution at each quadrature point, i.e. not only the saturation but also the velocities and pressure:
//
[0.x.7052] 
//
// Then we also have to get the values of the pressure right hand side and of the inverse permeability tensor at the quadrature points:
//
[0.x.7053] 
[0.x.7054] 
[0.x.7055] 
[0.x.7056] 
//
// With all this, we can now loop over all the quadrature points and shape functions on this cell and assemble those parts of the matrix and right hand side that we deal with in this function. The individual terms in the contributions should be self-explanatory given the explicit form of the bilinear form stated in the introduction:
//
[0.x.7057] 
[0.x.7058] 
[0.x.7059] 
[0.x.7060] 
//
[0.x.7061] 
[0.x.7062] 
[0.x.7063] 
[0.x.7064] 
//
[0.x.7065] 
[0.x.7066] 
[0.x.7067] 
[0.x.7068] 
[0.x.7069] 
[0.x.7070] 
[0.x.7071] 
[0.x.7072] 
//
[0.x.7073] 
[0.x.7074] 
[0.x.7075] 
[0.x.7076] 
[0.x.7077] 
[0.x.7078] 
[0.x.7079] 
//
[0.x.7080] 
[0.x.7081] 
[0.x.7082] 
//
// Next, we also have to deal with the pressure boundary values. This, again is as in  [2.x.983] :
//
[0.x.7083] 
[0.x.7084] 
[0.x.7085] 
[0.x.7086] 
//
[0.x.7087] 
[0.x.7088] 
//
[0.x.7089] 
[0.x.7090] 
[0.x.7091] 
[0.x.7092] 
[0.x.7093] 
//
[0.x.7094] 
[0.x.7095] 
[0.x.7096] 
[0.x.7097] 
[0.x.7098] 
//
// The final step in the loop over all cells is to transfer local contributions into the global matrix and right hand side vector:
//
[0.x.7099] 
[0.x.7100] 
[0.x.7101] 
[0.x.7102] 
[0.x.7103] 
[0.x.7104] 
//
[0.x.7105] 
[0.x.7106] 
[0.x.7107] 
[0.x.7108] 
//
// So much for assembly of matrix and right hand side. Note that we do not have to interpolate and apply boundary values since they have all been taken care of in the weak form already.
//
//  [2.x.984] 
//
// As explained in the introduction, we can only evaluate the right hand side of the saturation equation once the velocity has been computed. We therefore have this separate function to this end.
//
[0.x.7109] 
[0.x.7110] 
[0.x.7111] 
[0.x.7112] 
[0.x.7113] 
[0.x.7114] 
[0.x.7115] 
[0.x.7116] 
[0.x.7117] 
[0.x.7118] 
[0.x.7119] 
[0.x.7120] 
[0.x.7121] 
[0.x.7122] 
[0.x.7123] 
[0.x.7124] 
[0.x.7125] 
//
[0.x.7126] 
[0.x.7127] 
[0.x.7128] 
//
[0.x.7129] 
//
[0.x.7130] 
[0.x.7131] 
[0.x.7132] 
[0.x.7133] 
[0.x.7134] 
[0.x.7135] 
[0.x.7136] 
[0.x.7137] 
[0.x.7138] 
[0.x.7139] 
[0.x.7140] 
[0.x.7141] 
//
[0.x.7142] 
[0.x.7143] 
//
[0.x.7144] 
//
[0.x.7145] 
//
[0.x.7146] 
[0.x.7147] 
[0.x.7148] 
[0.x.7149] 
//
[0.x.7150] 
[0.x.7151] 
//
// First for the cell terms. These are, following the formulas in the introduction,  [2.x.985] , where  [2.x.986]  is the saturation component of the test function:
//
[0.x.7152] 
[0.x.7153] 
[0.x.7154] 
[0.x.7155] 
[0.x.7156] 
[0.x.7157] 
[0.x.7158] 
//
[0.x.7159] 
[0.x.7160] 
[0.x.7161] 
//
[0.x.7162] 
[0.x.7163] 
[0.x.7164] 
[0.x.7165] 
[0.x.7166] 
[0.x.7167] 
//
// Secondly, we have to deal with the flux parts on the face boundaries. This was a bit more involved because we first have to determine which are the influx and outflux parts of the cell boundary. If we have an influx boundary, we need to evaluate the saturation on the other side of the face (or the boundary values, if we are at the boundary of the domain).
//
// All this is a bit tricky, but has been explained in some detail already in  [2.x.987] . Take a look there how this is supposed to work!
//
[0.x.7168] 
[0.x.7169] 
[0.x.7170] 
//
[0.x.7171] 
[0.x.7172] 
[0.x.7173] 
[0.x.7174] 
//
[0.x.7175] 
[0.x.7176] 
[0.x.7177] 
[0.x.7178] 
[0.x.7179] 
[0.x.7180] 
[0.x.7181] 
[0.x.7182] 
//
[0.x.7183] 
//
[0.x.7184] 
[0.x.7185] 
//
[0.x.7186] 
[0.x.7187] 
[0.x.7188] 
[0.x.7189] 
//
[0.x.7190] 
[0.x.7191] 
[0.x.7192] 
[0.x.7193] 
[0.x.7194] 
//
[0.x.7195] 
[0.x.7196] 
//
[0.x.7197] 
//
[0.x.7198] 
[0.x.7199] 
[0.x.7200] 
[0.x.7201] 
[0.x.7202] 
[0.x.7203] 
[0.x.7204] 
[0.x.7205] 
[0.x.7206] 
[0.x.7207] 
[0.x.7208] 
//
[0.x.7209] 
[0.x.7210] 
[0.x.7211] 
[0.x.7212] 
[0.x.7213] 
//
//  [2.x.988] 
//
// After all these preparations, we finally solve the linear system for velocity and pressure in the same way as in  [2.x.989] . After that, we have to deal with the saturation equation (see below):
//
[0.x.7214] 
[0.x.7215] 
[0.x.7216] 
[0.x.7217] 
[0.x.7218] 
[0.x.7219] 
[0.x.7220] 
[0.x.7221] 
//
// First the pressure, using the pressure Schur complement of the first two equations:
//
[0.x.7222] 
[0.x.7223] 
[0.x.7224] 
[0.x.7225] 
//
[0.x.7226] 
//
[0.x.7227] 
//
[0.x.7228] 
[0.x.7229] 
//
[0.x.7230] 
[0.x.7231] 
[0.x.7232] 
//
[0.x.7233] 
//
[0.x.7234] 
[0.x.7235] 
[0.x.7236] 
//
// Now the velocity:
//
[0.x.7237] 
[0.x.7238] 
[0.x.7239] 
[0.x.7240] 
//
[0.x.7241] 
[0.x.7242] 
//
// Finally, we have to take care of the saturation equation. The first business we have here is to determine the time step using the formula in the introduction. Knowing the shape of our domain and that we created the mesh by regular subdivision of cells, we can compute the diameter of each of our cells quite easily (in fact we use the linear extensions in coordinate directions of the cells, not the diameter). Note that we will learn a more general way to do this in  [2.x.990] , where we use the  [2.x.991]  function.
//
// The maximal velocity we compute using a helper function to compute the maximal velocity defined below, and with all this we can evaluate our new time step length. We use the method  [2.x.992]  to suggest the new calculated value of the time step to the DiscreteTime object. In most cases, the time object uses the exact provided value to increment time. It some case, the step size may be modified further by the time object. For example, if the calculated time increment overshoots the end time, it is truncated accordingly.
//
[0.x.7243] 
[0.x.7244] 
//
// The next step is to assemble the right hand side, and then to pass everything on for solution. At the end, we project back saturations onto the physically reasonable range:
//
[0.x.7245] 
[0.x.7246] 
[0.x.7247] 
[0.x.7248] 
[0.x.7249] 
[0.x.7250] 
[0.x.7251] 
[0.x.7252] 
[0.x.7253] 
//
[0.x.7254] 
//
[0.x.7255] 
[0.x.7256] 
[0.x.7257] 
//
[0.x.7258] 
[0.x.7259] 
//[2.x.993] 
//
// There is nothing surprising here. Since the program will do a lot of time steps, we create an output file only every fifth time step and skip all other time steps at the top of the file already.
//
// When creating file names for output close to the bottom of the function, we convert the number of the time step to a string representation that is padded by leading zeros to four digits. We do this because this way all output file names have the same length, and consequently sort well when creating a directory listing.
//
[0.x.7260] 
[0.x.7261] 
[0.x.7262] 
[0.x.7263] 
[0.x.7264] 
//
[0.x.7265] 
[0.x.7266] 
[0.x.7267] 
[0.x.7268] 
[0.x.7269] 
[0.x.7270] 
//
[0.x.7271] 
[0.x.7272] 
[0.x.7273] 
//
[0.x.7274] 
[0.x.7275] 
[0.x.7276] 
//
[0.x.7277] 
//
[0.x.7278] 
[0.x.7279] 
//
[0.x.7280] 
//
[0.x.7281] 
[0.x.7282] 
[0.x.7283] 
[0.x.7284] 
[0.x.7285] 
//
//  [2.x.994] 
//
// In this function, we simply run over all saturation degrees of freedom and make sure that if they should have left the physically reasonable range, that they be reset to the interval  [2.x.995] . To do this, we only have to loop over all saturation components of the solution vector; these are stored in the block 2 (block 0 are the velocities, block 1 are the pressures).
//
// It may be instructive to note that this function almost never triggers when the time step is chosen as mentioned in the introduction. However, if we choose the timestep only slightly larger, we get plenty of values outside the proper range. Strictly speaking, the function is therefore unnecessary if we choose the time step small enough. In a sense, the function is therefore only a safety device to avoid situations where our entire solution becomes unphysical because individual degrees of freedom have become unphysical a few time steps earlier.
//
[0.x.7286] 
[0.x.7287] 
[0.x.7288] 
[0.x.7289] 
[0.x.7290] 
[0.x.7291] 
[0.x.7292] 
[0.x.7293] 
[0.x.7294] 
//[2.x.996] 
//
// The following function is used in determining the maximal allowable time step. What it does is to loop over all quadrature points in the domain and find what the maximal magnitude of the velocity is.
//
[0.x.7295] 
[0.x.7296] 
[0.x.7297] 
[0.x.7298] 
[0.x.7299] 
//
[0.x.7300] 
[0.x.7301] 
[0.x.7302] 
[0.x.7303] 
//
[0.x.7304] 
[0.x.7305] 
[0.x.7306] 
[0.x.7307] 
//
[0.x.7308] 
[0.x.7309] 
[0.x.7310] 
[0.x.7311] 
[0.x.7312] 
//
[0.x.7313] 
[0.x.7314] 
[0.x.7315] 
//
[0.x.7316] 
[0.x.7317] 
//[2.x.997] 
//
// This is the final function of our main class. Its brevity speaks for itself. There are only two points worth noting: First, the function projects the initial values onto the finite element space at the beginning; the  [2.x.998]  function doing this requires an argument indicating the hanging node constraints. We have none in this program (we compute on a uniformly refined mesh), but the function requires the argument anyway, of course. So we have to create a constraint object. In its original state, constraint objects are unsorted, and have to be sorted (using the  [2.x.999]  function) before they can be used. This is what we do here, and which is why we can't simply call the  [2.x.1000]  function with an anonymous temporary object  [2.x.1001]  as the second argument.
//
// The second point worth mentioning is that we only compute the length of the present time step in the middle of solving the linear system corresponding to each time step. We can therefore output the present time of a time step only at the end of the time step. We increment time by calling the method  [2.x.1002]  inside the loop. Since we are reporting the time and dt after we increment it, we have to call the method  [2.x.1003]  instead of  [2.x.1004]  After many steps, when the simulation reaches the end time, the last dt is chosen by the DiscreteTime class in such a way that the last step finishes exactly at the end time.
//
[0.x.7318] 
[0.x.7319] 
[0.x.7320] 
[0.x.7321] 
//
[0.x.7322] 
[0.x.7323] 
[0.x.7324] 
//
[0.x.7325] 
[0.x.7326] 
[0.x.7327] 
[0.x.7328] 
[0.x.7329] 
[0.x.7330] 
//
[0.x.7331] 
[0.x.7332] 
[0.x.7333] 
//
[0.x.7334] 
//
[0.x.7335] 
//
[0.x.7336] 
//
[0.x.7337] 
[0.x.7338] 
[0.x.7339] 
[0.x.7340] 
[0.x.7341] 
[0.x.7342] 
[0.x.7343] 
[0.x.7344] 
[0.x.7345] 
//[2.x.1005] 
//
// That's it. In the main function, we pass the degree of the finite element space to the constructor of the TwoPhaseFlowProblem object.  Here, we use zero-th degree elements, i.e.  [2.x.1006] . The rest is as in all the other programs.
//
[0.x.7346] 
[0.x.7347] 
[0.x.7348] 
[0.x.7349] 
[0.x.7350] 
//
[0.x.7351] 
[0.x.7352] 
[0.x.7353] 
[0.x.7354] 
[0.x.7355] 
[0.x.7356] 
[0.x.7357] 
[0.x.7358] 
[0.x.7359] 
[0.x.7360] 
[0.x.7361] 
[0.x.7362] 
[0.x.7363] 
[0.x.7364] 
//
[0.x.7365] 
[0.x.7366] 
[0.x.7367] 
[0.x.7368] 
[0.x.7369] 
[0.x.7370] 
[0.x.7371] 
[0.x.7372] 
[0.x.7373] 
[0.x.7374] 
[0.x.7375] 
[0.x.7376] 
[0.x.7377] 
[0.x.7378] 
//
[0.x.7379] 
[0.x.7380] 
[0.x.7381] 
[0.x.7382] 
[0.x.7383] 
[0.x.7384] 
[0.x.7385] 
[0.x.7386] 
[0.x.7387] 
[0.x.7388] 
[0.x.7389] 
[0.x.7390] 
[0.x.7391] 
[0.x.7392] 
[0.x.7393] 
[0.x.7394] 
//
[0.x.7395] 
[0.x.7396] 
[0.x.7397] 
//[2.x.1007] 
//
// As usual, we start by including some well-known files:
//
[0.x.7398] 
[0.x.7399] 
[0.x.7400] 
[0.x.7401] 
//
[0.x.7402] 
[0.x.7403] 
[0.x.7404] 
[0.x.7405] 
[0.x.7406] 
[0.x.7407] 
//
[0.x.7408] 
[0.x.7409] 
[0.x.7410] 
[0.x.7411] 
//
[0.x.7412] 
[0.x.7413] 
[0.x.7414] 
//
[0.x.7415] 
[0.x.7416] 
[0.x.7417] 
//
[0.x.7418] 
[0.x.7419] 
[0.x.7420] 
[0.x.7421] 
//
// Then we need to include the header file for the sparse direct solver UMFPACK:
//
[0.x.7422] 
//
// This includes the library for the incomplete LU factorization that will be used as a preconditioner in 3D:
//
[0.x.7423] 
//
// This is C++:
//
[0.x.7424] 
[0.x.7425] 
[0.x.7426] 
//
// As in all programs, the namespace dealii is included:
//
[0.x.7427] 
[0.x.7428] 
[0.x.7429] 
//[2.x.1008] 
//
// As explained in the introduction, we are going to use different preconditioners for two and three space dimensions, respectively. We distinguish between them by the use of the spatial dimension as a template parameter. See  [2.x.1009]  for details on templates. We are not going to create any preconditioner object here, all we do is to create class that holds a local alias determining the preconditioner class so we can write our program in a dimension-independent way.
//
[0.x.7430] 
[0.x.7431] 
//
// In 2D, we are going to use a sparse direct solver as preconditioner:
//
[0.x.7432] 
[0.x.7433] 
[0.x.7434] 
[0.x.7435] 
[0.x.7436] 
//
// And the ILU preconditioning in 3D, called by SparseILU:
//
[0.x.7437] 
[0.x.7438] 
[0.x.7439] 
[0.x.7440] 
[0.x.7441] 
//[2.x.1010] 
//
// This is an adaptation of  [2.x.1011] , so the main class and the data types are nearly the same as used there. The only difference is that we have an additional member  [2.x.1012] , that is used for preconditioning the Schur complement, and a corresponding sparsity pattern  [2.x.1013] . In addition, instead of relying on LinearOperator, we implement our own InverseMatrix class.
//
// In this example we also use adaptive grid refinement, which is handled in analogy to  [2.x.1014] . According to the discussion in the introduction, we are also going to use the AffineConstraints object for implementing Dirichlet boundary conditions. Hence, we change the name  [2.x.1015] .
//
[0.x.7442] 
[0.x.7443] 
[0.x.7444] 
[0.x.7445] 
[0.x.7446] 
[0.x.7447] 
//
[0.x.7448] 
[0.x.7449] 
[0.x.7450] 
[0.x.7451] 
[0.x.7452] 
[0.x.7453] 
//
[0.x.7454] 
//
[0.x.7455] 
[0.x.7456] 
[0.x.7457] 
//
[0.x.7458] 
//
[0.x.7459] 
[0.x.7460] 
//
[0.x.7461] 
[0.x.7462] 
//
[0.x.7463] 
[0.x.7464] 
//
// This one is new: We shall use a so-called shared pointer structure to access the preconditioner. Shared pointers are essentially just a convenient form of pointers. Several shared pointers can point to the same object (just like regular pointers), but when the last shared pointer object to point to a preconditioner object is deleted (for example if a shared pointer object goes out of scope, if the class of which it is a member is destroyed, or if the pointer is assigned a different preconditioner object) then the preconditioner object pointed to is also destroyed. This ensures that we don't have to manually track in how many places a preconditioner object is still referenced, it can never create a memory leak, and can never produce a dangling pointer to an already destroyed object:
//
[0.x.7465] 
[0.x.7466] 
//[2.x.1016] 
//
// As in  [2.x.1017]  and most other example programs, the next task is to define the data for the PDE: For the Stokes problem, we are going to use natural boundary values on parts of the boundary (i.e. homogeneous Neumann-type) for which we won't have to do anything special (the homogeneity implies that the corresponding terms in the weak form are simply zero), and boundary conditions on the velocity (Dirichlet-type) on the rest of the boundary, as described in the introduction.
//
// In order to enforce the Dirichlet boundary values on the velocity, we will use the  [2.x.1018]  function as usual which requires us to write a function object with as many components as the finite element has. In other words, we have to define the function on the  [2.x.1019] -space, but we are going to filter out the pressure component when interpolating the boundary values.
//
// The following function object is a representation of the boundary values described in the introduction:
//
[0.x.7467] 
[0.x.7468] 
[0.x.7469] 
[0.x.7470] 
[0.x.7471] 
[0.x.7472] 
[0.x.7473] 
//
[0.x.7474] 
[0.x.7475] 
//
[0.x.7476] 
[0.x.7477] 
[0.x.7478] 
//
[0.x.7479] 
[0.x.7480] 
[0.x.7481] 
[0.x.7482] 
[0.x.7483] 
[0.x.7484] 
//
[0.x.7485] 
[0.x.7486] 
[0.x.7487] 
[0.x.7488] 
//
[0.x.7489] 
[0.x.7490] 
[0.x.7491] 
[0.x.7492] 
[0.x.7493] 
[0.x.7494] 
[0.x.7495] 
//
// We implement similar functions for the right hand side which for the current example is simply zero:
//
[0.x.7496] 
[0.x.7497] 
[0.x.7498] 
[0.x.7499] 
[0.x.7500] 
[0.x.7501] 
[0.x.7502] 
//
[0.x.7503] 
[0.x.7504] 
//
[0.x.7505] 
[0.x.7506] 
[0.x.7507] 
//
[0.x.7508] 
[0.x.7509] 
[0.x.7510] 
[0.x.7511] 
[0.x.7512] 
[0.x.7513] 
//
[0.x.7514] 
[0.x.7515] 
[0.x.7516] 
[0.x.7517] 
[0.x.7518] 
[0.x.7519] 
[0.x.7520] 
//[2.x.1020] 
//
// The linear solvers and preconditioners are discussed extensively in the introduction. Here, we create the respective objects that will be used.
//
//  [2.x.1021]  The  [2.x.1022]  class represents the data structure for an inverse matrix. Unlike  [2.x.1023] , we implement this with a class instead of the helper function inverse_linear_operator() we will apply this class to different kinds of matrices that will require different preconditioners (in  [2.x.1024]  we only used a non-identity preconditioner for the mass matrix). The types of matrix and preconditioner are passed to this class via template parameters, and matrix and preconditioner objects of these types will then be passed to the constructor when an  [2.x.1025]  object is created. The member function  [2.x.1026]  is obtained by solving a linear system:
//
[0.x.7521] 
[0.x.7522] 
[0.x.7523] 
[0.x.7524] 
[0.x.7525] 
[0.x.7526] 
//
[0.x.7527] 
//
[0.x.7528] 
[0.x.7529] 
[0.x.7530] 
[0.x.7531] 
//
[0.x.7532] 
[0.x.7533] 
[0.x.7534] 
[0.x.7535] 
[0.x.7536] 
[0.x.7537] 
[0.x.7538] 
//
// This is the implementation of the  [2.x.1027]  function.
//
// In this class we use a rather large tolerance for the solver control. The reason for this is that the function is used very frequently, and hence, any additional effort to make the residual in the CG solve smaller makes the solution more expensive. Note that we do not only use this class as a preconditioner for the Schur complement, but also when forming the inverse of the Laplace matrix &ndash; which is hence directly responsible for the accuracy of the solution itself, so we can't choose a too large tolerance, either.
//
[0.x.7539] 
[0.x.7540] 
[0.x.7541] 
[0.x.7542] 
[0.x.7543] 
[0.x.7544] 
[0.x.7545] 
//
[0.x.7546] 
//
[0.x.7547] 
[0.x.7548] 
//[2.x.1028] 
//
// This class implements the Schur complement discussed in the introduction. It is in analogy to  [2.x.1029] .  Though, we now call it with a template parameter  [2.x.1030]  in order to access that when specifying the respective type of the inverse matrix class. As a consequence of the definition above, the declaration  [2.x.1031]  now contains the second template parameter for a preconditioner class as above, which affects the  [2.x.1032]  as well.
//
[0.x.7549] 
[0.x.7550] 
[0.x.7551] 
[0.x.7552] 
[0.x.7553] 
[0.x.7554] 
[0.x.7555] 
//
[0.x.7556] 
//
[0.x.7557] 
[0.x.7558] 
[0.x.7559] 
[0.x.7560] 
[0.x.7561] 
//
[0.x.7562] 
[0.x.7563] 
//
[0.x.7564] 
[0.x.7565] 
[0.x.7566] 
[0.x.7567] 
[0.x.7568] 
[0.x.7569] 
[0.x.7570] 
[0.x.7571] 
[0.x.7572] 
//
[0.x.7573] 
[0.x.7574] 
[0.x.7575] 
[0.x.7576] 
[0.x.7577] 
[0.x.7578] 
[0.x.7579] 
[0.x.7580] 
[0.x.7581] 
//[2.x.1033] 
//[2.x.1034] 
//
// The constructor of this class looks very similar to the one of  [2.x.1035] . The constructor initializes the variables for the polynomial degree, triangulation, finite element system and the dof handler. The underlying polynomial functions are of order  [2.x.1036]  for the vector-valued velocity components and of order  [2.x.1037]  for the pressure.  This gives the LBB-stable element pair  [2.x.1038] , often referred to as the Taylor-Hood element.
//
// Note that we initialize the triangulation with a MeshSmoothing argument, which ensures that the refinement of cells is done in a way that the approximation of the PDE solution remains well-behaved (problems arise if grids are too unstructured), see the documentation of  [2.x.1039]  for details.
//
[0.x.7582] 
[0.x.7583] 
[0.x.7584] 
[0.x.7585] 
[0.x.7586] 
[0.x.7587] 
[0.x.7588] 
//[2.x.1040] 
//
// Given a mesh, this function associates the degrees of freedom with it and creates the corresponding matrices and vectors. At the beginning it also releases the pointer to the preconditioner object (if the shared pointer pointed at anything at all at this point) since it will definitely not be needed any more after this point and will have to be re-computed after assembling the matrix, and unties the sparse matrices from their sparsity pattern objects.
//
// We then proceed with distributing degrees of freedom and renumbering them: In order to make the ILU preconditioner (in 3D) work efficiently, it is important to enumerate the degrees of freedom in such a way that it reduces the bandwidth of the matrix, or maybe more importantly: in such a way that the ILU is as close as possible to a real LU decomposition. On the other hand, we need to preserve the block structure of velocity and pressure already seen in  [2.x.1041]  and  [2.x.1042] . This is done in two steps: First, all dofs are renumbered to improve the ILU and then we renumber once again by components. Since  [2.x.1043]  does not touch the renumbering within the individual blocks, the basic renumbering from the first step remains. As for how the renumber degrees of freedom to improve the ILU: deal.II has a number of algorithms that attempt to find orderings to improve ILUs, or reduce the bandwidth of matrices, or optimize some other aspect. The DoFRenumbering namespace shows a comparison of the results we obtain with several of these algorithms based on the testcase discussed here in this tutorial program. Here, we will use the traditional Cuthill-McKee algorithm already used in some of the previous tutorial programs.  In the [1.x.32] we're going to discuss this issue in more detail.
//
// There is one more change compared to previous tutorial programs: There is no reason in sorting the  [2.x.1044]  velocity components individually. In fact, rather than first enumerating all  [2.x.1045] -velocities, then all  [2.x.1046] -velocities, etc, we would like to keep all velocities at the same location together and only separate between velocities (all components) and pressures. By default, this is not what the  [2.x.1047]  function does: it treats each vector component separately; what we have to do is group several components into "blocks" and pass this block structure to that function. Consequently, we allocate a vector  [2.x.1048]  with as many elements as there are components and describe all velocity components to correspond to block 0, while the pressure component will form block 1:
//
[0.x.7589] 
[0.x.7590] 
[0.x.7591] 
[0.x.7592] 
[0.x.7593] 
[0.x.7594] 
//
[0.x.7595] 
[0.x.7596] 
//
[0.x.7597] 
[0.x.7598] 
[0.x.7599] 
//
// Now comes the implementation of Dirichlet boundary conditions, which should be evident after the discussion in the introduction. All that changed is that the function already appears in the setup functions, whereas we were used to see it in some assembly routine. Further down below where we set up the mesh, we will associate the top boundary where we impose Dirichlet boundary conditions with boundary indicator 1.  We will have to pass this boundary indicator as second argument to the function below interpolating boundary values.  There is one more thing, though.  The function describing the Dirichlet conditions was defined for all components, both velocity and pressure. However, the Dirichlet conditions are to be set for the velocity only.  To this end, we use a ComponentMask that only selects the velocity components. The component mask is obtained from the finite element by specifying the particular components we want. Since we use adaptively refined grids, the affine constraints object needs to be first filled with hanging node constraints generated from the DoF handler. Note the order of the two functions &mdash; we first compute the hanging node constraints, and then insert the boundary values into the constraints object. This makes sure that we respect H<sup>1</sup> conformity on boundaries with hanging nodes (in three space dimensions), where the hanging node needs to dominate the Dirichlet boundary values.
//
[0.x.7600] 
[0.x.7601] 
//
[0.x.7602] 
[0.x.7603] 
[0.x.7604] 
[0.x.7605] 
[0.x.7606] 
[0.x.7607] 
[0.x.7608] 
[0.x.7609] 
//
[0.x.7610] 
//
// In analogy to  [2.x.1049] , we count the dofs in the individual components. We could do this in the same way as there, but we want to operate on the block structure we used already for the renumbering: The function  [2.x.1050]  does the same as  [2.x.1051] , but now grouped as velocity and pressure block via  [2.x.1052] .
//
[0.x.7611] 
[0.x.7612] 
[0.x.7613] 
[0.x.7614] 
//
[0.x.7615] 
[0.x.7616] 
[0.x.7617] 
[0.x.7618] 
//
// The next task is to allocate a sparsity pattern for the system matrix we will create and one for the preconditioner matrix. We could do this in the same way as in  [2.x.1053] , i.e. directly build an object of type SparsityPattern through  [2.x.1054]  However, there is a major reason not to do so: In 3D, the function  [2.x.1055]  yields a conservative but rather large number for the coupling between the individual dofs, so that the memory initially provided for the creation of the sparsity pattern of the matrix is far too much -- so much actually that the initial sparsity pattern won't even fit into the physical memory of most systems already for moderately-sized 3D problems, see also the discussion in  [2.x.1056] . Instead, we first build temporary objects that use a different data structure that doesn't require allocating more memory than necessary but isn't suitable for use as a basis of SparseMatrix or BlockSparseMatrix objects; in a second step we then copy these objects into objects of type BlockSparsityPattern. This is entirely analogous to what we already did in  [2.x.1057]  and  [2.x.1058] . In particular, we make use of the fact that we will never write into the  [2.x.1059]  block of the system matrix and that this is the only block to be filled for the preconditioner matrix.
//
// All this is done inside new scopes, which means that the memory of  [2.x.1060]  will be released once the information has been copied to  [2.x.1061] .
//
[0.x.7619] 
[0.x.7620] 
//
[0.x.7621] 
[0.x.7622] 
[0.x.7623] 
[0.x.7624] 
//
[0.x.7625] 
//
[0.x.7626] 
//
[0.x.7627] 
[0.x.7628] 
[0.x.7629] 
[0.x.7630] 
[0.x.7631] 
[0.x.7632] 
//
[0.x.7633] 
[0.x.7634] 
//
[0.x.7635] 
[0.x.7636] 
//
[0.x.7637] 
[0.x.7638] 
//
[0.x.7639] 
[0.x.7640] 
[0.x.7641] 
[0.x.7642] 
//
[0.x.7643] 
//
[0.x.7644] 
//
[0.x.7645] 
[0.x.7646] 
[0.x.7647] 
[0.x.7648] 
[0.x.7649] 
[0.x.7650] 
//
[0.x.7651] 
[0.x.7652] 
[0.x.7653] 
[0.x.7654] 
[0.x.7655] 
//
[0.x.7656] 
[0.x.7657] 
//
// Finally, the system matrix, the preconsitioner matrix, the solution and the right hand side vector are created from the block structure similar to the approach in  [2.x.1062] :
//
[0.x.7658] 
[0.x.7659] 
//
[0.x.7660] 
[0.x.7661] 
[0.x.7662] 
[0.x.7663] 
//
[0.x.7664] 
[0.x.7665] 
[0.x.7666] 
[0.x.7667] 
[0.x.7668] 
//[2.x.1063] 
//
// The assembly process follows the discussion in  [2.x.1064]  and in the introduction. We use the well-known abbreviations for the data structures that hold the local matrices, right hand side, and global numbering of the degrees of freedom for the present cell.
//
[0.x.7669] 
[0.x.7670] 
[0.x.7671] 
[0.x.7672] 
[0.x.7673] 
[0.x.7674] 
//
[0.x.7675] 
//
[0.x.7676] 
[0.x.7677] 
[0.x.7678] 
[0.x.7679] 
//
[0.x.7680] 
//
[0.x.7681] 
//
[0.x.7682] 
[0.x.7683] 
[0.x.7684] 
[0.x.7685] 
//
[0.x.7686] 
//
[0.x.7687] 
[0.x.7688] 
//
// Next, we need two objects that work as extractors for the FEValues object. Their use is explained in detail in the report on  [2.x.1065]  vector_valued :
//
[0.x.7689] 
[0.x.7690] 
//
// As an extension over  [2.x.1066]  and  [2.x.1067] , we include a few optimizations that make assembly much faster for this particular problem. The improvements are based on the observation that we do a few calculations too many times when we do as in  [2.x.1068] : The symmetric gradient actually has  [2.x.1069]  different values per quadrature point, but we extract it  [2.x.1070]  times from the FEValues object
//
// - for both the loop over  [2.x.1071]  and the inner loop over  [2.x.1072] . In 3d, that means evaluating it  [2.x.1073]  instead of  [2.x.1074]  times, a not insignificant difference.
//
// So what we're going to do here is to avoid such repeated calculations by getting a vector of rank-2 tensors (and similarly for the divergence and the basis function value on pressure) at the quadrature point prior to starting the loop over the dofs on the cell. First, we create the respective objects that will hold these values. Then, we start the loop over all cells and the loop over the quadrature points, where we first extract these values. There is one more optimization we implement here: the local matrix (as well as the global one) is going to be symmetric, since all the operations involved are symmetric with respect to  [2.x.1075]  and  [2.x.1076] . This is implemented by simply running the inner loop not to  [2.x.1077] , the index of the outer loop.
//
[0.x.7691] 
[0.x.7692] 
[0.x.7693] 
//
[0.x.7694] 
[0.x.7695] 
[0.x.7696] 
[0.x.7697] 
[0.x.7698] 
[0.x.7699] 
//
[0.x.7700] 
[0.x.7701] 
//
[0.x.7702] 
[0.x.7703] 
[0.x.7704] 
[0.x.7705] 
[0.x.7706] 
[0.x.7707] 
[0.x.7708] 
[0.x.7709] 
[0.x.7710] 
//
//   Now finally for the bilinear forms of both the system matrix and   the matrix we use for the preconditioner. Recall that the   formulas for these two are   [1.x.33]   and   [1.x.34]   respectively, where  [2.x.1078]  and  [2.x.1079]    are the velocity and pressure components of the  [2.x.1080] th shape   function. The various terms above are then easily recognized in   the following implementation:
//
[0.x.7711] 
[0.x.7712] 
[0.x.7713] 
[0.x.7714] 
[0.x.7715] 
[0.x.7716] 
[0.x.7717] 
[0.x.7718] 
[0.x.7719] 
//
[0.x.7720] 
[0.x.7721] 
[0.x.7722] 
[0.x.7723] 
//
//       Note that in the implementation of (1) above, `operator*`       is overloaded for symmetric tensors, yielding the scalar       product between the two tensors.             For the right-hand side we use the fact that the shape       functions are only non-zero in one component (because our       elements are primitive).  Instead of multiplying the tensor       representing the dim+1 values of shape function i with the       whole right-hand side vector, we only look at the only       non-zero component. The function        [2.x.1081]  will return       which component this shape function lives in (0=x velocity,       1=y velocity, 2=pressure in 2d), which we use to pick out       the correct component of the right-hand side vector to       multiply with.
//
[0.x.7724] 
[0.x.7725] 
[0.x.7726] 
[0.x.7727] 
[0.x.7728] 
[0.x.7729] 
[0.x.7730] 
//
// Before we can write the local data into the global matrix (and simultaneously use the AffineConstraints object to apply Dirichlet boundary conditions and eliminate hanging node constraints, as we discussed in the introduction), we have to be careful about one thing, though. We have only built half of the local matrices because of symmetry, but we're going to save the full matrices in order to use the standard functions for solving. This is done by flipping the indices in case we are pointing into the empty part of the local matrices.
//
[0.x.7731] 
[0.x.7732] 
[0.x.7733] 
[0.x.7734] 
[0.x.7735] 
[0.x.7736] 
[0.x.7737] 
//
[0.x.7738] 
[0.x.7739] 
[0.x.7740] 
[0.x.7741] 
[0.x.7742] 
[0.x.7743] 
[0.x.7744] 
[0.x.7745] 
[0.x.7746] 
[0.x.7747] 
//
// Before we're going to solve this linear system, we generate a preconditioner for the velocity-velocity matrix, i.e.,  [2.x.1082]  in the system matrix. As mentioned above, this depends on the spatial dimension. Since the two classes described by the  [2.x.1083]  alias have the same interface, we do not have to do anything different whether we want to use a sparse direct solver or an ILU:
//
[0.x.7748] 
//
[0.x.7749] 
[0.x.7750] 
[0.x.7751] 
[0.x.7752] 
[0.x.7753] 
[0.x.7754] 
//
//  [2.x.1084] 
//
// After the discussion in the introduction and the definition of the respective classes above, the implementation of the  [2.x.1085]  function is rather straight-forward and done in a similar way as in  [2.x.1086] . To start with, we need an object of the  [2.x.1087]  class that represents the inverse of the matrix A. As described in the introduction, the inverse is generated with the help of an inner preconditioner of type  [2.x.1088] .
//
[0.x.7755] 
[0.x.7756] 
[0.x.7757] 
[0.x.7758] 
[0.x.7759] 
[0.x.7760] 
[0.x.7761] 
//
// This is as in  [2.x.1089] . We generate the right hand side  [2.x.1090]  for the Schur complement and an object that represents the respective linear operation  [2.x.1091] , now with a template parameter indicating the preconditioner
//
// - in accordance with the definition of the class.
//
[0.x.7762] 
[0.x.7763] 
[0.x.7764] 
[0.x.7765] 
[0.x.7766] 
//
[0.x.7767] 
[0.x.7768] 
//
// The usual control structures for the solver call are created...
//
[0.x.7769] 
[0.x.7770] 
[0.x.7771] 
//
// Now to the preconditioner to the Schur complement. As explained in the introduction, the preconditioning is done by a mass matrix in the pressure variable.
//
// Actually, the solver needs to have the preconditioner in the form  [2.x.1092] , so we need to create an inverse operation. Once again, we use an object of the class  [2.x.1093] , which implements the  [2.x.1094]  operation that is needed by the solver.  In this case, we have to invert the pressure mass matrix. As it already turned out in earlier tutorial programs, the inversion of a mass matrix is a rather cheap and straight-forward operation (compared to, e.g., a Laplace matrix). The CG method with ILU preconditioning converges in 5-10 steps, independently on the mesh size.  This is precisely what we do here: We choose another ILU preconditioner and take it along to the InverseMatrix object via the corresponding template parameter.  A CG solver is then called within the vmult operation of the inverse matrix.
//
// An alternative that is cheaper to build, but needs more iterations afterwards, would be to choose a SSOR preconditioner with factor 1.2. It needs about twice the number of iterations, but the costs for its generation are almost negligible.
//
[0.x.7772] 
[0.x.7773] 
[0.x.7774] 
//
[0.x.7775] 
[0.x.7776] 
//
// With the Schur complement and an efficient preconditioner at hand, we can solve the respective equation for the pressure (i.e. block 0 in the solution vector) in the usual way:
//
[0.x.7777] 
//
// After this first solution step, the hanging node constraints have to be distributed to the solution in order to achieve a consistent pressure field.
//
[0.x.7778] 
//
[0.x.7779] 
[0.x.7780] 
[0.x.7781] 
[0.x.7782] 
//
// As in  [2.x.1095] , we finally need to solve for the velocity equation where we plug in the solution to the pressure equation. This involves only objects we already know
//
// - so we simply multiply  [2.x.1096]  by  [2.x.1097] , subtract the right hand side and multiply by the inverse of  [2.x.1098] . At the end, we need to distribute the constraints from hanging nodes in order to obtain a consistent flow field:
//
[0.x.7783] 
[0.x.7784] 
[0.x.7785] 
[0.x.7786] 
//
[0.x.7787] 
//
[0.x.7788] 
[0.x.7789] 
[0.x.7790] 
//[2.x.1099] 
//
// The next function generates graphical output. In this example, we are going to use the VTK file format.  We attach names to the individual variables in the problem:  [2.x.1100]  components of velocity and  [2.x.1101]  to the pressure.
//
// Not all visualization programs have the ability to group individual vector components into a vector to provide vector plots; in particular, this holds for some VTK-based visualization programs. In this case, the logical grouping of components into vectors should already be described in the file containing the data. In other words, what we need to do is provide our output writers with a way to know which of the components of the finite element logically form a vector (with  [2.x.1102]  components in  [2.x.1103]  space dimensions) rather than letting them assume that we simply have a bunch of scalar fields.  This is achieved using the members of the  [2.x.1104]  namespace: as with the filename, we create a vector in which the first  [2.x.1105]  components refer to the velocities and are given the tag  [2.x.1106]  we finally push one tag  [2.x.1107]  to describe the grouping of the pressure variable.
//
// The rest of the function is then the same as in  [2.x.1108] .
//
[0.x.7791] 
[0.x.7792] 
[0.x.7793] 
[0.x.7794] 
[0.x.7795] 
[0.x.7796] 
//
[0.x.7797] 
[0.x.7798] 
[0.x.7799] 
[0.x.7800] 
[0.x.7801] 
//
[0.x.7802] 
[0.x.7803] 
[0.x.7804] 
[0.x.7805] 
[0.x.7806] 
[0.x.7807] 
[0.x.7808] 
//
[0.x.7809] 
[0.x.7810] 
[0.x.7811] 
[0.x.7812] 
//[2.x.1109] 
//
// This is the last interesting function of the  [2.x.1110]  class.  As indicated by its name, it takes the solution to the problem and refines the mesh where this is needed. The procedure is the same as in the respective step in  [2.x.1111] , with the exception that we base the refinement only on the change in pressure, i.e., we call the Kelly error estimator with a mask object of type ComponentMask that selects the single scalar component for the pressure that we are interested in (we get such a mask from the finite element class by specifying the component we want). Additionally, we do not coarsen the grid again:
//
[0.x.7813] 
[0.x.7814] 
[0.x.7815] 
[0.x.7816] 
//
[0.x.7817] 
[0.x.7818] 
[0.x.7819] 
[0.x.7820] 
[0.x.7821] 
[0.x.7822] 
[0.x.7823] 
[0.x.7824] 
//
[0.x.7825] 
[0.x.7826] 
[0.x.7827] 
[0.x.7828] 
[0.x.7829] 
[0.x.7830] 
//[2.x.1112] 
//
// The last step in the Stokes class is, as usual, the function that generates the initial grid and calls the other functions in the respective order.
//
// We start off with a rectangle of size  [2.x.1113]  (in 2d) or  [2.x.1114]  (in 3d), placed in  [2.x.1115]  as  [2.x.1116]  or  [2.x.1117] , respectively. It is natural to start with equal mesh size in each direction, so we subdivide the initial rectangle four times in the first coordinate direction. To limit the scope of the variables involved in the creation of the mesh to the range where we actually need them, we put the entire block between a pair of braces:
//
[0.x.7831] 
[0.x.7832] 
[0.x.7833] 
[0.x.7834] 
[0.x.7835] 
[0.x.7836] 
//
[0.x.7837] 
[0.x.7838] 
[0.x.7839] 
//
[0.x.7840] 
[0.x.7841] 
[0.x.7842] 
//
[0.x.7843] 
[0.x.7844] 
[0.x.7845] 
[0.x.7846] 
[0.x.7847] 
//
// A boundary indicator of 1 is set to all boundaries that are subject to Dirichlet boundary conditions, i.e.  to faces that are located at 0 in the last coordinate direction. See the example description above for details.
//
[0.x.7848] 
[0.x.7849] 
[0.x.7850] 
[0.x.7851] 
//
// We then apply an initial refinement before solving for the first time. In 3D, there are going to be more degrees of freedom, so we refine less there:
//
[0.x.7852] 
//
// As first seen in  [2.x.1118] , we cycle over the different refinement levels and refine (except for the first cycle), setup the degrees of freedom and matrices, assemble, solve and create output:
//
[0.x.7853] 
[0.x.7854] 
[0.x.7855] 
[0.x.7856] 
//
[0.x.7857] 
[0.x.7858] 
//
[0.x.7859] 
//
[0.x.7860] 
[0.x.7861] 
//
[0.x.7862] 
[0.x.7863] 
//
[0.x.7864] 
//
[0.x.7865] 
[0.x.7866] 
[0.x.7867] 
[0.x.7868] 
//[2.x.1119] 
//
// The main function is the same as in  [2.x.1120] . We pass the element degree as a parameter and choose the space dimension at the well-known template slot.
//
[0.x.7869] 
[0.x.7870] 
[0.x.7871] 
[0.x.7872] 
[0.x.7873] 
//
[0.x.7874] 
[0.x.7875] 
[0.x.7876] 
[0.x.7877] 
[0.x.7878] 
[0.x.7879] 
[0.x.7880] 
[0.x.7881] 
[0.x.7882] 
[0.x.7883] 
[0.x.7884] 
[0.x.7885] 
[0.x.7886] 
[0.x.7887] 
//
[0.x.7888] 
[0.x.7889] 
[0.x.7890] 
[0.x.7891] 
[0.x.7892] 
[0.x.7893] 
[0.x.7894] 
[0.x.7895] 
[0.x.7896] 
[0.x.7897] 
[0.x.7898] 
[0.x.7899] 
[0.x.7900] 
[0.x.7901] 
//
[0.x.7902] 
[0.x.7903] 
[0.x.7904] 
[0.x.7905] 
[0.x.7906] 
[0.x.7907] 
[0.x.7908] 
[0.x.7909] 
[0.x.7910] 
[0.x.7911] 
[0.x.7912] 
[0.x.7913] 
[0.x.7914] 
[0.x.7915] 
[0.x.7916] 
[0.x.7917] 
//
[0.x.7918] 
[0.x.7919] 
[0.x.7920] 
//[2.x.1121] 
//
// We start with the usual assortment of include files that we've seen in so many of the previous tests:
//
[0.x.7921] 
[0.x.7922] 
//
[0.x.7923] 
[0.x.7924] 
[0.x.7925] 
[0.x.7926] 
[0.x.7927] 
[0.x.7928] 
//
[0.x.7929] 
[0.x.7930] 
//
[0.x.7931] 
[0.x.7932] 
//
[0.x.7933] 
//
[0.x.7934] 
//
[0.x.7935] 
[0.x.7936] 
//
// Here are the only three include files of some new interest: The first one is already used, for example, for the  [2.x.1122]  and  [2.x.1123]  functions. However, we here use another function in that class,  [2.x.1124]  to compute our initial values as the  [2.x.1125]  projection of the continuous initial values. Furthermore, we use  [2.x.1126]  to generate the integrals  [2.x.1127] . These were previously always generated by hand in  [2.x.1128]  or similar functions in application code. However, we're too lazy to do that here, so simply use a library function:
//
[0.x.7937] 
//
// In a very similar vein, we are also too lazy to write the code to assemble mass and Laplace matrices, although it would have only taken copying the relevant code from any number of previous tutorial programs. Rather, we want to focus on the things that are truly new to this program and therefore use the  [2.x.1129]  and  [2.x.1130]  functions. They are declared here:
//
[0.x.7938] 
//
// Finally, here is an include file that contains all sorts of tool functions that one sometimes needs. In particular, we need the  [2.x.1131]  class that, given an integer argument, returns a string representation of it. It is particularly useful since it allows for a second parameter indicating the number of digits to which we want the result padded with leading zeros. We will use this to write output files that have the form  [2.x.1132]  denotes the number of the time step and always consists of three digits even if we are still in the single or double digit time steps.
//
[0.x.7939] 
//
// The last step is as in all previous programs:
//
[0.x.7940] 
[0.x.7941] 
[0.x.7942] 
//[2.x.1133] 
//
// Next comes the declaration of the main class. It's public interface of functions is like in most of the other tutorial programs. Worth mentioning is that we now have to store four matrices instead of one: the mass matrix  [2.x.1134] , the Laplace matrix  [2.x.1135] , the matrix  [2.x.1136]  used for solving for  [2.x.1137] , and a copy of the mass matrix with boundary conditions applied used for solving for  [2.x.1138] . Note that it is a bit wasteful to have an additional copy of the mass matrix around. We will discuss strategies for how to avoid this in the section on possible improvements.
//
// Likewise, we need solution vectors for  [2.x.1139]  as well as for the corresponding vectors at the previous time step,  [2.x.1140] . The  [2.x.1141]  will be used for whatever right hand side vector we have when solving one of the two linear systems in each time step. These will be solved in the two functions  [2.x.1142]  and  [2.x.1143] .
//
// Finally, the variable  [2.x.1144]  is used to indicate the parameter  [2.x.1145]  that is used to define which time stepping scheme to use, as explained in the introduction. The rest is self-explanatory.
//
[0.x.7943] 
[0.x.7944] 
[0.x.7945] 
[0.x.7946] 
[0.x.7947] 
[0.x.7948] 
//
[0.x.7949] 
[0.x.7950] 
[0.x.7951] 
[0.x.7952] 
[0.x.7953] 
//
[0.x.7954] 
[0.x.7955] 
[0.x.7956] 
//
[0.x.7957] 
//
[0.x.7958] 
[0.x.7959] 
[0.x.7960] 
[0.x.7961] 
[0.x.7962] 
//
[0.x.7963] 
[0.x.7964] 
[0.x.7965] 
//
[0.x.7966] 
[0.x.7967] 
[0.x.7968] 
[0.x.7969] 
[0.x.7970] 
//
//  [2.x.1146] 
//
// Before we go on filling in the details of the main class, let us define the equation data corresponding to the problem, i.e. initial and boundary values for both the solution  [2.x.1147]  and its time derivative  [2.x.1148] , as well as a right hand side class. We do so using classes derived from the Function class template that has been used many times before, so the following should not be a surprise.
//
// Let's start with initial values and choose zero for both the value  [2.x.1149]  as well as its time derivative, the velocity  [2.x.1150] :
//
[0.x.7971] 
[0.x.7972] 
[0.x.7973] 
[0.x.7974] 
[0.x.7975] 
[0.x.7976] 
[0.x.7977] 
[0.x.7978] 
[0.x.7979] 
[0.x.7980] 
[0.x.7981] 
[0.x.7982] 
//
[0.x.7983] 
[0.x.7984] 
[0.x.7985] 
[0.x.7986] 
[0.x.7987] 
[0.x.7988] 
[0.x.7989] 
[0.x.7990] 
[0.x.7991] 
[0.x.7992] 
[0.x.7993] 
[0.x.7994] 
//
// Secondly, we have the right hand side forcing term. Boring as we are, we choose zero here as well:
//
[0.x.7995] 
[0.x.7996] 
[0.x.7997] 
[0.x.7998] 
[0.x.7999] 
[0.x.8000] 
[0.x.8001] 
[0.x.8002] 
[0.x.8003] 
[0.x.8004] 
[0.x.8005] 
[0.x.8006] 
//
// Finally, we have boundary values for  [2.x.1151]  and  [2.x.1152] . They are as described in the introduction, one being the time derivative of the other:
//
[0.x.8007] 
[0.x.8008] 
[0.x.8009] 
[0.x.8010] 
[0.x.8011] 
[0.x.8012] 
[0.x.8013] 
[0.x.8014] 
[0.x.8015] 
//
[0.x.8016] 
[0.x.8017] 
[0.x.8018] 
[0.x.8019] 
[0.x.8020] 
[0.x.8021] 
[0.x.8022] 
//
[0.x.8023] 
[0.x.8024] 
[0.x.8025] 
[0.x.8026] 
[0.x.8027] 
[0.x.8028] 
[0.x.8029] 
[0.x.8030] 
[0.x.8031] 
//
[0.x.8032] 
[0.x.8033] 
[0.x.8034] 
[0.x.8035] 
[0.x.8036] 
[0.x.8037] 
[0.x.8038] 
//
//  [2.x.1153] 
//
// The implementation of the actual logic is actually fairly short, since we relegate things like assembling the matrices and right hand side vectors to the library. The rest boils down to not much more than 130 lines of actual code, a significant fraction of which is boilerplate code that can be taken from previous example programs (e.g. the functions that solve linear systems, or that generate output).
//
// Let's start with the constructor (for an explanation of the choice of time step, see the section on Courant, Friedrichs, and Lewy in the introduction):
//
[0.x.8039] 
[0.x.8040] 
[0.x.8041] 
[0.x.8042] 
[0.x.8043] 
[0.x.8044] 
[0.x.8045] 
[0.x.8046] 
[0.x.8047] 
//[2.x.1154] 
//
// The next function is the one that sets up the mesh, DoFHandler, and matrices and vectors at the beginning of the program, i.e. before the first time step. The first few lines are pretty much standard if you've read through the tutorial programs at least up to  [2.x.1155] :
//
[0.x.8048] 
[0.x.8049] 
[0.x.8050] 
[0.x.8051] 
[0.x.8052] 
//
[0.x.8053] 
[0.x.8054] 
//
[0.x.8055] 
//
[0.x.8056] 
[0.x.8057] 
[0.x.8058] 
//
[0.x.8059] 
[0.x.8060] 
[0.x.8061] 
//
// Then comes a block where we have to initialize the 3 matrices we need in the course of the program: the mass matrix, the Laplace matrix, and the matrix  [2.x.1156]  used when solving for  [2.x.1157]  in each time step.
//
// When setting up these matrices, note that they all make use of the same sparsity pattern object. Finally, the reason why matrices and sparsity patterns are separate objects in deal.II (unlike in many other finite element or linear algebra classes) becomes clear: in a significant fraction of applications, one has to hold several matrices that happen to have the same sparsity pattern, and there is no reason for them not to share this information, rather than re-building and wasting memory on it several times.
//
// After initializing all of these matrices, we call library functions that build the Laplace and mass matrices. All they need is a DoFHandler object and a quadrature formula object that is to be used for numerical integration. Note that in many respects these functions are better than what we would usually do in application programs, for example because they automatically parallelize building the matrices if multiple processors are available in a machine: for more information see the documentation of WorkStream or the  [2.x.1158]  "Parallel computing with multiple processors" module. The matrices for solving linear systems will be filled in the run() method because we need to re-apply boundary conditions every time step.
//
[0.x.8062] 
[0.x.8063] 
[0.x.8064] 
[0.x.8065] 
//
[0.x.8066] 
[0.x.8067] 
[0.x.8068] 
[0.x.8069] 
[0.x.8070] 
[0.x.8071] 
//
// The rest of the function is spent on setting vector sizes to the correct value. The final line closes the hanging node constraints object. Since we work on a uniformly refined mesh, no constraints exist or have been computed (i.e. there was no need to call  [2.x.1159]  as in other programs), but we need a constraints object in one place further down below anyway.
//
[0.x.8072] 
[0.x.8073] 
[0.x.8074] 
[0.x.8075] 
[0.x.8076] 
//
[0.x.8077] 
[0.x.8078] 
//
//  [2.x.1160] 
//
// The next two functions deal with solving the linear systems associated with the equations for  [2.x.1161]  and  [2.x.1162] . Both are not particularly interesting as they pretty much follow the scheme used in all the previous tutorial programs.
//
// One can make little experiments with preconditioners for the two matrices we have to invert. As it turns out, however, for the matrices at hand here, using Jacobi or SSOR preconditioners reduces the number of iterations necessary to solve the linear system slightly, but due to the cost of applying the preconditioner it is no win in terms of run-time. It is not much of a loss either, but let's keep it simple and just do without:
//
[0.x.8079] 
[0.x.8080] 
[0.x.8081] 
[0.x.8082] 
[0.x.8083] 
//
[0.x.8084] 
//
[0.x.8085] 
[0.x.8086] 
[0.x.8087] 
//
[0.x.8088] 
[0.x.8089] 
[0.x.8090] 
[0.x.8091] 
[0.x.8092] 
//
[0.x.8093] 
//
[0.x.8094] 
[0.x.8095] 
[0.x.8096] 
//
//  [2.x.1163] 
//
// Likewise, the following function is pretty much what we've done before. The only thing worth mentioning is how here we generate a string representation of the time step number padded with leading zeros to 3 character length using the  [2.x.1164]  function's second argument.
//
[0.x.8097] 
[0.x.8098] 
[0.x.8099] 
[0.x.8100] 
//
[0.x.8101] 
[0.x.8102] 
[0.x.8103] 
//
[0.x.8104] 
//
[0.x.8105] 
[0.x.8106] 
//
// Like  [2.x.1165] , since we write output at every time step (and the system we have to solve is relatively easy), we instruct DataOut to use the zlib compression algorithm that is optimized for speed instead of disk usage since otherwise plotting the output becomes a bottleneck:
//
[0.x.8107] 
[0.x.8108] 
[0.x.8109] 
[0.x.8110] 
[0.x.8111] 
[0.x.8112] 
[0.x.8113] 
//
//  [2.x.1166] 
//
// The following is really the only interesting function of the program. It contains the loop over all time steps, but before we get to that we have to set up the grid, DoFHandler, and matrices. In addition, we have to somehow get started with initial values. To this end, we use the  [2.x.1167]  function that takes an object that describes a continuous function and computes the  [2.x.1168]  projection of this function onto the finite element space described by the DoFHandler object. Can't be any simpler than that:
//
[0.x.8114] 
[0.x.8115] 
[0.x.8116] 
[0.x.8117] 
//
[0.x.8118] 
[0.x.8119] 
[0.x.8120] 
[0.x.8121] 
[0.x.8122] 
[0.x.8123] 
[0.x.8124] 
[0.x.8125] 
[0.x.8126] 
[0.x.8127] 
//
// The next thing is to loop over all the time steps until we reach the end time ( [2.x.1169]  in this case). In each time step, we first have to solve for  [2.x.1170] , using the equation  [2.x.1171] 
//[2.x.1172] 
//[2.x.1173] . Note that we use the same mesh for all time steps, so that  [2.x.1174]  and  [2.x.1175] . What we therefore have to do first is to add up  [2.x.1176]  and the forcing terms, and put the result into the  [2.x.1177]  vector. (For these additions, we need a temporary vector that we declare before the loop to avoid repeated memory allocations in each time step.)
//
// The one thing to realize here is how we communicate the time variable to the object describing the right hand side: each object derived from the Function class has a time field that can be set using the  [2.x.1178]  and read by  [2.x.1179]  In essence, using this mechanism, all functions of space and time are therefore considered functions of space evaluated at a particular time. This matches well what we typically need in finite element programs, where we almost always work on a single time step at a time, and where it never happens that, for example, one would like to evaluate a space-time function for all times at any given spatial location.
//
[0.x.8128] 
[0.x.8129] 
//
[0.x.8130] 
[0.x.8131] 
[0.x.8132] 
[0.x.8133] 
//
[0.x.8134] 
//
[0.x.8135] 
[0.x.8136] 
//
[0.x.8137] 
[0.x.8138] 
//
[0.x.8139] 
[0.x.8140] 
[0.x.8141] 
[0.x.8142] 
[0.x.8143] 
[0.x.8144] 
[0.x.8145] 
[0.x.8146] 
//
[0.x.8147] 
[0.x.8148] 
[0.x.8149] 
[0.x.8150] 
[0.x.8151] 
//
[0.x.8152] 
//
[0.x.8153] 
//
// After so constructing the right hand side vector of the first equation, all we have to do is apply the correct boundary values. As for the right hand side, this is a space-time function evaluated at a particular time, which we interpolate at boundary nodes and then use the result to apply boundary values as we usually do. The result is then handed off to the solve_u() function:
//
[0.x.8154] 
[0.x.8155] 
[0.x.8156] 
//
[0.x.8157] 
[0.x.8158] 
[0.x.8159] 
[0.x.8160] 
[0.x.8161] 
//
// The matrix for solve_u() is the same in every time steps, so one could think that it is enough to do this only once at the beginning of the simulation. However, since we need to apply boundary values to the linear system (which eliminate some matrix rows and columns and give contributions to the right hand side), we have to refill the matrix in every time steps before we actually apply boundary data. The actual content is very simple: it is the sum of the mass matrix and a weighted Laplace matrix:
//
[0.x.8162] 
[0.x.8163] 
[0.x.8164] 
[0.x.8165] 
[0.x.8166] 
[0.x.8167] 
[0.x.8168] 
[0.x.8169] 
//
// The second step, i.e. solving for  [2.x.1180] , works similarly, except that this time the matrix on the left is the mass matrix (which we copy again in order to be able to apply boundary conditions, and the right hand side is  [2.x.1181]  plus forcing terms. Boundary values are applied in the same way as before, except that now we have to use the BoundaryValuesV class:
//
[0.x.8170] 
[0.x.8171] 
//
[0.x.8172] 
[0.x.8173] 
//
[0.x.8174] 
[0.x.8175] 
//
[0.x.8176] 
//
[0.x.8177] 
[0.x.8178] 
[0.x.8179] 
//
[0.x.8180] 
[0.x.8181] 
[0.x.8182] 
[0.x.8183] 
[0.x.8184] 
[0.x.8185] 
[0.x.8186] 
[0.x.8187] 
[0.x.8188] 
[0.x.8189] 
[0.x.8190] 
[0.x.8191] 
//
// Finally, after both solution components have been computed, we output the result, compute the energy in the solution, and go on to the next time step after shifting the present solution into the vectors that hold the solution at the previous time step. Note the function  [2.x.1182]  that can compute  [2.x.1183]  and  [2.x.1184]  in one step, saving us the expense of a temporary vector and several lines of code:
//
[0.x.8192] 
//
[0.x.8193] 
[0.x.8194] 
[0.x.8195] 
[0.x.8196] 
[0.x.8197] 
//
[0.x.8198] 
[0.x.8199] 
[0.x.8200] 
[0.x.8201] 
[0.x.8202] 
//[2.x.1185] 
//
// What remains is the main function of the program. There is nothing here that hasn't been shown in several of the previous programs:
//
[0.x.8203] 
[0.x.8204] 
[0.x.8205] 
[0.x.8206] 
[0.x.8207] 
//
[0.x.8208] 
[0.x.8209] 
[0.x.8210] 
[0.x.8211] 
[0.x.8212] 
[0.x.8213] 
[0.x.8214] 
[0.x.8215] 
[0.x.8216] 
[0.x.8217] 
[0.x.8218] 
[0.x.8219] 
[0.x.8220] 
[0.x.8221] 
//
[0.x.8222] 
[0.x.8223] 
[0.x.8224] 
[0.x.8225] 
[0.x.8226] 
[0.x.8227] 
[0.x.8228] 
[0.x.8229] 
[0.x.8230] 
[0.x.8231] 
[0.x.8232] 
[0.x.8233] 
[0.x.8234] 
[0.x.8235] 
//
[0.x.8236] 
[0.x.8237] 
[0.x.8238] 
[0.x.8239] 
[0.x.8240] 
[0.x.8241] 
[0.x.8242] 
[0.x.8243] 
[0.x.8244] 
[0.x.8245] 
[0.x.8246] 
[0.x.8247] 
[0.x.8248] 
[0.x.8249] 
[0.x.8250] 
[0.x.8251] 
//
[0.x.8252] 
[0.x.8253] 
[0.x.8254] 
//[2.x.1186] 
//
// The following have all been covered previously:
//
[0.x.8255] 
[0.x.8256] 
[0.x.8257] 
[0.x.8258] 
//
[0.x.8259] 
[0.x.8260] 
[0.x.8261] 
[0.x.8262] 
[0.x.8263] 
[0.x.8264] 
[0.x.8265] 
//
[0.x.8266] 
[0.x.8267] 
//
[0.x.8268] 
[0.x.8269] 
//
[0.x.8270] 
[0.x.8271] 
//
[0.x.8272] 
[0.x.8273] 
[0.x.8274] 
//
[0.x.8275] 
[0.x.8276] 
//
// This is the only new one: We will need a library function defined in the namespace GridTools that computes the minimal cell diameter.
//
[0.x.8277] 
//
// The last step is as in all previous programs:
//
[0.x.8278] 
[0.x.8279] 
[0.x.8280] 
//[2.x.1187] 
//
// The first part of the main class is exactly as in  [2.x.1188]  (except for the name):
//
[0.x.8281] 
[0.x.8282] 
[0.x.8283] 
[0.x.8284] 
[0.x.8285] 
[0.x.8286] 
//
[0.x.8287] 
[0.x.8288] 
[0.x.8289] 
[0.x.8290] 
[0.x.8291] 
//
[0.x.8292] 
[0.x.8293] 
[0.x.8294] 
//
[0.x.8295] 
//
[0.x.8296] 
[0.x.8297] 
[0.x.8298] 
[0.x.8299] 
//
[0.x.8300] 
[0.x.8301] 
[0.x.8302] 
//
[0.x.8303] 
[0.x.8304] 
[0.x.8305] 
//
//  Here's what's new: first, we need that boundary mass matrix  [2.x.1189]  that  came out of the absorbing boundary condition. Likewise, since this  time we consider a realistic medium, we must have a measure of the  wave speed  [2.x.1190]  that will enter all the formulas with the Laplace  matrix (which we still define as  [2.x.1191] ):
//
[0.x.8306] 
[0.x.8307] 
//
// The last thing we have to take care of is that we wanted to evaluate the solution at a certain number of detector locations. We need an array to hold these locations, declared here and filled in the constructor:
//
[0.x.8308] 
[0.x.8309] 
//[2.x.1192] 
//
// As usual, we have to define our initial values, boundary conditions, and right hand side functions. Things are a bit simpler this time: we consider a problem that is driven by initial conditions, so there is no right hand side function (though you could look up in  [2.x.1193]  to see how this can be done). Secondly, there are no boundary conditions: the entire boundary of the domain consists of absorbing boundary conditions. That only leaves initial conditions, and there things are simple too since for this particular application only nonzero initial conditions for the pressure are prescribed, not for the velocity (which is zero at the initial time).
//
// So this is all we need: a class that specifies initial conditions for the pressure. In the physical setting considered in this program, these are small absorbers, which we model as a series of little circles where we assume that the pressure surplus is one, whereas no absorption and therefore no pressure surplus is everywhere else. This is how we do things (note that if we wanted to expand this program to not only compile but also to run, we would have to initialize the sources with three-dimensional source locations):
//
[0.x.8310] 
[0.x.8311] 
[0.x.8312] 
[0.x.8313] 
[0.x.8314] 
[0.x.8315] 
[0.x.8316] 
[0.x.8317] 
[0.x.8318] 
[0.x.8319] 
[0.x.8320] 
[0.x.8321] 
[0.x.8322] 
//
[0.x.8323] 
[0.x.8324] 
[0.x.8325] 
//
[0.x.8326] 
[0.x.8327] 
//
[0.x.8328] 
[0.x.8329] 
[0.x.8330] 
[0.x.8331] 
[0.x.8332] 
[0.x.8333] 
[0.x.8334] 
//
[0.x.8335] 
[0.x.8336] 
[0.x.8337] 
[0.x.8338] 
//[2.x.1194] 
//
// Let's start again with the constructor. Setting the member variables is straightforward. We use the acoustic wave speed of mineral oil (in millimeters per microsecond, a common unit in experimental biomedical imaging) since this is where many of the experiments we want to compare the output with are made in. The Crank-Nicolson scheme is used again, i.e. theta is set to 0.5. The time step is later selected to satisfy  [2.x.1195] : here we initialize it to an invalid number.
//
[0.x.8339] 
[0.x.8340] 
[0.x.8341] 
[0.x.8342] 
[0.x.8343] 
[0.x.8344] 
[0.x.8345] 
[0.x.8346] 
[0.x.8347] 
[0.x.8348] 
//
// The second task in the constructor is to initialize the array that holds the detector locations. The results of this program were compared with experiments in which the step size of the detector spacing is 2.25 degree, corresponding to 160 detector locations. The radius of the scanning circle is selected to be half way between the center and the boundary to avoid that the remaining reflections from the imperfect boundary condition spoils our numerical results.
//
// The locations of the detectors are then calculated in clockwise order. Note that the following of course only works if we are computing in 2d, a condition that we guard with an assertion. If we later wanted to run the same program in 3d, we would have to add code here for the initialization of detector locations in 3d. Due to the assertion, there is no way we can forget to do this.
//
[0.x.8349] 
//
[0.x.8350] 
[0.x.8351] 
//
[0.x.8352] 
[0.x.8353] 
[0.x.8354] 
[0.x.8355] 
[0.x.8356] 
[0.x.8357] 
//
//  [2.x.1196] 
//
// The following system is pretty much what we've already done in  [2.x.1197] , but with two important differences. First, we have to create a circular (or spherical) mesh around the origin, with a radius of 1. This nothing new: we've done so before in  [2.x.1198]  and  [2.x.1199] , where we also explain how the PolarManifold or SphericalManifold object places new points on concentric circles when a cell is refined, which we will use here as well.
//
// One thing we had to make sure is that the time step satisfies the CFL condition discussed in the introduction of  [2.x.1200] . Back in that program, we ensured this by hand by setting a timestep that matches the mesh width, but that was error prone because if we refined the mesh once more we would also have to make sure the time step is changed. Here, we do that automatically: we ask a library function for the minimal diameter of any cell. Then we set  [2.x.1201] . The only problem is: what exactly is  [2.x.1202] ? The point is that there is really no good theory on this question for the wave equation. It is known that for uniformly refined meshes consisting of rectangles,  [2.x.1203]  is the minimal edge length. But for meshes on general quadrilaterals, the exact relationship appears to be unknown, i.e. it is unknown what properties of cells are relevant for the CFL condition. The problem is that the CFL condition follows from knowledge of the smallest eigenvalue of the Laplace matrix, and that can only be computed analytically for simply structured meshes.
//
// The upshot of all this is that we're not quite sure what exactly we should take for  [2.x.1204] . The function  [2.x.1205]  computes the minimal diameter of all cells. If the cells were all squares or cubes, then the minimal edge length would be the minimal diameter divided by  [2.x.1206] . We simply generalize this, without theoretical justification, to the case of non-uniform meshes.
//
// The only other significant change is that we need to build the boundary mass matrix. We will comment on this further down below.
//
[0.x.8358] 
[0.x.8359] 
[0.x.8360] 
[0.x.8361] 
[0.x.8362] 
[0.x.8363] 
//
[0.x.8364] 
[0.x.8365] 
//
[0.x.8366] 
[0.x.8367] 
//
[0.x.8368] 
//
[0.x.8369] 
[0.x.8370] 
[0.x.8371] 
//
[0.x.8372] 
[0.x.8373] 
[0.x.8374] 
//
[0.x.8375] 
[0.x.8376] 
[0.x.8377] 
//
[0.x.8378] 
[0.x.8379] 
[0.x.8380] 
[0.x.8381] 
[0.x.8382] 
[0.x.8383] 
//
// The second difference, as mentioned, to  [2.x.1207]  is that we need to build the boundary mass matrix that grew out of the absorbing boundary conditions.
//
// A first observation would be that this matrix is much sparser than the regular mass matrix, since none of the shape functions with purely interior support contribute to this matrix. We could therefore optimize the storage pattern to this situation and build up a second sparsity pattern that only contains the nonzero entries that we need. There is a trade-off to make here: first, we would have to have a second sparsity pattern object, so that costs memory. Secondly, the matrix attached to this sparsity pattern is going to be smaller and therefore requires less memory; it would also be faster to perform matrix-vector multiplications with it. The final argument, however, is the one that tips the scale: we are not primarily interested in performing matrix-vector with the boundary matrix alone (though we need to do that for the right hand side vector once per time step), but mostly wish to add it up to the other matrices used in the first of the two equations since this is the one that is going to be multiplied with once per iteration of the CG method, i.e. significantly more often. It is now the case that the  [2.x.1208]  class allows to add one matrix to another, but only if they use the same sparsity pattern (the reason being that we can't add nonzero entries to a matrix after the sparsity pattern has been created, so we simply require that the two matrices have the same sparsity pattern).
//
// So let's go with that:
//
[0.x.8384] 
//
// The second thing to do is to actually build the matrix. Here, we need to integrate over faces of cells, so first we need a quadrature object that works on  [2.x.1209]  dimensional objects. Secondly, the FEFaceValues variant of FEValues that works on faces, as its name suggest. And finally, the other variables that are part of the assembly machinery. All of this we put between curly braces to limit the scope of these variables to where we actually need them.
//
// The actual act of assembling the matrix is then fairly straightforward: we loop over all cells, over all faces of each of these cells, and then do something only if that particular face is at the boundary of the domain. Like this:
//
[0.x.8385] 
[0.x.8386] 
[0.x.8387] 
[0.x.8388] 
[0.x.8389] 
//
[0.x.8390] 
[0.x.8391] 
//
[0.x.8392] 
//
[0.x.8393] 
//
[0.x.8394] 
[0.x.8395] 
[0.x.8396] 
[0.x.8397] 
[0.x.8398] 
//
[0.x.8399] 
//
[0.x.8400] 
[0.x.8401] 
[0.x.8402] 
[0.x.8403] 
[0.x.8404] 
[0.x.8405] 
//
[0.x.8406] 
[0.x.8407] 
[0.x.8408] 
[0.x.8409] 
[0.x.8410] 
[0.x.8411] 
[0.x.8412] 
[0.x.8413] 
//
[0.x.8414] 
[0.x.8415] 
[0.x.8416] 
[0.x.8417] 
[0.x.8418] 
//
[0.x.8419] 
[0.x.8420] 
[0.x.8421] 
//
[0.x.8422] 
[0.x.8423] 
[0.x.8424] 
//
[0.x.8425] 
[0.x.8426] 
//[2.x.1210] 
//
// The following two functions, solving the linear systems for the pressure and the velocity variable, are taken pretty much verbatim (with the exception of the change of name from  [2.x.1211]  to  [2.x.1212]  of the primary variable) from  [2.x.1213] :
//
[0.x.8427] 
[0.x.8428] 
[0.x.8429] 
[0.x.8430] 
[0.x.8431] 
//
[0.x.8432] 
//
[0.x.8433] 
[0.x.8434] 
[0.x.8435] 
//
[0.x.8436] 
[0.x.8437] 
[0.x.8438] 
[0.x.8439] 
[0.x.8440] 
//
[0.x.8441] 
//
[0.x.8442] 
[0.x.8443] 
[0.x.8444] 
//
//  [2.x.1214] 
//
// The same holds here: the function is from  [2.x.1215] .
//
[0.x.8445] 
[0.x.8446] 
[0.x.8447] 
[0.x.8448] 
//
[0.x.8449] 
[0.x.8450] 
[0.x.8451] 
//
[0.x.8452] 
//
[0.x.8453] 
[0.x.8454] 
[0.x.8455] 
[0.x.8456] 
[0.x.8457] 
[0.x.8458] 
[0.x.8459] 
[0.x.8460] 
//
//  [2.x.1216] 
//
// This function that does most of the work is pretty much again like in  [2.x.1217] , though we make things a bit clearer by using the vectors G1 and G2 mentioned in the introduction. Compared to the overall memory consumption of the program, the introduction of a few temporary vectors isn't doing much harm.
//
// The only changes to this function are: first, that we do not have to project initial values for the velocity  [2.x.1218] , since we know that it is zero. And second that we evaluate the solution at the detector locations computed in the constructor. This is done using the  [2.x.1219]  function. These values are then written to a file that we open at the beginning of the function.
//
[0.x.8461] 
[0.x.8462] 
[0.x.8463] 
[0.x.8464] 
//
[0.x.8465] 
[0.x.8466] 
[0.x.8467] 
[0.x.8468] 
[0.x.8469] 
[0.x.8470] 
//
[0.x.8471] 
//
[0.x.8472] 
[0.x.8473] 
[0.x.8474] 
//
[0.x.8475] 
[0.x.8476] 
[0.x.8477] 
[0.x.8478] 
[0.x.8479] 
[0.x.8480] 
[0.x.8481] 
//
[0.x.8482] 
[0.x.8483] 
[0.x.8484] 
//
[0.x.8485] 
[0.x.8486] 
[0.x.8487] 
//
[0.x.8488] 
[0.x.8489] 
//
[0.x.8490] 
[0.x.8491] 
//
[0.x.8492] 
//
[0.x.8493] 
[0.x.8494] 
[0.x.8495] 
//
[0.x.8496] 
[0.x.8497] 
//
[0.x.8498] 
//
[0.x.8499] 
//
[0.x.8500] 
[0.x.8501] 
[0.x.8502] 
[0.x.8503] 
[0.x.8504] 
[0.x.8505] 
[0.x.8506] 
[0.x.8507] 
//
[0.x.8508] 
[0.x.8509] 
[0.x.8510] 
[0.x.8511] 
[0.x.8512] 
//
//  [2.x.1220] 
//
// What remains is the main function of the program. There is nothing here that hasn't been shown in several of the previous programs:
//
[0.x.8513] 
[0.x.8514] 
[0.x.8515] 
[0.x.8516] 
[0.x.8517] 
//
[0.x.8518] 
[0.x.8519] 
[0.x.8520] 
[0.x.8521] 
[0.x.8522] 
[0.x.8523] 
[0.x.8524] 
[0.x.8525] 
[0.x.8526] 
[0.x.8527] 
[0.x.8528] 
[0.x.8529] 
[0.x.8530] 
[0.x.8531] 
//
[0.x.8532] 
[0.x.8533] 
[0.x.8534] 
[0.x.8535] 
[0.x.8536] 
[0.x.8537] 
[0.x.8538] 
[0.x.8539] 
[0.x.8540] 
[0.x.8541] 
[0.x.8542] 
[0.x.8543] 
[0.x.8544] 
[0.x.8545] 
//
[0.x.8546] 
[0.x.8547] 
[0.x.8548] 
[0.x.8549] 
[0.x.8550] 
[0.x.8551] 
[0.x.8552] 
[0.x.8553] 
[0.x.8554] 
[0.x.8555] 
[0.x.8556] 
[0.x.8557] 
[0.x.8558] 
[0.x.8559] 
[0.x.8560] 
[0.x.8561] 
//
[0.x.8562] 
[0.x.8563] 
[0.x.8564] 
//[2.x.1221] 
//
// For an explanation of the include files, the reader should refer to the example programs  [2.x.1222]  through  [2.x.1223] . They are in the standard order, which is  [2.x.1224]  --  [2.x.1225]  (since each of these categories roughly builds upon previous ones), then a few C++ headers for file input/output and string streams.
//
[0.x.8565] 
[0.x.8566] 
[0.x.8567] 
//
[0.x.8568] 
[0.x.8569] 
[0.x.8570] 
[0.x.8571] 
[0.x.8572] 
[0.x.8573] 
[0.x.8574] 
//
[0.x.8575] 
[0.x.8576] 
//
[0.x.8577] 
[0.x.8578] 
//
[0.x.8579] 
[0.x.8580] 
//
[0.x.8581] 
[0.x.8582] 
[0.x.8583] 
//
[0.x.8584] 
[0.x.8585] 
//
// The last step is as in all previous programs:
//
[0.x.8586] 
[0.x.8587] 
[0.x.8588] 
//[2.x.1226] 
//
// The entire algorithm for solving the problem is encapsulated in this class. As in previous example programs, the class is declared with a template parameter, which is the spatial dimension, so that we can solve the sine-Gordon equation in one, two or three spatial dimensions. For more on the dimension-independent class-encapsulation of the problem, the reader should consult  [2.x.1227]  and  [2.x.1228] .
//
// Compared to  [2.x.1229]  and  [2.x.1230] , there isn't anything newsworthy in the general structure of the program (though there is of course in the inner workings of the various functions!). The most notable difference is the presence of the two new functions  [2.x.1231]  and  [2.x.1232]  that compute the nonlinear contributions to the system matrix and right-hand side of the first equation, as discussed in the Introduction. In addition, we have to have a vector  [2.x.1233]  that contains the nonlinear update to the solution vector in each Newton step.
//
// As also mentioned in the introduction, we do not store the velocity variable in this program, but the mass matrix times the velocity. This is done in the  [2.x.1234]  variable (the "x" is intended to stand for "times").
//
// Finally, the  [2.x.1235]  variable stores the number of time steps to be taken each time before graphical output is to be generated. This is of importance when using fine meshes (and consequently small time steps) where we would run lots of time steps and create lots of output files of solutions that look almost the same in subsequent files. This only clogs up our visualization procedures and we should avoid creating more output than we are really interested in. Therefore, if this variable is set to a value  [2.x.1236]  bigger than one, output is generated only every  [2.x.1237] th time step.
//
[0.x.8589] 
[0.x.8590] 
[0.x.8591] 
[0.x.8592] 
[0.x.8593] 
[0.x.8594] 
//
[0.x.8595] 
[0.x.8596] 
[0.x.8597] 
[0.x.8598] 
[0.x.8599] 
[0.x.8600] 
[0.x.8601] 
[0.x.8602] 
[0.x.8603] 
[0.x.8604] 
[0.x.8605] 
//
[0.x.8606] 
[0.x.8607] 
[0.x.8608] 
//
[0.x.8609] 
[0.x.8610] 
[0.x.8611] 
[0.x.8612] 
//
[0.x.8613] 
//
[0.x.8614] 
[0.x.8615] 
[0.x.8616] 
//
[0.x.8617] 
[0.x.8618] 
[0.x.8619] 
//
[0.x.8620] 
[0.x.8621] 
//[2.x.1238] 
//
// In the following two classes, we first implement the exact solution for 1D, 2D, and 3D mentioned in the introduction to this program. This space-time solution may be of independent interest if one wanted to test the accuracy of the program by comparing the numerical against the analytic solution (note however that the program uses a finite domain, whereas these are analytic solutions for an unbounded domain). This may, for example, be done using the  [2.x.1239]  function. Note, again (as was already discussed in  [2.x.1240] ), how we describe space-time functions as spatial functions that depend on a time variable that can be set and queried using the  [2.x.1241]  and  [2.x.1242]  member functions of the FunctionTime base class of the Function class.
//
[0.x.8622] 
[0.x.8623] 
[0.x.8624] 
[0.x.8625] 
[0.x.8626] 
[0.x.8627] 
[0.x.8628] 
//
[0.x.8629] 
[0.x.8630] 
[0.x.8631] 
[0.x.8632] 
//
[0.x.8633] 
[0.x.8634] 
[0.x.8635] 
[0.x.8636] 
[0.x.8637] 
[0.x.8638] 
[0.x.8639] 
[0.x.8640] 
[0.x.8641] 
[0.x.8642] 
[0.x.8643] 
//
[0.x.8644] 
[0.x.8645] 
[0.x.8646] 
[0.x.8647] 
[0.x.8648] 
[0.x.8649] 
[0.x.8650] 
[0.x.8651] 
[0.x.8652] 
[0.x.8653] 
[0.x.8654] 
//
[0.x.8655] 
[0.x.8656] 
[0.x.8657] 
[0.x.8658] 
[0.x.8659] 
[0.x.8660] 
[0.x.8661] 
[0.x.8662] 
[0.x.8663] 
[0.x.8664] 
[0.x.8665] 
[0.x.8666] 
[0.x.8667] 
//
[0.x.8668] 
[0.x.8669] 
[0.x.8670] 
[0.x.8671] 
[0.x.8672] 
[0.x.8673] 
//
// In the second part of this section, we provide the initial conditions. We are lazy (and cautious) and don't want to implement the same functions as above a second time. Rather, if we are queried for initial conditions, we create an object  [2.x.1243] , set it to the correct time, and let it compute whatever values the exact solution has at that time:
//
[0.x.8674] 
[0.x.8675] 
[0.x.8676] 
[0.x.8677] 
[0.x.8678] 
[0.x.8679] 
[0.x.8680] 
//
[0.x.8681] 
[0.x.8682] 
[0.x.8683] 
[0.x.8684] 
[0.x.8685] 
[0.x.8686] 
//[2.x.1244] 
//
// Let's move on to the implementation of the main class, as it implements the algorithm outlined in the introduction.
//
//  [2.x.1245] 
//
// This is the constructor of the  [2.x.1246]  class. It specifies the desired polynomial degree of the finite elements, associates a  [2.x.1247]  object (just as in the example programs  [2.x.1248]  and  [2.x.1249] ), initializes the current or initial time, the final time, the time step size, and the value of  [2.x.1250]  for the time stepping scheme. Since the solutions we compute here are time-periodic, the actual value of the start-time doesn't matter, and we choose it so that we start at an interesting time.
//
// Note that if we were to chose the explicit Euler time stepping scheme ( [2.x.1251] ), then we must pick a time step  [2.x.1252] , otherwise the scheme is not stable and oscillations might arise in the solution. The Crank-Nicolson scheme ( [2.x.1253] ) and the implicit Euler scheme ( [2.x.1254] ) do not suffer from this deficiency, since they are unconditionally stable. However, even then the time step should be chosen to be on the order of  [2.x.1255]  in order to obtain a good solution. Since we know that our mesh results from the uniform subdivision of a rectangle, we can compute that time step easily; if we had a different domain, the technique in  [2.x.1256]  using  [2.x.1257]  would work as well.
//
[0.x.8687] 
[0.x.8688] 
[0.x.8689] 
[0.x.8690] 
[0.x.8691] 
[0.x.8692] 
[0.x.8693] 
[0.x.8694] 
[0.x.8695] 
[0.x.8696] 
[0.x.8697] 
//[2.x.1258] 
//
// This function creates a rectangular grid in  [2.x.1259]  dimensions and refines it several times. Also, all matrix and vector members of the  [2.x.1260]  class are initialized to their appropriate sizes once the degrees of freedom have been assembled. Like  [2.x.1261] , we use  [2.x.1262]  functions to generate a mass matrix  [2.x.1263]  and a Laplace matrix  [2.x.1264]  and store them in the appropriate variables for the remainder of the program's life.
//
[0.x.8698] 
[0.x.8699] 
[0.x.8700] 
[0.x.8701] 
[0.x.8702] 
//
[0.x.8703] 
[0.x.8704] 
[0.x.8705] 
[0.x.8706] 
//
[0.x.8707] 
//
[0.x.8708] 
[0.x.8709] 
//
[0.x.8710] 
[0.x.8711] 
[0.x.8712] 
//
[0.x.8713] 
[0.x.8714] 
[0.x.8715] 
//
[0.x.8716] 
[0.x.8717] 
[0.x.8718] 
[0.x.8719] 
[0.x.8720] 
[0.x.8721] 
//
[0.x.8722] 
[0.x.8723] 
[0.x.8724] 
[0.x.8725] 
[0.x.8726] 
[0.x.8727] 
//[2.x.1265] 
//
// This function assembles the system matrix and right-hand side vector for each iteration of Newton's method. The reader should refer to the Introduction for the explicit formulas for the system matrix and right-hand side.
//
// Note that during each time step, we have to add up the various contributions to the matrix and right hand sides. In contrast to  [2.x.1266]  and  [2.x.1267] , this requires assembling a few more terms, since they depend on the solution of the previous time step or previous nonlinear step. We use the functions  [2.x.1268]  and  [2.x.1269]  to do this, while the present function provides the top-level logic.
//
[0.x.8728] 
[0.x.8729] 
[0.x.8730] 
//
// First we assemble the Jacobian matrix  [2.x.1270] , where  [2.x.1271]  is stored in the vector  [2.x.1272]  for convenience.
//
[0.x.8731] 
[0.x.8732] 
//
[0.x.8733] 
[0.x.8734] 
[0.x.8735] 
//
// Next we compute the right-hand side vector. This is just the combination of matrix-vector products implied by the description of  [2.x.1273]  in the introduction.
//
[0.x.8736] 
//
[0.x.8737] 
//
[0.x.8738] 
[0.x.8739] 
[0.x.8740] 
//
[0.x.8741] 
[0.x.8742] 
[0.x.8743] 
[0.x.8744] 
//
[0.x.8745] 
//
[0.x.8746] 
[0.x.8747] 
//
[0.x.8748] 
[0.x.8749] 
//[2.x.1274] 
//
// This function computes the vector  [2.x.1275] , which appears in the nonlinear term in both equations of the split formulation. This function not only simplifies the repeated computation of this term, but it is also a fundamental part of the nonlinear iterative solver that we use when the time stepping is implicit (i.e.  [2.x.1276] ). Moreover, we must allow the function to receive as input an "old" and a "new" solution. These may not be the actual solutions of the problem stored in  [2.x.1277] , but are simply the two functions we linearize about. For the purposes of this function, let us call the first two arguments  [2.x.1278]  and  [2.x.1279]  in the documentation of this class below, respectively.
//
// As a side-note, it is perhaps worth investigating what order quadrature formula is best suited for this type of integration. Since  [2.x.1280]  is not a polynomial, there are probably no quadrature formulas that can integrate these terms exactly. It is usually sufficient to just make sure that the right hand side is integrated up to the same order of accuracy as the discretization scheme is, but it may be possible to improve on the constant in the asymptotic statement of convergence by choosing a more accurate quadrature formula.
//
[0.x.8750] 
[0.x.8751] 
[0.x.8752] 
[0.x.8753] 
[0.x.8754] 
[0.x.8755] 
[0.x.8756] 
[0.x.8757] 
[0.x.8758] 
[0.x.8759] 
[0.x.8760] 
//
[0.x.8761] 
[0.x.8762] 
//
[0.x.8763] 
[0.x.8764] 
[0.x.8765] 
[0.x.8766] 
//
[0.x.8767] 
[0.x.8768] 
[0.x.8769] 
//
// Once we re-initialize our  [2.x.1281]  instantiation to the current cell, we make use of the  [2.x.1282]  routine to get the values of the "old" data (presumably at  [2.x.1283] ) and the "new" data (presumably at  [2.x.1284] ) at the nodes of the chosen quadrature formula.
//
[0.x.8770] 
[0.x.8771] 
[0.x.8772] 
//
// Now, we can evaluate  [2.x.1285]  using the desired quadrature formula.
//
[0.x.8773] 
[0.x.8774] 
[0.x.8775] 
[0.x.8776] 
[0.x.8777] 
[0.x.8778] 
//
// We conclude by adding up the contributions of the integrals over the cells to the global integral.
//
[0.x.8779] 
//
[0.x.8780] 
[0.x.8781] 
[0.x.8782] 
[0.x.8783] 
//[2.x.1286] 
//
// This is the second function dealing with the nonlinear scheme. It computes the matrix  [2.x.1287] , which appears in the nonlinear term in the Jacobian of  [2.x.1288] . Just as  [2.x.1289] , we must allow this function to receive as input an "old" and a "new" solution, which we again call  [2.x.1290]  and  [2.x.1291]  below, respectively.
//
[0.x.8784] 
[0.x.8785] 
[0.x.8786] 
[0.x.8787] 
[0.x.8788] 
[0.x.8789] 
[0.x.8790] 
[0.x.8791] 
[0.x.8792] 
[0.x.8793] 
[0.x.8794] 
//
[0.x.8795] 
[0.x.8796] 
//
[0.x.8797] 
[0.x.8798] 
[0.x.8799] 
[0.x.8800] 
//
[0.x.8801] 
[0.x.8802] 
[0.x.8803] 
//
// Again, first we re-initialize our  [2.x.1292]  instantiation to the current cell.
//
[0.x.8804] 
[0.x.8805] 
[0.x.8806] 
//
// Then, we evaluate  [2.x.1293]  using the desired quadrature formula.
//
[0.x.8807] 
[0.x.8808] 
[0.x.8809] 
[0.x.8810] 
[0.x.8811] 
[0.x.8812] 
[0.x.8813] 
[0.x.8814] 
//
// Finally, we add up the contributions of the integrals over the cells to the global integral.
//
[0.x.8815] 
//
[0.x.8816] 
[0.x.8817] 
[0.x.8818] 
[0.x.8819] 
[0.x.8820] 
[0.x.8821] 
[0.x.8822] 
//
//  [2.x.1294] 
//
// As discussed in the Introduction, this function uses the CG iterative solver on the linear system of equations resulting from the finite element spatial discretization of each iteration of Newton's method for the (nonlinear) first equation of the split formulation. The solution to the system is, in fact,  [2.x.1295]  so it is stored in  [2.x.1296]  in the  [2.x.1297]  function.
//
// Note that we re-set the solution update to zero before solving for it. This is not necessary: iterative solvers can start from any point and converge to the correct solution. If one has a good estimate about the solution of a linear system, it may be worthwhile to start from that vector, but as a general observation it is a fact that the starting point doesn't matter very much: it has to be a very, very good guess to reduce the number of iterations by more than a few. It turns out that for this problem, using the previous nonlinear update as a starting point actually hurts convergence and increases the number of iterations needed, so we simply set it to zero.
//
// The function returns the number of iterations it took to converge to a solution. This number will later be used to generate output on the screen showing how many iterations were needed in each nonlinear iteration.
//
[0.x.8823] 
[0.x.8824] 
[0.x.8825] 
[0.x.8826] 
[0.x.8827] 
//
[0.x.8828] 
[0.x.8829] 
//
[0.x.8830] 
//
[0.x.8831] 
[0.x.8832] 
//[2.x.1298] 
//
// This function outputs the results to a file. It is pretty much identical to the respective functions in  [2.x.1299]  and  [2.x.1300] :
//
[0.x.8833] 
[0.x.8834] 
[0.x.8835] 
[0.x.8836] 
[0.x.8837] 
//
[0.x.8838] 
[0.x.8839] 
[0.x.8840] 
//
[0.x.8841] 
[0.x.8842] 
[0.x.8843] 
[0.x.8844] 
[0.x.8845] 
[0.x.8846] 
[0.x.8847] 
[0.x.8848] 
[0.x.8849] 
//[2.x.1301] 
//
// This function has the top-level control over everything: it runs the (outer) time-stepping loop, the (inner) nonlinear-solver loop, and outputs the solution after each time step.
//
[0.x.8850] 
[0.x.8851] 
[0.x.8852] 
[0.x.8853] 
//
// To acknowledge the initial condition, we must use the function  [2.x.1302]  to compute  [2.x.1303] . To this end, below we will create an object of type  [2.x.1304] ; note that when we create this object (which is derived from the  [2.x.1305]  class), we set its internal time variable to  [2.x.1306] , to indicate that the initial condition is a function of space and time evaluated at  [2.x.1307] .
//
// Then we produce  [2.x.1308]  by projecting  [2.x.1309]  onto the grid using  [2.x.1310] . We have to use the same construct using hanging node constraints as in  [2.x.1311] : the  [2.x.1312]  function requires a hanging node constraints object, but to be used we first need to close it:
//
[0.x.8854] 
[0.x.8855] 
[0.x.8856] 
[0.x.8857] 
[0.x.8858] 
[0.x.8859] 
[0.x.8860] 
[0.x.8861] 
[0.x.8862] 
//
// For completeness, we output the zeroth time step to a file just like any other time step.
//
[0.x.8863] 
//
// Now we perform the time stepping: at every time step we solve the matrix equation(s) corresponding to the finite element discretization of the problem, and then advance our solution according to the time stepping formulas we discussed in the Introduction.
//
[0.x.8864] 
[0.x.8865] 
[0.x.8866] 
[0.x.8867] 
[0.x.8868] 
//
[0.x.8869] 
[0.x.8870] 
[0.x.8871] 
//
// At the beginning of each time step we must solve the nonlinear equation in the split formulation via Newton's method --- i.e. solve for  [2.x.1313]  then compute  [2.x.1314]  and so on. The stopping criterion for this nonlinear iteration is that  [2.x.1315] . Consequently, we need to record the norm of the residual in the first iteration.
//
// At the end of each iteration, we output to the console how many linear solver iterations it took us. When the loop below is done, we have (an approximation of)  [2.x.1316] .
//
[0.x.8872] 
[0.x.8873] 
[0.x.8874] 
[0.x.8875] 
[0.x.8876] 
//
[0.x.8877] 
[0.x.8878] 
//
[0.x.8879] 
//
[0.x.8880] 
//
[0.x.8881] 
[0.x.8882] 
[0.x.8883] 
[0.x.8884] 
[0.x.8885] 
[0.x.8886] 
[0.x.8887] 
//
[0.x.8888] 
//
// Upon obtaining the solution to the first equation of the problem at  [2.x.1317] , we must update the auxiliary velocity variable  [2.x.1318] . However, we do not compute and store  [2.x.1319]  since it is not a quantity we use directly in the problem. Hence, for simplicity, we update  [2.x.1320]  directly:
//
[0.x.8889] 
[0.x.8890] 
[0.x.8891] 
//
[0.x.8892] 
[0.x.8893] 
//
[0.x.8894] 
[0.x.8895] 
//
// Oftentimes, in particular for fine meshes, we must pick the time step to be quite small in order for the scheme to be stable. Therefore, there are a lot of time steps during which "nothing interesting happens" in the solution. To improve overall efficiency -- in particular, speed up the program and save disk space -- we only output the solution every  [2.x.1321]  time steps:
//
[0.x.8896] 
[0.x.8897] 
[0.x.8898] 
[0.x.8899] 
[0.x.8900] 
//[2.x.1322] 
//
// This is the main function of the program. It creates an object of top-level class and calls its principal function. If exceptions are thrown during the execution of the run method of the  [2.x.1323]  class, we catch and report them here. For more information about exceptions the reader should consult  [2.x.1324] .
//
[0.x.8901] 
[0.x.8902] 
[0.x.8903] 
[0.x.8904] 
[0.x.8905] 
//
[0.x.8906] 
[0.x.8907] 
[0.x.8908] 
[0.x.8909] 
[0.x.8910] 
[0.x.8911] 
[0.x.8912] 
[0.x.8913] 
[0.x.8914] 
[0.x.8915] 
[0.x.8916] 
[0.x.8917] 
[0.x.8918] 
[0.x.8919] 
//
[0.x.8920] 
[0.x.8921] 
[0.x.8922] 
[0.x.8923] 
[0.x.8924] 
[0.x.8925] 
[0.x.8926] 
[0.x.8927] 
[0.x.8928] 
[0.x.8929] 
[0.x.8930] 
[0.x.8931] 
[0.x.8932] 
[0.x.8933] 
//
[0.x.8934] 
[0.x.8935] 
[0.x.8936] 
[0.x.8937] 
[0.x.8938] 
[0.x.8939] 
[0.x.8940] 
[0.x.8941] 
[0.x.8942] 
[0.x.8943] 
[0.x.8944] 
[0.x.8945] 
[0.x.8946] 
[0.x.8947] 
[0.x.8948] 
[0.x.8949] 
//
[0.x.8950] 
[0.x.8951] 
[0.x.8952] 
//
// The program starts with the usual include files, all of which you should have seen before by now:
//
[0.x.8953] 
[0.x.8954] 
[0.x.8955] 
[0.x.8956] 
[0.x.8957] 
[0.x.8958] 
[0.x.8959] 
[0.x.8960] 
[0.x.8961] 
[0.x.8962] 
[0.x.8963] 
[0.x.8964] 
[0.x.8965] 
[0.x.8966] 
[0.x.8967] 
[0.x.8968] 
[0.x.8969] 
[0.x.8970] 
[0.x.8971] 
[0.x.8972] 
[0.x.8973] 
[0.x.8974] 
[0.x.8975] 
[0.x.8976] 
//
[0.x.8977] 
[0.x.8978] 
//
// Then the usual placing of all content of this program into a namespace and the importation of the deal.II namespace into the one we will work in:
//
[0.x.8979] 
[0.x.8980] 
[0.x.8981] 
//[2.x.1325] 
//
// The next piece is the declaration of the main class of this program. It follows the well trodden path of previous examples. If you have looked at  [2.x.1326] , for example, the only thing worth noting here is that we need to build two matrices (the mass and Laplace matrix) and keep the current and previous time step's solution. We then also need to store the current time, the size of the time step, and the number of the current time step. The last of the member variables denotes the theta parameter discussed in the introduction that allows us to treat the explicit and implicit Euler methods as well as the Crank-Nicolson method and other generalizations all in one program.
//
// As far as member functions are concerned, the only possible surprise is that the  [2.x.1327]  function takes arguments for the minimal and maximal mesh refinement level. The purpose of this is discussed in the introduction.
//
[0.x.8982] 
[0.x.8983] 
[0.x.8984] 
[0.x.8985] 
[0.x.8986] 
[0.x.8987] 
//
[0.x.8988] 
[0.x.8989] 
[0.x.8990] 
[0.x.8991] 
[0.x.8992] 
[0.x.8993] 
//
[0.x.8994] 
[0.x.8995] 
[0.x.8996] 
//
[0.x.8997] 
//
[0.x.8998] 
[0.x.8999] 
[0.x.9000] 
[0.x.9001] 
//
[0.x.9002] 
[0.x.9003] 
[0.x.9004] 
//
[0.x.9005] 
[0.x.9006] 
[0.x.9007] 
//
[0.x.9008] 
[0.x.9009] 
//
//  [2.x.1328] 
//
// In the following classes and functions, we implement the various pieces of data that define this problem (right hand side and boundary values) that are used in this program and for which we need function objects. The right hand side is chosen as discussed at the end of the introduction. For boundary values, we choose zero values, but this is easily changed below.
//
[0.x.9010] 
[0.x.9011] 
[0.x.9012] 
[0.x.9013] 
[0.x.9014] 
[0.x.9015] 
[0.x.9016] 
[0.x.9017] 
//
[0.x.9018] 
[0.x.9019] 
//
[0.x.9020] 
[0.x.9021] 
[0.x.9022] 
//
[0.x.9023] 
[0.x.9024] 
[0.x.9025] 
[0.x.9026] 
[0.x.9027] 
[0.x.9028] 
[0.x.9029] 
//
[0.x.9030] 
[0.x.9031] 
[0.x.9032] 
//
[0.x.9033] 
[0.x.9034] 
[0.x.9035] 
[0.x.9036] 
[0.x.9037] 
[0.x.9038] 
[0.x.9039] 
[0.x.9040] 
[0.x.9041] 
[0.x.9042] 
[0.x.9043] 
[0.x.9044] 
[0.x.9045] 
[0.x.9046] 
[0.x.9047] 
[0.x.9048] 
[0.x.9049] 
//
[0.x.9050] 
[0.x.9051] 
[0.x.9052] 
[0.x.9053] 
[0.x.9054] 
[0.x.9055] 
[0.x.9056] 
//
[0.x.9057] 
[0.x.9058] 
[0.x.9059] 
[0.x.9060] 
[0.x.9061] 
[0.x.9062] 
[0.x.9063] 
[0.x.9064] 
//
//  [2.x.1329] 
//
// It is time now for the implementation of the main class. Let's start with the constructor which selects a linear element, a time step constant at 1/500 (remember that one period of the source on the right hand side was set to 0.2 above, so we resolve each period with 100 time steps) and chooses the Crank Nicolson method by setting  [2.x.1330] .
//
[0.x.9065] 
[0.x.9066] 
[0.x.9067] 
[0.x.9068] 
[0.x.9069] 
[0.x.9070] 
[0.x.9071] 
//
//  [2.x.1331] 
//
// The next function is the one that sets up the DoFHandler object, computes the constraints, and sets the linear algebra objects to their correct sizes. We also compute the mass and Laplace matrix here by simply calling two functions in the library.
//
// Note that we do not take the hanging node constraints into account when assembling the matrices (both functions have an AffineConstraints argument that defaults to an empty object). This is because we are going to condense the constraints in run() after combining the matrices for the current time-step.
//
[0.x.9072] 
[0.x.9073] 
[0.x.9074] 
[0.x.9075] 
//
[0.x.9076] 
[0.x.9077] 
[0.x.9078] 
[0.x.9079] 
[0.x.9080] 
[0.x.9081] 
[0.x.9082] 
//
[0.x.9083] 
[0.x.9084] 
[0.x.9085] 
//
[0.x.9086] 
[0.x.9087] 
[0.x.9088] 
[0.x.9089] 
//
//                                    /*keep_constrained_dofs =  [2.x.1332]  true);
//
[0.x.9090] 
//
[0.x.9091] 
[0.x.9092] 
[0.x.9093] 
//
[0.x.9094] 
[0.x.9095] 
[0.x.9096] 
[0.x.9097] 
[0.x.9098] 
[0.x.9099] 
//
[0.x.9100] 
[0.x.9101] 
[0.x.9102] 
[0.x.9103] 
//[2.x.1333] 
//
// The next function is the one that solves the actual linear system for a single time step. There is nothing surprising here:
//
[0.x.9104] 
[0.x.9105] 
[0.x.9106] 
[0.x.9107] 
[0.x.9108] 
//
[0.x.9109] 
[0.x.9110] 
//
[0.x.9111] 
//
[0.x.9112] 
//
[0.x.9113] 
[0.x.9114] 
[0.x.9115] 
//
//  [2.x.1334] 
//
// Neither is there anything new in generating graphical output other than the fact that we tell the DataOut object what the current time and time step number is, so that this can be written into the output file:
//
[0.x.9116] 
[0.x.9117] 
[0.x.9118] 
[0.x.9119] 
//
[0.x.9120] 
[0.x.9121] 
//
[0.x.9122] 
//
[0.x.9123] 
//
[0.x.9124] 
[0.x.9125] 
[0.x.9126] 
[0.x.9127] 
[0.x.9128] 
//[2.x.1335] 
//
// This function is the interesting part of the program. It takes care of the adaptive mesh refinement. The three tasks this function performs is to first find out which cells to refine/coarsen, then to actually do the refinement and eventually transfer the solution vectors between the two different grids. The first task is simply achieved by using the well-established Kelly error estimator on the solution. The second task is to actually do the remeshing. That involves only basic functions as well, such as the  [2.x.1336]  that refines those cells with the largest estimated error that together make up 60 per cent of the error, and coarsens those cells with the smallest error that make up for a combined 40 per cent of the error. Note that for problems such as the current one where the areas where something is going on are shifting around, we want to aggressively coarsen so that we can move cells around to where it is necessary.
//
// As already discussed in the introduction, too small a mesh leads to too small a time step, whereas too large a mesh leads to too little resolution. Consequently, after the first two steps, we have two loops that limit refinement and coarsening to an allowable range of cells:
//
[0.x.9129] 
[0.x.9130] 
[0.x.9131] 
[0.x.9132] 
[0.x.9133] 
//
[0.x.9134] 
[0.x.9135] 
[0.x.9136] 
[0.x.9137] 
[0.x.9138] 
[0.x.9139] 
//
[0.x.9140] 
[0.x.9141] 
[0.x.9142] 
[0.x.9143] 
//
[0.x.9144] 
[0.x.9145] 
[0.x.9146] 
[0.x.9147] 
[0.x.9148] 
[0.x.9149] 
[0.x.9150] 
//
// These two loops above are slightly different but this is easily explained. In the first loop, instead of calling  [2.x.1337]  we may as well have called  [2.x.1338] . The two calls should yield the same iterator since iterators are sorted by level and there should not be any cells on levels higher than on level  [2.x.1339] . In fact, this very piece of code makes sure that this is the case.
//
// As part of mesh refinement we need to transfer the solution vectors from the old mesh to the new one. To this end we use the SolutionTransfer class and we have to prepare the solution vectors that should be transferred to the new grid (we will lose the old grid once we have done the refinement so the transfer has to happen concurrently with refinement). At the point where we call this function, we will have just computed the solution, so we no longer need the old_solution variable (it will be overwritten by the solution just after the mesh may have been refined, i.e., at the end of the time step; see below). In other words, we only need the one solution vector, and we copy it to a temporary object where it is safe from being reset when we further down below call  [2.x.1340] .
//
// Consequently, we initialize a SolutionTransfer object by attaching it to the old DoF handler. We then prepare the triangulation and the data vector for refinement (in this order).
//
[0.x.9151] 
//
[0.x.9152] 
[0.x.9153] 
[0.x.9154] 
[0.x.9155] 
//
// Now everything is ready, so do the refinement and recreate the DoF structure on the new grid, and finally initialize the matrix structures and the new vectors in the  [2.x.1341]  function. Next, we actually perform the interpolation of the solution from old to new grid. The final step is to apply the hanging node constraints to the solution vector, i.e., to make sure that the values of degrees of freedom located on hanging nodes are so that the solution is continuous. This is necessary since SolutionTransfer only operates on cells locally, without regard to the neighborhood.
//
[0.x.9156] 
[0.x.9157] 
//
[0.x.9158] 
[0.x.9159] 
[0.x.9160] 
//
//  [2.x.1342] 
//
// This is the main driver of the program, where we loop over all time steps. At the top of the function, we set the number of initial global mesh refinements and the number of initial cycles of adaptive mesh refinement by repeating the first time step a few times. Then we create a mesh, initialize the various objects we will work with, set a label for where we should start when re-running the first time step, and interpolate the initial solution onto out mesh (we choose the zero function here, which of course we could do in a simpler way by just setting the solution vector to zero). We also output the initial time step once.
//
//  [2.x.1343]  If you're an experienced programmer, you may be surprised that we use a  [2.x.1344]  statement in this piece of code!  [2.x.1345]  statements are not particularly well liked any more since Edsgar Dijkstra, one of the greats of computer science, wrote a letter in 1968 called "Go To Statement considered harmful" (see [1.x.35]). The author of this code subscribes to this notion whole-heartedly:  [2.x.1346]  is hard to understand. In fact, deal.II contains virtually no occurrences: excluding code that was essentially transcribed from books and not counting duplicated code pieces, there are 3 locations in about 600,000 lines of code at the time this note is written; we also use it in 4 tutorial programs, in exactly the same context as here. Instead of trying to justify the occurrence here, let's first look at the code and we'll come back to the issue at the end of function.
//
[0.x.9161] 
[0.x.9162] 
[0.x.9163] 
[0.x.9164] 
[0.x.9165] 
//
[0.x.9166] 
[0.x.9167] 
//
[0.x.9168] 
//
[0.x.9169] 
//
[0.x.9170] 
[0.x.9171] 
//
[0.x.9172] 
//
[0.x.9173] 
[0.x.9174] 
//
[0.x.9175] 
[0.x.9176] 
//
[0.x.9177] 
[0.x.9178] 
[0.x.9179] 
[0.x.9180] 
//
[0.x.9181] 
//
// Then we start the main loop until the computed time exceeds our end time of 0.5. The first task is to build the right hand side of the linear system we need to solve in each time step. Recall that it contains the term  [2.x.1347] . We put these terms into the variable system_rhs, with the help of a temporary vector:
//
[0.x.9182] 
[0.x.9183] 
[0.x.9184] 
[0.x.9185] 
//
[0.x.9186] 
[0.x.9187] 
//
[0.x.9188] 
//
[0.x.9189] 
[0.x.9190] 
//
// The second piece is to compute the contributions of the source terms. This corresponds to the term  [2.x.1348] . The following code calls  [2.x.1349]  to compute the vectors  [2.x.1350] , where we set the time of the right hand side (source) function before we evaluate it. The result of this all ends up in the forcing_terms variable:
//
[0.x.9191] 
[0.x.9192] 
[0.x.9193] 
[0.x.9194] 
[0.x.9195] 
[0.x.9196] 
[0.x.9197] 
[0.x.9198] 
//
[0.x.9199] 
[0.x.9200] 
[0.x.9201] 
[0.x.9202] 
[0.x.9203] 
//
[0.x.9204] 
//
// Next, we add the forcing terms to the ones that come from the time stepping, and also build the matrix  [2.x.1351]  that we have to invert in each time step. The final piece of these operations is to eliminate hanging node constrained degrees of freedom from the linear system:
//
[0.x.9205] 
//
[0.x.9206] 
[0.x.9207] 
//
[0.x.9208] 
//
// There is one more operation we need to do before we can solve it: boundary values. To this end, we create a boundary value object, set the proper time to the one of the current time step, and evaluate it as we have done many times before. The result is used to also set the correct boundary values in the linear system:
//
[0.x.9209] 
[0.x.9210] 
[0.x.9211] 
//
[0.x.9212] 
[0.x.9213] 
[0.x.9214] 
[0.x.9215] 
[0.x.9216] 
//
[0.x.9217] 
[0.x.9218] 
[0.x.9219] 
[0.x.9220] 
[0.x.9221] 
//
// With this out of the way, all we have to do is solve the system, generate graphical data, and...
//
[0.x.9222] 
//
[0.x.9223] 
//
// ...take care of mesh refinement. Here, what we want to do is (i) refine the requested number of times at the very beginning of the solution procedure, after which we jump to the top to restart the time iteration, (ii) refine every fifth time step after that.
//
// The time loop and, indeed, the main part of the program ends with starting into the next time step by setting old_solution to the solution we have just computed.
//
[0.x.9224] 
[0.x.9225] 
[0.x.9226] 
[0.x.9227] 
[0.x.9228] 
[0.x.9229] 
[0.x.9230] 
//
[0.x.9231] 
[0.x.9232] 
//
[0.x.9233] 
//
[0.x.9234] 
[0.x.9235] 
[0.x.9236] 
[0.x.9237] 
[0.x.9238] 
[0.x.9239] 
[0.x.9240] 
[0.x.9241] 
[0.x.9242] 
[0.x.9243] 
//
[0.x.9244] 
[0.x.9245] 
[0.x.9246] 
[0.x.9247] 
//
// Now that you have seen what the function does, let us come back to the issue of the  [2.x.1352] . In essence, what the code does is something like this: [1.x.36] Here, the condition "happy with the result" is whether we'd like to keep the current mesh or would rather refine the mesh and start over on the new mesh. We could of course replace the use of the  [2.x.1353]  by the following: [1.x.37] This has the advantage of getting rid of the  [2.x.1354]  but the disadvantage of having to duplicate the code that implements the "solve timestep" and "postprocess" operations in two different places. This could be countered by putting these parts of the code (sizable chunks in the actual implementation above) into their own functions, but a  [2.x.1355]  loop with a  [2.x.1356]  statement is not really all that much easier to read or understand than a  [2.x.1357] .
//
// In the end, one might simply agree that [1.x.38] 
//[2.x.1358]  statements are a bad idea but be pragmatic and state that there may be occasions where they can help avoid code duplication and awkward control flow. This may be one of these places, and it matches the position Steve McConnell takes in his excellent book "Code Complete"  [2.x.1359]  about good programming practices (see the mention of this book in the introduction of  [2.x.1360] ) that spends a surprising ten pages on the question of  [2.x.1361]  in general.
//
//  [2.x.1362] 
//
// Having made it this far,  there is, again, nothing much to discuss for the main function of this program: it looks like all such functions since  [2.x.1363] .
//
[0.x.9248] 
[0.x.9249] 
[0.x.9250] 
[0.x.9251] 
[0.x.9252] 
//
[0.x.9253] 
[0.x.9254] 
[0.x.9255] 
[0.x.9256] 
[0.x.9257] 
[0.x.9258] 
[0.x.9259] 
[0.x.9260] 
[0.x.9261] 
[0.x.9262] 
[0.x.9263] 
[0.x.9264] 
[0.x.9265] 
[0.x.9266] 
//
[0.x.9267] 
[0.x.9268] 
[0.x.9269] 
[0.x.9270] 
[0.x.9271] 
[0.x.9272] 
[0.x.9273] 
[0.x.9274] 
[0.x.9275] 
[0.x.9276] 
[0.x.9277] 
[0.x.9278] 
[0.x.9279] 
[0.x.9280] 
//
[0.x.9281] 
[0.x.9282] 
[0.x.9283] 
[0.x.9284] 
[0.x.9285] 
[0.x.9286] 
[0.x.9287] 
[0.x.9288] 
[0.x.9289] 
[0.x.9290] 
[0.x.9291] 
[0.x.9292] 
[0.x.9293] 
[0.x.9294] 
[0.x.9295] 
[0.x.9296] 
//
[0.x.9297] 
[0.x.9298] 
[0.x.9299] 
[0.x.9300] 
[0.x.9301] 
//[2.x.1364] 
//
// The first few files have already been covered in previous examples and will thus not be further commented on.
//
[0.x.9302] 
[0.x.9303] 
[0.x.9304] 
[0.x.9305] 
[0.x.9306] 
[0.x.9307] 
[0.x.9308] 
[0.x.9309] 
[0.x.9310] 
[0.x.9311] 
[0.x.9312] 
[0.x.9313] 
[0.x.9314] 
[0.x.9315] 
[0.x.9316] 
[0.x.9317] 
[0.x.9318] 
[0.x.9319] 
[0.x.9320] 
[0.x.9321] 
//
// These are the new files we need. The first and second provide the FECollection and the [1.x.39] version of the FEValues class as described in the introduction of this program. The next one provides the functionality for automatic  [2.x.1365] -adaptation, for which we will use the estimation algorithms based on decaying series expansion coefficients that are part of the last two files.
//
[0.x.9322] 
[0.x.9323] 
[0.x.9324] 
[0.x.9325] 
[0.x.9326] 
//
// The last set of include files are standard C++ headers.
//
[0.x.9327] 
[0.x.9328] 
//
// Finally, this is as in previous programs:
//
[0.x.9329] 
[0.x.9330] 
[0.x.9331] 
//[2.x.1366] 
//
// The main class of this program looks very much like the one already used in the first few tutorial programs, for example the one in  [2.x.1367] . The main difference is that we have merged the refine_grid and output_results functions into one since we will also want to output some of the quantities used in deciding how to refine the mesh (in particular the estimated smoothness of the solution).
//
// As far as member variables are concerned, we use the same structure as already used in  [2.x.1368] , but we need collections instead of individual finite element, quadrature, and face quadrature objects. We will fill these collections in the constructor of the class. The last variable,  [2.x.1369] , indicates the maximal polynomial degree of shape functions used.
//
[0.x.9332] 
[0.x.9333] 
[0.x.9334] 
[0.x.9335] 
[0.x.9336] 
[0.x.9337] 
//
[0.x.9338] 
//
[0.x.9339] 
[0.x.9340] 
[0.x.9341] 
[0.x.9342] 
[0.x.9343] 
[0.x.9344] 
//
[0.x.9345] 
//
[0.x.9346] 
[0.x.9347] 
[0.x.9348] 
[0.x.9349] 
//
[0.x.9350] 
//
[0.x.9351] 
[0.x.9352] 
//
[0.x.9353] 
[0.x.9354] 
//
[0.x.9355] 
[0.x.9356] 
//
//  [2.x.1370] 
//
// Next, let us define the right hand side function for this problem. It is  [2.x.1371]  in 1d,  [2.x.1372]  in 2d, and so on.
//
[0.x.9357] 
[0.x.9358] 
[0.x.9359] 
[0.x.9360] 
[0.x.9361] 
[0.x.9362] 
[0.x.9363] 
//
[0.x.9364] 
[0.x.9365] 
[0.x.9366] 
[0.x.9367] 
[0.x.9368] 
[0.x.9369] 
[0.x.9370] 
[0.x.9371] 
[0.x.9372] 
//
//  [2.x.1373] 
//[2.x.1374] 
//
// The constructor of this class is fairly straightforward. It associates the DoFHandler object with the triangulation, and then sets the maximal polynomial degree to 7 (in 1d and 2d) or 5 (in 3d and higher). We do so because using higher order polynomial degrees becomes prohibitively expensive, especially in higher space dimensions.
//
// Following this, we fill the collections of finite element, and cell and face quadrature objects. We start with quadratic elements, and each quadrature formula is chosen so that it is appropriate for the matching finite element in the  [2.x.1375]  object.
//
[0.x.9373] 
[0.x.9374] 
[0.x.9375] 
[0.x.9376] 
[0.x.9377] 
[0.x.9378] 
[0.x.9379] 
[0.x.9380] 
[0.x.9381] 
[0.x.9382] 
[0.x.9383] 
[0.x.9384] 
//[2.x.1376] 
//
// The destructor is unchanged from what we already did in  [2.x.1377] :
//
[0.x.9385] 
[0.x.9386] 
[0.x.9387] 
[0.x.9388] 
[0.x.9389] 
//[2.x.1378] 
//
// This function is again a verbatim copy of what we already did in  [2.x.1379] . Despite function calls with exactly the same names and arguments, the algorithms used internally are different in some aspect since the dof_handler variable here is in  [2.x.1380] -mode.
//
[0.x.9390] 
[0.x.9391] 
[0.x.9392] 
[0.x.9393] 
//
[0.x.9394] 
[0.x.9395] 
//
[0.x.9396] 
[0.x.9397] 
[0.x.9398] 
[0.x.9399] 
[0.x.9400] 
[0.x.9401] 
[0.x.9402] 
//
[0.x.9403] 
[0.x.9404] 
[0.x.9405] 
//
[0.x.9406] 
[0.x.9407] 
//
//  [2.x.1381] 
//
// This is the function that assembles the global matrix and right hand side vector from the local contributions of each cell. Its main working is as has been described in many of the tutorial programs before. The significant deviations are the ones necessary for [1.x.40] finite element methods. In particular, that we need to use a collection of FEValues object (implemented through the  [2.x.1382]  class), and that we have to eliminate constrained degrees of freedom already when copying local contributions into global objects. Both of these are explained in detail in the introduction of this program.
//
// One other slight complication is the fact that because we use different polynomial degrees on different cells, the matrices and vectors holding local contributions do not have the same size on all cells. At the beginning of the loop over all cells, we therefore each time have to resize them to the correct size (given by  [2.x.1383] ). Because these classes are implemented in such a way that reducing the size of a matrix or vector does not release the currently allocated memory (unless the new size is zero), the process of resizing at the beginning of the loop will only require re-allocation of memory during the first few iterations. Once we have found in a cell with the maximal finite element degree, no more re-allocations will happen because all subsequent  [2.x.1384]  calls will only set the size to something that fits the currently allocated memory. This is important since allocating memory is expensive, and doing so every time we visit a new cell would take significant compute time.
//
[0.x.9408] 
[0.x.9409] 
[0.x.9410] 
[0.x.9411] 
[0.x.9412] 
[0.x.9413] 
[0.x.9414] 
[0.x.9415] 
//
[0.x.9416] 
//
[0.x.9417] 
[0.x.9418] 
//
[0.x.9419] 
//
[0.x.9420] 
[0.x.9421] 
[0.x.9422] 
//
[0.x.9423] 
[0.x.9424] 
//
[0.x.9425] 
[0.x.9426] 
//
[0.x.9427] 
//
[0.x.9428] 
//
[0.x.9429] 
[0.x.9430] 
//
[0.x.9431] 
[0.x.9432] 
[0.x.9433] 
[0.x.9434] 
[0.x.9435] 
[0.x.9436] 
[0.x.9437] 
[0.x.9438] 
[0.x.9439] 
//
[0.x.9440] 
[0.x.9441] 
[0.x.9442] 
[0.x.9443] 
//
[0.x.9444] 
[0.x.9445] 
//
[0.x.9446] 
[0.x.9447] 
[0.x.9448] 
[0.x.9449] 
//
//  [2.x.1385] 
//
// The function solving the linear system is entirely unchanged from previous examples. We simply try to reduce the initial residual (which equals the  [2.x.1386]  norm of the right hand side) by a certain factor:
//
[0.x.9450] 
[0.x.9451] 
[0.x.9452] 
[0.x.9453] 
[0.x.9454] 
[0.x.9455] 
//
[0.x.9456] 
[0.x.9457] 
//
[0.x.9458] 
//
[0.x.9459] 
[0.x.9460] 
//
//  [2.x.1387] 
//
// After solving the linear system, we will want to postprocess the solution. Here, all we do is to estimate the error, estimate the local smoothness of the solution as described in the introduction, then write graphical output, and finally refine the mesh in both  [2.x.1388]  and  [2.x.1389]  according to the indicators computed before. We do all this in the same function because we want the estimated error and smoothness indicators not only for refinement, but also include them in the graphical output.
//
[0.x.9461] 
[0.x.9462] 
[0.x.9463] 
//
// Let us start with computing estimated error and smoothness indicators, which each are one number for each active cell of our triangulation. For the error indicator, we use the KellyErrorEstimator class as always.
//
[0.x.9464] 
[0.x.9465] 
[0.x.9466] 
[0.x.9467] 
[0.x.9468] 
[0.x.9469] 
[0.x.9470] 
//
// Estimating the smoothness is performed with the method of decaying expansion coefficients as outlined in the introduction. We will first need to create an object capable of transforming the finite element solution on every single cell into a sequence of Fourier series coefficients. The SmoothnessEstimator namespace offers a factory function for such a  [2.x.1390]  object that is optimized for the process of estimating smoothness. The actual determination of the decay of Fourier coefficients on every individual cell then happens in the last function.
//
[0.x.9471] 
[0.x.9472] 
[0.x.9473] 
[0.x.9474] 
[0.x.9475] 
[0.x.9476] 
[0.x.9477] 
//
// Next we want to generate graphical output. In addition to the two estimated quantities derived above, we would also like to output the polynomial degree of the finite elements used on each of the elements on the mesh.
//
// The way to do that requires that we loop over all cells and poll the active finite element index of them using  [2.x.1391] . We then use the result of this operation and query the finite element collection for the finite element with that index, and finally determine the polynomial degree of that element. The result we put into a vector with one element per cell. The DataOut class requires this to be a vector of  [2.x.1392] , even though our values are all integers, so that is what we use:
//
[0.x.9478] 
[0.x.9479] 
[0.x.9480] 
[0.x.9481] 
[0.x.9482] 
//
// With now all data vectors available -- solution, estimated errors and smoothness indicators, and finite element degrees --, we create a DataOut object for graphical output and attach all data:
//
[0.x.9483] 
//
[0.x.9484] 
[0.x.9485] 
[0.x.9486] 
[0.x.9487] 
[0.x.9488] 
[0.x.9489] 
//
// The final step in generating output is to determine a file name, open the file, and write the data into it (here, we use VTK format):
//
[0.x.9490] 
[0.x.9491] 
[0.x.9492] 
[0.x.9493] 
[0.x.9494] 
//
// After this, we would like to actually refine the mesh, in both  [2.x.1393]  and  [2.x.1394] . The way we are going to do this is as follows: first, we use the estimated error to flag those cells for refinement that have the largest error. This is what we have always done:
//
[0.x.9495] 
[0.x.9496] 
[0.x.9497] 
[0.x.9498] 
[0.x.9499] 
//
// Next we would like to figure out which of the cells that have been flagged for refinement should actually have  [2.x.1395]  increased instead of  [2.x.1396]  decreased. The strategy we choose here is that we look at the smoothness indicators of those cells that are flagged for refinement, and increase  [2.x.1397]  for those with a smoothness larger than a certain relative threshold. In other words, for every cell for which (i) the refinement flag is set, (ii) the smoothness indicator is larger than the threshold, and (iii) we still have a finite element with a polynomial degree higher than the current one in the finite element collection, we will assign a future FE index that corresponds to a polynomial with degree one higher than it currently is. The following function is capable of doing exactly this. Absent any better strategies, we will set the threshold via interpolation between the minimal and maximal smoothness indicators on cells flagged for refinement. Since the corner singularities are strongly localized, we will favor  [2.x.1398]
//
// - over  [2.x.1399] -refinement quantitatively. We achieve this with a low threshold by setting a small interpolation factor of 0.2. In the same way, we deal with cells that are going to be coarsened and decrease their polynomial degree when their smoothness indicator is below the corresponding threshold determined on cells to be coarsened.
//
[0.x.9500] 
[0.x.9501] 
//
// The above function only determines whether the polynomial degree will change via future FE indices, but does not manipulate the  [2.x.1400] -refinement flags. So for cells that are flagged for both refinement categories, we prefer  [2.x.1401]
//
// - over  [2.x.1402] -refinement. The following function call ensures that only one of  [2.x.1403]
//
// - or  [2.x.1404] -refinement is imposed, and not both at once.
//
[0.x.9502] 
//
// For grid adaptive refinement, we ensure a 2:1 mesh balance by limiting the difference of refinement levels of neighboring cells to one by calling  [2.x.1405]  We would like to achieve something similar for the p-levels of neighboring cells: levels of future finite elements are not allowed to differ by more than a specified difference. With its default parameters, a call of  [2.x.1406]  ensures that their level difference is limited to one. This will not necessarily decrease the number of hanging nodes in the domain, but makes sure that high order polynomials are not constrained to much lower polynomials on faces, e.g., fifth order to second order polynomials.
//
[0.x.9503] 
[0.x.9504] 
//
// At the end of this procedure, we then refine the mesh. During this process, children of cells undergoing bisection inherit their mother cell's finite element index. Further, future finite element indices will turn into active ones, so that the new finite elements will be assigned to cells after the next call of  [2.x.1407] 
[0.x.9505] 
[0.x.9506] 
[0.x.9507] 
//[2.x.1408] 
//
// The following function is used when creating the initial grid. The grid we would like to create is actually similar to the one from  [2.x.1409] , i.e., the square domain with the square hole in the middle. It can be generated by exactly the same function. However, since its implementation is only a specialization of the 2d case, we will present a different way of creating this domain which is dimension independent.
//
// We first create a hypercube triangulation with enough cells so that it already holds our desired domain  [2.x.1410] , subdivided into  [2.x.1411]  cells. We then remove those cells in the center of the domain by testing the coordinate values of the vertices on each cell. In the end, we refine the so created grid globally as usual.
//
[0.x.9508] 
[0.x.9509] 
[0.x.9510] 
[0.x.9511] 
[0.x.9512] 
//
[0.x.9513] 
[0.x.9514] 
[0.x.9515] 
[0.x.9516] 
[0.x.9517] 
//
[0.x.9518] 
[0.x.9519] 
[0.x.9520] 
//
[0.x.9521] 
[0.x.9522] 
//
//  [2.x.1412] 
//
// This function implements the logic of the program, as did the respective function in most of the previous programs already, see for example  [2.x.1413] .
//
// Basically, it contains the adaptive loop: in the first iteration create a coarse grid, and then set up the linear system, assemble it, solve, and postprocess the solution including mesh refinement. Then start over again. In the meantime, also output some information for those staring at the screen trying to figure out what the program does:
//
[0.x.9523] 
[0.x.9524] 
[0.x.9525] 
[0.x.9526] 
[0.x.9527] 
[0.x.9528] 
//
[0.x.9529] 
[0.x.9530] 
//
[0.x.9531] 
//
[0.x.9532] 
[0.x.9533] 
[0.x.9534] 
[0.x.9535] 
[0.x.9536] 
[0.x.9537] 
//
[0.x.9538] 
[0.x.9539] 
[0.x.9540] 
[0.x.9541] 
[0.x.9542] 
[0.x.9543] 
//[2.x.1414] 
//
// The main function is again verbatim what we had before: wrap creating and running an object of the main class into a  [2.x.1415]  block and catch whatever exceptions are thrown, thereby producing meaningful output if anything should go wrong:
//
[0.x.9544] 
[0.x.9545] 
[0.x.9546] 
[0.x.9547] 
[0.x.9548] 
//
[0.x.9549] 
[0.x.9550] 
[0.x.9551] 
[0.x.9552] 
[0.x.9553] 
[0.x.9554] 
[0.x.9555] 
[0.x.9556] 
[0.x.9557] 
[0.x.9558] 
[0.x.9559] 
[0.x.9560] 
[0.x.9561] 
[0.x.9562] 
//
[0.x.9563] 
[0.x.9564] 
[0.x.9565] 
[0.x.9566] 
[0.x.9567] 
[0.x.9568] 
[0.x.9569] 
[0.x.9570] 
[0.x.9571] 
[0.x.9572] 
[0.x.9573] 
[0.x.9574] 
[0.x.9575] 
[0.x.9576] 
//
[0.x.9577] 
[0.x.9578] 
[0.x.9579] 
[0.x.9580] 
[0.x.9581] 
[0.x.9582] 
[0.x.9583] 
[0.x.9584] 
[0.x.9585] 
[0.x.9586] 
[0.x.9587] 
[0.x.9588] 
[0.x.9589] 
[0.x.9590] 
[0.x.9591] 
[0.x.9592] 
//
[0.x.9593] 
[0.x.9594] 
[0.x.9595] 
//[2.x.1416] 
//
// We start with a bunch of include files that have already been explained in previous tutorial programs. One new one is  [2.x.1417] : This is the first example program that uses the Timer class. The Timer keeps track of both the elapsed wall clock time (that is, the amount of time that a clock mounted on the wall would measure) and CPU clock time (the amount of time that the current process uses on the CPUs). We will use a Timer below to measure how much CPU time each grid refinement cycle takes.
//
[0.x.9596] 
[0.x.9597] 
[0.x.9598] 
[0.x.9599] 
[0.x.9600] 
[0.x.9601] 
//
[0.x.9602] 
[0.x.9603] 
[0.x.9604] 
[0.x.9605] 
[0.x.9606] 
[0.x.9607] 
[0.x.9608] 
[0.x.9609] 
//
[0.x.9610] 
[0.x.9611] 
[0.x.9612] 
[0.x.9613] 
//
[0.x.9614] 
[0.x.9615] 
//
[0.x.9616] 
[0.x.9617] 
//
[0.x.9618] 
[0.x.9619] 
[0.x.9620] 
[0.x.9621] 
//
[0.x.9622] 
[0.x.9623] 
//
// We use the next include file to access block vectors which provide us a convenient way to manage solution and right hand side vectors of all energy groups:
//
[0.x.9624] 
//
// This include file is for transferring solutions from one mesh to another different mesh. We use it when we are initializing solutions after each mesh iteration:
//
[0.x.9625] 
//
// When integrating functions defined on one mesh against shape functions defined on a different mesh, we need a function  [2.x.1418]  (as discussed in the introduction) which is defined in the following header file:
//
[0.x.9626] 
//
// We use a little utility class from boost to save the state of an output stream (see the  [2.x.1419]  function below):
//
[0.x.9627] 
//
// Here are two more C++ standard headers that we use to define list data types as well as to fine-tune the output we generate:
//
[0.x.9628] 
[0.x.9629] 
//
// The last step is as in all previous programs:
//
[0.x.9630] 
[0.x.9631] 
[0.x.9632] 
//[2.x.1420] 
//
// First up, we need to define a class that provides material data (including diffusion coefficients, removal cross sections, scattering cross sections, fission cross sections and fission spectra) to the main class.
//
// The parameter to the constructor determines for how many energy groups we set up the relevant tables. At present, this program only includes data for 2 energy groups, but a more sophisticated program may be able to initialize the data structures for more groups as well, depending on how many energy groups are selected in the parameter file.
//
// For each of the different coefficient types, there is one function that returns the value of this coefficient for a particular energy group (or combination of energy groups, as for the distribution cross section  [2.x.1421]  or scattering cross section  [2.x.1422] ). In addition to the energy group or groups, these coefficients depend on the type of fuel or control rod, as explained in the introduction. The functions therefore take an additional parameter,  [2.x.1423]  material_id, that identifies the particular kind of rod. Within this program, we use  [2.x.1424]  different kinds of rods.
//
// Except for the scattering cross section, each of the coefficients therefore can be represented as an entry in a two-dimensional array of floating point values indexed by the energy group number as well as the material ID. The Table class template is the ideal way to store such data. Finally, the scattering coefficient depends on both two energy group indices and therefore needs to be stored in a three-dimensional array, for which we again use the Table class, where this time the first template argument (denoting the dimensionality of the array) of course needs to be three:
//
[0.x.9633] 
[0.x.9634] 
[0.x.9635] 
[0.x.9636] 
//
[0.x.9637] 
[0.x.9638] 
[0.x.9639] 
[0.x.9640] 
[0.x.9641] 
[0.x.9642] 
[0.x.9643] 
[0.x.9644] 
[0.x.9645] 
[0.x.9646] 
[0.x.9647] 
[0.x.9648] 
[0.x.9649] 
[0.x.9650] 
//
[0.x.9651] 
[0.x.9652] 
[0.x.9653] 
//
[0.x.9654] 
[0.x.9655] 
[0.x.9656] 
[0.x.9657] 
[0.x.9658] 
[0.x.9659] 
//
// The constructor of the class is used to initialize all the material data arrays. It takes the number of energy groups as an argument (an throws an error if that value is not equal to two, since at presently only data for two energy groups is implemented; however, using this, the function remains flexible and extendable into the future). In the member initialization part at the beginning, it also resizes the arrays to their correct sizes.
//
// At present, material data is stored for 8 different types of material. This, as well, may easily be extended in the future.
//
[0.x.9660] 
[0.x.9661] 
[0.x.9662] 
[0.x.9663] 
[0.x.9664] 
[0.x.9665] 
[0.x.9666] 
[0.x.9667] 
[0.x.9668] 
[0.x.9669] 
[0.x.9670] 
[0.x.9671] 
[0.x.9672] 
[0.x.9673] 
[0.x.9674] 
[0.x.9675] 
[0.x.9676] 
[0.x.9677] 
[0.x.9678] 
[0.x.9679] 
[0.x.9680] 
[0.x.9681] 
[0.x.9682] 
[0.x.9683] 
//
[0.x.9684] 
//
[0.x.9685] 
[0.x.9686] 
[0.x.9687] 
[0.x.9688] 
//
[0.x.9689] 
[0.x.9690] 
[0.x.9691] 
[0.x.9692] 
[0.x.9693] 
[0.x.9694] 
[0.x.9695] 
[0.x.9696] 
//
[0.x.9697] 
[0.x.9698] 
[0.x.9699] 
[0.x.9700] 
[0.x.9701] 
[0.x.9702] 
[0.x.9703] 
[0.x.9704] 
//
[0.x.9705] 
[0.x.9706] 
[0.x.9707] 
[0.x.9708] 
[0.x.9709] 
[0.x.9710] 
[0.x.9711] 
[0.x.9712] 
//
[0.x.9713] 
[0.x.9714] 
[0.x.9715] 
[0.x.9716] 
[0.x.9717] 
[0.x.9718] 
[0.x.9719] 
[0.x.9720] 
//
[0.x.9721] 
[0.x.9722] 
//
[0.x.9723] 
[0.x.9724] 
[0.x.9725] 
[0.x.9726] 
[0.x.9727] 
[0.x.9728] 
//
// Next are the functions that return the coefficient values for given materials and energy groups. All they do is to make sure that the given arguments are within the allowed ranges, and then look the respective value up in the corresponding tables:
//
[0.x.9729] 
[0.x.9730] 
[0.x.9731] 
[0.x.9732] 
[0.x.9733] 
[0.x.9734] 
[0.x.9735] 
//
[0.x.9736] 
[0.x.9737] 
//
[0.x.9738] 
[0.x.9739] 
[0.x.9740] 
[0.x.9741] 
[0.x.9742] 
[0.x.9743] 
//
[0.x.9744] 
[0.x.9745] 
//
[0.x.9746] 
[0.x.9747] 
[0.x.9748] 
[0.x.9749] 
[0.x.9750] 
[0.x.9751] 
//
[0.x.9752] 
[0.x.9753] 
//
[0.x.9754] 
[0.x.9755] 
[0.x.9756] 
[0.x.9757] 
[0.x.9758] 
[0.x.9759] 
[0.x.9760] 
[0.x.9761] 
//
[0.x.9762] 
[0.x.9763] 
//
[0.x.9764] 
[0.x.9765] 
[0.x.9766] 
[0.x.9767] 
[0.x.9768] 
[0.x.9769] 
[0.x.9770] 
//
[0.x.9771] 
[0.x.9772] 
//
// The function computing the fission distribution cross section is slightly different, since it computes its value as the product of two other coefficients. We don't need to check arguments here, since this already happens when we call the two other functions involved, even though it would probably not hurt either:
//
[0.x.9773] 
[0.x.9774] 
[0.x.9775] 
[0.x.9776] 
[0.x.9777] 
[0.x.9778] 
[0.x.9779] 
//
//  [2.x.1425] 
//
// The first interesting class is the one that contains everything that is specific to a single energy group. To group things that belong together into individual objects, we declare a structure that holds the Triangulation and DoFHandler objects for the mesh used for a single energy group, and a number of other objects and member functions that we will discuss in the following sections.
//
// The main reason for this class is as follows: for both the forward problem (with a specified right hand side) as well as for the eigenvalue problem, one typically solves a sequence of problems for a single energy group each, rather than the fully coupled problem. This becomes understandable once one realizes that the system matrix for a single energy group is symmetric and positive definite (it is simply a diffusion operator), whereas the matrix for the fully coupled problem is generally nonsymmetric and not definite. It is also very large and quite full if more than a few energy groups are involved.
//
// Let us first look at the equation to solve in the case of an external right hand side (for the time independent case): [1.x.41]
//
// We would typically solve this equation by moving all the terms on the right hand side with  [2.x.1426]  to the left hand side, and solving for  [2.x.1427] . Of course, we don't know  [2.x.1428]  yet, since the equations for those variables include right hand side terms involving  [2.x.1429] . What one typically does in such situations is to iterate: compute [1.x.42]
//
// In other words, we solve the equation one by one, using values for  [2.x.1430]  from the previous iteration  [2.x.1431]  if  [2.x.1432]  and already computed values for  [2.x.1433]  from the present iteration if  [2.x.1434] .
//
// When computing the eigenvalue, we do a very similar iteration, except that we have no external right hand side and that the solution is scaled after each iteration as explained in the introduction.
//
// In either case, these two cases can be treated jointly if all we do is to equip the following class with these abilities: (i) form the left hand side matrix, (ii) form the in-group right hand side contribution, i.e. involving the extraneous source, and (iii) form that contribution to the right hand side that stems from group  [2.x.1435] . This class does exactly these tasks (as well as some book-keeping, such as mesh refinement, setting up matrices and vectors, etc). On the other hand, the class itself has no idea how many energy groups there are, and in particular how they interact, i.e. the decision of how the outer iteration looks (and consequently whether we solve an eigenvalue or a direct problem) is left to the NeutronDiffusionProblem class further down below in this program.
//
// So let us go through the class and its interface:
//
[0.x.9780] 
[0.x.9781] 
[0.x.9782] 
[0.x.9783] 
//[2.x.1436] 
//
// The class has a good number of public member functions, since its the way it operates is controlled from the outside, and therefore all functions that do something significant need to be called from another class. Let's start off with book-keeping: the class obviously needs to know which energy group it represents, which material data to use, and from what coarse grid to start. The constructor takes this information and initializes the relevant member variables with that (see below).
//
// Then we also need functions that set up the linear system, i.e. correctly size the matrix and its sparsity pattern, etc, given a finite element object to use. The  [2.x.1437]  function does that. Finally, for this initial block, there are two functions that return the number of active cells and degrees of freedom used in this object -- using this, we can make the triangulation and DoF handler member variables private, and do not have to grant external use to it, enhancing encapsulation:
//
[0.x.9784] 
[0.x.9785] 
[0.x.9786] 
[0.x.9787] 
//
[0.x.9788] 
//
[0.x.9789] 
[0.x.9790] 
//
// Then there are functions that assemble the linear system for each iteration and the present energy group. Note that the matrix is independent of the iteration number, so only has to be computed once for each refinement cycle. The situation is a bit more involved for the right hand side that has to be updated in each inverse power iteration, and that is further complicated by the fact that computing it may involve several different meshes as explained in the introduction. To make things more flexible with regard to solving the forward or the eigenvalue problem, we split the computation of the right hand side into a function that assembles the extraneous source and in-group contributions (which we will call with a zero function as source terms for the eigenvalue problem) and one that computes contributions to the right hand side from another energy group:
//
[0.x.9791] 
[0.x.9792] 
[0.x.9793] 
//
// Next we need a set of functions that actually compute the solution of a linear system, and do something with it (such as computing the fission source contribution mentioned in the introduction, writing graphical information to an output file, computing error indicators, or actually refining the grid based on these criteria and thresholds for refinement and coarsening). All these functions will later be called from the driver class  [2.x.1438] , or any other class you may want to implement to solve a problem involving the neutron flux equations:
//
[0.x.9794] 
//
[0.x.9795] 
//
[0.x.9796] 
//
[0.x.9797] 
//
[0.x.9798] 
[0.x.9799] 
[0.x.9800] 
//[2.x.1439] 
//
// As is good practice in object oriented programming, we hide most data members by making them private. However, we have to grant the class that drives the process access to the solution vector as well as the solution of the previous iteration, since in the power iteration, the solution vector is scaled in every iteration by the present guess of the eigenvalue we are looking for:
//
[0.x.9801] 
[0.x.9802] 
[0.x.9803] 
//[2.x.1440] 
//
// The rest of the data members are private. Compared to all the previous tutorial programs, the only new data members are an integer storing which energy group this object represents, and a reference to the material data object that this object's constructor gets passed from the driver class. Likewise, the constructor gets a reference to the finite element object we are to use.
//
// Finally, we have to apply boundary values to the linear system in each iteration, i.e. quite frequently. Rather than interpolating them every time, we interpolate them once on each new mesh and then store them along with all the other data of this class:
//
[0.x.9804] 
[0.x.9805] 
[0.x.9806] 
//
[0.x.9807] 
[0.x.9808] 
[0.x.9809] 
//
[0.x.9810] 
[0.x.9811] 
//
[0.x.9812] 
//
[0.x.9813] 
[0.x.9814] 
//[2.x.1441] 
//
// There is one private member function in this class. It recursively walks over cells of two meshes to compute the cross-group right hand side terms. The algorithm for this is explained in the introduction to this program. The arguments to this function are a reference to an object representing the energy group against which we want to integrate a right hand side term, an iterator to a cell of the mesh used for the present energy group, an iterator to a corresponding cell on the other mesh, and the matrix that interpolates the degrees of freedom from the coarser of the two cells to the finer one:
//
[0.x.9815] 
[0.x.9816] 
[0.x.9817] 
[0.x.9818] 
[0.x.9819] 
[0.x.9820] 
[0.x.9821] 
//[2.x.1442] 
//
// The first few functions of this class are mostly self-explanatory. The constructor only sets a few data members and creates a copy of the given triangulation as the base for the triangulation used for this energy group. The next two functions simply return data from private data members, thereby enabling us to make these data members private.
//
[0.x.9822] 
[0.x.9823] 
[0.x.9824] 
[0.x.9825] 
[0.x.9826] 
[0.x.9827] 
[0.x.9828] 
[0.x.9829] 
[0.x.9830] 
[0.x.9831] 
[0.x.9832] 
[0.x.9833] 
[0.x.9834] 
//
[0.x.9835] 
[0.x.9836] 
[0.x.9837] 
[0.x.9838] 
[0.x.9839] 
//
[0.x.9840] 
[0.x.9841] 
[0.x.9842] 
[0.x.9843] 
[0.x.9844] 
//
//  [2.x.1443] 
//
// The first "real" function is the one that sets up the mesh, matrices, etc, on the new mesh or after mesh refinement. We use this function to initialize sparse system matrices, and the right hand side vector. If the solution vector has never been set before (as indicated by a zero size), we also initialize it and set it to a default value. We don't do that if it already has a non-zero size (i.e. this function is called after mesh refinement) since in that case we want to preserve the solution across mesh refinement (something we do in the  [2.x.1444]  function).
//
[0.x.9845] 
[0.x.9846] 
[0.x.9847] 
[0.x.9848] 
//
[0.x.9849] 
[0.x.9850] 
[0.x.9851] 
[0.x.9852] 
//
[0.x.9853] 
//
[0.x.9854] 
[0.x.9855] 
[0.x.9856] 
[0.x.9857] 
//
[0.x.9858] 
//
[0.x.9859] 
//
[0.x.9860] 
[0.x.9861] 
[0.x.9862] 
[0.x.9863] 
[0.x.9864] 
[0.x.9865] 
[0.x.9866] 
//
// At the end of this function, we update the list of boundary nodes and their values, by first clearing this list and the re-interpolating boundary values (remember that this function is called after first setting up the mesh, and each time after mesh refinement).
//
// To understand the code, it is necessary to realize that we create the mesh using the  [2.x.1445]  function (in  [2.x.1446] ) where we set the last parameter to  [2.x.1447] . This means that boundaries of the domain are "colored", i.e. the four (or six, in 3d) sides of the domain are assigned different boundary indicators. As it turns out, the bottom boundary gets indicator zero, the top one boundary indicator one, and left and right boundaries get indicators two and three, respectively.
//
// In this program, we simulate only one, namely the top right, quarter of a reactor. That is, we want to interpolate boundary conditions only on the top and right boundaries, while do nothing on the bottom and left boundaries (i.e. impose natural, no-flux Neumann boundary conditions). This is most easily generalized to arbitrary dimension by saying that we want to interpolate on those boundaries with indicators 1, 3, ..., which we do in the following loop (note that calls to  [2.x.1448]  are additive, i.e. they do not first clear the boundary value map):
//
[0.x.9867] 
//
[0.x.9868] 
[0.x.9869] 
[0.x.9870] 
[0.x.9871] 
[0.x.9872] 
[0.x.9873] 
//
//  [2.x.1449] 
//
// Next we need functions assembling the system matrix and right hand sides. Assembling the matrix is straightforward given the equations outlined in the introduction as well as what we've seen in previous example programs. Note the use of  [2.x.1450]  to get at the kind of material from which a cell is made up of. Note also how we set the order of the quadrature formula so that it is always appropriate for the finite element in use.
//
// Finally, note that since we only assemble the system matrix here, we can't yet eliminate boundary values (we need the right hand side vector for this). We defer this to the  [2.x.1451]  function, at which point all the information is available.
//
[0.x.9874] 
[0.x.9875] 
[0.x.9876] 
[0.x.9877] 
//
[0.x.9878] 
[0.x.9879] 
[0.x.9880] 
[0.x.9881] 
//
[0.x.9882] 
[0.x.9883] 
//
[0.x.9884] 
[0.x.9885] 
//
[0.x.9886] 
//
[0.x.9887] 
[0.x.9888] 
[0.x.9889] 
//
[0.x.9890] 
//
[0.x.9891] 
[0.x.9892] 
[0.x.9893] 
[0.x.9894] 
//
[0.x.9895] 
[0.x.9896] 
[0.x.9897] 
[0.x.9898] 
[0.x.9899] 
[0.x.9900] 
[0.x.9901] 
[0.x.9902] 
[0.x.9903] 
//
[0.x.9904] 
//
[0.x.9905] 
[0.x.9906] 
[0.x.9907] 
[0.x.9908] 
[0.x.9909] 
[0.x.9910] 
//
[0.x.9911] 
[0.x.9912] 
//
//  [2.x.1452] 
//
// As explained in the documentation of the  [2.x.1453]  class, we split assembling the right hand side into two parts: the ingroup and the cross-group couplings. First, we need a function to assemble the right hand side of one specific group here, i.e. including an extraneous source (that we will set to zero for the eigenvalue problem) as well as the ingroup fission contributions.  (In-group scattering has already been accounted for with the definition of removal cross section.) The function's workings are pretty standard as far as assembling right hand sides go, and therefore does not require more comments except that we mention that the right hand side vector is set to zero at the beginning of the function -- something we are not going to do for the cross-group terms that simply add to the right hand side vector.
//
[0.x.9913] 
[0.x.9914] 
[0.x.9915] 
[0.x.9916] 
[0.x.9917] 
//
[0.x.9918] 
//
[0.x.9919] 
[0.x.9920] 
//
[0.x.9921] 
[0.x.9922] 
[0.x.9923] 
[0.x.9924] 
//
[0.x.9925] 
[0.x.9926] 
[0.x.9927] 
//
[0.x.9928] 
//
[0.x.9929] 
[0.x.9930] 
[0.x.9931] 
//
[0.x.9932] 
//
[0.x.9933] 
[0.x.9934] 
//
[0.x.9935] 
[0.x.9936] 
//
[0.x.9937] 
//
[0.x.9938] 
//
[0.x.9939] 
[0.x.9940] 
[0.x.9941] 
[0.x.9942] 
[0.x.9943] 
[0.x.9944] 
//
[0.x.9945] 
[0.x.9946] 
[0.x.9947] 
[0.x.9948] 
//
//  [2.x.1454] 
//
// The more interesting function for assembling the right hand side vector for the equation of a single energy group is the one that couples energy group  [2.x.1455]  and  [2.x.1456] . As explained in the introduction, we first have to find the set of cells common to the meshes of the two energy groups. First we call  [2.x.1457]  to obtain this list of pairs of common cells from both meshes. Both cells in a pair may not be active but at least one of them is. We then hand each of these cell pairs off to a function that computes the right hand side terms recursively.
//
// Note that ingroup coupling is handled already before, so we exit the function early if  [2.x.1458] .
//
[0.x.9949] 
[0.x.9950] 
[0.x.9951] 
[0.x.9952] 
[0.x.9953] 
[0.x.9954] 
//
[0.x.9955] 
[0.x.9956] 
[0.x.9957] 
[0.x.9958] 
//
[0.x.9959] 
[0.x.9960] 
[0.x.9961] 
[0.x.9962] 
[0.x.9963] 
[0.x.9964] 
[0.x.9965] 
[0.x.9966] 
[0.x.9967] 
[0.x.9968] 
[0.x.9969] 
//
//  [2.x.1459] 
//
// This is finally the function that handles assembling right hand side terms on potentially different meshes recursively, using the algorithm described in the introduction. The function takes a reference to the object representing energy group  [2.x.1460] , as well as iterators to corresponding cells in the meshes for energy groups  [2.x.1461]  and  [2.x.1462] . At first, i.e. when this function is called from the one above, these two cells will be matching cells on two meshes; however, one of the two may be further refined, and we will call the function recursively with one of the two iterators replaced by one of the children of the original cell.
//
// The last argument is the matrix product matrix  [2.x.1463]  from the introduction that interpolates from the coarser of the two cells to the finer one. If the two cells match, then this is the identity matrix -- exactly what we pass to this function initially.
//
// The function has to consider two cases: that both of the two cells are not further refined, i.e. have no children, in which case we can finally assemble the right hand side contributions of this pair of cells; and that one of the two cells is further refined, in which case we have to keep recursing by looping over the children of the one cell that is not active. These two cases will be discussed below:
//
[0.x.9970] 
[0.x.9971] 
[0.x.9972] 
[0.x.9973] 
[0.x.9974] 
[0.x.9975] 
[0.x.9976] 
//
// The first case is that both cells are no further refined. In that case, we can assemble the relevant terms (see the introduction). This involves assembling the mass matrix on the finer of the two cells (in fact there are two mass matrices with different coefficients, one for the fission distribution cross section  [2.x.1464]  and one for the scattering cross section  [2.x.1465] ). This is straight forward, but note how we determine which of the two cells is the finer one by looking at the refinement level of the two cells:
//
[0.x.9977] 
[0.x.9978] 
[0.x.9979] 
[0.x.9980] 
//
[0.x.9981] 
[0.x.9982] 
[0.x.9983] 
//
[0.x.9984] 
[0.x.9985] 
[0.x.9986] 
[0.x.9987] 
//
[0.x.9988] 
[0.x.9989] 
[0.x.9990] 
[0.x.9991] 
//
[0.x.9992] 
[0.x.9993] 
[0.x.9994] 
[0.x.9995] 
//
[0.x.9996] 
[0.x.9997] 
[0.x.9998] 
[0.x.9999] 
//
[0.x.10000] 
[0.x.10001] 
[0.x.10002] 
[0.x.10003] 
[0.x.10004] 
[0.x.10005] 
[0.x.10006] 
[0.x.10007] 
[0.x.10008] 
[0.x.10009] 
[0.x.10010] 
//
// Now we have all the interpolation (prolongation) matrices as well as local mass matrices, so we only have to form the product [1.x.43] or [1.x.44] depending on which of the two cells is the finer. We do this using either the matrix-vector product provided by the  [2.x.1466]  function, or the product with the transpose matrix using  [2.x.1467] . After doing so, we transfer the result into the global right hand side vector of energy group  [2.x.1468] .
//
[0.x.10011] 
[0.x.10012] 
[0.x.10013] 
[0.x.10014] 
//
[0.x.10015] 
[0.x.10016] 
//
[0.x.10017] 
[0.x.10018] 
[0.x.10019] 
[0.x.10020] 
//
[0.x.10021] 
[0.x.10022] 
[0.x.10023] 
[0.x.10024] 
[0.x.10025] 
[0.x.10026] 
[0.x.10027] 
//
[0.x.10028] 
[0.x.10029] 
[0.x.10030] 
//
[0.x.10031] 
[0.x.10032] 
[0.x.10033] 
//
[0.x.10034] 
[0.x.10035] 
[0.x.10036] 
//
// The alternative is that one of the two cells is further refined. In that case, we have to loop over all the children, multiply the existing interpolation (prolongation) product of matrices from the left with the interpolation from the present cell to its child (using the matrix-matrix multiplication function  [2.x.1469] ), and then hand the result off to this very same function again, but with the cell that has children replaced by one of its children:
//
[0.x.10037] 
[0.x.10038] 
[0.x.10039] 
[0.x.10040] 
[0.x.10041] 
[0.x.10042] 
[0.x.10043] 
[0.x.10044] 
[0.x.10045] 
//
[0.x.10046] 
[0.x.10047] 
[0.x.10048] 
[0.x.10049] 
[0.x.10050] 
[0.x.10051] 
[0.x.10052] 
[0.x.10053] 
[0.x.10054] 
[0.x.10055] 
[0.x.10056] 
[0.x.10057] 
//[2.x.1470] 
//
// In the (inverse) power iteration, we use the integrated fission source to update the  [2.x.1471] -eigenvalue. Given its definition, the following function is essentially self-explanatory:
//
[0.x.10058] 
[0.x.10059] 
[0.x.10060] 
[0.x.10061] 
[0.x.10062] 
//
[0.x.10063] 
[0.x.10064] 
[0.x.10065] 
//
[0.x.10066] 
//
[0.x.10067] 
//
[0.x.10068] 
[0.x.10069] 
[0.x.10070] 
//
[0.x.10071] 
[0.x.10072] 
//
[0.x.10073] 
//
[0.x.10074] 
[0.x.10075] 
[0.x.10076] 
[0.x.10077] 
//
[0.x.10078] 
[0.x.10079] 
//[2.x.1472] 
//
// Next a function that solves the linear system assembled before. Things are pretty much standard, except that we delayed applying boundary values until we get here, since in all the previous functions we were still adding up contributions the right hand side vector.
//
[0.x.10080] 
[0.x.10081] 
[0.x.10082] 
[0.x.10083] 
[0.x.10084] 
[0.x.10085] 
[0.x.10086] 
[0.x.10087] 
//
[0.x.10088] 
[0.x.10089] 
[0.x.10090] 
//
[0.x.10091] 
[0.x.10092] 
//
[0.x.10093] 
//
[0.x.10094] 
[0.x.10095] 
//
//  [2.x.1473] 
//
// Mesh refinement is split into two functions. The first estimates the error for each cell, normalizes it by the magnitude of the solution, and returns it in the vector given as an argument. The calling function collects all error indicators from all energy groups, and computes thresholds for refining and coarsening cells.
//
[0.x.10096] 
[0.x.10097] 
[0.x.10098] 
[0.x.10099] 
[0.x.10100] 
[0.x.10101] 
[0.x.10102] 
[0.x.10103] 
[0.x.10104] 
[0.x.10105] 
[0.x.10106] 
//
//  [2.x.1474] 
//
// The second part is to refine the grid given the error indicators compute in the previous function and error thresholds above which cells shall be refined or below which cells shall be coarsened. Note that we do not use any of the functions in  [2.x.1475]  here, but rather set refinement flags ourselves.
//
// After setting these flags, we use the SolutionTransfer class to move the solution vector from the old to the new mesh. The procedure used here is described in detail in the documentation of that class:
//
[0.x.10107] 
[0.x.10108] 
[0.x.10109] 
[0.x.10110] 
[0.x.10111] 
[0.x.10112] 
[0.x.10113] 
[0.x.10114] 
[0.x.10115] 
[0.x.10116] 
//
[0.x.10117] 
//
[0.x.10118] 
[0.x.10119] 
//
[0.x.10120] 
[0.x.10121] 
[0.x.10122] 
//
[0.x.10123] 
[0.x.10124] 
//
// enforce constraints to make the interpolated solution conforming on the new mesh:
//
[0.x.10125] 
//
[0.x.10126] 
[0.x.10127] 
[0.x.10128] 
//[2.x.1476] 
//
// The last function of this class outputs meshes and solutions after each mesh iteration. This has been shown many times before. The only thing worth pointing out is the use of the  [2.x.1477]  function to convert an integer into its string representation. The second argument of that function denotes how many digits we shall use -- if this value was larger than one, then the number would be padded by leading zeros.
//
[0.x.10129] 
[0.x.10130] 
[0.x.10131] 
[0.x.10132] 
[0.x.10133] 
[0.x.10134] 
//
[0.x.10135] 
//
[0.x.10136] 
[0.x.10137] 
[0.x.10138] 
//
[0.x.10139] 
[0.x.10140] 
[0.x.10141] 
//
//  [2.x.1478] 
//
// This is the main class of the program, not because it implements all the functionality (in fact, most of it is implemented in the  [2.x.1479]  class) but because it contains the driving algorithm that determines what to compute and when. It is mostly as shown in many of the other tutorial programs in that it has a public  [2.x.1480]  function and private functions doing all the rest. In several places, we have to do something for all energy groups, in which case we will start tasks for each group to let these things run in parallel if deal.II was configured for multithreading.  For strategies of parallelization, take a look at the  [2.x.1481]  module.
//
// The biggest difference to previous example programs is that we also declare a nested class that has member variables for all the run-time parameters that can be passed to the program in an input file. Right now, these are the number of energy groups, the number of refinement cycles, the polynomial degree of the finite element to be used, and the tolerance used to determine when convergence of the inverse power iteration has occurred. In addition, we have a constructor of this class that sets all these values to their default values, a function  [2.x.1482]  that describes to the ParameterHandler class what parameters are accepted in the input file, and a function  [2.x.1483]  that can extract the values of these parameters from a ParameterHandler object. See also  [2.x.1484]  for another example of using ParameterHandler.
//
[0.x.10142] 
[0.x.10143] 
[0.x.10144] 
[0.x.10145] 
[0.x.10146] 
[0.x.10147] 
[0.x.10148] 
[0.x.10149] 
//
[0.x.10150] 
[0.x.10151] 
//
[0.x.10152] 
[0.x.10153] 
//
[0.x.10154] 
//
[0.x.10155] 
[0.x.10156] 
//
[0.x.10157] 
//
[0.x.10158] 
//
[0.x.10159] 
//[2.x.1485] 
//
// There are not that many member functions in this class since most of the functionality has been moved into the  [2.x.1486]  class and is simply called from the  [2.x.1487]  member function of this class. The ones that remain have self-explanatory names:
//
[0.x.10160] 
//
[0.x.10161] 
//
[0.x.10162] 
//[2.x.1488] 
//
// Next, we have a few member variables. In particular, these are (i) a reference to the parameter object (owned by the main function of this program, and passed to the constructor of this class), (ii) an object describing the material parameters for the number of energy groups requested in the input file, and (iii) the finite element to be used by all energy groups:
//
[0.x.10163] 
[0.x.10164] 
[0.x.10165] 
//
// Furthermore, we have (iv) the value of the computed eigenvalue at the present iteration. This is, in fact, the only part of the solution that is shared between all energy groups -- all other parts of the solution, such as neutron fluxes are particular to one or the other energy group, and are therefore stored in objects that describe a single energy group:
//
[0.x.10166] 
//
// The last computational object (v) is an array of pointers to the energy group objects. The length of this array is, of course, equal to the number of energy groups specified in the parameter file.
//
[0.x.10167] 
//
// Finally (vi) we have a file stream to which we will save summarized output.
//
[0.x.10168] 
[0.x.10169] 
//[2.x.1489] 
//
// Before going on to the implementation of the outer class, we have to implement the functions of the parameters structure. This is pretty straightforward and, in fact, looks pretty much the same for all such parameters classes using the ParameterHandler capabilities. We will therefore not comment further on this:
//
[0.x.10170] 
[0.x.10171] 
[0.x.10172] 
[0.x.10173] 
[0.x.10174] 
[0.x.10175] 
[0.x.10176] 
//
[0.x.10177] 
[0.x.10178] 
[0.x.10179] 
[0.x.10180] 
[0.x.10181] 
[0.x.10182] 
[0.x.10183] 
[0.x.10184] 
[0.x.10185] 
[0.x.10186] 
[0.x.10187] 
[0.x.10188] 
[0.x.10189] 
[0.x.10190] 
[0.x.10191] 
[0.x.10192] 
[0.x.10193] 
[0.x.10194] 
[0.x.10195] 
[0.x.10196] 
[0.x.10197] 
[0.x.10198] 
[0.x.10199] 
//
[0.x.10200] 
[0.x.10201] 
[0.x.10202] 
[0.x.10203] 
[0.x.10204] 
[0.x.10205] 
[0.x.10206] 
[0.x.10207] 
[0.x.10208] 
//
//  [2.x.1490] 
//
// Now for the  [2.x.1491]  class. The constructor and destructor have nothing of much interest:
//
[0.x.10209] 
[0.x.10210] 
[0.x.10211] 
[0.x.10212] 
[0.x.10213] 
[0.x.10214] 
[0.x.10215] 
[0.x.10216] 
//
//  [2.x.1492] 
//
// The first function of interest is the one that sets up the geometry of the reactor core. This is described in more detail in the introduction.
//
// The first part of the function defines geometry data, and then creates a coarse mesh that has as many cells as there are fuel rods (or pin cells, for that matter) in that part of the reactor core that we simulate. As mentioned when interpolating boundary values above, the last parameter to the  [2.x.1493]  function specifies that sides of the domain shall have unique boundary indicators that will later allow us to determine in a simple way which of the boundaries have Neumann and which have Dirichlet conditions attached to them.
//
[0.x.10217] 
[0.x.10218] 
[0.x.10219] 
[0.x.10220] 
[0.x.10221] 
[0.x.10222] 
//
[0.x.10223] 
//
[0.x.10224] 
[0.x.10225] 
[0.x.10226] 
[0.x.10227] 
[0.x.10228] 
[0.x.10229] 
[0.x.10230] 
//
[0.x.10231] 
[0.x.10232] 
[0.x.10233] 
[0.x.10234] 
[0.x.10235] 
[0.x.10236] 
//
[0.x.10237] 
[0.x.10238] 
[0.x.10239] 
//
// The second part of the function deals with material numbers of pin cells of each type of assembly. Here, we define four different types of assembly, for which we describe the arrangement of fuel rods in the following tables.
//
// The assemblies described here are taken from the benchmark mentioned in the introduction and are (in this order):  [2.x.1494] 
//[2.x.1495] 'UX' Assembly: UO2 fuel assembly with 24 guide tubes and a central Moveable Fission Chamber  [2.x.1496] 'UA' Assembly: UO2 fuel assembly with 24 AIC and a central Moveable Fission Chamber  [2.x.1497] 'PX' Assembly: MOX fuel assembly with 24 guide tubes and a central Moveable Fission Chamber  [2.x.1498] 'R' Assembly: a reflector.   [2.x.1499] 
//
// Note that the numbers listed here and taken from the benchmark description are, in good old Fortran fashion, one-based. We will later subtract one from each number when assigning materials to individual cells to convert things into the C-style zero-based indexing.
//
[0.x.10240] 
[0.x.10241] 
[0.x.10242] 
[0.x.10243] 
[0.x.10244] 
[0.x.10245] 
[0.x.10246] 
[0.x.10247] 
[0.x.10248] 
[0.x.10249] 
[0.x.10250] 
[0.x.10251] 
[0.x.10252] 
[0.x.10253] 
[0.x.10254] 
[0.x.10255] 
[0.x.10256] 
[0.x.10257] 
[0.x.10258] 
[0.x.10259] 
[0.x.10260] 
[0.x.10261] 
[0.x.10262] 
[0.x.10263] 
[0.x.10264] 
[0.x.10265] 
[0.x.10266] 
[0.x.10267] 
[0.x.10268] 
[0.x.10269] 
[0.x.10270] 
[0.x.10271] 
[0.x.10272] 
[0.x.10273] 
[0.x.10274] 
[0.x.10275] 
[0.x.10276] 
[0.x.10277] 
[0.x.10278] 
[0.x.10279] 
[0.x.10280] 
[0.x.10281] 
[0.x.10282] 
[0.x.10283] 
[0.x.10284] 
[0.x.10285] 
[0.x.10286] 
[0.x.10287] 
[0.x.10288] 
[0.x.10289] 
[0.x.10290] 
[0.x.10291] 
[0.x.10292] 
[0.x.10293] 
[0.x.10294] 
[0.x.10295] 
[0.x.10296] 
[0.x.10297] 
[0.x.10298] 
[0.x.10299] 
[0.x.10300] 
[0.x.10301] 
[0.x.10302] 
[0.x.10303] 
[0.x.10304] 
[0.x.10305] 
[0.x.10306] 
[0.x.10307] 
[0.x.10308] 
[0.x.10309] 
[0.x.10310] 
//
// After the description of the materials that make up an assembly, we have to specify the arrangement of assemblies within the core. We use a symmetric pattern that in fact only uses the 'UX' and 'PX' assemblies:
//
[0.x.10311] 
[0.x.10312] 
//
// We are now in a position to actually set material IDs for each cell. To this end, we loop over all cells, look at the location of the cell's center, and determine which assembly and fuel rod this would be in. (We add a few checks to see that the locations we compute are within the bounds of the arrays in which we have to look up materials.) At the end of the loop, we set material identifiers accordingly:
//
[0.x.10313] 
[0.x.10314] 
[0.x.10315] 
//
[0.x.10316] 
[0.x.10317] 
[0.x.10318] 
//
[0.x.10319] 
[0.x.10320] 
[0.x.10321] 
//
[0.x.10322] 
[0.x.10323] 
//
[0.x.10324] 
[0.x.10325] 
[0.x.10326] 
//
[0.x.10327] 
//
[0.x.10328] 
[0.x.10329] 
//
[0.x.10330] 
[0.x.10331] 
//
// With the coarse mesh so initialized, we create the appropriate number of energy group objects and let them initialize their individual meshes with the coarse mesh generated above:
//
[0.x.10332] 
[0.x.10333] 
[0.x.10334] 
[0.x.10335] 
[0.x.10336] 
[0.x.10337] 
//[2.x.1500] 
//
// In the eigenvalue computation, we need to calculate total fission neutron source after each power iteration. The total power then is used to renew k-effective.
//
// Since the total fission source is a sum over all the energy groups, and since each of these sums can be computed independently, we actually do this in parallel. One of the problems is that the function in the  [2.x.1501]  class that computes the fission source returns a value. We would like to add these values together in the loop itself: ideally, each task would compute its value and then immediately add it to the total. Concurrently summing values in this way requires two features:  [2.x.1502] 
//[2.x.1503] We need a way of storing a value such that multiple threads can   read and write into concurrently in a way that prevents data races   (i.e., thread-safe reading and writing). [2.x.1504] 
//[2.x.1505] We need a way to increment such a value that is also   thread-safe. [2.x.1506] 
//[2.x.1507] 
//
// The first feature is available through the template class  [2.x.1508] . However, the second feature, implemented by  [2.x.1509] , is only available in C++20 and later: since deal.II supports older versions of the C++ language standard we cannot use this feature yet. Hence, instead, we simply write each group's value out to an entry in a vector and sum the values at the end of the function.
//
[0.x.10338] 
[0.x.10339] 
[0.x.10340] 
[0.x.10341] 
[0.x.10342] 
[0.x.10343] 
[0.x.10344] 
[0.x.10345] 
[0.x.10346] 
[0.x.10347] 
//
[0.x.10348] 
[0.x.10349] 
//
//  [2.x.1510] 
//
// The next function lets the individual energy group objects refine their meshes. Much of this, again, is a task that can be done independently in parallel: first, let all the energy group objects calculate their error indicators in parallel, then compute the maximum error indicator over all energy groups and determine thresholds for refinement and coarsening of cells, and then ask all the energy groups to refine their meshes accordingly, again in parallel.
//
[0.x.10350] 
[0.x.10351] 
[0.x.10352] 
[0.x.10353] 
[0.x.10354] 
[0.x.10355] 
//
[0.x.10356] 
//
[0.x.10357] 
[0.x.10358] 
[0.x.10359] 
[0.x.10360] 
[0.x.10361] 
[0.x.10362] 
[0.x.10363] 
[0.x.10364] 
//
// The destructor of  [2.x.1511]  joins all threads so we know that the computation is done by the time we exit the scope.
//
[0.x.10365] 
[0.x.10366] 
[0.x.10367] 
//
[0.x.10368] 
[0.x.10369] 
[0.x.10370] 
[0.x.10371] 
[0.x.10372] 
[0.x.10373] 
[0.x.10374] 
[0.x.10375] 
[0.x.10376] 
[0.x.10377] 
//[2.x.1512] 
//
// Finally, this is the function where the meat is: iterate on a sequence of meshes, and on each of them do a power iteration to compute the eigenvalue.
//
// Given the description of the algorithm in the introduction, there is actually not much to comment on:
//
[0.x.10378] 
[0.x.10379] 
[0.x.10380] 
//
// We would like to change the output precision for just this function and restore the state of  [2.x.1513]  when this function returns. Hence, we need a way to undo the output format change. Boost provides a convenient way to save the state of an output stream and restore it at the end of the current block (when the destructor of  [2.x.1514]  is called) with the  [2.x.1515]  class, which we use here.
//
[0.x.10381] 
[0.x.10382] 
//
// We calculate the error below by the change in k_eff (i.e., the difference between k_eff_old,
//
[0.x.10383] 
//
[0.x.10384] 
[0.x.10385] 
[0.x.10386] 
//
// We will measure the CPU time that each cycle takes below. The constructor for Timer calls  [2.x.1516]  so once we create a timer we can query it for information. Since many parts of this loop are parallelized with tasks, the CPU time we measure (if we run with more than one thread) will be larger than the wall time.
//
[0.x.10387] 
//
[0.x.10388] 
//
[0.x.10389] 
[0.x.10390] 
[0.x.10391] 
[0.x.10392] 
[0.x.10393] 
[0.x.10394] 
//
[0.x.10395] 
[0.x.10396] 
[0.x.10397] 
[0.x.10398] 
[0.x.10399] 
[0.x.10400] 
//
[0.x.10401] 
[0.x.10402] 
[0.x.10403] 
[0.x.10404] 
[0.x.10405] 
[0.x.10406] 
[0.x.10407] 
[0.x.10408] 
//
[0.x.10409] 
[0.x.10410] 
[0.x.10411] 
[0.x.10412] 
[0.x.10413] 
//
[0.x.10414] 
[0.x.10415] 
[0.x.10416] 
[0.x.10417] 
[0.x.10418] 
[0.x.10419] 
[0.x.10420] 
[0.x.10421] 
//
[0.x.10422] 
[0.x.10423] 
[0.x.10424] 
[0.x.10425] 
//
[0.x.10426] 
[0.x.10427] 
//
[0.x.10428] 
[0.x.10429] 
[0.x.10430] 
[0.x.10431] 
[0.x.10432] 
[0.x.10433] 
[0.x.10434] 
[0.x.10435] 
[0.x.10436] 
[0.x.10437] 
//
[0.x.10438] 
[0.x.10439] 
[0.x.10440] 
[0.x.10441] 
[0.x.10442] 
[0.x.10443] 
//
[0.x.10444] 
[0.x.10445] 
[0.x.10446] 
[0.x.10447] 
[0.x.10448] 
[0.x.10449] 
[0.x.10450] 
[0.x.10451] 
[0.x.10452] 
//
[0.x.10453] 
[0.x.10454] 
//
// Print out information about the simulation as well as the elapsed CPU time. We can call  [2.x.1517]  without first calling  [2.x.1518]  to get the elapsed CPU time at the point of calling the function.
//
[0.x.10455] 
[0.x.10456] 
[0.x.10457] 
[0.x.10458] 
[0.x.10459] 
//
[0.x.10460] 
[0.x.10461] 
[0.x.10462] 
[0.x.10463] 
//
//  [2.x.1519] 
//
// The last thing in the program in the  [2.x.1520]  function. The structure is as in most other tutorial programs, with the only exception that we here handle a parameter file.  To this end, we first look at the command line arguments passed to this function: if no input file is specified on the command line, then use "project.prm", otherwise take the filename given as the first argument on the command line.
//
// With this, we create a ParameterHandler object, let the  [2.x.1521]  class declare all the parameters it wants to see in the input file (or, take the default values, if nothing is listed in the parameter file), then read the input file, ask the parameters object to extract the values, and finally hand everything off to an object of type  [2.x.1522]  for computation of the eigenvalue:
//
[0.x.10464] 
[0.x.10465] 
[0.x.10466] 
[0.x.10467] 
[0.x.10468] 
[0.x.10469] 
//
[0.x.10470] 
[0.x.10471] 
[0.x.10472] 
[0.x.10473] 
[0.x.10474] 
//
[0.x.10475] 
//
[0.x.10476] 
//
[0.x.10477] 
[0.x.10478] 
//
[0.x.10479] 
//
[0.x.10480] 
//
[0.x.10481] 
[0.x.10482] 
[0.x.10483] 
[0.x.10484] 
[0.x.10485] 
[0.x.10486] 
[0.x.10487] 
[0.x.10488] 
[0.x.10489] 
[0.x.10490] 
[0.x.10491] 
[0.x.10492] 
[0.x.10493] 
[0.x.10494] 
//
[0.x.10495] 
[0.x.10496] 
[0.x.10497] 
[0.x.10498] 
[0.x.10499] 
[0.x.10500] 
[0.x.10501] 
[0.x.10502] 
[0.x.10503] 
[0.x.10504] 
[0.x.10505] 
[0.x.10506] 
[0.x.10507] 
[0.x.10508] 
//
[0.x.10509] 
[0.x.10510] 
[0.x.10511] 
[0.x.10512] 
[0.x.10513] 
[0.x.10514] 
[0.x.10515] 
[0.x.10516] 
[0.x.10517] 
[0.x.10518] 
[0.x.10519] 
[0.x.10520] 
[0.x.10521] 
[0.x.10522] 
[0.x.10523] 
[0.x.10524] 
//
[0.x.10525] 
[0.x.10526] 
[0.x.10527] 
//[2.x.1523] 
//
// The following header files have all been discussed before:
//
[0.x.10528] 
[0.x.10529] 
[0.x.10530] 
//
[0.x.10531] 
[0.x.10532] 
[0.x.10533] 
[0.x.10534] 
//
[0.x.10535] 
[0.x.10536] 
[0.x.10537] 
//
[0.x.10538] 
[0.x.10539] 
//
[0.x.10540] 
[0.x.10541] 
//
[0.x.10542] 
[0.x.10543] 
[0.x.10544] 
//
[0.x.10545] 
[0.x.10546] 
//
// This header file contains the necessary declarations for the ParameterHandler class that we will use to read our parameters from a configuration file:
//
[0.x.10547] 
//
// For solving the linear system, we'll use the sparse LU-decomposition provided by UMFPACK (see the SparseDirectUMFPACK class), for which the following header file is needed.  Note that in order to compile this tutorial program, the deal.II-library needs to be built with UMFPACK support, which is enabled by default:
//
[0.x.10548] 
//
// The FESystem class allows us to stack several FE-objects to one compound, vector-valued finite element field. The necessary declarations for this class are provided in this header file:
//
[0.x.10549] 
//
// Finally, include the header file that declares the Timer class that we will use to determine how much time each of the operations of our program takes:
//
[0.x.10550] 
//
// As the last step at the beginning of this program, we put everything that is in this program into its namespace and, within it, make everything that is in the deal.II namespace globally available, without the need to prefix everything with  [2.x.1524] :
//
[0.x.10551] 
[0.x.10552] 
[0.x.10553] 
//[2.x.1525] 
//
// First we define a class for the function representing the Dirichlet boundary values. This has been done many times before and therefore does not need much explanation.
//
// Since there are two values  [2.x.1526]  and  [2.x.1527]  that need to be prescribed at the boundary, we have to tell the base class that this is a vector-valued function with two components, and the  [2.x.1528]  function and its cousin  [2.x.1529]  must return vectors with two entries. In our case the function is very simple, it just returns 1 for the real part  [2.x.1530]  and 0 for the imaginary part  [2.x.1531]  regardless of the point where it is evaluated.
//
[0.x.10554] 
[0.x.10555] 
[0.x.10556] 
[0.x.10557] 
[0.x.10558] 
[0.x.10559] 
[0.x.10560] 
//
[0.x.10561] 
[0.x.10562] 
[0.x.10563] 
[0.x.10564] 
//
[0.x.10565] 
[0.x.10566] 
[0.x.10567] 
//
[0.x.10568] 
[0.x.10569] 
[0.x.10570] 
[0.x.10571] 
[0.x.10572] 
[0.x.10573] 
//
[0.x.10574] 
[0.x.10575] 
[0.x.10576] 
[0.x.10577] 
//[2.x.1532] 
//
// The next class is responsible for preparing the ParameterHandler object and reading parameters from an input file.  It includes a function  [2.x.1533]  that declares all the necessary parameters and a  [2.x.1534]  function that is called from outside to initiate the parameter reading process.
//
[0.x.10578] 
[0.x.10579] 
[0.x.10580] 
[0.x.10581] 
[0.x.10582] 
//
[0.x.10583] 
[0.x.10584] 
[0.x.10585] 
[0.x.10586] 
//
// The constructor stores a reference to the ParameterHandler object that is passed to it:
//
[0.x.10587] 
[0.x.10588] 
[0.x.10589] 
//[2.x.1535] 
//
// The  [2.x.1536]  function declares all the parameters that our ParameterHandler object will be able to read from input files, along with their types, range conditions and the subsections they appear in. We will wrap all the entries that go into a section in a pair of braces to force the editor to indent them by one level, making it simpler to read which entries together form a section:
//
[0.x.10590] 
[0.x.10591] 
//
// Parameters for mesh and geometry include the number of global refinement steps that are applied to the initial coarse mesh and the focal distance  [2.x.1537]  of the transducer lens. For the number of refinement steps, we allow integer values in the range  [2.x.1538] , where the omitted second argument to the  [2.x.1539]  object denotes the half-open interval.  For the focal distance any number greater than zero is accepted:
//
[0.x.10592] 
[0.x.10593] 
[0.x.10594] 
[0.x.10595] 
[0.x.10596] 
[0.x.10597] 
[0.x.10598] 
//
[0.x.10599] 
[0.x.10600] 
[0.x.10601] 
[0.x.10602] 
[0.x.10603] 
[0.x.10604] 
[0.x.10605] 
//
// The next subsection is devoted to the physical parameters appearing in the equation, which are the frequency  [2.x.1540]  and wave speed  [2.x.1541] . Again, both need to lie in the half-open interval  [2.x.1542]  represented by calling the  [2.x.1543]  class with only the left end-point as argument:
//
[0.x.10606] 
[0.x.10607] 
[0.x.10608] 
//
[0.x.10609] 
[0.x.10610] 
[0.x.10611] 
//
// Last but not least we would like to be able to change some properties of the output, like filename and format, through entries in the configuration file, which is the purpose of the last subsection:
//
[0.x.10612] 
[0.x.10613] 
[0.x.10614] 
[0.x.10615] 
[0.x.10616] 
[0.x.10617] 
//
// Since different output formats may require different parameters for generating output (like for example, postscript output needs viewpoint angles, line widths, colors etc), it would be cumbersome if we had to declare all these parameters by hand for every possible output format supported in the library. Instead, each output format has a  [2.x.1544]  function, which declares all the parameters specific to that format in an own subsection. The following call of  [2.x.1545]  executes  [2.x.1546]  for all available output formats, so that for each format an own subsection will be created with parameters declared for that particular output format. (The actual value of the template parameter in the call,  [2.x.1547]  above, does not matter here: the function does the same work independent of the dimension, but happens to be in a template-parameter-dependent class.)  To find out what parameters there are for which output format, you can either consult the documentation of the DataOutBase class, or simply run this program without a parameter file present. It will then create a file with all declared parameters set to their default values, which can conveniently serve as a starting point for setting the parameters to the values you desire.
//
[0.x.10618] 
[0.x.10619] 
[0.x.10620] 
[0.x.10621] 
//[2.x.1548] 
//
// This is the main function in the ParameterReader class.  It gets called from outside, first declares all the parameters, and then reads them from the input file whose filename is provided by the caller. After the call to this function is complete, the  [2.x.1549]  object can be used to retrieve the values of the parameters read in from the file:
//
[0.x.10622] 
[0.x.10623] 
[0.x.10624] 
//
[0.x.10625] 
[0.x.10626] 
//
//  [2.x.1550] 
//
// As mentioned in the introduction, the quantity that we are really after is the spatial distribution of the intensity of the ultrasound wave, which corresponds to  [2.x.1551] . Now we could just be content with having  [2.x.1552]  and  [2.x.1553]  in our output, and use a suitable visualization or postprocessing tool to derive  [2.x.1554]  from the solution we computed. However, there is also a way to output data derived from the solution in deal.II, and we are going to make use of this mechanism here.
//
// So far we have always used the  [2.x.1555]  function to add vectors containing output data to a DataOut object.  There is a special version of this function that in addition to the data vector has an additional argument of type DataPostprocessor. What happens when this function is used for output is that at each point where output data is to be generated, the  [2.x.1556]  or  [2.x.1557]  function of the specified DataPostprocessor object is invoked to compute the output quantities from the values, the gradients and the second derivatives of the finite element function represented by the data vector (in the case of face related data, normal vectors are available as well). Hence, this allows us to output any quantity that can locally be derived from the values of the solution and its derivatives.  Of course, the ultrasound intensity  [2.x.1558]  is such a quantity and its computation doesn't even involve any derivatives of  [2.x.1559]  or  [2.x.1560] .
//
// In practice, the DataPostprocessor class only provides an interface to this functionality, and we need to derive our own class from it in order to implement the functions specified by the interface. In the most general case one has to implement several member functions but if the output quantity is a single scalar then some of this boilerplate code can be handled by a more specialized class, DataPostprocessorScalar and we can derive from that one instead. This is what the  [2.x.1561]  class does:
//
[0.x.10627] 
[0.x.10628] 
[0.x.10629] 
[0.x.10630] 
[0.x.10631] 
//
[0.x.10632] 
[0.x.10633] 
[0.x.10634] 
[0.x.10635] 
//
// In the constructor, we need to call the constructor of the base class with two arguments. The first denotes the name by which the single scalar quantity computed by this class should be represented in output files. In our case, the postprocessor has  [2.x.1562]  as output, so we use "Intensity".
//
// The second argument is a set of flags that indicate which data is needed by the postprocessor in order to compute the output quantities.  This can be any subset of update_values, update_gradients and update_hessians (and, in the case of face data, also update_normal_vectors), which are documented in UpdateFlags.  Of course, computation of the derivatives requires additional resources, so only the flags for data that are really needed should be given here, just as we do when we use FEValues objects. In our case, only the function values of  [2.x.1563]  and  [2.x.1564]  are needed to compute  [2.x.1565] , so we're good with the update_values flag.
//
[0.x.10636] 
[0.x.10637] 
[0.x.10638] 
[0.x.10639] 
//
// The actual postprocessing happens in the following function. Its input is an object that stores values of the function (which is here vector-valued) representing the data vector given to  [2.x.1566]  evaluated at all evaluation points where we generate output, and some tensor objects representing derivatives (that we don't use here since  [2.x.1567]  is computed from just  [2.x.1568]  and  [2.x.1569] ). The derived quantities are returned in the  [2.x.1570]  vector. Remember that this function may only use data for which the respective update flag is specified by  [2.x.1571] . For example, we may not use the derivatives here, since our implementation of  [2.x.1572]  requests that only function values are provided.
//
[0.x.10640] 
[0.x.10641] 
[0.x.10642] 
[0.x.10643] 
[0.x.10644] 
[0.x.10645] 
[0.x.10646] 
[0.x.10647] 
//
// The computation itself is straightforward: We iterate over each entry in the output vector and compute  [2.x.1573]  from the corresponding values of  [2.x.1574]  and  [2.x.1575] . We do this by creating a complex number  [2.x.1576]  and then calling  [2.x.1577]  on the result. (One may be tempted to call  [2.x.1578]  but in a historical quirk, the C++ committee decided that  [2.x.1579]  should return the [1.x.45] of the absolute value -- thereby not satisfying the properties mathematicians require of something called a "norm".)
//
[0.x.10648] 
[0.x.10649] 
[0.x.10650] 
[0.x.10651] 
[0.x.10652] 
[0.x.10653] 
//
[0.x.10654] 
[0.x.10655] 
//
[0.x.10656] 
[0.x.10657] 
[0.x.10658] 
//[2.x.1580] 
//
// Finally here is the main class of this program.  It's member functions are very similar to the previous examples, in particular  [2.x.1581] , and the list of member variables does not contain any major surprises either. The ParameterHandler object that is passed to the constructor is stored as a reference to allow easy access to the parameters from all functions of the class.  Since we are working with vector valued finite elements, the FE object we are using is of type FESystem.
//
[0.x.10659] 
[0.x.10660] 
[0.x.10661] 
[0.x.10662] 
[0.x.10663] 
[0.x.10664] 
//
[0.x.10665] 
[0.x.10666] 
[0.x.10667] 
[0.x.10668] 
[0.x.10669] 
[0.x.10670] 
//
[0.x.10671] 
//
[0.x.10672] 
[0.x.10673] 
[0.x.10674] 
//
[0.x.10675] 
[0.x.10676] 
[0.x.10677] 
[0.x.10678] 
//
// The constructor takes the ParameterHandler object and stores it in a reference. It also initializes the DoF-Handler and the finite element system, which consists of two copies of the scalar Q1 field, one for  [2.x.1582]  and one for  [2.x.1583] :
//
[0.x.10679] 
[0.x.10680] 
[0.x.10681] 
[0.x.10682] 
[0.x.10683] 
[0.x.10684] 
//[2.x.1584] 
//
// Here we setup the grid for our domain.  As mentioned in the exposition, the geometry is just a unit square (in 2d) with the part of the boundary that represents the transducer lens replaced by a sector of a circle.
//
[0.x.10685] 
[0.x.10686] 
[0.x.10687] 
//
// First we generate some logging output and start a timer so we can compute execution time when this function is done:
//
[0.x.10688] 
[0.x.10689] 
//
// Then we query the values for the focal distance of the transducer lens and the number of mesh refinement steps from our ParameterHandler object:
//
[0.x.10690] 
//
[0.x.10691] 
[0.x.10692] 
//
[0.x.10693] 
//
// Next, two points are defined for position and focal point of the transducer lens, which is the center of the circle whose segment will form the transducer part of the boundary. Notice that this is the only point in the program where things are slightly different in 2D and 3D. Even though this tutorial only deals with the 2D case, the necessary additions to make this program functional in 3D are so minimal that we opt for including them:
//
[0.x.10694] 
[0.x.10695] 
[0.x.10696] 
[0.x.10697] 
[0.x.10698] 
//
// As initial coarse grid we take a simple unit square with 5 subdivisions in each direction. The number of subdivisions is chosen so that the line segment  [2.x.1585]  that we want to designate as the transducer boundary is spanned by a single face. Then we step through all cells to find the faces where the transducer is to be located, which in fact is just the single edge from 0.4 to 0.6 on the x-axis. This is where we want the refinements to be made according to a circle shaped boundary, so we mark this edge with a different manifold indicator. Since we will Dirichlet boundary conditions on the transducer, we also change its boundary indicator.
//
[0.x.10699] 
//
[0.x.10700] 
[0.x.10701] 
[0.x.10702] 
[0.x.10703] 
[0.x.10704] 
[0.x.10705] 
[0.x.10706] 
[0.x.10707] 
//
// For the circle part of the transducer lens, a SphericalManifold object is used (which, of course, in 2D just represents a circle), with center computed as above.
//
[0.x.10708] 
//
// Now global refinement is executed. Cells near the transducer location will be automatically refined according to the circle shaped boundary of the transducer lens:
//
[0.x.10709] 
//
// Lastly, we generate some more logging output. We stop the timer and query the number of CPU seconds elapsed since the beginning of the function:
//
[0.x.10710] 
[0.x.10711] 
//
[0.x.10712] 
[0.x.10713] 
[0.x.10714] 
//[2.x.1586] 
//
// Initialization of the system matrix, sparsity patterns and vectors are the same as in previous examples and therefore do not need further comment. As in the previous function, we also output the run time of what we do here:
//
[0.x.10715] 
[0.x.10716] 
[0.x.10717] 
[0.x.10718] 
[0.x.10719] 
//
[0.x.10720] 
//
[0.x.10721] 
[0.x.10722] 
[0.x.10723] 
//
[0.x.10724] 
[0.x.10725] 
[0.x.10726] 
//
[0.x.10727] 
[0.x.10728] 
//
[0.x.10729] 
[0.x.10730] 
[0.x.10731] 
//[2.x.1587] 
//
// As before, this function takes care of assembling the system matrix and right hand side vector:
//
[0.x.10732] 
[0.x.10733] 
[0.x.10734] 
[0.x.10735] 
[0.x.10736] 
//
// First we query wavespeed and frequency from the ParameterHandler object and store them in local variables, as they will be used frequently throughout this function.
//
[0.x.10737] 
//
[0.x.10738] 
//
[0.x.10739] 
//
// As usual, for computing integrals ordinary Gauss quadrature rule is used. Since our bilinear form involves boundary integrals on  [2.x.1588] , we also need a quadrature rule for surface integration on the faces, which are  [2.x.1589]  dimensional:
//
[0.x.10740] 
[0.x.10741] 
//
[0.x.10742] 
[0.x.10743] 
[0.x.10744] 
//
// The FEValues objects will evaluate the shape functions for us.  For the part of the bilinear form that involves integration on  [2.x.1590] , we'll need the values and gradients of the shape functions, and of course the quadrature weights.  For the terms involving the boundary integrals, only shape function values and the quadrature weights are necessary.
//
[0.x.10745] 
[0.x.10746] 
[0.x.10747] 
[0.x.10748] 
//
[0.x.10749] 
[0.x.10750] 
[0.x.10751] 
//
// As usual, the system matrix is assembled cell by cell, and we need a matrix for storing the local cell contributions as well as an index vector to transfer the cell contributions to the appropriate location in the global system matrix after.
//
[0.x.10752] 
[0.x.10753] 
//
[0.x.10754] 
[0.x.10755] 
//
// On each cell, we first need to reset the local contribution matrix and request the FEValues object to compute the shape functions for the current cell:
//
[0.x.10756] 
[0.x.10757] 
//
[0.x.10758] 
[0.x.10759] 
[0.x.10760] 
[0.x.10761] 
//
//       At this point, it is important to keep in mind that we are       dealing with a finite element system with two       components. Due to the way we constructed this FESystem,       namely as the Cartesian product of two scalar finite       element fields, each shape function has only a single       nonzero component (they are, in deal.II lingo,  [2.x.1591]        GlossPrimitive "primitive").  Hence, each shape function       can be viewed as one of the  [2.x.1592] 's or  [2.x.1593] 's from the       introduction, and similarly the corresponding degrees of       freedom can be attributed to either  [2.x.1594]  or  [2.x.1595] .       As we iterate through all the degrees of freedom on the       current cell however, they do not come in any particular       order, and so we cannot decide right away whether the DoFs       with index  [2.x.1596]  and  [2.x.1597]  belong to the real or imaginary part       of our solution.  On the other hand, if you look at the       form of the system matrix in the introduction, this       distinction is crucial since it will determine to which       block in the system matrix the contribution of the current       pair of DoFs will go and hence which quantity we need to       compute from the given two shape functions.  Fortunately,       the FESystem object can provide us with this information,       namely it has a function        [2.x.1598]  that for each local       DoF index returns a pair of integers of which the first       indicates to which component of the system the DoF       belongs. The second integer of the pair indicates which       index the DoF has in the scalar base finite element field,       but this information is not relevant here. If you want to       know more about this function and the underlying scheme       behind primitive vector valued elements, take a look at        [2.x.1599]  or the  [2.x.1600]  module, where these topics       are explained in depth.
//
[0.x.10762] 
[0.x.10763] 
[0.x.10764] 
//
//           If both DoFs  [2.x.1601]  and  [2.x.1602]  belong to same component,           i.e. their shape functions are both  [2.x.1603] 's or both            [2.x.1604] 's, the contribution will end up in one of the           diagonal blocks in our system matrix, and since the           corresponding entries are computed by the same formula,           we do not bother if they actually are  [2.x.1605]  or  [2.x.1606]            shape functions. We can simply compute the entry by           iterating over all quadrature points and adding up           their contributions, where values and gradients of the           shape functions are supplied by our FEValues object.
//
[0.x.10765] 
[0.x.10766] 
[0.x.10767] 
[0.x.10768] 
[0.x.10769] 
[0.x.10770] 
[0.x.10771] 
[0.x.10772] 
[0.x.10773] 
[0.x.10774] 
//
//           You might think that we would have to specify which           component of the shape function we'd like to evaluate           when requesting shape function values or gradients from           the FEValues object. However, as the shape functions           are primitive, they have only one nonzero component,           and the FEValues class is smart enough to figure out           that we are definitely interested in this one nonzero           component.
//
[0.x.10775] 
[0.x.10776] 
[0.x.10777] 
//
// We also have to add contributions due to boundary terms. To this end, we loop over all faces of the current cell and see if first it is at the boundary, and second has the correct boundary indicator associated with  [2.x.1607] , the part of the boundary where we have absorbing boundary conditions:
//
[0.x.10778] 
[0.x.10779] 
[0.x.10780] 
[0.x.10781] 
//
//     These faces will certainly contribute to the off-diagonal     blocks of the system matrix, so we ask the FEFaceValues     object to provide us with the shape function values on this     face:
//
[0.x.10782] 
//
//     Next, we loop through all DoFs of the current cell to find     pairs that belong to different components and both have     support on the current face_no:
//
[0.x.10783] 
[0.x.10784] 
[0.x.10785] 
[0.x.10786] 
[0.x.10787] 
[0.x.10788] 
//
//           The check whether shape functions have support on a           face is not strictly necessary: if we don't check for           it we would simply add up terms to the local cell           matrix that happen to be zero because at least one of           the shape functions happens to be zero. However, we can           save that work by adding the checks above.
//
//           In either case, these DoFs will contribute to the           boundary integrals in the off-diagonal blocks of the           system matrix. To compute the integral, we loop over           all the quadrature points on the face and sum up the           contribution weighted with the quadrature weights that           the face quadrature rule provides.  In contrast to the           entries on the diagonal blocks, here it does matter           which one of the shape functions is a  [2.x.1608]  and which           one is a  [2.x.1609] , since that will determine the sign of           the entry.  We account for this by a simple conditional           statement that determines the correct sign. Since we           already checked that DoF  [2.x.1610]  and  [2.x.1611]  belong to           different components, it suffices here to test for one           of them to which component it belongs.
//
[0.x.10789] 
[0.x.10790] 
[0.x.10791] 
[0.x.10792] 
[0.x.10793] 
[0.x.10794] 
[0.x.10795] 
[0.x.10796] 
[0.x.10797] 
//
// Now we are done with this cell and have to transfer its contributions from the local to the global system matrix. To this end, we first get a list of the global indices of the this cells DoFs...
//
[0.x.10798] 
//
// ...and then add the entries to the system matrix one by one:
//
[0.x.10799] 
[0.x.10800] 
[0.x.10801] 
[0.x.10802] 
[0.x.10803] 
[0.x.10804] 
//
// The only thing left are the Dirichlet boundary values on  [2.x.1612] , which is characterized by the boundary indicator 1. The Dirichlet values are provided by the  [2.x.1613]  class we defined above:
//
[0.x.10805] 
[0.x.10806] 
[0.x.10807] 
[0.x.10808] 
[0.x.10809] 
//
[0.x.10810] 
[0.x.10811] 
[0.x.10812] 
[0.x.10813] 
//
[0.x.10814] 
[0.x.10815] 
[0.x.10816] 
//
//  [2.x.1614] 
//
// As already mentioned in the introduction, the system matrix is neither symmetric nor definite, and so it is not quite obvious how to come up with an iterative solver and a preconditioner that do a good job on this matrix.  We chose instead to go a different way and solve the linear system with the sparse LU decomposition provided by UMFPACK. This is often a good first choice for 2D problems and works reasonably well even for a large number of DoFs.  The deal.II interface to UMFPACK is given by the SparseDirectUMFPACK class, which is very easy to use and allows us to solve our linear system with just 3 lines of code.
//
// Note again that for compiling this example program, you need to have the deal.II library built with UMFPACK support.
//
[0.x.10817] 
[0.x.10818] 
[0.x.10819] 
[0.x.10820] 
[0.x.10821] 
//
// The code to solve the linear system is short: First, we allocate an object of the right type. The following  [2.x.1615]  call provides the matrix that we would like to invert to the SparseDirectUMFPACK object, and at the same time kicks off the LU-decomposition. Hence, this is also the point where most of the computational work in this program happens.
//
[0.x.10822] 
[0.x.10823] 
//
// After the decomposition, we can use  [2.x.1616]  like a matrix representing the inverse of our system matrix, so to compute the solution we just have to multiply with the right hand side vector:
//
[0.x.10824] 
//
[0.x.10825] 
[0.x.10826] 
[0.x.10827] 
//
//  [2.x.1617] 
//
// Here we output our solution  [2.x.1618]  and  [2.x.1619]  as well as the derived quantity  [2.x.1620]  in the format specified in the parameter file. Most of the work for deriving  [2.x.1621]  from  [2.x.1622]  and  [2.x.1623]  was already done in the implementation of the  [2.x.1624]  class, so that the output routine is rather straightforward and very similar to what is done in the previous tutorials.
//
[0.x.10828] 
[0.x.10829] 
[0.x.10830] 
[0.x.10831] 
[0.x.10832] 
//
// Define objects of our  [2.x.1625]  class and a DataOut object:
//
[0.x.10833] 
[0.x.10834] 
//
[0.x.10835] 
//
// Next we query the output-related parameters from the ParameterHandler. The  [2.x.1626]  call acts as a counterpart to the  [2.x.1627]  call in  [2.x.1628] . It collects all the output format related parameters from the ParameterHandler and sets the corresponding properties of the DataOut object accordingly.
//
[0.x.10836] 
//
[0.x.10837] 
[0.x.10838] 
//
[0.x.10839] 
//
// Now we put together the filename from the base name provided by the ParameterHandler and the suffix which is provided by the DataOut class (the default suffix is set to the right type that matches the one set in the .prm file through parse_parameters()):
//
[0.x.10840] 
//
[0.x.10841] 
//
// The solution vectors  [2.x.1629]  and  [2.x.1630]  are added to the DataOut object in the usual way:
//
[0.x.10842] 
[0.x.10843] 
[0.x.10844] 
//
[0.x.10845] 
//
// For the intensity, we just call  [2.x.1631]  again, but this with our  [2.x.1632]  object as the second argument, which effectively adds  [2.x.1633]  to the output data:
//
[0.x.10846] 
//
// The last steps are as before. Note that the actual output format is now determined by what is stated in the input file, i.e. one can change the output format without having to re-compile this program:
//
[0.x.10847] 
[0.x.10848] 
//
[0.x.10849] 
[0.x.10850] 
[0.x.10851] 
//
//  [2.x.1634] 
//
// Here we simply execute our functions one after the other:
//
[0.x.10852] 
[0.x.10853] 
[0.x.10854] 
[0.x.10855] 
[0.x.10856] 
[0.x.10857] 
[0.x.10858] 
[0.x.10859] 
[0.x.10860] 
[0.x.10861] 
//[2.x.1635] 
//
// Finally the  [2.x.1636]  function of the program. It has the same structure as in almost all of the other tutorial programs. The only exception is that we define ParameterHandler and  [2.x.1637]  objects, and let the latter read in the parameter values from a textfile called  [2.x.1638] . The values so read are then handed over to an instance of the UltrasoundProblem class:
//
[0.x.10862] 
[0.x.10863] 
[0.x.10864] 
[0.x.10865] 
[0.x.10866] 
[0.x.10867] 
//
[0.x.10868] 
[0.x.10869] 
[0.x.10870] 
//
[0.x.10871] 
[0.x.10872] 
[0.x.10873] 
[0.x.10874] 
[0.x.10875] 
[0.x.10876] 
[0.x.10877] 
[0.x.10878] 
[0.x.10879] 
[0.x.10880] 
[0.x.10881] 
[0.x.10882] 
[0.x.10883] 
[0.x.10884] 
[0.x.10885] 
[0.x.10886] 
[0.x.10887] 
[0.x.10888] 
[0.x.10889] 
[0.x.10890] 
[0.x.10891] 
[0.x.10892] 
[0.x.10893] 
[0.x.10894] 
[0.x.10895] 
[0.x.10896] 
[0.x.10897] 
[0.x.10898] 
[0.x.10899] 
[0.x.10900] 
[0.x.10901] 
[0.x.10902] 
[0.x.10903] 
[0.x.10904] 
[0.x.10905] 
[0.x.10906] 
[0.x.10907] 
[0.x.10908] 
[0.x.10909] 
[0.x.10910] 
[0.x.10911] 
[0.x.10912] 
[0.x.10913] 
[0.x.10914] 
//
[0.x.10915] 
[0.x.10916] 
[0.x.10917] 
[0.x.10918] 
//[2.x.1639] 
//
// These include files are already known to you. They declare the classes which handle triangulations and enumeration of degrees of freedom:
//
[0.x.10919] 
[0.x.10920] 
//
// And this is the file in which the functions are declared that create grids:
//
[0.x.10921] 
//
// This file contains the description of the Lagrange interpolation finite element:
//
[0.x.10922] 
//
// And this file is needed for the creation of sparsity patterns of sparse matrices, as shown in previous examples:
//
[0.x.10923] 
//
// The next two files are needed for assembling the matrix using quadrature on each cell. The classes declared in them will be explained below:
//
[0.x.10924] 
[0.x.10925] 
//
// The following three include files we need for the treatment of boundary values:
//
[0.x.10926] 
[0.x.10927] 
[0.x.10928] 
//
// We're now almost to the end. The second to last group of include files is for the linear algebra which we employ to solve the system of equations arising from the finite element discretization of the Laplace equation. We will use vectors and full matrices for assembling the system of equations locally on each cell, and transfer the results into a sparse matrix. We will then use a Conjugate Gradient solver to solve the problem, for which we need a preconditioner (in this program, we use the identity preconditioner which does nothing, but we need to include the file anyway):
//
[0.x.10929] 
[0.x.10930] 
[0.x.10931] 
[0.x.10932] 
[0.x.10933] 
[0.x.10934] 
//
// Finally, this is for output to a file and to the console:
//
[0.x.10935] 
[0.x.10936] 
[0.x.10937] 
//
// ...and this is to import the deal.II namespace into the global scope:
//
[0.x.10938] 
//[2.x.1640] 
//
// Instead of the procedural programming of previous examples, we encapsulate everything into a class for this program. The class consists of functions which each perform certain aspects of a finite element program, a `main` function which controls what is done first and what is done next, and a list of member variables.
//
// The public part of the class is rather short: it has a constructor and a function `run` that is called from the outside and acts as something like the `main` function: it coordinates which operations of this class shall be run in which order. Everything else in the class, i.e. all the functions that actually do anything, are in the private section of the class:
//
[0.x.10939] 
[0.x.10940] 
[0.x.10941] 
[0.x.10942] 
//
[0.x.10943] 
//
// Then there are the member functions that mostly do what their names suggest and whose have been discussed in the introduction already. Since they do not need to be called from outside, they are made private to this class.
//
[0.x.10944] 
[0.x.10945] 
[0.x.10946] 
[0.x.10947] 
[0.x.10948] 
[0.x.10949] 
//
// And finally we have some member variables. There are variables describing the triangulation and the global numbering of the degrees of freedom (we will specify the exact polynomial degree of the finite element in the constructor of this class)...
//
[0.x.10950] 
[0.x.10951] 
[0.x.10952] 
//
// ...variables for the sparsity pattern and values of the system matrix resulting from the discretization of the Laplace equation...
//
[0.x.10953] 
[0.x.10954] 
//
// ...and variables which will hold the right hand side and solution vectors.
//
[0.x.10955] 
[0.x.10956] 
[0.x.10957] 
//[2.x.1641] 
//
// Here comes the constructor. It does not much more than first to specify that we want bi-linear elements (denoted by the parameter to the finite element object, which indicates the polynomial degree), and to associate the dof_handler variable to the triangulation we use. (Note that the triangulation isn't set up with a mesh at all at the present time, but the DoFHandler doesn't care: it only wants to know which triangulation it will be associated with, and it only starts to care about an actual mesh once you try to distribute degree of freedom on the mesh using the distribute_dofs() function.) All the other member variables of the Step3 class have a default constructor which does all we want.
//
[0.x.10958] 
[0.x.10959] 
[0.x.10960] 
[0.x.10961] 
//[2.x.1642] 
//
// Now, the first thing we've got to do is to generate the triangulation on which we would like to do our computation and number each vertex with a degree of freedom. We have seen these two steps in  [2.x.1643]  and  [2.x.1644]  before, respectively.
//
// This function does the first part, creating the mesh.  We create the grid and refine all cells five times. Since the initial grid (which is the square  [2.x.1645] ) consists of only one cell, the final grid has 32 times 32 cells, for a total of 1024.
//
// Unsure that 1024 is the correct number? We can check that by outputting the number of cells using the  [2.x.1646]  function on the triangulation.
//
[0.x.10962] 
[0.x.10963] 
[0.x.10964] 
[0.x.10965] 
//
[0.x.10966] 
[0.x.10967] 
[0.x.10968] 
//[2.x.1647]  We call the  [2.x.1648]  function, rather than  [2.x.1649]  Here, [1.x.46] means the cells that aren't refined any further. We stress the adjective "active" since there are more cells, namely the parent cells of the finest cells, their parents, etc, up to the one cell which made up the initial grid. Of course, on the next coarser level, the number of cells is one quarter that of the cells on the finest level, i.e. 256, then 64, 16, 4, and 1. If you called  [2.x.1650]  instead in the code above, you would consequently get a value of 1365 instead. On the other hand, the number of cells (as opposed to the number of active cells) is not typically of much interest, so there is no good reason to print it.
//
//  [2.x.1651] 
//
// Next we enumerate all the degrees of freedom and set up matrix and vector objects to hold the system data. Enumerating is done by using  [2.x.1652]  as we have seen in the  [2.x.1653]  example. Since we use the FE_Q class and have set the polynomial degree to 1 in the constructor, i.e. bilinear elements, this associates one degree of freedom with each vertex. While we're at generating output, let us also take a look at how many degrees of freedom are generated:
//
[0.x.10969] 
[0.x.10970] 
[0.x.10971] 
[0.x.10972] 
[0.x.10973] 
//
// There should be one DoF for each vertex. Since we have a 32 times 32 grid, the number of DoFs should be 33 times 33, or 1089.
//
// As we have seen in the previous example, we set up a sparsity pattern by first creating a temporary structure, tagging those entries that might be nonzero, and then copying the data over to the SparsityPattern object that can then be used by the system matrix.
//
[0.x.10974] 
[0.x.10975] 
[0.x.10976] 
//
// Note that the SparsityPattern object does not hold the values of the matrix, it only stores the places where entries are. The entries themselves are stored in objects of type SparseMatrix, of which our variable system_matrix is one.
//
// The distinction between sparsity pattern and matrix was made to allow several matrices to use the same sparsity pattern. This may not seem relevant here, but when you consider the size which matrices can have, and that it may take some time to build the sparsity pattern, this becomes important in large-scale problems if you have to store several matrices in your program.
//
[0.x.10977] 
//
// The last thing to do in this function is to set the sizes of the right hand side vector and the solution vector to the right values:
//
[0.x.10978] 
[0.x.10979] 
[0.x.10980] 
//[2.x.1654] 
//
// The next step is to compute the entries of the matrix and right hand side that form the linear system from which we compute the solution. This is the central function of each finite element program and we have discussed the primary steps in the introduction already.
//
// The general approach to assemble matrices and vectors is to loop over all cells, and on each cell compute the contribution of that cell to the global matrix and right hand side by quadrature. The point to realize now is that we need the values of the shape functions at the locations of quadrature points on the real cell. However, both the finite element shape functions as well as the quadrature points are only defined on the reference cell. They are therefore of little help to us, and we will in fact hardly ever query information about finite element shape functions or quadrature points from these objects directly.
//
// Rather, what is required is a way to map this data from the reference cell to the real cell. Classes that can do that are derived from the Mapping class, though one again often does not have to deal with them directly: many functions in the library can take a mapping object as argument, but when it is omitted they simply resort to the standard bilinear Q1 mapping. We will go this route, and not bother with it for the moment (we come back to this in  [2.x.1655] ,  [2.x.1656] , and  [2.x.1657] ).
//
// So what we now have is a collection of three classes to deal with: finite element, quadrature, and mapping objects. That's too much, so there is one type of class that orchestrates information exchange between these three: the FEValues class. If given one instance of each three of these objects (or two, and an implicit linear mapping), it will be able to provide you with information about values and gradients of shape functions at quadrature points on a real cell.
//
// Using all this, we will assemble the linear system for this problem in the following function:
//
[0.x.10981] 
[0.x.10982] 
//
// Ok, let's start: we need a quadrature formula for the evaluation of the integrals on each cell. Let's take a Gauss formula with two quadrature points in each direction, i.e. a total of four points since we are in 2D. This quadrature formula integrates polynomials of degrees up to three exactly (in 1D). It is easy to check that this is sufficient for the present problem:
//
[0.x.10983] 
//
// And we initialize the object which we have briefly talked about above. It needs to be told which finite element we want to use, and the quadrature points and their weights (jointly described by a Quadrature object). As mentioned, we use the implied Q1 mapping, rather than specifying one ourselves explicitly. Finally, we have to tell it what we want it to compute on each cell: we need the values of the shape functions at the quadrature points (for the right hand side  [2.x.1658] ), their gradients (for the matrix entries  [2.x.1659] ), and also the weights of the quadrature points and the determinants of the Jacobian transformations from the reference cell to the real cells.
//
// This list of what kind of information we actually need is given as a collection of flags as the third argument to the constructor of FEValues. Since these values have to be recomputed, or updated, every time we go to a new cell, all of these flags start with the prefix  [2.x.1660]  and then indicate what it actually is that we want updated. The flag to give if we want the values of the shape functions computed is #update_values; for the gradients it is #update_gradients. The determinants of the Jacobians and the quadrature weights are always used together, so only the products (Jacobians times weights, or short  [2.x.1661] ) are computed; since we need them, we have to list #update_JxW_values as well:
//
[0.x.10984] 
[0.x.10985] 
[0.x.10986] 
//
// The advantage of this approach is that we can specify what kind of information we actually need on each cell. It is easily understandable that this approach can significantly speed up finite element computations, compared to approaches where everything, including second derivatives, normal vectors to cells, etc are computed on each cell, regardless of whether they are needed or not.
//
//  [2.x.1662]  The syntax <code>update_values | update_gradients | update_JxW_values</code> is not immediately obvious to anyone not used to programming bit operations in C for years already. First,  [2.x.1663]  is the [1.x.47], i.e., it takes two integer arguments that are interpreted as bit patterns and returns an integer in which every bit is set for which the corresponding bit is set in at least one of the two arguments. For example, consider the operation  [2.x.1664]  (where the prefix  [2.x.1665]  indicates that the number is to be interpreted as a binary number) and  [2.x.1666] . Going through each bit and seeing whether it is set in one of the argument, we arrive at  [2.x.1667]  or, in decimal notation,  [2.x.1668] . The second piece of information you need to know is that the various  [2.x.1669]  flags are all integers that have [1.x.48]. For example, assume that  [2.x.1670] ,  [2.x.1671] ,  [2.x.1672] . Then <code>update_values | update_gradients | update_JxW_values = 0b10011 = 19</code>. In other words, we obtain a number that [1.x.49], where each operation corresponds to exactly one bit in the integer that, if equal to one, means that a particular piece should be updated on each cell and, if it is zero, means that we need not compute it. In other words, even though  [2.x.1673]  is the [1.x.50], what it really represents is [1.x.51]. Such binary masks are quite common in C programming, but maybe not so in higher level languages like C++, but serve the current purpose quite well.
//
// For use further down below, we define a shortcut for a value that will be used very frequently. Namely, an abbreviation for the number of degrees of freedom on each cell (since we are in 2D and degrees of freedom are associated with vertices only, this number is four, but we rather want to write the definition of this variable in a way that does not preclude us from later choosing a different finite element that has a different number of degrees of freedom per cell, or work in a different space dimension).
//
// In general, it is a good idea to use a symbolic name instead of hard-coding these numbers even if you know them, since for example, you may want to change the finite element at some time. Changing the element would have to be done in a different function and it is easy to forget to make a corresponding change in another part of the program. It is better to not rely on your own calculations, but instead ask the right object for the information: Here, we ask the finite element to tell us about the number of degrees of freedom per cell and we will get the correct number regardless of the space dimension or polynomial degree we may have chosen elsewhere in the program.
//
// The shortcut here, defined primarily to discuss the basic concept and not because it saves a lot of typing, will then make the following loops a bit more readable. You will see such shortcuts in many places in larger programs, and `dofs_per_cell` is one that is more or less the conventional name for this kind of object.
//
[0.x.10987] 
//
// Now, we said that we wanted to assemble the global matrix and vector cell-by-cell. We could write the results directly into the global matrix, but this is not very efficient since access to the elements of a sparse matrix is slow. Rather, we first compute the contribution of each cell in a small matrix with the degrees of freedom on the present cell, and only transfer them to the global matrix when the computations are finished for this cell. We do the same for the right hand side vector. So let's first allocate these objects (these being local objects, all degrees of freedom are coupling with all others, and we should use a full matrix object rather than a sparse one for the local operations; everything will be transferred to a global sparse matrix later on):
//
[0.x.10988] 
[0.x.10989] 
//
// When assembling the contributions of each cell, we do this with the local numbering of the degrees of freedom (i.e. the number running from zero through dofs_per_cell-1). However, when we transfer the result into the global matrix, we have to know the global numbers of the degrees of freedom. When we query them, we need a scratch (temporary) array for these numbers (see the discussion at the end of the introduction for the type,  [2.x.1674]  used here):
//
[0.x.10990] 
//
// Now for the loop over all cells. We have seen before how this works for a triangulation. A DoFHandler has cell iterators that are exactly analogous to those of a Triangulation, but with extra information about the degrees of freedom for the finite element you're using. Looping over the active cells of a degree-of-freedom handler works the same as for a triangulation.
//
// Note that we declare the type of the cell as `const auto &` instead of `auto` this time around. In step 1, we were modifying the cells of the triangulation by flagging them with refinement indicators. Here we're only examining the cells without modifying them, so it's good practice to declare `cell` as `const` in order to enforce this invariant.
//
[0.x.10991] 
[0.x.10992] 
//
// We are now sitting on one cell, and we would like the values and gradients of the shape functions be computed, as well as the determinants of the Jacobian matrices of the mapping between reference cell and true cell, at the quadrature points. Since all these values depend on the geometry of the cell, we have to have the FEValues object re-compute them on each cell:
//
[0.x.10993] 
//
// Next, reset the local cell's contributions to global matrix and global right hand side to zero, before we fill them:
//
[0.x.10994] 
[0.x.10995] 
//
// Now it is time to start integration over the cell, which we do by looping over all quadrature points, which we will number by q_index.
//
[0.x.10996] 
[0.x.10997] 
//
// First assemble the matrix: For the Laplace problem, the matrix on each cell is the integral over the gradients of shape function i and j. Since we do not integrate, but rather use quadrature, this is the sum over all quadrature points of the integrands times the determinant of the Jacobian matrix at the quadrature point times the weight of this quadrature point. You can get the gradient of shape function  [2.x.1675]  at quadrature point with number q_index by using  [2.x.1676] ; this gradient is a 2-dimensional vector (in fact it is of type Tensor [2.x.1677]  with here dim=2) and the product of two such vectors is the scalar product, i.e. the product of the two shape_grad function calls is the dot product. This is in turn multiplied by the Jacobian determinant and the quadrature point weight (that one gets together by the call to  [2.x.1678]  ). Finally, this is repeated for all shape functions  [2.x.1679]  and  [2.x.1680] :
//
[0.x.10998] 
[0.x.10999] 
[0.x.11000] 
[0.x.11001] 
[0.x.11002] 
[0.x.11003] 
//
// We then do the same thing for the right hand side. Here, the integral is over the shape function i times the right hand side function, which we choose to be the function with constant value one (more interesting examples will be considered in the following programs).
//
[0.x.11004] 
[0.x.11005] 
[0.x.11006] 
[0.x.11007] 
[0.x.11008] 
//
// Now that we have the contribution of this cell, we have to transfer it to the global matrix and right hand side. To this end, we first have to find out which global numbers the degrees of freedom on this cell have. Let's simply ask the cell for that information:
//
[0.x.11009] 
//
// Then again loop over all shape functions i and j and transfer the local elements to the global matrix. The global numbers can be obtained using local_dof_indices[i]:
//
[0.x.11010] 
[0.x.11011] 
[0.x.11012] 
[0.x.11013] 
[0.x.11014] 
//
// And again, we do the same thing for the right hand side vector.
//
[0.x.11015] 
[0.x.11016] 
[0.x.11017] 
//
// Now almost everything is set up for the solution of the discrete system. However, we have not yet taken care of boundary values (in fact, Laplace's equation without Dirichlet boundary values is not even uniquely solvable, since you can add an arbitrary constant to the discrete solution). We therefore have to do something about the situation.
//
// For this, we first obtain a list of the degrees of freedom on the boundary and the value the shape function shall have there. For simplicity, we only interpolate the boundary value function, rather than projecting it onto the boundary. There is a function in the library which does exactly this:  [2.x.1681]  Its parameters are (omitting parameters for which default values exist and that we don't care about): the DoFHandler object to get the global numbers of the degrees of freedom on the boundary; the component of the boundary where the boundary values shall be interpolated; the boundary value function itself; and the output object.
//
// The component of the boundary is meant as follows: in many cases, you may want to impose certain boundary values only on parts of the boundary. For example, you may have inflow and outflow boundaries in fluid dynamics, or clamped and free parts of bodies in deformation computations of bodies. Then you will want to denote these different parts of the boundary by indicators, and tell the interpolate_boundary_values function to only compute the boundary values on a certain part of the boundary (e.g. the clamped part, or the inflow boundary). By default, all boundaries have a 0 boundary indicator, unless otherwise specified. If sections of the boundary have different boundary conditions, you have to number those parts with different boundary indicators. The function call below will then only determine boundary values for those parts of the boundary for which the boundary indicator is in fact the zero specified as the second argument.
//
// The function describing the boundary values is an object of type Function or of a derived class. One of the derived classes is  [2.x.1682]  which describes (not unexpectedly) a function which is zero everywhere. We create such an object in-place and pass it to the  [2.x.1683]  function.
//
// Finally, the output object is a list of pairs of global degree of freedom numbers (i.e. the number of the degrees of freedom on the boundary) and their boundary values (which are zero here for all entries). This mapping of DoF numbers to boundary values is done by the  [2.x.1684]  class.
//
[0.x.11018] 
[0.x.11019] 
[0.x.11020] 
[0.x.11021] 
[0.x.11022] 
//
// Now that we got the list of boundary DoFs and their respective boundary values, let's use them to modify the system of equations accordingly. This is done by the following function call:
//
[0.x.11023] 
[0.x.11024] 
[0.x.11025] 
[0.x.11026] 
[0.x.11027] 
//[2.x.1685] 
//
// The following function simply solves the discretized equation. As the system is quite a large one for direct solvers such as Gauss elimination or LU decomposition, we use a Conjugate Gradient algorithm. You should remember that the number of variables here (only 1089) is a very small number for finite element computations, where 100.000 is a more usual number.  For this number of variables, direct methods are no longer usable and you are forced to use methods like CG.
//
[0.x.11028] 
[0.x.11029] 
//
// First, we need to have an object that knows how to tell the CG algorithm when to stop. This is done by using a SolverControl object, and as stopping criterion we say: stop after a maximum of 1000 iterations (which is far more than is needed for 1089 variables; see the results section to find out how many were really used), and stop if the norm of the residual is below  [2.x.1686] . In practice, the latter criterion will be the one which stops the iteration:
//
[0.x.11030] 
//
// Then we need the solver itself. The template parameter to the SolverCG class is the type of the vectors, and leaving the empty angle brackets would indicate that we are taking the default argument (which is  [2.x.1687] ). However, we explicitly mention the template argument:
//
[0.x.11031] 
//
// Now solve the system of equations. The CG solver takes a preconditioner as its fourth argument. We don't feel ready to delve into this yet, so we tell it to use the identity operation as preconditioner:
//
[0.x.11032] 
//
// Now that the solver has done its job, the solution variable contains the nodal values of the solution function.
//
[0.x.11033] 
//[2.x.1688] 
//
// The last part of a typical finite element program is to output the results and maybe do some postprocessing (for example compute the maximal stress values at the boundary, or the average flux across the outflow, etc). We have no such postprocessing here, but we would like to write the solution to a file.
//
[0.x.11034] 
[0.x.11035] 
//
// To write the output to a file, we need an object which knows about output formats and the like. This is the DataOut class, and we need an object of that type:
//
[0.x.11036] 
//
// Now we have to tell it where to take the values from which it shall write. We tell it which DoFHandler object to use, and the solution vector (and the name by which the solution variable shall appear in the output file). If we had more than one vector which we would like to look at in the output (for example right hand sides, errors per cell, etc) we would add them as well:
//
[0.x.11037] 
[0.x.11038] 
//
// After the DataOut object knows which data it is to work on, we have to tell it to process them into something the back ends can handle. The reason is that we have separated the frontend (which knows about how to treat DoFHandler objects and data vectors) from the back end (which knows many different output formats) and use an intermediate data format to transfer data from the front- to the backend. The data is transformed into this intermediate format by the following function:
//
[0.x.11039] 
//
// Now we have everything in place for the actual output. Just open a file and write the data into it, using VTK format (there are many other functions in the DataOut class we are using here that can write the data in postscript, AVS, GMV, Gnuplot, or some other file formats):
//
[0.x.11040] 
[0.x.11041] 
[0.x.11042] 
//[2.x.1689] 
//
// Finally, the last function of this class is the main function which calls all the other functions of the  [2.x.1690]  class. The order in which this is done resembles the order in which most finite element programs work. Since the names are mostly self-explanatory, there is not much to comment about:
//
[0.x.11043] 
[0.x.11044] 
[0.x.11045] 
[0.x.11046] 
[0.x.11047] 
[0.x.11048] 
[0.x.11049] 
[0.x.11050] 
//[2.x.1691] 
//
// This is the main function of the program. Since the concept of a main function is mostly a remnant from the pre-object oriented era before C++ programming, it often does not do much more than creating an object of the top-level class and calling its principle function.
//
// Finally, the first line of the function is used to enable output of some diagnostics that deal.II can generate.  The  [2.x.1692]  variable (which stands for deal-log, not de-allog) represents a stream to which some parts of the library write output. For example, iterative solvers will generate diagnostics (starting residual, number of solver steps, final residual) as can be seen when running this tutorial program.
//
// The output of  [2.x.1693]  can be written to the console, to a file, or both. Both are disabled by default since over the years we have learned that a program should only generate output when a user explicitly asks for it. But this can be changed, and to explain how this can be done, we need to explain how  [2.x.1694]  works: When individual parts of the library want to log output, they open a "context" or "section" into which this output will be placed. At the end of the part that wants to write output, one exits this section again. Since a function may call another one from within the scope where this output section is open, output may in fact be nested hierarchically into these sections. The LogStream class of which  [2.x.1695]  is a variable calls each of these sections a "prefix" because all output is printed with this prefix at the left end of the line, with prefixes separated by colons. There is always a default prefix called "DEAL" (a hint at deal.II's history as the successor of a previous library called "DEAL" and from which the LogStream class is one of the few pieces of code that were taken into deal.II).
//
// By default,  [2.x.1696]  only outputs lines with zero prefixes -- i.e., all output is disabled because the default "DEAL" prefix is always there. But one can set a different maximal number of prefixes for lines that should be output to something larger, and indeed here we set it to two by calling  [2.x.1697]  This means that for all screen output, a context that has pushed one additional prefix beyond the default "DEAL" is allowed to print its output to the screen ("console"), whereas all further nested sections that would have three or more prefixes active would write to  [2.x.1698]  but  [2.x.1699]  does not forward this output to the screen. Thus, running this example (or looking at the "Results" section), you will see the solver statistics prefixed with "DEAL:CG", which is two prefixes. This is sufficient for the context of the current program, but you will see examples later on (e.g., in  [2.x.1700] ) where solvers are nested more deeply and where you may get useful information by setting the depth even higher.
//
[0.x.11051] 
[0.x.11052] 
[0.x.11053] 
//
[0.x.11054] 
[0.x.11055] 
//
[0.x.11056] 
[0.x.11057] 
[0.x.11058] 
[0.x.11059] 
[0.x.11060] 
[0.x.11061] 
[0.x.11062] 
[0.x.11063] 
[0.x.11064] 
[0.x.11065] 
[0.x.11066] 
[0.x.11067] 
[0.x.11068] 
[0.x.11069] 
[0.x.11070] 
[0.x.11071] 
//
[0.x.11072] 
[0.x.11073] 
[0.x.11074] 
//
// The deal.II include files have already been covered in previous examples and will thus not be further commented on.
//
[0.x.11075] 
[0.x.11076] 
[0.x.11077] 
[0.x.11078] 
[0.x.11079] 
[0.x.11080] 
[0.x.11081] 
[0.x.11082] 
[0.x.11083] 
[0.x.11084] 
[0.x.11085] 
[0.x.11086] 
[0.x.11087] 
[0.x.11088] 
[0.x.11089] 
[0.x.11090] 
[0.x.11091] 
[0.x.11092] 
//
// And this again is C++:
//
[0.x.11093] 
[0.x.11094] 
[0.x.11095] 
//
// The last step is as in all previous programs:
//
[0.x.11096] 
[0.x.11097] 
[0.x.11098] 
//[2.x.1701] 
//
// The classes describing equation data and the actual assembly of individual terms are almost entirely copied from  [2.x.1702] . We will comment on differences.
//
[0.x.11099] 
[0.x.11100] 
[0.x.11101] 
[0.x.11102] 
[0.x.11103] 
[0.x.11104] 
[0.x.11105] 
[0.x.11106] 
[0.x.11107] 
[0.x.11108] 
[0.x.11109] 
//
[0.x.11110] 
[0.x.11111] 
[0.x.11112] 
//
[0.x.11113] 
[0.x.11114] 
[0.x.11115] 
[0.x.11116] 
[0.x.11117] 
[0.x.11118] 
[0.x.11119] 
[0.x.11120] 
[0.x.11121] 
[0.x.11122] 
//
[0.x.11123] 
[0.x.11124] 
[0.x.11125] 
[0.x.11126] 
[0.x.11127] 
[0.x.11128] 
[0.x.11129] 
[0.x.11130] 
[0.x.11131] 
//
[0.x.11132] 
[0.x.11133] 
[0.x.11134] 
[0.x.11135] 
//
// The flow field is chosen to be a quarter circle with counterclockwise flow direction and with the origin as midpoint for the right half of the domain with positive  [2.x.1703]  values, whereas the flow simply goes to the left in the left part of the domain at a velocity that matches the one coming in from the right. In the circular part the magnitude of the flow velocity is proportional to the distance from the origin. This is a difference to  [2.x.1704] , where the magnitude was 1 everywhere. the new definition leads to a linear variation of  [2.x.1705]  along each given face of a cell. On the other hand, the solution  [2.x.1706]  is exactly the same as before.
//
[0.x.11136] 
[0.x.11137] 
[0.x.11138] 
[0.x.11139] 
[0.x.11140] 
//
[0.x.11141] 
[0.x.11142] 
[0.x.11143] 
[0.x.11144] 
[0.x.11145] 
[0.x.11146] 
[0.x.11147] 
[0.x.11148] 
[0.x.11149] 
[0.x.11150] 
[0.x.11151] 
[0.x.11152] 
[0.x.11153] 
[0.x.11154] 
[0.x.11155] 
//
//  [2.x.1707] 
//
// This declaration of this class is utterly unaffected by our current changes.
//
[0.x.11156] 
[0.x.11157] 
[0.x.11158] 
[0.x.11159] 
[0.x.11160] 
//
[0.x.11161] 
[0.x.11162] 
[0.x.11163] 
//
[0.x.11164] 
[0.x.11165] 
[0.x.11166] 
//
[0.x.11167] 
[0.x.11168] 
[0.x.11169] 
[0.x.11170] 
[0.x.11171] 
[0.x.11172] 
//
[0.x.11173] 
[0.x.11174] 
[0.x.11175] 
[0.x.11176] 
[0.x.11177] 
//
// Likewise, the constructor of the class as well as the functions assembling the terms corresponding to cell interiors and boundary faces are unchanged from before. The function that assembles face terms between cells also did not change because all it does is operate on two objects of type FEFaceValuesBase (which is the base class of both FEFaceValues and FESubfaceValues). Where these objects come from, i.e. how they are initialized, is of no concern to this function: it simply assumes that the quadrature points on faces or subfaces represented by the two objects correspond to the same points in physical space.
//
[0.x.11178] 
[0.x.11179] 
[0.x.11180] 
[0.x.11181] 
[0.x.11182] 
[0.x.11183] 
//
[0.x.11184] 
[0.x.11185] 
[0.x.11186] 
[0.x.11187] 
[0.x.11188] 
[0.x.11189] 
[0.x.11190] 
//
[0.x.11191] 
[0.x.11192] 
//
[0.x.11193] 
[0.x.11194] 
//
[0.x.11195] 
[0.x.11196] 
[0.x.11197] 
[0.x.11198] 
[0.x.11199] 
[0.x.11200] 
//
[0.x.11201] 
[0.x.11202] 
[0.x.11203] 
[0.x.11204] 
//
[0.x.11205] 
[0.x.11206] 
[0.x.11207] 
[0.x.11208] 
[0.x.11209] 
[0.x.11210] 
[0.x.11211] 
[0.x.11212] 
//
[0.x.11213] 
[0.x.11214] 
//
[0.x.11215] 
[0.x.11216] 
//
[0.x.11217] 
[0.x.11218] 
[0.x.11219] 
[0.x.11220] 
[0.x.11221] 
[0.x.11222] 
[0.x.11223] 
[0.x.11224] 
[0.x.11225] 
[0.x.11226] 
[0.x.11227] 
[0.x.11228] 
[0.x.11229] 
[0.x.11230] 
//
[0.x.11231] 
[0.x.11232] 
[0.x.11233] 
[0.x.11234] 
[0.x.11235] 
[0.x.11236] 
[0.x.11237] 
[0.x.11238] 
[0.x.11239] 
[0.x.11240] 
[0.x.11241] 
//
[0.x.11242] 
//
[0.x.11243] 
//
[0.x.11244] 
[0.x.11245] 
[0.x.11246] 
[0.x.11247] 
[0.x.11248] 
[0.x.11249] 
[0.x.11250] 
[0.x.11251] 
[0.x.11252] 
//
[0.x.11253] 
[0.x.11254] 
[0.x.11255] 
[0.x.11256] 
[0.x.11257] 
[0.x.11258] 
[0.x.11259] 
[0.x.11260] 
[0.x.11261] 
[0.x.11262] 
[0.x.11263] 
[0.x.11264] 
[0.x.11265] 
//
[0.x.11266] 
[0.x.11267] 
[0.x.11268] 
[0.x.11269] 
[0.x.11270] 
[0.x.11271] 
[0.x.11272] 
[0.x.11273] 
//[2.x.1708] 
//
// This declaration is much like that of  [2.x.1709] . However, we introduce a new routine (set_anisotropic_flags) and modify another one (refine_grid).
//
[0.x.11274] 
[0.x.11275] 
[0.x.11276] 
[0.x.11277] 
[0.x.11278] 
//
[0.x.11279] 
//
[0.x.11280] 
[0.x.11281] 
[0.x.11282] 
[0.x.11283] 
[0.x.11284] 
[0.x.11285] 
[0.x.11286] 
//
[0.x.11287] 
[0.x.11288] 
//
// Again we want to use DG elements of degree 1 (but this is only specified in the constructor). If you want to use a DG method of a different degree replace 1 in the constructor by the new degree.
//
[0.x.11289] 
[0.x.11290] 
[0.x.11291] 
//
[0.x.11292] 
[0.x.11293] 
//
// This is new, the threshold value used in the evaluation of the anisotropic jump indicator explained in the introduction. Its value is set to 3.0 in the constructor, but it can easily be changed to a different value greater than 1.
//
[0.x.11294] 
//
// This is a bool flag indicating whether anisotropic refinement shall be used or not. It is set by the constructor, which takes an argument of the same name.
//
[0.x.11295] 
//
[0.x.11296] 
[0.x.11297] 
//
[0.x.11298] 
[0.x.11299] 
//
[0.x.11300] 
[0.x.11301] 
//
[0.x.11302] 
[0.x.11303] 
[0.x.11304] 
[0.x.11305] 
//
// Change here for DG methods of different degrees.
//
[0.x.11306] 
[0.x.11307] 
[0.x.11308] 
[0.x.11309] 
[0.x.11310] 
[0.x.11311] 
//
// As beta is a linear function, we can choose the degree of the quadrature for which the resulting integration is correct. Thus, we choose to use  [2.x.1710]  Gauss points, which enables us to integrate exactly polynomials of degree  [2.x.1711] , enough for all the integrals we will perform in this program.
//
[0.x.11312] 
[0.x.11313] 
[0.x.11314] 
[0.x.11315] 
//
[0.x.11316] 
[0.x.11317] 
[0.x.11318] 
[0.x.11319] 
[0.x.11320] 
[0.x.11321] 
[0.x.11322] 
[0.x.11323] 
[0.x.11324] 
[0.x.11325] 
//
[0.x.11326] 
//
[0.x.11327] 
//
[0.x.11328] 
//
[0.x.11329] 
[0.x.11330] 
[0.x.11331] 
//[2.x.1712] 
//
// We proceed with the  [2.x.1713]  function that implements the DG discretization. This function does the same thing as the  [2.x.1714]  function from  [2.x.1715]  (but without MeshWorker).  The four cases considered for the neighbor-relations of a cell are the same as the isotropic case, namely a) cell is at the boundary, b) there are finer neighboring cells, c) the neighbor is neither coarser nor finer and d) the neighbor is coarser.  However, the way in which we decide upon which case we have are modified in the way described in the introduction.
//
[0.x.11332] 
[0.x.11333] 
[0.x.11334] 
[0.x.11335] 
[0.x.11336] 
[0.x.11337] 
//
[0.x.11338] 
[0.x.11339] 
[0.x.11340] 
//
[0.x.11341] 
[0.x.11342] 
[0.x.11343] 
//
[0.x.11344] 
//
[0.x.11345] 
[0.x.11346] 
[0.x.11347] 
[0.x.11348] 
[0.x.11349] 
[0.x.11350] 
[0.x.11351] 
[0.x.11352] 
[0.x.11353] 
[0.x.11354] 
[0.x.11355] 
[0.x.11356] 
[0.x.11357] 
//
[0.x.11358] 
[0.x.11359] 
//
[0.x.11360] 
[0.x.11361] 
//
[0.x.11362] 
//
[0.x.11363] 
[0.x.11364] 
[0.x.11365] 
[0.x.11366] 
//
[0.x.11367] 
//
[0.x.11368] 
//
[0.x.11369] 
//
[0.x.11370] 
[0.x.11371] 
[0.x.11372] 
//
//   Case (a): The face is at the boundary.
//
[0.x.11373] 
[0.x.11374] 
[0.x.11375] 
//
[0.x.11376] 
[0.x.11377] 
[0.x.11378] 
[0.x.11379] 
[0.x.11380] 
[0.x.11381] 
[0.x.11382] 
//
//       Case (b): This is an internal face and the neighbor       is refined (which we can test by asking whether the       face of the current cell has children). In this       case, we will need to integrate over the       "sub-faces", i.e., the children of the face of the       current cell.             (There is a slightly confusing corner case: If we       are in 1d -- where admittedly the current program       and its demonstration of anisotropic refinement is       not particularly relevant -- then the faces between       cells are always the same: they are just       vertices. In other words, in 1d, we do not want to       treat faces between cells of different level       differently. The condition `face->has_children()`       we check here ensures this: in 1d, this function       always returns `false`, and consequently in 1d we       will not ever go into this `if` branch. But we will       have to come back to this corner case below in case       (c).)
//
[0.x.11383] 
[0.x.11384] 
//
//           We need to know, which of the neighbors faces points in           the direction of our cell. Using the  [2.x.1716]            neighbor_face_no function we get this information for           both coarser and non-coarser neighbors.
//
[0.x.11385] 
[0.x.11386] 
//
//           Now we loop over all subfaces, i.e. the children and           possibly grandchildren of the current face.
//
[0.x.11387] 
[0.x.11388] 
[0.x.11389] 
[0.x.11390] 
//
//               To get the cell behind the current subface we can               use the  [2.x.1717]  function. it               takes care of all the complicated situations of               anisotropic refinement and non-standard faces.
//
[0.x.11391] 
[0.x.11392] 
[0.x.11393] 
[0.x.11394] 
//
//               The remaining part of this case is unchanged.
//
[0.x.11395] 
[0.x.11396] 
[0.x.11397] 
//
[0.x.11398] 
[0.x.11399] 
//
[0.x.11400] 
[0.x.11401] 
[0.x.11402] 
[0.x.11403] 
[0.x.11404] 
[0.x.11405] 
//
[0.x.11406] 
//
[0.x.11407] 
[0.x.11408] 
[0.x.11409] 
[0.x.11410] 
[0.x.11411] 
[0.x.11412] 
[0.x.11413] 
[0.x.11414] 
[0.x.11415] 
[0.x.11416] 
[0.x.11417] 
[0.x.11418] 
[0.x.11419] 
[0.x.11420] 
[0.x.11421] 
[0.x.11422] 
[0.x.11423] 
//
//           Case (c). We get here if this is an internal           face and if the neighbor is not further refined           (or, as mentioned above, we are in 1d in which           case we get here for every internal face). We           then need to decide whether we want to           integrate over the current face. If the           neighbor is in fact coarser, then we ignore the           face and instead handle it when we visit the           neighboring cell and look at the current face           (except in 1d, where as mentioned above this is           not happening):
//
[0.x.11424] 
[0.x.11425] 
//
//           On the other hand, if the neighbor is more           refined, then we have already handled the face           in case (b) above (except in 1d). So for 2d and           3d, we just have to decide whether we want to           handle a face between cells at the same level           from the current side or from the neighboring           side.  We do this by introducing a tie-breaker:           We'll just take the cell with the smaller index           (within the current refinement level). In 1d,           we take either the coarser cell, or if they are           on the same level, the one with the smaller           index within that level. This leads to a           complicated condition that, hopefully, makes           sense given the description above:
//
[0.x.11426] 
[0.x.11427] 
[0.x.11428] 
[0.x.11429] 
[0.x.11430] 
//
//               Here we know, that the neighbor is not coarser so we               can use the usual  [2.x.1718]                function. However, we could also use the more               general  [2.x.1719]  function.
//
[0.x.11431] 
[0.x.11432] 
//
[0.x.11433] 
[0.x.11434] 
[0.x.11435] 
//
[0.x.11436] 
[0.x.11437] 
//
[0.x.11438] 
[0.x.11439] 
[0.x.11440] 
[0.x.11441] 
[0.x.11442] 
[0.x.11443] 
//
[0.x.11444] 
//
[0.x.11445] 
[0.x.11446] 
[0.x.11447] 
[0.x.11448] 
[0.x.11449] 
[0.x.11450] 
[0.x.11451] 
[0.x.11452] 
[0.x.11453] 
[0.x.11454] 
[0.x.11455] 
[0.x.11456] 
[0.x.11457] 
[0.x.11458] 
//
//           We do not need to consider a case (d), as those           faces are treated 'from the other side within           case (b).
//
[0.x.11459] 
[0.x.11460] 
[0.x.11461] 
//
[0.x.11462] 
[0.x.11463] 
[0.x.11464] 
//
[0.x.11465] 
[0.x.11466] 
[0.x.11467] 
[0.x.11468] 
//[2.x.1720] 
//
// For this simple problem we use the simple Richardson iteration again. The solver is completely unaffected by our anisotropic changes.
//
[0.x.11469] 
[0.x.11470] 
[0.x.11471] 
[0.x.11472] 
[0.x.11473] 
//
[0.x.11474] 
//
[0.x.11475] 
//
[0.x.11476] 
[0.x.11477] 
//[2.x.1721] 
//
// We refine the grid according to the same simple refinement criterion used in  [2.x.1722] , namely an approximation to the gradient of the solution.
//
[0.x.11478] 
[0.x.11479] 
[0.x.11480] 
[0.x.11481] 
//
// We approximate the gradient,
//
[0.x.11482] 
[0.x.11483] 
[0.x.11484] 
[0.x.11485] 
//
// and scale it to obtain an error indicator.
//
[0.x.11486] 
[0.x.11487] 
[0.x.11488] 
//
// Then we use this indicator to flag the 30 percent of the cells with highest error indicator to be refined.
//
[0.x.11489] 
[0.x.11490] 
[0.x.11491] 
[0.x.11492] 
//
// Now the refinement flags are set for those cells with a large error indicator. If nothing is done to change this, those cells will be refined isotropically. If the  [2.x.1723]  flag given to this function is set, we now call the set_anisotropic_flags() function, which uses the jump indicator to reset some of the refinement flags to anisotropic refinement.
//
[0.x.11493] 
[0.x.11494] 
//
// Now execute the refinement considering anisotropic as well as isotropic refinement flags.
//
[0.x.11495] 
[0.x.11496] 
//
// Once an error indicator has been evaluated and the cells with largest error are flagged for refinement we want to loop over the flagged cells again to decide whether they need isotropic refinement or whether anisotropic refinement is more appropriate. This is the anisotropic jump indicator explained in the introduction.
//
[0.x.11497] 
[0.x.11498] 
[0.x.11499] 
//
// We want to evaluate the jump over faces of the flagged cells, so we need some objects to evaluate values of the solution on faces.
//
[0.x.11500] 
[0.x.11501] 
//
[0.x.11502] 
[0.x.11503] 
[0.x.11504] 
[0.x.11505] 
[0.x.11506] 
[0.x.11507] 
[0.x.11508] 
[0.x.11509] 
[0.x.11510] 
[0.x.11511] 
[0.x.11512] 
[0.x.11513] 
//
// Now we need to loop over all active cells.
//
[0.x.11514] 
//
// We only need to consider cells which are flagged for refinement.
//
[0.x.11515] 
[0.x.11516] 
[0.x.11517] 
[0.x.11518] 
//
[0.x.11519] 
[0.x.11520] 
[0.x.11521] 
//
[0.x.11522] 
[0.x.11523] 
[0.x.11524] 
[0.x.11525] 
[0.x.11526] 
[0.x.11527] 
//
[0.x.11528] 
[0.x.11529] 
//
//         The four cases of different neighbor relations seen in         the assembly routines are repeated much in the same way         here.
//
[0.x.11530] 
[0.x.11531] 
//
//             The neighbor is refined.  First we store the             information, which of the neighbor's faces points in             the direction of our current cell. This property is             inherited to the children.
//
[0.x.11532] 
//
//             Now we loop over all subfaces,
//
[0.x.11533] 
[0.x.11534] 
[0.x.11535] 
[0.x.11536] 
//
//                 get an iterator pointing to the cell behind the                 present subface...
//
[0.x.11537] 
[0.x.11538] 
[0.x.11539] 
[0.x.11540] 
[0.x.11541] 
//
//                 ... and reinit the respective FEFaceValues and                 FESubFaceValues objects.
//
[0.x.11542] 
[0.x.11543] 
//
//                 We obtain the function values
//
[0.x.11544] 
[0.x.11545] 
[0.x.11546] 
//
//                 as well as the quadrature weights, multiplied by                 the Jacobian determinant.
//
[0.x.11547] 
[0.x.11548] 
//
//                 Now we loop over all quadrature points
//
[0.x.11549] 
[0.x.11550] 
[0.x.11551] 
[0.x.11552] 
//
//                     and integrate the absolute value of the jump                     of the solution, i.e. the absolute value of                     the difference between the function value                     seen from the current cell and the                     neighboring cell, respectively. We know, that                     the first two faces are orthogonal to the                     first coordinate direction on the unit cell,                     the second two faces are orthogonal to the                     second coordinate direction and so on, so we                     accumulate these values into vectors with                      [2.x.1724]  components.
//
[0.x.11553] 
[0.x.11554] 
//
//                     We also sum up the scaled weights to obtain                     the measure of the face.
//
[0.x.11555] 
[0.x.11556] 
[0.x.11557] 
[0.x.11558] 
[0.x.11559] 
[0.x.11560] 
[0.x.11561] 
[0.x.11562] 
//
//                 Our current cell and the neighbor have the same                 refinement along the face under                 consideration. Apart from that, we do much the                 same as with one of the subcells in the above                 case.
//
[0.x.11563] 
[0.x.11564] 
//
[0.x.11565] 
[0.x.11566] 
//
[0.x.11567] 
[0.x.11568] 
[0.x.11569] 
//
[0.x.11570] 
[0.x.11571] 
//
[0.x.11572] 
[0.x.11573] 
[0.x.11574] 
[0.x.11575] 
[0.x.11576] 
[0.x.11577] 
[0.x.11578] 
[0.x.11579] 
[0.x.11580] 
[0.x.11581] 
[0.x.11582] 
//
//                 Now the neighbor is actually coarser. This case                 is new, in that it did not occur in the assembly                 routine. Here, we have to consider it, but this                 is not overly complicated. We simply use the  [2.x.1725]                  neighbor_of_coarser_neighbor function, which                 again takes care of anisotropic refinement and                 non-standard face orientation by itself.
//
[0.x.11583] 
[0.x.11584] 
[0.x.11585] 
[0.x.11586] 
[0.x.11587] 
[0.x.11588] 
[0.x.11589] 
[0.x.11590] 
[0.x.11591] 
[0.x.11592] 
[0.x.11593] 
[0.x.11594] 
[0.x.11595] 
//
[0.x.11596] 
[0.x.11597] 
[0.x.11598] 
[0.x.11599] 
//
[0.x.11600] 
[0.x.11601] 
[0.x.11602] 
//
[0.x.11603] 
[0.x.11604] 
//
[0.x.11605] 
[0.x.11606] 
[0.x.11607] 
[0.x.11608] 
[0.x.11609] 
[0.x.11610] 
[0.x.11611] 
[0.x.11612] 
[0.x.11613] 
[0.x.11614] 
[0.x.11615] 
[0.x.11616] 
//
// Now we analyze the size of the mean jumps, which we get dividing the jumps by the measure of the respective faces.
//
[0.x.11617] 
[0.x.11618] 
[0.x.11619] 
[0.x.11620] 
[0.x.11621] 
[0.x.11622] 
[0.x.11623] 
//
// Now we loop over the  [2.x.1726]  coordinate directions of the unit cell and compare the average jump over the faces orthogonal to that direction with the average jumps over faces orthogonal to the remaining direction(s). If the first is larger than the latter by a given factor, we refine only along hat axis. Otherwise we leave the refinement flag unchanged, resulting in isotropic refinement.
//
[0.x.11624] 
[0.x.11625] 
[0.x.11626] 
[0.x.11627] 
[0.x.11628] 
[0.x.11629] 
//[2.x.1727] 
//
// The remaining part of the program very much follows the scheme of previous tutorial programs. We output the mesh in VTU format (just as we did in  [2.x.1728] , for example), and the visualization output in VTU format as we almost always do.
//
[0.x.11630] 
[0.x.11631] 
[0.x.11632] 
[0.x.11633] 
[0.x.11634] 
[0.x.11635] 
[0.x.11636] 
[0.x.11637] 
//
[0.x.11638] 
[0.x.11639] 
[0.x.11640] 
[0.x.11641] 
[0.x.11642] 
//
[0.x.11643] 
[0.x.11644] 
[0.x.11645] 
//
[0.x.11646] 
[0.x.11647] 
[0.x.11648] 
[0.x.11649] 
[0.x.11650] 
[0.x.11651] 
//
[0.x.11652] 
[0.x.11653] 
[0.x.11654] 
//
[0.x.11655] 
//
[0.x.11656] 
[0.x.11657] 
[0.x.11658] 
//
[0.x.11659] 
[0.x.11660] 
[0.x.11661] 
[0.x.11662] 
[0.x.11663] 
[0.x.11664] 
//
[0.x.11665] 
[0.x.11666] 
//
//   Create the rectangular domain.
//
[0.x.11667] 
[0.x.11668] 
[0.x.11669] 
[0.x.11670] 
[0.x.11671] 
//
//   Adjust the number of cells in different directions to obtain   completely isotropic cells for the original mesh.
//
[0.x.11672] 
[0.x.11673] 
[0.x.11674] 
[0.x.11675] 
[0.x.11676] 
[0.x.11677] 
//
[0.x.11678] 
[0.x.11679] 
[0.x.11680] 
[0.x.11681] 
//
[0.x.11682] 
[0.x.11683] 
//
[0.x.11684] 
//
[0.x.11685] 
[0.x.11686] 
//
[0.x.11687] 
[0.x.11688] 
[0.x.11689] 
[0.x.11690] 
[0.x.11691] 
//
[0.x.11692] 
//
[0.x.11693] 
[0.x.11694] 
[0.x.11695] 
[0.x.11696] 
//
[0.x.11697] 
[0.x.11698] 
[0.x.11699] 
[0.x.11700] 
[0.x.11701] 
//
// If you want to run the program in 3D, simply change the following line to  [2.x.1729] .
//
[0.x.11702] 
//
[0.x.11703] 
//
// First, we perform a run with isotropic refinement.
//
[0.x.11704] 
[0.x.11705] 
[0.x.11706] 
[0.x.11707] 
[0.x.11708] 
[0.x.11709] 
[0.x.11710] 
//
[0.x.11711] 
//
// Now we do a second run, this time with anisotropic refinement.
//
[0.x.11712] 
[0.x.11713] 
[0.x.11714] 
[0.x.11715] 
[0.x.11716] 
[0.x.11717] 
[0.x.11718] 
[0.x.11719] 
[0.x.11720] 
[0.x.11721] 
[0.x.11722] 
[0.x.11723] 
[0.x.11724] 
[0.x.11725] 
[0.x.11726] 
[0.x.11727] 
[0.x.11728] 
[0.x.11729] 
[0.x.11730] 
[0.x.11731] 
[0.x.11732] 
[0.x.11733] 
[0.x.11734] 
[0.x.11735] 
[0.x.11736] 
[0.x.11737] 
[0.x.11738] 
[0.x.11739] 
[0.x.11740] 
[0.x.11741] 
[0.x.11742] 
[0.x.11743] 
[0.x.11744] 
[0.x.11745] 
//
[0.x.11746] 
[0.x.11747] 
[0.x.11748] 
[0.x.11749] 
[0.x.11750] 
[0.x.11751] 
[0.x.11752] 
[0.x.11753] 
[0.x.11754] 
[0.x.11755] 
[0.x.11756] 
[0.x.11757] 
[0.x.11758] 
[0.x.11759] 
[0.x.11760] 
[0.x.11761] 
[0.x.11762] 
[0.x.11763] 
[0.x.11764] 
[0.x.11765] 
//[2.x.1730] 
//
// The first step, as always, is to include the functionality of these well-known deal.II library files and some C++ header files.
//
[0.x.11766] 
[0.x.11767] 
[0.x.11768] 
//
[0.x.11769] 
[0.x.11770] 
[0.x.11771] 
[0.x.11772] 
[0.x.11773] 
//
[0.x.11774] 
[0.x.11775] 
[0.x.11776] 
[0.x.11777] 
//
[0.x.11778] 
[0.x.11779] 
[0.x.11780] 
//
[0.x.11781] 
[0.x.11782] 
[0.x.11783] 
//
[0.x.11784] 
[0.x.11785] 
[0.x.11786] 
[0.x.11787] 
//
// Then we need to include some header files that provide vector, matrix, and preconditioner classes that implement interfaces to the respective Trilinos classes. In particular, we will need interfaces to the matrix and vector classes based on Trilinos as well as Trilinos preconditioners:
//
[0.x.11788] 
[0.x.11789] 
[0.x.11790] 
[0.x.11791] 
[0.x.11792] 
[0.x.11793] 
//
// Finally, here are a few C++ headers that haven't been included yet by one of the aforelisted header files:
//
[0.x.11794] 
[0.x.11795] 
[0.x.11796] 
[0.x.11797] 
//
// At the end of this top-matter, we import all deal.II names into the global namespace:
//
[0.x.11798] 
[0.x.11799] 
[0.x.11800] 
//[2.x.1731] 
//
// Again, the next stage in the program is the definition of the equation data, that is, the various boundary conditions, the right hand sides and the initial condition (remember that we're about to solve a time-dependent system). The basic strategy for this definition is the same as in  [2.x.1732] . Regarding the details, though, there are some differences.
//
// The first thing is that we don't set any inhomogeneous boundary conditions on the velocity, since as is explained in the introduction we will use no-flux conditions  [2.x.1733] . So what is left are  [2.x.1734]  conditions for the tangential part of the normal component of the stress tensor,  [2.x.1735] ; we assume homogeneous values for these components, i.e., a natural boundary condition that requires no specific action (it appears as a zero term in the right hand side of the weak form).
//
// For the temperature  [2.x.1736] , we assume no thermal energy flux, i.e.,  [2.x.1737] . This, again, is a boundary condition that does not require us to do anything in particular.
//
// Secondly, we have to set initial conditions for the temperature (no initial conditions are required for the velocity and pressure, since the Stokes equations for the quasi-stationary case we consider here have no time derivatives of the velocity or pressure). Here, we choose a very simple test case, where the initial temperature is zero, and all dynamics are driven by the temperature right hand side.
//
// Thirdly, we need to define the right hand side of the temperature equation. We choose it to be constant within three circles (or spheres in 3d) somewhere at the bottom of the domain, as explained in the introduction, and zero outside.
//
// Finally, or maybe firstly, at the top of this namespace, we define the various material constants we need ( [2.x.1738] , density  [2.x.1739]  and the thermal expansion coefficient  [2.x.1740] ):
//
[0.x.11801] 
[0.x.11802] 
[0.x.11803] 
[0.x.11804] 
[0.x.11805] 
[0.x.11806] 
//
[0.x.11807] 
[0.x.11808] 
[0.x.11809] 
[0.x.11810] 
[0.x.11811] 
[0.x.11812] 
[0.x.11813] 
//
[0.x.11814] 
[0.x.11815] 
[0.x.11816] 
[0.x.11817] 
[0.x.11818] 
//
[0.x.11819] 
[0.x.11820] 
[0.x.11821] 
[0.x.11822] 
[0.x.11823] 
[0.x.11824] 
[0.x.11825] 
//
[0.x.11826] 
[0.x.11827] 
[0.x.11828] 
[0.x.11829] 
[0.x.11830] 
[0.x.11831] 
[0.x.11832] 
//
[0.x.11833] 
[0.x.11834] 
[0.x.11835] 
[0.x.11836] 
[0.x.11837] 
[0.x.11838] 
//
[0.x.11839] 
//
[0.x.11840] 
[0.x.11841] 
[0.x.11842] 
[0.x.11843] 
[0.x.11844] 
//
[0.x.11845] 
[0.x.11846] 
[0.x.11847] 
[0.x.11848] 
[0.x.11849] 
[0.x.11850] 
//
[0.x.11851] 
[0.x.11852] 
[0.x.11853] 
[0.x.11854] 
[0.x.11855] 
[0.x.11856] 
[0.x.11857] 
[0.x.11858] 
//
//  [2.x.1741] 
//
// This section introduces some objects that are used for the solution of the linear equations of the Stokes system that we need to solve in each time step. Many of the ideas used here are the same as in  [2.x.1742] , where Schur complement based preconditioners and solvers have been introduced, with the actual interface taken from  [2.x.1743]  (in particular the discussion in the "Results" section of  [2.x.1744] , in which we introduce alternatives to the direct Schur complement approach). Note, however, that here we don't use the Schur complement to solve the Stokes equations, though an approximate Schur complement (the mass matrix on the pressure space) appears in the preconditioner.
//
[0.x.11859] 
[0.x.11860] 
//[2.x.1745] 
//
// This class is an interface to calculate the action of an "inverted" matrix on a vector (using the  [2.x.1746]  operation) in the same way as the corresponding class in  [2.x.1747] : when the product of an object of this class is requested, we solve a linear equation system with that matrix using the CG method, accelerated by a preconditioner of (templated) class  [2.x.1748] .
//
// In a minor deviation from the implementation of the same class in  [2.x.1749] , we make the  [2.x.1750]  function take any kind of vector type (it will yield compiler errors, however, if the matrix does not allow a matrix-vector product with this kind of vector).
//
// Secondly, we catch any exceptions that the solver may have thrown. The reason is as follows: When debugging a program like this one occasionally makes a mistake of passing an indefinite or nonsymmetric matrix or preconditioner to the current class. The solver will, in that case, not converge and throw a run-time exception. If not caught here it will propagate up the call stack and may end up in  [2.x.1751]  where we output an error message that will say that the CG solver failed. The question then becomes: Which CG solver? The one that inverted the mass matrix? The one that inverted the top left block with the Laplace operator? Or a CG solver in one of the several other nested places where we use linear solvers in the current code? No indication about this is present in a run-time exception because it doesn't store the stack of calls through which we got to the place where the exception was generated.
//
// So rather than letting the exception propagate freely up to  [2.x.1752]  we realize that there is little that an outer function can do if the inner solver fails and rather convert the run-time exception into an assertion that fails and triggers a call to  [2.x.1753] , allowing us to trace back in a debugger how we got to the current place.
//
[0.x.11861] 
[0.x.11862] 
[0.x.11863] 
[0.x.11864] 
[0.x.11865] 
[0.x.11866] 
//
[0.x.11867] 
[0.x.11868] 
//
[0.x.11869] 
[0.x.11870] 
[0.x.11871] 
[0.x.11872] 
//
[0.x.11873] 
[0.x.11874] 
[0.x.11875] 
[0.x.11876] 
[0.x.11877] 
[0.x.11878] 
[0.x.11879] 
//
[0.x.11880] 
[0.x.11881] 
[0.x.11882] 
[0.x.11883] 
[0.x.11884] 
[0.x.11885] 
[0.x.11886] 
[0.x.11887] 
//
[0.x.11888] 
//
[0.x.11889] 
[0.x.11890] 
[0.x.11891] 
[0.x.11892] 
[0.x.11893] 
[0.x.11894] 
[0.x.11895] 
[0.x.11896] 
[0.x.11897] 
//[2.x.1754] 
//
// This is the implementation of the Schur complement preconditioner as described in detail in the introduction. As opposed to  [2.x.1755]  and  [2.x.1756] , we solve the block system all-at-once using GMRES, and use the Schur complement of the block structured matrix to build a good preconditioner instead.
//
// Let's have a look at the ideal preconditioner matrix  [2.x.1757]  described in the introduction. If we apply this matrix in the solution of a linear system, convergence of an iterative GMRES solver will be governed by the matrix [1.x.52] which indeed is very simple. A GMRES solver based on exact matrices would converge in one iteration, since all eigenvalues are equal (any Krylov method takes at most as many iterations as there are distinct eigenvalues). Such a preconditioner for the blocked Stokes system has been proposed by Silvester and Wathen ("Fast iterative solution of stabilised Stokes systems part II.  Using general block preconditioners", SIAM J. Numer. Anal., 31 (1994), pp. 1352-1367).
//
// Replacing  [2.x.1758]  by  [2.x.1759]  keeps that spirit alive: the product  [2.x.1760]  will still be close to a matrix with eigenvalues 1 with a distribution that does not depend on the problem size. This lets us hope to be able to get a number of GMRES iterations that is problem-size independent.
//
// The deal.II users who have already gone through the  [2.x.1761]  and  [2.x.1762]  tutorials can certainly imagine how we're going to implement this.  We replace the exact inverse matrices in  [2.x.1763]  by some approximate inverses built from the InverseMatrix class, and the inverse Schur complement will be approximated by the pressure mass matrix  [2.x.1764]  (weighted by  [2.x.1765]  as mentioned in the introduction). As pointed out in the results section of  [2.x.1766] , we can replace the exact inverse of  [2.x.1767]  by just the application of a preconditioner, in this case on a vector Laplace matrix as was explained in the introduction. This does increase the number of (outer) GMRES iterations, but is still significantly cheaper than an exact inverse, which would require between 20 and 35 CG iterations for  [2.x.1768] each [2.x.1769]  outer solver step (using the AMG preconditioner).
//
// Having the above explanations in mind, we define a preconditioner class with a  [2.x.1770]  functionality, which is all we need for the interaction with the usual solver functions further below in the program code.
//
// First the declarations. These are similar to the definition of the Schur complement in  [2.x.1771] , with the difference that we need some more preconditioners in the constructor and that the matrices we use here are built upon Trilinos:
//
[0.x.11898] 
[0.x.11899] 
[0.x.11900] 
[0.x.11901] 
[0.x.11902] 
[0.x.11903] 
[0.x.11904] 
[0.x.11905] 
[0.x.11906] 
//
[0.x.11907] 
[0.x.11908] 
//
[0.x.11909] 
[0.x.11910] 
[0.x.11911] 
[0.x.11912] 
[0.x.11913] 
[0.x.11914] 
[0.x.11915] 
//
[0.x.11916] 
[0.x.11917] 
//
// When using a  [2.x.1772]  or a  [2.x.1773]  the Vector is initialized using an IndexSet. IndexSet is used not only to resize the  [2.x.1774]  but it also associates an index in the  [2.x.1775]  with a degree of freedom (see  [2.x.1776]  for a more detailed explanation). The function complete_index_set() creates an IndexSet where every valid index is part of the set. Note that this program can only be run sequentially and will throw an exception if used in parallel.
//
[0.x.11918] 
[0.x.11919] 
[0.x.11920] 
[0.x.11921] 
[0.x.11922] 
[0.x.11923] 
[0.x.11924] 
[0.x.11925] 
[0.x.11926] 
[0.x.11927] 
[0.x.11928] 
[0.x.11929] 
//
// Next is the  [2.x.1777]  function. We implement the action of  [2.x.1778]  as described above in three successive steps.  In formulas, we want to compute  [2.x.1779]  where  [2.x.1780]  are both vectors with two block components.
//
// The first step multiplies the velocity part of the vector by a preconditioner of the matrix  [2.x.1781] , i.e., we compute  [2.x.1782] .  The resulting velocity vector is then multiplied by  [2.x.1783]  and subtracted from the pressure, i.e., we want to compute  [2.x.1784] . This second step only acts on the pressure vector and is accomplished by the residual function of our matrix classes, except that the sign is wrong. Consequently, we change the sign in the temporary pressure vector and finally multiply by the inverse pressure mass matrix to get the final pressure vector, completing our work on the Stokes preconditioner:
//
[0.x.11930] 
[0.x.11931] 
[0.x.11932] 
[0.x.11933] 
[0.x.11934] 
[0.x.11935] 
[0.x.11936] 
[0.x.11937] 
[0.x.11938] 
[0.x.11939] 
[0.x.11940] 
[0.x.11941] 
//
//  [2.x.1785] 
//
// The definition of the class that defines the top-level logic of solving the time-dependent Boussinesq problem is mainly based on the  [2.x.1786]  tutorial program. The main differences are that now we also have to solve for the temperature equation, which forces us to have a second DoFHandler object for the temperature variable as well as matrices, right hand sides, and solution vectors for the current and previous time steps. As mentioned in the introduction, all linear algebra objects are going to use wrappers of the corresponding Trilinos functionality.
//
// The member functions of this class are reminiscent of  [2.x.1787] , where we also used a staggered scheme that first solve the flow equations (here the Stokes equations, in  [2.x.1788]  Darcy flow) and then update the advected quantity (here the temperature, there the saturation). The functions that are new are mainly concerned with determining the time step, as well as the proper size of the artificial viscosity stabilization.
//
// The last three variables indicate whether the various matrices or preconditioners need to be rebuilt the next time the corresponding build functions are called. This allows us to move the corresponding  [2.x.1789]  into the respective function and thereby keeping our main  [2.x.1790]  function clean and easy to read.
//
[0.x.11942] 
[0.x.11943] 
[0.x.11944] 
[0.x.11945] 
[0.x.11946] 
[0.x.11947] 
//
[0.x.11948] 
[0.x.11949] 
[0.x.11950] 
[0.x.11951] 
[0.x.11952] 
[0.x.11953] 
[0.x.11954] 
[0.x.11955] 
[0.x.11956] 
[0.x.11957] 
[0.x.11958] 
[0.x.11959] 
//
[0.x.11960] 
[0.x.11961] 
[0.x.11962] 
[0.x.11963] 
[0.x.11964] 
[0.x.11965] 
[0.x.11966] 
[0.x.11967] 
[0.x.11968] 
[0.x.11969] 
[0.x.11970] 
[0.x.11971] 
[0.x.11972] 
//
[0.x.11973] 
[0.x.11974] 
//
[0.x.11975] 
[0.x.11976] 
[0.x.11977] 
[0.x.11978] 
//
[0.x.11979] 
[0.x.11980] 
[0.x.11981] 
//
[0.x.11982] 
[0.x.11983] 
[0.x.11984] 
//
[0.x.11985] 
[0.x.11986] 
[0.x.11987] 
[0.x.11988] 
//
[0.x.11989] 
[0.x.11990] 
[0.x.11991] 
//
[0.x.11992] 
[0.x.11993] 
[0.x.11994] 
[0.x.11995] 
//
[0.x.11996] 
[0.x.11997] 
[0.x.11998] 
//
[0.x.11999] 
[0.x.12000] 
//
[0.x.12001] 
[0.x.12002] 
[0.x.12003] 
[0.x.12004] 
//[2.x.1791] 
//[2.x.1792] 
//
// The constructor of this class is an extension of the constructor in  [2.x.1793] . We need to add the various variables that concern the temperature. As discussed in the introduction, we are going to use  [2.x.1794]  (Taylor-Hood) elements again for the Stokes part, and  [2.x.1795]  elements for the temperature. However, by using variables that store the polynomial degree of the Stokes and temperature finite elements, it is easy to consistently modify the degree of the elements as well as all quadrature formulas used on them downstream. Moreover, we initialize the time stepping as well as the options for matrix assembly and preconditioning:
//
[0.x.12005] 
[0.x.12006] 
[0.x.12007] 
[0.x.12008] 
[0.x.12009] 
[0.x.12010] 
[0.x.12011] 
[0.x.12012] 
//
[0.x.12013] 
[0.x.12014] 
[0.x.12015] 
[0.x.12016] 
//
[0.x.12017] 
[0.x.12018] 
[0.x.12019] 
[0.x.12020] 
[0.x.12021] 
[0.x.12022] 
[0.x.12023] 
//
//  [2.x.1796] 
//
// Starting the real functionality of this class is a helper function that determines the maximum ( [2.x.1797] ) velocity in the domain (at the quadrature points, in fact). How it works should be relatively obvious to all who have gotten to this point of the tutorial. Note that since we are only interested in the velocity, rather than using  [2.x.1798]  to get the values of the entire Stokes solution (velocities and pressures) we use  [2.x.1799]  to extract only the velocities part. This has the additional benefit that we get it as a Tensor<1,dim>, rather than some components in a Vector<double>, allowing us to process it right away using the  [2.x.1800]  function to get the magnitude of the velocity.
//
// The only point worth thinking about a bit is how to choose the quadrature points we use here. Since the goal of this function is to find the maximal velocity over a domain by looking at quadrature points on each cell. So we should ask how we should best choose these quadrature points on each cell. To this end, recall that if we had a single  [2.x.1801]  field (rather than the vector-valued field of higher order) then the maximum would be attained at a vertex of the mesh. In other words, we should use the QTrapezoid class that has quadrature points only at the vertices of cells.
//
// For higher order shape functions, the situation is more complicated: the maxima and minima may be attained at points between the support points of shape functions (for the usual  [2.x.1802]  elements the support points are the equidistant Lagrange interpolation points); furthermore, since we are looking for the maximum magnitude of a vector-valued quantity, we can even less say with certainty where the set of potential maximal points are. Nevertheless, intuitively if not provably, the Lagrange interpolation points appear to be a better choice than the Gauss points.
//
// There are now different methods to produce a quadrature formula with quadrature points equal to the interpolation points of the finite element. One option would be to use the  [2.x.1803]  function, reduce the output to a unique set of points to avoid duplicate function evaluations, and create a Quadrature object using these points. Another option, chosen here, is to use the QTrapezoid class and combine it with the QIterated class that repeats the QTrapezoid formula on a number of sub-cells in each coordinate direction. To cover all support points, we need to iterate it  [2.x.1804]  times since this is the polynomial degree of the Stokes element in use:
//
[0.x.12024] 
[0.x.12025] 
[0.x.12026] 
[0.x.12027] 
[0.x.12028] 
//
[0.x.12029] 
[0.x.12030] 
[0.x.12031] 
//
[0.x.12032] 
//
[0.x.12033] 
[0.x.12034] 
[0.x.12035] 
[0.x.12036] 
[0.x.12037] 
//
[0.x.12038] 
[0.x.12039] 
[0.x.12040] 
//
[0.x.12041] 
[0.x.12042] 
//
//  [2.x.1805] 
//
// Next a function that determines the minimum and maximum temperature at quadrature points inside  [2.x.1806]  when extrapolated from the two previous time steps to the current one. We need this information in the computation of the artificial viscosity parameter  [2.x.1807]  as discussed in the introduction.
//
// The formula for the extrapolated temperature is  [2.x.1808] . The way to compute it is to loop over all quadrature points and update the maximum and minimum value if the current value is bigger/smaller than the previous one. We initialize the variables that store the max and min before the loop over all quadrature points by the smallest and the largest number representable as a double. Then we know for a fact that it is larger/smaller than the minimum/maximum and that the loop over all quadrature points is ultimately going to update the initial value with the correct one.
//
// The only other complication worth mentioning here is that in the first time step,  [2.x.1809]  is not yet available of course. In that case, we can only use  [2.x.1810]  which we have from the initial temperature. As quadrature points, we use the same choice as in the previous function though with the difference that now the number of repetitions is determined by the polynomial degree of the temperature field.
//
[0.x.12043] 
[0.x.12044] 
[0.x.12045] 
[0.x.12046] 
[0.x.12047] 
[0.x.12048] 
[0.x.12049] 
//
[0.x.12050] 
[0.x.12051] 
[0.x.12052] 
//
[0.x.12053] 
[0.x.12054] 
[0.x.12055] 
[0.x.12056] 
//
[0.x.12057] 
[0.x.12058] 
[0.x.12059] 
[0.x.12060] 
[0.x.12061] 
[0.x.12062] 
[0.x.12063] 
//
[0.x.12064] 
[0.x.12065] 
[0.x.12066] 
[0.x.12067] 
[0.x.12068] 
//
[0.x.12069] 
[0.x.12070] 
[0.x.12071] 
[0.x.12072] 
//
[0.x.12073] 
[0.x.12074] 
[0.x.12075] 
[0.x.12076] 
[0.x.12077] 
[0.x.12078] 
//
[0.x.12079] 
[0.x.12080] 
[0.x.12081] 
[0.x.12082] 
[0.x.12083] 
//
[0.x.12084] 
[0.x.12085] 
[0.x.12086] 
//
[0.x.12087] 
[0.x.12088] 
[0.x.12089] 
[0.x.12090] 
//
[0.x.12091] 
[0.x.12092] 
[0.x.12093] 
//
//  [2.x.1811] 
//
// The last of the tool functions computes the artificial viscosity parameter  [2.x.1812]  on a cell  [2.x.1813]  as a function of the extrapolated temperature, its gradient and Hessian (second derivatives), the velocity, the right hand side  [2.x.1814]  all on the quadrature points of the current cell, and various other parameters as described in detail in the introduction.
//
// There are some universal constants worth mentioning here. First, we need to fix  [2.x.1815] ; we choose  [2.x.1816] , a choice discussed in detail in the results section of this tutorial program. The second is the exponent  [2.x.1817] ;  [2.x.1818]  appears to work fine for the current program, even though some additional benefit might be expected from choosing  [2.x.1819] . Finally, there is one thing that requires special casing: In the first time step, the velocity equals zero, and the formula for  [2.x.1820]  is not defined. In that case, we return  [2.x.1821] , a choice admittedly more motivated by heuristics than anything else (it is in the same order of magnitude, however, as the value returned for most cells on the second time step).
//
// The rest of the function should be mostly obvious based on the material discussed in the introduction:
//
[0.x.12094] 
[0.x.12095] 
[0.x.12096] 
[0.x.12097] 
[0.x.12098] 
[0.x.12099] 
[0.x.12100] 
[0.x.12101] 
[0.x.12102] 
[0.x.12103] 
[0.x.12104] 
[0.x.12105] 
[0.x.12106] 
[0.x.12107] 
[0.x.12108] 
[0.x.12109] 
[0.x.12110] 
//
[0.x.12111] 
[0.x.12112] 
//
[0.x.12113] 
//
[0.x.12114] 
[0.x.12115] 
//
[0.x.12116] 
[0.x.12117] 
[0.x.12118] 
[0.x.12119] 
//
[0.x.12120] 
[0.x.12121] 
[0.x.12122] 
[0.x.12123] 
//
[0.x.12124] 
[0.x.12125] 
[0.x.12126] 
[0.x.12127] 
//
[0.x.12128] 
[0.x.12129] 
[0.x.12130] 
[0.x.12131] 
//
[0.x.12132] 
[0.x.12133] 
[0.x.12134] 
//
[0.x.12135] 
[0.x.12136] 
[0.x.12137] 
//
[0.x.12138] 
[0.x.12139] 
[0.x.12140] 
[0.x.12141] 
[0.x.12142] 
//
//  [2.x.1822] 
//
// This is the function that sets up the DoFHandler objects we have here (one for the Stokes part and one for the temperature part) as well as set to the right sizes the various objects required for the linear algebra in this program. Its basic operations are similar to what we do in  [2.x.1823] .
//
// The body of the function first enumerates all degrees of freedom for the Stokes and temperature systems. For the Stokes part, degrees of freedom are then sorted to ensure that velocities precede pressure DoFs so that we can partition the Stokes matrix into a  [2.x.1824]  matrix. As a difference to  [2.x.1825] , we do not perform any additional DoF renumbering. In that program, it paid off since our solver was heavily dependent on ILU's, whereas we use AMG here which is not sensitive to the DoF numbering. The IC preconditioner for the inversion of the pressure mass matrix would of course take advantage of a Cuthill-McKee like renumbering, but its costs are low compared to the velocity portion, so the additional work does not pay off.
//
// We then proceed with the generation of the hanging node constraints that arise from adaptive grid refinement for both DoFHandler objects. For the velocity, we impose no-flux boundary conditions  [2.x.1826]  by adding constraints to the object that already stores the hanging node constraints matrix. The second parameter in the function describes the first of the velocity components in the total dof vector, which is zero here. The variable  [2.x.1827]  denotes the boundary indicators for which to set the no flux boundary conditions; here, this is boundary indicator zero.
//
// After having done so, we count the number of degrees of freedom in the various blocks:
//
[0.x.12143] 
[0.x.12144] 
[0.x.12145] 
[0.x.12146] 
[0.x.12147] 
//
[0.x.12148] 
[0.x.12149] 
[0.x.12150] 
//
[0.x.12151] 
[0.x.12152] 
[0.x.12153] 
[0.x.12154] 
[0.x.12155] 
[0.x.12156] 
[0.x.12157] 
[0.x.12158] 
[0.x.12159] 
[0.x.12160] 
[0.x.12161] 
[0.x.12162] 
[0.x.12163] 
//
[0.x.12164] 
[0.x.12165] 
[0.x.12166] 
[0.x.12167] 
[0.x.12168] 
//
[0.x.12169] 
[0.x.12170] 
//
[0.x.12171] 
[0.x.12172] 
[0.x.12173] 
//
[0.x.12174] 
[0.x.12175] 
[0.x.12176] 
[0.x.12177] 
[0.x.12178] 
//
// The next step is to create the sparsity pattern for the Stokes and temperature system matrices as well as the preconditioner matrix from which we build the Stokes preconditioner. As in  [2.x.1828] , we choose to create the pattern by using the blocked version of DynamicSparsityPattern.
//
// So, we first release the memory stored in the matrices, then set up an object of type BlockDynamicSparsityPattern consisting of  [2.x.1829]  blocks (for the Stokes system matrix and preconditioner) or DynamicSparsityPattern (for the temperature part). We then fill these objects with the nonzero pattern, taking into account that for the Stokes system matrix, there are no entries in the pressure-pressure block (but all velocity vector components couple with each other and with the pressure). Similarly, in the Stokes preconditioner matrix, only the diagonal blocks are nonzero, since we use the vector Laplacian as discussed in the introduction. This operator only couples each vector component of the Laplacian with itself, but not with the other vector components. (Application of the constraints resulting from the no-flux boundary conditions will couple vector components at the boundary again, however.)
//
// When generating the sparsity pattern, we directly apply the constraints from hanging nodes and no-flux boundary conditions. This approach was already used in  [2.x.1830] , but is different from the one in early tutorial programs where we first built the original sparsity pattern and only then added the entries resulting from constraints. The reason for doing so is that later during assembly we are going to distribute the constraints immediately when transferring local to global dofs. Consequently, there will be no data written at positions of constrained degrees of freedom, so we can let the  [2.x.1831]  function omit these entries by setting the last Boolean flag to  [2.x.1832] . Once the sparsity pattern is ready, we can use it to initialize the Trilinos matrices. Since the Trilinos matrices store the sparsity pattern internally, there is no need to keep the sparsity pattern around after the initialization of the matrix.
//
[0.x.12179] 
[0.x.12180] 
[0.x.12181] 
[0.x.12182] 
[0.x.12183] 
//
[0.x.12184] 
//
[0.x.12185] 
[0.x.12186] 
[0.x.12187] 
[0.x.12188] 
//
[0.x.12189] 
//
[0.x.12190] 
//
[0.x.12191] 
[0.x.12192] 
[0.x.12193] 
[0.x.12194] 
[0.x.12195] 
[0.x.12196] 
//
[0.x.12197] 
[0.x.12198] 
//
[0.x.12199] 
[0.x.12200] 
//
[0.x.12201] 
[0.x.12202] 
[0.x.12203] 
[0.x.12204] 
//
[0.x.12205] 
//
[0.x.12206] 
[0.x.12207] 
[0.x.12208] 
[0.x.12209] 
//
[0.x.12210] 
//
[0.x.12211] 
[0.x.12212] 
[0.x.12213] 
[0.x.12214] 
[0.x.12215] 
[0.x.12216] 
[0.x.12217] 
//
[0.x.12218] 
[0.x.12219] 
//
[0.x.12220] 
[0.x.12221] 
//
// The creation of the temperature matrix (or, rather, matrices, since we provide a temperature mass matrix and a temperature stiffness matrix, that will be added together for time discretization) follows the generation of the Stokes matrix &ndash; except that it is much easier here since we do not need to take care of any blocks or coupling between components. Note how we initialize the three temperature matrices: We only use the sparsity pattern for reinitialization of the first matrix, whereas we use the previously generated matrix for the two remaining reinits. The reason for doing so is that reinitialization from an already generated matrix allows Trilinos to reuse the sparsity pattern instead of generating a new one for each copy. This saves both some time and memory.
//
[0.x.12222] 
[0.x.12223] 
[0.x.12224] 
[0.x.12225] 
//
[0.x.12226] 
[0.x.12227] 
[0.x.12228] 
[0.x.12229] 
[0.x.12230] 
//
[0.x.12231] 
[0.x.12232] 
[0.x.12233] 
[0.x.12234] 
//
// Lastly, we set the vectors for the Stokes solutions  [2.x.1833]  and  [2.x.1834] , as well as for the temperatures  [2.x.1835] ,  [2.x.1836]  and  [2.x.1837]  (required for time stepping) and all the system right hand sides to their correct sizes and block structure:
//
[0.x.12235] 
[0.x.12236] 
[0.x.12237] 
[0.x.12238] 
//
[0.x.12239] 
[0.x.12240] 
[0.x.12241] 
[0.x.12242] 
//
[0.x.12243] 
[0.x.12244] 
//
//  [2.x.1838] 
//
// This function assembles the matrix we use for preconditioning the Stokes system. What we need are a vector Laplace matrix on the velocity components and a mass matrix weighted by  [2.x.1839]  on the pressure component. We start by generating a quadrature object of appropriate order, the FEValues object that can give values and gradients at the quadrature points (together with quadrature weights). Next we create data structures for the cell matrix and the relation between local and global DoFs. The vectors  [2.x.1840]  are going to hold the values of the basis functions in order to faster build up the local matrices, as was already done in  [2.x.1841] . Before we start the loop over all active cells, we have to specify which components are pressure and which are velocity.
//
[0.x.12245] 
[0.x.12246] 
[0.x.12247] 
[0.x.12248] 
//
[0.x.12249] 
[0.x.12250] 
[0.x.12251] 
[0.x.12252] 
[0.x.12253] 
//
[0.x.12254] 
[0.x.12255] 
//
[0.x.12256] 
[0.x.12257] 
//
[0.x.12258] 
[0.x.12259] 
//
[0.x.12260] 
[0.x.12261] 
//
[0.x.12262] 
[0.x.12263] 
[0.x.12264] 
[0.x.12265] 
//
// The creation of the local matrix is rather simple. There are only a Laplace term (on the velocity) and a mass matrix weighted by  [2.x.1842]  to be generated, so the creation of the local matrix is done in two lines. Once the local matrix is ready (loop over rows and columns in the local matrix on each quadrature point), we get the local DoF indices and write the local information into the global matrix. We do this as in  [2.x.1843] , i.e., we directly apply the constraints from hanging nodes locally. By doing so, we don't have to do that afterwards, and we don't also write into entries of the matrix that will actually be set to zero again later when eliminating constraints.
//
[0.x.12266] 
[0.x.12267] 
[0.x.12268] 
[0.x.12269] 
[0.x.12270] 
[0.x.12271] 
[0.x.12272] 
//
[0.x.12273] 
[0.x.12274] 
[0.x.12275] 
[0.x.12276] 
[0.x.12277] 
[0.x.12278] 
[0.x.12279] 
[0.x.12280] 
//
[0.x.12281] 
[0.x.12282] 
[0.x.12283] 
[0.x.12284] 
[0.x.12285] 
//
//  [2.x.1844] 
//
// This function generates the inner preconditioners that are going to be used for the Schur complement block preconditioner. Since the preconditioners need only to be regenerated when the matrices change, this function does not have to do anything in case the matrices have not changed (i.e., the flag  [2.x.1845]  has the value  [2.x.1846] ). Otherwise its first task is to call  [2.x.1847]  to generate the preconditioner matrices.
//
// Next, we set up the preconditioner for the velocity-velocity matrix  [2.x.1848] . As explained in the introduction, we are going to use an AMG preconditioner based on a vector Laplace matrix  [2.x.1849]  (which is spectrally close to the Stokes matrix  [2.x.1850] ). Usually, the  [2.x.1851]  class can be seen as a good black-box preconditioner which does not need any special knowledge. In this case, however, we have to be careful: since we build an AMG for a vector problem, we have to tell the preconditioner setup which dofs belong to which vector component. We do this using the function  [2.x.1852]  a function that generates a set of  [2.x.1853]  vectors, where each one has ones in the respective component of the vector problem and zeros elsewhere. Hence, these are the constant modes on each component, which explains the name of the variable.
//
[0.x.12286] 
[0.x.12287] 
[0.x.12288] 
[0.x.12289] 
[0.x.12290] 
//
[0.x.12291] 
//
[0.x.12292] 
//
[0.x.12293] 
//
[0.x.12294] 
[0.x.12295] 
[0.x.12296] 
[0.x.12297] 
[0.x.12298] 
[0.x.12299] 
[0.x.12300] 
[0.x.12301] 
//
// Next, we set some more options of the AMG preconditioner. In particular, we need to tell the AMG setup that we use quadratic basis functions for the velocity matrix (this implies more nonzero elements in the matrix, so that a more robust algorithm needs to be chosen internally). Moreover, we want to be able to control how the coarsening structure is build up. The way the Trilinos smoothed aggregation AMG does this is to look which matrix entries are of similar size as the diagonal entry in order to algebraically build a coarse-grid structure. By setting the parameter  [2.x.1854]  to 0.02, we specify that all entries that are more than two percent of size of some diagonal pivots in that row should form one coarse grid point. This parameter is rather ad hoc, and some fine-tuning of it can influence the performance of the preconditioner. As a rule of thumb, larger values of  [2.x.1855]  will decrease the number of iterations, but increase the costs per iteration. A look at the Trilinos documentation will provide more information on these parameters. With this data set, we then initialize the preconditioner with the matrix we want it to apply to.
//
// Finally, we also initialize the preconditioner for the inversion of the pressure mass matrix. This matrix is symmetric and well-behaved, so we can chose a simple preconditioner. We stick with an incomplete Cholesky (IC) factorization preconditioner, which is designed for symmetric matrices. We could have also chosen an SSOR preconditioner with relaxation factor around 1.2, but IC is cheaper for our example. We wrap the preconditioners into a  [2.x.1856]  pointer, which makes it easier to recreate the preconditioner next time around since we do not have to care about destroying the previously used object.
//
[0.x.12302] 
[0.x.12303] 
[0.x.12304] 
[0.x.12305] 
[0.x.12306] 
[0.x.12307] 
//
[0.x.12308] 
[0.x.12309] 
//
[0.x.12310] 
//
[0.x.12311] 
[0.x.12312] 
//
//  [2.x.1857] 
//
// The time lag scheme we use for advancing the coupled Stokes-temperature system forces us to split up the assembly (and the solution of linear systems) into two step. The first one is to create the Stokes system matrix and right hand side, and the second is to create matrix and right hand sides for the temperature dofs, which depends on the result of the linear system for the velocity.
//
// This function is called at the beginning of each time step. In the first time step or if the mesh has changed, indicated by the  [2.x.1858] , we need to assemble the Stokes matrix; on the other hand, if the mesh hasn't changed and the matrix is already available, this is not necessary and all we need to do is assemble the right hand side vector which changes in each time step.
//
// Regarding the technical details of implementation, not much has changed from  [2.x.1859] . We reset matrix and vector, create a quadrature formula on the cells, and then create the respective FEValues object. For the update flags, we require basis function derivatives only in case of a full assembly, since they are not needed for the right hand side; as always, choosing the minimal set of flags depending on what is currently needed makes the call to  [2.x.1860]  further down in the program more efficient.
//
// There is one thing that needs to be commented &ndash; since we have a separate finite element and DoFHandler for the temperature, we need to generate a second FEValues object for the proper evaluation of the temperature solution. This isn't too complicated to realize here: just use the temperature structures and set an update flag for the basis function values which we need for evaluation of the temperature solution. The only important part to remember here is that the same quadrature formula is used for both FEValues objects to ensure that we get matching information when we loop over the quadrature points of the two objects.
//
// The declarations proceed with some shortcuts for array sizes, the creation of the local matrix and right hand side as well as the vector for the indices of the local dofs compared to the global system.
//
[0.x.12313] 
[0.x.12314] 
[0.x.12315] 
[0.x.12316] 
//
[0.x.12317] 
[0.x.12318] 
//
[0.x.12319] 
//
[0.x.12320] 
[0.x.12321] 
[0.x.12322] 
[0.x.12323] 
[0.x.12324] 
[0.x.12325] 
//
[0.x.12326] 
[0.x.12327] 
[0.x.12328] 
//
[0.x.12329] 
[0.x.12330] 
//
[0.x.12331] 
[0.x.12332] 
//
[0.x.12333] 
//
// Next we need a vector that will contain the values of the temperature solution at the previous time level at the quadrature points to assemble the source term in the right hand side of the momentum equation. Let's call this vector  [2.x.1861] .
//
// The set of vectors we create next hold the evaluations of the basis functions as well as their gradients and symmetrized gradients that will be used for creating the matrices. Putting these into their own arrays rather than asking the FEValues object for this information each time it is needed is an optimization to accelerate the assembly process, see  [2.x.1862]  for details.
//
// The last two declarations are used to extract the individual blocks (velocity, pressure, temperature) from the total FE system.
//
[0.x.12334] 
//
[0.x.12335] 
[0.x.12336] 
[0.x.12337] 
[0.x.12338] 
//
[0.x.12339] 
[0.x.12340] 
//
// Now start the loop over all cells in the problem. We are working on two different DoFHandlers for this assembly routine, so we must have two different cell iterators for the two objects in use. This might seem a bit peculiar, since both the Stokes system and the temperature system use the same grid, but that's the only way to keep degrees of freedom in sync. The first statements within the loop are again all very familiar, doing the update of the finite element data as specified by the update flags, zeroing out the local arrays and getting the values of the old solution at the quadrature points. Then we are ready to loop over the quadrature points on the cell.
//
[0.x.12341] 
[0.x.12342] 
[0.x.12343] 
//
[0.x.12344] 
[0.x.12345] 
[0.x.12346] 
[0.x.12347] 
//
[0.x.12348] 
[0.x.12349] 
//
[0.x.12350] 
[0.x.12351] 
//
[0.x.12352] 
[0.x.12353] 
[0.x.12354] 
//
//   Next we extract the values and gradients of basis functions   relevant to the terms in the inner products. As shown in    [2.x.1863]  this helps accelerate assembly.     Once this is done, we start the loop over the rows and columns   of the local matrix and feed the matrix with the relevant   products. The right hand side is filled with the forcing term   driven by temperature in direction of gravity (which is   vertical in our example).  Note that the right hand side term   is always generated, whereas the matrix contributions are only   updated when it is requested by the    [2.x.1864]  flag.
//
[0.x.12355] 
[0.x.12356] 
[0.x.12357] 
[0.x.12358] 
[0.x.12359] 
[0.x.12360] 
[0.x.12361] 
[0.x.12362] 
[0.x.12363] 
[0.x.12364] 
[0.x.12365] 
[0.x.12366] 
//
[0.x.12367] 
[0.x.12368] 
[0.x.12369] 
[0.x.12370] 
[0.x.12371] 
[0.x.12372] 
[0.x.12373] 
//
[0.x.12374] 
[0.x.12375] 
[0.x.12376] 
[0.x.12377] 
[0.x.12378] 
[0.x.12379] 
[0.x.12380] 
//
// The last step in the loop over all cells is to enter the local contributions into the global matrix and vector structures to the positions specified in  [2.x.1865] .  Again, we let the AffineConstraints class do the insertion of the cell matrix elements to the global matrix, which already condenses the hanging node constraints.
//
[0.x.12381] 
//
[0.x.12382] 
[0.x.12383] 
[0.x.12384] 
[0.x.12385] 
[0.x.12386] 
[0.x.12387] 
[0.x.12388] 
[0.x.12389] 
[0.x.12390] 
[0.x.12391] 
[0.x.12392] 
//
[0.x.12393] 
//
[0.x.12394] 
[0.x.12395] 
//
//  [2.x.1866] 
//
// This function assembles the matrix in the temperature equation. The temperature matrix consists of two parts, a mass matrix and the time step size times a stiffness matrix given by a Laplace term times the amount of diffusion. Since the matrix depends on the time step size (which varies from one step to another), the temperature matrix needs to be updated every time step. We could simply regenerate the matrices in every time step, but this is not really efficient since mass and Laplace matrix do only change when we change the mesh. Hence, we do this more efficiently by generating two separate matrices in this function, one for the mass matrix and one for the stiffness (diffusion) matrix. We will then sum up the matrix plus the stiffness matrix times the time step size once we know the actual time step.
//
// So the details for this first step are very simple. In case we need to rebuild the matrix (i.e., the mesh has changed), we zero the data structures, get a quadrature formula and a FEValues object, and create local matrices, local dof indices and evaluation structures for the basis functions.
//
[0.x.12396] 
[0.x.12397] 
[0.x.12398] 
[0.x.12399] 
[0.x.12400] 
//
[0.x.12401] 
[0.x.12402] 
//
[0.x.12403] 
[0.x.12404] 
[0.x.12405] 
[0.x.12406] 
[0.x.12407] 
//
[0.x.12408] 
[0.x.12409] 
//
[0.x.12410] 
[0.x.12411] 
//
[0.x.12412] 
//
[0.x.12413] 
[0.x.12414] 
//
// Now, let's start the loop over all cells in the triangulation. We need to zero out the local matrices, update the finite element evaluations, and then loop over the rows and columns of the matrices on each quadrature point, where we then create the mass matrix and the stiffness matrix (Laplace terms times the diffusion  [2.x.1867] . Finally, we let the constraints object insert these values into the global matrix, and directly condense the constraints into the matrix.
//
[0.x.12415] 
[0.x.12416] 
[0.x.12417] 
[0.x.12418] 
//
[0.x.12419] 
//
[0.x.12420] 
[0.x.12421] 
[0.x.12422] 
[0.x.12423] 
[0.x.12424] 
[0.x.12425] 
[0.x.12426] 
//
[0.x.12427] 
[0.x.12428] 
[0.x.12429] 
[0.x.12430] 
[0.x.12431] 
[0.x.12432] 
[0.x.12433] 
[0.x.12434] 
[0.x.12435] 
[0.x.12436] 
//
[0.x.12437] 
//
[0.x.12438] 
[0.x.12439] 
[0.x.12440] 
[0.x.12441] 
[0.x.12442] 
[0.x.12443] 
[0.x.12444] 
//
[0.x.12445] 
[0.x.12446] 
//
//  [2.x.1868] 
//
// This function does the second part of the assembly work on the temperature matrix, the actual addition of pressure mass and stiffness matrix (where the time step size comes into play), as well as the creation of the velocity-dependent right hand side. The declarations for the right hand side assembly in this function are pretty much the same as the ones used in the other assembly routines, except that we restrict ourselves to vectors this time. We are going to calculate residuals on the temperature system, which means that we have to evaluate second derivatives, specified by the update flag  [2.x.1869] .
//
// The temperature equation is coupled to the Stokes system by means of the fluid velocity. These two parts of the solution are associated with different DoFHandlers, so we again need to create a second FEValues object for the evaluation of the velocity at the quadrature points.
//
[0.x.12447] 
[0.x.12448] 
[0.x.12449] 
[0.x.12450] 
[0.x.12451] 
//
[0.x.12452] 
[0.x.12453] 
[0.x.12454] 
[0.x.12455] 
[0.x.12456] 
[0.x.12457] 
[0.x.12458] 
[0.x.12459] 
[0.x.12460] 
[0.x.12461] 
[0.x.12462] 
[0.x.12463] 
//
[0.x.12464] 
//
[0.x.12465] 
[0.x.12466] 
[0.x.12467] 
[0.x.12468] 
[0.x.12469] 
[0.x.12470] 
[0.x.12471] 
[0.x.12472] 
[0.x.12473] 
[0.x.12474] 
//
[0.x.12475] 
[0.x.12476] 
//
[0.x.12477] 
//
[0.x.12478] 
//
// Next comes the declaration of vectors to hold the old and older solution values (as a notation for time levels  [2.x.1870]  and  [2.x.1871] , respectively) and gradients at quadrature points of the current cell. We also declare an object to hold the temperature right hand side values ( [2.x.1872] ), and we again use shortcuts for the temperature basis functions. Eventually, we need to find the temperature extrema and the diameter of the computational domain which will be used for the definition of the stabilization parameter (we got the maximal velocity as an input to this function).
//
[0.x.12479] 
[0.x.12480] 
[0.x.12481] 
[0.x.12482] 
[0.x.12483] 
[0.x.12484] 
[0.x.12485] 
[0.x.12486] 
//
[0.x.12487] 
[0.x.12488] 
//
[0.x.12489] 
[0.x.12490] 
//
[0.x.12491] 
[0.x.12492] 
//
[0.x.12493] 
//
// Now, let's start the loop over all cells in the triangulation. Again, we need two cell iterators that walk in parallel through the cells of the two involved DoFHandler objects for the Stokes and temperature part. Within the loop, we first set the local rhs to zero, and then get the values and derivatives of the old solution functions at the quadrature points, since they are going to be needed for the definition of the stabilization parameters and as coefficients in the equation, respectively. Note that since the temperature has its own DoFHandler and FEValues object we get the entire solution at the quadrature point (which is the scalar temperature field only anyway) whereas for the Stokes part we restrict ourselves to extracting the velocity part (and ignoring the pressure part) by using  [2.x.1873] .
//
[0.x.12494] 
[0.x.12495] 
[0.x.12496] 
//
[0.x.12497] 
[0.x.12498] 
[0.x.12499] 
//
[0.x.12500] 
[0.x.12501] 
//
[0.x.12502] 
[0.x.12503] 
[0.x.12504] 
[0.x.12505] 
//
[0.x.12506] 
[0.x.12507] 
[0.x.12508] 
[0.x.12509] 
//
[0.x.12510] 
[0.x.12511] 
[0.x.12512] 
[0.x.12513] 
//
[0.x.12514] 
[0.x.12515] 
//
[0.x.12516] 
[0.x.12517] 
[0.x.12518] 
[0.x.12519] 
//
// Next, we calculate the artificial viscosity for stabilization according to the discussion in the introduction using the dedicated function. With that at hand, we can get into the loop over quadrature points and local rhs vector components. The terms here are quite lengthy, but their definition follows the time-discrete system developed in the introduction of this program. The BDF-2 scheme needs one more term from the old time step (and involves more complicated factors) than the backward Euler scheme that is used for the first time step. When all this is done, we distribute the local vector into the global one (including hanging node constraints).
//
[0.x.12520] 
[0.x.12521] 
[0.x.12522] 
[0.x.12523] 
[0.x.12524] 
[0.x.12525] 
[0.x.12526] 
[0.x.12527] 
[0.x.12528] 
[0.x.12529] 
[0.x.12530] 
[0.x.12531] 
[0.x.12532] 
//
[0.x.12533] 
[0.x.12534] 
[0.x.12535] 
[0.x.12536] 
[0.x.12537] 
[0.x.12538] 
[0.x.12539] 
//
[0.x.12540] 
[0.x.12541] 
[0.x.12542] 
[0.x.12543] 
[0.x.12544] 
[0.x.12545] 
//
[0.x.12546] 
[0.x.12547] 
[0.x.12548] 
[0.x.12549] 
[0.x.12550] 
//
[0.x.12551] 
[0.x.12552] 
[0.x.12553] 
[0.x.12554] 
[0.x.12555] 
//
[0.x.12556] 
[0.x.12557] 
[0.x.12558] 
[0.x.12559] 
[0.x.12560] 
[0.x.12561] 
[0.x.12562] 
[0.x.12563] 
//
[0.x.12564] 
[0.x.12565] 
[0.x.12566] 
[0.x.12567] 
[0.x.12568] 
[0.x.12569] 
//
//  [2.x.1874] 
//
// This function solves the linear systems of equations. Following the introduction, we start with the Stokes system, where we need to generate our block Schur preconditioner. Since all the relevant actions are implemented in the class  [2.x.1875] , all we have to do is to initialize the class appropriately. What we need to pass down is an  [2.x.1876]  object for the pressure mass matrix, which we set up using the respective class together with the IC preconditioner we already generated, and the AMG preconditioner for the velocity-velocity matrix. Note that both  [2.x.1877]  and  [2.x.1878]  are only pointers, so we use  [2.x.1879]  to pass down the actual preconditioner objects.
//
// Once the preconditioner is ready, we create a GMRES solver for the block system. Since we are working with Trilinos data structures, we have to set the respective template argument in the solver. GMRES needs to internally store temporary vectors for each iteration (see the discussion in the results section of  [2.x.1880] ) &ndash; the more vectors it can use, the better it will generally perform. To keep memory demands in check, we set the number of vectors to 100. This means that up to 100 solver iterations, every temporary vector can be stored. If the solver needs to iterate more often to get the specified tolerance, it will work on a reduced set of vectors by restarting at every 100 iterations.
//
// With this all set up, we solve the system and distribute the constraints in the Stokes system, i.e., hanging nodes and no-flux boundary condition, in order to have the appropriate solution values even at constrained dofs. Finally, we write the number of iterations to the screen.
//
[0.x.12570] 
[0.x.12571] 
[0.x.12572] 
[0.x.12573] 
//
[0.x.12574] 
[0.x.12575] 
[0.x.12576] 
[0.x.12577] 
[0.x.12578] 
//
[0.x.12579] 
[0.x.12580] 
[0.x.12581] 
[0.x.12582] 
//
[0.x.12583] 
[0.x.12584] 
//
[0.x.12585] 
[0.x.12586] 
[0.x.12587] 
//
[0.x.12588] 
[0.x.12589] 
[0.x.12590] 
//
[0.x.12591] 
//
[0.x.12592] 
//
[0.x.12593] 
[0.x.12594] 
[0.x.12595] 
//
// Once we know the Stokes solution, we can determine the new time step from the maximal velocity. We have to do this to satisfy the CFL condition since convection terms are treated explicitly in the temperature equation, as discussed in the introduction. The exact form of the formula used here for the time step is discussed in the results section of this program.
//
// There is a snatch here. The formula contains a division by the maximum value of the velocity. However, at the start of the computation, we have a constant temperature field (we start with a constant temperature, and it will be nonconstant only after the first time step during which the source acts). Constant temperature means that no buoyancy acts, and so the velocity is zero. Dividing by it will not likely lead to anything good.
//
// To avoid the resulting infinite time step, we ask whether the maximal velocity is very small (in particular smaller than the values we encounter during any of the following time steps) and if so rather than dividing by zero we just divide by a small value, resulting in a large but finite time step.
//
[0.x.12596] 
[0.x.12597] 
//
[0.x.12598] 
[0.x.12599] 
[0.x.12600] 
[0.x.12601] 
[0.x.12602] 
[0.x.12603] 
[0.x.12604] 
//
[0.x.12605] 
[0.x.12606] 
//
[0.x.12607] 
//
// Next we set up the temperature system and the right hand side using the function  [2.x.1881] .  Knowing the matrix and right hand side of the temperature equation, we set up a preconditioner and a solver. The temperature matrix is a mass matrix (with eigenvalues around one) plus a Laplace matrix (with eigenvalues between zero and  [2.x.1882] ) times a small number proportional to the time step  [2.x.1883] . Hence, the resulting symmetric and positive definite matrix has eigenvalues in the range  [2.x.1884]  (up to constants). This matrix is only moderately ill conditioned even for small mesh sizes and we get a reasonably good preconditioner by simple means, for example with an incomplete Cholesky decomposition preconditioner (IC) as we also use for preconditioning the pressure mass matrix solver. As a solver, we choose the conjugate gradient method CG. As before, we tell the solver to use Trilinos vectors via the template argument  [2.x.1885] . Finally, we solve, distribute the hanging node constraints and write out the number of iterations.
//
[0.x.12608] 
[0.x.12609] 
[0.x.12610] 
[0.x.12611] 
[0.x.12612] 
//
[0.x.12613] 
[0.x.12614] 
//
[0.x.12615] 
[0.x.12616] 
[0.x.12617] 
[0.x.12618] 
//
[0.x.12619] 
//
[0.x.12620] 
[0.x.12621] 
//
// At the end of this function, we step through the vector and read out the maximum and minimum temperature value, which we also want to output. This will come in handy when determining the correct constant in the choice of time step as discuss in the results section of this program.
//
[0.x.12622] 
[0.x.12623] 
[0.x.12624] 
[0.x.12625] 
[0.x.12626] 
[0.x.12627] 
[0.x.12628] 
[0.x.12629] 
[0.x.12630] 
//
[0.x.12631] 
[0.x.12632] 
[0.x.12633] 
[0.x.12634] 
//
//  [2.x.1886] 
//
// This function writes the solution to a VTK output file for visualization, which is done every tenth time step. This is usually quite a simple task, since the deal.II library provides functions that do almost all the job for us. There is one new function compared to previous examples: We want to visualize both the Stokes solution and the temperature as one data set, but we have done all the calculations based on two different DoFHandler objects. Luckily, the DataOut class is prepared to deal with it. All we have to do is to not attach one single DoFHandler at the beginning and then use that for all added vector, but specify the DoFHandler to each vector separately. The rest is done as in  [2.x.1887] . We create solution names (that are going to appear in the visualization program for the individual components). The first  [2.x.1888]  components are the vector velocity, and then we have pressure for the Stokes part, whereas temperature is scalar. This information is read out using the DataComponentInterpretation helper class. Next, we actually attach the data vectors with their DoFHandler objects, build patches according to the degree of freedom, which are (sub-) elements that describe the data for visualization programs. Finally, we open a file (that includes the time step number) and write the vtk data into it.
//
[0.x.12635] 
[0.x.12636] 
[0.x.12637] 
[0.x.12638] 
[0.x.12639] 
//
[0.x.12640] 
[0.x.12641] 
[0.x.12642] 
[0.x.12643] 
[0.x.12644] 
[0.x.12645] 
[0.x.12646] 
[0.x.12647] 
//
[0.x.12648] 
[0.x.12649] 
[0.x.12650] 
[0.x.12651] 
[0.x.12652] 
[0.x.12653] 
[0.x.12654] 
[0.x.12655] 
[0.x.12656] 
//
[0.x.12657] 
[0.x.12658] 
[0.x.12659] 
[0.x.12660] 
//
//  [2.x.1889] 
//
// This function takes care of the adaptive mesh refinement. The three tasks this function performs is to first find out which cells to refine/coarsen, then to actually do the refinement and eventually transfer the solution vectors between the two different grids. The first task is simply achieved by using the well-established Kelly error estimator on the temperature (it is the temperature we're mainly interested in for this program, and we need to be accurate in regions of high temperature gradients, also to not have too much numerical diffusion). The second task is to actually do the remeshing. That involves only basic functions as well, such as the  [2.x.1890]  that refines those cells with the largest estimated error that together make up 80 per cent of the error, and coarsens those cells with the smallest error that make up for a combined 10 per cent of the error.
//
// If implemented like this, we would get a program that will not make much progress: Remember that we expect temperature fields that are nearly discontinuous (the diffusivity  [2.x.1891]  is very small after all) and consequently we can expect that a freely adapted mesh will refine further and further into the areas of large gradients. This decrease in mesh size will then be accompanied by a decrease in time step, requiring an exceedingly large number of time steps to solve to a given final time. It will also lead to meshes that are much better at resolving discontinuities after several mesh refinement cycles than in the beginning.
//
// In particular to prevent the decrease in time step size and the correspondingly large number of time steps, we limit the maximal refinement depth of the mesh. To this end, after the refinement indicator has been applied to the cells, we simply loop over all cells on the finest level and unselect them from refinement if they would result in too high a mesh level.
//
[0.x.12661] 
[0.x.12662] 
[0.x.12663] 
[0.x.12664] 
[0.x.12665] 
//
[0.x.12666] 
[0.x.12667] 
[0.x.12668] 
[0.x.12669] 
[0.x.12670] 
//
[0.x.12671] 
[0.x.12672] 
[0.x.12673] 
[0.x.12674] 
[0.x.12675] 
[0.x.12676] 
[0.x.12677] 
[0.x.12678] 
//
// As part of mesh refinement we need to transfer the solution vectors from the old mesh to the new one. To this end we use the SolutionTransfer class and we have to prepare the solution vectors that should be transferred to the new grid (we will lose the old grid once we have done the refinement so the transfer has to happen concurrently with refinement). What we definitely need are the current and the old temperature (BDF-2 time stepping requires two old solutions). Since the SolutionTransfer objects only support to transfer one object per dof handler, we need to collect the two temperature solutions in one data structure. Moreover, we choose to transfer the Stokes solution, too, since we need the velocity at two previous time steps, of which only one is calculated on the fly.
//
// Consequently, we initialize two SolutionTransfer objects for the Stokes and temperature DoFHandler objects, by attaching them to the old dof handlers. With this at place, we can prepare the triangulation and the data vectors for refinement (in this order).
//
[0.x.12679] 
[0.x.12680] 
[0.x.12681] 
[0.x.12682] 
//
[0.x.12683] 
[0.x.12684] 
[0.x.12685] 
[0.x.12686] 
//
[0.x.12687] 
[0.x.12688] 
[0.x.12689] 
//
// Now everything is ready, so do the refinement and recreate the dof structure on the new grid, and initialize the matrix structures and the new vectors in the  [2.x.1892]  function. Next, we actually perform the interpolation of the solutions between the grids. We create another copy of temporary vectors for temperature (now corresponding to the new grid), and let the interpolate function do the job. Then, the resulting array of vectors is written into the respective vector member variables.
//
// Remember that the set of constraints will be updated for the new triangulation in the setup_dofs() call.
//
[0.x.12690] 
[0.x.12691] 
//
[0.x.12692] 
[0.x.12693] 
[0.x.12694] 
[0.x.12695] 
//
[0.x.12696] 
[0.x.12697] 
//
// After the solution has been transferred we then enforce the constraints on the transferred solution.
//
[0.x.12698] 
[0.x.12699] 
//
// For the Stokes vector, everything is just the same &ndash; except that we do not need another temporary vector since we just interpolate a single vector. In the end, we have to tell the program that the matrices and preconditioners need to be regenerated, since the mesh has changed.
//
[0.x.12700] 
//
[0.x.12701] 
//
[0.x.12702] 
[0.x.12703] 
[0.x.12704] 
[0.x.12705] 
//
//  [2.x.1893] 
//
// This function performs all the essential steps in the Boussinesq program. It starts by setting up a grid (depending on the spatial dimension, we choose some different level of initial refinement and additional adaptive refinement steps, and then create a cube in  [2.x.1894]  dimensions and set up the dofs for the first time. Since we want to start the time stepping already with an adaptively refined grid, we perform some pre-refinement steps, consisting of all assembly, solution and refinement, but without actually advancing in time. Rather, we use the vilified  [2.x.1895]  statement to jump out of the time loop right after mesh refinement to start all over again on the new mesh beginning at the  [2.x.1896]  label. (The use of the  [2.x.1897]  is discussed in  [2.x.1898] .)
//
// Before we start, we project the initial values to the grid and obtain the first data for the  [2.x.1899]  vector. Then, we initialize time step number and time step and start the time loop.
//
[0.x.12706] 
[0.x.12707] 
[0.x.12708] 
[0.x.12709] 
[0.x.12710] 
//
[0.x.12711] 
[0.x.12712] 
//
[0.x.12713] 
//
[0.x.12714] 
//
[0.x.12715] 
//
[0.x.12716] 
//
[0.x.12717] 
[0.x.12718] 
[0.x.12719] 
[0.x.12720] 
[0.x.12721] 
//
[0.x.12722] 
[0.x.12723] 
//
[0.x.12724] 
//
[0.x.12725] 
[0.x.12726] 
[0.x.12727] 
[0.x.12728] 
//
// The first steps in the time loop are all obvious &ndash; we assemble the Stokes system, the preconditioner, the temperature matrix (matrices and preconditioner do actually only change in case we've remeshed before), and then do the solve. Before going on with the next time step, we have to check whether we should first finish the pre-refinement steps or if we should remesh (every fifth time step), refining up to a level that is consistent with initial refinement and pre-refinement steps. Last in the loop is to advance the solutions, i.e., to copy the solutions to the next "older" time level.
//
[0.x.12729] 
[0.x.12730] 
[0.x.12731] 
//
[0.x.12732] 
//
[0.x.12733] 
//
[0.x.12734] 
//
[0.x.12735] 
[0.x.12736] 
[0.x.12737] 
[0.x.12738] 
[0.x.12739] 
[0.x.12740] 
[0.x.12741] 
[0.x.12742] 
[0.x.12743] 
//
[0.x.12744] 
[0.x.12745] 
//
[0.x.12746] 
[0.x.12747] 
[0.x.12748] 
[0.x.12749] 
//
// Do all the above until we arrive at time 100.
//
[0.x.12750] 
[0.x.12751] 
[0.x.12752] 
//
//  [2.x.1900] 
//
// The main function looks almost the same as in all other programs.
//
// There is one difference we have to be careful about. This program uses Trilinos and, typically, Trilinos is configured so that it can run in %parallel using MPI. This doesn't mean that it [1.x.53] to run in %parallel, and in fact this program (unlike  [2.x.1901] ) makes no attempt at all to do anything in %parallel using MPI. Nevertheless, Trilinos wants the MPI system to be initialized. We do that be creating an object of type  [2.x.1902]  that initializes MPI (if available) using the arguments given to main() (i.e.,  [2.x.1903]  and  [2.x.1904] ) and de-initializes it again when the object goes out of scope.
//
[0.x.12753] 
[0.x.12754] 
[0.x.12755] 
[0.x.12756] 
[0.x.12757] 
[0.x.12758] 
//
[0.x.12759] 
[0.x.12760] 
//
// This program can only be run in serial. Otherwise, throw an exception.
//
[0.x.12761] 
[0.x.12762] 
[0.x.12763] 
//
[0.x.12764] 
[0.x.12765] 
[0.x.12766] 
[0.x.12767] 
[0.x.12768] 
[0.x.12769] 
[0.x.12770] 
[0.x.12771] 
[0.x.12772] 
[0.x.12773] 
[0.x.12774] 
[0.x.12775] 
[0.x.12776] 
[0.x.12777] 
//
[0.x.12778] 
[0.x.12779] 
[0.x.12780] 
[0.x.12781] 
[0.x.12782] 
[0.x.12783] 
[0.x.12784] 
[0.x.12785] 
[0.x.12786] 
[0.x.12787] 
[0.x.12788] 
[0.x.12789] 
[0.x.12790] 
[0.x.12791] 
//
[0.x.12792] 
[0.x.12793] 
[0.x.12794] 
[0.x.12795] 
[0.x.12796] 
[0.x.12797] 
[0.x.12798] 
[0.x.12799] 
[0.x.12800] 
[0.x.12801] 
[0.x.12802] 
[0.x.12803] 
[0.x.12804] 
[0.x.12805] 
[0.x.12806] 
[0.x.12807] 
//
[0.x.12808] 
[0.x.12809] 
[0.x.12810] 
[0.x.12811] 
[0.x.12812] 
//[2.x.1905] 
//
// The first task as usual is to include the functionality of these well-known deal.II library files and some C++ header files.
//
[0.x.12813] 
[0.x.12814] 
[0.x.12815] 
[0.x.12816] 
[0.x.12817] 
[0.x.12818] 
[0.x.12819] 
[0.x.12820] 
//
[0.x.12821] 
[0.x.12822] 
[0.x.12823] 
[0.x.12824] 
[0.x.12825] 
[0.x.12826] 
[0.x.12827] 
[0.x.12828] 
[0.x.12829] 
[0.x.12830] 
[0.x.12831] 
//
[0.x.12832] 
[0.x.12833] 
[0.x.12834] 
[0.x.12835] 
[0.x.12836] 
[0.x.12837] 
//
[0.x.12838] 
[0.x.12839] 
[0.x.12840] 
//
[0.x.12841] 
[0.x.12842] 
[0.x.12843] 
[0.x.12844] 
[0.x.12845] 
[0.x.12846] 
//
[0.x.12847] 
[0.x.12848] 
[0.x.12849] 
[0.x.12850] 
[0.x.12851] 
//
[0.x.12852] 
[0.x.12853] 
[0.x.12854] 
[0.x.12855] 
[0.x.12856] 
//
// This is the only include file that is new: It introduces the  [2.x.1906]  equivalent of the  [2.x.1907]  class to take a solution from on mesh to the next one upon mesh refinement, but in the case of parallel distributed triangulations:
//
[0.x.12857] 
//
// The following classes are used in parallel distributed computations and have all already been introduced in  [2.x.1908] :
//
[0.x.12858] 
[0.x.12859] 
[0.x.12860] 
//
// The next step is like in all previous tutorial programs: We put everything into a namespace of its own and then import the deal.II classes and functions into it:
//
[0.x.12861] 
[0.x.12862] 
[0.x.12863] 
//[2.x.1909] 
//
// In the following namespace, we define the various pieces of equation data that describe the problem. This corresponds to the various aspects of making the problem at least slightly realistic and that were exhaustively discussed in the description of the testcase in the introduction.
//
// We start with a few coefficients that have constant values (the comment after the value indicates its physical units):
//
[0.x.12864] 
[0.x.12865] 
[0.x.12866] 
[0.x.12867] 
[0.x.12868] 
[0.x.12869] 
[0.x.12870] 
[0.x.12871] 
[0.x.12872] 
//
[0.x.12873] 
[0.x.12874] 
//
[0.x.12875] 
[0.x.12876] 
//
// The next set of definitions are for functions that encode the density as a function of temperature, the gravity vector, and the initial values for the temperature. Again, all of these (along with the values they compute) are discussed in the introduction:
//
[0.x.12877] 
[0.x.12878] 
[0.x.12879] 
[0.x.12880] 
[0.x.12881] 
[0.x.12882] 
//
[0.x.12883] 
[0.x.12884] 
[0.x.12885] 
[0.x.12886] 
[0.x.12887] 
[0.x.12888] 
//
[0.x.12889] 
[0.x.12890] 
[0.x.12891] 
[0.x.12892] 
[0.x.12893] 
[0.x.12894] 
[0.x.12895] 
//
[0.x.12896] 
[0.x.12897] 
//
[0.x.12898] 
[0.x.12899] 
[0.x.12900] 
//
[0.x.12901] 
[0.x.12902] 
[0.x.12903] 
[0.x.12904] 
[0.x.12905] 
[0.x.12906] 
//
[0.x.12907] 
[0.x.12908] 
[0.x.12909] 
[0.x.12910] 
[0.x.12911] 
//
[0.x.12912] 
[0.x.12913] 
//
[0.x.12914] 
[0.x.12915] 
[0.x.12916] 
[0.x.12917] 
[0.x.12918] 
[0.x.12919] 
[0.x.12920] 
[0.x.12921] 
//
// As mentioned in the introduction we need to rescale the pressure to avoid the relative ill-conditioning of the momentum and mass conservation equations. The scaling factor is  [2.x.1910]  where  [2.x.1911]  was a typical length scale. By experimenting it turns out that a good length scale is the diameter of plumes, which is around 10 km:
//
[0.x.12922] 
//
// The final number in this namespace is a constant that denotes the number of seconds per (average, tropical) year. We use this only when generating screen output: internally, all computations of this program happen in SI units (kilogram, meter, seconds) but writing geological times in seconds yields numbers that one can't relate to reality, and so we convert to years using the factor defined here:
//
[0.x.12923] 
//
[0.x.12924] 
//
//  [2.x.1912] 
//
// This namespace implements the preconditioner. As discussed in the introduction, this preconditioner differs in a number of key portions from the one used in  [2.x.1913] . Specifically, it is a right preconditioner, implementing the matrix [1.x.54] where the two inverse matrix operations are approximated by linear solvers or, if the right flag is given to the constructor of this class, by a single AMG V-cycle for the velocity block. The three code blocks of the  [2.x.1914]  function implement the multiplications with the three blocks of this preconditioner matrix and should be self explanatory if you have read through  [2.x.1915]  or the discussion of composing solvers in  [2.x.1916] .
//
[0.x.12925] 
[0.x.12926] 
[0.x.12927] 
[0.x.12928] 
[0.x.12929] 
[0.x.12930] 
[0.x.12931] 
[0.x.12932] 
[0.x.12933] 
[0.x.12934] 
[0.x.12935] 
[0.x.12936] 
[0.x.12937] 
[0.x.12938] 
[0.x.12939] 
[0.x.12940] 
[0.x.12941] 
//
[0.x.12942] 
[0.x.12943] 
[0.x.12944] 
[0.x.12945] 
//
[0.x.12946] 
[0.x.12947] 
//
[0.x.12948] 
//
[0.x.12949] 
[0.x.12950] 
[0.x.12951] 
[0.x.12952] 
//
[0.x.12953] 
[0.x.12954] 
//
[0.x.12955] 
[0.x.12956] 
[0.x.12957] 
[0.x.12958] 
[0.x.12959] 
//
[0.x.12960] 
[0.x.12961] 
[0.x.12962] 
[0.x.12963] 
[0.x.12964] 
[0.x.12965] 
[0.x.12966] 
[0.x.12967] 
[0.x.12968] 
[0.x.12969] 
[0.x.12970] 
[0.x.12971] 
//
[0.x.12972] 
[0.x.12973] 
[0.x.12974] 
[0.x.12975] 
[0.x.12976] 
[0.x.12977] 
[0.x.12978] 
[0.x.12979] 
[0.x.12980] 
[0.x.12981] 
//
//  [2.x.1917] 
//
// As described in the introduction, we will use the WorkStream mechanism discussed in the  [2.x.1918]  module to parallelize operations among the processors of a single machine. The WorkStream class requires that data is passed around in two kinds of data structures, one for scratch data and one to pass data from the assembly function to the function that copies local contributions into global objects.
//
// The following namespace (and the two sub-namespaces) contains a collection of data structures that serve this purpose, one pair for each of the four operations discussed in the introduction that we will want to parallelize. Each assembly routine gets two sets of data: a Scratch array that collects all the classes and arrays that are used for the calculation of the cell contribution, and a CopyData array that keeps local matrices and vectors which will be written into the global matrix. Whereas CopyData is a container for the final data that is written into the global matrices and vector (and, thus, absolutely necessary), the Scratch arrays are merely there for performance reasons &mdash; it would be much more expensive to set up a FEValues object on each cell, than creating it only once and updating some derivative data.
//
//  [2.x.1919]  had four assembly routines: One for the preconditioner matrix of the Stokes system, one for the Stokes matrix and right hand side, one for the temperature matrices and one for the right hand side of the temperature equation. We here organize the scratch arrays and CopyData objects for each of those four assembly components using a  [2.x.1920]  environment (since we consider these as temporary objects we pass around, rather than classes that implement functionality of their own, though this is a more subjective point of view to distinguish between  [2.x.1921] es).
//
// Regarding the Scratch objects, each struct is equipped with a constructor that creates an  [2.x.1922]  object using the  [2.x.1923] , Quadrature,  [2.x.1924]  (which describes the interpolation of curved boundaries), and  [2.x.1925]  instances. Moreover, we manually implement a copy constructor (since the FEValues class is not copyable by itself), and provide some additional vector fields that are used to hold intermediate data during the computation of local contributions.
//
// Let us start with the scratch arrays and, specifically, the one used for assembly of the Stokes preconditioner:
//
[0.x.12982] 
[0.x.12983] 
[0.x.12984] 
[0.x.12985] 
[0.x.12986] 
[0.x.12987] 
[0.x.12988] 
[0.x.12989] 
[0.x.12990] 
[0.x.12991] 
[0.x.12992] 
//
[0.x.12993] 
//
[0.x.12994] 
//
[0.x.12995] 
[0.x.12996] 
[0.x.12997] 
//
[0.x.12998] 
[0.x.12999] 
[0.x.13000] 
[0.x.13001] 
[0.x.13002] 
[0.x.13003] 
[0.x.13004] 
[0.x.13005] 
[0.x.13006] 
[0.x.13007] 
//
[0.x.13008] 
[0.x.13009] 
[0.x.13010] 
[0.x.13011] 
[0.x.13012] 
[0.x.13013] 
[0.x.13014] 
[0.x.13015] 
[0.x.13016] 
[0.x.13017] 
//
// The next one is the scratch object used for the assembly of the full Stokes system. Observe that we derive the StokesSystem scratch class from the StokesPreconditioner class above. We do this because all the objects that are necessary for the assembly of the preconditioner are also needed for the actual matrix system and right hand side, plus some extra data. This makes the program more compact. Note also that the assembly of the Stokes system and the temperature right hand side further down requires data from temperature and velocity, respectively, so we actually need two FEValues objects for those two cases.
//
[0.x.13018] 
[0.x.13019] 
[0.x.13020] 
[0.x.13021] 
[0.x.13022] 
[0.x.13023] 
[0.x.13024] 
[0.x.13025] 
[0.x.13026] 
//
[0.x.13027] 
//
[0.x.13028] 
//
[0.x.13029] 
[0.x.13030] 
[0.x.13031] 
//
[0.x.13032] 
[0.x.13033] 
//
[0.x.13034] 
[0.x.13035] 
[0.x.13036] 
[0.x.13037] 
[0.x.13038] 
[0.x.13039] 
[0.x.13040] 
[0.x.13041] 
[0.x.13042] 
[0.x.13043] 
[0.x.13044] 
[0.x.13045] 
[0.x.13046] 
[0.x.13047] 
[0.x.13048] 
[0.x.13049] 
[0.x.13050] 
[0.x.13051] 
[0.x.13052] 
[0.x.13053] 
[0.x.13054] 
//
[0.x.13055] 
[0.x.13056] 
[0.x.13057] 
[0.x.13058] 
[0.x.13059] 
[0.x.13060] 
[0.x.13061] 
[0.x.13062] 
[0.x.13063] 
[0.x.13064] 
[0.x.13065] 
[0.x.13066] 
[0.x.13067] 
//
// After defining the objects used in the assembly of the Stokes system, we do the same for the assembly of the matrices necessary for the temperature system. The general structure is very similar:
//
[0.x.13068] 
[0.x.13069] 
[0.x.13070] 
[0.x.13071] 
[0.x.13072] 
[0.x.13073] 
//
[0.x.13074] 
//
[0.x.13075] 
//
[0.x.13076] 
[0.x.13077] 
[0.x.13078] 
//
[0.x.13079] 
[0.x.13080] 
[0.x.13081] 
[0.x.13082] 
[0.x.13083] 
[0.x.13084] 
[0.x.13085] 
[0.x.13086] 
[0.x.13087] 
[0.x.13088] 
[0.x.13089] 
[0.x.13090] 
[0.x.13091] 
//
[0.x.13092] 
[0.x.13093] 
[0.x.13094] 
[0.x.13095] 
[0.x.13096] 
[0.x.13097] 
[0.x.13098] 
[0.x.13099] 
[0.x.13100] 
[0.x.13101] 
[0.x.13102] 
//
// The final scratch object is used in the assembly of the right hand side of the temperature system. This object is significantly larger than the ones above because a lot more quantities enter the computation of the right hand side of the temperature equation. In particular, the temperature values and gradients of the previous two time steps need to be evaluated at the quadrature points, as well as the velocities and the strain rates (i.e. the symmetric gradients of the velocity) that enter the right hand side as friction heating terms. Despite the number of terms, the following should be rather self explanatory:
//
[0.x.13103] 
[0.x.13104] 
[0.x.13105] 
[0.x.13106] 
[0.x.13107] 
[0.x.13108] 
[0.x.13109] 
//
[0.x.13110] 
//
[0.x.13111] 
[0.x.13112] 
//
[0.x.13113] 
[0.x.13114] 
//
[0.x.13115] 
[0.x.13116] 
//
[0.x.13117] 
[0.x.13118] 
//
[0.x.13119] 
[0.x.13120] 
[0.x.13121] 
[0.x.13122] 
[0.x.13123] 
[0.x.13124] 
[0.x.13125] 
//
[0.x.13126] 
[0.x.13127] 
[0.x.13128] 
[0.x.13129] 
[0.x.13130] 
[0.x.13131] 
[0.x.13132] 
[0.x.13133] 
[0.x.13134] 
[0.x.13135] 
[0.x.13136] 
[0.x.13137] 
[0.x.13138] 
[0.x.13139] 
[0.x.13140] 
[0.x.13141] 
[0.x.13142] 
[0.x.13143] 
[0.x.13144] 
//
[0.x.13145] 
[0.x.13146] 
[0.x.13147] 
[0.x.13148] 
[0.x.13149] 
//
[0.x.13150] 
[0.x.13151] 
[0.x.13152] 
[0.x.13153] 
[0.x.13154] 
[0.x.13155] 
[0.x.13156] 
//
[0.x.13157] 
[0.x.13158] 
[0.x.13159] 
[0.x.13160] 
[0.x.13161] 
[0.x.13162] 
[0.x.13163] 
[0.x.13164] 
[0.x.13165] 
[0.x.13166] 
[0.x.13167] 
[0.x.13168] 
[0.x.13169] 
[0.x.13170] 
//
[0.x.13171] 
[0.x.13172] 
[0.x.13173] 
[0.x.13174] 
[0.x.13175] 
//
[0.x.13176] 
[0.x.13177] 
[0.x.13178] 
[0.x.13179] 
[0.x.13180] 
[0.x.13181] 
[0.x.13182] 
[0.x.13183] 
//
// The CopyData objects are even simpler than the Scratch objects as all they have to do is to store the results of local computations until they can be copied into the global matrix or vector objects. These structures therefore only need to provide a constructor, a copy operation, and some arrays for local matrix, local vectors and the relation between local and global degrees of freedom (a.k.a.  [2.x.1926] ). Again, we have one such structure for each of the four operations we will parallelize using the WorkStream class:
//
[0.x.13184] 
[0.x.13185] 
[0.x.13186] 
[0.x.13187] 
[0.x.13188] 
[0.x.13189] 
[0.x.13190] 
[0.x.13191] 
//
[0.x.13192] 
[0.x.13193] 
[0.x.13194] 
//
[0.x.13195] 
[0.x.13196] 
[0.x.13197] 
[0.x.13198] 
[0.x.13199] 
[0.x.13200] 
//
[0.x.13201] 
[0.x.13202] 
[0.x.13203] 
[0.x.13204] 
[0.x.13205] 
[0.x.13206] 
//
[0.x.13207] 
[0.x.13208] 
[0.x.13209] 
[0.x.13210] 
//
[0.x.13211] 
[0.x.13212] 
//
[0.x.13213] 
[0.x.13214] 
[0.x.13215] 
[0.x.13216] 
[0.x.13217] 
//
[0.x.13218] 
[0.x.13219] 
[0.x.13220] 
[0.x.13221] 
//
[0.x.13222] 
[0.x.13223] 
[0.x.13224] 
[0.x.13225] 
//
[0.x.13226] 
[0.x.13227] 
[0.x.13228] 
[0.x.13229] 
[0.x.13230] 
[0.x.13231] 
[0.x.13232] 
[0.x.13233] 
[0.x.13234] 
//
[0.x.13235] 
[0.x.13236] 
[0.x.13237] 
[0.x.13238] 
//
[0.x.13239] 
[0.x.13240] 
[0.x.13241] 
[0.x.13242] 
//
[0.x.13243] 
[0.x.13244] 
[0.x.13245] 
[0.x.13246] 
[0.x.13247] 
[0.x.13248] 
[0.x.13249] 
[0.x.13250] 
[0.x.13251] 
[0.x.13252] 
//
//  [2.x.1927] 
//
// This is the declaration of the main class. It is very similar to  [2.x.1928]  but there are a number differences we will comment on below.
//
// The top of the class is essentially the same as in  [2.x.1929] , listing the public methods and a set of private functions that do the heavy lifting. Compared to  [2.x.1930]  there are only two additions to this section: the function  [2.x.1931]  that computes the maximum CFL number over all cells which we then compute the global time step from, and the function  [2.x.1932]  that is used in the computation of the entropy stabilization. It is akin to the  [2.x.1933]  we have used in  [2.x.1934]  for this purpose, but works on the entropy instead of the temperature instead.
//
[0.x.13253] 
[0.x.13254] 
[0.x.13255] 
[0.x.13256] 
[0.x.13257] 
[0.x.13258] 
[0.x.13259] 
//
[0.x.13260] 
[0.x.13261] 
[0.x.13262] 
[0.x.13263] 
[0.x.13264] 
[0.x.13265] 
[0.x.13266] 
[0.x.13267] 
[0.x.13268] 
[0.x.13269] 
[0.x.13270] 
[0.x.13271] 
[0.x.13272] 
[0.x.13273] 
//
[0.x.13274] 
[0.x.13275] 
[0.x.13276] 
[0.x.13277] 
[0.x.13278] 
[0.x.13279] 
[0.x.13280] 
[0.x.13281] 
[0.x.13282] 
[0.x.13283] 
[0.x.13284] 
[0.x.13285] 
[0.x.13286] 
[0.x.13287] 
[0.x.13288] 
[0.x.13289] 
//
[0.x.13290] 
//
// The first significant new component is the definition of a struct for the parameters according to the discussion in the introduction. This structure is initialized by reading from a parameter file during construction of this object.
//
[0.x.13291] 
[0.x.13292] 
[0.x.13293] 
//
[0.x.13294] 
[0.x.13295] 
//
[0.x.13296] 
//
[0.x.13297] 
[0.x.13298] 
//
[0.x.13299] 
[0.x.13300] 
//
[0.x.13301] 
//
[0.x.13302] 
[0.x.13303] 
[0.x.13304] 
//
[0.x.13305] 
[0.x.13306] 
//
[0.x.13307] 
[0.x.13308] 
//
[0.x.13309] 
[0.x.13310] 
//
// The  [2.x.1935]  (for [1.x.55]) object is used to simplify writing output: each MPI process can use this to generate output as usual, but since each of these processes will (hopefully) produce the same output it will just be replicated many times over; with the ConditionalOStream class, only the output generated by one MPI process will actually be printed to screen, whereas the output by all the other threads will simply be forgotten.
//
[0.x.13311] 
//
// The following member variables will then again be similar to those in  [2.x.1936]  (and to other tutorial programs). As mentioned in the introduction, we fully distribute computations, so we will have to use the  [2.x.1937]  class (see  [2.x.1938] ) but the remainder of these variables is rather standard with two exceptions:
//
//
//
// - The  [2.x.1939]  variable is used to denote a higher-order polynomial mapping. As mentioned in the introduction, we use this mapping when forming integrals through quadrature for all cells that are adjacent to either the inner or outer boundaries of our domain where the boundary is curved.
//
//
//
// - In a bit of naming confusion, you will notice below that some of the variables from namespace TrilinosWrappers are taken from namespace  [2.x.1940]  (such as the right hand side vectors) whereas others are not (such as the various matrices). This is due to legacy reasons. We will frequently have to query velocities and temperatures at arbitrary quadrature points; consequently, rather than importing ghost information of a vector whenever we need access to degrees of freedom that are relevant locally but owned by another processor, we solve linear systems in %parallel but then immediately initialize a vector including ghost entries of the solution for further processing. The various  [2.x.1941]  vectors are therefore filled immediately after solving their respective linear system in %parallel and will always contain values for all  [2.x.1942]  "locally relevant degrees of freedom"; the fully distributed vectors that we obtain from the solution process and that only ever contain the  [2.x.1943]  "locally owned degrees of freedom" are destroyed immediately after the solution process and after we have copied the relevant values into the member variable vectors.
//
[0.x.13312] 
[0.x.13313] 
//
[0.x.13314] 
//
[0.x.13315] 
[0.x.13316] 
[0.x.13317] 
//
[0.x.13318] 
[0.x.13319] 
//
[0.x.13320] 
[0.x.13321] 
[0.x.13322] 
//
[0.x.13323] 
[0.x.13324] 
[0.x.13325] 
//
[0.x.13326] 
[0.x.13327] 
[0.x.13328] 
//
[0.x.13329] 
[0.x.13330] 
[0.x.13331] 
[0.x.13332] 
//
[0.x.13333] 
[0.x.13334] 
[0.x.13335] 
//
[0.x.13336] 
[0.x.13337] 
[0.x.13338] 
//
[0.x.13339] 
[0.x.13340] 
[0.x.13341] 
[0.x.13342] 
//
// The next member variable,  [2.x.1944]  is used to conveniently account for compute time spent in certain "sections" of the code that are repeatedly entered. For example, we will enter (and leave) sections for Stokes matrix assembly and would like to accumulate the run time spent in this section over all time steps. Every so many time steps as well as at the end of the program (through the destructor of the TimerOutput class) we will then produce a nice summary of the times spent in the different sections into which we categorize the run-time of this program.
//
[0.x.13343] 
//
// After these member variables we have a number of auxiliary functions that have been broken out of the ones listed above. Specifically, there are first three functions that we call from  [2.x.1945]  and then the ones that do the assembling of linear systems:
//
[0.x.13344] 
[0.x.13345] 
[0.x.13346] 
[0.x.13347] 
[0.x.13348] 
[0.x.13349] 
[0.x.13350] 
[0.x.13351] 
[0.x.13352] 
//
// Following the  [2.x.1946]  "task-based parallelization" paradigm, we split all the assembly routines into two parts: a first part that can do all the calculations on a certain cell without taking care of other threads, and a second part (which is writing the local data into the global matrices and vectors) which can be entered by only one thread at a time. In order to implement that, we provide functions for each of those two steps for all the four assembly routines that we use in this program. The following eight functions do exactly this:
//
[0.x.13353] 
[0.x.13354] 
[0.x.13355] 
[0.x.13356] 
//
[0.x.13357] 
[0.x.13358] 
//
[0.x.13359] 
[0.x.13360] 
[0.x.13361] 
[0.x.13362] 
//
[0.x.13363] 
[0.x.13364] 
//
[0.x.13365] 
[0.x.13366] 
[0.x.13367] 
[0.x.13368] 
//
[0.x.13369] 
[0.x.13370] 
//
[0.x.13371] 
[0.x.13372] 
[0.x.13373] 
[0.x.13374] 
[0.x.13375] 
[0.x.13376] 
[0.x.13377] 
//
[0.x.13378] 
[0.x.13379] 
//
// Finally, we forward declare a member class that we will define later on and that will be used to compute a number of quantities from our solution vectors that we'd like to put into the output files for visualization.
//
[0.x.13380] 
[0.x.13381] 
//[2.x.1947] 
//[2.x.1948] 
//
// Here comes the definition of the parameters for the Stokes problem. We allow to set the end time for the simulation, the level of refinements (both global and adaptive, which in the sum specify what maximum level the cells are allowed to have), and the interval between refinements in the time stepping.
//
// Then, we let the user specify constants for the stabilization parameters (as discussed in the introduction), the polynomial degree for the Stokes velocity space, whether to use the locally conservative discretization based on FE_DGP elements for the pressure or not (FE_Q elements for pressure), and the polynomial degree for the temperature interpolation.
//
// The constructor checks for a valid input file (if not, a file with default parameters for the quantities is written), and eventually parses the parameters.
//
[0.x.13382] 
[0.x.13383] 
[0.x.13384] 
[0.x.13385] 
[0.x.13386] 
[0.x.13387] 
[0.x.13388] 
[0.x.13389] 
[0.x.13390] 
[0.x.13391] 
[0.x.13392] 
[0.x.13393] 
[0.x.13394] 
[0.x.13395] 
[0.x.13396] 
[0.x.13397] 
//
[0.x.13398] 
//
[0.x.13399] 
[0.x.13400] 
[0.x.13401] 
//
[0.x.13402] 
[0.x.13403] 
//
[0.x.13404] 
[0.x.13405] 
[0.x.13406] 
[0.x.13407] 
[0.x.13408] 
[0.x.13409] 
//
[0.x.13410] 
[0.x.13411] 
[0.x.13412] 
//
// Next we have a function that declares the parameters that we expect in the input file, together with their data types, default values and a description:
//
[0.x.13413] 
[0.x.13414] 
[0.x.13415] 
[0.x.13416] 
[0.x.13417] 
[0.x.13418] 
[0.x.13419] 
[0.x.13420] 
[0.x.13421] 
[0.x.13422] 
[0.x.13423] 
[0.x.13424] 
[0.x.13425] 
[0.x.13426] 
[0.x.13427] 
[0.x.13428] 
[0.x.13429] 
[0.x.13430] 
[0.x.13431] 
[0.x.13432] 
[0.x.13433] 
[0.x.13434] 
[0.x.13435] 
[0.x.13436] 
[0.x.13437] 
[0.x.13438] 
[0.x.13439] 
[0.x.13440] 
[0.x.13441] 
[0.x.13442] 
[0.x.13443] 
[0.x.13444] 
[0.x.13445] 
[0.x.13446] 
[0.x.13447] 
//
[0.x.13448] 
[0.x.13449] 
[0.x.13450] 
[0.x.13451] 
[0.x.13452] 
[0.x.13453] 
[0.x.13454] 
[0.x.13455] 
[0.x.13456] 
[0.x.13457] 
[0.x.13458] 
[0.x.13459] 
[0.x.13460] 
[0.x.13461] 
[0.x.13462] 
[0.x.13463] 
[0.x.13464] 
[0.x.13465] 
[0.x.13466] 
//
[0.x.13467] 
[0.x.13468] 
[0.x.13469] 
[0.x.13470] 
[0.x.13471] 
[0.x.13472] 
[0.x.13473] 
[0.x.13474] 
[0.x.13475] 
[0.x.13476] 
[0.x.13477] 
[0.x.13478] 
[0.x.13479] 
[0.x.13480] 
[0.x.13481] 
[0.x.13482] 
[0.x.13483] 
[0.x.13484] 
[0.x.13485] 
[0.x.13486] 
[0.x.13487] 
[0.x.13488] 
[0.x.13489] 
[0.x.13490] 
[0.x.13491] 
//
// And then we need a function that reads the contents of the ParameterHandler object we get by reading the input file and puts the results into variables that store the values of the parameters we have previously declared:
//
[0.x.13492] 
[0.x.13493] 
[0.x.13494] 
[0.x.13495] 
[0.x.13496] 
[0.x.13497] 
[0.x.13498] 
[0.x.13499] 
//
[0.x.13500] 
[0.x.13501] 
//
[0.x.13502] 
[0.x.13503] 
[0.x.13504] 
//
[0.x.13505] 
[0.x.13506] 
[0.x.13507] 
[0.x.13508] 
[0.x.13509] 
[0.x.13510] 
[0.x.13511] 
//
[0.x.13512] 
[0.x.13513] 
[0.x.13514] 
[0.x.13515] 
[0.x.13516] 
[0.x.13517] 
[0.x.13518] 
[0.x.13519] 
[0.x.13520] 
[0.x.13521] 
//
//  [2.x.1949] 
//
// The constructor of the problem is very similar to the constructor in  [2.x.1950] . What is different is the %parallel communication: Trilinos uses a message passing interface (MPI) for data distribution. When entering the BoussinesqFlowProblem class, we have to decide how the parallelization is to be done. We choose a rather simple strategy and let all processors that are running the program work together, specified by the communicator  [2.x.1951] . Next, we create the output stream (as we already did in  [2.x.1952] ) that only generates output on the first MPI process and is completely forgetful on all others. The implementation of this idea is to check the process number when  [2.x.1953]  gets a true argument, and it uses the  [2.x.1954]  stream for output. If we are one processor five, for instance, then we will give a  [2.x.1955] , which means that the output of that processor will not be printed. With the exception of the mapping object (for which we use polynomials of degree 4) all but the final member variable are exactly the same as in  [2.x.1956] .
//
// This final object, the TimerOutput object, is then told to restrict output to the  [2.x.1957]  stream (processor 0), and then we specify that we want to get a summary table at the end of the program which shows us wallclock times (as opposed to CPU times). We will manually also request intermediate summaries every so many time steps in the  [2.x.1958]  function below.
//
[0.x.13522] 
[0.x.13523] 
[0.x.13524] 
[0.x.13525] 
[0.x.13526] 
//
[0.x.13527] 
[0.x.13528] 
[0.x.13529] 
[0.x.13530] 
[0.x.13531] 
//
[0.x.13532] 
[0.x.13533] 
//
[0.x.13534] 
[0.x.13535] 
//
[0.x.13536] 
[0.x.13537] 
[0.x.13538] 
[0.x.13539] 
[0.x.13540] 
[0.x.13541] 
[0.x.13542] 
[0.x.13543] 
[0.x.13544] 
//
[0.x.13545] 
[0.x.13546] 
//
[0.x.13547] 
[0.x.13548] 
[0.x.13549] 
//
[0.x.13550] 
[0.x.13551] 
[0.x.13552] 
[0.x.13553] 
[0.x.13554] 
[0.x.13555] 
[0.x.13556] 
[0.x.13557] 
//
[0.x.13558] 
[0.x.13559] 
[0.x.13560] 
[0.x.13561] 
[0.x.13562] 
//
//  [2.x.1959] 
//[2.x.1960] 
//
// Except for two small details, the function to compute the global maximum of the velocity is the same as in  [2.x.1961] . The first detail is actually common to all functions that implement loops over all cells in the triangulation: When operating in %parallel, each processor can only work on a chunk of cells since each processor only has a certain part of the entire triangulation. This chunk of cells that we want to work on is identified via a so-called  [2.x.1962] , as we also did in  [2.x.1963] . All we need to change is hence to perform the cell-related operations only on cells that are owned by the current process (as opposed to ghost or artificial cells), i.e. for which the subdomain id equals the number of the process ID. Since this is a commonly used operation, there is a shortcut for this operation: we can ask whether the cell is owned by the current processor using  [2.x.1964] .
//
// The second difference is the way we calculate the maximum value. Before, we could simply have a  [2.x.1965]  variable that we checked against on each quadrature point for each cell. Now, we have to be a bit more careful since each processor only operates on a subset of cells. What we do is to first let each processor calculate the maximum among its cells, and then do a global communication operation  [2.x.1966]  that computes the maximum value among all the maximum values of the individual processors. MPI provides such a call, but it's even simpler to use the respective function in namespace  [2.x.1967]  using the MPI communicator object since that will do the right thing even if we work without MPI and on a single machine only. The call to  [2.x.1968]  needs two arguments, namely the local maximum (input) and the MPI communicator, which is MPI_COMM_WORLD in this example.
//
[0.x.13563] 
[0.x.13564] 
[0.x.13565] 
[0.x.13566] 
[0.x.13567] 
[0.x.13568] 
//
[0.x.13569] 
[0.x.13570] 
[0.x.13571] 
[0.x.13572] 
[0.x.13573] 
//
[0.x.13574] 
//
[0.x.13575] 
//
[0.x.13576] 
[0.x.13577] 
[0.x.13578] 
[0.x.13579] 
[0.x.13580] 
[0.x.13581] 
//
[0.x.13582] 
[0.x.13583] 
[0.x.13584] 
[0.x.13585] 
//
[0.x.13586] 
[0.x.13587] 
//[2.x.1969] 
//
// The next function does something similar, but we now compute the CFL number, i.e., maximal velocity on a cell divided by the cell diameter. This number is necessary to determine the time step size, as we use a semi-explicit time stepping scheme for the temperature equation (see  [2.x.1970]  for a discussion). We compute it in the same way as above: Compute the local maximum over all locally owned cells, then exchange it via MPI to find the global maximum.
//
[0.x.13588] 
[0.x.13589] 
[0.x.13590] 
[0.x.13591] 
[0.x.13592] 
[0.x.13593] 
//
[0.x.13594] 
[0.x.13595] 
[0.x.13596] 
[0.x.13597] 
[0.x.13598] 
//
[0.x.13599] 
//
[0.x.13600] 
//
[0.x.13601] 
[0.x.13602] 
[0.x.13603] 
[0.x.13604] 
[0.x.13605] 
[0.x.13606] 
//
[0.x.13607] 
[0.x.13608] 
[0.x.13609] 
[0.x.13610] 
[0.x.13611] 
[0.x.13612] 
[0.x.13613] 
//
[0.x.13614] 
[0.x.13615] 
//[2.x.1971] 
//
// Next comes the computation of the global entropy variation  [2.x.1972]  where the entropy  [2.x.1973]  is defined as discussed in the introduction.  This is needed for the evaluation of the stabilization in the temperature equation as explained in the introduction. The entropy variation is actually only needed if we use  [2.x.1974]  as a power in the residual computation. The infinity norm is computed by the maxima over quadrature points, as usual in discrete computations.
//
// In order to compute this quantity, we first have to find the space-average  [2.x.1975]  and then evaluate the maximum. However, that means that we would need to perform two loops. We can avoid the overhead by noting that  [2.x.1976] , i.e., the maximum out of the deviation from the average entropy in positive and negative directions. The four quantities we need for the latter formula (maximum entropy, minimum entropy, average entropy, area) can all be evaluated in the same loop over all cells, so we choose this simpler variant.
//
[0.x.13616] 
[0.x.13617] 
[0.x.13618] 
[0.x.13619] 
[0.x.13620] 
[0.x.13621] 
//
[0.x.13622] 
[0.x.13623] 
//
[0.x.13624] 
[0.x.13625] 
[0.x.13626] 
[0.x.13627] 
[0.x.13628] 
//
// In the two functions above we computed the maximum of numbers that were all non-negative, so we knew that zero was certainly a lower bound. On the other hand, here we need to find the maximum deviation from the average value, i.e., we will need to know the maximal and minimal values of the entropy for which we don't a priori know the sign.
//
// To compute it, we can therefore start with the largest and smallest possible values we can store in a double precision number: The minimum is initialized with a bigger and the maximum with a smaller number than any one that is going to appear. We are then guaranteed that these numbers will be overwritten in the loop on the first cell or, if this processor does not own any cells, in the communication step at the latest. The following loop then computes the minimum and maximum local entropy as well as keeps track of the area/volume of the part of the domain we locally own and the integral over the entropy on it:
//
[0.x.13629] 
[0.x.13630] 
[0.x.13631] 
//
[0.x.13632] 
[0.x.13633] 
[0.x.13634] 
[0.x.13635] 
[0.x.13636] 
[0.x.13637] 
[0.x.13638] 
[0.x.13639] 
[0.x.13640] 
[0.x.13641] 
[0.x.13642] 
[0.x.13643] 
[0.x.13644] 
[0.x.13645] 
//
[0.x.13646] 
[0.x.13647] 
[0.x.13648] 
[0.x.13649] 
[0.x.13650] 
[0.x.13651] 
//
// Now we only need to exchange data between processors: we need to sum the two integrals ( [2.x.1977] ), and get the extrema for maximum and minimum. We could do this through four different data exchanges, but we can it with two:  [2.x.1978]  also exists in a variant that takes an array of values that are all to be summed up. And we can also utilize the  [2.x.1979]  function by realizing that forming the minimum over the minimal entropies equals forming the negative of the maximum over the negative of the minimal entropies; this maximum can then be combined with forming the maximum over the maximal entropies.
//
[0.x.13652] 
[0.x.13653] 
[0.x.13654] 
//
[0.x.13655] 
[0.x.13656] 
//
// Having computed everything this way, we can then compute the average entropy and find the  [2.x.1980]  norm by taking the larger of the deviation of the maximum or minimum from the average:
//
[0.x.13657] 
[0.x.13658] 
[0.x.13659] 
[0.x.13660] 
[0.x.13661] 
//
//  [2.x.1981] 
//
// The next function computes the minimal and maximal value of the extrapolated temperature over the entire domain. Again, this is only a slightly modified version of the respective function in  [2.x.1982] . As in the function above, we collect local minima and maxima and then compute the global extrema using the same trick as above.
//
// As already discussed in  [2.x.1983] , the function needs to distinguish between the first and all following time steps because it uses a higher order temperature extrapolation scheme when at least two previous time steps are available.
//
[0.x.13662] 
[0.x.13663] 
[0.x.13664] 
[0.x.13665] 
[0.x.13666] 
[0.x.13667] 
[0.x.13668] 
//
[0.x.13669] 
[0.x.13670] 
[0.x.13671] 
[0.x.13672] 
[0.x.13673] 
[0.x.13674] 
//
[0.x.13675] 
[0.x.13676] 
//
[0.x.13677] 
[0.x.13678] 
[0.x.13679] 
[0.x.13680] 
[0.x.13681] 
[0.x.13682] 
[0.x.13683] 
[0.x.13684] 
[0.x.13685] 
[0.x.13686] 
//
[0.x.13687] 
[0.x.13688] 
[0.x.13689] 
[0.x.13690] 
[0.x.13691] 
[0.x.13692] 
//
[0.x.13693] 
[0.x.13694] 
[0.x.13695] 
[0.x.13696] 
[0.x.13697] 
[0.x.13698] 
[0.x.13699] 
[0.x.13700] 
[0.x.13701] 
[0.x.13702] 
[0.x.13703] 
[0.x.13704] 
[0.x.13705] 
[0.x.13706] 
[0.x.13707] 
//
[0.x.13708] 
[0.x.13709] 
[0.x.13710] 
//
[0.x.13711] 
[0.x.13712] 
[0.x.13713] 
[0.x.13714] 
[0.x.13715] 
[0.x.13716] 
[0.x.13717] 
//
[0.x.13718] 
[0.x.13719] 
[0.x.13720] 
//
[0.x.13721] 
[0.x.13722] 
//[2.x.1984] 
//
// The function that calculates the viscosity is purely local and so needs no communication at all. It is mostly the same as in  [2.x.1985]  but with an updated formulation of the viscosity if  [2.x.1986]  is chosen:
//
[0.x.13723] 
[0.x.13724] 
[0.x.13725] 
[0.x.13726] 
[0.x.13727] 
[0.x.13728] 
[0.x.13729] 
[0.x.13730] 
[0.x.13731] 
[0.x.13732] 
[0.x.13733] 
[0.x.13734] 
[0.x.13735] 
[0.x.13736] 
[0.x.13737] 
[0.x.13738] 
[0.x.13739] 
[0.x.13740] 
[0.x.13741] 
[0.x.13742] 
//
[0.x.13743] 
//
[0.x.13744] 
[0.x.13745] 
//
[0.x.13746] 
[0.x.13747] 
[0.x.13748] 
[0.x.13749] 
//
[0.x.13750] 
[0.x.13751] 
//
[0.x.13752] 
[0.x.13753] 
[0.x.13754] 
[0.x.13755] 
[0.x.13756] 
//
[0.x.13757] 
[0.x.13758] 
[0.x.13759] 
[0.x.13760] 
[0.x.13761] 
[0.x.13762] 
[0.x.13763] 
[0.x.13764] 
//
[0.x.13765] 
[0.x.13766] 
[0.x.13767] 
//
[0.x.13768] 
[0.x.13769] 
[0.x.13770] 
//
[0.x.13771] 
[0.x.13772] 
[0.x.13773] 
[0.x.13774] 
[0.x.13775] 
[0.x.13776] 
[0.x.13777] 
//
[0.x.13778] 
[0.x.13779] 
[0.x.13780] 
[0.x.13781] 
[0.x.13782] 
[0.x.13783] 
[0.x.13784] 
[0.x.13785] 
[0.x.13786] 
[0.x.13787] 
//
[0.x.13788] 
[0.x.13789] 
[0.x.13790] 
//
//  [2.x.1987] 
//
// The following three functions set up the Stokes matrix, the matrix used for the Stokes preconditioner, and the temperature matrix. The code is mostly the same as in  [2.x.1988] , but it has been broken out into three functions of their own for simplicity.
//
// The main functional difference between the code here and that in  [2.x.1989]  is that the matrices we want to set up are distributed across multiple processors. Since we still want to build up the sparsity pattern first for efficiency reasons, we could continue to build the [1.x.56] sparsity pattern as a BlockDynamicSparsityPattern, as we did in  [2.x.1990] . However, that would be inefficient: every processor would build the same sparsity pattern, but only initialize a small part of the matrix using it. It also violates the principle that every processor should only work on those cells it owns (and, if necessary the layer of ghost cells around it).
//
// Rather, we use an object of type  [2.x.1991]  which is (obviously) a wrapper around a sparsity pattern object provided by Trilinos. The advantage is that the Trilinos sparsity pattern class can communicate across multiple processors: if this processor fills in all the nonzero entries that result from the cells it owns, and every other processor does so as well, then at the end after some MPI communication initiated by the  [2.x.1992]  call, we will have the globally assembled sparsity pattern available with which the global matrix can be initialized.
//
// There is one important aspect when initializing Trilinos sparsity patterns in parallel: In addition to specifying the locally owned rows and columns of the matrices via the  [2.x.1993]  index set, we also supply information about all the rows we are possibly going to write into when assembling on a certain processor. The set of locally relevant rows contains all such rows (possibly also a few unnecessary ones, but it is difficult to find the exact row indices before actually getting indices on all cells and resolving constraints). This additional information allows to exactly determine the structure for the off-processor data found during assembly. While Trilinos matrices are able to collect this information on the fly as well (when initializing them from some other reinit method), it is less efficient and leads to problems when assembling matrices with multiple threads. In this program, we pessimistically assume that only one processor at a time can write into the matrix while assembly (whereas the computation is parallel), which is fine for Trilinos matrices. In practice, one can do better by hinting WorkStream at cells that do not share vertices, allowing for parallelism among those cells (see the graph coloring algorithms and WorkStream with colored iterators argument). However, that only works when only one MPI processor is present because Trilinos' internal data structures for accumulating off-processor data on the fly are not thread safe. With the initialization presented here, there is no such problem and one could safely introduce graph coloring for this algorithm.
//
// The only other change we need to make is to tell the  [2.x.1994]  function that it is only supposed to work on a subset of cells, namely the ones whose  [2.x.1995]  equals the number of the current processor, and to ignore all other cells.
//
// This strategy is replicated across all three of the following functions.
//
// Note that Trilinos matrices store the information contained in the sparsity patterns, so we can safely release the  [2.x.1996]  variable once the matrix has been given the sparsity structure.
//
[0.x.13791] 
[0.x.13792] 
[0.x.13793] 
[0.x.13794] 
[0.x.13795] 
[0.x.13796] 
//
[0.x.13797] 
[0.x.13798] 
[0.x.13799] 
[0.x.13800] 
//
[0.x.13801] 
[0.x.13802] 
[0.x.13803] 
[0.x.13804] 
[0.x.13805] 
[0.x.13806] 
[0.x.13807] 
//
[0.x.13808] 
[0.x.13809] 
[0.x.13810] 
[0.x.13811] 
[0.x.13812] 
[0.x.13813] 
[0.x.13814] 
[0.x.13815] 
//
[0.x.13816] 
[0.x.13817] 
//
[0.x.13818] 
[0.x.13819] 
[0.x.13820] 
[0.x.13821] 
[0.x.13822] 
[0.x.13823] 
[0.x.13824] 
//
[0.x.13825] 
//
[0.x.13826] 
[0.x.13827] 
[0.x.13828] 
[0.x.13829] 
//
[0.x.13830] 
[0.x.13831] 
[0.x.13832] 
[0.x.13833] 
[0.x.13834] 
[0.x.13835] 
[0.x.13836] 
//
[0.x.13837] 
[0.x.13838] 
[0.x.13839] 
[0.x.13840] 
[0.x.13841] 
[0.x.13842] 
[0.x.13843] 
[0.x.13844] 
//
[0.x.13845] 
[0.x.13846] 
//
[0.x.13847] 
[0.x.13848] 
[0.x.13849] 
[0.x.13850] 
[0.x.13851] 
[0.x.13852] 
[0.x.13853] 
[0.x.13854] 
[0.x.13855] 
//
[0.x.13856] 
[0.x.13857] 
[0.x.13858] 
[0.x.13859] 
[0.x.13860] 
[0.x.13861] 
[0.x.13862] 
[0.x.13863] 
[0.x.13864] 
[0.x.13865] 
[0.x.13866] 
//
[0.x.13867] 
[0.x.13868] 
[0.x.13869] 
[0.x.13870] 
//
// The remainder of the setup function (after splitting out the three functions above) mostly has to deal with the things we need to do for parallelization across processors. Because setting all of this up is a significant compute time expense of the program, we put everything we do here into a timer group so that we can get summary information about the fraction of time spent in this part of the program at its end.
//
// At the top as usual we enumerate degrees of freedom and sort them by component/block, followed by writing their numbers to the screen from processor zero. The  [2.x.1997]  function, when applied to a  [2.x.1998]  object, sorts degrees of freedom in such a way that all degrees of freedom associated with subdomain zero come before all those associated with subdomain one, etc. For the Stokes part, this entails, however, that velocities and pressures become intermixed, but this is trivially solved by sorting again by blocks; it is worth noting that this latter operation leaves the relative ordering of all velocities and pressures alone, i.e. within the velocity block we will still have all those associated with subdomain zero before all velocities associated with subdomain one, etc. This is important since we store each of the blocks of this matrix distributed across all processors and want this to be done in such a way that each processor stores that part of the matrix that is roughly equal to the degrees of freedom located on those cells that it will actually work on.
//
// When printing the numbers of degrees of freedom, note that these numbers are going to be large if we use many processors. Consequently, we let the stream put a comma separator in between every three digits. The state of the stream, using the locale, is saved from before to after this operation. While slightly opaque, the code works because the default locale (which we get using the constructor call  [2.x.1999] ) implies printing numbers with a comma separator for every third digit (i.e., thousands, millions, billions).
//
// In this function as well as many below, we measure how much time we spend here and collect that in a section called "Setup dof systems" across function invocations. This is done using an  [2.x.2000]  object that gets a timer going in the section with above name of the `computing_timer` object upon construction of the local variable; the timer is stopped again when the destructor of the `timing_section` variable is called.  This, of course, happens either at the end of the function, or if we leave the function through a `return` statement or when an exception is thrown somewhere -- in other words, whenever we leave this function in any way. The use of such "scope" objects therefore makes sure that we do not have to manually add code that tells the timer to stop at every location where this function may be left.
//
[0.x.13871] 
[0.x.13872] 
[0.x.13873] 
[0.x.13874] 
//
[0.x.13875] 
//
[0.x.13876] 
[0.x.13877] 
[0.x.13878] 
//
[0.x.13879] 
//
[0.x.13880] 
[0.x.13881] 
//
[0.x.13882] 
[0.x.13883] 
[0.x.13884] 
//
[0.x.13885] 
[0.x.13886] 
[0.x.13887] 
[0.x.13888] 
[0.x.13889] 
[0.x.13890] 
[0.x.13891] 
[0.x.13892] 
//
// After this, we have to set up the various partitioners (of type  [2.x.2001] , see the introduction) that describe which parts of each matrix or vector will be stored where, then call the functions that actually set up the matrices, and at the end also resize the various vectors we keep around in this program.
//
[0.x.13893] 
[0.x.13894] 
[0.x.13895] 
[0.x.13896] 
[0.x.13897] 
[0.x.13898] 
[0.x.13899] 
[0.x.13900] 
//
[0.x.13901] 
[0.x.13902] 
[0.x.13903] 
[0.x.13904] 
[0.x.13905] 
[0.x.13906] 
//
[0.x.13907] 
[0.x.13908] 
[0.x.13909] 
[0.x.13910] 
//
// Following this, we can compute constraints for the solution vectors, including hanging node constraints and homogeneous and inhomogeneous boundary values for the Stokes and temperature fields. Note that as for everything else, the constraint objects can not hold [1.x.57] constraints on every processor. Rather, each processor needs to store only those that are actually necessary for correctness given that it only assembles linear systems on cells it owns. As discussed in the  [2.x.2002]  "this paper", the set of constraints we need to know about is exactly the set of constraints on all locally relevant degrees of freedom, so this is what we use to initialize the constraint objects.
//
[0.x.13911] 
[0.x.13912] 
[0.x.13913] 
//
[0.x.13914] 
[0.x.13915] 
//
[0.x.13916] 
[0.x.13917] 
[0.x.13918] 
[0.x.13919] 
[0.x.13920] 
[0.x.13921] 
[0.x.13922] 
//
[0.x.13923] 
[0.x.13924] 
[0.x.13925] 
[0.x.13926] 
[0.x.13927] 
[0.x.13928] 
[0.x.13929] 
[0.x.13930] 
[0.x.13931] 
[0.x.13932] 
[0.x.13933] 
[0.x.13934] 
//
[0.x.13935] 
[0.x.13936] 
[0.x.13937] 
[0.x.13938] 
[0.x.13939] 
[0.x.13940] 
[0.x.13941] 
[0.x.13942] 
[0.x.13943] 
[0.x.13944] 
[0.x.13945] 
[0.x.13946] 
[0.x.13947] 
[0.x.13948] 
//
// All this done, we can then initialize the various matrix and vector objects to their proper sizes. At the end, we also record that all matrices and preconditioners have to be re-computed at the beginning of the next time step. Note how we initialize the vectors for the Stokes and temperature right hand sides: These are writable vectors (last boolean argument set to  [2.x.2003]  that have the correct one-to-one partitioning of locally owned elements but are still given the relevant partitioning for means of figuring out the vector entries that are going to be set right away. As for matrices, this allows for writing local contributions into the vector with multiple threads (always assuming that the same vector entry is not accessed by multiple threads at the same time). The other vectors only allow for read access of individual elements, including ghosts, but are not suitable for solvers.
//
[0.x.13949] 
[0.x.13950] 
[0.x.13951] 
[0.x.13952] 
[0.x.13953] 
//
[0.x.13954] 
[0.x.13955] 
[0.x.13956] 
[0.x.13957] 
[0.x.13958] 
[0.x.13959] 
//
[0.x.13960] 
[0.x.13961] 
[0.x.13962] 
[0.x.13963] 
[0.x.13964] 
[0.x.13965] 
[0.x.13966] 
[0.x.13967] 
//
[0.x.13968] 
[0.x.13969] 
[0.x.13970] 
[0.x.13971] 
[0.x.13972] 
//
//  [2.x.2004] 
//
// Following the discussion in the introduction and in the  [2.x.2005]  module, we split the assembly functions into different parts:
//
//  [2.x.2006] 
//[2.x.2007]  The local calculations of matrices and right hand sides, given a certain cell as input (these functions are named  [2.x.2008]  below). The resulting function is, in other words, essentially the body of the loop over all cells in  [2.x.2009] . Note, however, that these functions store the result from the local calculations in variables of classes from the CopyData namespace.
//
//  [2.x.2010] These objects are then given to the second step which writes the local data into the global data structures (these functions are named  [2.x.2011]  below). These functions are pretty trivial.
//
//  [2.x.2012] These two subfunctions are then used in the respective assembly routine (called  [2.x.2013]  below), where a WorkStream object is set up and runs over all the cells that belong to the processor's subdomain.   [2.x.2014] 
//[2.x.2015] 
//
// Let us start with the functions that builds the Stokes preconditioner. The first two of these are pretty trivial, given the discussion above. Note in particular that the main point in using the scratch data object is that we want to avoid allocating any objects on the free space each time we visit a new cell. As a consequence, the assembly function below only has automatic local variables, and everything else is accessed through the scratch data object, which is allocated only once before we start the loop over all cells:
//
[0.x.13973] 
[0.x.13974] 
[0.x.13975] 
[0.x.13976] 
[0.x.13977] 
[0.x.13978] 
[0.x.13979] 
[0.x.13980] 
[0.x.13981] 
//
[0.x.13982] 
[0.x.13983] 
//
[0.x.13984] 
[0.x.13985] 
//
[0.x.13986] 
//
[0.x.13987] 
[0.x.13988] 
[0.x.13989] 
[0.x.13990] 
[0.x.13991] 
[0.x.13992] 
[0.x.13993] 
[0.x.13994] 
//
[0.x.13995] 
[0.x.13996] 
[0.x.13997] 
[0.x.13998] 
[0.x.13999] 
[0.x.14000] 
[0.x.14001] 
[0.x.14002] 
[0.x.14003] 
[0.x.14004] 
[0.x.14005] 
//
[0.x.14006] 
[0.x.14007] 
[0.x.14008] 
[0.x.14009] 
[0.x.14010] 
[0.x.14011] 
[0.x.14012] 
[0.x.14013] 
//
// Now for the function that actually puts things together, using the WorkStream functions.   [2.x.2016]  needs a start and end iterator to enumerate the cells it is supposed to work on. Typically, one would use  [2.x.2017]  and  [2.x.2018]  for that but here we actually only want the subset of cells that in fact are owned by the current processor. This is where the FilteredIterator class comes into play: you give it a range of cells and it provides an iterator that only iterates over that subset of cells that satisfy a certain predicate (a predicate is a function of one argument that either returns true or false). The predicate we use here is  [2.x.2019]  i.e., it returns true exactly if the cell is owned by the current processor. The resulting iterator range is then exactly what we need.
//
// With this obstacle out of the way, we call the  [2.x.2020]  function with this set of cells, scratch and copy objects, and with pointers to two functions: the local assembly and copy-local-to-global function. These functions need to have very specific signatures: three arguments in the first and one argument in the latter case (see the documentation of the  [2.x.2021]  function for the meaning of these arguments). Note how we use a lambda functions to create a function object that satisfies this requirement. It uses function arguments for the local assembly function that specify cell, scratch data, and copy data, as well as function argument for the copy function that expects the data to be written into the global matrix (also see the discussion in  [2.x.2022] 's  [2.x.2023]  function). On the other hand, the implicit zeroth argument of member functions (namely the  [2.x.2024]  pointer of the object on which that member function is to operate on) is [1.x.58] to the  [2.x.2025]  pointer of the current function and is captured. The  [2.x.2026]  function, as a consequence, does not need to know anything about the object these functions work on.
//
// When the WorkStream is executed, it will create several local assembly routines of the first kind for several cells and let some available processors work on them. The function that needs to be synchronized, i.e., the write operation into the global matrix, however, is executed by only one thread at a time in the prescribed order. Of course, this only holds for the parallelization on a single MPI process. Different MPI processes will have their own WorkStream objects and do that work completely independently (and in different memory spaces). In a distributed calculation, some data will accumulate at degrees of freedom that are not owned by the respective processor. It would be inefficient to send data around every time we encounter such a dof. What happens instead is that the Trilinos sparse matrix will keep that data and send it to the owner at the end of assembly, by calling the  [2.x.2027]  command.
//
[0.x.14014] 
[0.x.14015] 
[0.x.14016] 
[0.x.14017] 
//
[0.x.14018] 
//
[0.x.14019] 
[0.x.14020] 
//
[0.x.14021] 
[0.x.14022] 
[0.x.14023] 
[0.x.14024] 
[0.x.14025] 
[0.x.14026] 
//
[0.x.14027] 
[0.x.14028] 
[0.x.14029] 
[0.x.14030] 
//
[0.x.14031] 
[0.x.14032] 
[0.x.14033] 
[0.x.14034] 
[0.x.14035] 
[0.x.14036] 
[0.x.14037] 
[0.x.14038] 
[0.x.14039] 
[0.x.14040] 
[0.x.14041] 
[0.x.14042] 
//
[0.x.14043] 
[0.x.14044] 
//
// The final function in this block initiates assembly of the Stokes preconditioner matrix and then in fact builds the Stokes preconditioner. It is mostly the same as in the serial case. The only difference to  [2.x.2028]  is that we use a Jacobi preconditioner for the pressure mass matrix instead of IC, as discussed in the introduction.
//
[0.x.14045] 
[0.x.14046] 
[0.x.14047] 
[0.x.14048] 
[0.x.14049] 
//
[0.x.14050] 
[0.x.14051] 
[0.x.14052] 
//
[0.x.14053] 
//
[0.x.14054] 
[0.x.14055] 
[0.x.14056] 
[0.x.14057] 
[0.x.14058] 
[0.x.14059] 
//
[0.x.14060] 
[0.x.14061] 
[0.x.14062] 
//
[0.x.14063] 
[0.x.14064] 
[0.x.14065] 
[0.x.14066] 
[0.x.14067] 
[0.x.14068] 
//
[0.x.14069] 
[0.x.14070] 
[0.x.14071] 
//
[0.x.14072] 
//
[0.x.14073] 
[0.x.14074] 
//[2.x.2029] 
//
// The next three functions implement the assembly of the Stokes system, again split up into a part performing local calculations, one for writing the local data into the global matrix and vector, and one for actually running the loop over all cells with the help of the WorkStream class. Note that the assembly of the Stokes matrix needs only to be done in case we have changed the mesh. Otherwise, just the (temperature-dependent) right hand side needs to be calculated here. Since we are working with distributed matrices and vectors, we have to call the respective  [2.x.2030]  functions in the end of the assembly in order to send non-local data to the owner process.
//
[0.x.14075] 
[0.x.14076] 
[0.x.14077] 
[0.x.14078] 
[0.x.14079] 
[0.x.14080] 
[0.x.14081] 
[0.x.14082] 
[0.x.14083] 
[0.x.14084] 
//
[0.x.14085] 
[0.x.14086] 
//
[0.x.14087] 
//
[0.x.14088] 
[0.x.14089] 
[0.x.14090] 
//
[0.x.14091] 
[0.x.14092] 
[0.x.14093] 
//
[0.x.14094] 
[0.x.14095] 
//
[0.x.14096] 
[0.x.14097] 
[0.x.14098] 
//
[0.x.14099] 
[0.x.14100] 
[0.x.14101] 
[0.x.14102] 
[0.x.14103] 
[0.x.14104] 
[0.x.14105] 
[0.x.14106] 
[0.x.14107] 
[0.x.14108] 
[0.x.14109] 
[0.x.14110] 
[0.x.14111] 
//
[0.x.14112] 
[0.x.14113] 
[0.x.14114] 
[0.x.14115] 
[0.x.14116] 
[0.x.14117] 
[0.x.14118] 
[0.x.14119] 
[0.x.14120] 
[0.x.14121] 
[0.x.14122] 
//
[0.x.14123] 
[0.x.14124] 
//
[0.x.14125] 
[0.x.14126] 
[0.x.14127] 
[0.x.14128] 
[0.x.14129] 
//
[0.x.14130] 
[0.x.14131] 
//
[0.x.14132] 
[0.x.14133] 
[0.x.14134] 
[0.x.14135] 
[0.x.14136] 
[0.x.14137] 
[0.x.14138] 
[0.x.14139] 
[0.x.14140] 
[0.x.14141] 
[0.x.14142] 
[0.x.14143] 
[0.x.14144] 
[0.x.14145] 
[0.x.14146] 
//
[0.x.14147] 
[0.x.14148] 
[0.x.14149] 
[0.x.14150] 
[0.x.14151] 
//
[0.x.14152] 
[0.x.14153] 
//
[0.x.14154] 
//
[0.x.14155] 
//
[0.x.14156] 
[0.x.14157] 
//
[0.x.14158] 
[0.x.14159] 
[0.x.14160] 
[0.x.14161] 
[0.x.14162] 
[0.x.14163] 
[0.x.14164] 
[0.x.14165] 
[0.x.14166] 
[0.x.14167] 
[0.x.14168] 
[0.x.14169] 
[0.x.14170] 
[0.x.14171] 
[0.x.14172] 
[0.x.14173] 
[0.x.14174] 
[0.x.14175] 
[0.x.14176] 
[0.x.14177] 
[0.x.14178] 
//
[0.x.14179] 
[0.x.14180] 
[0.x.14181] 
//
[0.x.14182] 
//
[0.x.14183] 
[0.x.14184] 
//[2.x.2031] 
//
// The task to be performed by the next three functions is to calculate a mass matrix and a Laplace matrix on the temperature system. These will be combined in order to yield the semi-implicit time stepping matrix that consists of the mass matrix plus a time  [2.x.2032] dependent weight factor times the Laplace matrix. This function is again essentially the body of the loop over all cells from  [2.x.2033] .
//
// The two following functions perform similar services as the ones above.
//
[0.x.14185] 
[0.x.14186] 
[0.x.14187] 
[0.x.14188] 
[0.x.14189] 
[0.x.14190] 
[0.x.14191] 
[0.x.14192] 
[0.x.14193] 
[0.x.14194] 
//
[0.x.14195] 
[0.x.14196] 
//
[0.x.14197] 
[0.x.14198] 
//
[0.x.14199] 
[0.x.14200] 
[0.x.14201] 
[0.x.14202] 
[0.x.14203] 
[0.x.14204] 
[0.x.14205] 
[0.x.14206] 
//
[0.x.14207] 
[0.x.14208] 
[0.x.14209] 
[0.x.14210] 
[0.x.14211] 
[0.x.14212] 
[0.x.14213] 
[0.x.14214] 
[0.x.14215] 
[0.x.14216] 
[0.x.14217] 
[0.x.14218] 
//
[0.x.14219] 
[0.x.14220] 
[0.x.14221] 
[0.x.14222] 
[0.x.14223] 
[0.x.14224] 
[0.x.14225] 
[0.x.14226] 
[0.x.14227] 
[0.x.14228] 
[0.x.14229] 
[0.x.14230] 
//
[0.x.14231] 
[0.x.14232] 
[0.x.14233] 
[0.x.14234] 
[0.x.14235] 
//
[0.x.14236] 
[0.x.14237] 
[0.x.14238] 
[0.x.14239] 
//
[0.x.14240] 
//
[0.x.14241] 
[0.x.14242] 
//
[0.x.14243] 
[0.x.14244] 
[0.x.14245] 
[0.x.14246] 
[0.x.14247] 
[0.x.14248] 
[0.x.14249] 
[0.x.14250] 
[0.x.14251] 
[0.x.14252] 
[0.x.14253] 
[0.x.14254] 
[0.x.14255] 
[0.x.14256] 
[0.x.14257] 
[0.x.14258] 
[0.x.14259] 
//
[0.x.14260] 
[0.x.14261] 
//
[0.x.14262] 
[0.x.14263] 
[0.x.14264] 
//[2.x.2034] 
//
// This is the last assembly function. It calculates the right hand side of the temperature system, which includes the convection and the stabilization terms. It includes a lot of evaluations of old solutions at the quadrature points (which are necessary for calculating the artificial viscosity of stabilization), but is otherwise similar to the other assembly functions. Notice, once again, how we resolve the dilemma of having inhomogeneous boundary conditions, by just making a right hand side at this point (compare the comments for the  [2.x.2035]  function above): We create some matrix columns with exactly the values that would be entered for the temperature stiffness matrix, in case we have inhomogeneously constrained dofs. That will account for the correct balance of the right hand side vector with the matrix system of temperature.
//
[0.x.14265] 
[0.x.14266] 
[0.x.14267] 
[0.x.14268] 
[0.x.14269] 
[0.x.14270] 
[0.x.14271] 
[0.x.14272] 
[0.x.14273] 
[0.x.14274] 
//
[0.x.14275] 
[0.x.14276] 
[0.x.14277] 
[0.x.14278] 
//
[0.x.14279] 
//
[0.x.14280] 
[0.x.14281] 
[0.x.14282] 
//
[0.x.14283] 
//
[0.x.14284] 
[0.x.14285] 
[0.x.14286] 
//
[0.x.14287] 
[0.x.14288] 
[0.x.14289] 
[0.x.14290] 
//
[0.x.14291] 
[0.x.14292] 
[0.x.14293] 
[0.x.14294] 
//
[0.x.14295] 
[0.x.14296] 
[0.x.14297] 
[0.x.14298] 
//
[0.x.14299] 
[0.x.14300] 
[0.x.14301] 
[0.x.14302] 
[0.x.14303] 
[0.x.14304] 
[0.x.14305] 
[0.x.14306] 
//
[0.x.14307] 
[0.x.14308] 
[0.x.14309] 
[0.x.14310] 
[0.x.14311] 
[0.x.14312] 
[0.x.14313] 
[0.x.14314] 
[0.x.14315] 
[0.x.14316] 
[0.x.14317] 
[0.x.14318] 
[0.x.14319] 
[0.x.14320] 
[0.x.14321] 
[0.x.14322] 
//
[0.x.14323] 
[0.x.14324] 
[0.x.14325] 
[0.x.14326] 
[0.x.14327] 
[0.x.14328] 
[0.x.14329] 
[0.x.14330] 
//
[0.x.14331] 
[0.x.14332] 
[0.x.14333] 
[0.x.14334] 
[0.x.14335] 
[0.x.14336] 
[0.x.14337] 
//
[0.x.14338] 
[0.x.14339] 
[0.x.14340] 
[0.x.14341] 
[0.x.14342] 
[0.x.14343] 
//
[0.x.14344] 
[0.x.14345] 
[0.x.14346] 
[0.x.14347] 
[0.x.14348] 
[0.x.14349] 
//
[0.x.14350] 
[0.x.14351] 
[0.x.14352] 
[0.x.14353] 
[0.x.14354] 
//
[0.x.14355] 
[0.x.14356] 
[0.x.14357] 
[0.x.14358] 
[0.x.14359] 
//
[0.x.14360] 
[0.x.14361] 
[0.x.14362] 
[0.x.14363] 
[0.x.14364] 
//
[0.x.14365] 
[0.x.14366] 
[0.x.14367] 
[0.x.14368] 
[0.x.14369] 
[0.x.14370] 
[0.x.14371] 
[0.x.14372] 
//
[0.x.14373] 
[0.x.14374] 
[0.x.14375] 
[0.x.14376] 
[0.x.14377] 
[0.x.14378] 
[0.x.14379] 
[0.x.14380] 
[0.x.14381] 
[0.x.14382] 
[0.x.14383] 
[0.x.14384] 
[0.x.14385] 
[0.x.14386] 
[0.x.14387] 
[0.x.14388] 
//
[0.x.14389] 
[0.x.14390] 
[0.x.14391] 
[0.x.14392] 
[0.x.14393] 
[0.x.14394] 
[0.x.14395] 
[0.x.14396] 
[0.x.14397] 
//
// In the function that runs the WorkStream for actually calculating the right hand side, we also generate the final matrix. As mentioned above, it is a sum of the mass matrix and the Laplace matrix, times some time  [2.x.2036] dependent weight. This weight is specified by the BDF-2 time integration scheme, see the introduction in  [2.x.2037] . What is new in this tutorial program (in addition to the use of MPI parallelization and the WorkStream class), is that we now precompute the temperature preconditioner as well. The reason is that the setup of the Jacobi preconditioner takes a noticeable time compared to the solver because we usually only need between 10 and 20 iterations for solving the temperature system (this might sound strange, as Jacobi really only consists of a diagonal, but in Trilinos it is derived from more general framework for point relaxation preconditioners which is a bit inefficient). Hence, it is more efficient to precompute the preconditioner, even though the matrix entries may slightly change because the time step might change. This is not too big a problem because we remesh every few time steps (and regenerate the preconditioner then).
//
[0.x.14398] 
[0.x.14399] 
[0.x.14400] 
[0.x.14401] 
[0.x.14402] 
//
[0.x.14403] 
[0.x.14404] 
[0.x.14405] 
[0.x.14406] 
[0.x.14407] 
[0.x.14408] 
[0.x.14409] 
[0.x.14410] 
[0.x.14411] 
[0.x.14412] 
[0.x.14413] 
[0.x.14414] 
//
[0.x.14415] 
[0.x.14416] 
[0.x.14417] 
[0.x.14418] 
[0.x.14419] 
[0.x.14420] 
[0.x.14421] 
//
// The next part is computing the right hand side vectors.  To do so, we first compute the average temperature  [2.x.2038]  that we use for evaluating the artificial viscosity stabilization through the residual  [2.x.2039] . We do this by defining the midpoint between maximum and minimum temperature as average temperature in the definition of the entropy viscosity. An alternative would be to use the integral average, but the results are not very sensitive to this choice. The rest then only requires calling  [2.x.2040]  again, binding the arguments to the  [2.x.2041]  function that are the same in every call to the correct values:
//
[0.x.14422] 
//
[0.x.14423] 
[0.x.14424] 
[0.x.14425] 
//
[0.x.14426] 
[0.x.14427] 
[0.x.14428] 
[0.x.14429] 
//
[0.x.14430] 
[0.x.14431] 
//
[0.x.14432] 
[0.x.14433] 
[0.x.14434] 
[0.x.14435] 
[0.x.14436] 
[0.x.14437] 
[0.x.14438] 
[0.x.14439] 
[0.x.14440] 
[0.x.14441] 
[0.x.14442] 
[0.x.14443] 
//
[0.x.14444] 
[0.x.14445] 
[0.x.14446] 
//
[0.x.14447] 
[0.x.14448] 
[0.x.14449] 
[0.x.14450] 
[0.x.14451] 
[0.x.14452] 
[0.x.14453] 
[0.x.14454] 
[0.x.14455] 
//
[0.x.14456] 
[0.x.14457] 
//
//  [2.x.2042] 
//
// This function solves the linear systems in each time step of the Boussinesq problem. First, we work on the Stokes system and then on the temperature system. In essence, it does the same things as the respective function in  [2.x.2043] . However, there are a few changes here.
//
// The first change is related to the way we store our solution: we keep the vectors with locally owned degrees of freedom plus ghost nodes on each MPI node. When we enter a solver which is supposed to perform matrix-vector products with a distributed matrix, this is not the appropriate form, though. There, we will want to have the solution vector to be distributed in the same way as the matrix, i.e. without any ghosts. So what we do first is to generate a distributed vector called  [2.x.2044]  and put only the locally owned dofs into that, which is neatly done by the  [2.x.2045]  of the Trilinos vector.
//
// Next, we scale the pressure solution (or rather, the initial guess) for the solver so that it matches with the length scales in the matrices, as discussed in the introduction. We also immediately scale the pressure solution back to the correct units after the solution is completed.  We also need to set the pressure values at hanging nodes to zero. This we also did in  [2.x.2046]  in order not to disturb the Schur complement by some vector entries that actually are irrelevant during the solve stage. As a difference to  [2.x.2047] , here we do it only for the locally owned pressure dofs. After solving for the Stokes solution, each processor copies the distributed solution back into the solution vector that also includes ghost elements.
//
// The third and most obvious change is that we have two variants for the Stokes solver: A fast solver that sometimes breaks down, and a robust solver that is slower. This is what we already discussed in the introduction. Here is how we realize it: First, we perform 30 iterations with the fast solver based on the simple preconditioner based on the AMG V-cycle instead of an approximate solve (this is indicated by the  [2.x.2048]  argument to the  [2.x.2049]  object). If we converge, everything is fine. If we do not converge, the solver control object will throw an exception  [2.x.2050]  Usually, this would abort the program because we don't catch them in our usual  [2.x.2051]  functions. This is certainly not what we want to happen here. Rather, we want to switch to the strong solver and continue the solution process with whatever vector we got so far. Hence, we catch the exception with the C++ try/catch mechanism. We then simply go through the same solver sequence again in the  [2.x.2052]  clause, this time passing the  [2.x.2053]  flag to the preconditioner for the strong solver, signaling an approximate CG solve.
//
[0.x.14458] 
[0.x.14459] 
[0.x.14460] 
[0.x.14461] 
[0.x.14462] 
[0.x.14463] 
//
[0.x.14464] 
//
[0.x.14465] 
[0.x.14466] 
[0.x.14467] 
//
[0.x.14468] 
//
[0.x.14469] 
[0.x.14470] 
[0.x.14471] 
[0.x.14472] 
[0.x.14473] 
[0.x.14474] 
[0.x.14475] 
[0.x.14476] 
//
[0.x.14477] 
//
[0.x.14478] 
[0.x.14479] 
[0.x.14480] 
//
[0.x.14481] 
[0.x.14482] 
[0.x.14483] 
[0.x.14484] 
[0.x.14485] 
[0.x.14486] 
[0.x.14487] 
[0.x.14488] 
[0.x.14489] 
[0.x.14490] 
//
[0.x.14491] 
[0.x.14492] 
[0.x.14493] 
[0.x.14494] 
[0.x.14495] 
[0.x.14496] 
[0.x.14497] 
[0.x.14498] 
[0.x.14499] 
//
[0.x.14500] 
[0.x.14501] 
//
[0.x.14502] 
[0.x.14503] 
[0.x.14504] 
[0.x.14505] 
[0.x.14506] 
[0.x.14507] 
[0.x.14508] 
[0.x.14509] 
[0.x.14510] 
[0.x.14511] 
//
[0.x.14512] 
[0.x.14513] 
[0.x.14514] 
[0.x.14515] 
[0.x.14516] 
[0.x.14517] 
[0.x.14518] 
[0.x.14519] 
[0.x.14520] 
[0.x.14521] 
[0.x.14522] 
//
[0.x.14523] 
[0.x.14524] 
[0.x.14525] 
//
[0.x.14526] 
//
[0.x.14527] 
//
[0.x.14528] 
[0.x.14529] 
[0.x.14530] 
//
// Now let's turn to the temperature part: First, we compute the time step size. We found that we need smaller time steps for 3D than for 2D for the shell geometry. This is because the cells are more distorted in that case (it is the smallest edge length that determines the CFL number). Instead of computing the time step from maximum velocity and minimal mesh size as in  [2.x.2054] , we compute local CFL numbers, i.e., on each cell we compute the maximum velocity times the mesh size, and compute the maximum of them. Hence, we need to choose the factor in front of the time step slightly smaller.
//
// After temperature right hand side assembly, we solve the linear system for temperature (with fully distributed vectors without any ghosts), apply constraints and copy the vector back to one with ghosts.
//
// In the end, we extract the temperature range similarly to  [2.x.2055]  to produce some output (for example in order to help us choose the stabilization constants, as discussed in the introduction). The only difference is that we need to exchange maxima over all processors.
//
[0.x.14531] 
[0.x.14532] 
[0.x.14533] 
//
[0.x.14534] 
//
[0.x.14535] 
[0.x.14536] 
[0.x.14537] 
//
[0.x.14538] 
[0.x.14539] 
[0.x.14540] 
[0.x.14541] 
[0.x.14542] 
[0.x.14543] 
[0.x.14544] 
//
[0.x.14545] 
[0.x.14546] 
[0.x.14547] 
//
[0.x.14548] 
[0.x.14549] 
[0.x.14550] 
//
[0.x.14551] 
[0.x.14552] 
[0.x.14553] 
//
[0.x.14554] 
[0.x.14555] 
[0.x.14556] 
//
[0.x.14557] 
[0.x.14558] 
[0.x.14559] 
[0.x.14560] 
//
[0.x.14561] 
[0.x.14562] 
//
[0.x.14563] 
[0.x.14564] 
//
[0.x.14565] 
[0.x.14566] 
[0.x.14567] 
//
[0.x.14568] 
[0.x.14569] 
[0.x.14570] 
[0.x.14571] 
[0.x.14572] 
[0.x.14573] 
[0.x.14574] 
[0.x.14575] 
[0.x.14576] 
[0.x.14577] 
[0.x.14578] 
[0.x.14579] 
//
[0.x.14580] 
[0.x.14581] 
[0.x.14582] 
//
[0.x.14583] 
[0.x.14584] 
[0.x.14585] 
[0.x.14586] 
//[2.x.2056] 
//
// Next comes the function that generates the output. The quantities to output could be introduced manually like we did in  [2.x.2057] . An alternative is to hand this task over to a class PostProcessor that inherits from the class DataPostprocessor, which can be attached to DataOut. This allows us to output derived quantities from the solution, like the friction heating included in this example. It overloads the virtual function  [2.x.2058]  which is then internally called from  [2.x.2059]  We have to give it values of the numerical solution, its derivatives, normals to the cell, the actual evaluation points and any additional quantities. This follows the same procedure as discussed in  [2.x.2060]  and other programs.
//
[0.x.14587] 
[0.x.14588] 
[0.x.14589] 
[0.x.14590] 
[0.x.14591] 
[0.x.14592] 
//
[0.x.14593] 
[0.x.14594] 
[0.x.14595] 
//
[0.x.14596] 
//
[0.x.14597] 
[0.x.14598] 
[0.x.14599] 
//
[0.x.14600] 
//
[0.x.14601] 
[0.x.14602] 
[0.x.14603] 
[0.x.14604] 
//
[0.x.14605] 
[0.x.14606] 
[0.x.14607] 
[0.x.14608] 
[0.x.14609] 
[0.x.14610] 
[0.x.14611] 
//
// Here we define the names for the variables we want to output. These are the actual solution values for velocity, pressure, and temperature, as well as the friction heating and to each cell the number of the processor that owns it. This allows us to visualize the partitioning of the domain among the processors. Except for the velocity, which is vector-valued, all other quantities are scalar.
//
[0.x.14612] 
[0.x.14613] 
[0.x.14614] 
[0.x.14615] 
[0.x.14616] 
[0.x.14617] 
[0.x.14618] 
[0.x.14619] 
[0.x.14620] 
//
[0.x.14621] 
[0.x.14622] 
//
[0.x.14623] 
[0.x.14624] 
[0.x.14625] 
[0.x.14626] 
[0.x.14627] 
[0.x.14628] 
[0.x.14629] 
[0.x.14630] 
//
[0.x.14631] 
[0.x.14632] 
[0.x.14633] 
[0.x.14634] 
//
[0.x.14635] 
[0.x.14636] 
//
[0.x.14637] 
[0.x.14638] 
[0.x.14639] 
[0.x.14640] 
[0.x.14641] 
[0.x.14642] 
//
// Now we implement the function that computes the derived quantities. As we also did for the output, we rescale the velocity from its SI units to something more readable, namely cm/year. Next, the pressure is scaled to be between 0 and the maximum pressure. This makes it more easily comparable -- in essence making all pressure variables positive or zero. Temperature is taken as is, and the friction heating is computed as  [2.x.2061] .
//
// The quantities we output here are more for illustration, rather than for actual scientific value. We come back to this briefly in the results section of this program and explain what one may in fact be interested in.
//
[0.x.14643] 
[0.x.14644] 
[0.x.14645] 
[0.x.14646] 
[0.x.14647] 
[0.x.14648] 
[0.x.14649] 
[0.x.14650] 
[0.x.14651] 
[0.x.14652] 
[0.x.14653] 
//
[0.x.14654] 
[0.x.14655] 
[0.x.14656] 
[0.x.14657] 
[0.x.14658] 
//
[0.x.14659] 
[0.x.14660] 
[0.x.14661] 
//
[0.x.14662] 
[0.x.14663] 
//
[0.x.14664] 
[0.x.14665] 
[0.x.14666] 
[0.x.14667] 
[0.x.14668] 
[0.x.14669] 
//
[0.x.14670] 
[0.x.14671] 
[0.x.14672] 
//
// The  [2.x.2062]  function has a similar task to the one in  [2.x.2063] . However, here we are going to demonstrate a different technique on how to merge output from different DoFHandler objects. The way we're going to achieve this recombination is to create a joint DoFHandler that collects both components, the Stokes solution and the temperature solution. This can be nicely done by combining the finite elements from the two systems to form one FESystem, and let this collective system define a new DoFHandler object. To be sure that everything was done correctly, we perform a sanity check that ensures that we got all the dofs from both Stokes and temperature even in the combined system. We then combine the data vectors. Unfortunately, there is no straight-forward relation that tells us how to sort Stokes and temperature vector into the joint vector. The way we can get around this trouble is to rely on the information collected in the FESystem. For each dof on a cell, the joint finite element knows to which equation component (velocity component, pressure, or temperature) it belongs  that's the information we need! So we step through all cells (with iterators into all three DoFHandlers moving in sync), and for each joint cell dof, we read out that component using the  [2.x.2064]  function (see there for a description of what the various parts of its return value contain). We also need to keep track whether we're on a Stokes dof or a temperature dof, which is contained in joint_fe.system_to_base_index(i).first.first. Eventually, the dof_indices data structures on either of the three systems tell us how the relation between global vector and local dofs looks like on the present cell, which concludes this tedious work. We make sure that each processor only works on the subdomain it owns locally (and not on ghost or artificial cells) when building the joint solution vector. The same will then have to be done in  [2.x.2065]  but that function does so automatically.
//
// What we end up with is a set of patches that we can write using the functions in DataOutBase in a variety of output formats. Here, we then have to pay attention that what each processor writes is really only its own part of the domain, i.e. we will want to write each processor's contribution into a separate file. This we do by adding an additional number to the filename when we write the solution. This is not really new, we did it similarly in  [2.x.2066] . Note that we write in the compressed format  [2.x.2067]  instead of plain vtk files, which saves quite some storage.
//
// All the rest of the work is done in the PostProcessor class.
//
[0.x.14673] 
[0.x.14674] 
[0.x.14675] 
[0.x.14676] 
//
[0.x.14677] 
//
[0.x.14678] 
[0.x.14679] 
[0.x.14680] 
[0.x.14681] 
[0.x.14682] 
//
[0.x.14683] 
[0.x.14684] 
[0.x.14685] 
//
[0.x.14686] 
[0.x.14687] 
[0.x.14688] 
[0.x.14689] 
[0.x.14690] 
[0.x.14691] 
[0.x.14692] 
//
[0.x.14693] 
[0.x.14694] 
[0.x.14695] 
[0.x.14696] 
[0.x.14697] 
[0.x.14698] 
[0.x.14699] 
[0.x.14700] 
[0.x.14701] 
[0.x.14702] 
[0.x.14703] 
[0.x.14704] 
//
[0.x.14705] 
[0.x.14706] 
[0.x.14707] 
[0.x.14708] 
[0.x.14709] 
[0.x.14710] 
//
[0.x.14711] 
[0.x.14712] 
[0.x.14713] 
[0.x.14714] 
[0.x.14715] 
[0.x.14716] 
[0.x.14717] 
[0.x.14718] 
[0.x.14719] 
[0.x.14720] 
[0.x.14721] 
[0.x.14722] 
[0.x.14723] 
[0.x.14724] 
[0.x.14725] 
[0.x.14726] 
[0.x.14727] 
[0.x.14728] 
//
[0.x.14729] 
//
[0.x.14730] 
[0.x.14731] 
[0.x.14732] 
[0.x.14733] 
[0.x.14734] 
[0.x.14735] 
[0.x.14736] 
//
[0.x.14737] 
[0.x.14738] 
[0.x.14739] 
//
[0.x.14740] 
[0.x.14741] 
[0.x.14742] 
[0.x.14743] 
//
[0.x.14744] 
[0.x.14745] 
[0.x.14746] 
//
[0.x.14747] 
[0.x.14748] 
//
//  [2.x.2068] 
//
// This function isn't really new either. Since the  [2.x.2069]  function that we call in the middle has its own timer section, we split timing this function into two sections. It will also allow us to easily identify which of the two is more expensive.
//
// One thing of note, however, is that we only want to compute error indicators on the locally owned subdomain. In order to achieve this, we pass one additional argument to the  [2.x.2070]  function. Note that the vector for error estimates is resized to the number of active cells present on the current process, which is less than the total number of active cells on all processors (but more than the number of locally owned active cells); each processor only has a few coarse cells around the locally owned ones, as also explained in  [2.x.2071] .
//
// The local error estimates are then handed to a %parallel version of GridRefinement (in namespace  [2.x.2072]  see also  [2.x.2073] ) which looks at the errors and finds the cells that need refinement by comparing the error values across processors. As in  [2.x.2074] , we want to limit the maximum grid level. So in case some cells have been marked that are already at the finest level, we simply clear the refine flags.
//
[0.x.14749] 
[0.x.14750] 
[0.x.14751] 
[0.x.14752] 
[0.x.14753] 
[0.x.14754] 
[0.x.14755] 
[0.x.14756] 
[0.x.14757] 
//
[0.x.14758] 
[0.x.14759] 
[0.x.14760] 
//
[0.x.14761] 
//
[0.x.14762] 
[0.x.14763] 
[0.x.14764] 
[0.x.14765] 
[0.x.14766] 
[0.x.14767] 
[0.x.14768] 
[0.x.14769] 
[0.x.14770] 
[0.x.14771] 
//
[0.x.14772] 
[0.x.14773] 
//
[0.x.14774] 
[0.x.14775] 
[0.x.14776] 
[0.x.14777] 
[0.x.14778] 
[0.x.14779] 
//
// With all flags marked as necessary, we can then tell the  [2.x.2075]  objects to get ready to transfer data from one mesh to the next, which they will do when notified by Triangulation as part of the  [2.x.2076]  call. The syntax is similar to the non-%parallel solution transfer (with the exception that here a pointer to the vector entries is enough). The remainder of the function further down below is then concerned with setting up the data structures again after mesh refinement and restoring the solution vectors on the new mesh.
//
[0.x.14780] 
[0.x.14781] 
[0.x.14782] 
[0.x.14783] 
[0.x.14784] 
[0.x.14785] 
//
[0.x.14786] 
//
[0.x.14787] 
[0.x.14788] 
//
[0.x.14789] 
[0.x.14790] 
//
[0.x.14791] 
//
[0.x.14792] 
[0.x.14793] 
[0.x.14794] 
//
[0.x.14795] 
[0.x.14796] 
[0.x.14797] 
//
[0.x.14798] 
[0.x.14799] 
[0.x.14800] 
[0.x.14801] 
//
// enforce constraints to make the interpolated solution conforming on the new mesh:
//
[0.x.14802] 
[0.x.14803] 
//
[0.x.14804] 
[0.x.14805] 
[0.x.14806] 
//
[0.x.14807] 
[0.x.14808] 
[0.x.14809] 
//
[0.x.14810] 
[0.x.14811] 
[0.x.14812] 
//
[0.x.14813] 
//
// enforce constraints to make the interpolated solution conforming on the new mesh:
//
[0.x.14814] 
[0.x.14815] 
//
[0.x.14816] 
[0.x.14817] 
[0.x.14818] 
[0.x.14819] 
[0.x.14820] 
//
//  [2.x.2077] 
//
// This is the final and controlling function in this class. It, in fact, runs the entire rest of the program and is, once more, very similar to  [2.x.2078] . The only substantial difference is that we use a different mesh now (a  [2.x.2079]  instead of a simple cube geometry).
//
[0.x.14821] 
[0.x.14822] 
[0.x.14823] 
[0.x.14824] 
[0.x.14825] 
[0.x.14826] 
[0.x.14827] 
[0.x.14828] 
[0.x.14829] 
//
[0.x.14830] 
//
[0.x.14831] 
//
[0.x.14832] 
//
[0.x.14833] 
//
[0.x.14834] 
//
[0.x.14835] 
[0.x.14836] 
[0.x.14837] 
//[2.x.2080]  supports parallel vector classes with most standard finite elements via deal.II's own native MatrixFree framework: since we use standard Lagrange elements of moderate order this function works well here.
//
[0.x.14838] 
[0.x.14839] 
[0.x.14840] 
[0.x.14841] 
[0.x.14842] 
//
// Having so computed the current temperature field, let us set the member variable that holds the temperature nodes. Strictly speaking, we really only need to set  [2.x.2081]  since the first thing we will do is to compute the Stokes solution that only requires the previous time step's temperature field. That said, nothing good can come from not initializing the other vectors as well (especially since it's a relatively cheap operation and we only have to do it once at the beginning of the program) if we ever want to extend our numerical method or physical model, and so we initialize  [2.x.2082]  and  [2.x.2083]  as well. The assignment makes sure that the vectors on the left hand side (which where initialized to contain ghost elements as well) also get the correct ghost elements. In other words, the assignment here requires communication between processors:
//
[0.x.14843] 
[0.x.14844] 
[0.x.14845] 
[0.x.14846] 
//
[0.x.14847] 
[0.x.14848] 
//
[0.x.14849] 
//
[0.x.14850] 
[0.x.14851] 
[0.x.14852] 
[0.x.14853] 
[0.x.14854] 
//
[0.x.14855] 
[0.x.14856] 
[0.x.14857] 
//
[0.x.14858] 
//
[0.x.14859] 
//
[0.x.14860] 
[0.x.14861] 
[0.x.14862] 
[0.x.14863] 
[0.x.14864] 
[0.x.14865] 
[0.x.14866] 
[0.x.14867] 
[0.x.14868] 
[0.x.14869] 
[0.x.14870] 
[0.x.14871] 
[0.x.14872] 
//
[0.x.14873] 
[0.x.14874] 
[0.x.14875] 
//
// In order to speed up linear solvers, we extrapolate the solutions from the old time levels to the new one. This gives a very good initial guess, cutting the number of iterations needed in solvers by more than one half. We do not need to extrapolate in the last iteration, so if we reached the final time, we stop here.
//
// As the last thing during a time step (before actually bumping up the number of the time step), we check whether the current time step number is divisible by 100, and if so we let the computing timer print a summary of CPU times spent so far.
//
[0.x.14876] 
[0.x.14877] 
//
[0.x.14878] 
[0.x.14879] 
[0.x.14880] 
[0.x.14881] 
[0.x.14882] 
[0.x.14883] 
[0.x.14884] 
//
//   Trilinos sadd does not like ghost vectors even as input. Copy   into distributed vectors for now:
//
[0.x.14885] 
[0.x.14886] 
[0.x.14887] 
[0.x.14888] 
[0.x.14889] 
[0.x.14890] 
[0.x.14891] 
[0.x.14892] 
[0.x.14893] 
[0.x.14894] 
[0.x.14895] 
[0.x.14896] 
[0.x.14897] 
[0.x.14898] 
[0.x.14899] 
[0.x.14900] 
[0.x.14901] 
[0.x.14902] 
[0.x.14903] 
[0.x.14904] 
[0.x.14905] 
//
[0.x.14906] 
[0.x.14907] 
//
[0.x.14908] 
[0.x.14909] 
[0.x.14910] 
[0.x.14911] 
//
// If we are generating graphical output, do so also for the last time step unless we had just done so before we left the do-while loop
//
[0.x.14912] 
[0.x.14913] 
[0.x.14914] 
[0.x.14915] 
[0.x.14916] 
//
//  [2.x.2084] 
//
// The main function is short as usual and very similar to the one in  [2.x.2085] . Since we use a parameter file which is specified as an argument in the command line, we have to read it in here and pass it on to the Parameters class for parsing. If no filename is given in the command line, we simply use the  [2.x.2086]  file which is distributed together with the program.
//
// Because 3d computations are simply very slow unless you throw a lot of processors at them, the program defaults to 2d. You can get the 3d version by changing the constant dimension below to 3.
//
[0.x.14917] 
[0.x.14918] 
[0.x.14919] 
[0.x.14920] 
[0.x.14921] 
[0.x.14922] 
//
[0.x.14923] 
[0.x.14924] 
//
[0.x.14925] 
[0.x.14926] 
[0.x.14927] 
[0.x.14928] 
[0.x.14929] 
//
[0.x.14930] 
[0.x.14931] 
[0.x.14932] 
[0.x.14933] 
[0.x.14934] 
[0.x.14935] 
[0.x.14936] 
[0.x.14937] 
[0.x.14938] 
[0.x.14939] 
[0.x.14940] 
[0.x.14941] 
[0.x.14942] 
[0.x.14943] 
[0.x.14944] 
[0.x.14945] 
//
[0.x.14946] 
[0.x.14947] 
[0.x.14948] 
[0.x.14949] 
[0.x.14950] 
[0.x.14951] 
[0.x.14952] 
[0.x.14953] 
[0.x.14954] 
[0.x.14955] 
[0.x.14956] 
[0.x.14957] 
[0.x.14958] 
[0.x.14959] 
//
[0.x.14960] 
[0.x.14961] 
[0.x.14962] 
[0.x.14963] 
[0.x.14964] 
[0.x.14965] 
[0.x.14966] 
[0.x.14967] 
[0.x.14968] 
[0.x.14969] 
[0.x.14970] 
[0.x.14971] 
[0.x.14972] 
[0.x.14973] 
[0.x.14974] 
[0.x.14975] 
//
[0.x.14976] 
[0.x.14977] 
[0.x.14978] 
//[2.x.2087] 
//
// First a standard set of deal.II includes. Nothing special to comment on here:
//
[0.x.14979] 
[0.x.14980] 
[0.x.14981] 
[0.x.14982] 
[0.x.14983] 
[0.x.14984] 
//
[0.x.14985] 
[0.x.14986] 
//
[0.x.14987] 
[0.x.14988] 
[0.x.14989] 
[0.x.14990] 
[0.x.14991] 
//
[0.x.14992] 
[0.x.14993] 
//
[0.x.14994] 
[0.x.14995] 
[0.x.14996] 
[0.x.14997] 
//
[0.x.14998] 
[0.x.14999] 
[0.x.15000] 
//
// Then, as mentioned in the introduction, we use various Trilinos packages as linear solvers as well as for automatic differentiation. These are in the following include files.
//
// Since deal.II provides interfaces to the basic Trilinos matrices, preconditioners and solvers, we include them similarly as deal.II linear algebra structures.
//
[0.x.15001] 
[0.x.15002] 
[0.x.15003] 
//
// Sacado is the automatic differentiation package within Trilinos, which is used to find the Jacobian for a fully implicit Newton iteration:
//
[0.x.15004] 
//
// And this again is C++:
//
[0.x.15005] 
[0.x.15006] 
[0.x.15007] 
[0.x.15008] 
[0.x.15009] 
//
// To end this section, introduce everything in the dealii library into the namespace into which the contents of this program will go:
//
[0.x.15010] 
[0.x.15011] 
[0.x.15012] 
//[2.x.2088] 
//
// Here we define the flux function for this particular system of conservation laws, as well as pretty much everything else that's specific to the Euler equations for gas dynamics, for reasons discussed in the introduction. We group all this into a structure that defines everything that has to do with the flux. All members of this structure are static, i.e. the structure has no actual state specified by instance member variables. The better way to do this, rather than a structure with all static members would be to use a namespace -- but namespaces can't be templatized and we want some of the member variables of the structure to depend on the space dimension, which we in our usual way introduce using a template parameter.
//
[0.x.15013] 
[0.x.15014] 
[0.x.15015] 
//[2.x.2089] 
//
// First a few variables that describe the various components of our solution vector in a generic way. This includes the number of components in the system (Euler's equations have one entry for momenta in each spatial direction, plus the energy and density components, for a total of  [2.x.2090]  components), as well as functions that describe the index within the solution vector of the first momentum component, the density component, and the energy density component. Note that all these %numbers depend on the space dimension; defining them in a generic way (rather than by implicit convention) makes our code more flexible and makes it easier to later extend it, for example by adding more components to the equations.
//
[0.x.15016] 
[0.x.15017] 
[0.x.15018] 
[0.x.15019] 
//
// When generating graphical output way down in this program, we need to specify the names of the solution variables as well as how the various components group into vector and scalar fields. We could describe this there, but in order to keep things that have to do with the Euler equation localized here and the rest of the program as generic as possible, we provide this sort of information in the following two functions:
//
[0.x.15020] 
[0.x.15021] 
[0.x.15022] 
[0.x.15023] 
[0.x.15024] 
//
[0.x.15025] 
[0.x.15026] 
//
[0.x.15027] 
[0.x.15028] 
[0.x.15029] 
[0.x.15030] 
[0.x.15031] 
[0.x.15032] 
[0.x.15033] 
[0.x.15034] 
[0.x.15035] 
[0.x.15036] 
//
[0.x.15037] 
[0.x.15038] 
//[2.x.2091] 
//
// Next, we define the gas constant. We will set it to 1.4 in its definition immediately following the declaration of this class (unlike integer variables, like the ones above, static const floating point member variables cannot be initialized within the class declaration in C++). This value of 1.4 is representative of a gas that consists of molecules composed of two atoms, such as air which consists up to small traces almost entirely of  [2.x.2092]  and  [2.x.2093] .
//
[0.x.15039] 
//
// In the following, we will need to compute the kinetic energy and the pressure from a vector of conserved variables. This we can do based on the energy density and the kinetic energy  [2.x.2094]  (note that the independent variables contain the momentum components  [2.x.2095] , not the velocities  [2.x.2096] ).
//
[0.x.15040] 
[0.x.15041] 
[0.x.15042] 
[0.x.15043] 
[0.x.15044] 
[0.x.15045] 
[0.x.15046] 
[0.x.15047] 
[0.x.15048] 
//
[0.x.15049] 
[0.x.15050] 
//
[0.x.15051] 
[0.x.15052] 
[0.x.15053] 
[0.x.15054] 
[0.x.15055] 
[0.x.15056] 
[0.x.15057] 
//[2.x.2097] 
//
// We define the flux function  [2.x.2098]  as one large matrix.  Each row of this matrix represents a scalar conservation law for the component in that row.  The exact form of this matrix is given in the introduction. Note that we know the size of the matrix: it has as many rows as the system has components, and  [2.x.2099]  columns; rather than using a FullMatrix object for such a matrix (which has a variable number of rows and columns and must therefore allocate memory on the heap each time such a matrix is created), we use a rectangular array of numbers right away.
//
// We templatize the numerical type of the flux function so that we may use the automatic differentiation type here.  Similarly, we will call the function with different input vector data types, so we templatize on it as well:
//
[0.x.15058] 
[0.x.15059] 
[0.x.15060] 
[0.x.15061] 
[0.x.15062] 
[0.x.15063] 
//
// First compute the pressure that appears in the flux matrix, and then compute the first  [2.x.2100]  columns of the matrix that correspond to the momentum terms:
//
[0.x.15064] 
//
[0.x.15065] 
[0.x.15066] 
[0.x.15067] 
[0.x.15068] 
[0.x.15069] 
[0.x.15070] 
//
[0.x.15071] 
[0.x.15072] 
//
// Then the terms for the density (i.e. mass conservation), and, lastly, conservation of energy:
//
[0.x.15073] 
[0.x.15074] 
//
[0.x.15075] 
[0.x.15076] 
[0.x.15077] 
[0.x.15078] 
[0.x.15079] 
//[2.x.2101] 
//
// On the boundaries of the domain and across hanging nodes we use a numerical flux function to enforce boundary conditions.  This routine is the basic Lax-Friedrich's flux with a stabilization parameter  [2.x.2102] . It's form has also been given already in the introduction:
//
[0.x.15080] 
[0.x.15081] 
[0.x.15082] 
[0.x.15083] 
[0.x.15084] 
[0.x.15085] 
[0.x.15086] 
[0.x.15087] 
[0.x.15088] 
[0.x.15089] 
[0.x.15090] 
[0.x.15091] 
//
[0.x.15092] 
[0.x.15093] 
//
[0.x.15094] 
[0.x.15095] 
[0.x.15096] 
[0.x.15097] 
[0.x.15098] 
//
[0.x.15099] 
[0.x.15100] 
[0.x.15101] 
//[2.x.2103] 
//
// In the same way as describing the flux function  [2.x.2104] , we also need to have a way to describe the right hand side forcing term. As mentioned in the introduction, we consider only gravity here, which leads to the specific form  [2.x.2105] , shown here for the 3d case. More specifically, we will consider only  [2.x.2106]  in 3d, or  [2.x.2107]  in 2d. This naturally leads to the following function:
//
[0.x.15102] 
[0.x.15103] 
[0.x.15104] 
[0.x.15105] 
[0.x.15106] 
[0.x.15107] 
//
[0.x.15108] 
[0.x.15109] 
[0.x.15110] 
[0.x.15111] 
[0.x.15112] 
[0.x.15113] 
[0.x.15114] 
[0.x.15115] 
[0.x.15116] 
[0.x.15117] 
[0.x.15118] 
[0.x.15119] 
[0.x.15120] 
//[2.x.2108] 
//
// Another thing we have to deal with is boundary conditions. To this end, let us first define the kinds of boundary conditions we currently know how to deal with:
//
[0.x.15121] 
[0.x.15122] 
[0.x.15123] 
[0.x.15124] 
[0.x.15125] 
[0.x.15126] 
[0.x.15127] 
//
// The next part is to actually decide what to do at each kind of boundary. To this end, remember from the introduction that boundary conditions are specified by choosing a value  [2.x.2109]  on the outside of a boundary given an inhomogeneity  [2.x.2110]  and possibly the solution's value  [2.x.2111]  on the inside. Both are then passed to the numerical flux  [2.x.2112]  to define boundary contributions to the bilinear form.
//
// Boundary conditions can in some cases be specified for each component of the solution vector independently. For example, if component  [2.x.2113]  is marked for inflow, then  [2.x.2114] . If it is an outflow, then  [2.x.2115] . These two simple cases are handled first in the function below.
//
// There is a little snag that makes this function unpleasant from a C++ language viewpoint: The output vector  [2.x.2116]  will of course be modified, so it shouldn't be a  [2.x.2117]  argument. Yet it is in the implementation below, and needs to be in order to allow the code to compile. The reason is that we call this function at a place where  [2.x.2118]  is of type  [2.x.2119] , this being 2d table with indices representing the quadrature point and the vector component, respectively. We call this function with  [2.x.2120]  as last argument; subscripting a 2d table yields a temporary accessor object representing a 1d vector, just what we want here. The problem is that a temporary accessor object can't be bound to a non-const reference argument of a function, as we would like here, according to the C++ 1998 and 2003 standards (something that will be fixed with the next standard in the form of rvalue references).  We get away with making the output argument here a constant because it is the [1.x.59] object that's constant, not the table it points to: that one can still be written to. The hack is unpleasant nevertheless because it restricts the kind of data types that may be used as template argument to this function: a regular vector isn't going to do because that one can not be written to when marked  [2.x.2121] . With no good solution around at the moment, we'll go with the pragmatic, even if not pretty, solution shown here:
//
[0.x.15128] 
[0.x.15129] 
[0.x.15130] 
[0.x.15131] 
[0.x.15132] 
[0.x.15133] 
[0.x.15134] 
[0.x.15135] 
[0.x.15136] 
[0.x.15137] 
[0.x.15138] 
[0.x.15139] 
[0.x.15140] 
[0.x.15141] 
[0.x.15142] 
[0.x.15143] 
//
[0.x.15144] 
[0.x.15145] 
[0.x.15146] 
[0.x.15147] 
[0.x.15148] 
//
//   Prescribed pressure boundary conditions are a bit more   complicated by the fact that even though the pressure is   prescribed, we really are setting the energy component here,   which will depend on velocity and pressure. So even though this   seems like a Dirichlet type boundary condition, we get   sensitivities of energy to velocity and density (unless these are   also prescribed):
//
[0.x.15149] 
[0.x.15150] 
[0.x.15151] 
[0.x.15152] 
[0.x.15153] 
[0.x.15154] 
//
[0.x.15155] 
[0.x.15156] 
[0.x.15157] 
[0.x.15158] 
[0.x.15159] 
[0.x.15160] 
[0.x.15161] 
//
[0.x.15162] 
[0.x.15163] 
//
[0.x.15164] 
[0.x.15165] 
//
[0.x.15166] 
[0.x.15167] 
//
//       We prescribe the velocity (we are dealing with a particular       component here so that the average of the velocities is       orthogonal to the surface normal.  This creates sensitivities       of across the velocity components.
//
[0.x.15168] 
[0.x.15169] 
[0.x.15170] 
[0.x.15171] 
[0.x.15172] 
//
[0.x.15173] 
[0.x.15174] 
[0.x.15175] 
//
[0.x.15176] 
[0.x.15177] 
[0.x.15178] 
[0.x.15179] 
//[2.x.2122] 
//
// In this class, we also want to specify how to refine the mesh. The class  [2.x.2123]  that will use all the information we provide here in the  [2.x.2124]  class is pretty agnostic about the particular conservation law it solves: as doesn't even really care how many components a solution vector has. Consequently, it can't know what a reasonable refinement indicator would be. On the other hand, here we do, or at least we can come up with a reasonable choice: we simply look at the gradient of the density, and compute  [2.x.2125] , where  [2.x.2126]  is the center of cell  [2.x.2127] .
//
// There are certainly a number of equally reasonable refinement indicators, but this one does, and it is easy to compute:
//
[0.x.15180] 
[0.x.15181] 
[0.x.15182] 
[0.x.15183] 
[0.x.15184] 
[0.x.15185] 
[0.x.15186] 
[0.x.15187] 
//
[0.x.15188] 
[0.x.15189] 
[0.x.15190] 
[0.x.15191] 
[0.x.15192] 
[0.x.15193] 
//
[0.x.15194] 
[0.x.15195] 
//
[0.x.15196] 
[0.x.15197] 
[0.x.15198] 
[0.x.15199] 
[0.x.15200] 
//
[0.x.15201] 
[0.x.15202] 
[0.x.15203] 
[0.x.15204] 
//
//  [2.x.2128] 
//
// Finally, we declare a class that implements a postprocessing of data components. The problem this class solves is that the variables in the formulation of the Euler equations we use are in conservative rather than physical form: they are momentum densities  [2.x.2129] , density  [2.x.2130] , and energy density  [2.x.2131] . What we would like to also put into our output file are velocities  [2.x.2132]  and pressure  [2.x.2133] .
//
// In addition, we would like to add the possibility to generate schlieren plots. Schlieren plots are a way to visualize shocks and other sharp interfaces. The word "schlieren" is a German word that may be translated as "striae" -- it may be simpler to explain it by an example, however: schlieren is what you see when you, for example, pour highly concentrated alcohol, or a transparent saline solution, into water; the two have the same color, but they have different refractive indices and so before they are fully mixed light goes through the mixture along bent rays that lead to brightness variations if you look at it. That's "schlieren". A similar effect happens in compressible flow because the refractive index depends on the pressure (and therefore the density) of the gas.
//
// The origin of the word refers to two-dimensional projections of a three-dimensional volume (we see a 2d picture of the 3d fluid). In computational fluid dynamics, we can get an idea of this effect by considering what causes it: density variations. Schlieren plots are therefore produced by plotting  [2.x.2134] ; obviously,  [2.x.2135]  is large in shocks and at other highly dynamic places. If so desired by the user (by specifying this in the input file), we would like to generate these schlieren plots in addition to the other derived quantities listed above.
//
// The implementation of the algorithms to compute derived quantities from the ones that solve our problem, and to output them into data file, rests on the DataPostprocessor class. It has extensive documentation, and other uses of the class can also be found in  [2.x.2136] . We therefore refrain from extensive comments.
//
[0.x.15205] 
[0.x.15206] 
[0.x.15207] 
[0.x.15208] 
//
[0.x.15209] 
[0.x.15210] 
[0.x.15211] 
//
[0.x.15212] 
//
[0.x.15213] 
[0.x.15214] 
[0.x.15215] 
//
[0.x.15216] 
//
[0.x.15217] 
[0.x.15218] 
[0.x.15219] 
[0.x.15220] 
//
[0.x.15221] 
[0.x.15222] 
//
[0.x.15223] 
[0.x.15224] 
[0.x.15225] 
[0.x.15226] 
[0.x.15227] 
//
// This is the only function worth commenting on. When generating graphical output, the DataOut and related classes will call this function on each cell, with access to values, gradients, Hessians, and normal vectors (in case we're working on faces) at each quadrature point. Note that the data at each quadrature point is itself vector-valued, namely the conserved variables. What we're going to do here is to compute the quantities we're interested in at each quadrature point. Note that for this we can ignore the Hessians ("inputs.solution_hessians") and normal vectors ("inputs.normals").
//
[0.x.15228] 
[0.x.15229] 
[0.x.15230] 
[0.x.15231] 
[0.x.15232] 
//
// At the beginning of the function, let us make sure that all variables have the correct sizes, so that we can access individual vector elements without having to wonder whether we might read or write invalid elements; we also check that the  [2.x.2137]  vector only contains data if we really need it (the system knows about this because we say so in the  [2.x.2138]  function below). For the inner vectors, we check that at least the first element of the outer vector has the correct inner size:
//
[0.x.15233] 
//
[0.x.15234] 
[0.x.15235] 
[0.x.15236] 
//
[0.x.15237] 
[0.x.15238] 
//
[0.x.15239] 
[0.x.15240] 
//
[0.x.15241] 
[0.x.15242] 
[0.x.15243] 
[0.x.15244] 
[0.x.15245] 
[0.x.15246] 
[0.x.15247] 
[0.x.15248] 
//
// Then loop over all quadrature points and do our work there. The code should be pretty self-explanatory. The order of output variables is first  [2.x.2139]  velocities, then the pressure, and if so desired the schlieren plot. Note that we try to be generic about the order of variables in the input vector, using the  [2.x.2140]  and  [2.x.2141]  information:
//
[0.x.15249] 
[0.x.15250] 
[0.x.15251] 
//
[0.x.15252] 
[0.x.15253] 
[0.x.15254] 
//
[0.x.15255] 
[0.x.15256] 
//
[0.x.15257] 
[0.x.15258] 
[0.x.15259] 
[0.x.15260] 
[0.x.15261] 
[0.x.15262] 
//
[0.x.15263] 
[0.x.15264] 
[0.x.15265] 
[0.x.15266] 
[0.x.15267] 
[0.x.15268] 
[0.x.15269] 
//
[0.x.15270] 
[0.x.15271] 
//
[0.x.15272] 
[0.x.15273] 
//
[0.x.15274] 
[0.x.15275] 
[0.x.15276] 
[0.x.15277] 
[0.x.15278] 
[0.x.15279] 
[0.x.15280] 
//
[0.x.15281] 
//
[0.x.15282] 
[0.x.15283] 
[0.x.15284] 
//
[0.x.15285] 
[0.x.15286] 
//
[0.x.15287] 
[0.x.15288] 
[0.x.15289] 
[0.x.15290] 
[0.x.15291] 
[0.x.15292] 
[0.x.15293] 
[0.x.15294] 
[0.x.15295] 
//[2.x.2142] 
//
// Our next job is to define a few classes that will contain run-time parameters (for example solver tolerances, number of iterations, stabilization parameter, and the like). One could do this in the main class, but we separate it from that one to make the program more modular and easier to read: Everything that has to do with run-time parameters will be in the following namespace, whereas the program logic is in the main class.
//
// We will split the run-time parameters into a few separate structures, which we will all put into a namespace  [2.x.2143] . Of these classes, there are a few that group the parameters for individual groups, such as for solvers, mesh refinement, or output. Each of these classes have functions  [2.x.2144]  and  [2.x.2145]  that declare parameter subsections and entries in a ParameterHandler object, and retrieve actual parameter values from such an object, respectively. These classes declare all their parameters in subsections of the ParameterHandler.
//
// The final class of the following namespace combines all the previous classes by deriving from them and taking care of a few more entries at the top level of the input file, as well as a few odd other entries in subsections that are too short to warrant a structure by themselves.
//
// It is worth pointing out one thing here: None of the classes below have a constructor that would initialize the various member variables. This isn't a problem, however, since we will read all variables declared in these classes from the input file (or indirectly: a ParameterHandler object will read it from there, and we will get the values from this object), and they will be initialized this way. In case a certain variable is not specified at all in the input file, this isn't a problem either: The ParameterHandler class will in this case simply take the default value that was specified when declaring an entry in the  [2.x.2146]  functions of the classes below.
//
[0.x.15296] 
[0.x.15297] 
//[2.x.2147] 
//
// The first of these classes deals with parameters for the linear inner solver. It offers parameters that indicate which solver to use (GMRES as a solver for general non-symmetric indefinite systems, or a sparse direct solver), the amount of output to be produced, as well as various parameters that tweak the thresholded incomplete LU decomposition (ILUT) that we use as a preconditioner for GMRES.
//
// In particular, the ILUT takes the following parameters:
//
// - ilut_fill: the number of extra entries to add when forming the ILU   decomposition
//
// - ilut_atol, ilut_rtol: When forming the preconditioner, for certain   problems bad conditioning (or just bad luck) can cause the   preconditioner to be very poorly conditioned.  Hence it can help to   add diagonal perturbations to the original matrix and form the   preconditioner for this slightly better matrix.  ATOL is an absolute   perturbation that is added to the diagonal before forming the prec,   and RTOL is a scaling factor  [2.x.2148] .
//
// - ilut_drop: The ILUT will drop any values that have magnitude less   than this value.  This is a way to manage the amount of memory used   by this preconditioner.
//
// The meaning of each parameter is also briefly described in the third argument of the  [2.x.2149]  call in  [2.x.2150] .
//
[0.x.15298] 
[0.x.15299] 
[0.x.15300] 
[0.x.15301] 
[0.x.15302] 
[0.x.15303] 
[0.x.15304] 
[0.x.15305] 
//
[0.x.15306] 
[0.x.15307] 
[0.x.15308] 
[0.x.15309] 
[0.x.15310] 
[0.x.15311] 
//
[0.x.15312] 
[0.x.15313] 
//
[0.x.15314] 
[0.x.15315] 
[0.x.15316] 
[0.x.15317] 
//
[0.x.15318] 
[0.x.15319] 
[0.x.15320] 
//
[0.x.15321] 
[0.x.15322] 
[0.x.15323] 
[0.x.15324] 
[0.x.15325] 
[0.x.15326] 
[0.x.15327] 
[0.x.15328] 
[0.x.15329] 
[0.x.15330] 
[0.x.15331] 
[0.x.15332] 
[0.x.15333] 
[0.x.15334] 
[0.x.15335] 
[0.x.15336] 
[0.x.15337] 
[0.x.15338] 
[0.x.15339] 
[0.x.15340] 
[0.x.15341] 
[0.x.15342] 
[0.x.15343] 
[0.x.15344] 
[0.x.15345] 
[0.x.15346] 
[0.x.15347] 
[0.x.15348] 
[0.x.15349] 
[0.x.15350] 
[0.x.15351] 
[0.x.15352] 
[0.x.15353] 
[0.x.15354] 
[0.x.15355] 
[0.x.15356] 
[0.x.15357] 
[0.x.15358] 
[0.x.15359] 
[0.x.15360] 
[0.x.15361] 
[0.x.15362] 
//
[0.x.15363] 
[0.x.15364] 
[0.x.15365] 
[0.x.15366] 
[0.x.15367] 
[0.x.15368] 
[0.x.15369] 
[0.x.15370] 
[0.x.15371] 
//
[0.x.15372] 
[0.x.15373] 
[0.x.15374] 
[0.x.15375] 
[0.x.15376] 
//
[0.x.15377] 
[0.x.15378] 
[0.x.15379] 
[0.x.15380] 
[0.x.15381] 
[0.x.15382] 
[0.x.15383] 
[0.x.15384] 
[0.x.15385] 
//
//  [2.x.2151] 
//
// Similarly, here are a few parameters that determine how the mesh is to be refined (and if it is to be refined at all). For what exactly the shock parameters do, see the mesh refinement functions further down.
//
[0.x.15386] 
[0.x.15387] 
[0.x.15388] 
[0.x.15389] 
[0.x.15390] 
//
[0.x.15391] 
[0.x.15392] 
[0.x.15393] 
//
[0.x.15394] 
[0.x.15395] 
[0.x.15396] 
[0.x.15397] 
[0.x.15398] 
[0.x.15399] 
[0.x.15400] 
[0.x.15401] 
[0.x.15402] 
[0.x.15403] 
[0.x.15404] 
[0.x.15405] 
[0.x.15406] 
[0.x.15407] 
[0.x.15408] 
[0.x.15409] 
[0.x.15410] 
[0.x.15411] 
[0.x.15412] 
[0.x.15413] 
[0.x.15414] 
[0.x.15415] 
[0.x.15416] 
[0.x.15417] 
[0.x.15418] 
[0.x.15419] 
[0.x.15420] 
[0.x.15421] 
[0.x.15422] 
[0.x.15423] 
[0.x.15424] 
//
[0.x.15425] 
[0.x.15426] 
[0.x.15427] 
[0.x.15428] 
[0.x.15429] 
[0.x.15430] 
[0.x.15431] 
[0.x.15432] 
[0.x.15433] 
[0.x.15434] 
//
//  [2.x.2152] 
//
// Next a section on flux modifications to make it more stable. In particular, two options are offered to stabilize the Lax-Friedrichs flux: either choose  [2.x.2153]  where  [2.x.2154]  is either a fixed number specified in the input file, or where  [2.x.2155]  is a mesh dependent value. In the latter case, it is chosen as  [2.x.2156]  with  [2.x.2157]  the diameter of the face to which the flux is applied, and  [2.x.2158]  the current time step.
//
[0.x.15435] 
[0.x.15436] 
[0.x.15437] 
[0.x.15438] 
[0.x.15439] 
[0.x.15440] 
[0.x.15441] 
[0.x.15442] 
//
[0.x.15443] 
//
[0.x.15444] 
[0.x.15445] 
[0.x.15446] 
//
[0.x.15447] 
[0.x.15448] 
[0.x.15449] 
[0.x.15450] 
[0.x.15451] 
[0.x.15452] 
[0.x.15453] 
[0.x.15454] 
[0.x.15455] 
[0.x.15456] 
[0.x.15457] 
[0.x.15458] 
[0.x.15459] 
[0.x.15460] 
[0.x.15461] 
[0.x.15462] 
[0.x.15463] 
//
[0.x.15464] 
[0.x.15465] 
[0.x.15466] 
[0.x.15467] 
[0.x.15468] 
[0.x.15469] 
[0.x.15470] 
[0.x.15471] 
[0.x.15472] 
[0.x.15473] 
[0.x.15474] 
//
[0.x.15475] 
[0.x.15476] 
[0.x.15477] 
[0.x.15478] 
//
//  [2.x.2159] 
//
// Then a section on output parameters. We offer to produce Schlieren plots (the squared gradient of the density, a tool to visualize shock fronts), and a time interval between graphical output in case we don't want an output file every time step.
//
[0.x.15479] 
[0.x.15480] 
[0.x.15481] 
[0.x.15482] 
//
[0.x.15483] 
[0.x.15484] 
[0.x.15485] 
//
[0.x.15486] 
[0.x.15487] 
[0.x.15488] 
[0.x.15489] 
[0.x.15490] 
[0.x.15491] 
[0.x.15492] 
[0.x.15493] 
[0.x.15494] 
[0.x.15495] 
[0.x.15496] 
[0.x.15497] 
[0.x.15498] 
[0.x.15499] 
[0.x.15500] 
//
[0.x.15501] 
[0.x.15502] 
[0.x.15503] 
[0.x.15504] 
[0.x.15505] 
[0.x.15506] 
[0.x.15507] 
[0.x.15508] 
[0.x.15509] 
//
//  [2.x.2160] 
//
// Finally the class that brings it all together. It declares a number of parameters itself, mostly ones at the top level of the parameter file as well as several in section too small to warrant their own classes. It also contains everything that is actually space dimension dependent, like initial or boundary conditions.
//
// Since this class is derived from all the ones above, the  [2.x.2161]  functions call the respective functions of the base classes as well.
//
// Note that this class also handles the declaration of initial and boundary conditions specified in the input file. To this end, in both cases, there are entries like "w_0 value" which represent an expression in terms of  [2.x.2162]  that describe the initial or boundary condition as a formula that will later be parsed by the FunctionParser class. Similar expressions exist for "w_1", "w_2", etc, denoting the  [2.x.2163]  conserved variables of the Euler system. Similarly, we allow up to  [2.x.2164]  boundary indicators to be used in the input file, and each of these boundary indicators can be associated with an inflow, outflow, or pressure boundary condition, with homogeneous boundary conditions being specified for each component and each boundary indicator separately.
//
// The data structure used to store the boundary indicators is a bit complicated. It is an array of  [2.x.2165]  elements indicating the range of boundary indicators that will be accepted. For each entry in this array, we store a pair of data in the  [2.x.2166]  structure: first, an array of size  [2.x.2167]  that for each component of the solution vector indicates whether it is an inflow, outflow, or other kind of boundary, and second a FunctionParser object that describes all components of the solution vector for this boundary id at once.
//
// The  [2.x.2168]  structure requires a constructor since we need to tell the function parser object at construction time how many vector components it is to describe. This initialization can therefore not wait till we actually set the formulas the FunctionParser object represents later in  [2.x.2169] 
//
// For the same reason of having to tell Function objects their vector size at construction time, we have to have a constructor of the  [2.x.2170]  class that at least initializes the other FunctionParser object, i.e. the one describing initial conditions.
//
[0.x.15510] 
[0.x.15511] 
[0.x.15512] 
[0.x.15513] 
[0.x.15514] 
[0.x.15515] 
[0.x.15516] 
//
[0.x.15517] 
[0.x.15518] 
[0.x.15519] 
[0.x.15520] 
[0.x.15521] 
//
[0.x.15522] 
//
[0.x.15523] 
[0.x.15524] 
//
[0.x.15525] 
//
[0.x.15526] 
//
[0.x.15527] 
[0.x.15528] 
[0.x.15529] 
//
[0.x.15530] 
//
[0.x.15531] 
[0.x.15532] 
//
[0.x.15533] 
[0.x.15534] 
[0.x.15535] 
//
[0.x.15536] 
[0.x.15537] 
[0.x.15538] 
[0.x.15539] 
[0.x.15540] 
[0.x.15541] 
[0.x.15542] 
[0.x.15543] 
//
[0.x.15544] 
[0.x.15545] 
[0.x.15546] 
[0.x.15547] 
[0.x.15548] 
[0.x.15549] 
[0.x.15550] 
[0.x.15551] 
[0.x.15552] 
//
[0.x.15553] 
[0.x.15554] 
[0.x.15555] 
[0.x.15556] 
[0.x.15557] 
[0.x.15558] 
[0.x.15559] 
//
[0.x.15560] 
[0.x.15561] 
[0.x.15562] 
[0.x.15563] 
//
[0.x.15564] 
[0.x.15565] 
[0.x.15566] 
[0.x.15567] 
[0.x.15568] 
[0.x.15569] 
[0.x.15570] 
[0.x.15571] 
[0.x.15572] 
[0.x.15573] 
[0.x.15574] 
[0.x.15575] 
[0.x.15576] 
[0.x.15577] 
[0.x.15578] 
[0.x.15579] 
[0.x.15580] 
[0.x.15581] 
//
[0.x.15582] 
[0.x.15583] 
[0.x.15584] 
[0.x.15585] 
[0.x.15586] 
[0.x.15587] 
[0.x.15588] 
[0.x.15589] 
[0.x.15590] 
//
[0.x.15591] 
[0.x.15592] 
[0.x.15593] 
[0.x.15594] 
[0.x.15595] 
[0.x.15596] 
[0.x.15597] 
[0.x.15598] 
//
[0.x.15599] 
[0.x.15600] 
[0.x.15601] 
[0.x.15602] 
[0.x.15603] 
[0.x.15604] 
[0.x.15605] 
[0.x.15606] 
[0.x.15607] 
//
[0.x.15608] 
[0.x.15609] 
[0.x.15610] 
[0.x.15611] 
[0.x.15612] 
[0.x.15613] 
[0.x.15614] 
[0.x.15615] 
[0.x.15616] 
//
[0.x.15617] 
[0.x.15618] 
[0.x.15619] 
[0.x.15620] 
[0.x.15621] 
//
[0.x.15622] 
[0.x.15623] 
[0.x.15624] 
[0.x.15625] 
[0.x.15626] 
//
[0.x.15627] 
[0.x.15628] 
[0.x.15629] 
[0.x.15630] 
[0.x.15631] 
[0.x.15632] 
[0.x.15633] 
[0.x.15634] 
[0.x.15635] 
[0.x.15636] 
[0.x.15637] 
//
[0.x.15638] 
[0.x.15639] 
[0.x.15640] 
[0.x.15641] 
//
[0.x.15642] 
[0.x.15643] 
[0.x.15644] 
[0.x.15645] 
[0.x.15646] 
[0.x.15647] 
[0.x.15648] 
[0.x.15649] 
//
[0.x.15650] 
//
[0.x.15651] 
[0.x.15652] 
[0.x.15653] 
[0.x.15654] 
[0.x.15655] 
//
[0.x.15656] 
[0.x.15657] 
[0.x.15658] 
[0.x.15659] 
[0.x.15660] 
[0.x.15661] 
[0.x.15662] 
[0.x.15663] 
[0.x.15664] 
[0.x.15665] 
[0.x.15666] 
[0.x.15667] 
[0.x.15668] 
[0.x.15669] 
//
[0.x.15670] 
[0.x.15671] 
[0.x.15672] 
//
[0.x.15673] 
[0.x.15674] 
[0.x.15675] 
[0.x.15676] 
[0.x.15677] 
[0.x.15678] 
[0.x.15679] 
//
[0.x.15680] 
[0.x.15681] 
[0.x.15682] 
[0.x.15683] 
[0.x.15684] 
[0.x.15685] 
[0.x.15686] 
[0.x.15687] 
[0.x.15688] 
[0.x.15689] 
[0.x.15690] 
[0.x.15691] 
[0.x.15692] 
//
[0.x.15693] 
[0.x.15694] 
[0.x.15695] 
[0.x.15696] 
[0.x.15697] 
[0.x.15698] 
//
//  [2.x.2171] 
//
// Here finally comes the class that actually does something with all the Euler equation and parameter specifics we've defined above. The public interface is pretty much the same as always (the constructor now takes the name of a file from which to read parameters, which is passed on the command line). The private function interface is also pretty similar to the usual arrangement, with the  [2.x.2172]  function split into three parts: one that contains the main loop over all cells and that then calls the other two for integrals over cells and faces, respectively.
//
[0.x.15699] 
[0.x.15700] 
[0.x.15701] 
[0.x.15702] 
[0.x.15703] 
[0.x.15704] 
//
[0.x.15705] 
[0.x.15706] 
//
[0.x.15707] 
[0.x.15708] 
[0.x.15709] 
[0.x.15710] 
[0.x.15711] 
[0.x.15712] 
[0.x.15713] 
[0.x.15714] 
[0.x.15715] 
[0.x.15716] 
[0.x.15717] 
[0.x.15718] 
//
[0.x.15719] 
//
[0.x.15720] 
[0.x.15721] 
//
[0.x.15722] 
//
// The first few member variables are also rather standard. Note that we define a mapping object to be used throughout the program when assembling terms (we will hand it to every FEValues and FEFaceValues object); the mapping we use is just the standard  [2.x.2173]  mapping -- nothing fancy, in other words -- but declaring one here and using it throughout the program will make it simpler later on to change it if that should become necessary. This is, in fact, rather pertinent: it is known that for transsonic simulations with the Euler equations, computations do not converge even as  [2.x.2174]  if the boundary approximation is not of sufficiently high order.
//
[0.x.15723] 
[0.x.15724] 
//
[0.x.15725] 
[0.x.15726] 
//
[0.x.15727] 
[0.x.15728] 
//
// Next come a number of data vectors that correspond to the solution of the previous time step ( [2.x.2175] ), the best guess of the current solution ( [2.x.2176] ; we say [1.x.60] because the Newton iteration to compute it may not have converged yet, whereas  [2.x.2177]  refers to the fully converged final result of the previous time step), and a predictor for the solution at the next time step, computed by extrapolating the current and previous solution one time step into the future:
//
[0.x.15729] 
[0.x.15730] 
[0.x.15731] 
//
[0.x.15732] 
//
// This final set of member variables (except for the object holding all run-time parameters at the very bottom and a screen output stream that only prints something if verbose output has been requested) deals with the interface we have in this program to the Trilinos library that provides us with linear solvers. Similarly to including PETSc matrices in  [2.x.2178]  and  [2.x.2179] , all we need to do is to create a Trilinos sparse matrix instead of the standard deal.II class. The system matrix is used for the Jacobian in each Newton step. Since we do not intend to run this program in parallel (which wouldn't be too hard with Trilinos data structures, though), we don't have to think about anything else like distributing the degrees of freedom.
//
[0.x.15733] 
//
[0.x.15734] 
[0.x.15735] 
[0.x.15736] 
//[2.x.2180] 
//
// There is nothing much to say about the constructor. Essentially, it reads the input file and fills the parameter object with the parsed values:
//
[0.x.15737] 
[0.x.15738] 
[0.x.15739] 
[0.x.15740] 
[0.x.15741] 
[0.x.15742] 
[0.x.15743] 
[0.x.15744] 
[0.x.15745] 
[0.x.15746] 
[0.x.15747] 
//
[0.x.15748] 
[0.x.15749] 
//
[0.x.15750] 
[0.x.15751] 
[0.x.15752] 
//
//  [2.x.2181] 
//
// The following (easy) function is called each time the mesh is changed. All it does is to resize the Trilinos matrix according to a sparsity pattern that we generate as in all the previous tutorial programs.
//
[0.x.15753] 
[0.x.15754] 
[0.x.15755] 
[0.x.15756] 
[0.x.15757] 
//
[0.x.15758] 
[0.x.15759] 
//[2.x.2182] 
//
// This and the following two functions are the meat of this program: They assemble the linear system that results from applying Newton's method to the nonlinear system of conservation equations.
//
// This first function puts all of the assembly pieces together in a routine that dispatches the correct piece for each cell/face.  The actual implementation of the assembly on these objects is done in the following functions.
//
// At the top of the function we do the usual housekeeping: allocate FEValues, FEFaceValues, and FESubfaceValues objects necessary to do the integrations on cells, faces, and subfaces (in case of adjoining cells on different refinement levels). Note that we don't need all information (like values, gradients, or real locations of quadrature points) for all of these objects, so we only let the FEValues classes whatever is actually necessary by specifying the minimal set of UpdateFlags. For example, when using a FEFaceValues object for the neighboring cell we only need the shape values: Given a specific face, the quadrature points and  [2.x.2183]  values are the same as for the current cells, and the normal vectors are known to be the negative of the normal vectors of the current cell.
//
[0.x.15760] 
[0.x.15761] 
[0.x.15762] 
[0.x.15763] 
//
[0.x.15764] 
[0.x.15765] 
//
[0.x.15766] 
[0.x.15767] 
[0.x.15768] 
[0.x.15769] 
[0.x.15770] 
[0.x.15771] 
[0.x.15772] 
//
[0.x.15773] 
[0.x.15774] 
[0.x.15775] 
[0.x.15776] 
[0.x.15777] 
[0.x.15778] 
[0.x.15779] 
[0.x.15780] 
[0.x.15781] 
[0.x.15782] 
[0.x.15783] 
[0.x.15784] 
[0.x.15785] 
[0.x.15786] 
[0.x.15787] 
[0.x.15788] 
[0.x.15789] 
//
// Then loop over all cells, initialize the FEValues object for the current cell and call the function that assembles the problem on this cell.
//
[0.x.15790] 
[0.x.15791] 
[0.x.15792] 
[0.x.15793] 
//
[0.x.15794] 
//
// Then loop over all the faces of this cell.  If a face is part of the external boundary, then assemble boundary conditions there (the fifth argument to  [2.x.2184]  indicates whether we are working on an external or internal face; if it is an external face, the fourth argument denoting the degrees of freedom indices of the neighbor is ignored, so we pass an empty vector):
//
[0.x.15795] 
[0.x.15796] 
[0.x.15797] 
[0.x.15798] 
[0.x.15799] 
[0.x.15800] 
[0.x.15801] 
[0.x.15802] 
[0.x.15803] 
[0.x.15804] 
[0.x.15805] 
[0.x.15806] 
[0.x.15807] 
//
// The alternative is that we are dealing with an internal face. There are two cases that we need to distinguish: that this is a normal face between two cells at the same refinement level, and that it is a face between two cells of the different refinement levels.
//
// In the first case, there is nothing we need to do: we are using a continuous finite element, and face terms do not appear in the bilinear form in this case. The second case usually does not lead to face terms either if we enforce hanging node constraints strongly (as in all previous tutorial programs so far whenever we used continuous finite elements -- this enforcement is done by the AffineConstraints class together with  [2.x.2185]  In the current program, however, we opt to enforce continuity weakly at faces between cells of different refinement level, for two reasons: (i) because we can, and more importantly (ii) because we would have to thread the automatic differentiation we use to compute the elements of the Newton matrix from the residual through the operations of the AffineConstraints class. This would be possible, but is not trivial, and so we choose this alternative approach.
//
// What needs to be decided is which side of an interface between two cells of different refinement level we are sitting on.
//
// Let's take the case where the neighbor is more refined first. We then have to loop over the children of the face of the current cell and integrate on each of them. We sprinkle a couple of assertions into the code to ensure that our reasoning trying to figure out which of the neighbor's children's faces coincides with a given subface of the current cell's faces is correct -- a bit of defensive programming never hurts.
//
// We then call the function that integrates over faces; since this is an internal face, the fifth argument is false, and the sixth one is ignored so we pass an invalid value again:
//
[0.x.15808] 
[0.x.15809] 
[0.x.15810] 
[0.x.15811] 
[0.x.15812] 
[0.x.15813] 
//
[0.x.15814] 
[0.x.15815] 
[0.x.15816] 
[0.x.15817] 
[0.x.15818] 
[0.x.15819] 
[0.x.15820] 
//
[0.x.15821] 
[0.x.15822] 
[0.x.15823] 
[0.x.15824] 
//
[0.x.15825] 
[0.x.15826] 
//
[0.x.15827] 
//
[0.x.15828] 
[0.x.15829] 
[0.x.15830] 
[0.x.15831] 
[0.x.15832] 
[0.x.15833] 
[0.x.15834] 
[0.x.15835] 
[0.x.15836] 
[0.x.15837] 
[0.x.15838] 
//
//     The other possibility we have to care for is if the neighbor     is coarser than the current cell (in particular, because of     the usual restriction of only one hanging node per face, the     neighbor must be exactly one level coarser than the current     cell, something that we check with an assertion). Again, we     then integrate over this interface:
//
[0.x.15839] 
[0.x.15840] 
[0.x.15841] 
[0.x.15842] 
[0.x.15843] 
[0.x.15844] 
//
[0.x.15845] 
//
[0.x.15846] 
[0.x.15847] 
[0.x.15848] 
[0.x.15849] 
[0.x.15850] 
//
[0.x.15851] 
[0.x.15852] 
[0.x.15853] 
//
[0.x.15854] 
[0.x.15855] 
[0.x.15856] 
[0.x.15857] 
//
[0.x.15858] 
[0.x.15859] 
[0.x.15860] 
[0.x.15861] 
[0.x.15862] 
[0.x.15863] 
[0.x.15864] 
[0.x.15865] 
[0.x.15866] 
[0.x.15867] 
[0.x.15868] 
[0.x.15869] 
//[2.x.2186] 
//
// This function assembles the cell term by computing the cell part of the residual, adding its negative to the right hand side vector, and adding its derivative with respect to the local variables to the Jacobian (i.e. the Newton matrix). Recall that the cell contributions to the residual read  [2.x.2187] 
//[2.x.2188] 
//[2.x.2189]  where  [2.x.2190] 
//[2.x.2191] 
//[2.x.2192]  for both  [2.x.2193]  and  [2.x.2194]  ,  [2.x.2195]  is the  [2.x.2196] th vector valued test function.   Furthermore, the scalar product  [2.x.2197]  is understood as  [2.x.2198]  where  [2.x.2199]  is the  [2.x.2200] th component of the  [2.x.2201] th test function.
//
// At the top of this function, we do the usual housekeeping in terms of allocating some local variables that we will need later. In particular, we will allocate variables that will hold the values of the current solution  [2.x.2202]  after the  [2.x.2203] th Newton iteration (variable  [2.x.2204] ) and the previous time step's solution  [2.x.2205]  (variable  [2.x.2206] ).
//
// In addition to these, we need the gradients of the current variables.  It is a bit of a shame that we have to compute these; we almost don't.  The nice thing about a simple conservation law is that the flux doesn't generally involve any gradients.  We do need these, however, for the diffusion stabilization.
//
// The actual format in which we store these variables requires some explanation. First, we need values at each quadrature point for each of the  [2.x.2207]  components of the solution vector. This makes for a two-dimensional table for which we use deal.II's Table class (this is more efficient than  [2.x.2208]  because it only needs to allocate memory once, rather than once for each element of the outer vector). Similarly, the gradient is a three-dimensional table, which the Table class also supports.
//
// Secondly, we want to use automatic differentiation. To this end, we use the  [2.x.2209]  template for everything that is computed from the variables with respect to which we would like to compute derivatives. This includes the current solution and gradient at the quadrature points (which are linear combinations of the degrees of freedom) as well as everything that is computed from them such as the residual, but not the previous time step's solution. These variables are all found in the first part of the function, along with a variable that we will use to store the derivatives of a single component of the residual:
//
[0.x.15870] 
[0.x.15871] 
[0.x.15872] 
[0.x.15873] 
[0.x.15874] 
[0.x.15875] 
[0.x.15876] 
//
[0.x.15877] 
[0.x.15878] 
//
[0.x.15879] 
//
[0.x.15880] 
[0.x.15881] 
//
[0.x.15882] 
[0.x.15883] 
[0.x.15884] 
//
[0.x.15885] 
//
// Next, we have to define the independent variables that we will try to determine by solving a Newton step. These independent variables are the values of the local degrees of freedom which we extract here:
//
[0.x.15886] 
[0.x.15887] 
[0.x.15888] 
[0.x.15889] 
//
// The next step incorporates all the magic: we declare a subset of the autodifferentiation variables as independent degrees of freedom, whereas all the other ones remain dependent functions. These are precisely the local degrees of freedom just extracted. All calculations that reference them (either directly or indirectly) will accumulate sensitivities with respect to these variables.
//
// In order to mark the variables as independent, the following does the trick, marking  [2.x.2210]  as the  [2.x.2211] th independent variable out of a total of  [2.x.2212] :
//
[0.x.15890] 
[0.x.15891] 
//
// After all these declarations, let us actually compute something. First, the values of  [2.x.2213]  and  [2.x.2214] , which we can compute from the local DoF values by using the formula  [2.x.2215] , where  [2.x.2216]  is the  [2.x.2217] th entry of the (local part of the) solution vector, and  [2.x.2218]  the value of the  [2.x.2219] th vector-valued shape function evaluated at quadrature point  [2.x.2220] . The gradient can be computed in a similar way.
//
// Ideally, we could compute this information using a call into something like  [2.x.2221]  and  [2.x.2222]  but since (i) we would have to extend the FEValues class for this, and (ii) we don't want to make the entire  [2.x.2223]  vector fad types, only the local cell variables, we explicitly code the loop above. Before this, we add another loop that initializes all the fad variables to zero:
//
[0.x.15892] 
[0.x.15893] 
[0.x.15894] 
[0.x.15895] 
[0.x.15896] 
[0.x.15897] 
[0.x.15898] 
[0.x.15899] 
[0.x.15900] 
[0.x.15901] 
[0.x.15902] 
//
[0.x.15903] 
[0.x.15904] 
[0.x.15905] 
[0.x.15906] 
[0.x.15907] 
//
[0.x.15908] 
[0.x.15909] 
[0.x.15910] 
[0.x.15911] 
//
[0.x.15912] 
[0.x.15913] 
[0.x.15914] 
[0.x.15915] 
[0.x.15916] 
[0.x.15917] 
[0.x.15918] 
[0.x.15919] 
//
// Next, in order to compute the cell contributions, we need to evaluate  [2.x.2224] ,  [2.x.2225]  and  [2.x.2226] ,  [2.x.2227]  at all quadrature points. To store these, we also need to allocate a bit of memory. Note that we compute the flux matrices and right hand sides in terms of autodifferentiation variables, so that the Jacobian contributions can later easily be computed from it:
//
[0.x.15920] 
[0.x.15921] 
[0.x.15922] 
[0.x.15923] 
//
[0.x.15924] 
[0.x.15925] 
//
[0.x.15926] 
[0.x.15927] 
[0.x.15928] 
//
[0.x.15929] 
[0.x.15930] 
//
[0.x.15931] 
[0.x.15932] 
[0.x.15933] 
[0.x.15934] 
[0.x.15935] 
[0.x.15936] 
[0.x.15937] 
//
// We now have all of the pieces in place, so perform the assembly.  We have an outer loop through the components of the system, and an inner loop over the quadrature points, where we accumulate contributions to the  [2.x.2228] th residual  [2.x.2229] . The general formula for this residual is given in the introduction and at the top of this function. We can, however, simplify it a bit taking into account that the  [2.x.2230] th (vector-valued) test function  [2.x.2231]  has in reality only a single nonzero component (more on this topic can be found in the  [2.x.2232]  vector_valued module). It will be represented by the variable  [2.x.2233]  below. With this, the residual term can be re-written as [1.x.61] where integrals are understood to be evaluated through summation over quadrature points.
//
// We initially sum all contributions of the residual in the positive sense, so that we don't need to negative the Jacobian entries.  Then, when we sum into the  [2.x.2234]  vector, we negate this residual.
//
[0.x.15938] 
[0.x.15939] 
[0.x.15940] 
//
[0.x.15941] 
[0.x.15942] 
//
// The residual for each row (i) will be accumulating into this fad variable.  At the end of the assembly for this row, we will query for the sensitivities to this variable and add them into the Jacobian.
//
[0.x.15943] 
[0.x.15944] 
[0.x.15945] 
[0.x.15946] 
[0.x.15947] 
[0.x.15948] 
[0.x.15949] 
//
[0.x.15950] 
[0.x.15951] 
[0.x.15952] 
[0.x.15953] 
[0.x.15954] 
[0.x.15955] 
//
[0.x.15956] 
[0.x.15957] 
[0.x.15958] 
[0.x.15959] 
[0.x.15960] 
[0.x.15961] 
[0.x.15962] 
[0.x.15963] 
[0.x.15964] 
//
[0.x.15965] 
[0.x.15966] 
[0.x.15967] 
[0.x.15968] 
[0.x.15969] 
[0.x.15970] 
//
// At the end of the loop, we have to add the sensitivities to the matrix and subtract the residual from the right hand side. Trilinos FAD data type gives us access to the derivatives using  [2.x.2235] , so we store the data in a temporary array. This information about the whole row of local dofs is then added to the Trilinos matrix at once (which supports the data types we have chosen).
//
[0.x.15971] 
[0.x.15972] 
[0.x.15973] 
[0.x.15974] 
[0.x.15975] 
[0.x.15976] 
//[2.x.2236] 
//
// Here, we do essentially the same as in the previous function. At the top, we introduce the independent variables. Because the current function is also used if we are working on an internal face between two cells, the independent variables are not only the degrees of freedom on the current cell but in the case of an interior face also the ones on the neighbor.
//
[0.x.15977] 
[0.x.15978] 
[0.x.15979] 
[0.x.15980] 
[0.x.15981] 
[0.x.15982] 
[0.x.15983] 
[0.x.15984] 
[0.x.15985] 
[0.x.15986] 
[0.x.15987] 
[0.x.15988] 
[0.x.15989] 
//
[0.x.15990] 
[0.x.15991] 
[0.x.15992] 
[0.x.15993] 
//
[0.x.15994] 
[0.x.15995] 
//
[0.x.15996] 
[0.x.15997] 
[0.x.15998] 
[0.x.15999] 
[0.x.16000] 
//
[0.x.16001] 
[0.x.16002] 
[0.x.16003] 
[0.x.16004] 
[0.x.16005] 
[0.x.16006] 
[0.x.16007] 
[0.x.16008] 
//
// Next, we need to define the values of the conservative variables  [2.x.2237]  on this side of the face ( [2.x.2238] ) and on the opposite side ( [2.x.2239] ), for both  [2.x.2240]  and   [2.x.2241] . The "this side" values can be computed in exactly the same way as in the previous function, but note that the  [2.x.2242]  variable now is of type FEFaceValues or FESubfaceValues:
//
[0.x.16009] 
[0.x.16010] 
[0.x.16011] 
[0.x.16012] 
[0.x.16013] 
//
[0.x.16014] 
[0.x.16015] 
[0.x.16016] 
[0.x.16017] 
[0.x.16018] 
[0.x.16019] 
[0.x.16020] 
[0.x.16021] 
[0.x.16022] 
[0.x.16023] 
[0.x.16024] 
[0.x.16025] 
//
// Computing "opposite side" is a bit more complicated. If this is an internal face, we can compute it as above by simply using the independent variables from the neighbor:
//
[0.x.16026] 
[0.x.16027] 
[0.x.16028] 
[0.x.16029] 
[0.x.16030] 
[0.x.16031] 
[0.x.16032] 
[0.x.16033] 
[0.x.16034] 
[0.x.16035] 
[0.x.16036] 
[0.x.16037] 
[0.x.16038] 
[0.x.16039] 
[0.x.16040] 
//
// On the other hand, if this is an external boundary face, then the values of  [2.x.2243]  will be either functions of  [2.x.2244] , or they will be prescribed, depending on the kind of boundary condition imposed here.
//
// To start the evaluation, let us ensure that the boundary id specified for this boundary is one for which we actually have data in the parameters object. Next, we evaluate the function object for the inhomogeneity.  This is a bit tricky: a given boundary might have both prescribed and implicit values.  If a particular component is not prescribed, the values evaluate to zero and are ignored below.
//
// The rest is done by a function that actually knows the specifics of Euler equation boundary conditions. Note that since we are using fad variables here, sensitivities will be updated appropriately, a process that would otherwise be tremendously complicated.
//
[0.x.16041] 
[0.x.16042] 
[0.x.16043] 
[0.x.16044] 
[0.x.16045] 
[0.x.16046] 
//
[0.x.16047] 
[0.x.16048] 
[0.x.16049] 
[0.x.16050] 
//
[0.x.16051] 
[0.x.16052] 
[0.x.16053] 
[0.x.16054] 
[0.x.16055] 
[0.x.16056] 
[0.x.16057] 
[0.x.16058] 
//
//   Here we assume that boundary type, boundary normal vector and   boundary data values maintain the same during time advancing.
//
[0.x.16059] 
[0.x.16060] 
[0.x.16061] 
[0.x.16062] 
[0.x.16063] 
[0.x.16064] 
[0.x.16065] 
[0.x.16066] 
//
// Now that we have  [2.x.2245]  and  [2.x.2246] , we can go about computing the numerical flux function  [2.x.2247]  for each quadrature point. Before calling the function that does so, we also need to determine the Lax-Friedrich's stability parameter:
//
[0.x.16067] 
[0.x.16068] 
[0.x.16069] 
[0.x.16070] 
[0.x.16071] 
//
[0.x.16072] 
//
[0.x.16073] 
[0.x.16074] 
[0.x.16075] 
[0.x.16076] 
[0.x.16077] 
[0.x.16078] 
[0.x.16079] 
[0.x.16080] 
[0.x.16081] 
[0.x.16082] 
[0.x.16083] 
[0.x.16084] 
//
[0.x.16085] 
[0.x.16086] 
[0.x.16087] 
[0.x.16088] 
[0.x.16089] 
[0.x.16090] 
[0.x.16091] 
[0.x.16092] 
[0.x.16093] 
[0.x.16094] 
//
// Now assemble the face term in exactly the same way as for the cell contributions in the previous function. The only difference is that if this is an internal face, we also have to take into account the sensitivities of the residual contributions to the degrees of freedom on the neighboring cell:
//
[0.x.16095] 
[0.x.16096] 
[0.x.16097] 
[0.x.16098] 
[0.x.16099] 
//
[0.x.16100] 
[0.x.16101] 
[0.x.16102] 
[0.x.16103] 
//
[0.x.16104] 
[0.x.16105] 
[0.x.16106] 
[0.x.16107] 
[0.x.16108] 
[0.x.16109] 
//
[0.x.16110] 
[0.x.16111] 
[0.x.16112] 
//
[0.x.16113] 
[0.x.16114] 
[0.x.16115] 
[0.x.16116] 
[0.x.16117] 
[0.x.16118] 
[0.x.16119] 
[0.x.16120] 
//
[0.x.16121] 
[0.x.16122] 
[0.x.16123] 
//[2.x.2248] 
//
// Here, we actually solve the linear system, using either of Trilinos' Aztec or Amesos linear solvers. The result of the computation will be written into the argument vector passed to this function. The result is a pair of number of iterations and the final linear residual.
//
[0.x.16124] 
[0.x.16125] 
[0.x.16126] 
[0.x.16127] 
[0.x.16128] 
[0.x.16129] 
//
// If the parameter file specified that a direct solver shall be used, then we'll get here. The process is straightforward, since deal.II provides a wrapper class to the Amesos direct solver within Trilinos. All we have to do is to create a solver control object (which is just a dummy object here, since we won't perform any iterations), and then create the direct solver object. When actually doing the solve, note that we don't pass a preconditioner. That wouldn't make much sense for a direct solver anyway.  At the end we return the solver control statistics &mdash; which will tell that no iterations have been performed and that the final linear residual is zero, absent any better information that may be provided here:
//
[0.x.16130] 
[0.x.16131] 
[0.x.16132] 
[0.x.16133] 
[0.x.16134] 
[0.x.16135] 
//
[0.x.16136] 
//
[0.x.16137] 
[0.x.16138] 
//
// Likewise, if we are to use an iterative solver, we use Aztec's GMRES solver. We could use the Trilinos wrapper classes for iterative solvers and preconditioners here as well, but we choose to use an Aztec solver directly. For the given problem, Aztec's internal preconditioner implementations are superior over the ones deal.II has wrapper classes to, so we use ILU-T preconditioning within the AztecOO solver and set a bunch of options that can be changed from the parameter file.
//
// There are two more practicalities: Since we have built our right hand side and solution vector as deal.II Vector objects (as opposed to the matrix, which is a Trilinos object), we must hand the solvers Trilinos Epetra vectors.  Luckily, they support the concept of a 'view', so we just send in a pointer to our deal.II vectors. We have to provide an Epetra_Map for the vector that sets the parallel distribution, which is just a dummy object in serial. The easiest way is to ask the matrix for its map, and we're going to be ready for matrix-vector products with it.
//
// Secondly, the Aztec solver wants us to pass a Trilinos Epetra_CrsMatrix in, not the deal.II wrapper class itself. So we access to the actual Trilinos matrix in the Trilinos wrapper class by the command trilinos_matrix(). Trilinos wants the matrix to be non-constant, so we have to manually remove the constantness using a const_cast.
//
[0.x.16139] 
[0.x.16140] 
[0.x.16141] 
[0.x.16142] 
[0.x.16143] 
[0.x.16144] 
[0.x.16145] 
[0.x.16146] 
//
[0.x.16147] 
[0.x.16148] 
[0.x.16149] 
[0.x.16150] 
[0.x.16151] 
[0.x.16152] 
[0.x.16153] 
[0.x.16154] 
//
[0.x.16155] 
[0.x.16156] 
[0.x.16157] 
[0.x.16158] 
//
[0.x.16159] 
[0.x.16160] 
[0.x.16161] 
[0.x.16162] 
//
[0.x.16163] 
[0.x.16164] 
//
[0.x.16165] 
[0.x.16166] 
//
[0.x.16167] 
[0.x.16168] 
[0.x.16169] 
//
[0.x.16170] 
[0.x.16171] 
[0.x.16172] 
//[2.x.2249] 
//
// This function is real simple: We don't pretend that we know here what a good refinement indicator would be. Rather, we assume that the  [2.x.2250]  class would know about this, and so we simply defer to the respective function we've implemented there:
//
[0.x.16173] 
[0.x.16174] 
[0.x.16175] 
[0.x.16176] 
[0.x.16177] 
[0.x.16178] 
[0.x.16179] 
[0.x.16180] 
[0.x.16181] 
//
//  [2.x.2251] 
//
// Here, we use the refinement indicators computed before and refine the mesh. At the beginning, we loop over all cells and mark those that we think should be refined:
//
[0.x.16182] 
[0.x.16183] 
[0.x.16184] 
[0.x.16185] 
[0.x.16186] 
[0.x.16187] 
[0.x.16188] 
[0.x.16189] 
[0.x.16190] 
//
[0.x.16191] 
[0.x.16192] 
[0.x.16193] 
[0.x.16194] 
[0.x.16195] 
[0.x.16196] 
[0.x.16197] 
[0.x.16198] 
//
// Then we need to transfer the various solution vectors from the old to the new grid while we do the refinement. The SolutionTransfer class is our friend here; it has a fairly extensive documentation, including examples, so we won't comment much on the following code. The last three lines simply re-set the sizes of some other vectors to the now correct size:
//
[0.x.16199] 
[0.x.16200] 
//
[0.x.16201] 
[0.x.16202] 
//
[0.x.16203] 
//
[0.x.16204] 
[0.x.16205] 
//
[0.x.16206] 
//
[0.x.16207] 
[0.x.16208] 
//
[0.x.16209] 
[0.x.16210] 
[0.x.16211] 
//
[0.x.16212] 
[0.x.16213] 
[0.x.16214] 
[0.x.16215] 
[0.x.16216] 
//
[0.x.16217] 
//
[0.x.16218] 
[0.x.16219] 
//
[0.x.16220] 
[0.x.16221] 
//
[0.x.16222] 
[0.x.16223] 
[0.x.16224] 
[0.x.16225] 
//[2.x.2252] 
//
// This function now is rather straightforward. All the magic, including transforming data from conservative variables to physical ones has been abstracted and moved into the EulerEquations class so that it can be replaced in case we want to solve some other hyperbolic conservation law.
//
// Note that the number of the output file is determined by keeping a counter in the form of a static variable that is set to zero the first time we come to this function and is incremented by one at the end of each invocation.
//
[0.x.16226] 
[0.x.16227] 
[0.x.16228] 
[0.x.16229] 
[0.x.16230] 
//
[0.x.16231] 
[0.x.16232] 
//
[0.x.16233] 
[0.x.16234] 
[0.x.16235] 
[0.x.16236] 
//
[0.x.16237] 
//
[0.x.16238] 
//
[0.x.16239] 
[0.x.16240] 
[0.x.16241] 
[0.x.16242] 
[0.x.16243] 
//
[0.x.16244] 
[0.x.16245] 
//
//  [2.x.2253] 
//
// This function contains the top-level logic of this program: initialization, the time loop, and the inner Newton iteration.
//
// At the beginning, we read the mesh file specified by the parameter file, setup the DoFHandler and various vectors, and then interpolate the given initial conditions on this mesh. We then perform a number of mesh refinements, based on the initial conditions, to obtain a mesh that is already well adapted to the starting solution. At the end of this process, we output the initial solution.
//
[0.x.16246] 
[0.x.16247] 
[0.x.16248] 
[0.x.16249] 
[0.x.16250] 
[0.x.16251] 
//
[0.x.16252] 
[0.x.16253] 
//
[0.x.16254] 
[0.x.16255] 
//
[0.x.16256] 
[0.x.16257] 
//
// Size all of the fields.
//
[0.x.16258] 
[0.x.16259] 
[0.x.16260] 
[0.x.16261] 
//
[0.x.16262] 
//
[0.x.16263] 
[0.x.16264] 
[0.x.16265] 
[0.x.16266] 
[0.x.16267] 
//
[0.x.16268] 
[0.x.16269] 
[0.x.16270] 
[0.x.16271] 
//
[0.x.16272] 
[0.x.16273] 
//
[0.x.16274] 
//
[0.x.16275] 
[0.x.16276] 
[0.x.16277] 
[0.x.16278] 
[0.x.16279] 
[0.x.16280] 
//
[0.x.16281] 
//
// We then enter into the main time stepping loop. At the top we simply output some status information so one can keep track of where a computation is, as well as the header for a table that indicates progress of the nonlinear inner iteration:
//
[0.x.16282] 
//
[0.x.16283] 
[0.x.16284] 
//
[0.x.16285] 
[0.x.16286] 
[0.x.16287] 
[0.x.16288] 
[0.x.16289] 
[0.x.16290] 
[0.x.16291] 
[0.x.16292] 
[0.x.16293] 
//
[0.x.16294] 
[0.x.16295] 
//
// Then comes the inner Newton iteration to solve the nonlinear problem in each time step. The way it works is to reset matrix and right hand side to zero, then assemble the linear system. If the norm of the right hand side is small enough, then we declare that the Newton iteration has converged. Otherwise, we solve the linear system, update the current solution with the Newton increment, and output convergence information. At the end, we check that the number of Newton iterations is not beyond a limit of 10 -- if it is, it appears likely that iterations are diverging and further iterations would do no good. If that happens, we throw an exception that will be caught in  [2.x.2254]  with status information being displayed before the program aborts.
//
// Note that the way we write the AssertThrow macro below is by and large equivalent to writing something like <code>if (!(nonlin_iter  [2.x.2255]  10)) throw ExcMessage ("No convergence in nonlinear solver");</code>. The only significant difference is that AssertThrow also makes sure that the exception being thrown carries with it information about the location (file name and line number) where it was generated. This is not overly critical here, because there is only a single place where this sort of exception can happen; however, it is generally a very useful tool when one wants to find out where an error occurred.
//
[0.x.16296] 
[0.x.16297] 
[0.x.16298] 
[0.x.16299] 
[0.x.16300] 
//
[0.x.16301] 
[0.x.16302] 
//
[0.x.16303] 
[0.x.16304] 
[0.x.16305] 
[0.x.16306] 
[0.x.16307] 
[0.x.16308] 
[0.x.16309] 
[0.x.16310] 
[0.x.16311] 
//
[0.x.16312] 
[0.x.16313] 
//
[0.x.16314] 
//
[0.x.16315] 
[0.x.16316] 
[0.x.16317] 
[0.x.16318] 
[0.x.16319] 
//
[0.x.16320] 
[0.x.16321] 
[0.x.16322] 
[0.x.16323] 
//
// We only get to this point if the Newton iteration has converged, so do various post convergence tasks here:
//
// First, we update the time and produce graphical output if so desired. Then we update a predictor for the solution at the next time step by approximating  [2.x.2256]  to try and make adaptivity work better.  The idea is to try and refine ahead of a front, rather than stepping into a coarse set of elements and smearing the old_solution.  This simple time extrapolator does the job. With this, we then refine the mesh if so desired by the user, and finally continue on with the next time step:
//
[0.x.16324] 
//
[0.x.16325] 
[0.x.16326] 
[0.x.16327] 
[0.x.16328] 
[0.x.16329] 
[0.x.16330] 
[0.x.16331] 
//
[0.x.16332] 
[0.x.16333] 
//
[0.x.16334] 
//
[0.x.16335] 
[0.x.16336] 
[0.x.16337] 
[0.x.16338] 
[0.x.16339] 
//
[0.x.16340] 
[0.x.16341] 
//
[0.x.16342] 
[0.x.16343] 
[0.x.16344] 
[0.x.16345] 
[0.x.16346] 
//[2.x.2257] 
//
// The following ``main'' function is similar to previous examples and need not to be commented on. Note that the program aborts if no input file name is given on the command line.
//
[0.x.16347] 
[0.x.16348] 
[0.x.16349] 
[0.x.16350] 
[0.x.16351] 
[0.x.16352] 
//
[0.x.16353] 
[0.x.16354] 
[0.x.16355] 
[0.x.16356] 
[0.x.16357] 
//
[0.x.16358] 
[0.x.16359] 
//
[0.x.16360] 
[0.x.16361] 
[0.x.16362] 
[0.x.16363] 
[0.x.16364] 
[0.x.16365] 
[0.x.16366] 
[0.x.16367] 
[0.x.16368] 
[0.x.16369] 
[0.x.16370] 
[0.x.16371] 
[0.x.16372] 
[0.x.16373] 
[0.x.16374] 
[0.x.16375] 
[0.x.16376] 
[0.x.16377] 
[0.x.16378] 
[0.x.16379] 
[0.x.16380] 
[0.x.16381] 
[0.x.16382] 
[0.x.16383] 
[0.x.16384] 
[0.x.16385] 
[0.x.16386] 
[0.x.16387] 
//
[0.x.16388] 
[0.x.16389] 
[0.x.16390] 
[0.x.16391] 
[0.x.16392] 
[0.x.16393] 
[0.x.16394] 
[0.x.16395] 
[0.x.16396] 
[0.x.16397] 
[0.x.16398] 
[0.x.16399] 
[0.x.16400] 
[0.x.16401] 
[0.x.16402] 
[0.x.16403] 
//
[0.x.16404] 
[0.x.16405] 
[0.x.16406] 
//[2.x.2258] 
//
// The program starts with including a bunch of include files that we will use in the various parts of the program. Most of them have been discussed in previous tutorials already:
//
[0.x.16407] 
[0.x.16408] 
[0.x.16409] 
[0.x.16410] 
[0.x.16411] 
[0.x.16412] 
//
[0.x.16413] 
[0.x.16414] 
[0.x.16415] 
[0.x.16416] 
[0.x.16417] 
//
[0.x.16418] 
[0.x.16419] 
[0.x.16420] 
[0.x.16421] 
[0.x.16422] 
//
[0.x.16423] 
[0.x.16424] 
//
[0.x.16425] 
[0.x.16426] 
[0.x.16427] 
//
[0.x.16428] 
[0.x.16429] 
//
// And here are a few C++ standard header files that we will need:
//
[0.x.16430] 
[0.x.16431] 
[0.x.16432] 
[0.x.16433] 
//
// The last part of this preamble is to import everything in the dealii namespace into the one into which everything in this program will go:
//
[0.x.16434] 
[0.x.16435] 
[0.x.16436] 
//[2.x.2259] 
//
// First, let us define a bit of the boundary integral equation machinery.
//
// The following two functions are the actual calculations of the single and double layer potential kernels, that is  [2.x.2260]  and  [2.x.2261] . They are well defined only if the vector  [2.x.2262]  is different from zero.
//
[0.x.16437] 
[0.x.16438] 
[0.x.16439] 
[0.x.16440] 
[0.x.16441] 
[0.x.16442] 
[0.x.16443] 
[0.x.16444] 
[0.x.16445] 
//
[0.x.16446] 
[0.x.16447] 
//
[0.x.16448] 
[0.x.16449] 
[0.x.16450] 
[0.x.16451] 
[0.x.16452] 
//
[0.x.16453] 
[0.x.16454] 
[0.x.16455] 
[0.x.16456] 
[0.x.16457] 
[0.x.16458] 
[0.x.16459] 
[0.x.16460] 
[0.x.16461] 
//
[0.x.16462] 
[0.x.16463] 
[0.x.16464] 
[0.x.16465] 
[0.x.16466] 
[0.x.16467] 
//[2.x.2263] 
//
// The structure of a boundary element method code is very similar to the structure of a finite element code, and so the member functions of this class are like those of most of the other tutorial programs. In particular, by now you should be familiar with reading parameters from an external file, and with the splitting of the different tasks into different modules. The same applies to boundary element methods, and we won't comment too much on them, except on the differences.
//
[0.x.16468] 
[0.x.16469] 
[0.x.16470] 
[0.x.16471] 
[0.x.16472] 
[0.x.16473] 
//
[0.x.16474] 
//
[0.x.16475] 
[0.x.16476] 
//
[0.x.16477] 
//
[0.x.16478] 
//
// The only really different function that we find here is the assembly routine. We wrote this function in the most possible general way, in order to allow for easy generalization to higher order methods and to different fundamental solutions (e.g., Stokes or Maxwell).
//
// The most noticeable difference is the fact that the final matrix is full, and that we have a nested loop inside the usual loop on cells that visits all support points of the degrees of freedom.  Moreover, when the support point lies inside the cell which we are visiting, then the integral we perform becomes singular.
//
// The practical consequence is that we have two sets of quadrature formulas, finite element values and temporary storage, one for standard integration and one for the singular integration, which are used where necessary.
//
[0.x.16479] 
//
// There are two options for the solution of this problem. The first is to use a direct solver, and the second is to use an iterative solver. We opt for the second option.
//
// The matrix that we assemble is not symmetric, and we opt to use the GMRES method; however the construction of an efficient preconditioner for boundary element methods is not a trivial issue. Here we use a non preconditioned GMRES solver. The options for the iterative solver, such as the tolerance, the maximum number of iterations, are selected through the parameter file.
//
[0.x.16480] 
//
// Once we obtained the solution, we compute the  [2.x.2264]  error of the computed potential as well as the  [2.x.2265]  error of the approximation of the solid angle. The mesh we are using is an approximation of a smooth curve, therefore the computed diagonal matrix of fraction of angles or solid angles  [2.x.2266]  should be constantly equal to  [2.x.2267] . In this routine we output the error on the potential and the error in the approximation of the computed angle. Notice that the latter error is actually not the error in the computation of the angle, but a measure of how well we are approximating the sphere and the circle.
//
// Experimenting a little with the computation of the angles gives very accurate results for simpler geometries. To verify this you can comment out, in the read_domain() method, the tria.set_manifold(1, manifold) line, and check the alpha that is generated by the program. By removing this call, whenever the mesh is refined new nodes will be placed along the straight lines that made up the coarse mesh, rather than be pulled onto the surface that we really want to approximate. In the three dimensional case, the coarse grid of the sphere is obtained starting from a cube, and the obtained values of alphas are exactly  [2.x.2268]  on the nodes of the faces,  [2.x.2269]  on the nodes of the edges and  [2.x.2270]  on the 8 nodes of the vertices.
//
[0.x.16481] 
//
// Once we obtained a solution on the codimension one domain, we want to interpolate it to the rest of the space. This is done by performing again the convolution of the solution with the kernel in the compute_exterior_solution() function.
//
// We would like to plot the velocity variable which is the gradient of the potential solution. The potential solution is only known on the boundary, but we use the convolution with the fundamental solution to interpolate it on a standard dim dimensional continuous finite element space. The plot of the gradient of the extrapolated solution will give us the velocity we want.
//
// In addition to the solution on the exterior domain, we also output the solution on the domain's boundary in the output_results() function, of course.
//
[0.x.16482] 
//
[0.x.16483] 
//
// To allow for dimension independent programming, we specialize this single function to extract the singular quadrature formula needed to integrate the singular kernels in the interior of the cells.
//
[0.x.16484] 
[0.x.16485] 
[0.x.16486] 
//
// The usual deal.II classes can be used for boundary element methods by specifying the "codimension" of the problem. This is done by setting the optional second template arguments to Triangulation, FiniteElement and DoFHandler to the dimension of the embedding space. In our case we generate either 1 or 2 dimensional meshes embedded in 2 or 3 dimensional spaces.
//
// The optional argument by default is equal to the first argument, and produces the usual finite element classes that we saw in all previous examples.
//
// The class is constructed in a way to allow for arbitrary order of approximation of both the domain (through high order mapping) and the finite element space. The order of the finite element space and of the mapping can be selected in the constructor of the class.
//
[0.x.16487] 
[0.x.16488] 
[0.x.16489] 
[0.x.16490] 
//
// In BEM methods, the matrix that is generated is dense. Depending on the size of the problem, the final system might be solved by direct LU decomposition, or by iterative methods. In this example we use an unpreconditioned GMRES method. Building a preconditioner for BEM method is non trivial, and we don't treat this subject here.
//
[0.x.16491] 
[0.x.16492] 
//
// The next two variables will denote the solution  [2.x.2271]  as well as a vector that will hold the values of  [2.x.2272]  (the fraction of  [2.x.2273]  visible from a point  [2.x.2274] ) at the support points of our shape functions.
//
[0.x.16493] 
[0.x.16494] 
//
// The convergence table is used to output errors in the exact solution and in the computed alphas.
//
[0.x.16495] 
//
// The following variables are the ones that we fill through a parameter file.  The new objects that we use in this example are the  [2.x.2275]  object and the QuadratureSelector object.
//
// The  [2.x.2276]  class allows us to easily and quickly define new function objects via parameter files, with custom definitions which can be very complex (see the documentation of that class for all the available options).
//
// We will allocate the quadrature object using the QuadratureSelector class that allows us to generate quadrature formulas based on an identifying string and on the possible degree of the formula itself. We used this to allow custom selection of the quadrature formulas for the standard integration, and to define the order of the singular quadrature rule.
//
// We also define a couple of parameters which are used in case we wanted to extend the solution to the entire domain.
//
[0.x.16496] 
[0.x.16497] 
//
[0.x.16498] 
[0.x.16499] 
//
[0.x.16500] 
//
[0.x.16501] 
[0.x.16502] 
//
[0.x.16503] 
[0.x.16504] 
[0.x.16505] 
//[2.x.2277] 
//
// The constructor initializes the various object in much the same way as done in the finite element programs such as  [2.x.2278]  or  [2.x.2279] . The only new ingredient here is the ParsedFunction object, which needs, at construction time, the specification of the number of components.
//
// For the exact solution the number of vector components is one, and no action is required since one is the default value for a ParsedFunction object. The wind, however, requires dim components to be specified. Notice that when declaring entries in a parameter file for the expression of the  [2.x.2280]  we need to specify the number of components explicitly, since the function  [2.x.2281]  is static, and has no knowledge of the number of components.
//
[0.x.16506] 
[0.x.16507] 
[0.x.16508] 
[0.x.16509] 
[0.x.16510] 
[0.x.16511] 
[0.x.16512] 
[0.x.16513] 
[0.x.16514] 
[0.x.16515] 
[0.x.16516] 
[0.x.16517] 
[0.x.16518] 
//
[0.x.16519] 
[0.x.16520] 
[0.x.16521] 
[0.x.16522] 
[0.x.16523] 
[0.x.16524] 
//
[0.x.16525] 
//
[0.x.16526] 
[0.x.16527] 
[0.x.16528] 
[0.x.16529] 
[0.x.16530] 
[0.x.16531] 
[0.x.16532] 
//
[0.x.16533] 
[0.x.16534] 
[0.x.16535] 
[0.x.16536] 
[0.x.16537] 
[0.x.16538] 
[0.x.16539] 
[0.x.16540] 
[0.x.16541] 
[0.x.16542] 
[0.x.16543] 
//
// For both two and three dimensions, we set the default input data to be such that the solution is  [2.x.2282]  or  [2.x.2283] . The actually computed solution will have value zero at infinity. In this case, this coincide with the exact solution, and no additional corrections are needed, but you should be aware of the fact that we arbitrarily set  [2.x.2284] , and the exact solution we pass to the program needs to have the same value at infinity for the error to be computed correctly.
//
// The use of the  [2.x.2285]  object is pretty straight forward. The  [2.x.2286]  function takes an additional integer argument that specifies the number of components of the given function. Its default value is one. When the corresponding  [2.x.2287]  method is called, the calling object has to have the same number of components defined here, otherwise an exception is thrown.
//
// When declaring entries, we declare both 2 and three dimensional functions. However only the dim-dimensional one is ultimately parsed. This allows us to have only one parameter file for both 2 and 3 dimensional problems.
//
// Notice that from a mathematical point of view, the wind function on the boundary should satisfy the condition  [2.x.2288] , for the problem to have a solution. If this condition is not satisfied, then no solution can be found, and the solver will not converge.
//
[0.x.16544] 
[0.x.16545] 
[0.x.16546] 
[0.x.16547] 
[0.x.16548] 
[0.x.16549] 
//
[0.x.16550] 
[0.x.16551] 
[0.x.16552] 
[0.x.16553] 
[0.x.16554] 
[0.x.16555] 
//
[0.x.16556] 
[0.x.16557] 
[0.x.16558] 
[0.x.16559] 
[0.x.16560] 
[0.x.16561] 
//
[0.x.16562] 
[0.x.16563] 
[0.x.16564] 
[0.x.16565] 
[0.x.16566] 
[0.x.16567] 
//
// In the solver section, we set all SolverControl parameters. The object will then be fed to the GMRES solver in the solve_system() function.
//
[0.x.16568] 
[0.x.16569] 
[0.x.16570] 
//
// After declaring all these parameters to the ParameterHandler object, let's read an input file that will give the parameters their values. We then proceed to extract these values from the ParameterHandler object:
//
[0.x.16571] 
//
[0.x.16572] 
[0.x.16573] 
[0.x.16574] 
//
[0.x.16575] 
[0.x.16576] 
[0.x.16577] 
[0.x.16578] 
[0.x.16579] 
[0.x.16580] 
[0.x.16581] 
[0.x.16582] 
//
[0.x.16583] 
[0.x.16584] 
[0.x.16585] 
[0.x.16586] 
[0.x.16587] 
//
[0.x.16588] 
[0.x.16589] 
[0.x.16590] 
[0.x.16591] 
[0.x.16592] 
//
[0.x.16593] 
[0.x.16594] 
[0.x.16595] 
//
// Finally, here's another example of how to use parameter files in dimension independent programming.  If we wanted to switch off one of the two simulations, we could do this by setting the corresponding "Run 2d simulation" or "Run 3d simulation" flag to false:
//
[0.x.16596] 
[0.x.16597] 
[0.x.16598] 
//[2.x.2289] 
//
// A boundary element method triangulation is basically the same as a (dim-1) dimensional triangulation, with the difference that the vertices belong to a (dim) dimensional space.
//
// Some of the mesh formats supported in deal.II use by default three dimensional points to describe meshes. These are the formats which are compatible with the boundary element method capabilities of deal.II. In particular we can use either UCD or GMSH formats. In both cases, we have to be particularly careful with the orientation of the mesh, because, unlike in the standard finite element case, no reordering or compatibility check is performed here.  All meshes are considered as oriented, because they are embedded in a higher dimensional space. (See the documentation of the GridIn and of the Triangulation for further details on orientation of cells in a triangulation.) In our case, the normals to the mesh are external to both the circle in 2d or the sphere in 3d.
//
// The other detail that is required for appropriate refinement of the boundary element mesh is an accurate description of the manifold that the mesh approximates. We already saw this several times for the boundary of standard finite element meshes (for example in  [2.x.2290]  and  [2.x.2291] ), and here the principle and usage is the same, except that the SphericalManifold class takes an additional template parameter that specifies the embedding space dimension.
//
[0.x.16599] 
[0.x.16600] 
[0.x.16601] 
[0.x.16602] 
[0.x.16603] 
//
[0.x.16604] 
[0.x.16605] 
[0.x.16606] 
[0.x.16607] 
[0.x.16608] 
[0.x.16609] 
//
[0.x.16610] 
[0.x.16611] 
[0.x.16612] 
//
[0.x.16613] 
[0.x.16614] 
[0.x.16615] 
//
[0.x.16616] 
[0.x.16617] 
[0.x.16618] 
//
[0.x.16619] 
//
// The call to  [2.x.2292]  copies the manifold (via  [2.x.2293]  so we do not need to worry about invalid pointers to  [2.x.2294] :
//
[0.x.16620] 
[0.x.16621] 
//[2.x.2295] 
//
// This function globally refines the mesh, distributes degrees of freedom, and resizes matrices and vectors.
//
[0.x.16622] 
[0.x.16623] 
[0.x.16624] 
[0.x.16625] 
//
[0.x.16626] 
//
[0.x.16627] 
//
[0.x.16628] 
//
[0.x.16629] 
[0.x.16630] 
[0.x.16631] 
[0.x.16632] 
//[2.x.2296] 
//
// The following is the main function of this program, assembling the matrix that corresponds to the boundary integral equation.
//
[0.x.16633] 
[0.x.16634] 
[0.x.16635] 
//
// First we initialize an FEValues object with the quadrature formula for the integration of the kernel in non singular cells. This quadrature is selected with the parameter file, and needs to be quite precise, since the functions we are integrating are not polynomial functions.
//
[0.x.16636] 
[0.x.16637] 
[0.x.16638] 
[0.x.16639] 
[0.x.16640] 
//
[0.x.16641] 
//
[0.x.16642] 
[0.x.16643] 
//
[0.x.16644] 
[0.x.16645] 
//
// Unlike in finite element methods, if we use a collocation boundary element method, then in each assembly loop we only assemble the information that refers to the coupling between one degree of freedom (the degree associated with support point  [2.x.2297] ) and the current cell. This is done using a vector of fe.dofs_per_cell elements, which will then be distributed to the matrix in the global row  [2.x.2298] . The following object will hold this information:
//
[0.x.16646] 
//
// The index  [2.x.2299]  runs on the collocation points, which are the support points of the  [2.x.2300] th basis function, while  [2.x.2301]  runs on inner integration points.
//
// We construct a vector of support points which will be used in the local integrations:
//
[0.x.16647] 
[0.x.16648] 
[0.x.16649] 
[0.x.16650] 
//
// After doing so, we can start the integration loop over all cells, where we first initialize the FEValues object and get the values of  [2.x.2302]  at the quadrature points (this vector field should be constant, but it doesn't hurt to be more general):
//
[0.x.16651] 
[0.x.16652] 
[0.x.16653] 
[0.x.16654] 
//
[0.x.16655] 
[0.x.16656] 
[0.x.16657] 
//
// We then form the integral over the current cell for all degrees of freedom (note that this includes degrees of freedom not located on the current cell, a deviation from the usual finite element integrals). The integral that we need to perform is singular if one of the local degrees of freedom is the same as the support point  [2.x.2303] . A the beginning of the loop we therefore check whether this is the case, and we store which one is the singular index:
//
[0.x.16658] 
[0.x.16659] 
[0.x.16660] 
//
[0.x.16661] 
[0.x.16662] 
//
[0.x.16663] 
[0.x.16664] 
[0.x.16665] 
[0.x.16666] 
[0.x.16667] 
[0.x.16668] 
[0.x.16669] 
//
//   We then perform the integral. If the index  [2.x.2304]  is not one of   the local degrees of freedom, we simply have to add the single   layer terms to the right hand side, and the double layer terms   to the matrix:
//
[0.x.16670] 
[0.x.16671] 
[0.x.16672] 
[0.x.16673] 
[0.x.16674] 
[0.x.16675] 
[0.x.16676] 
//
[0.x.16677] 
//
[0.x.16678] 
[0.x.16679] 
//
[0.x.16680] 
//
[0.x.16681] 
[0.x.16682] 
[0.x.16683] 
[0.x.16684] 
[0.x.16685] 
[0.x.16686] 
[0.x.16687] 
//
//       Now we treat the more delicate case. If we are here, this       means that the cell that runs on the  [2.x.2305]  index contains       support_point[i]. In this case both the single and the       double layer potential are singular, and they require       special treatment.             Whenever the integration is performed with the singularity       inside the given cell, then a special quadrature formula is       used that allows one to integrate arbitrary functions       against a singular weight on the reference cell.             The correct quadrature formula is selected by the       get_singular_quadrature function, which is explained in       detail below.
//
[0.x.16688] 
[0.x.16689] 
//
[0.x.16690] 
[0.x.16691] 
//
[0.x.16692] 
[0.x.16693] 
[0.x.16694] 
[0.x.16695] 
[0.x.16696] 
[0.x.16697] 
//
[0.x.16698] 
//
[0.x.16699] 
[0.x.16700] 
//
[0.x.16701] 
[0.x.16702] 
[0.x.16703] 
[0.x.16704] 
//
[0.x.16705] 
//
[0.x.16706] 
[0.x.16707] 
[0.x.16708] 
[0.x.16709] 
[0.x.16710] 
[0.x.16711] 
[0.x.16712] 
[0.x.16713] 
//
[0.x.16714] 
[0.x.16715] 
//
[0.x.16716] 
[0.x.16717] 
[0.x.16718] 
[0.x.16719] 
[0.x.16720] 
[0.x.16721] 
[0.x.16722] 
[0.x.16723] 
[0.x.16724] 
[0.x.16725] 
//
//   Finally, we need to add the contributions of the current cell   to the global matrix.
//
[0.x.16726] 
[0.x.16727] 
[0.x.16728] 
[0.x.16729] 
//
// The second part of the integral operator is the term  [2.x.2306] . Since we use a collocation scheme,  [2.x.2307]  and the corresponding matrix is a diagonal one with entries equal to  [2.x.2308] .
//
// One quick way to compute this diagonal matrix of the solid angles, is to use the Neumann matrix itself. It is enough to multiply the matrix with a vector of elements all equal to -1, to get the diagonal matrix of the alpha angles, or solid angles (see the formula in the introduction for this). The result is then added back onto the system matrix object to yield the final form of the matrix:
//
[0.x.16730] 
[0.x.16731] 
//
[0.x.16732] 
[0.x.16733] 
[0.x.16734] 
[0.x.16735] 
[0.x.16736] 
//[2.x.2309] 
//
// The next function simply solves the linear system.
//
[0.x.16737] 
[0.x.16738] 
[0.x.16739] 
[0.x.16740] 
[0.x.16741] 
[0.x.16742] 
//[2.x.2310] 
//
// The computation of the errors is exactly the same in all other example programs, and we won't comment too much. Notice how the same methods that are used in the finite element methods can be used here.
//
[0.x.16743] 
[0.x.16744] 
[0.x.16745] 
[0.x.16746] 
[0.x.16747] 
[0.x.16748] 
[0.x.16749] 
[0.x.16750] 
[0.x.16751] 
[0.x.16752] 
[0.x.16753] 
[0.x.16754] 
[0.x.16755] 
[0.x.16756] 
[0.x.16757] 
//
// The error in the alpha vector can be computed directly using the  [2.x.2311]  function, since on each node, the value should be  [2.x.2312] . All errors are then output and appended to our ConvergenceTable object for later computation of convergence rates:
//
[0.x.16758] 
[0.x.16759] 
//
[0.x.16760] 
[0.x.16761] 
[0.x.16762] 
//
[0.x.16763] 
[0.x.16764] 
[0.x.16765] 
[0.x.16766] 
//
[0.x.16767] 
[0.x.16768] 
[0.x.16769] 
[0.x.16770] 
[0.x.16771] 
[0.x.16772] 
//
// Singular integration requires a careful selection of the quadrature rules. In particular the deal.II library provides quadrature rules which are tailored for logarithmic singularities (QGaussLog, QGaussLogR), as well as for 1/R singularities (QGaussOneOverR).
//
// Singular integration is typically obtained by constructing weighted quadrature formulas with singular weights, so that it is possible to write
//
// [1.x.62]
//
// where  [2.x.2313]  is a given singularity, and the weights and quadrature points  [2.x.2314]  are carefully selected to make the formula above an equality for a certain class of functions  [2.x.2315] .
//
// In all the finite element examples we have seen so far, the weight of the quadrature itself (namely, the function  [2.x.2316] ), was always constantly equal to 1.  For singular integration, we have two choices: we can use the definition above, factoring out the singularity from the integrand (i.e., integrating  [2.x.2317]  with the special quadrature rule), or we can ask the quadrature rule to "normalize" the weights  [2.x.2318]  with  [2.x.2319] :
//
// [1.x.63]
//
// We use this second option, through the  [2.x.2320]  parameter of both QGaussLogR and QGaussOneOverR.
//
// These integrals are somewhat delicate, especially in two dimensions, due to the transformation from the real to the reference cell, where the variable of integration is scaled with the determinant of the transformation.
//
// In two dimensions this process does not result only in a factor appearing as a constant factor on the entire integral, but also on an additional integral altogether that needs to be evaluated:
//
// [1.x.64]
//
// This process is taken care of by the constructor of the QGaussLogR class, which adds additional quadrature points and weights to take into consideration also the second part of the integral.
//
// A similar reasoning should be done in the three dimensional case, since the singular quadrature is tailored on the inverse of the radius  [2.x.2321]  in the reference cell, while our singular function lives in real space, however in the three dimensional case everything is simpler because the singularity scales linearly with the determinant of the transformation. This allows us to build the singular two dimensional quadrature rules only once and, reuse them over all cells.
//
// In the one dimensional singular integration this is not possible, since we need to know the scaling parameter for the quadrature, which is not known a priori. Here, the quadrature rule itself depends also on the size of the current cell. For this reason, it is necessary to create a new quadrature for each singular integration.
//
// The different quadrature rules are built inside the get_singular_quadrature, which is specialized for dim=2 and dim=3, and they are retrieved inside the assemble_system function. The index given as an argument is the index of the unit support point where the singularity is located.
//
[0.x.16773] 
[0.x.16774] 
[0.x.16775] 
[0.x.16776] 
[0.x.16777] 
[0.x.16778] 
[0.x.16779] 
//
[0.x.16780] 
[0.x.16781] 
[0.x.16782] 
[0.x.16783] 
[0.x.16784] 
[0.x.16785] 
[0.x.16786] 
[0.x.16787] 
//
[0.x.16788] 
[0.x.16789] 
[0.x.16790] 
[0.x.16791] 
[0.x.16792] 
[0.x.16793] 
[0.x.16794] 
//
[0.x.16795] 
[0.x.16796] 
[0.x.16797] 
//
[0.x.16798] 
[0.x.16799] 
[0.x.16800] 
[0.x.16801] 
[0.x.16802] 
[0.x.16803] 
//
//  [2.x.2322] 
//
// We'd like to also know something about the value of the potential  [2.x.2323]  in the exterior domain: after all our motivation to consider the boundary integral problem was that we wanted to know the velocity in the exterior domain!
//
// To this end, let us assume here that the boundary element domain is contained in the box  [2.x.2324] , and we extrapolate the actual solution inside this box using the convolution with the fundamental solution. The formula for this is given in the introduction.
//
// The reconstruction of the solution in the entire space is done on a continuous finite element grid of dimension dim. These are the usual ones, and we don't comment any further on them. At the end of the function, we output this exterior solution in, again, much the usual way.
//
[0.x.16804] 
[0.x.16805] 
[0.x.16806] 
[0.x.16807] 
[0.x.16808] 
//
[0.x.16809] 
[0.x.16810] 
[0.x.16811] 
//
[0.x.16812] 
[0.x.16813] 
[0.x.16814] 
//
[0.x.16815] 
[0.x.16816] 
[0.x.16817] 
[0.x.16818] 
[0.x.16819] 
//
[0.x.16820] 
//
[0.x.16821] 
//
[0.x.16822] 
[0.x.16823] 
[0.x.16824] 
//
[0.x.16825] 
[0.x.16826] 
[0.x.16827] 
[0.x.16828] 
//
[0.x.16829] 
[0.x.16830] 
[0.x.16831] 
//
[0.x.16832] 
[0.x.16833] 
//
[0.x.16834] 
[0.x.16835] 
//
[0.x.16836] 
//
[0.x.16837] 
[0.x.16838] 
[0.x.16839] 
[0.x.16840] 
[0.x.16841] 
[0.x.16842] 
//
[0.x.16843] 
[0.x.16844] 
[0.x.16845] 
[0.x.16846] 
//
[0.x.16847] 
[0.x.16848] 
[0.x.16849] 
[0.x.16850] 
[0.x.16851] 
[0.x.16852] 
[0.x.16853] 
//
[0.x.16854] 
//
[0.x.16855] 
[0.x.16856] 
[0.x.16857] 
//
[0.x.16858] 
[0.x.16859] 
//
[0.x.16860] 
[0.x.16861] 
//[2.x.2325] 
//
// Outputting the results of our computations is a rather mechanical tasks. All the components of this function have been discussed before.
//
[0.x.16862] 
[0.x.16863] 
[0.x.16864] 
[0.x.16865] 
//
[0.x.16866] 
[0.x.16867] 
[0.x.16868] 
[0.x.16869] 
[0.x.16870] 
[0.x.16871] 
[0.x.16872] 
[0.x.16873] 
//
[0.x.16874] 
[0.x.16875] 
[0.x.16876] 
//
[0.x.16877] 
//
[0.x.16878] 
[0.x.16879] 
[0.x.16880] 
[0.x.16881] 
//
[0.x.16882] 
[0.x.16883] 
//
[0.x.16884] 
[0.x.16885] 
[0.x.16886] 
[0.x.16887] 
[0.x.16888] 
[0.x.16889] 
[0.x.16890] 
[0.x.16891] 
//[2.x.2326] 
//
// This is the main function. It should be self explanatory in its briefness:
//
[0.x.16892] 
[0.x.16893] 
[0.x.16894] 
[0.x.16895] 
//
[0.x.16896] 
[0.x.16897] 
[0.x.16898] 
[0.x.16899] 
[0.x.16900] 
[0.x.16901] 
//
[0.x.16902] 
//
[0.x.16903] 
[0.x.16904] 
[0.x.16905] 
[0.x.16906] 
[0.x.16907] 
[0.x.16908] 
[0.x.16909] 
[0.x.16910] 
//
[0.x.16911] 
[0.x.16912] 
[0.x.16913] 
[0.x.16914] 
//[2.x.2327] 
//
// This is the main function of this program. It is exactly like all previous tutorial programs:
//
[0.x.16915] 
[0.x.16916] 
[0.x.16917] 
[0.x.16918] 
[0.x.16919] 
//
[0.x.16920] 
[0.x.16921] 
//
[0.x.16922] 
[0.x.16923] 
[0.x.16924] 
//
[0.x.16925] 
[0.x.16926] 
[0.x.16927] 
[0.x.16928] 
[0.x.16929] 
[0.x.16930] 
[0.x.16931] 
[0.x.16932] 
[0.x.16933] 
[0.x.16934] 
[0.x.16935] 
[0.x.16936] 
[0.x.16937] 
[0.x.16938] 
//
[0.x.16939] 
[0.x.16940] 
[0.x.16941] 
[0.x.16942] 
[0.x.16943] 
[0.x.16944] 
[0.x.16945] 
[0.x.16946] 
[0.x.16947] 
[0.x.16948] 
[0.x.16949] 
[0.x.16950] 
[0.x.16951] 
[0.x.16952] 
//
[0.x.16953] 
[0.x.16954] 
[0.x.16955] 
[0.x.16956] 
[0.x.16957] 
[0.x.16958] 
[0.x.16959] 
[0.x.16960] 
[0.x.16961] 
[0.x.16962] 
[0.x.16963] 
[0.x.16964] 
[0.x.16965] 
[0.x.16966] 
[0.x.16967] 
[0.x.16968] 
//
[0.x.16969] 
[0.x.16970] 
[0.x.16971] 
//[2.x.2328] 
//
// We start by including all the necessary deal.II header files and some C++ related ones. Each one of them has been discussed in previous tutorial programs, so we will not get into details here.
//
[0.x.16972] 
[0.x.16973] 
[0.x.16974] 
[0.x.16975] 
[0.x.16976] 
[0.x.16977] 
[0.x.16978] 
[0.x.16979] 
[0.x.16980] 
[0.x.16981] 
//
[0.x.16982] 
[0.x.16983] 
[0.x.16984] 
[0.x.16985] 
[0.x.16986] 
[0.x.16987] 
[0.x.16988] 
[0.x.16989] 
[0.x.16990] 
//
[0.x.16991] 
[0.x.16992] 
[0.x.16993] 
[0.x.16994] 
//
[0.x.16995] 
[0.x.16996] 
[0.x.16997] 
//
[0.x.16998] 
[0.x.16999] 
[0.x.17000] 
[0.x.17001] 
//
[0.x.17002] 
[0.x.17003] 
[0.x.17004] 
//
[0.x.17005] 
[0.x.17006] 
[0.x.17007] 
//
// Finally this is as in all previous programs:
//
[0.x.17008] 
[0.x.17009] 
[0.x.17010] 
//[2.x.2329] 
//
// Since our method has several parameters that can be fine-tuned we put them into an external file, so that they can be determined at run-time.
//
// This includes, in particular, the formulation of the equation for the auxiliary variable  [2.x.2330] , for which we declare an  [2.x.2331] . Next, we declare a class that is going to read and store all the parameters that our program needs to run.
//
[0.x.17011] 
[0.x.17012] 
[0.x.17013] 
[0.x.17014] 
[0.x.17015] 
[0.x.17016] 
[0.x.17017] 
//
[0.x.17018] 
[0.x.17019] 
[0.x.17020] 
[0.x.17021] 
//
[0.x.17022] 
//
[0.x.17023] 
//
[0.x.17024] 
[0.x.17025] 
[0.x.17026] 
//
[0.x.17027] 
//
[0.x.17028] 
//
[0.x.17029] 
//
[0.x.17030] 
[0.x.17031] 
[0.x.17032] 
[0.x.17033] 
[0.x.17034] 
[0.x.17035] 
//
[0.x.17036] 
[0.x.17037] 
//
[0.x.17038] 
[0.x.17039] 
[0.x.17040] 
//
// In the constructor of this class we declare all the parameters. The details of how this works have been discussed elsewhere, for example in  [2.x.2332] .
//
[0.x.17041] 
[0.x.17042] 
[0.x.17043] 
[0.x.17044] 
[0.x.17045] 
[0.x.17046] 
[0.x.17047] 
[0.x.17048] 
[0.x.17049] 
[0.x.17050] 
[0.x.17051] 
[0.x.17052] 
[0.x.17053] 
[0.x.17054] 
[0.x.17055] 
[0.x.17056] 
[0.x.17057] 
[0.x.17058] 
[0.x.17059] 
[0.x.17060] 
[0.x.17061] 
[0.x.17062] 
[0.x.17063] 
[0.x.17064] 
[0.x.17065] 
[0.x.17066] 
[0.x.17067] 
[0.x.17068] 
[0.x.17069] 
[0.x.17070] 
[0.x.17071] 
[0.x.17072] 
[0.x.17073] 
[0.x.17074] 
[0.x.17075] 
[0.x.17076] 
[0.x.17077] 
[0.x.17078] 
//
[0.x.17079] 
[0.x.17080] 
[0.x.17081] 
[0.x.17082] 
[0.x.17083] 
[0.x.17084] 
[0.x.17085] 
[0.x.17086] 
//
[0.x.17087] 
[0.x.17088] 
[0.x.17089] 
[0.x.17090] 
[0.x.17091] 
[0.x.17092] 
[0.x.17093] 
[0.x.17094] 
[0.x.17095] 
[0.x.17096] 
[0.x.17097] 
[0.x.17098] 
//
[0.x.17099] 
[0.x.17100] 
[0.x.17101] 
[0.x.17102] 
[0.x.17103] 
[0.x.17104] 
[0.x.17105] 
[0.x.17106] 
[0.x.17107] 
[0.x.17108] 
[0.x.17109] 
[0.x.17110] 
[0.x.17111] 
[0.x.17112] 
[0.x.17113] 
[0.x.17114] 
[0.x.17115] 
[0.x.17116] 
[0.x.17117] 
[0.x.17118] 
[0.x.17119] 
[0.x.17120] 
[0.x.17121] 
[0.x.17122] 
[0.x.17123] 
[0.x.17124] 
[0.x.17125] 
[0.x.17126] 
[0.x.17127] 
[0.x.17128] 
[0.x.17129] 
//
[0.x.17130] 
[0.x.17131] 
[0.x.17132] 
[0.x.17133] 
[0.x.17134] 
//
[0.x.17135] 
[0.x.17136] 
[0.x.17137] 
[0.x.17138] 
[0.x.17139] 
[0.x.17140] 
//
[0.x.17141] 
[0.x.17142] 
[0.x.17143] 
[0.x.17144] 
//
[0.x.17145] 
//
[0.x.17146] 
[0.x.17147] 
[0.x.17148] 
[0.x.17149] 
//
[0.x.17150] 
[0.x.17151] 
[0.x.17152] 
[0.x.17153] 
[0.x.17154] 
[0.x.17155] 
[0.x.17156] 
//
[0.x.17157] 
[0.x.17158] 
[0.x.17159] 
[0.x.17160] 
[0.x.17161] 
//
[0.x.17162] 
[0.x.17163] 
[0.x.17164] 
[0.x.17165] 
[0.x.17166] 
[0.x.17167] 
//
[0.x.17168] 
[0.x.17169] 
[0.x.17170] 
[0.x.17171] 
[0.x.17172] 
[0.x.17173] 
[0.x.17174] 
[0.x.17175] 
[0.x.17176] 
[0.x.17177] 
//
[0.x.17178] 
//
[0.x.17179] 
[0.x.17180] 
[0.x.17181] 
//
//  [2.x.2333] 
//
// In the next namespace, we declare the initial and boundary conditions:
//
[0.x.17182] 
[0.x.17183] 
//
// As we have chosen a completely decoupled formulation, we will not take advantage of deal.II's capabilities to handle vector valued problems. We do, however, want to use an interface for the equation data that is somehow dimension independent. To be able to do that, our functions should be able to know on which spatial component we are currently working, and we should be able to have a common interface to do that. The following class is an attempt in that direction.
//
[0.x.17184] 
[0.x.17185] 
[0.x.17186] 
[0.x.17187] 
[0.x.17188] 
[0.x.17189] 
//
[0.x.17190] 
[0.x.17191] 
[0.x.17192] 
//
[0.x.17193] 
[0.x.17194] 
[0.x.17195] 
[0.x.17196] 
[0.x.17197] 
[0.x.17198] 
//
[0.x.17199] 
[0.x.17200] 
[0.x.17201] 
[0.x.17202] 
[0.x.17203] 
[0.x.17204] 
//
// With this class defined, we declare classes that describe the boundary conditions for velocity and pressure:
//
[0.x.17205] 
[0.x.17206] 
[0.x.17207] 
[0.x.17208] 
[0.x.17209] 
//
[0.x.17210] 
[0.x.17211] 
//
[0.x.17212] 
[0.x.17213] 
[0.x.17214] 
[0.x.17215] 
//
[0.x.17216] 
[0.x.17217] 
[0.x.17218] 
[0.x.17219] 
//
[0.x.17220] 
[0.x.17221] 
[0.x.17222] 
[0.x.17223] 
[0.x.17224] 
[0.x.17225] 
[0.x.17226] 
[0.x.17227] 
[0.x.17228] 
[0.x.17229] 
[0.x.17230] 
//
[0.x.17231] 
[0.x.17232] 
[0.x.17233] 
[0.x.17234] 
[0.x.17235] 
[0.x.17236] 
[0.x.17237] 
[0.x.17238] 
[0.x.17239] 
[0.x.17240] 
[0.x.17241] 
[0.x.17242] 
//
[0.x.17243] 
[0.x.17244] 
[0.x.17245] 
[0.x.17246] 
[0.x.17247] 
//
[0.x.17248] 
[0.x.17249] 
//
[0.x.17250] 
[0.x.17251] 
[0.x.17252] 
[0.x.17253] 
//
[0.x.17254] 
[0.x.17255] 
[0.x.17256] 
[0.x.17257] 
//
[0.x.17258] 
[0.x.17259] 
[0.x.17260] 
[0.x.17261] 
[0.x.17262] 
[0.x.17263] 
[0.x.17264] 
[0.x.17265] 
//
[0.x.17266] 
[0.x.17267] 
[0.x.17268] 
[0.x.17269] 
[0.x.17270] 
[0.x.17271] 
[0.x.17272] 
[0.x.17273] 
[0.x.17274] 
[0.x.17275] 
[0.x.17276] 
[0.x.17277] 
[0.x.17278] 
[0.x.17279] 
//
//  [2.x.2334] 
//
// Now for the main class of the program. It implements the various versions of the projection method for Navier-Stokes equations. The names for all the methods and member variables should be self-explanatory, taking into account the implementation details given in the introduction.
//
[0.x.17280] 
[0.x.17281] 
[0.x.17282] 
[0.x.17283] 
[0.x.17284] 
//
[0.x.17285] 
//
[0.x.17286] 
[0.x.17287] 
//
[0.x.17288] 
[0.x.17289] 
[0.x.17290] 
[0.x.17291] 
[0.x.17292] 
//
[0.x.17293] 
[0.x.17294] 
[0.x.17295] 
//
[0.x.17296] 
//
[0.x.17297] 
[0.x.17298] 
//
[0.x.17299] 
[0.x.17300] 
//
[0.x.17301] 
[0.x.17302] 
//
[0.x.17303] 
[0.x.17304] 
[0.x.17305] 
//
[0.x.17306] 
[0.x.17307] 
[0.x.17308] 
[0.x.17309] 
[0.x.17310] 
[0.x.17311] 
[0.x.17312] 
[0.x.17313] 
[0.x.17314] 
//
[0.x.17315] 
[0.x.17316] 
[0.x.17317] 
[0.x.17318] 
[0.x.17319] 
[0.x.17320] 
[0.x.17321] 
[0.x.17322] 
[0.x.17323] 
[0.x.17324] 
[0.x.17325] 
//
[0.x.17326] 
[0.x.17327] 
[0.x.17328] 
[0.x.17329] 
//
[0.x.17330] 
[0.x.17331] 
[0.x.17332] 
[0.x.17333] 
[0.x.17334] 
[0.x.17335] 
//
[0.x.17336] 
//
[0.x.17337] 
//
[0.x.17338] 
//
[0.x.17339] 
//
[0.x.17340] 
//
[0.x.17341] 
//
[0.x.17342] 
[0.x.17343] 
[0.x.17344] 
[0.x.17345] 
[0.x.17346] 
[0.x.17347] 
[0.x.17348] 
//
[0.x.17349] 
//
[0.x.17350] 
//
// The next few structures and functions are for doing various things in parallel. They follow the scheme laid out in  [2.x.2335] , using the WorkStream class. As explained there, this requires us to declare two structures for each of the assemblers, a per-task data and a scratch data structure. These are then handed over to functions that assemble local contributions and that copy these local contributions to the global objects.
//
// One of the things that are specific to this program is that we don't just have a single DoFHandler object that represents both the velocities and the pressure, but we use individual DoFHandler objects for these two kinds of variables. We pay for this optimization when we want to assemble terms that involve both variables, such as the divergence of the velocity and the gradient of the pressure, times the respective test functions. When doing so, we can't just anymore use a single FEValues object, but rather we need two, and they need to be initialized with cell iterators that point to the same cell in the triangulation but different DoFHandlers.
//
// To do this in practice, we declare a "synchronous" iterator -- an object that internally consists of several (in our case two) iterators, and each time the synchronous iteration is moved forward one step, each of the iterators stored internally is moved forward one step as well, thereby always staying in sync. As it so happens, there is a deal.II class that facilitates this sort of thing. (What is important here is to know that two DoFHandler objects built on the same triangulation will walk over the cells of the triangulation in the same order.)
//
[0.x.17351] 
[0.x.17352] 
[0.x.17353] 
//
[0.x.17354] 
//
[0.x.17355] 
//
[0.x.17356] 
[0.x.17357] 
[0.x.17358] 
[0.x.17359] 
[0.x.17360] 
[0.x.17361] 
[0.x.17362] 
[0.x.17363] 
//
[0.x.17364] 
[0.x.17365] 
[0.x.17366] 
[0.x.17367] 
[0.x.17368] 
[0.x.17369] 
[0.x.17370] 
[0.x.17371] 
[0.x.17372] 
[0.x.17373] 
[0.x.17374] 
//
[0.x.17375] 
[0.x.17376] 
[0.x.17377] 
[0.x.17378] 
[0.x.17379] 
[0.x.17380] 
[0.x.17381] 
[0.x.17382] 
[0.x.17383] 
[0.x.17384] 
[0.x.17385] 
[0.x.17386] 
[0.x.17387] 
[0.x.17388] 
[0.x.17389] 
[0.x.17390] 
[0.x.17391] 
[0.x.17392] 
[0.x.17393] 
[0.x.17394] 
[0.x.17395] 
[0.x.17396] 
[0.x.17397] 
[0.x.17398] 
//
[0.x.17399] 
[0.x.17400] 
[0.x.17401] 
//
[0.x.17402] 
//
// The same general layout also applies to the following classes and functions implementing the assembly of the advection term:
//
[0.x.17403] 
//
[0.x.17404] 
[0.x.17405] 
[0.x.17406] 
[0.x.17407] 
[0.x.17408] 
[0.x.17409] 
[0.x.17410] 
[0.x.17411] 
[0.x.17412] 
//
[0.x.17413] 
[0.x.17414] 
[0.x.17415] 
[0.x.17416] 
[0.x.17417] 
[0.x.17418] 
[0.x.17419] 
[0.x.17420] 
[0.x.17421] 
[0.x.17422] 
[0.x.17423] 
[0.x.17424] 
[0.x.17425] 
[0.x.17426] 
[0.x.17427] 
[0.x.17428] 
[0.x.17429] 
[0.x.17430] 
//
[0.x.17431] 
[0.x.17432] 
[0.x.17433] 
[0.x.17434] 
[0.x.17435] 
[0.x.17436] 
[0.x.17437] 
[0.x.17438] 
[0.x.17439] 
[0.x.17440] 
[0.x.17441] 
//
[0.x.17442] 
[0.x.17443] 
[0.x.17444] 
[0.x.17445] 
//
[0.x.17446] 
//
// The final few functions implement the diffusion solve as well as postprocessing the output, including computing the curl of the velocity:
//
[0.x.17447] 
//
[0.x.17448] 
//
[0.x.17449] 
[0.x.17450] 
//
//  [2.x.2336] 
//
// In the constructor, we just read all the data from the  [2.x.2337]  object that is passed as an argument, verify that the data we read is reasonable and, finally, create the triangulation and load the initial data.
//
[0.x.17451] 
[0.x.17452] 
[0.x.17453] 
[0.x.17454] 
[0.x.17455] 
[0.x.17456] 
[0.x.17457] 
[0.x.17458] 
[0.x.17459] 
[0.x.17460] 
[0.x.17461] 
[0.x.17462] 
[0.x.17463] 
[0.x.17464] 
[0.x.17465] 
[0.x.17466] 
[0.x.17467] 
[0.x.17468] 
[0.x.17469] 
[0.x.17470] 
[0.x.17471] 
[0.x.17472] 
[0.x.17473] 
[0.x.17474] 
[0.x.17475] 
[0.x.17476] 
[0.x.17477] 
[0.x.17478] 
//
[0.x.17479] 
//
[0.x.17480] 
[0.x.17481] 
[0.x.17482] 
//[2.x.2338] 
//
// The method that creates the triangulation and refines it the needed number of times. After creating the triangulation, it creates the mesh dependent data, i.e. it distributes degrees of freedom and renumbers them, and initializes the matrices and vectors that we will use.
//
[0.x.17483] 
[0.x.17484] 
[0.x.17485] 
[0.x.17486] 
[0.x.17487] 
[0.x.17488] 
//
[0.x.17489] 
[0.x.17490] 
[0.x.17491] 
[0.x.17492] 
[0.x.17493] 
[0.x.17494] 
//
[0.x.17495] 
[0.x.17496] 
[0.x.17497] 
[0.x.17498] 
//
[0.x.17499] 
//
[0.x.17500] 
[0.x.17501] 
[0.x.17502] 
[0.x.17503] 
//
[0.x.17504] 
[0.x.17505] 
[0.x.17506] 
//
[0.x.17507] 
[0.x.17508] 
[0.x.17509] 
[0.x.17510] 
[0.x.17511] 
[0.x.17512] 
[0.x.17513] 
[0.x.17514] 
[0.x.17515] 
[0.x.17516] 
[0.x.17517] 
[0.x.17518] 
[0.x.17519] 
[0.x.17520] 
//
[0.x.17521] 
[0.x.17522] 
[0.x.17523] 
[0.x.17524] 
[0.x.17525] 
[0.x.17526] 
[0.x.17527] 
//[2.x.2339] 
//
// This method creates the constant matrices and loads the initial data
//
[0.x.17528] 
[0.x.17529] 
[0.x.17530] 
[0.x.17531] 
[0.x.17532] 
[0.x.17533] 
//
[0.x.17534] 
[0.x.17535] 
[0.x.17536] 
[0.x.17537] 
[0.x.17538] 
[0.x.17539] 
[0.x.17540] 
[0.x.17541] 
[0.x.17542] 
[0.x.17543] 
[0.x.17544] 
[0.x.17545] 
[0.x.17546] 
[0.x.17547] 
[0.x.17548] 
[0.x.17549] 
[0.x.17550] 
//[2.x.2340] 
//
// In this set of methods we initialize the sparsity patterns, the constraints (if any) and assemble the matrices that do not depend on the timestep  [2.x.2341] . Note that for the Laplace and mass matrices, we can use functions in the library that do this. Because the expensive operations of this function -- creating the two matrices -- are entirely independent, we could in principle mark them as tasks that can be worked on in %parallel using the  [2.x.2342]  functions. We won't do that here since these functions internally already are parallelized, and in particular because the current function is only called once per program run and so does not incur a cost in each time step. The necessary modifications would be quite straightforward, however.
//
[0.x.17551] 
[0.x.17552] 
[0.x.17553] 
[0.x.17554] 
[0.x.17555] 
[0.x.17556] 
[0.x.17557] 
[0.x.17558] 
[0.x.17559] 
[0.x.17560] 
[0.x.17561] 
[0.x.17562] 
[0.x.17563] 
[0.x.17564] 
[0.x.17565] 
//
[0.x.17566] 
[0.x.17567] 
[0.x.17568] 
[0.x.17569] 
[0.x.17570] 
[0.x.17571] 
[0.x.17572] 
//
// The initialization of the matrices that act on the pressure space is similar to the ones that act on the velocity space.
//
[0.x.17573] 
[0.x.17574] 
[0.x.17575] 
[0.x.17576] 
[0.x.17577] 
[0.x.17578] 
[0.x.17579] 
[0.x.17580] 
[0.x.17581] 
//
[0.x.17582] 
[0.x.17583] 
[0.x.17584] 
//
[0.x.17585] 
[0.x.17586] 
[0.x.17587] 
[0.x.17588] 
[0.x.17589] 
[0.x.17590] 
[0.x.17591] 
//
// For the gradient operator, we start by initializing the sparsity pattern and compressing it. It is important to notice here that the gradient operator acts from the pressure space into the velocity space, so we have to deal with two different finite element spaces. To keep the loops synchronized, we use the alias that we have defined before, namely  [2.x.2343] .
//
[0.x.17592] 
[0.x.17593] 
[0.x.17594] 
[0.x.17595] 
[0.x.17596] 
[0.x.17597] 
[0.x.17598] 
[0.x.17599] 
[0.x.17600] 
[0.x.17601] 
[0.x.17602] 
//
[0.x.17603] 
[0.x.17604] 
[0.x.17605] 
[0.x.17606] 
[0.x.17607] 
[0.x.17608] 
[0.x.17609] 
[0.x.17610] 
//
[0.x.17611] 
[0.x.17612] 
[0.x.17613] 
[0.x.17614] 
[0.x.17615] 
[0.x.17616] 
[0.x.17617] 
[0.x.17618] 
[0.x.17619] 
[0.x.17620] 
[0.x.17621] 
[0.x.17622] 
[0.x.17623] 
[0.x.17624] 
[0.x.17625] 
[0.x.17626] 
//
[0.x.17627] 
[0.x.17628] 
[0.x.17629] 
[0.x.17630] 
[0.x.17631] 
[0.x.17632] 
[0.x.17633] 
[0.x.17634] 
//
[0.x.17635] 
[0.x.17636] 
//
[0.x.17637] 
[0.x.17638] 
[0.x.17639] 
[0.x.17640] 
[0.x.17641] 
[0.x.17642] 
[0.x.17643] 
[0.x.17644] 
[0.x.17645] 
[0.x.17646] 
[0.x.17647] 
//
[0.x.17648] 
[0.x.17649] 
[0.x.17650] 
[0.x.17651] 
[0.x.17652] 
[0.x.17653] 
[0.x.17654] 
[0.x.17655] 
[0.x.17656] 
[0.x.17657] 
//[2.x.2344] 
//
// This is the time marching function, which starting at  [2.x.2345]  advances in time using the projection method with time step  [2.x.2346]  until  [2.x.2347] .
//
// Its second parameter,  [2.x.2348]  indicates whether the function should output information what it is doing at any given moment: for example, it will say whether we are working on the diffusion, projection substep; updating preconditioners etc. Rather than implementing this output using code like [1.x.65] we use the ConditionalOStream class to do that for us. That class takes an output stream and a condition that indicates whether the things you pass to it should be passed through to the given output stream, or should just be ignored. This way, above code simply becomes [1.x.66] and does the right thing in either case.
//
[0.x.17658] 
[0.x.17659] 
[0.x.17660] 
[0.x.17661] 
[0.x.17662] 
//
[0.x.17663] 
[0.x.17664] 
[0.x.17665] 
[0.x.17666] 
[0.x.17667] 
[0.x.17668] 
[0.x.17669] 
[0.x.17670] 
[0.x.17671] 
[0.x.17672] 
[0.x.17673] 
[0.x.17674] 
//
[0.x.17675] 
[0.x.17676] 
[0.x.17677] 
[0.x.17678] 
[0.x.17679] 
[0.x.17680] 
[0.x.17681] 
[0.x.17682] 
[0.x.17683] 
[0.x.17684] 
[0.x.17685] 
[0.x.17686] 
[0.x.17687] 
[0.x.17688] 
//
[0.x.17689] 
[0.x.17690] 
[0.x.17691] 
[0.x.17692] 
[0.x.17693] 
[0.x.17694] 
[0.x.17695] 
[0.x.17696] 
[0.x.17697] 
//[2.x.2349] 
//
// The implementation of a diffusion step. Note that the expensive operation is the diffusion solve at the end of the function, which we have to do once for each velocity component. To accelerate things a bit, we allow to do this in %parallel, using the  [2.x.2350]  function which makes sure that the  [2.x.2351]  solves are all taken care of and are scheduled to available processors: if your machine has more than one processor core and no other parts of this program are using resources currently, then the diffusion solves will run in %parallel. On the other hand, if your system has only one processor core then running things in %parallel would be inefficient (since it leads, for example, to cache congestion) and things will be executed sequentially.
//
[0.x.17698] 
[0.x.17699] 
[0.x.17700] 
[0.x.17701] 
[0.x.17702] 
//
[0.x.17703] 
//
[0.x.17704] 
[0.x.17705] 
[0.x.17706] 
[0.x.17707] 
[0.x.17708] 
[0.x.17709] 
//
[0.x.17710] 
[0.x.17711] 
//
[0.x.17712] 
[0.x.17713] 
//
[0.x.17714] 
[0.x.17715] 
[0.x.17716] 
[0.x.17717] 
[0.x.17718] 
[0.x.17719] 
[0.x.17720] 
[0.x.17721] 
[0.x.17722] 
[0.x.17723] 
[0.x.17724] 
[0.x.17725] 
[0.x.17726] 
[0.x.17727] 
[0.x.17728] 
[0.x.17729] 
[0.x.17730] 
[0.x.17731] 
[0.x.17732] 
[0.x.17733] 
[0.x.17734] 
[0.x.17735] 
[0.x.17736] 
[0.x.17737] 
[0.x.17738] 
[0.x.17739] 
[0.x.17740] 
[0.x.17741] 
[0.x.17742] 
[0.x.17743] 
[0.x.17744] 
[0.x.17745] 
[0.x.17746] 
[0.x.17747] 
[0.x.17748] 
[0.x.17749] 
[0.x.17750] 
[0.x.17751] 
[0.x.17752] 
[0.x.17753] 
[0.x.17754] 
[0.x.17755] 
[0.x.17756] 
//
[0.x.17757] 
[0.x.17758] 
[0.x.17759] 
[0.x.17760] 
[0.x.17761] 
[0.x.17762] 
[0.x.17763] 
[0.x.17764] 
[0.x.17765] 
[0.x.17766] 
[0.x.17767] 
[0.x.17768] 
//
[0.x.17769] 
[0.x.17770] 
[0.x.17771] 
[0.x.17772] 
[0.x.17773] 
[0.x.17774] 
[0.x.17775] 
[0.x.17776] 
[0.x.17777] 
[0.x.17778] 
//[2.x.2352] 
//
// The following few functions deal with assembling the advection terms, which is the part of the system matrix for the diffusion step that changes at every time step. As mentioned above, we will run the assembly loop over all cells in %parallel, using the WorkStream class and other facilities as described in the documentation module on  [2.x.2353] .
//
[0.x.17779] 
[0.x.17780] 
[0.x.17781] 
[0.x.17782] 
[0.x.17783] 
[0.x.17784] 
[0.x.17785] 
[0.x.17786] 
[0.x.17787] 
[0.x.17788] 
[0.x.17789] 
[0.x.17790] 
[0.x.17791] 
[0.x.17792] 
[0.x.17793] 
[0.x.17794] 
[0.x.17795] 
[0.x.17796] 
//
[0.x.17797] 
[0.x.17798] 
[0.x.17799] 
[0.x.17800] 
[0.x.17801] 
[0.x.17802] 
[0.x.17803] 
[0.x.17804] 
[0.x.17805] 
[0.x.17806] 
[0.x.17807] 
[0.x.17808] 
[0.x.17809] 
[0.x.17810] 
//
[0.x.17811] 
[0.x.17812] 
[0.x.17813] 
[0.x.17814] 
[0.x.17815] 
[0.x.17816] 
[0.x.17817] 
[0.x.17818] 
[0.x.17819] 
[0.x.17820] 
//
[0.x.17821] 
[0.x.17822] 
[0.x.17823] 
[0.x.17824] 
[0.x.17825] 
[0.x.17826] 
[0.x.17827] 
[0.x.17828] 
[0.x.17829] 
[0.x.17830] 
[0.x.17831] 
[0.x.17832] 
[0.x.17833] 
[0.x.17834] 
//
[0.x.17835] 
[0.x.17836] 
[0.x.17837] 
[0.x.17838] 
[0.x.17839] 
[0.x.17840] 
[0.x.17841] 
[0.x.17842] 
[0.x.17843] 
[0.x.17844] 
//
//  [2.x.2354] 
//
// This implements the projection step:
//
[0.x.17845] 
[0.x.17846] 
[0.x.17847] 
[0.x.17848] 
//
[0.x.17849] 
[0.x.17850] 
[0.x.17851] 
//
[0.x.17852] 
//
[0.x.17853] 
[0.x.17854] 
[0.x.17855] 
[0.x.17856] 
[0.x.17857] 
[0.x.17858] 
//
[0.x.17859] 
//
[0.x.17860] 
[0.x.17861] 
[0.x.17862] 
[0.x.17863] 
//
[0.x.17864] 
[0.x.17865] 
[0.x.17866] 
//
[0.x.17867] 
[0.x.17868] 
//[2.x.2355] 
//
// This is the pressure update step of the projection method. It implements the standard formulation of the method, that is [1.x.67] or the rotational form, which is [1.x.68]
//
[0.x.17869] 
[0.x.17870] 
[0.x.17871] 
[0.x.17872] 
[0.x.17873] 
[0.x.17874] 
[0.x.17875] 
[0.x.17876] 
[0.x.17877] 
[0.x.17878] 
[0.x.17879] 
[0.x.17880] 
[0.x.17881] 
[0.x.17882] 
[0.x.17883] 
[0.x.17884] 
[0.x.17885] 
[0.x.17886] 
[0.x.17887] 
[0.x.17888] 
[0.x.17889] 
//[2.x.2356] 
//
// This method plots the current solution. The main difficulty is that we want to create a single output file that contains the data for all velocity components, the pressure, and also the vorticity of the flow. On the other hand, velocities and the pressure live on separate DoFHandler objects, and so can't be written to the same file using a single DataOut object. As a consequence, we have to work a bit harder to get the various pieces of data into a single DoFHandler object, and then use that to drive graphical output.
//
// We will not elaborate on this process here, but rather refer to  [2.x.2357] , where a similar procedure is used (and is documented) to create a joint DoFHandler object for all variables.
//
// Let us also note that we here compute the vorticity as a scalar quantity in a separate function, using the  [2.x.2358]  projection of the quantity  [2.x.2359]  onto the finite element space used for the components of the velocity. In principle, however, we could also have computed as a pointwise quantity from the velocity, and do so through the DataPostprocessor mechanism discussed in  [2.x.2360]  and  [2.x.2361] .
//
[0.x.17890] 
[0.x.17891] 
[0.x.17892] 
[0.x.17893] 
[0.x.17894] 
[0.x.17895] 
[0.x.17896] 
[0.x.17897] 
[0.x.17898] 
[0.x.17899] 
[0.x.17900] 
[0.x.17901] 
[0.x.17902] 
[0.x.17903] 
[0.x.17904] 
[0.x.17905] 
[0.x.17906] 
[0.x.17907] 
[0.x.17908] 
[0.x.17909] 
[0.x.17910] 
[0.x.17911] 
[0.x.17912] 
[0.x.17913] 
[0.x.17914] 
[0.x.17915] 
[0.x.17916] 
[0.x.17917] 
[0.x.17918] 
[0.x.17919] 
[0.x.17920] 
[0.x.17921] 
[0.x.17922] 
[0.x.17923] 
[0.x.17924] 
[0.x.17925] 
[0.x.17926] 
[0.x.17927] 
[0.x.17928] 
[0.x.17929] 
[0.x.17930] 
[0.x.17931] 
[0.x.17932] 
[0.x.17933] 
[0.x.17934] 
[0.x.17935] 
[0.x.17936] 
[0.x.17937] 
[0.x.17938] 
[0.x.17939] 
[0.x.17940] 
[0.x.17941] 
[0.x.17942] 
[0.x.17943] 
[0.x.17944] 
[0.x.17945] 
[0.x.17946] 
[0.x.17947] 
[0.x.17948] 
[0.x.17949] 
[0.x.17950] 
[0.x.17951] 
[0.x.17952] 
[0.x.17953] 
[0.x.17954] 
[0.x.17955] 
[0.x.17956] 
[0.x.17957] 
[0.x.17958] 
[0.x.17959] 
[0.x.17960] 
[0.x.17961] 
[0.x.17962] 
[0.x.17963] 
[0.x.17964] 
[0.x.17965] 
//
// Following is the helper function that computes the vorticity by projecting the term  [2.x.2362]  onto the finite element space used for the components of the velocity. The function is only called whenever we generate graphical output, so not very often, and as a consequence we didn't bother parallelizing it using the WorkStream concept as we do for the other assembly functions. That should not be overly complicated, however, if needed. Moreover, the implementation that we have here only works for 2d, so we bail if that is not the case.
//
[0.x.17966] 
[0.x.17967] 
[0.x.17968] 
[0.x.17969] 
[0.x.17970] 
[0.x.17971] 
//
[0.x.17972] 
[0.x.17973] 
[0.x.17974] 
[0.x.17975] 
[0.x.17976] 
[0.x.17977] 
[0.x.17978] 
[0.x.17979] 
//
[0.x.17980] 
[0.x.17981] 
//
[0.x.17982] 
[0.x.17983] 
[0.x.17984] 
[0.x.17985] 
[0.x.17986] 
[0.x.17987] 
[0.x.17988] 
[0.x.17989] 
[0.x.17990] 
[0.x.17991] 
[0.x.17992] 
[0.x.17993] 
//
[0.x.17994] 
[0.x.17995] 
[0.x.17996] 
//
[0.x.17997] 
[0.x.17998] 
[0.x.17999] 
//[2.x.2363] 
//
// The main function looks very much like in all the other tutorial programs, so there is little to comment on here:
//
[0.x.18000] 
[0.x.18001] 
[0.x.18002] 
[0.x.18003] 
[0.x.18004] 
//
[0.x.18005] 
[0.x.18006] 
//
[0.x.18007] 
//
[0.x.18008] 
[0.x.18009] 
[0.x.18010] 
[0.x.18011] 
[0.x.18012] 
[0.x.18013] 
[0.x.18014] 
[0.x.18015] 
[0.x.18016] 
[0.x.18017] 
[0.x.18018] 
[0.x.18019] 
[0.x.18020] 
[0.x.18021] 
[0.x.18022] 
[0.x.18023] 
[0.x.18024] 
[0.x.18025] 
[0.x.18026] 
[0.x.18027] 
[0.x.18028] 
[0.x.18029] 
[0.x.18030] 
[0.x.18031] 
[0.x.18032] 
[0.x.18033] 
[0.x.18034] 
[0.x.18035] 
[0.x.18036] 
[0.x.18037] 
[0.x.18038] 
[0.x.18039] 
[0.x.18040] 
[0.x.18041] 
[0.x.18042] 
[0.x.18043] 
[0.x.18044] 
[0.x.18045] 
[0.x.18046] 
[0.x.18047] 
[0.x.18048] 
[0.x.18049] 
[0.x.18050] 
[0.x.18051] 
[0.x.18052] 
[0.x.18053] 
[0.x.18054] 
[0.x.18055] 
[0.x.18056] 
//
[0.x.18057] 
[0.x.18058] 
[0.x.18059] 
[0.x.18060] 
//[2.x.2364] 
//
// As mentioned in the introduction, this program is essentially only a slightly revised version of  [2.x.2365] . As a consequence, most of the following include files are as used there, or at least as used already in previous tutorial programs:
//
[0.x.18061] 
[0.x.18062] 
[0.x.18063] 
[0.x.18064] 
[0.x.18065] 
[0.x.18066] 
[0.x.18067] 
[0.x.18068] 
[0.x.18069] 
[0.x.18070] 
[0.x.18071] 
[0.x.18072] 
[0.x.18073] 
[0.x.18074] 
[0.x.18075] 
[0.x.18076] 
[0.x.18077] 
//
// IndexSet is used to set the size of each  [2.x.2366] 
[0.x.18078] 
//
// PETSc appears here because SLEPc depends on this library:
//
[0.x.18079] 
[0.x.18080] 
//
// And then we need to actually import the interfaces for solvers that SLEPc provides:
//
[0.x.18081] 
//
// We also need some standard C++:
//
[0.x.18082] 
[0.x.18083] 
//
// Finally, as in previous programs, we import all the deal.II class and function names into the namespace into which everything in this program will go:
//
[0.x.18084] 
[0.x.18085] 
[0.x.18086] 
//[2.x.2367] 
//
// Following is the class declaration for the main class template. It looks pretty much exactly like what has already been shown in  [2.x.2368] :
//
[0.x.18087] 
[0.x.18088] 
[0.x.18089] 
[0.x.18090] 
[0.x.18091] 
[0.x.18092] 
//
[0.x.18093] 
[0.x.18094] 
[0.x.18095] 
[0.x.18096] 
[0.x.18097] 
//
[0.x.18098] 
[0.x.18099] 
[0.x.18100] 
//
// With these exceptions: For our eigenvalue problem, we need both a stiffness matrix for the left hand side as well as a mass matrix for the right hand side. We also need not just one solution function, but a whole set of these for the eigenfunctions we want to compute, along with the corresponding eigenvalues:
//
[0.x.18101] 
[0.x.18102] 
[0.x.18103] 
//
// And then we need an object that will store several run-time parameters that we will specify in an input file:
//
[0.x.18104] 
//
// Finally, we will have an object that contains "constraints" on our degrees of freedom. This could include hanging node constraints if we had adaptively refined meshes (which we don't have in the current program). Here, we will store the constraints for boundary nodes  [2.x.2369] .
//
[0.x.18105] 
[0.x.18106] 
//[2.x.2370] 
//[2.x.2371] 
//
// First up, the constructor. The main new part is handling the run-time input parameters. We need to declare their existence first, and then read their values from the input file whose name is specified as an argument to this function:
//
[0.x.18107] 
[0.x.18108] 
[0.x.18109] 
[0.x.18110] 
[0.x.18111] 
//
// TODO investigate why the minimum number of refinement steps required to obtain the correct eigenvalue degeneracies is 6
//
[0.x.18112] 
[0.x.18113] 
[0.x.18114] 
[0.x.18115] 
[0.x.18116] 
[0.x.18117] 
[0.x.18118] 
[0.x.18119] 
[0.x.18120] 
[0.x.18121] 
[0.x.18122] 
[0.x.18123] 
[0.x.18124] 
[0.x.18125] 
[0.x.18126] 
//
[0.x.18127] 
[0.x.18128] 
//[2.x.2372] 
//
// The next function creates a mesh on the domain  [2.x.2373] , refines it as many times as the input file calls for, and then attaches a DoFHandler to it and initializes the matrices and vectors to their correct sizes. We also build the constraints that correspond to the boundary values  [2.x.2374] .
//
// For the matrices, we use the PETSc wrappers. These have the ability to allocate memory as necessary as non-zero entries are added. This seems inefficient: we could as well first compute the sparsity pattern, initialize the matrices with it, and as we then insert entries we can be sure that we do not need to re-allocate memory and free the one used previously. One way to do that would be to use code like this: [1.x.69] instead of the two  [2.x.2375]  calls for the stiffness and mass matrices below.
//
// This doesn't quite work, unfortunately. The code above may lead to a few entries in the non-zero pattern to which we only ever write zero entries; most notably, this holds true for off-diagonal entries for those rows and columns that belong to boundary nodes. This shouldn't be a problem, but for whatever reason, PETSc's ILU preconditioner, which we use to solve linear systems in the eigenvalue solver, doesn't like these extra entries and aborts with an error message.
//
// In the absence of any obvious way to avoid this, we simply settle for the second best option, which is have PETSc allocate memory as necessary. That said, since this is not a time critical part, this whole affair is of no further importance.
//
[0.x.18129] 
[0.x.18130] 
[0.x.18131] 
[0.x.18132] 
[0.x.18133] 
[0.x.18134] 
[0.x.18135] 
//
[0.x.18136] 
[0.x.18137] 
//
[0.x.18138] 
[0.x.18139] 
[0.x.18140] 
[0.x.18141] 
[0.x.18142] 
[0.x.18143] 
//
// The next step is to take care of the eigenspectrum. In this case, the outputs are eigenvalues and eigenfunctions, so we set the size of the list of eigenfunctions and eigenvalues to be as large as we asked for in the input file. When using a  [2.x.2376]  the Vector is initialized using an IndexSet. IndexSet is used not only to resize the  [2.x.2377]  but it also associates an index in the  [2.x.2378]  with a degree of freedom (see  [2.x.2379]  for a more detailed explanation). The function complete_index_set() creates an IndexSet where every valid index is part of the set. Note that this program can only be run sequentially and will throw an exception if used in parallel.
//
[0.x.18144] 
[0.x.18145] 
[0.x.18146] 
[0.x.18147] 
[0.x.18148] 
//
[0.x.18149] 
[0.x.18150] 
//[2.x.2380] 
//
// Here, we assemble the global stiffness and mass matrices from local contributions  [2.x.2381]  and  [2.x.2382]  respectively. This function should be immediately familiar if you've seen previous tutorial programs. The only thing new would be setting up an object that described the potential  [2.x.2383]  using the expression that we got from the input file. We then need to evaluate this object at the quadrature points on each cell. If you've seen how to evaluate function objects (see, for example the coefficient in  [2.x.2384] ), the code here will also look rather familiar.
//
[0.x.18151] 
[0.x.18152] 
[0.x.18153] 
[0.x.18154] 
//
[0.x.18155] 
[0.x.18156] 
[0.x.18157] 
[0.x.18158] 
//
[0.x.18159] 
[0.x.18160] 
//
[0.x.18161] 
[0.x.18162] 
//
[0.x.18163] 
//
[0.x.18164] 
[0.x.18165] 
[0.x.18166] 
[0.x.18167] 
//
[0.x.18168] 
[0.x.18169] 
[0.x.18170] 
[0.x.18171] 
[0.x.18172] 
[0.x.18173] 
//
[0.x.18174] 
[0.x.18175] 
//
[0.x.18176] 
[0.x.18177] 
[0.x.18178] 
[0.x.18179] 
[0.x.18180] 
[0.x.18181] 
[0.x.18182] 
[0.x.18183] 
[0.x.18184] 
[0.x.18185] 
[0.x.18186] 
[0.x.18187] 
[0.x.18188] 
//
[0.x.18189] 
[0.x.18190] 
[0.x.18191] 
[0.x.18192] 
[0.x.18193] 
[0.x.18194] 
//
// Now that we have the local matrix contributions, we transfer them into the global objects and take care of zero boundary constraints:
//
[0.x.18195] 
//
[0.x.18196] 
[0.x.18197] 
[0.x.18198] 
[0.x.18199] 
[0.x.18200] 
[0.x.18201] 
[0.x.18202] 
//
// At the end of the function, we tell PETSc that the matrices have now been fully assembled and that the sparse matrix representation can now be compressed as no more entries will be added:
//
[0.x.18203] 
[0.x.18204] 
//
// Before leaving the function, we calculate spurious eigenvalues, introduced to the system by zero Dirichlet constraints. As discussed in the introduction, the use of Dirichlet boundary conditions coupled with the fact that the degrees of freedom located at the boundary of the domain remain part of the linear system we solve, introduces a number of spurious eigenvalues. Below, we output the interval within which they all lie to ensure that we can ignore them should they show up in our computations.
//
[0.x.18205] 
[0.x.18206] 
//
[0.x.18207] 
[0.x.18208] 
[0.x.18209] 
[0.x.18210] 
[0.x.18211] 
[0.x.18212] 
[0.x.18213] 
//
[0.x.18214] 
[0.x.18215] 
[0.x.18216] 
[0.x.18217] 
//[2.x.2385] 
//
// This is the key new functionality of the program. Now that the system is set up, here is a good time to actually solve the problem: As with other examples this is done using a "solve" routine. Essentially, it works as in other programs: you set up a SolverControl object that describes the accuracy to which we want to solve the linear systems, and then we select the kind of solver we want. Here we choose the Krylov-Schur solver of SLEPc, a pretty fast and robust choice for this kind of problem:
//
[0.x.18218] 
[0.x.18219] 
[0.x.18220] 
//
// We start here, as we normally do, by assigning convergence control we want:
//
[0.x.18221] 
[0.x.18222] 
//
// Before we actually solve for the eigenfunctions and -values, we have to also select which set of eigenvalues to solve for. Lets select those eigenvalues and corresponding eigenfunctions with the smallest real part (in fact, the problem we solve here is symmetric and so the eigenvalues are purely real). After that, we can actually let SLEPc do its work:
//
[0.x.18223] 
//
[0.x.18224] 
//
[0.x.18225] 
[0.x.18226] 
[0.x.18227] 
[0.x.18228] 
[0.x.18229] 
//
// The output of the call above is a set of vectors and values. In eigenvalue problems, the eigenfunctions are only determined up to a constant that can be fixed pretty arbitrarily. Knowing nothing about the origin of the eigenvalue problem, SLEPc has no other choice than to normalize the eigenvectors to one in the  [2.x.2386]  (vector) norm. Unfortunately this norm has little to do with any norm we may be interested from a eigenfunction perspective: the  [2.x.2387]  norm, or maybe the  [2.x.2388]  norm.
//
// Let us choose the latter and rescale eigenfunctions so that they have  [2.x.2389]  instead of  [2.x.2390]  (where  [2.x.2391]  is the  [2.x.2392] th eigen[1.x.70] and  [2.x.2393]  the corresponding vector of nodal values). For the  [2.x.2394]  elements chosen here, we know that the maximum of the function  [2.x.2395]  is attained at one of the nodes, so  [2.x.2396] , making the normalization in the  [2.x.2397]  norm trivial. Note that this doesn't work as easily if we had chosen  [2.x.2398]  elements with  [2.x.2399] : there, the maximum of a function does not necessarily have to be attained at a node, and so  [2.x.2400]  (although the equality is usually nearly true).
//
[0.x.18230] 
[0.x.18231] 
//
// Finally return the number of iterations it took to converge:
//
[0.x.18232] 
[0.x.18233] 
//[2.x.2401] 
//
// This is the last significant function of this program. It uses the DataOut class to generate graphical output from the eigenfunctions for later visualization. It works as in many of the other tutorial programs.
//
// The whole collection of functions is then output as a single VTK file.
//
[0.x.18234] 
[0.x.18235] 
[0.x.18236] 
[0.x.18237] 
//
[0.x.18238] 
//
[0.x.18239] 
[0.x.18240] 
[0.x.18241] 
[0.x.18242] 
//
// The only thing worth discussing may be that because the potential is specified as a function expression in the input file, it would be nice to also have it as a graphical representation along with the eigenfunctions. The process to achieve this is relatively straightforward: we build an object that represents  [2.x.2402]  and then we interpolate this continuous function onto the finite element space. The result we also attach to the DataOut object for visualization.
//
[0.x.18243] 
[0.x.18244] 
[0.x.18245] 
[0.x.18246] 
[0.x.18247] 
[0.x.18248] 
[0.x.18249] 
[0.x.18250] 
[0.x.18251] 
//
[0.x.18252] 
//
[0.x.18253] 
[0.x.18254] 
[0.x.18255] 
//[2.x.2403] 
//
// This is the function which has the top-level control over everything. It is almost exactly the same as in  [2.x.2404] :
//
[0.x.18256] 
[0.x.18257] 
[0.x.18258] 
[0.x.18259] 
//
[0.x.18260] 
[0.x.18261] 
[0.x.18262] 
[0.x.18263] 
//
[0.x.18264] 
//
[0.x.18265] 
[0.x.18266] 
[0.x.18267] 
//
[0.x.18268] 
//
[0.x.18269] 
[0.x.18270] 
[0.x.18271] 
[0.x.18272] 
[0.x.18273] 
[0.x.18274] 
//[2.x.2405] 
[0.x.18275] 
[0.x.18276] 
[0.x.18277] 
[0.x.18278] 
[0.x.18279] 
[0.x.18280] 
//
[0.x.18281] 
//
// This program can only be run in serial. Otherwise, throw an exception.
//
[0.x.18282] 
[0.x.18283] 
[0.x.18284] 
//
[0.x.18285] 
[0.x.18286] 
[0.x.18287] 
//
// All the while, we are watching out if any exceptions should have been generated. If that is so, we panic...
//
[0.x.18288] 
[0.x.18289] 
[0.x.18290] 
[0.x.18291] 
[0.x.18292] 
[0.x.18293] 
[0.x.18294] 
[0.x.18295] 
[0.x.18296] 
[0.x.18297] 
[0.x.18298] 
//
[0.x.18299] 
[0.x.18300] 
[0.x.18301] 
[0.x.18302] 
[0.x.18303] 
[0.x.18304] 
[0.x.18305] 
[0.x.18306] 
[0.x.18307] 
[0.x.18308] 
[0.x.18309] 
[0.x.18310] 
[0.x.18311] 
[0.x.18312] 
//
// If no exceptions are thrown, then we tell the program to stop monkeying around and exit nicely:
//
[0.x.18313] 
//
[0.x.18314] 
[0.x.18315] 
[0.x.18316] 
[0.x.18317] 
[0.x.18318] 
[0.x.18319] 
[0.x.18320] 
[0.x.18321] 
[0.x.18322] 
[0.x.18323] 
[0.x.18324] 
[0.x.18325] 
[0.x.18326] 
[0.x.18327] 
[0.x.18328] 
[0.x.18329] 
//
[0.x.18330] 
[0.x.18331] 
[0.x.18332] 
[0.x.18333] 
//
// First include the necessary files from the deal.II library.
//
[0.x.18334] 
[0.x.18335] 
[0.x.18336] 
//
[0.x.18337] 
[0.x.18338] 
[0.x.18339] 
[0.x.18340] 
//
[0.x.18341] 
//
[0.x.18342] 
[0.x.18343] 
//
[0.x.18344] 
[0.x.18345] 
[0.x.18346] 
[0.x.18347] 
[0.x.18348] 
[0.x.18349] 
//
[0.x.18350] 
[0.x.18351] 
//
// This includes the data structures for the efficient implementation of matrix-free methods or more generic finite element operators with the class MatrixFree.
//
[0.x.18352] 
[0.x.18353] 
[0.x.18354] 
//
[0.x.18355] 
[0.x.18356] 
//
[0.x.18357] 
[0.x.18358] 
[0.x.18359] 
//
// To be efficient, the operations performed in the matrix-free implementation require knowledge of loop lengths at compile time, which are given by the degree of the finite element. Hence, we collect the values of the two template parameters that can be changed at one place in the code. Of course, one could make the degree of the finite element a run-time parameter by compiling the computational kernels for all degrees that are likely (say, between 1 and 6) and selecting the appropriate kernel at run time. Here, we simply choose second order  [2.x.2406]  elements and choose dimension 3 as standard.
//
[0.x.18360] 
[0.x.18361] 
//[2.x.2407] 
//
// We define a variable coefficient function for the Poisson problem. It is similar to the function in  [2.x.2408]  but we use the form  [2.x.2409]  instead of a discontinuous one. It is merely to demonstrate the possibilities of this implementation, rather than making much sense physically. We define the coefficient in the same way as functions in earlier tutorial programs. There is one new function, namely a  [2.x.2410]  method with template argument  [2.x.2411] 
[0.x.18362] 
[0.x.18363] 
[0.x.18364] 
[0.x.18365] 
[0.x.18366] 
[0.x.18367] 
//
[0.x.18368] 
[0.x.18369] 
[0.x.18370] 
[0.x.18371] 
//
// This is the new function mentioned above: Evaluate the coefficient for abstract type  [2.x.2412]  It might be just a usual double, but it can also be a somewhat more complicated type that we call VectorizedArray. This data type is essentially a short array of doubles as discussed in the introduction that holds data from several cells. For example, we evaluate the coefficient shown here not on a simple point as usually done, but we hand it a Point<dim,VectorizedArray<double> > point, which is actually a collection of four points in the case of AVX. Do not confuse the entries in VectorizedArray with the different coordinates of the point. Indeed, the data is laid out such that  [2.x.2413]  returns a VectorizedArray, which in turn contains the x-coordinate for the first point and the second point. You may access the coordinates individually using e.g.  [2.x.2414] , j=0,1,2,3, but it is recommended to define operations on a VectorizedArray as much as possible in order to make use of vectorized operations.
//
// In the function implementation, we assume that the number type overloads basic arithmetic operations, so we just write the code as usual. The base class function  [2.x.2415]  is then computed from the templated function with double type, in order to avoid duplicating code.
//
[0.x.18372] 
[0.x.18373] 
[0.x.18374] 
[0.x.18375] 
[0.x.18376] 
[0.x.18377] 
[0.x.18378] 
//
[0.x.18379] 
[0.x.18380] 
[0.x.18381] 
[0.x.18382] 
[0.x.18383] 
[0.x.18384] 
//[2.x.2416] 
//
// The following class, called  [2.x.2417] , implements the differential operator. For all practical purposes, it is a matrix, i.e., you can ask it for its size (member functions  [2.x.2418] ) and you can apply it to a vector (the  [2.x.2419]  function). The difference to a real matrix of course lies in the fact that this class does not actually store the [1.x.71] of the matrix, but only knows how to compute the action of the operator when applied to a vector.
//
// The infrastructure describing the matrix size, the initialization from a MatrixFree object, and the various interfaces to matrix-vector products through vmult() and Tvmult() methods, is provided by the class  [2.x.2420]  from which this class derives. The LaplaceOperator class defined here only has to provide a few interfaces, namely the actual action of the operator through the apply_add() method that gets used in the vmult() functions, and a method to compute the diagonal entries of the underlying matrix. We need the diagonal for the definition of the multigrid smoother. Since we consider a problem with variable coefficient, we further implement a method that can fill the coefficient values.
//
// Note that the file  [2.x.2421]  already contains an implementation of the Laplacian through the class  [2.x.2422]  For educational purposes, the operator is re-implemented in this tutorial program, explaining the ingredients and concepts used there.
//
// This program makes use of the data cache for finite element operator application that is integrated in deal.II. This data cache class is called MatrixFree. It contains mapping information (Jacobians) and index relations between local and global degrees of freedom. It also contains constraints like the ones from hanging nodes or Dirichlet boundary conditions. Moreover, it can issue a loop over all cells in %parallel, making sure that only cells are worked on that do not share any degree of freedom (this makes the loop thread-safe when writing into destination vectors). This is a more advanced strategy compared to the WorkStream class described in the  [2.x.2423]  module. Of course, to not destroy thread-safety, we have to be careful when writing into class-global structures.
//
// The class implementing the Laplace operator has three template arguments, one for the dimension (as many deal.II classes carry), one for the degree of the finite element (which we need to enable efficient computations through the FEEvaluation class), and one for the underlying scalar type. We want to use  [2.x.2424]  numbers (i.e., double precision, 64-bit floating point) for the final matrix, but floats (single precision, 32-bit floating point numbers) for the multigrid level matrices (as that is only a preconditioner, and floats can be processed twice as fast). The class FEEvaluation also takes a template argument for the number of quadrature points in one dimension. In the code below, we hard-code it to  [2.x.2425] . If we wanted to change it independently of the polynomial degree, we would need to add a template parameter as is done in the  [2.x.2426]  class.
//
// As a sidenote, if we implemented several different operations on the same grid and degrees of freedom (like a mass matrix and a Laplace matrix), we would define two classes like the current one for each of the operators (derived from the  [2.x.2427]  class), and let both of them refer to the same MatrixFree data cache from the general problem class. The interface through  [2.x.2428]  requires us to only provide a minimal set of functions. This concept allows for writing complex application codes with many matrix-free operations.
//
//  [2.x.2429]  Storing values of type  [2.x.2430]  requires care: Here, we use the deal.II table class which is prepared to hold the data with correct alignment. However, storing e.g. an  [2.x.2431]  is not possible with vectorization: A certain alignment of the data with the memory address boundaries is required (essentially, a VectorizedArray that is 32 bytes long in case of AVX needs to start at a memory address that is divisible by 32). The table class (as well as the AlignedVector class it is based on) makes sure that this alignment is respected, whereas  [2.x.2432]  does not in general, which may lead to segmentation faults at strange places for some systems or suboptimal performance for other systems.
//
[0.x.18385] 
[0.x.18386] 
[0.x.18387] 
[0.x.18388] 
[0.x.18389] 
[0.x.18390] 
[0.x.18391] 
//
[0.x.18392] 
//
[0.x.18393] 
//
[0.x.18394] 
//
[0.x.18395] 
//
[0.x.18396] 
[0.x.18397] 
[0.x.18398] 
[0.x.18399] 
//
[0.x.18400] 
[0.x.18401] 
[0.x.18402] 
[0.x.18403] 
[0.x.18404] 
//
[0.x.18405] 
[0.x.18406] 
[0.x.18407] 
[0.x.18408] 
[0.x.18409] 
//
[0.x.18410] 
[0.x.18411] 
//
// This is the constructor of the  [2.x.2433]  class. All it does is to call the default constructor of the base class  [2.x.2434]  which in turn is based on the Subscriptor class that asserts that this class is not accessed after going out of scope e.g. in a preconditioner.
//
[0.x.18412] 
[0.x.18413] 
[0.x.18414] 
[0.x.18415] 
[0.x.18416] 
//
[0.x.18417] 
[0.x.18418] 
[0.x.18419] 
[0.x.18420] 
[0.x.18421] 
[0.x.18422] 
[0.x.18423] 
//
//  [2.x.2435] 
//
// To initialize the coefficient, we directly give it the Coefficient class defined above and then select the method  [2.x.2436]  with vectorized number (which the compiler can deduce from the point data type). The use of the FEEvaluation class (and its template arguments) will be explained below.
//
[0.x.18424] 
[0.x.18425] 
[0.x.18426] 
[0.x.18427] 
[0.x.18428] 
[0.x.18429] 
//
[0.x.18430] 
[0.x.18431] 
[0.x.18432] 
[0.x.18433] 
[0.x.18434] 
[0.x.18435] 
[0.x.18436] 
[0.x.18437] 
[0.x.18438] 
//
//  [2.x.2437] 
//
// Here comes the main function of this class, the evaluation of the matrix-vector product (or, in general, a finite element operator evaluation). This is done in a function that takes exactly four arguments, the MatrixFree object, the destination and source vectors, and a range of cells that are to be worked on. The method  [2.x.2438]  in the MatrixFree class will internally call this function with some range of cells that is obtained by checking which cells are possible to work on simultaneously so that write operations do not cause any race condition. Note that the cell range used in the loop is not directly the number of (active) cells in the current mesh, but rather a collection of batches of cells.  In other word, "cell" may be the wrong term to begin with, since FEEvaluation groups data from several cells together. This means that in the loop over quadrature points we are actually seeing a group of quadrature points of several cells as one block. This is done to enable a higher degree of vectorization.  The number of such "cells" or "cell batches" is stored in MatrixFree and can be queried through  [2.x.2439]  Compared to the deal.II cell iterators, in this class all cells are laid out in a plain array with no direct knowledge of level or neighborship relations, which makes it possible to index the cells by unsigned integers.
//
// The implementation of the Laplace operator is quite simple: First, we need to create an object FEEvaluation that contains the computational kernels and has data fields to store temporary results (e.g. gradients evaluated on all quadrature points on a collection of a few cells). Note that temporary results do not use a lot of memory, and since we specify template arguments with the element order, the data is stored on the stack (without expensive memory allocation). Usually, one only needs to set two template arguments, the dimension as a first argument and the degree of the finite element as the second argument (this is equal to the number of degrees of freedom per dimension minus one for FE_Q elements). However, here we also want to be able to use float numbers for the multigrid preconditioner, which is the last (fifth) template argument. Therefore, we cannot rely on the default template arguments and must also fill the third and fourth field, consequently. The third argument specifies the number of quadrature points per direction and has a default value equal to the degree of the element plus one. The fourth argument sets the number of components (one can also evaluate vector-valued functions in systems of PDEs, but the default is a scalar element), and finally the last argument sets the number type.
//
// Next, we loop over the given cell range and then we continue with the actual implementation:  [2.x.2440] 
//[2.x.2441] Tell the FEEvaluation object the (macro) cell we want to work on.   [2.x.2442] Read in the values of the source vectors ( [2.x.2443]  including the resolution of constraints. This stores  [2.x.2444]  as described in the introduction.   [2.x.2445] Compute the unit-cell gradient (the evaluation of finite element functions). Since FEEvaluation can combine value computations with gradient computations, it uses a unified interface to all kinds of derivatives of order between zero and two. We only want gradients, no values and no second derivatives, so we set the function arguments to true in the gradient slot (second slot), and to false in the values slot (first slot). There is also a third slot for the Hessian which is false by default, so it needs not be given. Note that the FEEvaluation class internally evaluates shape functions in an efficient way where one dimension is worked on at a time (using the tensor product form of shape functions and quadrature points as mentioned in the introduction). This gives complexity equal to  [2.x.2446]  for polynomial degree  [2.x.2447]  in  [2.x.2448]  dimensions, compared to the naive approach with loops over all local degrees of freedom and quadrature points that is used in FEValues and costs  [2.x.2449] .   [2.x.2450] Next comes the application of the Jacobian transformation, the multiplication by the variable coefficient and the quadrature weight. FEEvaluation has an access function  [2.x.2451]  that applies the Jacobian and returns the gradient in real space. Then, we just need to multiply by the (scalar) coefficient, and let the function  [2.x.2452]  apply the second Jacobian (for the test function) and the quadrature weight and Jacobian determinant (JxW). Note that the submitted gradient is stored in the same data field as where it is read from in  [2.x.2453]  Therefore, you need to make sure to not read from the same quadrature point again after having called  [2.x.2454]  on that particular quadrature point. In general, it is a good idea to copy the result of  [2.x.2455]  when it is used more often than once.   [2.x.2456] Next follows the summation over quadrature points for all test functions that corresponds to the actual integration step. For the Laplace operator, we just multiply by the gradient, so we call the integrate function with the respective argument set. If you have an equation where you test by both the values of the test functions and the gradients, both template arguments need to be set to true. Calling first the integrate function for values and then gradients in a separate call leads to wrong results, since the second call will internally overwrite the results from the first call. Note that there is no function argument for the second derivative for integrate step.   [2.x.2457] Eventually, the local contributions in the vector  [2.x.2458]  as mentioned in the introduction need to be added into the result vector (and constraints are applied). This is done with a call to  [2.x.2459]  the same name as the corresponding function in the AffineConstraints (only that we now store the local vector in the FEEvaluation object, as are the indices between local and global degrees of freedom).   [2.x.2460] 
[0.x.18439] 
[0.x.18440] 
[0.x.18441] 
[0.x.18442] 
[0.x.18443] 
[0.x.18444] 
[0.x.18445] 
[0.x.18446] 
//
[0.x.18447] 
[0.x.18448] 
[0.x.18449] 
[0.x.18450] 
//
[0.x.18451] 
[0.x.18452] 
[0.x.18453] 
[0.x.18454] 
[0.x.18455] 
[0.x.18456] 
[0.x.18457] 
[0.x.18458] 
[0.x.18459] 
//
// This function implements the loop over all cells for the  [2.x.2461]  interface. This is done with the  [2.x.2462]  of the MatrixFree class, which takes the operator() of this class with arguments MatrixFree, OutVector, InVector, cell_range. When working with MPI parallelization (but no threading) as is done in this tutorial program, the cell loop corresponds to the following three lines of code:
//
// [1.x.72]
//
// Here, the two calls update_ghost_values() and compress() perform the data exchange on processor boundaries for MPI, once for the source vector where we need to read from entries owned by remote processors, and once for the destination vector where we have accumulated parts of the residuals that need to be added to the respective entry of the owner processor. However,  [2.x.2463]  does not only abstract away those two calls, but also performs some additional optimizations. On the one hand, it will split the update_ghost_values() and compress() calls in a way to allow for overlapping communication and computation. The local_apply function is then called with three cell ranges representing partitions of the cell range from 0 to  [2.x.2464]  On the other hand, cell_loop also supports thread parallelism in which case the cell ranges are split into smaller chunks and scheduled in an advanced way that avoids access to the same vector entry by several threads. That feature is explained in  [2.x.2465] .
//
// Note that after the cell loop, the constrained degrees of freedom need to be touched once more for sensible vmult() operators: Since the assembly loop automatically resolves constraints (just as the  [2.x.2466]  call does), it does not compute any contribution for constrained degrees of freedom, leaving the respective entries zero. This would represent a matrix that had empty rows and columns for constrained degrees of freedom. However, iterative solvers like CG only work for non-singular matrices. The easiest way to do that is to set the sub-block of the matrix that corresponds to constrained DoFs to an identity matrix, in which case application of the matrix would simply copy the elements of the right hand side vector into the left hand side. Fortunately, the vmult() implementations  [2.x.2467]  do this automatically for us outside the apply_add() function, so we do not need to take further action here.
//
// When using the combination of MatrixFree and FEEvaluation in parallel with MPI, there is one aspect to be careful about &mdash; the indexing used for accessing the vector. For performance reasons, MatrixFree and FEEvaluation are designed to access vectors in MPI-local index space also when working with multiple processors. Working in local index space means that no index translation needs to be performed at the place the vector access happens, apart from the unavoidable indirect addressing. However, local index spaces are ambiguous: While it is standard convention to access the locally owned range of a vector with indices between 0 and the local size, the numbering is not so clear for the ghosted entries and somewhat arbitrary. For the matrix-vector product, only the indices appearing on locally owned cells (plus those referenced via hanging node constraints) are necessary. However, in deal.II we often set all the degrees of freedom on ghosted elements as ghosted vector entries, called the  [2.x.2468]  "locally relevant DoFs described in the glossary". In that case, the MPI-local index of a ghosted vector entry can in general be different in the two possible ghost sets, despite referring to the same global index. To avoid problems, FEEvaluation checks that the partitioning of the vector used for the matrix-vector product does indeed match with the partitioning of the indices in MatrixFree by a check called  [2.x.2469]  To facilitate things, the  [2.x.2470]  class includes a mechanism to fit the ghost set to the correct layout. This happens in the ghost region of the vector, so keep in mind that the ghost region might be modified in both the destination and source vector after a call to a vmult() method. This is legitimate because the ghost region of a distributed deal.II vector is a mutable section and filled on demand. Vectors used in matrix-vector products must not be ghosted upon entry of vmult() functions, so no information gets lost.
//
[0.x.18460] 
[0.x.18461] 
[0.x.18462] 
[0.x.18463] 
[0.x.18464] 
[0.x.18465] 
[0.x.18466] 
//
// The following function implements the computation of the diagonal of the operator. Computing matrix entries of a matrix-free operator evaluation turns out to be more complicated than evaluating the operator. Fundamentally, we could obtain a matrix representation of the operator by applying the operator on [1.x.73] unit vectors. Of course, that would be very inefficient since we would need to perform [1.x.74] operator evaluations to retrieve the whole matrix. Furthermore, this approach would completely ignore the matrix sparsity. On an individual cell, however, this is the way to go and actually not that inefficient as there usually is a coupling between all degrees of freedom inside the cell.
//
// We first initialize the diagonal vector to the correct parallel layout. This vector is encapsulated in a member called inverse_diagonal_entries of type DiagonalMatrix in the base class  [2.x.2471]  This member is a shared pointer that we first need to initialize and then get the vector representing the diagonal entries in the matrix. As to the actual diagonal computation, we again use the cell_loop infrastructure of MatrixFree to invoke a local worker routine called local_compute_diagonal(). Since we will only write into a vector but not have any source vector, we put a dummy argument of type <tt>unsigned int</tt> in place of the source vector to confirm with the cell_loop interface. After the loop, we need to set the vector entries subject to Dirichlet boundary conditions to one (either those on the boundary described by the AffineConstraints object inside MatrixFree or the indices at the interface between different grid levels in adaptive multigrid). This is done through the function  [2.x.2472]  and matches with the setting in the matrix-vector product provided by the Base operator. Finally, we need to invert the diagonal entries which is the form required by the Chebyshev smoother based on the Jacobi iteration. In the loop, we assert that all entries are non-zero, because they should either have obtained a positive contribution from integrals or be constrained and treated by  [2.x.2473]  following cell_loop.
//
[0.x.18467] 
[0.x.18468] 
[0.x.18469] 
[0.x.18470] 
[0.x.18471] 
[0.x.18472] 
[0.x.18473] 
[0.x.18474] 
[0.x.18475] 
[0.x.18476] 
[0.x.18477] 
[0.x.18478] 
[0.x.18479] 
//
[0.x.18480] 
//
[0.x.18481] 
[0.x.18482] 
[0.x.18483] 
[0.x.18484] 
[0.x.18485] 
[0.x.18486] 
[0.x.18487] 
[0.x.18488] 
[0.x.18489] 
//
// In the local compute loop, we compute the diagonal by a loop over all columns in the local matrix and putting the entry 1 in the [1.x.75]th slot and a zero entry in all other slots, i.e., we apply the cell-wise differential operator on one unit vector at a time. The inner part invoking  [2.x.2474]  the loop over quadrature points, and  [2.x.2475]  is exactly the same as in the local_apply function. Afterwards, we pick out the [1.x.76]th entry of the local result and put it to a temporary storage (as we overwrite all entries in the array behind  [2.x.2476]  with the next loop iteration). Finally, the temporary storage is written to the destination vector. Note how we use  [2.x.2477]  and  [2.x.2478]  to read and write to the data field that FEEvaluation uses for the integration on the one hand and writes into the global vector on the other hand.
//
// Given that we are only interested in the matrix diagonal, we simply throw away all other entries of the local matrix that have been computed along the way. While it might seem wasteful to compute the complete cell matrix and then throw away everything but the diagonal, the integration are so efficient that the computation does not take too much time. Note that the complexity of operator evaluation per element is  [2.x.2479]  for polynomial degree  [2.x.2480] , so computing the whole matrix costs us  [2.x.2481]  operations, not too far away from  [2.x.2482]  complexity for computing the diagonal with FEValues. Since FEEvaluation is also considerably faster due to vectorization and other optimizations, the diagonal computation with this function is actually the fastest (simple) variant. (It would be possible to compute the diagonal with sum factorization techniques in  [2.x.2483]  operations involving specifically adapted kernels&mdash;but since such kernels are only useful in that particular context and the diagonal computation is typically not on the critical path, they have not been implemented in deal.II.)
//
// Note that the code that calls distribute_local_to_global on the vector to accumulate the diagonal entries into the global matrix has some limitations. For operators with hanging node constraints that distribute an integral contribution of a constrained DoF to several other entries inside the distribute_local_to_global call, the vector interface used here does not exactly compute the diagonal entries, but lumps some contributions located on the diagonal of the local matrix that would end up in a off-diagonal position of the global matrix to the diagonal. The result is correct up to discretization accuracy as explained in [1.x.77], but not mathematically equal. In this tutorial program, no harm can happen because the diagonal is only used for the multigrid level matrices where no hanging node constraints appear.
//
[0.x.18490] 
[0.x.18491] 
[0.x.18492] 
[0.x.18493] 
[0.x.18494] 
[0.x.18495] 
[0.x.18496] 
[0.x.18497] 
//
[0.x.18498] 
//
[0.x.18499] 
[0.x.18500] 
[0.x.18501] 
[0.x.18502] 
//
[0.x.18503] 
[0.x.18504] 
[0.x.18505] 
[0.x.18506] 
[0.x.18507] 
[0.x.18508] 
//
[0.x.18509] 
[0.x.18510] 
[0.x.18511] 
[0.x.18512] 
[0.x.18513] 
[0.x.18514] 
[0.x.18515] 
[0.x.18516] 
[0.x.18517] 
[0.x.18518] 
[0.x.18519] 
[0.x.18520] 
//
//  [2.x.2484] 
//
// This class is based on the one in  [2.x.2485] . However, we replaced the SparseMatrix<double> class by our matrix-free implementation, which means that we can also skip the sparsity patterns. Notice that we define the LaplaceOperator class with the degree of finite element as template argument (the value is defined at the top of the file), and that we use float numbers for the multigrid level matrices.
//
// The class also has a member variable to keep track of all the detailed timings for setting up the entire chain of data before we actually go about solving the problem. In addition, there is an output stream (that is disabled by default) that can be used to output details for the individual setup operations instead of the summary only that is printed out by default.
//
// Since this program is designed to be used with MPI, we also provide the usual  [2.x.2486]  output stream that only prints the information of the processor with MPI rank 0. The grid used for this programs can either be a distributed triangulation based on p4est (in case deal.II is configured to use p4est), otherwise it is a serial grid that only runs without MPI.
//
[0.x.18521] 
[0.x.18522] 
[0.x.18523] 
[0.x.18524] 
[0.x.18525] 
[0.x.18526] 
//
[0.x.18527] 
[0.x.18528] 
[0.x.18529] 
[0.x.18530] 
[0.x.18531] 
//
[0.x.18532] 
[0.x.18533] 
[0.x.18534] 
[0.x.18535] 
[0.x.18536] 
//
[0.x.18537] 
[0.x.18538] 
//
[0.x.18539] 
//
[0.x.18540] 
[0.x.18541] 
[0.x.18542] 
[0.x.18543] 
//
[0.x.18544] 
[0.x.18545] 
[0.x.18546] 
//
[0.x.18547] 
[0.x.18548] 
//
[0.x.18549] 
[0.x.18550] 
[0.x.18551] 
[0.x.18552] 
//
// When we initialize the finite element, we of course have to use the degree specified at the top of the file as well (otherwise, an exception will be thrown at some point, since the computational kernel defined in the templated LaplaceOperator class and the information from the finite element read out by MatrixFree will not match). The constructor of the triangulation needs to set an additional flag that tells the grid to conform to the 2:1 cell balance over vertices, which is needed for the convergence of the geometric multigrid routines. For the distributed grid, we also need to specifically enable the multigrid hierarchy.
//
[0.x.18553] 
[0.x.18554] 
[0.x.18555] 
[0.x.18556] 
[0.x.18557] 
[0.x.18558] 
[0.x.18559] 
[0.x.18560] 
[0.x.18561] 
[0.x.18562] 
[0.x.18563] 
[0.x.18564] 
[0.x.18565] 
[0.x.18566] 
[0.x.18567] 
[0.x.18568] 
[0.x.18569] 
[0.x.18570] 
//
// The LaplaceProblem class holds an additional output stream that collects detailed timings about the setup phase. This stream, called time_details, is disabled by default through the  [2.x.2487]  argument specified here. For detailed timings, removing the  [2.x.2488]  argument prints all the details.
//
[0.x.18571] 
[0.x.18572] 
[0.x.18573] 
//
//  [2.x.2489] 
//
// The setup stage is in analogy to  [2.x.2490]  with relevant changes due to the LaplaceOperator class. The first thing to do is to set up the DoFHandler, including the degrees of freedom for the multigrid levels, and to initialize constraints from hanging nodes and homogeneous Dirichlet conditions. Since we intend to use this programs in %parallel with MPI, we need to make sure that the constraints get to know the locally relevant degrees of freedom, otherwise the storage would explode when using more than a few hundred millions of degrees of freedom, see  [2.x.2491] .
//
// Once we have created the multigrid dof_handler and the constraints, we can call the reinit function for the global matrix operator as well as each level of the multigrid scheme. The main action is to set up the  [2.x.2492]  instance for the problem. The base class of the  [2.x.2493]  class,  [2.x.2494]  is initialized with a shared pointer to MatrixFree object. This way, we can simply create it here and then pass it on to the system matrix and level matrices, respectively. For setting up MatrixFree, we need to activate the update flag in the AdditionalData field of MatrixFree that enables the storage of quadrature point coordinates in real space (by default, it only caches data for gradients (inverse transposed Jacobians) and JxW values). Note that if we call the reinit function without specifying the level (i.e., giving  [2.x.2495] ), MatrixFree constructs a loop over the active cells. In this tutorial, we do not use threads in addition to MPI, which is why we explicitly disable it by setting the  [2.x.2496]  to  [2.x.2497]  Finally, the coefficient is evaluated and vectors are initialized as explained above.
//
[0.x.18574] 
[0.x.18575] 
[0.x.18576] 
[0.x.18577] 
[0.x.18578] 
//
[0.x.18579] 
[0.x.18580] 
//
[0.x.18581] 
[0.x.18582] 
//
[0.x.18583] 
[0.x.18584] 
//
[0.x.18585] 
[0.x.18586] 
//
[0.x.18587] 
[0.x.18588] 
[0.x.18589] 
[0.x.18590] 
[0.x.18591] 
[0.x.18592] 
[0.x.18593] 
[0.x.18594] 
[0.x.18595] 
[0.x.18596] 
//
[0.x.18597] 
[0.x.18598] 
[0.x.18599] 
[0.x.18600] 
[0.x.18601] 
[0.x.18602] 
[0.x.18603] 
[0.x.18604] 
[0.x.18605] 
[0.x.18606] 
[0.x.18607] 
[0.x.18608] 
[0.x.18609] 
[0.x.18610] 
[0.x.18611] 
//
[0.x.18612] 
//
[0.x.18613] 
[0.x.18614] 
//
[0.x.18615] 
[0.x.18616] 
[0.x.18617] 
[0.x.18618] 
//
// Next, initialize the matrices for the multigrid method on all the levels. The data structure MGConstrainedDoFs keeps information about the indices subject to boundary conditions as well as the indices on edges between different refinement levels as described in the  [2.x.2498]  tutorial program. We then go through the levels of the mesh and construct the constraints and matrices on each level. These follow closely the construction of the system matrix on the original mesh, except the slight difference in naming when accessing information on the levels rather than the active cells.
//
[0.x.18619] 
[0.x.18620] 
//
[0.x.18621] 
[0.x.18622] 
[0.x.18623] 
[0.x.18624] 
[0.x.18625] 
//
[0.x.18626] 
[0.x.18627] 
[0.x.18628] 
[0.x.18629] 
[0.x.18630] 
[0.x.18631] 
[0.x.18632] 
[0.x.18633] 
[0.x.18634] 
[0.x.18635] 
[0.x.18636] 
//
[0.x.18637] 
[0.x.18638] 
[0.x.18639] 
[0.x.18640] 
[0.x.18641] 
[0.x.18642] 
[0.x.18643] 
[0.x.18644] 
[0.x.18645] 
[0.x.18646] 
[0.x.18647] 
[0.x.18648] 
[0.x.18649] 
//
[0.x.18650] 
[0.x.18651] 
[0.x.18652] 
[0.x.18653] 
[0.x.18654] 
[0.x.18655] 
[0.x.18656] 
[0.x.18657] 
[0.x.18658] 
//
//  [2.x.2499] 
//
// The assemble function is very simple since all we have to do is to assemble the right hand side. Thanks to FEEvaluation and all the data cached in the MatrixFree class, which we query from  [2.x.2500]  this can be done in a few lines. Since this call is not wrapped into a  [2.x.2501]  (which would be an alternative), we must not forget to call compress() at the end of the assembly to send all the contributions of the right hand side to the owner of the respective degree of freedom.
//
[0.x.18659] 
[0.x.18660] 
[0.x.18661] 
[0.x.18662] 
//
[0.x.18663] 
[0.x.18664] 
[0.x.18665] 
[0.x.18666] 
[0.x.18667] 
[0.x.18668] 
[0.x.18669] 
[0.x.18670] 
[0.x.18671] 
[0.x.18672] 
[0.x.18673] 
[0.x.18674] 
[0.x.18675] 
[0.x.18676] 
//
[0.x.18677] 
[0.x.18678] 
[0.x.18679] 
[0.x.18680] 
//
//  [2.x.2502] 
//
// The solution process is similar as in  [2.x.2503] . We start with the setup of the transfer. For  [2.x.2504]  there is a very fast transfer class called MGTransferMatrixFree that does the interpolation between the grid levels with the same fast sum factorization kernels that get also used in FEEvaluation.
//
[0.x.18681] 
[0.x.18682] 
[0.x.18683] 
[0.x.18684] 
[0.x.18685] 
[0.x.18686] 
[0.x.18687] 
[0.x.18688] 
[0.x.18689] 
[0.x.18690] 
//
// As a smoother, this tutorial program uses a Chebyshev iteration instead of SOR in  [2.x.2505] . (SOR would be very difficult to implement because we do not have the matrix elements available explicitly, and it is difficult to make it work efficiently in %parallel.)  The smoother is initialized with our level matrices and the mandatory additional data for the Chebyshev smoother. We use a relatively high degree here (5), since matrix-vector products are comparably cheap. We choose to smooth out a range of  [2.x.2506]  in the smoother where  [2.x.2507]  is an estimate of the largest eigenvalue (the factor 1.2 is applied inside PreconditionChebyshev). In order to compute that eigenvalue, the Chebyshev initialization performs a few steps of a CG algorithm without preconditioner. Since the highest eigenvalue is usually the easiest one to find and a rough estimate is enough, we choose 10 iterations. Finally, we also set the inner preconditioner type in the Chebyshev method which is a Jacobi iteration. This is represented by the DiagonalMatrix class that gets the inverse diagonal entry provided by our LaplaceOperator class.
//
// On level zero, we initialize the smoother differently because we want to use the Chebyshev iteration as a solver. PreconditionChebyshev allows the user to switch to solver mode where the number of iterations is internally chosen to the correct value. In the additional data object, this setting is activated by choosing the polynomial degree to  [2.x.2508]  The algorithm will then attack all eigenvalues between the smallest and largest one in the coarse level matrix. The number of steps in the Chebyshev smoother are chosen such that the Chebyshev convergence estimates guarantee to reduce the residual by the number specified in the variable  [2.x.2509]  smoothing_range. Note that for solving,  [2.x.2510]  is a relative tolerance and chosen smaller than one, in this case, we select three orders of magnitude, whereas it is a number larger than 1 when only selected eigenvalues are smoothed.
//
// From a computational point of view, the Chebyshev iteration is a very attractive coarse grid solver as long as the coarse size is moderate. This is because the Chebyshev method performs only matrix-vector products and vector updates, which typically parallelize better to the largest cluster size with more than a few tens of thousands of cores than inner product involved in other iterative methods. The former involves only local communication between neighbors in the (coarse) mesh, whereas the latter requires global communication over all processors.
//
[0.x.18691] 
[0.x.18692] 
[0.x.18693] 
[0.x.18694] 
[0.x.18695] 
[0.x.18696] 
[0.x.18697] 
[0.x.18698] 
[0.x.18699] 
[0.x.18700] 
[0.x.18701] 
[0.x.18702] 
[0.x.18703] 
[0.x.18704] 
[0.x.18705] 
[0.x.18706] 
[0.x.18707] 
[0.x.18708] 
[0.x.18709] 
[0.x.18710] 
[0.x.18711] 
[0.x.18712] 
[0.x.18713] 
[0.x.18714] 
[0.x.18715] 
[0.x.18716] 
[0.x.18717] 
[0.x.18718] 
//
[0.x.18719] 
[0.x.18720] 
[0.x.18721] 
//
// The next step is to set up the interface matrices that are needed for the case with hanging nodes. The adaptive multigrid realization in deal.II implements an approach called local smoothing. This means that the smoothing on the finest level only covers the local part of the mesh defined by the fixed (finest) grid level and ignores parts of the computational domain where the terminal cells are coarser than this level. As the method progresses to coarser levels, more and more of the global mesh will be covered. At some coarser level, the whole mesh will be covered. Since all level matrices in the multigrid method cover a single level in the mesh, no hanging nodes appear on the level matrices. At the interface between multigrid levels, homogeneous Dirichlet boundary conditions are set while smoothing. When the residual is transferred to the next coarser level, however, the coupling over the multigrid interface needs to be taken into account. This is done by the so-called interface (or edge) matrices that compute the part of the residual that is missed by the level matrix with homogeneous Dirichlet conditions. We refer to the  [2.x.2511]  "Multigrid paper by Janssen and Kanschat" for more details.
//
// For the implementation of those interface matrices, there is already a pre-defined class  [2.x.2512]  that wraps the routines  [2.x.2513]  and  [2.x.2514]  in a new class with  [2.x.2515]  vmult() and  [2.x.2516]  operations (that were originally written for matrices, hence expecting those names). Note that vmult_interface_down is used during the restriction phase of the multigrid V-cycle, whereas vmult_interface_up is used during the prolongation phase.
//
// Once the interface matrix is created, we set up the remaining Multigrid preconditioner infrastructure in complete analogy to  [2.x.2517]  to obtain a  [2.x.2518]  object that can be applied to a matrix.
//
[0.x.18722] 
[0.x.18723] 
//
[0.x.18724] 
[0.x.18725] 
[0.x.18726] 
[0.x.18727] 
[0.x.18728] 
[0.x.18729] 
[0.x.18730] 
[0.x.18731] 
//
[0.x.18732] 
[0.x.18733] 
[0.x.18734] 
//
[0.x.18735] 
[0.x.18736] 
[0.x.18737] 
[0.x.18738] 
//
// The setup of the multigrid routines is quite easy and one cannot see any difference in the solve process as compared to  [2.x.2519] . All the magic is hidden behind the implementation of the  [2.x.2520]  operation. Note that we print out the solve time and the accumulated setup time through standard out, i.e., in any case, whereas detailed times for the setup operations are only printed in case the flag for detail_times in the constructor is changed.
//
[0.x.18739] 
[0.x.18740] 
[0.x.18741] 
[0.x.18742] 
[0.x.18743] 
[0.x.18744] 
//
[0.x.18745] 
[0.x.18746] 
[0.x.18747] 
[0.x.18748] 
//
[0.x.18749] 
//
[0.x.18750] 
[0.x.18751] 
[0.x.18752] 
[0.x.18753] 
//
//  [2.x.2521] 
//
// Here is the data output, which is a simplified version of  [2.x.2522] . We use the standard VTU (= compressed VTK) output for each grid produced in the refinement process. In addition, we use a compression algorithm that is optimized for speed rather than disk usage. The default setting (which optimizes for disk usage) makes saving the output take about 4 times as long as running the linear solver, while setting  [2.x.2523]  to  [2.x.2524]  lowers this to only one fourth the time of the linear solve.
//
// We disable the output when the mesh gets too large. A variant of this program has been run on hundreds of thousands MPI ranks with as many as 100 billion grid cells, which is not directly accessible to classical visualization tools.
//
[0.x.18754] 
[0.x.18755] 
[0.x.18756] 
[0.x.18757] 
[0.x.18758] 
[0.x.18759] 
//
[0.x.18760] 
//
[0.x.18761] 
[0.x.18762] 
[0.x.18763] 
[0.x.18764] 
//
[0.x.18765] 
[0.x.18766] 
[0.x.18767] 
[0.x.18768] 
[0.x.18769] 
//
[0.x.18770] 
[0.x.18771] 
[0.x.18772] 
//
//  [2.x.2525] 
//
// The function that runs the program is very similar to the one in  [2.x.2526] . We do few refinement steps in 3D compared to 2D, but that's it.
//
// Before we run the program, we output some information about the detected vectorization level as discussed in the introduction.
//
[0.x.18773] 
[0.x.18774] 
[0.x.18775] 
[0.x.18776] 
[0.x.18777] 
[0.x.18778] 
//
[0.x.18779] 
[0.x.18780] 
[0.x.18781] 
[0.x.18782] 
[0.x.18783] 
//
[0.x.18784] 
[0.x.18785] 
[0.x.18786] 
//
[0.x.18787] 
[0.x.18788] 
[0.x.18789] 
[0.x.18790] 
[0.x.18791] 
[0.x.18792] 
[0.x.18793] 
[0.x.18794] 
[0.x.18795] 
[0.x.18796] 
[0.x.18797] 
[0.x.18798] 
[0.x.18799] 
[0.x.18800] 
//
//  [2.x.2527] 
//
// Apart from the fact that we set up the MPI framework according to  [2.x.2528] , there are no surprises in the main function.
//
[0.x.18801] 
[0.x.18802] 
[0.x.18803] 
[0.x.18804] 
[0.x.18805] 
//
[0.x.18806] 
//
[0.x.18807] 
[0.x.18808] 
[0.x.18809] 
[0.x.18810] 
[0.x.18811] 
[0.x.18812] 
[0.x.18813] 
[0.x.18814] 
[0.x.18815] 
[0.x.18816] 
[0.x.18817] 
[0.x.18818] 
[0.x.18819] 
[0.x.18820] 
[0.x.18821] 
[0.x.18822] 
[0.x.18823] 
[0.x.18824] 
[0.x.18825] 
[0.x.18826] 
[0.x.18827] 
[0.x.18828] 
[0.x.18829] 
[0.x.18830] 
[0.x.18831] 
[0.x.18832] 
[0.x.18833] 
[0.x.18834] 
//
[0.x.18835] 
[0.x.18836] 
[0.x.18837] 
[0.x.18838] 
[0.x.18839] 
[0.x.18840] 
[0.x.18841] 
[0.x.18842] 
[0.x.18843] 
[0.x.18844] 
[0.x.18845] 
[0.x.18846] 
[0.x.18847] 
[0.x.18848] 
[0.x.18849] 
[0.x.18850] 
[0.x.18851] 
[0.x.18852] 
[0.x.18853] 
//[2.x.2529] 
//
// If you've read through  [2.x.2530]  and  [2.x.2531] , you will recognize that we have used all of the following include files there already. Consequently, we will not explain their meaning here again.
//
[0.x.18854] 
[0.x.18855] 
//
[0.x.18856] 
[0.x.18857] 
[0.x.18858] 
[0.x.18859] 
[0.x.18860] 
[0.x.18861] 
[0.x.18862] 
//
[0.x.18863] 
[0.x.18864] 
[0.x.18865] 
//
[0.x.18866] 
[0.x.18867] 
//
[0.x.18868] 
[0.x.18869] 
[0.x.18870] 
//
[0.x.18871] 
[0.x.18872] 
[0.x.18873] 
//
[0.x.18874] 
[0.x.18875] 
//
[0.x.18876] 
[0.x.18877] 
[0.x.18878] 
//[2.x.2532] 
//
// This class is almost exactly similar to the  [2.x.2533]  class in  [2.x.2534] .
//
// The essential differences are these:
//
//
//
// - The template parameter now denotes the dimensionality of the embedding   space, which is no longer the same as the dimensionality of the domain   and the triangulation on which we compute. We indicate this by calling   the parameter  [2.x.2535]  and introducing a constant  [2.x.2536]  equal to   the dimensionality of the domain -- here equal to    [2.x.2537] .
//
// - All member variables that have geometric aspects now need to know about   both their own dimensionality as well as that of the embedding   space. Consequently, we need to specify both of their template   parameters one for the dimension of the mesh  [2.x.2538]  and the other for   the dimension of the embedding space,  [2.x.2539]  This is exactly what   we did in  [2.x.2540] , take a look there for a deeper explanation.
//
// - We need an object that describes which kind of mapping to use from the   reference cell to the cells that the triangulation is composed of. The   classes derived from the Mapping base class do exactly this. Throughout   most of deal.II, if you don't do anything at all, the library assumes   that you want an object of kind MappingQ1 that uses a (bi-, tri-)linear   mapping. In many cases, this is quite sufficient, which is why the use   of these objects is mostly optional: for example, if you have a   polygonal two-dimensional domain in two-dimensional space, a bilinear   mapping of the reference cell to the cells of the triangulation yields   an exact representation of the domain. If you have a curved domain, one   may want to use a higher order mapping for those cells that lie at the   boundary of the domain -- this is what we did in  [2.x.2541] , for   example. However, here we have a curved domain, not just a curved   boundary, and while we can approximate it with bilinearly mapped cells,   it is really only prudent to use a higher order mapping for all   cells. Consequently, this class has a member variable of type MappingQ;   we will choose the polynomial degree of the mapping equal to the   polynomial degree of the finite element used in the computations to   ensure optimal approximation, though this iso-parametricity is not   required.
//
[0.x.18879] 
[0.x.18880] 
[0.x.18881] 
[0.x.18882] 
[0.x.18883] 
[0.x.18884] 
//
[0.x.18885] 
[0.x.18886] 
//
[0.x.18887] 
[0.x.18888] 
[0.x.18889] 
[0.x.18890] 
[0.x.18891] 
//
[0.x.18892] 
[0.x.18893] 
[0.x.18894] 
[0.x.18895] 
//
[0.x.18896] 
[0.x.18897] 
//
[0.x.18898] 
[0.x.18899] 
[0.x.18900] 
//[2.x.2542] 
//
// Next, let us define the classes that describe the exact solution and the right hand sides of the problem. This is in analogy to  [2.x.2543]  and  [2.x.2544]  where we also defined such objects. Given the discussion in the introduction, the actual formulas should be self-explanatory. A point of interest may be how we define the value and gradient functions for the 2d and 3d cases separately, using explicit specializations of the general template. An alternative to doing it this way might have been to define the general template and have a  [2.x.2545]  statement (or a sequence of  [2.x.2546] s) for each possible value of the spatial dimension.
//
[0.x.18901] 
[0.x.18902] 
[0.x.18903] 
[0.x.18904] 
[0.x.18905] 
[0.x.18906] 
//
[0.x.18907] 
[0.x.18908] 
[0.x.18909] 
[0.x.18910] 
//
[0.x.18911] 
[0.x.18912] 
[0.x.18913] 
[0.x.18914] 
[0.x.18915] 
//
[0.x.18916] 
[0.x.18917] 
[0.x.18918] 
[0.x.18919] 
[0.x.18920] 
[0.x.18921] 
[0.x.18922] 
//
[0.x.18923] 
[0.x.18924] 
//
[0.x.18925] 
[0.x.18926] 
[0.x.18927] 
[0.x.18928] 
[0.x.18929] 
[0.x.18930] 
//
[0.x.18931] 
[0.x.18932] 
[0.x.18933] 
[0.x.18934] 
[0.x.18935] 
//
[0.x.18936] 
//
[0.x.18937] 
[0.x.18938] 
[0.x.18939] 
//
[0.x.18940] 
[0.x.18941] 
//
[0.x.18942] 
[0.x.18943] 
[0.x.18944] 
[0.x.18945] 
[0.x.18946] 
[0.x.18947] 
[0.x.18948] 
//
[0.x.18949] 
[0.x.18950] 
[0.x.18951] 
[0.x.18952] 
[0.x.18953] 
[0.x.18954] 
//
[0.x.18955] 
[0.x.18956] 
[0.x.18957] 
[0.x.18958] 
[0.x.18959] 
//
[0.x.18960] 
//
[0.x.18961] 
[0.x.18962] 
[0.x.18963] 
//
[0.x.18964] 
[0.x.18965] 
//
[0.x.18966] 
[0.x.18967] 
//
[0.x.18968] 
[0.x.18969] 
//
[0.x.18970] 
[0.x.18971] 
[0.x.18972] 
[0.x.18973] 
//
[0.x.18974] 
[0.x.18975] 
//
[0.x.18976] 
[0.x.18977] 
[0.x.18978] 
//[2.x.2547] 
//
// The rest of the program is actually quite unspectacular if you know  [2.x.2548] . Our first step is to define the constructor, setting the polynomial degree of the finite element and mapping, and associating the DoF handler to the triangulation:
//
[0.x.18979] 
[0.x.18980] 
[0.x.18981] 
[0.x.18982] 
[0.x.18983] 
[0.x.18984] 
[0.x.18985] 
//[2.x.2549] 
//
// The next step is to create the mesh, distribute degrees of freedom, and set up the various variables that describe the linear system. All of these steps are standard with the exception of how to create a mesh that describes a surface. We could generate a mesh for the domain we are interested in, generate a triangulation using a mesh generator, and read it in using the GridIn class. Or, as we do here, we generate the mesh using the facilities in the GridGenerator namespace.
//
// In particular, what we're going to do is this (enclosed between the set of braces below): we generate a  [2.x.2550]  dimensional mesh for the half disk (in 2d) or half ball (in 3d), using the  [2.x.2551]  function. This function sets the boundary indicators of all faces on the outside of the boundary to zero for the ones located on the perimeter of the disk/ball, and one on the straight part that splits the full disk/ball into two halves. The next step is the main point: The  [2.x.2552]  function creates a mesh that consists of those cells that are the faces of the previous mesh, i.e. it describes the [1.x.78] cells of the original (volume) mesh. However, we do not want all faces: only those on the perimeter of the disk or ball which carry boundary indicator zero; we can select these cells using a set of boundary indicators that we pass to  [2.x.2553] 
//
// There is one point that needs to be mentioned. In order to refine a surface mesh appropriately if the manifold is curved (similarly to refining the faces of cells that are adjacent to a curved boundary), the triangulation has to have an object attached to it that describes where new vertices should be located. If you don't attach such a boundary object, they will be located halfway between existing vertices; this is appropriate if you have a domain with straight boundaries (e.g. a polygon) but not when, as here, the manifold has curvature. So for things to work properly, we need to attach a manifold object to our (surface) triangulation, in much the same way as we've already done in 1d for the boundary. We create such an object and attach it to the triangulation.
//
// The final step in creating the mesh is to refine it a number of times. The rest of the function is the same as in previous tutorial programs.
//
[0.x.18986] 
[0.x.18987] 
[0.x.18988] 
[0.x.18989] 
[0.x.18990] 
[0.x.18991] 
//
[0.x.18992] 
[0.x.18993] 
//
[0.x.18994] 
[0.x.18995] 
[0.x.18996] 
[0.x.18997] 
[0.x.18998] 
[0.x.18999] 
//
[0.x.19000] 
//
[0.x.19001] 
[0.x.19002] 
//
[0.x.19003] 
//
[0.x.19004] 
[0.x.19005] 
//
[0.x.19006] 
[0.x.19007] 
[0.x.19008] 
//
[0.x.19009] 
//
[0.x.19010] 
[0.x.19011] 
[0.x.19012] 
//[2.x.2554] 
//
// The following is the central function of this program, assembling the matrix that corresponds to the surface Laplacian (Laplace-Beltrami operator). Maybe surprisingly, it actually looks exactly the same as for the regular Laplace operator discussed in, for example,  [2.x.2555] . The key is that the  [2.x.2556]  function does the magic: It returns the surface gradient  [2.x.2557]  of the  [2.x.2558] th shape function at the  [2.x.2559] th quadrature point. The rest then does not need any changes either:
//
[0.x.19013] 
[0.x.19014] 
[0.x.19015] 
[0.x.19016] 
[0.x.19017] 
//
[0.x.19018] 
[0.x.19019] 
[0.x.19020] 
[0.x.19021] 
[0.x.19022] 
[0.x.19023] 
[0.x.19024] 
//
[0.x.19025] 
[0.x.19026] 
//
[0.x.19027] 
[0.x.19028] 
//
[0.x.19029] 
[0.x.19030] 
//
[0.x.19031] 
//
[0.x.19032] 
[0.x.19033] 
[0.x.19034] 
[0.x.19035] 
//
[0.x.19036] 
//
[0.x.19037] 
//
[0.x.19038] 
[0.x.19039] 
[0.x.19040] 
[0.x.19041] 
[0.x.19042] 
[0.x.19043] 
//
[0.x.19044] 
[0.x.19045] 
[0.x.19046] 
[0.x.19047] 
//
[0.x.19048] 
[0.x.19049] 
[0.x.19050] 
[0.x.19051] 
[0.x.19052] 
[0.x.19053] 
[0.x.19054] 
//
[0.x.19055] 
[0.x.19056] 
[0.x.19057] 
//
[0.x.19058] 
[0.x.19059] 
[0.x.19060] 
//
[0.x.19061] 
[0.x.19062] 
[0.x.19063] 
//
//  [2.x.2560] 
//
// The next function is the one that solves the linear system. Here, too, no changes are necessary:
//
[0.x.19064] 
[0.x.19065] 
[0.x.19066] 
[0.x.19067] 
[0.x.19068] 
//
[0.x.19069] 
[0.x.19070] 
//
[0.x.19071] 
[0.x.19072] 
//
//  [2.x.2561] 
//
// This is the function that generates graphical output from the solution. Most of it is boilerplate code, but there are two points worth pointing out:
//
//
//
// - The  [2.x.2562]  function can take two kinds of vectors:   Either vectors that have one value per degree of freedom defined by the   DoFHandler object previously attached via  [2.x.2563]    and vectors that have one value for each cell of the triangulation, for   example to output estimated errors for each cell. Typically, the   DataOut class knows to tell these two kinds of vectors apart: there are   almost always more degrees of freedom than cells, so we can   differentiate by the two kinds looking at the length of a vector. We   could do the same here, but only because we got lucky: we use a half   sphere. If we had used the whole sphere as domain and  [2.x.2564]  elements,   we would have the same number of cells as vertices and consequently the   two kinds of vectors would have the same number of elements. To avoid   the resulting confusion, we have to tell the  [2.x.2565]    function which kind of vector we have: DoF data. This is what the third   argument to the function does.
//
// - The  [2.x.2566]  function can generate output that subdivides   each cell so that visualization programs can resolve curved manifolds   or higher polynomial degree shape functions better. We here subdivide   each element in each coordinate direction as many times as the   polynomial degree of the finite element in use.
//
[0.x.19073] 
[0.x.19074] 
[0.x.19075] 
[0.x.19076] 
[0.x.19077] 
[0.x.19078] 
[0.x.19079] 
[0.x.19080] 
[0.x.19081] 
//
[0.x.19082] 
[0.x.19083] 
[0.x.19084] 
[0.x.19085] 
[0.x.19086] 
//
//  [2.x.2567] 
//
// This is the last piece of functionality: we want to compute the error in the numerical solution. It is a verbatim copy of the code previously shown and discussed in  [2.x.2568] . As mentioned in the introduction, the  [2.x.2569]  class provides the (tangential) gradient of the solution. To avoid evaluating the error only a superconvergence points, we choose a quadrature rule of sufficiently high order.
//
[0.x.19087] 
[0.x.19088] 
[0.x.19089] 
[0.x.19090] 
[0.x.19091] 
[0.x.19092] 
[0.x.19093] 
[0.x.19094] 
[0.x.19095] 
[0.x.19096] 
[0.x.19097] 
//
[0.x.19098] 
[0.x.19099] 
[0.x.19100] 
[0.x.19101] 
[0.x.19102] 
//
//  [2.x.2570] 
//
// The last function provides the top-level logic. Its contents are self-explanatory:
//
[0.x.19103] 
[0.x.19104] 
[0.x.19105] 
[0.x.19106] 
[0.x.19107] 
[0.x.19108] 
[0.x.19109] 
[0.x.19110] 
[0.x.19111] 
[0.x.19112] 
//[2.x.2571] 
//
// The remainder of the program is taken up by the  [2.x.2572]  function. It follows exactly the general layout first introduced in  [2.x.2573]  and used in all following tutorial programs:
//
[0.x.19113] 
[0.x.19114] 
[0.x.19115] 
[0.x.19116] 
[0.x.19117] 
//
[0.x.19118] 
[0.x.19119] 
[0.x.19120] 
[0.x.19121] 
[0.x.19122] 
[0.x.19123] 
[0.x.19124] 
[0.x.19125] 
[0.x.19126] 
[0.x.19127] 
[0.x.19128] 
[0.x.19129] 
[0.x.19130] 
[0.x.19131] 
[0.x.19132] 
[0.x.19133] 
[0.x.19134] 
[0.x.19135] 
[0.x.19136] 
[0.x.19137] 
[0.x.19138] 
[0.x.19139] 
[0.x.19140] 
[0.x.19141] 
[0.x.19142] 
[0.x.19143] 
[0.x.19144] 
[0.x.19145] 
//
[0.x.19146] 
[0.x.19147] 
[0.x.19148] 
[0.x.19149] 
[0.x.19150] 
[0.x.19151] 
[0.x.19152] 
[0.x.19153] 
[0.x.19154] 
[0.x.19155] 
[0.x.19156] 
[0.x.19157] 
[0.x.19158] 
[0.x.19159] 
[0.x.19160] 
[0.x.19161] 
//
[0.x.19162] 
[0.x.19163] 
[0.x.19164] 
//
// The include files for the linear algebra: A regular SparseMatrix, which in turn will include the necessary files for SparsityPattern and Vector classes.
//
[0.x.19165] 
[0.x.19166] 
[0.x.19167] 
[0.x.19168] 
[0.x.19169] 
[0.x.19170] 
//
// Include files for setting up the mesh
//
[0.x.19171] 
[0.x.19172] 
//
// Include files for FiniteElement classes and DoFHandler.
//
[0.x.19173] 
[0.x.19174] 
[0.x.19175] 
[0.x.19176] 
//
// The include files for using the MeshWorker framework
//
[0.x.19177] 
[0.x.19178] 
[0.x.19179] 
[0.x.19180] 
//
// The include file for local integrators associated with the Laplacian
//
[0.x.19181] 
//
// Support for multigrid methods
//
[0.x.19182] 
[0.x.19183] 
[0.x.19184] 
[0.x.19185] 
[0.x.19186] 
[0.x.19187] 
//
// Finally, we take our exact solution from the library as well as quadrature and additional tools.
//
[0.x.19188] 
[0.x.19189] 
[0.x.19190] 
[0.x.19191] 
//
[0.x.19192] 
[0.x.19193] 
//
// All classes of the deal.II library are in the namespace dealii. In order to save typing, we tell the compiler to search names in there as well.
//
[0.x.19194] 
[0.x.19195] 
[0.x.19196] 
//
// This is the function we use to set the boundary values and also the exact solution we compare to.
//
[0.x.19197] 
//[2.x.2574] 
//
// MeshWorker separates local integration from the loops over cells and faces. Thus, we have to write local integration classes for generating matrices, the right hand side and the error estimator.
//
// All these classes have the same three functions for integrating over cells, boundary faces and interior faces, respectively. All the information needed for the local integration is provided by  [2.x.2575]  Note that the signature of the functions cannot be changed, because it is expected by  [2.x.2576] 
//
// The first class defining local integrators is responsible for computing cell and face matrices. It is used to assemble the global matrix as well as the level matrices.
//
[0.x.19198] 
[0.x.19199] 
[0.x.19200] 
[0.x.19201] 
[0.x.19202] 
[0.x.19203] 
[0.x.19204] 
[0.x.19205] 
[0.x.19206] 
[0.x.19207] 
[0.x.19208] 
[0.x.19209] 
[0.x.19210] 
[0.x.19211] 
//
// On each cell, we integrate the Dirichlet form. We use the library of ready made integrals in LocalIntegrators to avoid writing these loops ourselves. Similarly, we implement Nitsche boundary conditions and the interior penalty fluxes between cells.
//
// The boundary and flux terms need a penalty parameter, which should be adjusted to the cell size and the polynomial degree. A safe choice of this parameter for constant coefficients can be found in  [2.x.2577]  and we use this below.
//
[0.x.19212] 
[0.x.19213] 
[0.x.19214] 
[0.x.19215] 
[0.x.19216] 
[0.x.19217] 
[0.x.19218] 
[0.x.19219] 
//
[0.x.19220] 
[0.x.19221] 
[0.x.19222] 
[0.x.19223] 
[0.x.19224] 
[0.x.19225] 
[0.x.19226] 
[0.x.19227] 
[0.x.19228] 
[0.x.19229] 
[0.x.19230] 
//
// Interior faces use the interior penalty method
//
[0.x.19231] 
[0.x.19232] 
[0.x.19233] 
[0.x.19234] 
[0.x.19235] 
[0.x.19236] 
[0.x.19237] 
[0.x.19238] 
[0.x.19239] 
[0.x.19240] 
[0.x.19241] 
[0.x.19242] 
[0.x.19243] 
[0.x.19244] 
[0.x.19245] 
[0.x.19246] 
[0.x.19247] 
[0.x.19248] 
//
// The second local integrator builds the right hand side. In our example, the right hand side function is zero, such that only the boundary condition is set here in weak form.
//
[0.x.19249] 
[0.x.19250] 
[0.x.19251] 
[0.x.19252] 
[0.x.19253] 
[0.x.19254] 
[0.x.19255] 
[0.x.19256] 
[0.x.19257] 
[0.x.19258] 
[0.x.19259] 
[0.x.19260] 
[0.x.19261] 
[0.x.19262] 
//
[0.x.19263] 
[0.x.19264] 
[0.x.19265] 
[0.x.19266] 
[0.x.19267] 
//
[0.x.19268] 
[0.x.19269] 
[0.x.19270] 
[0.x.19271] 
[0.x.19272] 
[0.x.19273] 
[0.x.19274] 
//
[0.x.19275] 
[0.x.19276] 
//
[0.x.19277] 
[0.x.19278] 
[0.x.19279] 
//
[0.x.19280] 
[0.x.19281] 
[0.x.19282] 
[0.x.19283] 
[0.x.19284] 
[0.x.19285] 
[0.x.19286] 
//
[0.x.19287] 
[0.x.19288] 
[0.x.19289] 
[0.x.19290] 
[0.x.19291] 
[0.x.19292] 
[0.x.19293] 
//
// The third local integrator is responsible for the contributions to the error estimate. This is the standard energy estimator due to Karakashian and Pascal (2003).
//
[0.x.19294] 
[0.x.19295] 
[0.x.19296] 
[0.x.19297] 
[0.x.19298] 
[0.x.19299] 
[0.x.19300] 
[0.x.19301] 
[0.x.19302] 
[0.x.19303] 
[0.x.19304] 
[0.x.19305] 
[0.x.19306] 
[0.x.19307] 
//
// The cell contribution is the Laplacian of the discrete solution, since the right hand side is zero.
//
[0.x.19308] 
[0.x.19309] 
[0.x.19310] 
[0.x.19311] 
[0.x.19312] 
[0.x.19313] 
//
[0.x.19314] 
[0.x.19315] 
[0.x.19316] 
[0.x.19317] 
[0.x.19318] 
[0.x.19319] 
[0.x.19320] 
[0.x.19321] 
//
// At the boundary, we use simply a weighted form of the boundary residual, namely the norm of the difference between the finite element solution and the correct boundary condition.
//
[0.x.19322] 
[0.x.19323] 
[0.x.19324] 
[0.x.19325] 
[0.x.19326] 
[0.x.19327] 
//
[0.x.19328] 
[0.x.19329] 
//
[0.x.19330] 
//
[0.x.19331] 
[0.x.19332] 
[0.x.19333] 
//
[0.x.19334] 
[0.x.19335] 
[0.x.19336] 
[0.x.19337] 
[0.x.19338] 
[0.x.19339] 
[0.x.19340] 
//
// Finally, on interior faces, the estimator consists of the jumps of the solution and its normal derivative, weighted appropriately.
//
[0.x.19341] 
[0.x.19342] 
[0.x.19343] 
[0.x.19344] 
[0.x.19345] 
[0.x.19346] 
[0.x.19347] 
[0.x.19348] 
[0.x.19349] 
[0.x.19350] 
[0.x.19351] 
[0.x.19352] 
//
[0.x.19353] 
[0.x.19354] 
[0.x.19355] 
[0.x.19356] 
[0.x.19357] 
[0.x.19358] 
[0.x.19359] 
//
[0.x.19360] 
[0.x.19361] 
[0.x.19362] 
[0.x.19363] 
[0.x.19364] 
[0.x.19365] 
[0.x.19366] 
[0.x.19367] 
[0.x.19368] 
[0.x.19369] 
[0.x.19370] 
//
// Finally we have an integrator for the error. Since the energy norm for discontinuous Galerkin problems not only involves the difference of the gradient inside the cells, but also the jump terms across faces and at the boundary, we cannot just use  [2.x.2578]  Instead, we use the MeshWorker interface to compute the error ourselves.
//
// There are several different ways to define this energy norm, but all of them are equivalent to each other uniformly with mesh size (some not uniformly with polynomial degree). Here, we choose [1.x.79]
//
[0.x.19371] 
[0.x.19372] 
[0.x.19373] 
[0.x.19374] 
[0.x.19375] 
[0.x.19376] 
[0.x.19377] 
[0.x.19378] 
[0.x.19379] 
[0.x.19380] 
[0.x.19381] 
[0.x.19382] 
[0.x.19383] 
[0.x.19384] 
//
// Here we have the integration on cells. There is currently no good interface in MeshWorker that would allow us to access values of regular functions in the quadrature points. Thus, we have to create the vectors for the exact function's values and gradients inside the cell integrator. After that, everything is as before and we just add up the squares of the differences.
//
// Additionally to computing the error in the energy norm, we use the capability of the mesh worker to compute two functionals at the same time and compute the [1.x.80]-error in the same loop. Obviously, this one does not have any jump terms and only appears in the integration on cells.
//
[0.x.19385] 
[0.x.19386] 
[0.x.19387] 
[0.x.19388] 
[0.x.19389] 
[0.x.19390] 
[0.x.19391] 
[0.x.19392] 
//
[0.x.19393] 
[0.x.19394] 
//
[0.x.19395] 
[0.x.19396] 
//
[0.x.19397] 
[0.x.19398] 
[0.x.19399] 
[0.x.19400] 
[0.x.19401] 
[0.x.19402] 
[0.x.19403] 
[0.x.19404] 
[0.x.19405] 
[0.x.19406] 
[0.x.19407] 
[0.x.19408] 
[0.x.19409] 
[0.x.19410] 
[0.x.19411] 
//
[0.x.19412] 
[0.x.19413] 
[0.x.19414] 
[0.x.19415] 
[0.x.19416] 
[0.x.19417] 
//
[0.x.19418] 
[0.x.19419] 
//
[0.x.19420] 
//
[0.x.19421] 
[0.x.19422] 
[0.x.19423] 
//
[0.x.19424] 
[0.x.19425] 
[0.x.19426] 
[0.x.19427] 
[0.x.19428] 
[0.x.19429] 
[0.x.19430] 
//
[0.x.19431] 
[0.x.19432] 
[0.x.19433] 
[0.x.19434] 
[0.x.19435] 
[0.x.19436] 
[0.x.19437] 
[0.x.19438] 
[0.x.19439] 
[0.x.19440] 
//
[0.x.19441] 
[0.x.19442] 
[0.x.19443] 
[0.x.19444] 
[0.x.19445] 
[0.x.19446] 
//
[0.x.19447] 
[0.x.19448] 
[0.x.19449] 
[0.x.19450] 
[0.x.19451] 
[0.x.19452] 
[0.x.19453] 
[0.x.19454] 
//
//  [2.x.2579] 
//
// This class does the main job, like in previous examples. For a description of the functions declared here, please refer to the implementation below.
//
[0.x.19455] 
[0.x.19456] 
[0.x.19457] 
[0.x.19458] 
[0.x.19459] 
//
[0.x.19460] 
//
[0.x.19461] 
//
[0.x.19462] 
[0.x.19463] 
[0.x.19464] 
[0.x.19465] 
[0.x.19466] 
[0.x.19467] 
[0.x.19468] 
[0.x.19469] 
[0.x.19470] 
//
// The member objects related to the discretization are here.
//
[0.x.19471] 
[0.x.19472] 
[0.x.19473] 
[0.x.19474] 
//
// Then, we have the matrices and vectors related to the global discrete system.
//
[0.x.19475] 
[0.x.19476] 
[0.x.19477] 
[0.x.19478] 
[0.x.19479] 
//
// Finally, we have a group of sparsity patterns and sparse matrices related to the multilevel preconditioner.  First, we have a level matrix and its sparsity pattern.
//
[0.x.19480] 
[0.x.19481] 
//
// When we perform multigrid with local smoothing on locally refined meshes, additional matrices are required; see Kanschat (2004). Here is the sparsity pattern for these edge matrices. We only need one, because the pattern of the up matrix is the transpose of that of the down matrix. Actually, we do not care too much about these details, since the MeshWorker is filling these matrices.
//
[0.x.19482] 
//
// The flux matrix at the refinement edge, coupling fine level degrees of freedom to coarse level.
//
[0.x.19483] 
//
// The transpose of the flux matrix at the refinement edge, coupling coarse level degrees of freedom to fine level.
//
[0.x.19484] 
[0.x.19485] 
//
// The constructor simply sets up the coarse grid and the DoFHandler. The FiniteElement is provided as a parameter to allow flexibility.
//
[0.x.19486] 
[0.x.19487] 
[0.x.19488] 
[0.x.19489] 
[0.x.19490] 
[0.x.19491] 
[0.x.19492] 
[0.x.19493] 
[0.x.19494] 
[0.x.19495] 
[0.x.19496] 
//
// In this function, we set up the dimension of the linear system and the sparsity patterns for the global matrix as well as the level matrices.
//
[0.x.19497] 
[0.x.19498] 
[0.x.19499] 
//
// First, we use the finite element to distribute degrees of freedom over the mesh and number them.
//
[0.x.19500] 
[0.x.19501] 
[0.x.19502] 
//
// Then, we already know the size of the vectors representing finite element functions.
//
[0.x.19503] 
[0.x.19504] 
//
// Next, we set up the sparsity pattern for the global matrix. Since we do not know the row sizes in advance, we first fill a temporary DynamicSparsityPattern object and copy it to the regular SparsityPattern once it is complete.
//
[0.x.19505] 
[0.x.19506] 
[0.x.19507] 
[0.x.19508] 
//
[0.x.19509] 
//
// The global system is set up, now we attend to the level matrices. We resize all matrix objects to hold one matrix per level.
//
[0.x.19510] 
[0.x.19511] 
[0.x.19512] 
[0.x.19513] 
[0.x.19514] 
[0.x.19515] 
//
// It is important to update the sparsity patterns after <tt>clear()</tt> was called for the level matrices, since the matrices lock the sparsity pattern through the SmartPointer and Subscriptor mechanism.
//
[0.x.19516] 
[0.x.19517] 
//
// Now all objects are prepared to hold one sparsity pattern or matrix per level. What's left is setting up the sparsity patterns on each level.
//
[0.x.19518] 
[0.x.19519] 
[0.x.19520] 
[0.x.19521] 
//
// These are roughly the same lines as above for the global matrix, now for each level.
//
[0.x.19522] 
[0.x.19523] 
[0.x.19524] 
[0.x.19525] 
//
// Additionally, we need to initialize the transfer matrices at the refinement edge between levels. They are stored at the index referring to the finer of the two indices, thus there is no such object on level 0.
//
[0.x.19526] 
[0.x.19527] 
[0.x.19528] 
[0.x.19529] 
[0.x.19530] 
[0.x.19531] 
[0.x.19532] 
[0.x.19533] 
[0.x.19534] 
[0.x.19535] 
[0.x.19536] 
[0.x.19537] 
//
// In this function, we assemble the global system matrix, where by global we indicate that this is the matrix of the discrete system we solve and it is covering the whole mesh.
//
[0.x.19538] 
[0.x.19539] 
[0.x.19540] 
//
// First, we need t set up the object providing the values we integrate. This object contains all FEValues and FEFaceValues objects needed and also maintains them automatically such that they always point to the current cell. To this end, we need to tell it first, where and what to compute. Since we are not doing anything fancy, we can rely on their standard choice for quadrature rules.
//
// Since their default update flags are minimal, we add what we need additionally, namely the values and gradients of shape functions on all objects (cells, boundary and interior faces). Afterwards, we are ready to initialize the container, which will create all necessary FEValuesBase objects for integration.
//
[0.x.19541] 
[0.x.19542] 
[0.x.19543] 
[0.x.19544] 
//
// This is the object into which we integrate local data. It is filled by the local integration routines in MatrixIntegrator and then used by the assembler to distribute the information into the global matrix.
//
[0.x.19545] 
//
// Furthermore, we need an object that assembles the local matrix into the global matrix. These assembler objects have all the knowledge of the structures of the target object, in this case a SparseMatrix, possible constraints and the mesh structure.
//
[0.x.19546] 
[0.x.19547] 
//
// Now comes the part we coded ourselves, the local integrator. This is the only part which is problem dependent.
//
[0.x.19548] 
//
// Now, we throw everything into a  [2.x.2580]  which here traverses all active cells of the mesh, computes cell and face matrices and assembles them into the global matrix. We use the variable <tt>dof_handler</tt> here in order to use the global numbering of degrees of freedom.
//
[0.x.19549] 
[0.x.19550] 
[0.x.19551] 
[0.x.19552] 
[0.x.19553] 
[0.x.19554] 
[0.x.19555] 
//
// Now, we do the same for the level matrices. Not too surprisingly, this function looks like a twin of the previous one. Indeed, there are only two minor differences.
//
[0.x.19556] 
[0.x.19557] 
[0.x.19558] 
[0.x.19559] 
[0.x.19560] 
[0.x.19561] 
[0.x.19562] 
//
[0.x.19563] 
//
// Obviously, the assembler needs to be replaced by one filling level matrices. Note that it automatically fills the edge matrices as well.
//
[0.x.19564] 
[0.x.19565] 
[0.x.19566] 
//
[0.x.19567] 
//
// Here is the other difference to the previous function: we run over all cells, not only the active ones. And we use functions ending on  [2.x.2581]  since we need the degrees of freedom on each level, not the global numbering.
//
[0.x.19568] 
[0.x.19569] 
[0.x.19570] 
[0.x.19571] 
[0.x.19572] 
[0.x.19573] 
[0.x.19574] 
//
// Here we have another clone of the assemble function. The difference to assembling the system matrix consists in that we assemble a vector here.
//
[0.x.19575] 
[0.x.19576] 
[0.x.19577] 
[0.x.19578] 
[0.x.19579] 
[0.x.19580] 
[0.x.19581] 
[0.x.19582] 
//
[0.x.19583] 
//
// Since this assembler allows us to fill several vectors, the interface is a little more complicated as above. The pointers to the vectors have to be stored in an AnyData object. While this seems to cause two extra lines of code here, it actually comes handy in more complex applications.
//
[0.x.19584] 
[0.x.19585] 
[0.x.19586] 
[0.x.19587] 
//
[0.x.19588] 
[0.x.19589] 
[0.x.19590] 
[0.x.19591] 
[0.x.19592] 
[0.x.19593] 
[0.x.19594] 
//
[0.x.19595] 
[0.x.19596] 
//
// Now that we have coded all functions building the discrete linear system, it is about time that we actually solve it.
//
[0.x.19597] 
[0.x.19598] 
[0.x.19599] 
//
// The solver of choice is conjugate gradient.
//
[0.x.19600] 
[0.x.19601] 
//
// Now we are setting up the components of the multilevel preconditioner. First, we need transfer between grid levels. The object we are using here generates sparse matrices for these transfers.
//
[0.x.19602] 
[0.x.19603] 
//
// Then, we need an exact solver for the matrix on the coarsest level.
//
[0.x.19604] 
[0.x.19605] 
[0.x.19606] 
[0.x.19607] 
//
// While transfer and coarse grid solver are pretty much generic, more flexibility is offered for the smoother. First, we choose Gauss-Seidel as our smoothing method.
//
[0.x.19608] 
[0.x.19609] 
[0.x.19610] 
[0.x.19611] 
[0.x.19612] 
//
// Do two smoothing steps on each level.
//
[0.x.19613] 
//
// Since the SOR method is not symmetric, but we use conjugate gradient iteration below, here is a trick to make the multilevel preconditioner a symmetric operator even for nonsymmetric smoothers.
//
[0.x.19614] 
//
// The smoother class optionally implements the variable V-cycle, which we do not want here.
//
[0.x.19615] 
//
// Finally, we must wrap our matrices in an object having the required multiplication functions.
//
[0.x.19616] 
[0.x.19617] 
[0.x.19618] 
//
// Now, we are ready to set up the V-cycle operator and the multilevel preconditioner.
//
[0.x.19619] 
[0.x.19620] 
//
// Let us not forget the edge matrices needed because of the adaptive refinement.
//
[0.x.19621] 
//
// After all preparations, wrap the Multigrid object into another object, which can be used as a regular preconditioner,
//
[0.x.19622] 
[0.x.19623] 
//
// and use it to solve the system.
//
[0.x.19624] 
[0.x.19625] 
//
// Another clone of the assemble function. The big difference to the previous ones is here that we also have an input vector.
//
[0.x.19626] 
[0.x.19627] 
[0.x.19628] 
//
// The results of the estimator are stored in a vector with one entry per cell. Since cells in deal.II are not numbered, we have to create our own numbering in order to use this vector. For the assembler used below the information in which component of a vector the result is stored is transmitted by the user_index variable for each cell. We need to set this numbering up here.
//
// On the other hand, somebody might have used the user indices already. So, let's be good citizens and save them before tampering with them.
//
[0.x.19629] 
[0.x.19630] 
//
[0.x.19631] 
[0.x.19632] 
[0.x.19633] 
[0.x.19634] 
//
// This starts like before,
//
[0.x.19635] 
[0.x.19636] 
[0.x.19637] 
[0.x.19638] 
[0.x.19639] 
[0.x.19640] 
//
// but now we need to notify the info box of the finite element function we want to evaluate in the quadrature points. First, we create an AnyData object with this vector, which is the solution we just computed.
//
[0.x.19641] 
[0.x.19642] 
//
// Then, we tell the  [2.x.2582]  for cells, that we need the second derivatives of this solution (to compute the Laplacian). Therefore, the Boolean arguments selecting function values and first derivatives a false, only the last one selecting second derivatives is true.
//
[0.x.19643] 
//
// On interior and boundary faces, we need the function values and the first derivatives, but not second derivatives.
//
[0.x.19644] 
[0.x.19645] 
//
// And we continue as before, with the exception that the default update flags are already adjusted to the values and derivatives we requested above.
//
[0.x.19646] 
[0.x.19647] 
//
[0.x.19648] 
//
// The assembler stores one number per cell, but else this is the same as in the computation of the right hand side.
//
[0.x.19649] 
[0.x.19650] 
[0.x.19651] 
[0.x.19652] 
//
[0.x.19653] 
[0.x.19654] 
[0.x.19655] 
[0.x.19656] 
[0.x.19657] 
[0.x.19658] 
[0.x.19659] 
//
// Right before we return the result of the error estimate, we restore the old user indices.
//
[0.x.19660] 
[0.x.19661] 
[0.x.19662] 
//
// Here we compare our finite element solution with the (known) exact solution and compute the mean quadratic error of the gradient and the function itself. This function is a clone of the estimation function right above.
//
// Since we compute the error in the energy and the [1.x.81]-norm, respectively, our block vector needs two blocks here.
//
[0.x.19663] 
[0.x.19664] 
[0.x.19665] 
[0.x.19666] 
[0.x.19667] 
[0.x.19668] 
//
[0.x.19669] 
[0.x.19670] 
[0.x.19671] 
[0.x.19672] 
[0.x.19673] 
//
[0.x.19674] 
[0.x.19675] 
[0.x.19676] 
[0.x.19677] 
[0.x.19678] 
[0.x.19679] 
//
[0.x.19680] 
[0.x.19681] 
//
[0.x.19682] 
[0.x.19683] 
[0.x.19684] 
//
[0.x.19685] 
[0.x.19686] 
[0.x.19687] 
//
[0.x.19688] 
//
[0.x.19689] 
[0.x.19690] 
[0.x.19691] 
[0.x.19692] 
//
[0.x.19693] 
[0.x.19694] 
[0.x.19695] 
[0.x.19696] 
[0.x.19697] 
[0.x.19698] 
[0.x.19699] 
[0.x.19700] 
//
[0.x.19701] 
[0.x.19702] 
[0.x.19703] 
//
// Create graphical output. We produce the filename by collating the name from its various components, including the refinement cycle that we output with two digits.
//
[0.x.19704] 
[0.x.19705] 
[0.x.19706] 
[0.x.19707] 
[0.x.19708] 
[0.x.19709] 
//
[0.x.19710] 
[0.x.19711] 
[0.x.19712] 
//
[0.x.19713] 
[0.x.19714] 
[0.x.19715] 
[0.x.19716] 
//
[0.x.19717] 
//
[0.x.19718] 
[0.x.19719] 
//
// And finally the adaptive loop, more or less like in previous examples.
//
[0.x.19720] 
[0.x.19721] 
[0.x.19722] 
[0.x.19723] 
[0.x.19724] 
[0.x.19725] 
[0.x.19726] 
[0.x.19727] 
[0.x.19728] 
[0.x.19729] 
[0.x.19730] 
[0.x.19731] 
[0.x.19732] 
[0.x.19733] 
[0.x.19734] 
//
[0.x.19735] 
[0.x.19736] 
[0.x.19737] 
//
[0.x.19738] 
[0.x.19739] 
[0.x.19740] 
[0.x.19741] 
[0.x.19742] 
//
[0.x.19743] 
[0.x.19744] 
[0.x.19745] 
[0.x.19746] 
[0.x.19747] 
[0.x.19748] 
[0.x.19749] 
[0.x.19750] 
[0.x.19751] 
[0.x.19752] 
[0.x.19753] 
[0.x.19754] 
[0.x.19755] 
[0.x.19756] 
//
[0.x.19757] 
[0.x.19758] 
[0.x.19759] 
[0.x.19760] 
[0.x.19761] 
[0.x.19762] 
//
[0.x.19763] 
[0.x.19764] 
[0.x.19765] 
[0.x.19766] 
[0.x.19767] 
[0.x.19768] 
[0.x.19769] 
[0.x.19770] 
[0.x.19771] 
[0.x.19772] 
[0.x.19773] 
[0.x.19774] 
[0.x.19775] 
[0.x.19776] 
[0.x.19777] 
[0.x.19778] 
[0.x.19779] 
[0.x.19780] 
[0.x.19781] 
[0.x.19782] 
[0.x.19783] 
[0.x.19784] 
[0.x.19785] 
[0.x.19786] 
[0.x.19787] 
[0.x.19788] 
[0.x.19789] 
[0.x.19790] 
[0.x.19791] 
[0.x.19792] 
[0.x.19793] 
[0.x.19794] 
//
[0.x.19795] 
[0.x.19796] 
[0.x.19797] 
[0.x.19798] 
[0.x.19799] 
[0.x.19800] 
[0.x.19801] 
[0.x.19802] 
[0.x.19803] 
[0.x.19804] 
[0.x.19805] 
[0.x.19806] 
[0.x.19807] 
[0.x.19808] 
[0.x.19809] 
[0.x.19810] 
//
[0.x.19811] 
[0.x.19812] 
[0.x.19813] 
//[2.x.2583] 
//
// The first few (many?) include files have already been used in the previous example, so we will not explain their meaning here again.
//
[0.x.19814] 
[0.x.19815] 
[0.x.19816] 
[0.x.19817] 
[0.x.19818] 
[0.x.19819] 
[0.x.19820] 
[0.x.19821] 
[0.x.19822] 
[0.x.19823] 
[0.x.19824] 
[0.x.19825] 
[0.x.19826] 
[0.x.19827] 
[0.x.19828] 
[0.x.19829] 
//
[0.x.19830] 
[0.x.19831] 
[0.x.19832] 
//
// This is new, however: in the previous example we got some unwanted output from the linear solvers. If we want to suppress it, we have to include this file and add a single line somewhere to the program (see the main() function below for that):
//
[0.x.19833] 
//
// The final step, as in previous programs, is to import all the deal.II class and function names into the global namespace:
//
[0.x.19834] 
//[2.x.2584] 
//
// This is again the same  [2.x.2585]  class as in the previous example. The only difference is that we have now declared it as a class with a template parameter, and the template parameter is of course the spatial dimension in which we would like to solve the Laplace equation. Of course, several of the member variables depend on this dimension as well, in particular the Triangulation class, which has to represent quadrilaterals or hexahedra, respectively. Apart from this, everything is as before.
//
[0.x.19835] 
[0.x.19836] 
[0.x.19837] 
[0.x.19838] 
[0.x.19839] 
[0.x.19840] 
//
[0.x.19841] 
[0.x.19842] 
[0.x.19843] 
[0.x.19844] 
[0.x.19845] 
[0.x.19846] 
//
[0.x.19847] 
[0.x.19848] 
[0.x.19849] 
//
[0.x.19850] 
[0.x.19851] 
//
[0.x.19852] 
[0.x.19853] 
[0.x.19854] 
//[2.x.2586] 
//
// In the following, we declare two more classes denoting the right hand side and the non-homogeneous Dirichlet boundary values. Both are functions of a dim-dimensional space variable, so we declare them as templates as well.
//
// Each of these classes is derived from a common, abstract base class Function, which declares the common interface which all functions have to follow. In particular, concrete classes have to overload the  [2.x.2587]  function, which takes a point in dim-dimensional space as parameters and returns the value at that point as a  [2.x.2588]  variable.
//
// The  [2.x.2589]  function takes a second argument, which we have here named  [2.x.2590] : This is only meant for vector-valued functions, where you may want to access a certain component of the vector at the point  [2.x.2591] . However, our functions are scalar, so we need not worry about this parameter and we will not use it in the implementation of the functions. Inside the library's header files, the Function base class's declaration of the  [2.x.2592]  function has a default value of zero for the component, so we will access the  [2.x.2593]  function of the right hand side with only one parameter, namely the point where we want to evaluate the function. A value for the component can then simply be omitted for scalar functions.
//
// Function objects are used in lots of places in the library (for example, in  [2.x.2594]  we used a  [2.x.2595]  instance as an argument to  [2.x.2596]  and this is the first tutorial where we define a new class that inherits from Function. Since we only ever call  [2.x.2597]  we could get away with just a plain function (and this is what is done in  [2.x.2598] ), but since this is a tutorial we inherit from Function for the sake of example.
//
[0.x.19855] 
[0.x.19856] 
[0.x.19857] 
[0.x.19858] 
[0.x.19859] 
[0.x.19860] 
[0.x.19861] 
//
[0.x.19862] 
[0.x.19863] 
[0.x.19864] 
[0.x.19865] 
[0.x.19866] 
[0.x.19867] 
[0.x.19868] 
//
// If you are not familiar with what the keywords `virtual` and `override` in the function declarations above mean, you will probably want to take a look at your favorite C++ book or an online tutorial such as http:www.cplusplus.com/doc/tutorial/polymorphism/ . In essence, what is happening here is that Function<dim> is an "abstract" base class that declares a certain "interface" -- a set of functions one can call on objects of this kind. But it does not actually *implement* these functions: it just says "this is how Function objects look like", but what kind of function it actually is, is left to derived classes that implement the `value()` function.
//
// Deriving one class from another is often called an "is-a" relationship function. Here, the `RightHandSide` class "is a" Function class because it implements the interface described by the Function base class. (The actual implementation of the `value()` function is in the code block below.) The `virtual` keyword then means "Yes, the function here is one that can be overridden by derived classes", and the `override` keyword means "Yes, this is in fact a function we know has been declared as part of the base class". The `override` keyword is not strictly necessary, but is an insurance against typos: If we get the name of the function or the type of one argument wrong, the compiler will warn us by stating "You say that this function overrides one in a base class, but I don't actually know any such function with this name and these arguments."
//
// But back to the concrete case here: For this tutorial, we choose as right hand side the function  [2.x.2599]  in 2D, or  [2.x.2600]  in 3D. We could write this distinction using an if-statement on the space dimension, but here is a simple way that also allows us to use the same function in 1D (or in 4D, if you should desire to do so), by using a short loop.  Fortunately, the compiler knows the size of the loop at compile time (remember that at the time when you define the template, the compiler doesn't know the value of  [2.x.2601] , but when it later encounters a statement or declaration  [2.x.2602] , it will take the template, replace all occurrences of dim by 2 and compile the resulting function).  In other words, at the time of compiling this function, the number of times the body will be executed is known, and the compiler can minimize the overhead needed for the loop; the result will be as fast as if we had used the formulas above right away.
//
// The last thing to note is that a  [2.x.2603]  denotes a point in dim-dimensional space, and its individual components (i.e.  [2.x.2604] ,  [2.x.2605] , ... coordinates) can be accessed using the () operator (in fact, the [] operator will work just as well) with indices starting at zero as usual in C and C++.
//
[0.x.19869] 
[0.x.19870] 
[0.x.19871] 
[0.x.19872] 
[0.x.19873] 
[0.x.19874] 
[0.x.19875] 
//
[0.x.19876] 
[0.x.19877] 
//
// As boundary values, we choose  [2.x.2606]  in 2D, and  [2.x.2607]  in 3D. This happens to be equal to the square of the vector from the origin to the point at which we would like to evaluate the function, irrespective of the dimension. So that is what we return:
//
[0.x.19878] 
[0.x.19879] 
[0.x.19880] 
[0.x.19881] 
[0.x.19882] 
[0.x.19883] 
//
//  [2.x.2608] 
//
// Next for the implementation of the class template that makes use of the functions above. As before, we will write everything as templates that have a formal parameter  [2.x.2609]  that we assume unknown at the time we define the template functions. Only later, the compiler will find a declaration of  [2.x.2610]  function, actually) and compile the entire class with  [2.x.2611]  replaced by 2, a process referred to as `instantiation of a template'. When doing so, it will also replace instances of  [2.x.2612]  by  [2.x.2613]  and instantiate the latter class from the class template.
//
// In fact, the compiler will also find a declaration  [2.x.2614]  in  [2.x.2615] . This will cause it to again go back to the general  [2.x.2616]  template, replace all occurrences of  [2.x.2617] , this time by 3, and compile the class a second time. Note that the two instantiations  [2.x.2618]  and  [2.x.2619]  are completely independent classes; their only common feature is that they are both instantiated from the same general template, but they are not convertible into each other, for example, and share no code (both instantiations are compiled completely independently).
//
//  [2.x.2620] 
//
// After this introduction, here is the constructor of the  [2.x.2621]  class. It specifies the desired polynomial degree of the finite elements and associates the DoFHandler to the triangulation just as in the previous example program,  [2.x.2622] :
//
[0.x.19884] 
[0.x.19885] 
[0.x.19886] 
[0.x.19887] 
[0.x.19888] 
//[2.x.2623] 
//
// Grid creation is something inherently dimension dependent. However, as long as the domains are sufficiently similar in 2D or 3D, the library can abstract for you. In our case, we would like to again solve on the square  [2.x.2624]  in 2D, or on the cube  [2.x.2625]  in 3D; both can be termed  [2.x.2626]  so we may use the same function in whatever dimension we are. Of course, the functions that create a hypercube in two and three dimensions are very much different, but that is something you need not care about. Let the library handle the difficult things.
//
[0.x.19889] 
[0.x.19890] 
[0.x.19891] 
[0.x.19892] 
[0.x.19893] 
//
[0.x.19894] 
[0.x.19895] 
[0.x.19896] 
[0.x.19897] 
[0.x.19898] 
//[2.x.2627] 
//
// This function looks exactly like in the previous example, although it performs actions that in their details are quite different if  [2.x.2628]  happens to be 3. The only significant difference from a user's perspective is the number of cells resulting, which is much higher in three than in two space dimensions!
//
[0.x.19899] 
[0.x.19900] 
[0.x.19901] 
[0.x.19902] 
//
[0.x.19903] 
[0.x.19904] 
//
[0.x.19905] 
[0.x.19906] 
[0.x.19907] 
//
[0.x.19908] 
//
[0.x.19909] 
[0.x.19910] 
[0.x.19911] 
//[2.x.2629] 
//
// Unlike in the previous example, we would now like to use a non-constant right hand side function and non-zero boundary values. Both are tasks that are readily achieved with only a few new lines of code in the assemblage of the matrix and right hand side.
//
// More interesting, though, is the way we assemble matrix and right hand side vector dimension independently: there is simply no difference to the two-dimensional case. Since the important objects used in this function (quadrature formula, FEValues) depend on the dimension by way of a template parameter as well, they can take care of setting up properly everything for the dimension for which this function is compiled. By declaring all classes which might depend on the dimension using a template parameter, the library can make nearly all work for you and you don't have to care about most things.
//
[0.x.19912] 
[0.x.19913] 
[0.x.19914] 
[0.x.19915] 
//
// We wanted to have a non-constant right hand side, so we use an object of the class declared above to generate the necessary data. Since this right hand side object is only used locally in the present function, we declare it here as a local variable:
//
[0.x.19916] 
//
// Compared to the previous example, in order to evaluate the non-constant right hand side function we now also need the quadrature points on the cell we are presently on (previously, we only required values and gradients of the shape function from the FEValues object, as well as the quadrature weights,  [2.x.2630]  ). We can tell the FEValues object to do for us by also giving it the #update_quadrature_points flag:
//
[0.x.19917] 
[0.x.19918] 
[0.x.19919] 
[0.x.19920] 
//
// We then again define the same abbreviation as in the previous program. The value of this variable of course depends on the dimension which we are presently using, but the FiniteElement class does all the necessary work for you and you don't have to care about the dimension dependent parts:
//
[0.x.19921] 
//
[0.x.19922] 
[0.x.19923] 
//
[0.x.19924] 
//
// Next, we again have to loop over all cells and assemble local contributions.  Note, that a cell is a quadrilateral in two space dimensions, but a hexahedron in 3D. In fact, the  [2.x.2631]  data type is something different, depending on the dimension we are in, but to the outside world they look alike and you will probably never see a difference. In any case, the real type is hidden by using `auto`:
//
[0.x.19925] 
[0.x.19926] 
[0.x.19927] 
[0.x.19928] 
[0.x.19929] 
//
// Now we have to assemble the local matrix and right hand side. This is done exactly like in the previous example, but now we revert the order of the loops (which we can safely do since they are independent of each other) and merge the loops for the local matrix and the local vector as far as possible to make things a bit faster.
//
// Assembling the right hand side presents the only significant difference to how we did things in  [2.x.2632] : Instead of using a constant right hand side with value 1, we use the object representing the right hand side and evaluate it at the quadrature points:
//
[0.x.19930] 
[0.x.19931] 
[0.x.19932] 
[0.x.19933] 
[0.x.19934] 
[0.x.19935] 
[0.x.19936] 
[0.x.19937] 
//
[0.x.19938] 
[0.x.19939] 
[0.x.19940] 
[0.x.19941] 
[0.x.19942] 
//
// As a final remark to these loops: when we assemble the local contributions into  [2.x.2633] , we have to multiply the gradients of shape functions  [2.x.2634]  and  [2.x.2635]  at point number q_index and multiply it with the scalar weights JxW. This is what actually happens:  [2.x.2636]  returns a  [2.x.2637]  dimensional vector, represented by a  [2.x.2638]  object, and the operator* that multiplies it with the result of  [2.x.2639]  makes sure that the  [2.x.2640]  components of the two vectors are properly contracted, and the result is a scalar floating point number that then is multiplied with the weights. Internally, this operator* makes sure that this happens correctly for all  [2.x.2641]  components of the vectors, whether  [2.x.2642]  be 2, 3, or any other space dimension; from a user's perspective, this is not something worth bothering with, however, making things a lot simpler if one wants to write code dimension independently.
//
// With the local systems assembled, the transfer into the global matrix and right hand side is done exactly as before, but here we have again merged some loops for efficiency:
//
[0.x.19943] 
[0.x.19944] 
[0.x.19945] 
[0.x.19946] 
[0.x.19947] 
[0.x.19948] 
[0.x.19949] 
//
[0.x.19950] 
[0.x.19951] 
[0.x.19952] 
//
// As the final step in this function, we wanted to have non-homogeneous boundary values in this example, unlike the one before. This is a simple task, we only have to replace the  [2.x.2643]  used there by an object of the class which describes the boundary values we would like to use (i.e. the  [2.x.2644]  class declared above):
//
// The function  [2.x.2645]  will only work on faces that have been marked with boundary indicator 0 (because that's what we say the function should work on with the second argument below). If there are faces with boundary id other than 0, then the function interpolate_boundary_values will do nothing on these faces. For the Laplace equation doing nothing is equivalent to assuming that on those parts of the boundary a zero Neumann boundary condition holds.
//
[0.x.19953] 
[0.x.19954] 
[0.x.19955] 
[0.x.19956] 
[0.x.19957] 
[0.x.19958] 
[0.x.19959] 
[0.x.19960] 
[0.x.19961] 
[0.x.19962] 
//[2.x.2646] 
//
// Solving the linear system of equations is something that looks almost identical in most programs. In particular, it is dimension independent, so this function is copied verbatim from the previous example.
//
[0.x.19963] 
[0.x.19964] 
[0.x.19965] 
[0.x.19966] 
[0.x.19967] 
[0.x.19968] 
//
// We have made one addition, though: since we suppress output from the linear solvers, we have to print the number of iterations by hand.
//
[0.x.19969] 
[0.x.19970] 
[0.x.19971] 
//[2.x.2647] 
//
// This function also does what the respective one did in  [2.x.2648] . No changes here for dimension independence either.
//
// Since the program will run both 2d and 3d versions of the Laplace solver, we use the dimension in the filename to generate distinct filenames for each run (in a better program, one would check whether  [2.x.2649]  can have other values than 2 or 3, but we neglect this here for the sake of brevity).
//
[0.x.19972] 
[0.x.19973] 
[0.x.19974] 
[0.x.19975] 
//
[0.x.19976] 
[0.x.19977] 
//
[0.x.19978] 
//
[0.x.19979] 
[0.x.19980] 
[0.x.19981] 
//
//  [2.x.2650] 
//
// This is the function which has the top-level control over everything. Apart from one line of additional output, it is the same as for the previous example.
//
[0.x.19982] 
[0.x.19983] 
[0.x.19984] 
[0.x.19985] 
[0.x.19986] 
//
[0.x.19987] 
[0.x.19988] 
[0.x.19989] 
[0.x.19990] 
[0.x.19991] 
[0.x.19992] 
//[2.x.2651] 
//
// And this is the main function. It also looks mostly like in  [2.x.2652] , but if you look at the code below, note how we first create a variable of type  [2.x.2653]  (forcing the compiler to compile the class template with  [2.x.2654] ) and run a 2d simulation, and then we do the whole thing over in 3d.
//
// In practice, this is probably not what you would do very frequently (you probably either want to solve a 2d problem, or one in 3d, but not both at the same time). However, it demonstrates the mechanism by which we can simply change which dimension we want in a single place, and thereby force the compiler to recompile the dimension independent class templates for the dimension we request. The emphasis here lies on the fact that we only need to change a single place. This makes it rather trivial to debug the program in 2d where computations are fast, and then switch a single place to a 3 to run the much more computing intensive program in 3d for `real' computations.
//
// Each of the two blocks is enclosed in braces to make sure that the  [2.x.2655]  variable goes out of scope (and releases the memory it holds) before we move on to allocate memory for the 3d case. Without the additional braces, the  [2.x.2656]  variable would only be destroyed at the end of the function, i.e. after running the 3d problem, and would needlessly hog memory while the 3d run could actually use it.
//
[0.x.19993] 
[0.x.19994] 
[0.x.19995] 
[0.x.19996] 
[0.x.19997] 
[0.x.19998] 
//
[0.x.19999] 
[0.x.20000] 
[0.x.20001] 
[0.x.20002] 
//
[0.x.20003] 
[0.x.20004] 
[0.x.20005] 
[0.x.20006] 
[0.x.20007] 
[0.x.20008] 
[0.x.20009] 
[0.x.20010] 
[0.x.20011] 
[0.x.20012] 
[0.x.20013] 
[0.x.20014] 
[0.x.20015] 
[0.x.20016] 
[0.x.20017] 
[0.x.20018] 
//
[0.x.20019] 
[0.x.20020] 
[0.x.20021] 
[0.x.20022] 
//[2.x.2657] 
//
// Most of the include files we need for this program have already been discussed in previous programs. In particular, all of the following should already be familiar friends:
//
[0.x.20023] 
[0.x.20024] 
[0.x.20025] 
//
[0.x.20026] 
//
// This program can use either PETSc or Trilinos for its parallel algebra needs. By default, if deal.II has been configured with PETSc, it will use PETSc. Otherwise, the following few lines will check that deal.II has been configured with Trilinos and take that.
//
// But there may be cases where you want to use Trilinos, even though deal.II has *also* been configured with PETSc, for example to compare the performance of these two libraries. To do this, add the following \#define to the source code: [1.x.82]
//
// Using this logic, the following lines will then import either the PETSc or Trilinos wrappers into the namespace `LA` (for "linear algebra). In the former case, we are also defining the macro `USE_PETSC_LA` so that we can detect if we are using PETSc (see solve() for an example where this is necessary).
//
[0.x.20027] 
[0.x.20028] 
[0.x.20029] 
[0.x.20030] 
[0.x.20031] 
[0.x.20032] 
[0.x.20033] 
[0.x.20034] 
[0.x.20035] 
[0.x.20036] 
[0.x.20037] 
[0.x.20038] 
//
[0.x.20039] 
[0.x.20040] 
[0.x.20041] 
[0.x.20042] 
[0.x.20043] 
//
[0.x.20044] 
[0.x.20045] 
[0.x.20046] 
[0.x.20047] 
[0.x.20048] 
[0.x.20049] 
[0.x.20050] 
[0.x.20051] 
//
// The following, however, will be new or be used in new roles. Let's walk through them. The first of these will provide the tools of the  [2.x.2658]  namespace that we will use to query things like the number of processors associated with the current MPI universe, or the number within this universe the processor this job runs on is:
//
[0.x.20052] 
//
// The next one provides a class, ConditionOStream that allows us to write code that would output things to a stream (such as  [2.x.2659]  on every processor but throws the text away on all but one of them. We could achieve the same by simply putting an  [2.x.2660]  statement in front of each place where we may generate output, but this doesn't make the code any prettier. In addition, the condition whether this processor should or should not produce output to the screen is the same every time -- and consequently it should be simple enough to put it into the statements that generate output itself.
//
[0.x.20053] 
//
// After these preliminaries, here is where it becomes more interesting. As mentioned in the  [2.x.2661]  module, one of the fundamental truths of solving problems on large numbers of processors is that there is no way for any processor to store everything (e.g. information about all cells in the mesh, all degrees of freedom, or the values of all elements of the solution vector). Rather, every processor will [1.x.83] a few of each of these and, if necessary, may [1.x.84] about a few more, for example the ones that are located on cells adjacent to the ones this processor owns itself. We typically call the latter [1.x.85], [1.x.86] or [1.x.87]. The point of this discussion here is that we need to have a way to indicate which elements a particular processor owns or need to know of. This is the realm of the IndexSet class: if there are a total of  [2.x.2662]  cells, degrees of freedom, or vector elements, associated with (non-negative) integral indices  [2.x.2663] , then both the set of elements the current processor owns as well as the (possibly larger) set of indices it needs to know about are subsets of the set  [2.x.2664] . IndexSet is a class that stores subsets of this set in an efficient format:
//
[0.x.20054] 
//
// The next header file is necessary for a single function,  [2.x.2665]  The role of this function will be explained below.
//
[0.x.20055] 
//
// The final two, new header files provide the class  [2.x.2666]  that provides meshes distributed across a potentially very large number of processors, while the second provides the namespace  [2.x.2667]  that offers functions that can adaptively refine such distributed meshes:
//
[0.x.20056] 
[0.x.20057] 
//
[0.x.20058] 
[0.x.20059] 
//
[0.x.20060] 
[0.x.20061] 
[0.x.20062] 
//[2.x.2668] 
//
// Next let's declare the main class of this program. Its structure is almost exactly that of the  [2.x.2669]  tutorial program. The only significant differences are:
//
// - The  [2.x.2670]  variable that   describes the set of processors we want this code to run on. In practice,   this will be MPI_COMM_WORLD, i.e. all processors the batch scheduling   system has assigned to this particular job.
//
// - The presence of the  [2.x.2671]  variable of type ConditionOStream.
//
// - The obvious use of  [2.x.2672]  instead of Triangulation.
//
// - The presence of two IndexSet objects that denote which sets of degrees of   freedom (and associated elements of solution and right hand side vectors)   we own on the current processor and which we need (as ghost elements) for   the algorithms in this program to work.
//
// - The fact that all matrices and vectors are now distributed. We use   either the PETSc or Trilinos wrapper classes so that we can use one of   the sophisticated preconditioners offered by Hypre (with PETSc) or ML   (with Trilinos). Note that as part of this class, we store a solution   vector that does not only contain the degrees of freedom the current   processor owns, but also (as ghost elements) all those vector elements   that correspond to "locally relevant" degrees of freedom (i.e. all   those that live on locally owned cells or the layer of ghost cells that   surround it).
//
[0.x.20063] 
[0.x.20064] 
[0.x.20065] 
[0.x.20066] 
[0.x.20067] 
//
[0.x.20068] 
//
[0.x.20069] 
[0.x.20070] 
[0.x.20071] 
[0.x.20072] 
[0.x.20073] 
[0.x.20074] 
//
[0.x.20075] 
//
[0.x.20076] 
//
[0.x.20077] 
[0.x.20078] 
//
[0.x.20079] 
[0.x.20080] 
//
[0.x.20081] 
//
[0.x.20082] 
[0.x.20083] 
[0.x.20084] 
//
[0.x.20085] 
[0.x.20086] 
[0.x.20087] 
//[2.x.2673] 
//[2.x.2674] 
//
// Constructors and destructors are rather trivial. In addition to what we do in  [2.x.2675] , we set the set of processors we want to work on to all machines available (MPI_COMM_WORLD); ask the triangulation to ensure that the mesh remains smooth and free to refined islands, for example; and initialize the  [2.x.2676]  variable to only allow processor zero to output anything. The final piece is to initialize a timer that we use to determine how much compute time the different parts of the program take:
//
[0.x.20088] 
[0.x.20089] 
[0.x.20090] 
[0.x.20091] 
[0.x.20092] 
[0.x.20093] 
[0.x.20094] 
[0.x.20095] 
[0.x.20096] 
[0.x.20097] 
[0.x.20098] 
[0.x.20099] 
[0.x.20100] 
[0.x.20101] 
[0.x.20102] 
[0.x.20103] 
//
//  [2.x.2677] 
//
// The following function is, arguably, the most interesting one in the entire program since it goes to the heart of what distinguishes %parallel  [2.x.2678]  from sequential  [2.x.2679] .
//
// At the top we do what we always do: tell the DoFHandler object to distribute degrees of freedom. Since the triangulation we use here is distributed, the DoFHandler object is smart enough to recognize that on each processor it can only distribute degrees of freedom on cells it owns; this is followed by an exchange step in which processors tell each other about degrees of freedom on ghost cell. The result is a DoFHandler that knows about the degrees of freedom on locally owned cells and ghost cells (i.e. cells adjacent to locally owned cells) but nothing about cells that are further away, consistent with the basic philosophy of distributed computing that no processor can know everything.
//
[0.x.20104] 
[0.x.20105] 
[0.x.20106] 
[0.x.20107] 
//
[0.x.20108] 
//
// The next two lines extract some information we will need later on, namely two index sets that provide information about which degrees of freedom are owned by the current processor (this information will be used to initialize solution and right hand side vectors, and the system matrix, indicating which elements to store on the current processor and which to expect to be stored somewhere else); and an index set that indicates which degrees of freedom are locally relevant (i.e. live on cells that the current processor owns or on the layer of ghost cells around the locally owned cells; we need all of these degrees of freedom, for example, to estimate the error on the local cells).
//
[0.x.20109] 
[0.x.20110] 
//
// Next, let us initialize the solution and right hand side vectors. As mentioned above, the solution vector we seek does not only store elements we own, but also ghost entries; on the other hand, the right hand side vector only needs to have the entries the current processor owns since all we will ever do is write into it, never read from it on locally owned cells (of course the linear solvers will read from it, but they do not care about the geometric location of degrees of freedom).
//
[0.x.20111] 
[0.x.20112] 
[0.x.20113] 
[0.x.20114] 
//
// The next step is to compute hanging node and boundary value constraints, which we combine into a single object storing all constraints.
//
// As with all other things in %parallel, the mantra must be that no processor can store all information about the entire universe. As a consequence, we need to tell the AffineConstraints object for which degrees of freedom it can store constraints and for which it may not expect any information to store. In our case, as explained in the  [2.x.2680]  module, the degrees of freedom we need to care about on each processor are the locally relevant ones, so we pass this to the  [2.x.2681]  function. As a side note, if you forget to pass this argument, the AffineConstraints class will allocate an array with length equal to the largest DoF index it has seen so far. For processors with high MPI process number, this may be very large -- maybe on the order of billions. The program would then allocate more memory than for likely all other operations combined for this single array.
//
[0.x.20115] 
[0.x.20116] 
[0.x.20117] 
[0.x.20118] 
[0.x.20119] 
[0.x.20120] 
[0.x.20121] 
[0.x.20122] 
//
// The last part of this function deals with initializing the matrix with accompanying sparsity pattern. As in previous tutorial programs, we use the DynamicSparsityPattern as an intermediate with which we then initialize the system matrix. To do so we have to tell the sparsity pattern its size but as above there is no way the resulting object will be able to store even a single pointer for each global degree of freedom; the best we can hope for is that it stores information about each locally relevant degree of freedom, i.e. all those that we may ever touch in the process of assembling the matrix (the  [2.x.2682]  "distributed computing paper" has a long discussion why one really needs the locally relevant, and not the small set of locally active degrees of freedom in this context).
//
// So we tell the sparsity pattern its size and what DoFs to store anything for and then ask  [2.x.2683]  to fill it (this function ignores all cells that are not locally owned, mimicking what we will do below in the assembly process). After this, we call a function that exchanges entries in these sparsity pattern between processors so that in the end each processor really knows about all the entries that will exist in that part of the finite element matrix that it will own. The final step is to initialize the matrix with the sparsity pattern.
//
[0.x.20123] 
//
[0.x.20124] 
[0.x.20125] 
[0.x.20126] 
[0.x.20127] 
[0.x.20128] 
//
[0.x.20129] 
[0.x.20130] 
[0.x.20131] 
[0.x.20132] 
[0.x.20133] 
//
//  [2.x.2684] 
//
// The function that then assembles the linear system is comparatively boring, being almost exactly what we've seen before. The points to watch out for are:
//
// - Assembly must only loop over locally owned cells. There   are multiple ways to test that; for example, we could compare a cell's   subdomain_id against information from the triangulation as in   <code>cell->subdomain_id() ==   triangulation.locally_owned_subdomain()</code>, or skip all cells for   which the condition <code>cell->is_ghost() ||   cell->is_artificial()</code> is true. The simplest way, however, is to   simply ask the cell whether it is owned by the local processor.
//
// - Copying local contributions into the global matrix must include   distributing constraints and boundary values. In other words, we cannot   (as we did in  [2.x.2685] ) first copy every local contribution into the global   matrix and only in a later step take care of hanging node constraints and   boundary values. The reason is, as discussed in  [2.x.2686] , that the   parallel vector classes do not provide access to arbitrary elements of   the matrix once they have been assembled into it -- in parts because they   may simply no longer reside on the current processor but have instead   been shipped to a different machine.
//
// - The way we compute the right hand side (given the   formula stated in the introduction) may not be the most elegant but will   do for a program whose focus lies somewhere entirely different.
//
[0.x.20134] 
[0.x.20135] 
[0.x.20136] 
[0.x.20137] 
//
[0.x.20138] 
//
[0.x.20139] 
[0.x.20140] 
[0.x.20141] 
[0.x.20142] 
//
[0.x.20143] 
[0.x.20144] 
//
[0.x.20145] 
[0.x.20146] 
//
[0.x.20147] 
//
[0.x.20148] 
[0.x.20149] 
[0.x.20150] 
[0.x.20151] 
[0.x.20152] 
//
[0.x.20153] 
//
[0.x.20154] 
[0.x.20155] 
[0.x.20156] 
[0.x.20157] 
[0.x.20158] 
[0.x.20159] 
[0.x.20160] 
[0.x.20161] 
[0.x.20162] 
//
[0.x.20163] 
[0.x.20164] 
[0.x.20165] 
[0.x.20166] 
[0.x.20167] 
[0.x.20168] 
//
[0.x.20169] 
[0.x.20170] 
[0.x.20171] 
[0.x.20172] 
[0.x.20173] 
//
[0.x.20174] 
[0.x.20175] 
[0.x.20176] 
[0.x.20177] 
[0.x.20178] 
[0.x.20179] 
[0.x.20180] 
//
// Notice that the assembling above is just a local operation. So, to form the "global" linear system, a synchronization between all processors is needed. This could be done by invoking the function compress(). See  [2.x.2687]  "Compressing distributed objects" for more information on what is compress() designed to do.
//
[0.x.20181] 
[0.x.20182] 
[0.x.20183] 
//
//  [2.x.2688] 
//
// Even though solving linear systems on potentially tens of thousands of processors is by far not a trivial job, the function that does this is -- at least at the outside -- relatively simple. Most of the parts you've seen before. There are really only two things worth mentioning:
//
// - Solvers and preconditioners are built on the deal.II wrappers of PETSc   and Trilinos functionality. It is relatively well known that the   primary bottleneck of massively %parallel linear solvers is not   actually the communication between processors, but the fact that it is   difficult to produce preconditioners that scale well to large numbers   of processors. Over the second half of the first decade of the 21st   century, it has become clear that algebraic multigrid (AMG) methods   turn out to be extremely efficient in this context, and we will use one   of them -- either the BoomerAMG implementation of the Hypre package   that can be interfaced to through PETSc, or a preconditioner provided   by ML, which is part of Trilinos -- for the current program. The rest   of the solver itself is boilerplate and has been shown before. Since   the linear system is symmetric and positive definite, we can use the CG   method as the outer solver.
//
// - Ultimately, we want a vector that stores not only the elements   of the solution for degrees of freedom the current processor owns, but   also all other locally relevant degrees of freedom. On the other hand,   the solver itself needs a vector that is uniquely split between   processors, without any overlap. We therefore create a vector at the   beginning of this function that has these properties, use it to solve the   linear system, and only assign it to the vector we want at the very   end. This last step ensures that all ghost elements are also copied as   necessary.
//
[0.x.20184] 
[0.x.20185] 
[0.x.20186] 
[0.x.20187] 
[0.x.20188] 
[0.x.20189] 
//
[0.x.20190] 
//
[0.x.20191] 
[0.x.20192] 
[0.x.20193] 
[0.x.20194] 
[0.x.20195] 
//
[0.x.20196] 
//
[0.x.20197] 
//
[0.x.20198] 
[0.x.20199] 
[0.x.20200] 
//
//    /* Trilinos defaults are good  [2.x.2689] 
[0.x.20201] 
[0.x.20202] 
//
[0.x.20203] 
[0.x.20204] 
[0.x.20205] 
[0.x.20206] 
//
[0.x.20207] 
[0.x.20208] 
//
[0.x.20209] 
//
[0.x.20210] 
[0.x.20211] 
//
//  [2.x.2690] 
//
// The function that estimates the error and refines the grid is again almost exactly like the one in  [2.x.2691] . The only difference is that the function that flags cells to be refined is now in namespace  [2.x.2692]  -- a namespace that has functions that can communicate between all involved processors and determine global thresholds to use in deciding which cells to refine and which to coarsen.
//
// Note that we didn't have to do anything special about the KellyErrorEstimator class: we just give it a vector with as many elements as the local triangulation has cells (locally owned cells, ghost cells, and artificial ones), but it only fills those entries that correspond to cells that are locally owned.
//
[0.x.20212] 
[0.x.20213] 
[0.x.20214] 
[0.x.20215] 
//
[0.x.20216] 
[0.x.20217] 
[0.x.20218] 
[0.x.20219] 
[0.x.20220] 
[0.x.20221] 
[0.x.20222] 
[0.x.20223] 
[0.x.20224] 
[0.x.20225] 
[0.x.20226] 
//
//  [2.x.2693] 
//
// Compared to the corresponding function in  [2.x.2694] , the one here is a tad more complicated. There are two reasons: the first one is that we do not just want to output the solution but also for each cell which processor owns it (i.e. which "subdomain" it is in). Secondly, as discussed at length in  [2.x.2695]  and  [2.x.2696] , generating graphical data can be a bottleneck in parallelizing. In  [2.x.2697] , we have moved this step out of the actual computation but shifted it into a separate program that later combined the output from various processors into a single file. But this doesn't scale: if the number of processors is large, this may mean that the step of combining data on a single processor later becomes the longest running part of the program, or it may produce a file that's so large that it can't be visualized any more. We here follow a more sensible approach, namely creating individual files for each MPI process and leaving it to the visualization program to make sense of that.
//
// To start, the top of the function looks like it usually does. In addition to attaching the solution vector (the one that has entries for all locally relevant, not only the locally owned, elements), we attach a data vector that stores, for each cell, the subdomain the cell belongs to. This is slightly tricky, because of course not every processor knows about every cell. The vector we attach therefore has an entry for every cell that the current processor has in its mesh (locally owned ones, ghost cells, and artificial cells), but the DataOut class will ignore all entries that correspond to cells that are not owned by the current processor. As a consequence, it doesn't actually matter what values we write into these vector entries: we simply fill the entire vector with the number of the current MPI process (i.e. the subdomain_id of the current process); this correctly sets the values we care for, i.e. the entries that correspond to locally owned cells, while providing the wrong value for all other elements -- but these are then ignored anyway.
//
[0.x.20227] 
[0.x.20228] 
[0.x.20229] 
[0.x.20230] 
[0.x.20231] 
[0.x.20232] 
//
[0.x.20233] 
[0.x.20234] 
[0.x.20235] 
[0.x.20236] 
//
[0.x.20237] 
//
// The next step is to write this data to disk. We write up to 8 VTU files in parallel with the help of MPI-IO. Additionally a PVTU record is generated, which groups the written VTU files.
//
[0.x.20238] 
[0.x.20239] 
[0.x.20240] 
//
//  [2.x.2698] 
//
// The function that controls the overall behavior of the program is again like the one in  [2.x.2699] . The minor difference are the use of  [2.x.2700]  for output to the console (see also  [2.x.2701] ) and that we only generate graphical output if at most 32 processors are involved. Without this limit, it would be just too easy for people carelessly running this program without reading it first to bring down the cluster interconnect and fill any file system available :-)
//
// A functional difference to  [2.x.2702]  is the use of a square domain and that we start with a slightly finer mesh (5 global refinement cycles) -- there just isn't much of a point showing a massively %parallel program starting on 4 cells (although admittedly the point is only slightly stronger starting on 1024).
//
[0.x.20241] 
[0.x.20242] 
[0.x.20243] 
[0.x.20244] 
[0.x.20245] 
[0.x.20246] 
[0.x.20247] 
[0.x.20248] 
[0.x.20249] 
[0.x.20250] 
[0.x.20251] 
//
[0.x.20252] 
[0.x.20253] 
[0.x.20254] 
[0.x.20255] 
//
[0.x.20256] 
[0.x.20257] 
[0.x.20258] 
[0.x.20259] 
[0.x.20260] 
[0.x.20261] 
[0.x.20262] 
//
[0.x.20263] 
//
[0.x.20264] 
[0.x.20265] 
[0.x.20266] 
[0.x.20267] 
//
[0.x.20268] 
[0.x.20269] 
//
[0.x.20270] 
[0.x.20271] 
[0.x.20272] 
[0.x.20273] 
[0.x.20274] 
//
[0.x.20275] 
[0.x.20276] 
//
[0.x.20277] 
[0.x.20278] 
[0.x.20279] 
[0.x.20280] 
//
//  [2.x.2703] 
//
// The final function,  [2.x.2704] , again has the same structure as in all other programs, in particular  [2.x.2705] . Like the other programs that use MPI, we have to initialize and finalize MPI, which is done using the helper object  [2.x.2706]  The constructor of that class also initializes libraries that depend on MPI, such as p4est, PETSc, SLEPc, and Zoltan (though the last two are not used in this tutorial). The order here is important: we cannot use any of these libraries until they are initialized, so it does not make sense to do anything before creating an instance of  [2.x.2707] 
//
// After the solver finishes, the LaplaceProblem destructor will run followed by  [2.x.2708]  This order is also important:  [2.x.2709]  calls  [2.x.2710]  (and finalization functions for other libraries), which will delete any in-use PETSc objects. This must be done after we destruct the Laplace solver to avoid double deletion errors. Fortunately, due to the order of destructor call rules of C++, we do not need to worry about any of this: everything happens in the correct order (i.e., the reverse of the order of construction). The last function called by  [2.x.2711]  is  [2.x.2712] : i.e., once this object is destructed the program should exit since MPI will no longer be available.
//
[0.x.20281] 
[0.x.20282] 
[0.x.20283] 
[0.x.20284] 
[0.x.20285] 
[0.x.20286] 
//
[0.x.20287] 
//
[0.x.20288] 
[0.x.20289] 
[0.x.20290] 
[0.x.20291] 
[0.x.20292] 
[0.x.20293] 
[0.x.20294] 
[0.x.20295] 
[0.x.20296] 
[0.x.20297] 
[0.x.20298] 
[0.x.20299] 
[0.x.20300] 
[0.x.20301] 
//
[0.x.20302] 
[0.x.20303] 
[0.x.20304] 
[0.x.20305] 
[0.x.20306] 
[0.x.20307] 
[0.x.20308] 
[0.x.20309] 
[0.x.20310] 
[0.x.20311] 
[0.x.20312] 
[0.x.20313] 
[0.x.20314] 
[0.x.20315] 
//
[0.x.20316] 
[0.x.20317] 
[0.x.20318] 
[0.x.20319] 
[0.x.20320] 
[0.x.20321] 
[0.x.20322] 
[0.x.20323] 
[0.x.20324] 
[0.x.20325] 
[0.x.20326] 
[0.x.20327] 
[0.x.20328] 
[0.x.20329] 
[0.x.20330] 
[0.x.20331] 
//
[0.x.20332] 
[0.x.20333] 
[0.x.20334] 
[0.x.20335] 
[0.x.20336] 
//[2.x.2713] 
//
// As usual, at the beginning we include all the header files we need in here. With the exception of the various files that provide interfaces to the Trilinos library, there are no surprises:
//
[0.x.20337] 
[0.x.20338] 
[0.x.20339] 
//
[0.x.20340] 
[0.x.20341] 
[0.x.20342] 
[0.x.20343] 
[0.x.20344] 
[0.x.20345] 
[0.x.20346] 
[0.x.20347] 
//
[0.x.20348] 
[0.x.20349] 
//
[0.x.20350] 
[0.x.20351] 
//
[0.x.20352] 
[0.x.20353] 
//
[0.x.20354] 
[0.x.20355] 
//
[0.x.20356] 
[0.x.20357] 
//
[0.x.20358] 
[0.x.20359] 
[0.x.20360] 
//[2.x.2714] 
//
// This class supplies all function and variables needed to describe the obstacle problem. It is close to what we had to do in  [2.x.2715] , and so relatively simple. The only real new components are the update_solution_and_constraints function that computes the active set and a number of variables that are necessary to describe the original (unconstrained) form of the linear system ( [2.x.2716]  and  [2.x.2717] ) as well as the active set itself and the diagonal of the mass matrix  [2.x.2718]  used in scaling Lagrange multipliers in the active set formulation. The rest is as in  [2.x.2719] :
//
[0.x.20361] 
[0.x.20362] 
[0.x.20363] 
[0.x.20364] 
[0.x.20365] 
[0.x.20366] 
//
[0.x.20367] 
[0.x.20368] 
[0.x.20369] 
[0.x.20370] 
[0.x.20371] 
[0.x.20372] 
[0.x.20373] 
[0.x.20374] 
[0.x.20375] 
//
[0.x.20376] 
[0.x.20377] 
[0.x.20378] 
[0.x.20379] 
[0.x.20380] 
//
[0.x.20381] 
[0.x.20382] 
//
[0.x.20383] 
[0.x.20384] 
[0.x.20385] 
[0.x.20386] 
[0.x.20387] 
[0.x.20388] 
//[2.x.2720] 
//
// In the following, we define classes that describe the right hand side function, the Dirichlet boundary values, and the height of the obstacle as a function of  [2.x.2721] . In all three cases, we derive these classes from Function [2.x.2722]  although in the case of  [2.x.2723]  and  [2.x.2724]  this is more out of convention than necessity since we never pass such objects to the library. In any case, the definition of the right hand side and boundary values classes is obvious given our choice of  [2.x.2725] ,  [2.x.2726] :
//
[0.x.20389] 
[0.x.20390] 
[0.x.20391] 
[0.x.20392] 
[0.x.20393] 
[0.x.20394] 
[0.x.20395] 
[0.x.20396] 
[0.x.20397] 
//
[0.x.20398] 
[0.x.20399] 
[0.x.20400] 
//
[0.x.20401] 
[0.x.20402] 
[0.x.20403] 
[0.x.20404] 
[0.x.20405] 
[0.x.20406] 
[0.x.20407] 
[0.x.20408] 
[0.x.20409] 
//
[0.x.20410] 
[0.x.20411] 
[0.x.20412] 
//
// We describe the obstacle function by a cascaded barrier (think: stair steps):
//
[0.x.20413] 
[0.x.20414] 
[0.x.20415] 
[0.x.20416] 
[0.x.20417] 
[0.x.20418] 
[0.x.20419] 
[0.x.20420] 
[0.x.20421] 
//
[0.x.20422] 
[0.x.20423] 
[0.x.20424] 
[0.x.20425] 
[0.x.20426] 
[0.x.20427] 
[0.x.20428] 
[0.x.20429] 
[0.x.20430] 
[0.x.20431] 
//
//  [2.x.2727] 
//[2.x.2728] 
//
// To everyone who has taken a look at the first few tutorial programs, the constructor is completely obvious:
//
[0.x.20432] 
[0.x.20433] 
[0.x.20434] 
[0.x.20435] 
[0.x.20436] 
//[2.x.2729] 
//
// We solve our obstacle problem on the square  [2.x.2730]  in 2D. This function therefore just sets up one of the simplest possible meshes.
//
[0.x.20437] 
[0.x.20438] 
[0.x.20439] 
[0.x.20440] 
[0.x.20441] 
//
[0.x.20442] 
[0.x.20443] 
[0.x.20444] 
[0.x.20445] 
[0.x.20446] 
//[2.x.2731] 
//
// In this first function of note, we set up the degrees of freedom handler, resize vectors and matrices, and deal with the constraints. Initially, the constraints are, of course, only given by boundary values, so we interpolate them towards the top of the function.
//
[0.x.20447] 
[0.x.20448] 
[0.x.20449] 
[0.x.20450] 
[0.x.20451] 
//
[0.x.20452] 
[0.x.20453] 
[0.x.20454] 
//
[0.x.20455] 
[0.x.20456] 
[0.x.20457] 
[0.x.20458] 
[0.x.20459] 
//
[0.x.20460] 
[0.x.20461] 
//
[0.x.20462] 
[0.x.20463] 
//
[0.x.20464] 
[0.x.20465] 
[0.x.20466] 
[0.x.20467] 
[0.x.20468] 
//
// The only other thing to do here is to compute the factors in the  [2.x.2732]  matrix which is used to scale the residual. As discussed in the introduction, we'll use a little trick to make this mass matrix diagonal, and in the following then first compute all of this as a matrix and then extract the diagonal elements for later use:
//
[0.x.20469] 
[0.x.20470] 
[0.x.20471] 
[0.x.20472] 
[0.x.20473] 
[0.x.20474] 
[0.x.20475] 
//[2.x.2733] 
//
// This function at once assembles the system matrix and right-hand-side and applied the constraints (both due to the active set as well as from boundary values) to our system. Otherwise, it is functionally equivalent to the corresponding function in, for example,  [2.x.2734] .
//
[0.x.20476] 
[0.x.20477] 
[0.x.20478] 
[0.x.20479] 
//
[0.x.20480] 
[0.x.20481] 
//
[0.x.20482] 
[0.x.20483] 
//
[0.x.20484] 
[0.x.20485] 
[0.x.20486] 
[0.x.20487] 
//
[0.x.20488] 
[0.x.20489] 
//
[0.x.20490] 
[0.x.20491] 
//
[0.x.20492] 
//
[0.x.20493] 
[0.x.20494] 
[0.x.20495] 
[0.x.20496] 
[0.x.20497] 
//
[0.x.20498] 
[0.x.20499] 
[0.x.20500] 
[0.x.20501] 
[0.x.20502] 
[0.x.20503] 
[0.x.20504] 
//
[0.x.20505] 
[0.x.20506] 
[0.x.20507] 
[0.x.20508] 
[0.x.20509] 
//
[0.x.20510] 
//
[0.x.20511] 
[0.x.20512] 
[0.x.20513] 
[0.x.20514] 
[0.x.20515] 
[0.x.20516] 
[0.x.20517] 
[0.x.20518] 
//
//  [2.x.2735] 
//
// The next function is used in the computation of the diagonal mass matrix  [2.x.2736]  used to scale variables in the active set method. As discussed in the introduction, we get the mass matrix to be diagonal by choosing the trapezoidal rule for quadrature. Doing so we don't really need the triple loop over quadrature points, indices  [2.x.2737]  and indices  [2.x.2738]  any more and can, instead, just use a double loop. The rest of the function is obvious given what we have discussed in many of the previous tutorial programs.
//
// Note that at the time this function is called, the constraints object only contains boundary value constraints; we therefore do not have to pay attention in the last copy-local-to-global step to preserve the values of matrix entries that may later on be constrained by the active set.
//
// Note also that the trick with the trapezoidal rule only works if we have in fact  [2.x.2739]  elements. For higher order elements, one would need to use a quadrature formula that has quadrature points at all the support points of the finite element. Constructing such a quadrature formula isn't really difficult, but not the point here, and so we simply assert at the top of the function that our implicit assumption about the finite element is in fact satisfied.
//
[0.x.20519] 
[0.x.20520] 
[0.x.20521] 
[0.x.20522] 
[0.x.20523] 
//
[0.x.20524] 
[0.x.20525] 
[0.x.20526] 
[0.x.20527] 
//
[0.x.20528] 
[0.x.20529] 
//
[0.x.20530] 
[0.x.20531] 
//
[0.x.20532] 
[0.x.20533] 
[0.x.20534] 
[0.x.20535] 
//
[0.x.20536] 
[0.x.20537] 
[0.x.20538] 
[0.x.20539] 
[0.x.20540] 
//
[0.x.20541] 
//
[0.x.20542] 
[0.x.20543] 
[0.x.20544] 
[0.x.20545] 
[0.x.20546] 
//[2.x.2740] 
//
// In a sense, this is the central function of this program.  It updates the active set of constrained degrees of freedom as discussed in the introduction and computes an AffineConstraints object from it that can then be used to eliminate constrained degrees of freedom from the solution of the next iteration. At the same time we set the constrained degrees of freedom of the solution to the correct value, namely the height of the obstacle.
//
// Fundamentally, the function is rather simple: We have to loop over all degrees of freedom and check the sign of the function  [2.x.2741]  because in our case  [2.x.2742] . To this end, we use the formula given in the introduction by which we can compute the Lagrange multiplier as the residual of the original linear system (given via the variables  [2.x.2743] . At the top of this function, we compute this residual using a function that is part of the matrix classes.
//
[0.x.20547] 
[0.x.20548] 
[0.x.20549] 
[0.x.20550] 
//
[0.x.20551] 
//
[0.x.20552] 
[0.x.20553] 
[0.x.20554] 
//
// compute contact_force[i] =
//
// - lambda[i] * diagonal_of_mass_matrix[i]
//
[0.x.20555] 
[0.x.20556] 
[0.x.20557] 
//
// The next step is to reset the active set and constraints objects and to start the loop over all degrees of freedom. This is made slightly more complicated by the fact that we can't just loop over all elements of the solution vector since there is no way for us then to find out what location a DoF is associated with; however, we need this location to test whether the displacement of a DoF is larger or smaller than the height of the obstacle at this location.
//
// We work around this by looping over all cells and DoFs defined on each of these cells. We use here that the displacement is described using a  [2.x.2744]  function for which degrees of freedom are always located on the vertices of the cell; thus, we can get the index of each degree of freedom and its location by asking the vertex for this information. On the other hand, this clearly wouldn't work for higher order elements, and so we add an assertion that makes sure that we only deal with elements for which all degrees of freedom are located in vertices to avoid tripping ourselves with non-functional code in case someone wants to play with increasing the polynomial degree of the solution.
//
// The price to pay for having to loop over cells rather than DoFs is that we may encounter some degrees of freedom more than once, namely each time we visit one of the cells adjacent to a given vertex. We will therefore have to keep track which vertices we have already touched and which we haven't so far. We do so by using an array of flags  [2.x.2745] :
//
[0.x.20558] 
[0.x.20559] 
//
[0.x.20560] 
[0.x.20561] 
//
[0.x.20562] 
[0.x.20563] 
[0.x.20564] 
[0.x.20565] 
[0.x.20566] 
//
[0.x.20567] 
//
[0.x.20568] 
[0.x.20569] 
[0.x.20570] 
[0.x.20571] 
//
// Now that we know that we haven't touched this DoF yet, let's get the value of the displacement function there as well as the value of the obstacle function and use this to decide whether the current DoF belongs to the active set. For that we use the function given above and in the introduction.
//
// If we decide that the DoF should be part of the active set, we add its index to the active set, introduce an inhomogeneous equality constraint in the AffineConstraints object, and reset the solution value to the height of the obstacle. Finally, the residual of the non-contact part of the system serves as an additional control (the residual equals the remaining, unaccounted forces, and should be zero outside the contact zone), so we zero out the components of the residual vector (i.e., the Lagrange multiplier lambda) that correspond to the area where the body is in contact; at the end of the loop over all cells, the residual will therefore only consist of the residual in the non-contact zone. We output the norm of this residual along with the size of the active set after the loop.
//
[0.x.20572] 
[0.x.20573] 
//
[0.x.20574] 
[0.x.20575] 
[0.x.20576] 
[0.x.20577] 
[0.x.20578] 
[0.x.20579] 
[0.x.20580] 
[0.x.20581] 
//
[0.x.20582] 
//
[0.x.20583] 
[0.x.20584] 
[0.x.20585] 
[0.x.20586] 
[0.x.20587] 
//
[0.x.20588] 
[0.x.20589] 
//
// In a final step, we add to the set of constraints on DoFs we have so far from the active set those that result from Dirichlet boundary values, and close the constraints object:
//
[0.x.20590] 
[0.x.20591] 
[0.x.20592] 
[0.x.20593] 
[0.x.20594] 
[0.x.20595] 
//[2.x.2746] 
//
// There is nothing to say really about the solve function. In the context of a Newton method, we are not typically interested in very high accuracy (why ask for a highly accurate solution of a linear problem that we know only gives us an approximation of the solution of the nonlinear problem), and so we use the ReductionControl class that stops iterations when either an absolute tolerance is reached (for which we choose  [2.x.2747] ) or when the residual is reduced by a certain factor (here,  [2.x.2748] ).
//
[0.x.20596] 
[0.x.20597] 
[0.x.20598] 
[0.x.20599] 
//
[0.x.20600] 
[0.x.20601] 
[0.x.20602] 
[0.x.20603] 
//
[0.x.20604] 
[0.x.20605] 
//
[0.x.20606] 
[0.x.20607] 
[0.x.20608] 
[0.x.20609] 
[0.x.20610] 
//[2.x.2749] 
//
// We use the vtk-format for the output.  The file contains the displacement and a numerical representation of the active set.
//
[0.x.20611] 
[0.x.20612] 
[0.x.20613] 
[0.x.20614] 
//
[0.x.20615] 
[0.x.20616] 
[0.x.20617] 
[0.x.20618] 
//
[0.x.20619] 
//
[0.x.20620] 
[0.x.20621] 
[0.x.20622] 
[0.x.20623] 
//
[0.x.20624] 
//
[0.x.20625] 
[0.x.20626] 
[0.x.20627] 
[0.x.20628] 
//
//  [2.x.2750] 
//
// This is the function which has the top-level control over everything.  It is not very long, and in fact rather straightforward: in every iteration of the active set method, we assemble the linear system, solve it, update the active set and project the solution back to the feasible set, and then output the results. The iteration is terminated whenever the active set has not changed in the previous iteration.
//
// The only trickier part is that we have to save the linear system (i.e., the matrix and right hand side) after assembling it in the first iteration. The reason is that this is the only step where we can access the linear system as built without any of the contact constraints active. We need this to compute the residual of the solution at other iterations, but in other iterations that linear system we form has the rows and columns that correspond to constrained degrees of freedom eliminated, and so we can no longer access the full residual of the original equation.
//
[0.x.20629] 
[0.x.20630] 
[0.x.20631] 
[0.x.20632] 
[0.x.20633] 
//
[0.x.20634] 
[0.x.20635] 
[0.x.20636] 
[0.x.20637] 
//
[0.x.20638] 
//
[0.x.20639] 
[0.x.20640] 
[0.x.20641] 
[0.x.20642] 
[0.x.20643] 
//
[0.x.20644] 
[0.x.20645] 
[0.x.20646] 
//
[0.x.20647] 
[0.x.20648] 
//
[0.x.20649] 
//
[0.x.20650] 
[0.x.20651] 
[0.x.20652] 
[0.x.20653] 
//[2.x.2751] 
//
// And this is the main function. It follows the pattern of all other main functions. The call to initialize MPI exists because the Trilinos library upon which we build our linear solvers in this program requires it.
//
[0.x.20654] 
[0.x.20655] 
[0.x.20656] 
[0.x.20657] 
[0.x.20658] 
[0.x.20659] 
//
[0.x.20660] 
[0.x.20661] 
//
// This program can only be run in serial. Otherwise, throw an exception.
//
[0.x.20662] 
[0.x.20663] 
[0.x.20664] 
//
[0.x.20665] 
[0.x.20666] 
[0.x.20667] 
[0.x.20668] 
[0.x.20669] 
[0.x.20670] 
[0.x.20671] 
[0.x.20672] 
[0.x.20673] 
[0.x.20674] 
[0.x.20675] 
[0.x.20676] 
[0.x.20677] 
[0.x.20678] 
//
[0.x.20679] 
[0.x.20680] 
[0.x.20681] 
[0.x.20682] 
[0.x.20683] 
[0.x.20684] 
[0.x.20685] 
[0.x.20686] 
[0.x.20687] 
[0.x.20688] 
[0.x.20689] 
[0.x.20690] 
[0.x.20691] 
[0.x.20692] 
//
[0.x.20693] 
[0.x.20694] 
[0.x.20695] 
[0.x.20696] 
[0.x.20697] 
[0.x.20698] 
[0.x.20699] 
[0.x.20700] 
[0.x.20701] 
[0.x.20702] 
[0.x.20703] 
[0.x.20704] 
[0.x.20705] 
[0.x.20706] 
[0.x.20707] 
[0.x.20708] 
//
[0.x.20709] 
[0.x.20710] 
[0.x.20711] 
[0.x.20712] 
[0.x.20713] 
[0.x.20714] 
//[2.x.2752]  The set of include files is not much of a surprise any more at this time:
//
[0.x.20715] 
[0.x.20716] 
[0.x.20717] 
[0.x.20718] 
[0.x.20719] 
[0.x.20720] 
[0.x.20721] 
//
[0.x.20722] 
[0.x.20723] 
[0.x.20724] 
[0.x.20725] 
[0.x.20726] 
[0.x.20727] 
[0.x.20728] 
[0.x.20729] 
[0.x.20730] 
[0.x.20731] 
[0.x.20732] 
[0.x.20733] 
[0.x.20734] 
[0.x.20735] 
//
[0.x.20736] 
[0.x.20737] 
[0.x.20738] 
[0.x.20739] 
//
[0.x.20740] 
[0.x.20741] 
[0.x.20742] 
//
[0.x.20743] 
[0.x.20744] 
[0.x.20745] 
//
[0.x.20746] 
[0.x.20747] 
[0.x.20748] 
//
[0.x.20749] 
[0.x.20750] 
[0.x.20751] 
[0.x.20752] 
[0.x.20753] 
//
[0.x.20754] 
[0.x.20755] 
//
// Finally, we include two system headers that let us create a directory for output files. The first header provides the  [2.x.2753]  function and the second lets us determine what happened if  [2.x.2754]  fails.
//
[0.x.20756] 
[0.x.20757] 
//
[0.x.20758] 
[0.x.20759] 
[0.x.20760] 
//[2.x.2755] 
//
// This class provides an interface for a constitutive law, i.e., for the relationship between strain  [2.x.2756]  and stress  [2.x.2757] . In this example we are using an elastoplastic material behavior with linear, isotropic hardening. Such materials are characterized by Young's modulus  [2.x.2758] , Poisson's ratio  [2.x.2759] , the initial yield stress  [2.x.2760]  and the isotropic hardening parameter  [2.x.2761] .  For  [2.x.2762]  we obtain perfect elastoplastic behavior.
//
// As explained in the paper that describes this program, the first Newton steps are solved with a completely elastic material model to avoid having to deal with both nonlinearities (plasticity and contact) at once. To this end, this class has a function  [2.x.2763]  that we use later on to simply set  [2.x.2764]  to a very large value -- essentially guaranteeing that the actual stress will not exceed it, and thereby producing an elastic material. When we are ready to use a plastic model, we set  [2.x.2765]  back to its proper value, using the same function.  As a result of this approach, we need to leave  [2.x.2766]  as the only non-const member variable of this class.
//
[0.x.20761] 
[0.x.20762] 
[0.x.20763] 
[0.x.20764] 
[0.x.20765] 
[0.x.20766] 
[0.x.20767] 
[0.x.20768] 
//
[0.x.20769] 
//
[0.x.20770] 
[0.x.20771] 
[0.x.20772] 
//
[0.x.20773] 
[0.x.20774] 
[0.x.20775] 
[0.x.20776] 
//
[0.x.20777] 
[0.x.20778] 
[0.x.20779] 
[0.x.20780] 
[0.x.20781] 
//
[0.x.20782] 
[0.x.20783] 
[0.x.20784] 
//
// The constructor of the ConstitutiveLaw class sets the required material parameter for our deformable body. Material parameters for elastic isotropic media can be defined in a variety of ways, such as the pair  [2.x.2767]  (elastic modulus and Poisson's number), using the Lam&eacute; parameters  [2.x.2768]  or several other commonly used conventions. Here, the constructor takes a description of material parameters in the form of  [2.x.2769] , but since this turns out to these are not the coefficients that appear in the equations of the plastic projector, we immediately convert them into the more suitable set  [2.x.2770]  of bulk and shear moduli.  In addition, the constructor takes  [2.x.2771]  (the yield stress absent any plastic strain) and  [2.x.2772]  (the hardening parameter) as arguments. In this constructor, we also compute the two principal components of the stress-strain relation and its linearization.
//
[0.x.20785] 
[0.x.20786] 
[0.x.20787] 
[0.x.20788] 
[0.x.20789] 
[0.x.20790] 
[0.x.20791] 
[0.x.20792] 
[0.x.20793] 
[0.x.20794] 
[0.x.20795] 
[0.x.20796] 
[0.x.20797] 
[0.x.20798] 
[0.x.20799] 
[0.x.20800] 
[0.x.20801] 
[0.x.20802] 
//
[0.x.20803] 
[0.x.20804] 
[0.x.20805] 
[0.x.20806] 
[0.x.20807] 
//[2.x.2773] 
//
// This is the principal component of the constitutive law. It computes the fourth order symmetric tensor that relates the strain to the stress according to the projection given above, when evaluated at a particular strain point. We need this function to calculate the nonlinear residual in  [2.x.2774]  where we multiply this tensor with the strain given in a quadrature point. The computations follow the formulas laid out in the introduction. In comparing the formulas there with the implementation below, recall that  [2.x.2775]  and that  [2.x.2776] .
//
// The function returns whether the quadrature point is plastic to allow for some statistics downstream on how many of the quadrature points are plastic and how many are elastic.
//
[0.x.20808] 
[0.x.20809] 
[0.x.20810] 
[0.x.20811] 
[0.x.20812] 
[0.x.20813] 
//
[0.x.20814] 
[0.x.20815] 
[0.x.20816] 
//
[0.x.20817] 
[0.x.20818] 
[0.x.20819] 
//
[0.x.20820] 
[0.x.20821] 
[0.x.20822] 
[0.x.20823] 
[0.x.20824] 
[0.x.20825] 
//
[0.x.20826] 
//
[0.x.20827] 
[0.x.20828] 
//[2.x.2777] 
//
// This function returns the linearized stress strain tensor, linearized around the solution  [2.x.2778]  of the previous Newton step  [2.x.2779] .  The parameter  [2.x.2780]  (commonly denoted  [2.x.2781] ) must be passed as an argument, and serves as the linearization point. The function returns the derivative of the nonlinear constitutive law in the variable stress_strain_tensor, as well as the stress-strain tensor of the linearized problem in stress_strain_tensor_linearized.  See  [2.x.2782]  where this function is used.
//
[0.x.20829] 
[0.x.20830] 
[0.x.20831] 
[0.x.20832] 
[0.x.20833] 
[0.x.20834] 
[0.x.20835] 
//
[0.x.20836] 
[0.x.20837] 
[0.x.20838] 
//
[0.x.20839] 
[0.x.20840] 
//
[0.x.20841] 
[0.x.20842] 
//
[0.x.20843] 
[0.x.20844] 
[0.x.20845] 
[0.x.20846] 
[0.x.20847] 
[0.x.20848] 
[0.x.20849] 
[0.x.20850] 
[0.x.20851] 
[0.x.20852] 
//
[0.x.20853] 
[0.x.20854] 
[0.x.20855] 
//[1.x.88]
//
// The following should be relatively standard. We need classes for the boundary forcing term (which we here choose to be zero) and boundary values on those part of the boundary that are not part of the contact surface (also chosen to be zero here).
//
[0.x.20856] 
[0.x.20857] 
[0.x.20858] 
[0.x.20859] 
[0.x.20860] 
[0.x.20861] 
[0.x.20862] 
//
[0.x.20863] 
[0.x.20864] 
//
[0.x.20865] 
[0.x.20866] 
[0.x.20867] 
//
[0.x.20868] 
[0.x.20869] 
[0.x.20870] 
[0.x.20871] 
//
[0.x.20872] 
[0.x.20873] 
[0.x.20874] 
[0.x.20875] 
[0.x.20876] 
[0.x.20877] 
//
[0.x.20878] 
[0.x.20879] 
[0.x.20880] 
[0.x.20881] 
[0.x.20882] 
[0.x.20883] 
[0.x.20884] 
//
[0.x.20885] 
[0.x.20886] 
[0.x.20887] 
[0.x.20888] 
[0.x.20889] 
//
[0.x.20890] 
[0.x.20891] 
[0.x.20892] 
//
[0.x.20893] 
[0.x.20894] 
[0.x.20895] 
[0.x.20896] 
//
[0.x.20897] 
[0.x.20898] 
[0.x.20899] 
[0.x.20900] 
[0.x.20901] 
[0.x.20902] 
//
//  [2.x.2783] 
//
// The following class is the first of two obstacles that can be selected from the input file. It describes a sphere centered at position  [2.x.2784]  and radius  [2.x.2785] , where  [2.x.2786]  is the vertical position of the (flat) surface of the deformable body. The function's  [2.x.2787]  returns the location of the obstacle for a given  [2.x.2788]  value if the point actually lies below the sphere, or a large positive value that can't possibly interfere with the deformation if it lies outside the "shadow" of the sphere.
//
[0.x.20903] 
[0.x.20904] 
[0.x.20905] 
[0.x.20906] 
[0.x.20907] 
//
[0.x.20908] 
[0.x.20909] 
//
[0.x.20910] 
[0.x.20911] 
//
[0.x.20912] 
[0.x.20913] 
[0.x.20914] 
//
[0.x.20915] 
[0.x.20916] 
[0.x.20917] 
[0.x.20918] 
[0.x.20919] 
//
[0.x.20920] 
[0.x.20921] 
[0.x.20922] 
[0.x.20923] 
[0.x.20924] 
[0.x.20925] 
[0.x.20926] 
[0.x.20927] 
[0.x.20928] 
[0.x.20929] 
[0.x.20930] 
[0.x.20931] 
[0.x.20932] 
[0.x.20933] 
[0.x.20934] 
[0.x.20935] 
[0.x.20936] 
//
[0.x.20937] 
[0.x.20938] 
//
//         preceding Assert
//
[0.x.20939] 
//
[0.x.20940] 
[0.x.20941] 
[0.x.20942] 
[0.x.20943] 
[0.x.20944] 
[0.x.20945] 
[0.x.20946] 
//[2.x.2789] 
//
// The following two classes describe the obstacle outlined in the introduction, i.e., the Chinese character. The first of the two,  [2.x.2790]  is responsible for reading in data from a picture file stored in pbm ascii format. This data will be bilinearly interpolated and thereby provides a function that describes the obstacle. (The code below shows how one can construct a function by interpolating between given data points. One could use the  [2.x.2791]  introduced after this tutorial program was written, which does exactly what we want here, but it is instructive to see how to do it by hand.)
//
// The data which we read from the file will be stored in a double  [2.x.2792]  named obstacle_data.  This vector composes the base to calculate a piecewise bilinear function as a polynomial interpolation. The data we will read from a file consists of zeros (white) and ones (black).
//
// The  [2.x.2793]  variables denote the spacing between pixels in  [2.x.2794]  and  [2.x.2795]  directions.  [2.x.2796]  are the numbers of pixels in each of these directions.   [2.x.2797]  returns the value of the image at a given location, interpolated from the adjacent pixel values.
//
[0.x.20947] 
[0.x.20948] 
[0.x.20949] 
[0.x.20950] 
[0.x.20951] 
//
[0.x.20952] 
//
[0.x.20953] 
[0.x.20954] 
[0.x.20955] 
[0.x.20956] 
//
[0.x.20957] 
[0.x.20958] 
//
// The constructor of this class reads in the data that describes the obstacle from the given file name.
//
[0.x.20959] 
[0.x.20960] 
[0.x.20961] 
[0.x.20962] 
[0.x.20963] 
[0.x.20964] 
[0.x.20965] 
[0.x.20966] 
[0.x.20967] 
[0.x.20968] 
[0.x.20969] 
[0.x.20970] 
//
[0.x.20971] 
[0.x.20972] 
//
[0.x.20973] 
//
[0.x.20974] 
[0.x.20975] 
[0.x.20976] 
[0.x.20977] 
[0.x.20978] 
[0.x.20979] 
//
[0.x.20980] 
[0.x.20981] 
//
[0.x.20982] 
[0.x.20983] 
[0.x.20984] 
[0.x.20985] 
[0.x.20986] 
//
// The following two functions return the value of a given pixel with coordinates  [2.x.2798] , which we identify with the values of a function defined at positions  [2.x.2799] , and at arbitrary coordinates  [2.x.2800]  where we do a bilinear interpolation between point values returned by the first of the two functions. In the second function, for each  [2.x.2801] , we first compute the (integer) location of the nearest pixel coordinate to the bottom left of  [2.x.2802] , and then compute the coordinates  [2.x.2803]  within this pixel. We truncate both kinds of variables from both below and above to avoid problems when evaluating the function outside of its defined range as may happen due to roundoff errors.
//
[0.x.20987] 
[0.x.20988] 
[0.x.20989] 
[0.x.20990] 
[0.x.20991] 
[0.x.20992] 
[0.x.20993] 
//
[0.x.20994] 
[0.x.20995] 
[0.x.20996] 
[0.x.20997] 
[0.x.20998] 
//
[0.x.20999] 
[0.x.21000] 
//
[0.x.21001] 
[0.x.21002] 
[0.x.21003] 
[0.x.21004] 
[0.x.21005] 
//
// Finally, this is the class that actually uses the class above. It has a BitmapFile object as a member that describes the height of the obstacle. As mentioned above, the BitmapFile class will provide us with a mask, i.e., values that are either zero or one (and, if you ask for locations between pixels, values that are interpolated between zero and one). This class translates this to heights that are either 0.001 below the surface of the deformable body (if the BitmapFile class reports a one at this location) or 0.999 above the obstacle (if the BitmapFile class reports a zero). The following function should then be self-explanatory.
//
[0.x.21006] 
[0.x.21007] 
[0.x.21008] 
[0.x.21009] 
[0.x.21010] 
//
[0.x.21011] 
[0.x.21012] 
//
[0.x.21013] 
[0.x.21014] 
//
[0.x.21015] 
[0.x.21016] 
[0.x.21017] 
[0.x.21018] 
//
[0.x.21019] 
[0.x.21020] 
[0.x.21021] 
[0.x.21022] 
[0.x.21023] 
[0.x.21024] 
[0.x.21025] 
//
[0.x.21026] 
[0.x.21027] 
[0.x.21028] 
[0.x.21029] 
[0.x.21030] 
[0.x.21031] 
[0.x.21032] 
[0.x.21033] 
[0.x.21034] 
[0.x.21035] 
[0.x.21036] 
[0.x.21037] 
[0.x.21038] 
//
[0.x.21039] 
[0.x.21040] 
//
//         preceding Assert
//
[0.x.21041] 
//
[0.x.21042] 
[0.x.21043] 
[0.x.21044] 
[0.x.21045] 
[0.x.21046] 
[0.x.21047] 
[0.x.21048] 
[0.x.21049] 
//[2.x.2804] 
//
// This is the main class of this program and supplies all functions and variables needed to describe the nonlinear contact problem. It is close to  [2.x.2805]  but with some additional features like handling hanging nodes, a Newton method, using Trilinos and p4est for parallel distributed computing. To deal with hanging nodes makes life a bit more complicated since we need another AffineConstraints object now. We create a Newton method for the active set method for the contact situation and to handle the nonlinear operator for the constitutive law.
//
// The general layout of this class is very much like for most other tutorial programs. To make our life a bit easier, this class reads a set of input parameters from an input file. These parameters, using the ParameterHandler class, are declared in the  [2.x.2806]  function (which is static so that it can be called before we even create an object of the current type), and a ParameterHandler object that has been used to read an input file will then be passed to the constructor of this class.
//
// The remaining member functions are by and large as we have seen in several of the other tutorial programs, though with additions for the current nonlinear system. We will comment on their purpose as we get to them further below.
//
[0.x.21050] 
[0.x.21051] 
[0.x.21052] 
[0.x.21053] 
[0.x.21054] 
//
[0.x.21055] 
//
[0.x.21056] 
//
[0.x.21057] 
[0.x.21058] 
[0.x.21059] 
[0.x.21060] 
[0.x.21061] 
[0.x.21062] 
[0.x.21063] 
[0.x.21064] 
[0.x.21065] 
[0.x.21066] 
[0.x.21067] 
[0.x.21068] 
[0.x.21069] 
[0.x.21070] 
[0.x.21071] 
[0.x.21072] 
//
[0.x.21073] 
//
// As far as member variables are concerned, we start with ones that we use to indicate the MPI universe this program runs on, a stream we use to let exactly one processor produce output to the console (see  [2.x.2807] ) and a variable that is used to time the various sections of the program:
//
[0.x.21074] 
[0.x.21075] 
[0.x.21076] 
//
// The next group describes the mesh and the finite element space. In particular, for this parallel program, the finite element space has associated with it variables that indicate which degrees of freedom live on the current processor (the index sets, see also  [2.x.2808]  and the  [2.x.2809]  documentation module) as well as a variety of constraints: those imposed by hanging nodes, by Dirichlet boundary conditions, and by the active set of contact nodes. Of the three AffineConstraints variables defined here, the first only contains hanging node constraints, the second also those associated with Dirichlet boundary conditions, and the third these plus the contact constraints.
//
// The variable  [2.x.2810]  consists of those degrees of freedom constrained by the contact, and we use  [2.x.2811]  to keep track of the fraction of quadrature points on each cell where the stress equals the yield stress. The latter is only used to create graphical output showing the plastic zone, but not for any further computation; the variable is a member variable of this class since the information is computed as a by-product of computing the residual, but is used only much later. (Note that the vector is a vector of length equal to the number of active cells on the [1.x.89]; it is never used to exchange information between processors and can therefore be a regular deal.II vector.)
//
[0.x.21077] 
[0.x.21078] 
//
[0.x.21079] 
[0.x.21080] 
[0.x.21081] 
//
[0.x.21082] 
[0.x.21083] 
//
[0.x.21084] 
[0.x.21085] 
[0.x.21086] 
//
[0.x.21087] 
[0.x.21088] 
//
// The next block of variables corresponds to the solution and the linear systems we need to form. In particular, this includes the Newton matrix and right hand side; the vector that corresponds to the residual (i.e., the Newton right hand side) but from which we have not eliminated the various constraints and that is used to determine which degrees of freedom need to be constrained in the next iteration; and a vector that corresponds to the diagonal of the  [2.x.2812]  matrix briefly mentioned in the introduction and discussed in the accompanying paper.
//
[0.x.21089] 
//
[0.x.21090] 
[0.x.21091] 
[0.x.21092] 
[0.x.21093] 
//
// The next block contains the variables that describe the material response:
//
[0.x.21094] 
[0.x.21095] 
//
// And then there is an assortment of other variables that are used to identify the mesh we are asked to build as selected by the parameter file, the obstacle that is being pushed into the deformable body, the mesh refinement strategy, whether to transfer the solution from one mesh to the next, and how many mesh refinement cycles to perform. As possible, we mark these kinds of variables as  [2.x.2813]  to help the reader identify which ones may or may not be modified later on (the output directory being an exception -- it is never modified outside the constructor but it is awkward to initialize in the member-initializer-list following the colon in the constructor since there we have only one shot at setting it; the same is true for the mesh refinement criterion):
//
[0.x.21096] 
[0.x.21097] 
//
[0.x.21098] 
[0.x.21099] 
[0.x.21100] 
[0.x.21101] 
[0.x.21102] 
[0.x.21103] 
[0.x.21104] 
[0.x.21105] 
[0.x.21106] 
[0.x.21107] 
//
[0.x.21108] 
[0.x.21109] 
[0.x.21110] 
[0.x.21111] 
[0.x.21112] 
//[2.x.2814] 
//[2.x.2815] 
//
// Let us start with the declaration of run-time parameters that can be selected in the input file. These values will be read back in the constructor of this class to initialize the member variables of this class:
//
[0.x.21113] 
[0.x.21114] 
[0.x.21115] 
[0.x.21116] 
[0.x.21117] 
[0.x.21118] 
[0.x.21119] 
[0.x.21120] 
[0.x.21121] 
[0.x.21122] 
[0.x.21123] 
[0.x.21124] 
[0.x.21125] 
[0.x.21126] 
[0.x.21127] 
[0.x.21128] 
[0.x.21129] 
[0.x.21130] 
[0.x.21131] 
[0.x.21132] 
[0.x.21133] 
[0.x.21134] 
[0.x.21135] 
[0.x.21136] 
[0.x.21137] 
[0.x.21138] 
[0.x.21139] 
[0.x.21140] 
[0.x.21141] 
[0.x.21142] 
[0.x.21143] 
[0.x.21144] 
[0.x.21145] 
[0.x.21146] 
[0.x.21147] 
[0.x.21148] 
[0.x.21149] 
[0.x.21150] 
[0.x.21151] 
[0.x.21152] 
[0.x.21153] 
[0.x.21154] 
[0.x.21155] 
[0.x.21156] 
[0.x.21157] 
[0.x.21158] 
[0.x.21159] 
[0.x.21160] 
[0.x.21161] 
[0.x.21162] 
//[2.x.2816] 
//
// Given the declarations of member variables as well as the declarations of run-time parameters that are read from the input file, there is nothing surprising in this constructor. In the body we initialize the mesh refinement strategy and the output directory, creating such a directory if necessary.
//
[0.x.21163] 
[0.x.21164] 
[0.x.21165] 
[0.x.21166] 
[0.x.21167] 
[0.x.21168] 
[0.x.21169] 
[0.x.21170] 
[0.x.21171] 
[0.x.21172] 
//
[0.x.21173] 
[0.x.21174] 
[0.x.21175] 
[0.x.21176] 
[0.x.21177] 
[0.x.21178] 
//
[0.x.21179] 
[0.x.21180] 
[0.x.21181] 
[0.x.21182] 
[0.x.21183] 
//
[0.x.21184] 
[0.x.21185] 
[0.x.21186] 
[0.x.21187] 
[0.x.21188] 
[0.x.21189] 
[0.x.21190] 
[0.x.21191] 
[0.x.21192] 
//
[0.x.21193] 
[0.x.21194] 
[0.x.21195] 
//
[0.x.21196] 
[0.x.21197] 
[0.x.21198] 
[0.x.21199] 
[0.x.21200] 
[0.x.21201] 
[0.x.21202] 
[0.x.21203] 
//
[0.x.21204] 
[0.x.21205] 
[0.x.21206] 
//
// If necessary, create a new directory for the output.
//
[0.x.21207] 
[0.x.21208] 
[0.x.21209] 
[0.x.21210] 
[0.x.21211] 
//
[0.x.21212] 
[0.x.21213] 
[0.x.21214] 
[0.x.21215] 
[0.x.21216] 
//
//  [2.x.2817] 
//
// The next block deals with constructing the starting mesh. We will use the following helper function and the first block of the  [2.x.2818]  to construct a mesh that corresponds to a half sphere. deal.II has a function that creates such a mesh, but it is in the wrong location and facing the wrong direction, so we need to shift and rotate it a bit before using it.
//
// For later reference, as described in the documentation of  [2.x.2819]  the flat surface of the halfsphere has boundary indicator zero, while the remainder has boundary indicator one.
//
[0.x.21217] 
[0.x.21218] 
[0.x.21219] 
[0.x.21220] 
//
[0.x.21221] 
[0.x.21222] 
[0.x.21223] 
[0.x.21224] 
[0.x.21225] 
[0.x.21226] 
[0.x.21227] 
[0.x.21228] 
//
// Since we will attach a different manifold below, we immediately clear the default manifold description:
//
[0.x.21229] 
//
[0.x.21230] 
[0.x.21231] 
//
[0.x.21232] 
[0.x.21233] 
[0.x.21234] 
[0.x.21235] 
//
// Alternatively, create a hypercube mesh. After creating it, assign boundary indicators as follows: [1.x.90] In other words, the boundary indicators of the sides of the cube are 8. The boundary indicator of the bottom is 6 and the top has indicator 1. We set these by looping over all cells of all faces and looking at coordinate values of the cell center, and will make use of these indicators later when evaluating which boundary will carry Dirichlet boundary conditions or will be subject to potential contact. (In the current case, the mesh contains only a single cell, and all of its faces are on the boundary, so both the loop over all cells and the query whether a face is on the boundary are, strictly speaking, unnecessary; we retain them simply out of habit: this kind of code can be found in many programs in essentially this form.)
//
[0.x.21236] 
[0.x.21237] 
[0.x.21238] 
[0.x.21239] 
//
[0.x.21240] 
//
[0.x.21241] 
[0.x.21242] 
[0.x.21243] 
[0.x.21244] 
[0.x.21245] 
[0.x.21246] 
[0.x.21247] 
[0.x.21248] 
[0.x.21249] 
[0.x.21250] 
[0.x.21251] 
[0.x.21252] 
[0.x.21253] 
[0.x.21254] 
[0.x.21255] 
//
[0.x.21256] 
[0.x.21257] 
//
//  [2.x.2820] 
//
// The next piece in the puzzle is to set up the DoFHandler, resize vectors and take care of various other status variables such as index sets and constraint matrices.
//
// In the following, each group of operations is put into a brace-enclosed block that is being timed by the variable declared at the top of the block (the constructor of the  [2.x.2821]  variable starts the timed section, the destructor that is called at the end of the block stops it again).
//
[0.x.21258] 
[0.x.21259] 
[0.x.21260] 
//
//    /* setup dofs and get index sets for locally owned and relevant dofs  [2.x.2822] 
[0.x.21261] 
[0.x.21262] 
[0.x.21263] 
//
[0.x.21264] 
[0.x.21265] 
[0.x.21266] 
[0.x.21267] 
[0.x.21268] 
//
//    /* setup hanging nodes and Dirichlet constraints  [2.x.2823] 
[0.x.21269] 
[0.x.21270] 
[0.x.21271] 
[0.x.21272] 
[0.x.21273] 
[0.x.21274] 
//
[0.x.21275] 
[0.x.21276] 
[0.x.21277] 
[0.x.21278] 
//
[0.x.21279] 
[0.x.21280] 
//
//    /* initialization of vectors and the active set  [2.x.2824] 
[0.x.21281] 
[0.x.21282] 
[0.x.21283] 
[0.x.21284] 
[0.x.21285] 
[0.x.21286] 
[0.x.21287] 
[0.x.21288] 
//
[0.x.21289] 
[0.x.21290] 
[0.x.21291] 
//
// Finally, we set up sparsity patterns and matrices. We temporarily (ab)use the system matrix to also build the (diagonal) matrix that we use in eliminating degrees of freedom that are in contact with the obstacle, but we then immediately set the Newton matrix back to zero.
//
[0.x.21292] 
[0.x.21293] 
[0.x.21294] 
[0.x.21295] 
//
[0.x.21296] 
[0.x.21297] 
[0.x.21298] 
[0.x.21299] 
[0.x.21300] 
[0.x.21301] 
[0.x.21302] 
[0.x.21303] 
//
[0.x.21304] 
//
[0.x.21305] 
//
[0.x.21306] 
[0.x.21307] 
[0.x.21308] 
[0.x.21309] 
[0.x.21310] 
//
[0.x.21311] 
[0.x.21312] 
[0.x.21313] 
//[2.x.2825] 
//
// This function, broken out of the preceding one, computes the constraints associated with Dirichlet-type boundary conditions and puts them into the  [2.x.2826]  variable by merging with the constraints that come from hanging nodes.
//
// As laid out in the introduction, we need to distinguish between two cases:
//
// - If the domain is a box, we set the displacement to zero at the bottom,   and allow vertical movement in z-direction along the sides. As   shown in the  [2.x.2827]  function, the former corresponds   to boundary indicator 6, the latter to 8.
//
// - If the domain is a half sphere, then we impose zero displacement along   the curved part of the boundary, associated with boundary indicator zero.
//
[0.x.21314] 
[0.x.21315] 
[0.x.21316] 
[0.x.21317] 
[0.x.21318] 
//
[0.x.21319] 
[0.x.21320] 
//
// interpolate all components of the solution
//
[0.x.21321] 
[0.x.21322] 
[0.x.21323] 
[0.x.21324] 
[0.x.21325] 
[0.x.21326] 
//
// interpolate x- and y-components of the solution (this is a bit mask, so apply operator| )
//
[0.x.21327] 
[0.x.21328] 
[0.x.21329] 
[0.x.21330] 
[0.x.21331] 
[0.x.21332] 
[0.x.21333] 
[0.x.21334] 
[0.x.21335] 
[0.x.21336] 
[0.x.21337] 
[0.x.21338] 
[0.x.21339] 
[0.x.21340] 
[0.x.21341] 
[0.x.21342] 
[0.x.21343] 
//
[0.x.21344] 
[0.x.21345] 
//
//  [2.x.2828] 
//
// The next helper function computes the (diagonal) mass matrix that is used to determine the active set of the active set method we use in the contact algorithm. This matrix is of mass matrix type, but unlike the standard mass matrix, we can make it diagonal (even in the case of higher order elements) by using a quadrature formula that has its quadrature points at exactly the same locations as the interpolation points for the finite element are located. We achieve this by using a QGaussLobatto quadrature formula here, along with initializing the finite element with a set of interpolation points derived from the same quadrature formula. The remainder of the function is relatively straightforward: we put the resulting matrix into the given argument; because we know the matrix is diagonal, it is sufficient to have a loop over only  [2.x.2829]  and not over  [2.x.2830] . Strictly speaking, we could even avoid multiplying the shape function's values at quadrature point  [2.x.2831]  by itself because we know the shape value to be a vector with exactly one one which when dotted with itself yields one. Since this function is not time critical we add this term for clarity.
//
[0.x.21346] 
[0.x.21347] 
[0.x.21348] 
[0.x.21349] 
[0.x.21350] 
//
[0.x.21351] 
[0.x.21352] 
[0.x.21353] 
//
[0.x.21354] 
[0.x.21355] 
//
[0.x.21356] 
[0.x.21357] 
//
[0.x.21358] 
//
[0.x.21359] 
[0.x.21360] 
[0.x.21361] 
[0.x.21362] 
[0.x.21363] 
[0.x.21364] 
[0.x.21365] 
//
[0.x.21366] 
[0.x.21367] 
[0.x.21368] 
[0.x.21369] 
[0.x.21370] 
[0.x.21371] 
[0.x.21372] 
//
[0.x.21373] 
//
[0.x.21374] 
[0.x.21375] 
[0.x.21376] 
[0.x.21377] 
[0.x.21378] 
[0.x.21379] 
[0.x.21380] 
//[2.x.2832] 
//
// The following function is the first function we call in each Newton iteration in the  [2.x.2833]  function. What it does is to project the solution onto the feasible set and update the active set for the degrees of freedom that touch or penetrate the obstacle.
//
// In order to function, we first need to do some bookkeeping: We need to write into the solution vector (which we can only do with fully distributed vectors without ghost elements) and we need to read the Lagrange multiplier and the elements of the diagonal mass matrix from their respective vectors (which we can only do with vectors that do have ghost elements), so we create the respective vectors. We then also initialize the constraints object that will contain constraints from contact and all other sources, as well as an object that contains an index set of all locally owned degrees of freedom that are part of the contact:
//
[0.x.21381] 
[0.x.21382] 
[0.x.21383] 
[0.x.21384] 
//
[0.x.21385] 
[0.x.21386] 
[0.x.21387] 
//
[0.x.21388] 
[0.x.21389] 
[0.x.21390] 
//
[0.x.21391] 
[0.x.21392] 
[0.x.21393] 
//
[0.x.21394] 
[0.x.21395] 
//
// The second part is a loop over all cells in which we look at each point where a degree of freedom is defined whether the active set condition is true and we need to add this degree of freedom to the active set of contact nodes. As we always do, if we want to evaluate functions at individual points, we do this with an FEValues object (or, here, an FEFaceValues object since we need to check contact at the surface) with an appropriately chosen quadrature object. We create this face quadrature object by choosing the "support points" of the shape functions defined on the faces of cells (for more on support points, see this  [2.x.2834]  "glossary entry"). As a consequence, we have as many quadrature points as there are shape functions per face and looping over quadrature points is equivalent to looping over shape functions defined on a face. With this, the code looks as follows:
//
[0.x.21396] 
[0.x.21397] 
[0.x.21398] 
[0.x.21399] 
//
[0.x.21400] 
[0.x.21401] 
//
[0.x.21402] 
//
[0.x.21403] 
[0.x.21404] 
[0.x.21405] 
[0.x.21406] 
[0.x.21407] 
[0.x.21408] 
[0.x.21409] 
//
[0.x.21410] 
[0.x.21411] 
[0.x.21412] 
//
//         At each quadrature point (i.e., at each support point of a         degree of freedom located on the contact boundary), we then         ask whether it is part of the z-displacement degrees of         freedom and if we haven't encountered this degree of         freedom yet (which can happen for those on the edges         between faces), we need to evaluate the gap between the         deformed object and the obstacle. If the active set         condition is true, then we add a constraint to the         AffineConstraints object that the next Newton update needs         to satisfy, set the solution vector's corresponding element         to the correct value, and add the index to the IndexSet         object that stores which degree of freedom is part of the         contact:
//
[0.x.21413] 
[0.x.21414] 
//
[0.x.21415] 
//
[0.x.21416] 
[0.x.21417] 
[0.x.21418] 
//
[0.x.21419] 
[0.x.21420] 
//
[0.x.21421] 
[0.x.21422] 
[0.x.21423] 
[0.x.21424] 
[0.x.21425] 
//
[0.x.21426] 
[0.x.21427] 
[0.x.21428] 
[0.x.21429] 
[0.x.21430] 
[0.x.21431] 
[0.x.21432] 
[0.x.21433] 
[0.x.21434] 
[0.x.21435] 
[0.x.21436] 
//
[0.x.21437] 
[0.x.21438] 
[0.x.21439] 
[0.x.21440] 
[0.x.21441] 
//
// At the end of this function, we exchange data between processors updating those ghost elements in the  [2.x.2835]  variable that have been written by other processors. We then merge the Dirichlet constraints and those from hanging nodes into the AffineConstraints object that already contains the active set. We finish the function by outputting the total number of actively constrained degrees of freedom for which we sum over the number of actively constrained degrees of freedom owned by each of the processors. This number of locally owned constrained degrees of freedom is of course the number of elements of the intersection of the active set and the set of locally owned degrees of freedom, which we can get by using  [2.x.2836]  on two IndexSets:
//
[0.x.21442] 
[0.x.21443] 
//
[0.x.21444] 
[0.x.21445] 
//
[0.x.21446] 
[0.x.21447] 
[0.x.21448] 
[0.x.21449] 
[0.x.21450] 
//[2.x.2837] 
//
// Given the complexity of the problem, it may come as a bit of a surprise that assembling the linear system we have to solve in each Newton iteration is actually fairly straightforward. The following function builds the Newton right hand side and Newton matrix. It looks fairly innocent because the heavy lifting happens in the call to  [2.x.2838]  and in particular in  [2.x.2839]  using the constraints we have previously computed.
//
[0.x.21451] 
[0.x.21452] 
[0.x.21453] 
[0.x.21454] 
[0.x.21455] 
//
[0.x.21456] 
[0.x.21457] 
//
[0.x.21458] 
[0.x.21459] 
[0.x.21460] 
[0.x.21461] 
//
[0.x.21462] 
[0.x.21463] 
[0.x.21464] 
[0.x.21465] 
//
[0.x.21466] 
[0.x.21467] 
[0.x.21468] 
//
[0.x.21469] 
[0.x.21470] 
[0.x.21471] 
//
[0.x.21472] 
[0.x.21473] 
//
[0.x.21474] 
//
[0.x.21475] 
//
[0.x.21476] 
[0.x.21477] 
[0.x.21478] 
[0.x.21479] 
[0.x.21480] 
[0.x.21481] 
//
[0.x.21482] 
[0.x.21483] 
[0.x.21484] 
//
[0.x.21485] 
[0.x.21486] 
[0.x.21487] 
[0.x.21488] 
[0.x.21489] 
[0.x.21490] 
[0.x.21491] 
[0.x.21492] 
//
[0.x.21493] 
[0.x.21494] 
//
//         Having computed the stress-strain tensor and its         linearization, we can now put together the parts of the         matrix and right hand side. In both, we need the linearized         stress-strain tensor times the symmetric gradient of          [2.x.2840] , i.e. the term  [2.x.2841] ,         so we introduce an abbreviation of this term. Recall that         the matrix corresponds to the bilinear form          [2.x.2842]          in the notation of the accompanying publication, whereas         the right hand side is  [2.x.2843]  where  [2.x.2844]          is the current linearization points (typically the last         solution). This might suggest that the right hand side will         be zero if the material is completely elastic (where          [2.x.2845] ) but this ignores the fact that the right         hand side will also contain contributions from         non-homogeneous constraints due to the contact.                 The code block that follows this adds contributions that         are due to boundary forces, should there be any.
//
[0.x.21495] 
[0.x.21496] 
[0.x.21497] 
//
[0.x.21498] 
[0.x.21499] 
[0.x.21500] 
[0.x.21501] 
[0.x.21502] 
//
[0.x.21503] 
[0.x.21504] 
[0.x.21505] 
[0.x.21506] 
[0.x.21507] 
[0.x.21508] 
[0.x.21509] 
[0.x.21510] 
//
[0.x.21511] 
[0.x.21512] 
[0.x.21513] 
[0.x.21514] 
//
[0.x.21515] 
[0.x.21516] 
[0.x.21517] 
//
[0.x.21518] 
[0.x.21519] 
[0.x.21520] 
[0.x.21521] 
[0.x.21522] 
[0.x.21523] 
[0.x.21524] 
[0.x.21525] 
[0.x.21526] 
[0.x.21527] 
[0.x.21528] 
//
[0.x.21529] 
[0.x.21530] 
[0.x.21531] 
[0.x.21532] 
[0.x.21533] 
[0.x.21534] 
[0.x.21535] 
[0.x.21536] 
//
[0.x.21537] 
[0.x.21538] 
[0.x.21539] 
//
//  [2.x.2846] 
//
// The following function computes the nonlinear residual of the equation given the current solution (or any other linearization point). This is needed in the linear search algorithm where we need to try various linear combinations of previous and current (trial) solution to compute the (real, globalized) solution of the current Newton step.
//
// That said, in a slight abuse of the name of the function, it actually does significantly more. For example, it also computes the vector that corresponds to the Newton residual but without eliminating constrained degrees of freedom. We need this vector to compute contact forces and, ultimately, to compute the next active set. Likewise, by keeping track of how many quadrature points we encounter on each cell that show plastic yielding, we also compute the  [2.x.2847]  vector that we can later output to visualize the plastic zone. In both of these cases, the results are not necessary as part of the line search, and so we may be wasting a small amount of time computing them. At the same time, this information appears as a natural by-product of what we need to do here anyway, and we want to collect it once at the end of each Newton step, so we may as well do it here.
//
// The actual implementation of this function should be rather obvious:
//
[0.x.21540] 
[0.x.21541] 
[0.x.21542] 
[0.x.21543] 
[0.x.21544] 
[0.x.21545] 
//
[0.x.21546] 
[0.x.21547] 
[0.x.21548] 
[0.x.21549] 
//
[0.x.21550] 
[0.x.21551] 
[0.x.21552] 
[0.x.21553] 
//
[0.x.21554] 
[0.x.21555] 
[0.x.21556] 
//
[0.x.21557] 
[0.x.21558] 
[0.x.21559] 
//
[0.x.21560] 
//
[0.x.21561] 
//
[0.x.21562] 
//
[0.x.21563] 
[0.x.21564] 
//
[0.x.21565] 
//
[0.x.21566] 
[0.x.21567] 
[0.x.21568] 
[0.x.21569] 
[0.x.21570] 
//
[0.x.21571] 
[0.x.21572] 
[0.x.21573] 
//
[0.x.21574] 
[0.x.21575] 
[0.x.21576] 
[0.x.21577] 
[0.x.21578] 
[0.x.21579] 
[0.x.21580] 
[0.x.21581] 
[0.x.21582] 
//
[0.x.21583] 
[0.x.21584] 
[0.x.21585] 
[0.x.21586] 
[0.x.21587] 
[0.x.21588] 
//
[0.x.21589] 
[0.x.21590] 
[0.x.21591] 
[0.x.21592] 
[0.x.21593] 
[0.x.21594] 
//
[0.x.21595] 
[0.x.21596] 
[0.x.21597] 
[0.x.21598] 
//
[0.x.21599] 
[0.x.21600] 
[0.x.21601] 
//
[0.x.21602] 
[0.x.21603] 
[0.x.21604] 
[0.x.21605] 
[0.x.21606] 
[0.x.21607] 
[0.x.21608] 
[0.x.21609] 
[0.x.21610] 
[0.x.21611] 
[0.x.21612] 
//
[0.x.21613] 
[0.x.21614] 
[0.x.21615] 
//
[0.x.21616] 
[0.x.21617] 
[0.x.21618] 
//
[0.x.21619] 
[0.x.21620] 
[0.x.21621] 
[0.x.21622] 
//
//  [2.x.2848] 
//
// The last piece before we can discuss the actual Newton iteration on a single mesh is the solver for the linear systems. There are a couple of complications that slightly obscure the code, but mostly it is just setup then solve. Among the complications are:
//
//
//
// - For the hanging nodes we have to apply   the  [2.x.2849]  function to newton_rhs.   This is necessary if a hanging node with solution value  [2.x.2850]    has one neighbor with value  [2.x.2851]  which is in contact with the   obstacle and one neighbor  [2.x.2852]  which is not in contact. Because   the update for the former will be prescribed, the hanging node constraint   will have an inhomogeneity and will look like  [2.x.2853] . So the corresponding entries in the right-hand-side are   non-zero with a meaningless value. These values we have to set to zero.
//
// - Like in  [2.x.2854] , we need to shuffle between vectors that do and do   not have ghost elements when solving or using the solution.
//
// The rest of the function is similar to  [2.x.2855]  and  [2.x.2856]  except that we use a BiCGStab solver instead of CG. This is due to the fact that for very small hardening parameters  [2.x.2857] , the linear system becomes almost semidefinite though still symmetric. BiCGStab appears to have an easier time with such linear systems.
//
[0.x.21623] 
[0.x.21624] 
[0.x.21625] 
[0.x.21626] 
//
[0.x.21627] 
[0.x.21628] 
[0.x.21629] 
//
[0.x.21630] 
[0.x.21631] 
//
[0.x.21632] 
[0.x.21633] 
[0.x.21634] 
//
[0.x.21635] 
[0.x.21636] 
[0.x.21637] 
[0.x.21638] 
//
[0.x.21639] 
[0.x.21640] 
[0.x.21641] 
[0.x.21642] 
[0.x.21643] 
[0.x.21644] 
[0.x.21645] 
[0.x.21646] 
//
[0.x.21647] 
[0.x.21648] 
//
[0.x.21649] 
[0.x.21650] 
//
[0.x.21651] 
//
[0.x.21652] 
[0.x.21653] 
[0.x.21654] 
[0.x.21655] 
//
[0.x.21656] 
[0.x.21657] 
[0.x.21658] 
[0.x.21659] 
[0.x.21660] 
[0.x.21661] 
//
[0.x.21662] 
[0.x.21663] 
[0.x.21664] 
[0.x.21665] 
[0.x.21666] 
//
[0.x.21667] 
//
[0.x.21668] 
[0.x.21669] 
//[2.x.2858] 
//
// This is, finally, the function that implements the damped Newton method on the current mesh. There are two nested loops: the outer loop for the Newton iteration and the inner loop for the line search which will be used only if necessary. To obtain a good and reasonable starting value we solve an elastic problem in the very first Newton step on each mesh (or only on the first mesh if we transfer solutions between meshes). We do so by setting the yield stress to an unreasonably large value in these iterations and then setting it back to the correct value in subsequent iterations.
//
// Other than this, the top part of this function should be reasonably obvious. We initialize the variable  [2.x.2859]  to the most negative value representable with double precision numbers so that the comparison whether the current residual is less than that of the previous step will always fail in the first step.
//
[0.x.21670] 
[0.x.21671] 
[0.x.21672] 
[0.x.21673] 
[0.x.21674] 
[0.x.21675] 
[0.x.21676] 
[0.x.21677] 
[0.x.21678] 
[0.x.21679] 
[0.x.21680] 
[0.x.21681] 
[0.x.21682] 
//
[0.x.21683] 
[0.x.21684] 
//
[0.x.21685] 
//
[0.x.21686] 
//
[0.x.21687] 
[0.x.21688] 
[0.x.21689] 
[0.x.21690] 
[0.x.21691] 
[0.x.21692] 
[0.x.21693] 
[0.x.21694] 
[0.x.21695] 
//
[0.x.21696] 
[0.x.21697] 
[0.x.21698] 
//
[0.x.21699] 
[0.x.21700] 
[0.x.21701] 
[0.x.21702] 
//
[0.x.21703] 
[0.x.21704] 
[0.x.21705] 
[0.x.21706] 
//
[0.x.21707] 
[0.x.21708] 
//
// It gets a bit more hairy after we have computed the trial solution  [2.x.2860]  of the current Newton step. We handle a highly nonlinear problem so we have to damp Newton's method using a line search. To understand how we do this, recall that in our formulation, we compute a trial solution in each Newton step and not the update between old and new solution. Since the solution set is a convex set, we will use a line search that tries linear combinations of the previous and the trial solution to guarantee that the damped solution is in our solution set again. At most we apply 5 damping steps.
//
// There are exceptions to when we use a line search. First, if this is the first Newton step on any mesh, then we don't have any point to compare the residual to, so we always accept a full step. Likewise, if this is the second Newton step on the first mesh (or the second on any mesh if we don't transfer solutions from mesh to mesh), then we have computed the first of these steps using just an elastic model (see how we set the yield stress sigma to an unreasonably large value above). In this case, the first Newton solution was a purely elastic one, the second one a plastic one, and any linear combination would not necessarily be expected to lie in the feasible set -- so we just accept the solution we just got.
//
// In either of these two cases, we bypass the line search and just update residual and other vectors as necessary.
//
[0.x.21709] 
[0.x.21710] 
[0.x.21711] 
[0.x.21712] 
[0.x.21713] 
[0.x.21714] 
[0.x.21715] 
//
[0.x.21716] 
[0.x.21717] 
[0.x.21718] 
[0.x.21719] 
[0.x.21720] 
[0.x.21721] 
//
[0.x.21722] 
//
[0.x.21723] 
//
[0.x.21724] 
[0.x.21725] 
[0.x.21726] 
[0.x.21727] 
[0.x.21728] 
[0.x.21729] 
[0.x.21730] 
[0.x.21731] 
//
[0.x.21732] 
[0.x.21733] 
[0.x.21734] 
//
[0.x.21735] 
//
[0.x.21736] 
[0.x.21737] 
[0.x.21738] 
//
[0.x.21739] 
[0.x.21740] 
[0.x.21741] 
[0.x.21742] 
[0.x.21743] 
//
[0.x.21744] 
//
[0.x.21745] 
//
[0.x.21746] 
[0.x.21747] 
[0.x.21748] 
[0.x.21749] 
[0.x.21750] 
//
[0.x.21751] 
[0.x.21752] 
[0.x.21753] 
//
[0.x.21754] 
[0.x.21755] 
[0.x.21756] 
//
[0.x.21757] 
//
// The final step is to check for convergence. If the active set has not changed across all processors and the residual is less than a threshold of  [2.x.2861] , then we terminate the iteration on the current mesh:
//
[0.x.21758] 
[0.x.21759] 
[0.x.21760] 
[0.x.21761] 
[0.x.21762] 
[0.x.21763] 
[0.x.21764] 
//
[0.x.21765] 
[0.x.21766] 
[0.x.21767] 
//[2.x.2862] 
//
// If you've made it this far into the deal.II tutorial, the following function refining the mesh should not pose any challenges to you any more. It refines the mesh, either globally or using the Kelly error estimator, and if so asked also transfers the solution from the previous to the next mesh. In the latter case, we also need to compute the active set and other quantities again, for which we need the information computed by  [2.x.2863] .
//
[0.x.21768] 
[0.x.21769] 
[0.x.21770] 
[0.x.21771] 
[0.x.21772] 
[0.x.21773] 
[0.x.21774] 
[0.x.21775] 
[0.x.21776] 
[0.x.21777] 
[0.x.21778] 
[0.x.21779] 
[0.x.21780] 
[0.x.21781] 
[0.x.21782] 
[0.x.21783] 
[0.x.21784] 
[0.x.21785] 
[0.x.21786] 
[0.x.21787] 
[0.x.21788] 
//
[0.x.21789] 
[0.x.21790] 
[0.x.21791] 
//
[0.x.21792] 
//
[0.x.21793] 
[0.x.21794] 
[0.x.21795] 
[0.x.21796] 
//
[0.x.21797] 
//
[0.x.21798] 
//
[0.x.21799] 
[0.x.21800] 
[0.x.21801] 
[0.x.21802] 
[0.x.21803] 
//
// enforce constraints to make the interpolated solution conforming on the new mesh:
//
[0.x.21804] 
//
[0.x.21805] 
[0.x.21806] 
[0.x.21807] 
[0.x.21808] 
//[2.x.2864] 
//
// The remaining three functions before we get to  [2.x.2865]  have to do with generating output. The following one is an attempt at showing the deformed body in its deformed configuration. To this end, this function takes a displacement vector field and moves every vertex of the (local part) of the mesh by the previously computed displacement. We will call this function with the current displacement field before we generate graphical output, and we will call it again after generating graphical output with the negative displacement field to undo the changes to the mesh so made.
//
// The function itself is pretty straightforward. All we have to do is keep track which vertices we have already touched, as we encounter the same vertices multiple times as we loop over cells.
//
[0.x.21809] 
[0.x.21810] 
[0.x.21811] 
[0.x.21812] 
[0.x.21813] 
//
[0.x.21814] 
[0.x.21815] 
[0.x.21816] 
[0.x.21817] 
[0.x.21818] 
[0.x.21819] 
//
[0.x.21820] 
[0.x.21821] 
[0.x.21822] 
[0.x.21823] 
//
[0.x.21824] 
[0.x.21825] 
[0.x.21826] 
//
//  [2.x.2866] 
//
// Next is the function we use to actually generate graphical output. The function is a bit tedious, but not actually particularly complicated. It moves the mesh at the top (and moves it back at the end), then computes the contact forces along the contact surface. We can do so (as shown in the accompanying paper) by taking the untreated residual vector and identifying which degrees of freedom correspond to those with contact by asking whether they have an inhomogeneous constraints associated with them. As always, we need to be mindful that we can only write into completely distributed vectors (i.e., vectors without ghost elements) but that when we want to generate output, we need vectors that do indeed have ghost entries for all locally relevant degrees of freedom.
//
[0.x.21827] 
[0.x.21828] 
[0.x.21829] 
[0.x.21830] 
[0.x.21831] 
//
[0.x.21832] 
//
[0.x.21833] 
//
// Calculation of the contact forces
//
[0.x.21834] 
[0.x.21835] 
[0.x.21836] 
[0.x.21837] 
[0.x.21838] 
[0.x.21839] 
[0.x.21840] 
[0.x.21841] 
[0.x.21842] 
[0.x.21843] 
//
[0.x.21844] 
[0.x.21845] 
[0.x.21846] 
//
[0.x.21847] 
[0.x.21848] 
[0.x.21849] 
[0.x.21850] 
[0.x.21851] 
[0.x.21852] 
//
[0.x.21853] 
[0.x.21854] 
[0.x.21855] 
//
[0.x.21856] 
//
[0.x.21857] 
//
[0.x.21858] 
[0.x.21859] 
[0.x.21860] 
[0.x.21861] 
[0.x.21862] 
[0.x.21863] 
[0.x.21864] 
[0.x.21865] 
[0.x.21866] 
[0.x.21867] 
[0.x.21868] 
[0.x.21869] 
[0.x.21870] 
[0.x.21871] 
[0.x.21872] 
//
[0.x.21873] 
[0.x.21874] 
[0.x.21875] 
[0.x.21876] 
//
[0.x.21877] 
[0.x.21878] 
//
[0.x.21879] 
//
// In the remainder of the function, we generate one VTU file on every processor, indexed by the subdomain id of this processor. On the first processor, we then also create a  [2.x.2867]  file that indexes [1.x.91] of the VTU files so that the entire set of output files can be read at once. These  [2.x.2868]  are used by Paraview to describe an entire parallel computation's output files. We then do the same again for the competitor of Paraview, the VisIt visualization program, by creating a matching  [2.x.2869]  file.
//
[0.x.21880] 
[0.x.21881] 
[0.x.21882] 
//
[0.x.21883] 
[0.x.21884] 
[0.x.21885] 
[0.x.21886] 
//[2.x.2870] 
//
// This last auxiliary function computes the contact force by calculating an integral over the contact pressure in z-direction over the contact area. For this purpose we set the contact pressure lambda to 0 for all inactive dofs (whether a degree of freedom is part of the contact is determined just as we did in the previous function). For all active dofs, lambda contains the quotient of the nonlinear residual (newton_rhs_uncondensed) and corresponding diagonal entry of the mass matrix (diag_mass_matrix_vector). Because it is not unlikely that hanging nodes show up in the contact area it is important to apply constraints_hanging_nodes.distribute to the distributed_lambda vector.
//
[0.x.21887] 
[0.x.21888] 
[0.x.21889] 
[0.x.21890] 
[0.x.21891] 
[0.x.21892] 
[0.x.21893] 
[0.x.21894] 
[0.x.21895] 
[0.x.21896] 
[0.x.21897] 
[0.x.21898] 
[0.x.21899] 
[0.x.21900] 
[0.x.21901] 
//
[0.x.21902] 
[0.x.21903] 
[0.x.21904] 
//
[0.x.21905] 
//
[0.x.21906] 
[0.x.21907] 
[0.x.21908] 
[0.x.21909] 
//
[0.x.21910] 
//
[0.x.21911] 
//
[0.x.21912] 
[0.x.21913] 
[0.x.21914] 
[0.x.21915] 
[0.x.21916] 
[0.x.21917] 
//
[0.x.21918] 
[0.x.21919] 
[0.x.21920] 
//
[0.x.21921] 
[0.x.21922] 
[0.x.21923] 
[0.x.21924] 
[0.x.21925] 
[0.x.21926] 
//
[0.x.21927] 
[0.x.21928] 
//[2.x.2871] 
//
// As in all other tutorial programs, the  [2.x.2872]  function contains the overall logic. There is not very much to it here: in essence, it performs the loops over all mesh refinement cycles, and within each, hands things over to the Newton solver in  [2.x.2873]  on the current mesh and calls the function that creates graphical output for the so-computed solution. It then outputs some statistics concerning both run times and memory consumption that has been collected over the course of computations on this mesh.
//
[0.x.21929] 
[0.x.21930] 
[0.x.21931] 
[0.x.21932] 
[0.x.21933] 
[0.x.21934] 
[0.x.21935] 
[0.x.21936] 
[0.x.21937] 
//
[0.x.21938] 
[0.x.21939] 
//
[0.x.21940] 
[0.x.21941] 
[0.x.21942] 
[0.x.21943] 
[0.x.21944] 
[0.x.21945] 
[0.x.21946] 
[0.x.21947] 
[0.x.21948] 
[0.x.21949] 
[0.x.21950] 
//
[0.x.21951] 
//
[0.x.21952] 
//
[0.x.21953] 
[0.x.21954] 
//
[0.x.21955] 
[0.x.21956] 
[0.x.21957] 
[0.x.21958] 
//
[0.x.21959] 
[0.x.21960] 
[0.x.21961] 
[0.x.21962] 
[0.x.21963] 
//[2.x.2874] 
//
// There really isn't much to the  [2.x.2875]  function. It looks like they always do:
//
[0.x.21964] 
[0.x.21965] 
[0.x.21966] 
[0.x.21967] 
//
[0.x.21968] 
[0.x.21969] 
[0.x.21970] 
[0.x.21971] 
[0.x.21972] 
[0.x.21973] 
[0.x.21974] 
[0.x.21975] 
[0.x.21976] 
[0.x.21977] 
//
[0.x.21978] 
[0.x.21979] 
[0.x.21980] 
[0.x.21981] 
[0.x.21982] 
[0.x.21983] 
[0.x.21984] 
[0.x.21985] 
[0.x.21986] 
[0.x.21987] 
[0.x.21988] 
[0.x.21989] 
[0.x.21990] 
[0.x.21991] 
[0.x.21992] 
[0.x.21993] 
[0.x.21994] 
[0.x.21995] 
[0.x.21996] 
//
[0.x.21997] 
[0.x.21998] 
[0.x.21999] 
[0.x.22000] 
[0.x.22001] 
[0.x.22002] 
[0.x.22003] 
[0.x.22004] 
[0.x.22005] 
[0.x.22006] 
[0.x.22007] 
[0.x.22008] 
[0.x.22009] 
[0.x.22010] 
//
[0.x.22011] 
[0.x.22012] 
[0.x.22013] 
[0.x.22014] 
[0.x.22015] 
[0.x.22016] 
[0.x.22017] 
[0.x.22018] 
[0.x.22019] 
[0.x.22020] 
[0.x.22021] 
[0.x.22022] 
[0.x.22023] 
[0.x.22024] 
[0.x.22025] 
[0.x.22026] 
//
[0.x.22027] 
[0.x.22028] 
[0.x.22029] 
[0.x.22030] 
//[2.x.2876] 
//
// The first step, as always, is to include the functionality of a number of deal.II and C++ header files.
//
// The list includes some header files that provide vector, matrix, and preconditioner classes that implement interfaces to the respective Trilinos classes; some more information on these may be found in  [2.x.2877] .
//
[0.x.22031] 
[0.x.22032] 
[0.x.22033] 
[0.x.22034] 
[0.x.22035] 
[0.x.22036] 
//
[0.x.22037] 
[0.x.22038] 
[0.x.22039] 
[0.x.22040] 
[0.x.22041] 
//
[0.x.22042] 
[0.x.22043] 
[0.x.22044] 
//
[0.x.22045] 
[0.x.22046] 
[0.x.22047] 
//
[0.x.22048] 
[0.x.22049] 
[0.x.22050] 
//
[0.x.22051] 
[0.x.22052] 
[0.x.22053] 
//
[0.x.22054] 
[0.x.22055] 
[0.x.22056] 
[0.x.22057] 
[0.x.22058] 
//
[0.x.22059] 
[0.x.22060] 
[0.x.22061] 
//
// At the end of this top-matter, we open a namespace for the current project into which all the following material will go, and then import all deal.II names into this namespace:
//
[0.x.22062] 
[0.x.22063] 
[0.x.22064] 
//[2.x.2878] 
//
// The following part is taken directly from  [2.x.2879]  so there is no need to repeat the descriptions found there.
//
[0.x.22065] 
[0.x.22066] 
[0.x.22067] 
[0.x.22068] 
[0.x.22069] 
[0.x.22070] 
[0.x.22071] 
//
[0.x.22072] 
[0.x.22073] 
[0.x.22074] 
//
[0.x.22075] 
[0.x.22076] 
[0.x.22077] 
[0.x.22078] 
[0.x.22079] 
[0.x.22080] 
[0.x.22081] 
//
[0.x.22082] 
[0.x.22083] 
[0.x.22084] 
[0.x.22085] 
[0.x.22086] 
[0.x.22087] 
[0.x.22088] 
//
[0.x.22089] 
[0.x.22090] 
[0.x.22091] 
//
[0.x.22092] 
[0.x.22093] 
[0.x.22094] 
[0.x.22095] 
[0.x.22096] 
[0.x.22097] 
[0.x.22098] 
[0.x.22099] 
[0.x.22100] 
[0.x.22101] 
//
[0.x.22102] 
[0.x.22103] 
[0.x.22104] 
[0.x.22105] 
[0.x.22106] 
[0.x.22107] 
[0.x.22108] 
//
[0.x.22109] 
[0.x.22110] 
//
[0.x.22111] 
[0.x.22112] 
[0.x.22113] 
//
[0.x.22114] 
[0.x.22115] 
[0.x.22116] 
[0.x.22117] 
[0.x.22118] 
[0.x.22119] 
[0.x.22120] 
//
[0.x.22121] 
[0.x.22122] 
[0.x.22123] 
[0.x.22124] 
[0.x.22125] 
[0.x.22126] 
[0.x.22127] 
//[2.x.2880] 
//
// In this tutorial, we still use the two permeability models previously used in  [2.x.2881]  so we again refrain from commenting in detail about them.
//
[0.x.22128] 
[0.x.22129] 
[0.x.22130] 
[0.x.22131] 
[0.x.22132] 
[0.x.22133] 
[0.x.22134] 
[0.x.22135] 
[0.x.22136] 
//
[0.x.22137] 
[0.x.22138] 
[0.x.22139] 
[0.x.22140] 
//
[0.x.22141] 
[0.x.22142] 
[0.x.22143] 
[0.x.22144] 
[0.x.22145] 
[0.x.22146] 
//
[0.x.22147] 
[0.x.22148] 
[0.x.22149] 
//
[0.x.22150] 
[0.x.22151] 
//
[0.x.22152] 
[0.x.22153] 
[0.x.22154] 
[0.x.22155] 
//
[0.x.22156] 
[0.x.22157] 
[0.x.22158] 
[0.x.22159] 
[0.x.22160] 
//
[0.x.22161] 
[0.x.22162] 
[0.x.22163] 
[0.x.22164] 
[0.x.22165] 
[0.x.22166] 
[0.x.22167] 
[0.x.22168] 
[0.x.22169] 
//
[0.x.22170] 
[0.x.22171] 
[0.x.22172] 
//
[0.x.22173] 
[0.x.22174] 
[0.x.22175] 
//
[0.x.22176] 
[0.x.22177] 
[0.x.22178] 
[0.x.22179] 
//
[0.x.22180] 
[0.x.22181] 
[0.x.22182] 
[0.x.22183] 
//
[0.x.22184] 
[0.x.22185] 
//
[0.x.22186] 
[0.x.22187] 
[0.x.22188] 
[0.x.22189] 
[0.x.22190] 
//
[0.x.22191] 
[0.x.22192] 
[0.x.22193] 
//
[0.x.22194] 
[0.x.22195] 
[0.x.22196] 
[0.x.22197] 
//
[0.x.22198] 
[0.x.22199] 
//
[0.x.22200] 
[0.x.22201] 
[0.x.22202] 
[0.x.22203] 
[0.x.22204] 
//[2.x.2882] 
//
// The implementations of all the physical quantities such as total mobility  [2.x.2883]  and fractional flow of water  [2.x.2884]  are taken from  [2.x.2885]  so again we don't have do any comment about them. Compared to  [2.x.2886]  we have added checks that the saturation passed to these functions is in fact within the physically valid range. Furthermore, given that the wetting phase moves at speed  [2.x.2887]  it is clear that  [2.x.2888]  must be greater or equal to zero, so we assert that as well to make sure that our calculations to get at the formula for the derivative made sense.
//
[0.x.22205] 
[0.x.22206] 
[0.x.22207] 
[0.x.22208] 
//
[0.x.22209] 
[0.x.22210] 
[0.x.22211] 
[0.x.22212] 
//
[0.x.22213] 
[0.x.22214] 
//
[0.x.22215] 
[0.x.22216] 
[0.x.22217] 
[0.x.22218] 
//
[0.x.22219] 
//
[0.x.22220] 
[0.x.22221] 
[0.x.22222] 
//
[0.x.22223] 
//
[0.x.22224] 
//
[0.x.22225] 
[0.x.22226] 
//[2.x.2889] 
//
// In this first part we define a number of classes that we need in the construction of linear solvers and preconditioners. This part is essentially the same as that used in  [2.x.2890] . The only difference is that the original variable name stokes_matrix is replaced by another name darcy_matrix to match our problem.
//
[0.x.22227] 
[0.x.22228] 
[0.x.22229] 
[0.x.22230] 
[0.x.22231] 
[0.x.22232] 
[0.x.22233] 
[0.x.22234] 
//
[0.x.22235] 
[0.x.22236] 
//
[0.x.22237] 
[0.x.22238] 
[0.x.22239] 
[0.x.22240] 
//
[0.x.22241] 
[0.x.22242] 
[0.x.22243] 
[0.x.22244] 
[0.x.22245] 
[0.x.22246] 
[0.x.22247] 
//
[0.x.22248] 
[0.x.22249] 
[0.x.22250] 
[0.x.22251] 
[0.x.22252] 
[0.x.22253] 
[0.x.22254] 
[0.x.22255] 
//
[0.x.22256] 
//
[0.x.22257] 
[0.x.22258] 
[0.x.22259] 
[0.x.22260] 
[0.x.22261] 
[0.x.22262] 
[0.x.22263] 
[0.x.22264] 
[0.x.22265] 
//
[0.x.22266] 
[0.x.22267] 
[0.x.22268] 
[0.x.22269] 
[0.x.22270] 
[0.x.22271] 
[0.x.22272] 
[0.x.22273] 
[0.x.22274] 
//
[0.x.22275] 
[0.x.22276] 
//
[0.x.22277] 
[0.x.22278] 
[0.x.22279] 
[0.x.22280] 
[0.x.22281] 
[0.x.22282] 
[0.x.22283] 
//
[0.x.22284] 
[0.x.22285] 
//
[0.x.22286] 
[0.x.22287] 
[0.x.22288] 
[0.x.22289] 
[0.x.22290] 
[0.x.22291] 
[0.x.22292] 
[0.x.22293] 
[0.x.22294] 
[0.x.22295] 
[0.x.22296] 
[0.x.22297] 
//
[0.x.22298] 
[0.x.22299] 
[0.x.22300] 
[0.x.22301] 
[0.x.22302] 
[0.x.22303] 
[0.x.22304] 
[0.x.22305] 
[0.x.22306] 
[0.x.22307] 
[0.x.22308] 
[0.x.22309] 
//[2.x.2891] 
//
// The definition of the class that defines the top-level logic of solving the time-dependent advection-dominated two-phase flow problem (or Buckley-Leverett problem [Buckley 1942]) is mainly based on tutorial programs  [2.x.2892]  and  [2.x.2893] , and in particular on  [2.x.2894]  where we have used basically the same general structure as done here. As in  [2.x.2895] , the key routines to look for in the implementation below are the  [2.x.2896]  functions.
//
// The main difference to  [2.x.2897]  is that, since adaptive operator splitting is considered, we need a couple more member variables to hold the last two computed Darcy (velocity/pressure) solutions in addition to the current one (which is either computed directly, or extrapolated from the previous two), and we need to remember the last two times we computed the Darcy solution. We also need a helper function that figures out whether we do indeed need to recompute the Darcy solution.
//
// Unlike  [2.x.2898] , this step uses one more AffineConstraints object called darcy_preconditioner_constraints. This constraint object is used only for assembling the matrix for the Darcy preconditioner and includes hanging node constraints as well as Dirichlet boundary value constraints for the pressure variable. We need this because we are building a Laplace matrix for the pressure as an approximation of the Schur complement) which is only positive definite if boundary conditions are applied.
//
// The collection of member functions and variables thus declared in this class is then rather similar to those in  [2.x.2899] :
//
[0.x.22310] 
[0.x.22311] 
[0.x.22312] 
[0.x.22313] 
[0.x.22314] 
[0.x.22315] 
//
[0.x.22316] 
[0.x.22317] 
[0.x.22318] 
[0.x.22319] 
[0.x.22320] 
[0.x.22321] 
[0.x.22322] 
[0.x.22323] 
[0.x.22324] 
[0.x.22325] 
[0.x.22326] 
[0.x.22327] 
[0.x.22328] 
[0.x.22329] 
[0.x.22330] 
[0.x.22331] 
[0.x.22332] 
[0.x.22333] 
[0.x.22334] 
[0.x.22335] 
[0.x.22336] 
[0.x.22337] 
//
// We follow with a number of helper functions that are used in a variety of places throughout the program:
//
[0.x.22338] 
[0.x.22339] 
[0.x.22340] 
[0.x.22341] 
[0.x.22342] 
[0.x.22343] 
[0.x.22344] 
[0.x.22345] 
[0.x.22346] 
[0.x.22347] 
[0.x.22348] 
[0.x.22349] 
[0.x.22350] 
//
// This all is followed by the member variables, most of which are similar to the ones in  [2.x.2900] , with the exception of the ones that pertain to the macro time stepping for the velocity/pressure system:
//
[0.x.22351] 
[0.x.22352] 
//
[0.x.22353] 
//
[0.x.22354] 
[0.x.22355] 
[0.x.22356] 
[0.x.22357] 
//
[0.x.22358] 
//
[0.x.22359] 
[0.x.22360] 
//
[0.x.22361] 
[0.x.22362] 
//
[0.x.22363] 
[0.x.22364] 
//
[0.x.22365] 
[0.x.22366] 
[0.x.22367] 
[0.x.22368] 
//
[0.x.22369] 
//
[0.x.22370] 
[0.x.22371] 
[0.x.22372] 
[0.x.22373] 
//
[0.x.22374] 
[0.x.22375] 
//
[0.x.22376] 
//
[0.x.22377] 
[0.x.22378] 
//
[0.x.22379] 
[0.x.22380] 
//
[0.x.22381] 
[0.x.22382] 
[0.x.22383] 
//
[0.x.22384] 
[0.x.22385] 
[0.x.22386] 
//
[0.x.22387] 
[0.x.22388] 
//
[0.x.22389] 
//
// At the very end we declare a variable that denotes the material model. Compared to  [2.x.2901] , we do this here as a member variable since we will want to use it in a variety of places and so having a central place where such a variable is declared will make it simpler to replace one class by another (e.g. replace  [2.x.2902]  by  [2.x.2903] 
[0.x.22390] 
[0.x.22391] 
//[2.x.2904] 
//
// The constructor of this class is an extension of the constructors in  [2.x.2905]  and  [2.x.2906] . We need to add the various variables that concern the saturation. As discussed in the introduction, we are going to use  [2.x.2907]  (Taylor-Hood) elements again for the Darcy system, an element combination that fulfills the Ladyzhenskaya-Babuska-Brezzi (LBB) conditions [Brezzi and Fortin 1991, Chen 2005], and  [2.x.2908]  elements for the saturation. However, by using variables that store the polynomial degree of the Darcy and temperature finite elements, it is easy to consistently modify the degree of the elements as well as all quadrature formulas used on them downstream. Moreover, we initialize the time stepping variables related to operator splitting as well as the option for matrix assembly and preconditioning:
//
[0.x.22392] 
[0.x.22393] 
[0.x.22394] 
[0.x.22395] 
[0.x.22396] 
[0.x.22397] 
[0.x.22398] 
[0.x.22399] 
[0.x.22400] 
//
[0.x.22401] 
[0.x.22402] 
[0.x.22403] 
[0.x.22404] 
//
[0.x.22405] 
[0.x.22406] 
//
[0.x.22407] 
[0.x.22408] 
[0.x.22409] 
//
[0.x.22410] 
[0.x.22411] 
[0.x.22412] 
//
[0.x.22413] 
[0.x.22414] 
[0.x.22415] 
[0.x.22416] 
[0.x.22417] 
[0.x.22418] 
[0.x.22419] 
//
[0.x.22420] 
[0.x.22421] 
//[2.x.2909] 
//
// This is the function that sets up the DoFHandler objects we have here (one for the Darcy part and one for the saturation part) as well as set to the right sizes the various objects required for the linear algebra in this program. Its basic operations are similar to what  [2.x.2910]  did.
//
// The body of the function first enumerates all degrees of freedom for the Darcy and saturation systems. For the Darcy part, degrees of freedom are then sorted to ensure that velocities precede pressure DoFs so that we can partition the Darcy matrix into a  [2.x.2911]  matrix.
//
// Then, we need to incorporate hanging node constraints and Dirichlet boundary value constraints into darcy_preconditioner_constraints.  The boundary condition constraints are only set on the pressure component since the Schur complement preconditioner that corresponds to the porous media flow operator in non-mixed form,  [2.x.2912] , acts only on the pressure variable. Therefore, we use a component_mask that filters out the velocity component, so that the condensation is performed on pressure degrees of freedom only.
//
// After having done so, we count the number of degrees of freedom in the various blocks. This information is then used to create the sparsity pattern for the Darcy and saturation system matrices as well as the preconditioner matrix from which we build the Darcy preconditioner. As in  [2.x.2913] , we choose to create the pattern using the blocked version of DynamicSparsityPattern. So, for this, we follow the same way as  [2.x.2914]  did and we don't have to repeat descriptions again for the rest of the member function.
//
[0.x.22422] 
[0.x.22423] 
[0.x.22424] 
[0.x.22425] 
[0.x.22426] 
[0.x.22427] 
[0.x.22428] 
[0.x.22429] 
[0.x.22430] 
//
[0.x.22431] 
[0.x.22432] 
[0.x.22433] 
[0.x.22434] 
[0.x.22435] 
[0.x.22436] 
[0.x.22437] 
//
[0.x.22438] 
[0.x.22439] 
[0.x.22440] 
[0.x.22441] 
[0.x.22442] 
[0.x.22443] 
[0.x.22444] 
//
[0.x.22445] 
//
[0.x.22446] 
[0.x.22447] 
[0.x.22448] 
[0.x.22449] 
[0.x.22450] 
[0.x.22451] 
//
[0.x.22452] 
[0.x.22453] 
//
[0.x.22454] 
[0.x.22455] 
[0.x.22456] 
[0.x.22457] 
[0.x.22458] 
[0.x.22459] 
//
[0.x.22460] 
[0.x.22461] 
[0.x.22462] 
[0.x.22463] 
[0.x.22464] 
//
[0.x.22465] 
[0.x.22466] 
//
[0.x.22467] 
//
[0.x.22468] 
[0.x.22469] 
[0.x.22470] 
[0.x.22471] 
//
[0.x.22472] 
//
[0.x.22473] 
//
[0.x.22474] 
[0.x.22475] 
[0.x.22476] 
[0.x.22477] 
[0.x.22478] 
[0.x.22479] 
//
[0.x.22480] 
[0.x.22481] 
//
[0.x.22482] 
[0.x.22483] 
//
[0.x.22484] 
[0.x.22485] 
[0.x.22486] 
[0.x.22487] 
//
[0.x.22488] 
//
[0.x.22489] 
[0.x.22490] 
[0.x.22491] 
[0.x.22492] 
//
[0.x.22493] 
//
[0.x.22494] 
[0.x.22495] 
[0.x.22496] 
[0.x.22497] 
[0.x.22498] 
[0.x.22499] 
[0.x.22500] 
//
[0.x.22501] 
[0.x.22502] 
//
[0.x.22503] 
[0.x.22504] 
//
[0.x.22505] 
[0.x.22506] 
//
[0.x.22507] 
//
[0.x.22508] 
[0.x.22509] 
[0.x.22510] 
[0.x.22511] 
//
[0.x.22512] 
[0.x.22513] 
//
[0.x.22514] 
[0.x.22515] 
[0.x.22516] 
[0.x.22517] 
[0.x.22518] 
//
[0.x.22519] 
[0.x.22520] 
//
[0.x.22521] 
[0.x.22522] 
[0.x.22523] 
//
[0.x.22524] 
[0.x.22525] 
//
[0.x.22526] 
[0.x.22527] 
[0.x.22528] 
[0.x.22529] 
//
[0.x.22530] 
[0.x.22531] 
//
[0.x.22532] 
[0.x.22533] 
//[2.x.2915] 
//
// The next few functions are devoted to setting up the various system and preconditioner matrices and right hand sides that we have to deal with in this program.
//
//  [2.x.2916] 
//
// This function assembles the matrix we use for preconditioning the Darcy system. What we need are a vector mass matrix weighted by  [2.x.2917]  on the velocity components and a mass matrix weighted by  [2.x.2918]  on the pressure component. We start by generating a quadrature object of appropriate order, the FEValues object that can give values and gradients at the quadrature points (together with quadrature weights). Next we create data structures for the cell matrix and the relation between local and global DoFs. The vectors phi_u and grad_phi_p are going to hold the values of the basis functions in order to faster build up the local matrices, as was already done in  [2.x.2919] . Before we start the loop over all active cells, we have to specify which components are pressure and which are velocity.
//
// The creation of the local matrix is rather simple. There are only a term weighted by  [2.x.2920]  (on the velocity) and a Laplace matrix weighted by  [2.x.2921]  to be generated, so the creation of the local matrix is done in essentially two lines. Since the material model functions at the top of this file only provide the inverses of the permeability and mobility, we have to compute  [2.x.2922]  and  [2.x.2923]  by hand from the given values, once per quadrature point.
//
// Once the local matrix is ready (loop over rows and columns in the local matrix on each quadrature point), we get the local DoF indices and write the local information into the global matrix. We do this by directly applying the constraints (i.e. darcy_preconditioner_constraints) that takes care of hanging node and zero Dirichlet boundary condition constraints. By doing so, we don't have to do that afterwards, and we later don't have to use  [2.x.2924]  and  [2.x.2925]  both functions that would need to modify matrix and vector entries and so are difficult to write for the Trilinos classes where we don't immediately have access to individual memory locations.
//
[0.x.22534] 
[0.x.22535] 
[0.x.22536] 
[0.x.22537] 
//
[0.x.22538] 
//
[0.x.22539] 
[0.x.22540] 
[0.x.22541] 
[0.x.22542] 
[0.x.22543] 
[0.x.22544] 
[0.x.22545] 
[0.x.22546] 
[0.x.22547] 
//
[0.x.22548] 
[0.x.22549] 
//
[0.x.22550] 
//
[0.x.22551] 
//
[0.x.22552] 
[0.x.22553] 
//
[0.x.22554] 
[0.x.22555] 
//
[0.x.22556] 
[0.x.22557] 
//
[0.x.22558] 
[0.x.22559] 
[0.x.22560] 
//
[0.x.22561] 
[0.x.22562] 
[0.x.22563] 
[0.x.22564] 
//
[0.x.22565] 
//
[0.x.22566] 
[0.x.22567] 
//
[0.x.22568] 
[0.x.22569] 
//
[0.x.22570] 
[0.x.22571] 
[0.x.22572] 
//
[0.x.22573] 
[0.x.22574] 
[0.x.22575] 
//
[0.x.22576] 
[0.x.22577] 
[0.x.22578] 
[0.x.22579] 
[0.x.22580] 
//
[0.x.22581] 
[0.x.22582] 
[0.x.22583] 
[0.x.22584] 
[0.x.22585] 
[0.x.22586] 
[0.x.22587] 
[0.x.22588] 
[0.x.22589] 
[0.x.22590] 
//
[0.x.22591] 
[0.x.22592] 
[0.x.22593] 
[0.x.22594] 
[0.x.22595] 
//[2.x.2926] 
//
// After calling the above functions to assemble the preconditioner matrix, this function generates the inner preconditioners that are going to be used for the Schur complement block preconditioner. The preconditioners need to be regenerated at every saturation time step since they depend on the saturation  [2.x.2927]  that varies with time.
//
// In here, we set up the preconditioner for the velocity-velocity matrix  [2.x.2928]  and the Schur complement  [2.x.2929] . As explained in the introduction, we are going to use an IC preconditioner based on the vector matrix  [2.x.2930]  and another based on the scalar Laplace matrix  [2.x.2931]  (which is spectrally close to the Schur complement of the Darcy matrix). Usually, the  [2.x.2932]  class can be seen as a good black-box preconditioner which does not need any special knowledge of the matrix structure and/or the operator that's behind it.
//
[0.x.22596] 
[0.x.22597] 
[0.x.22598] 
[0.x.22599] 
//
[0.x.22600] 
[0.x.22601] 
//
[0.x.22602] 
[0.x.22603] 
[0.x.22604] 
//[2.x.2933] 
//
// This is the function that assembles the linear system for the Darcy system.
//
// Regarding the technical details of implementation, the procedures are similar to those in  [2.x.2934]  and  [2.x.2935] . We reset matrix and vector, create a quadrature formula on the cells, and then create the respective FEValues object.
//
// There is one thing that needs to be commented: since we have a separate finite element and DoFHandler for the saturation, we need to generate a second FEValues object for the proper evaluation of the saturation solution. This isn't too complicated to realize here: just use the saturation structures and set an update flag for the basis function values which we need for evaluation of the saturation solution. The only important part to remember here is that the same quadrature formula is used for both FEValues objects to ensure that we get matching information when we loop over the quadrature points of the two objects.
//
// The declarations proceed with some shortcuts for array sizes, the creation of the local matrix, right hand side as well as the vector for the indices of the local dofs compared to the global system.
//
[0.x.22605] 
[0.x.22606] 
[0.x.22607] 
[0.x.22608] 
[0.x.22609] 
//
[0.x.22610] 
[0.x.22611] 
//
[0.x.22612] 
[0.x.22613] 
[0.x.22614] 
[0.x.22615] 
[0.x.22616] 
//
[0.x.22617] 
[0.x.22618] 
[0.x.22619] 
//
[0.x.22620] 
[0.x.22621] 
[0.x.22622] 
[0.x.22623] 
[0.x.22624] 
[0.x.22625] 
//
[0.x.22626] 
//
[0.x.22627] 
[0.x.22628] 
//
[0.x.22629] 
[0.x.22630] 
//
[0.x.22631] 
//
[0.x.22632] 
[0.x.22633] 
//
[0.x.22634] 
[0.x.22635] 
[0.x.22636] 
//
// Next we need a vector that will contain the values of the saturation solution at the previous time level at the quadrature points to assemble the saturation dependent coefficients in the Darcy equations.
//
// The set of vectors we create next hold the evaluations of the basis functions as well as their gradients that will be used for creating the matrices. Putting these into their own arrays rather than asking the FEValues object for this information each time it is needed is an optimization to accelerate the assembly process, see  [2.x.2936]  for details.
//
// The last two declarations are used to extract the individual blocks (velocity, pressure, saturation) from the total FE system.
//
[0.x.22637] 
//
[0.x.22638] 
[0.x.22639] 
[0.x.22640] 
//
[0.x.22641] 
[0.x.22642] 
//
// Now start the loop over all cells in the problem. We are working on two different DoFHandlers for this assembly routine, so we must have two different cell iterators for the two objects in use. This might seem a bit peculiar, but since both the Darcy system and the saturation system use the same grid we can assume that the two iterators run in sync over the cells of the two DoFHandler objects.
//
// The first statements within the loop are again all very familiar, doing the update of the finite element data as specified by the update flags, zeroing out the local arrays and getting the values of the old solution at the quadrature points.  At this point we also have to get the values of the saturation function of the previous time step at the quadrature points. To this end, we can use the  [2.x.2937]  (previously already used in  [2.x.2938] ,  [2.x.2939]  and  [2.x.2940] ), a function that takes a solution vector and returns a list of function values at the quadrature points of the present cell. In fact, it returns the complete vector-valued solution at each quadrature point, i.e. not only the saturation but also the velocities and pressure.
//
// Then we are ready to loop over the quadrature points on the cell to do the integration. The formula for this follows in a straightforward way from what has been discussed in the introduction.
//
// Once this is done, we start the loop over the rows and columns of the local matrix and feed the matrix with the relevant products.
//
// The last step in the loop over all cells is to enter the local contributions into the global matrix and vector structures to the positions specified in local_dof_indices. Again, we let the AffineConstraints class do the insertion of the cell matrix elements to the global matrix, which already condenses the hanging node constraints.
//
[0.x.22643] 
[0.x.22644] 
[0.x.22645] 
//
[0.x.22646] 
[0.x.22647] 
[0.x.22648] 
[0.x.22649] 
//
[0.x.22650] 
[0.x.22651] 
//
[0.x.22652] 
[0.x.22653] 
//
[0.x.22654] 
[0.x.22655] 
[0.x.22656] 
[0.x.22657] 
//
[0.x.22658] 
[0.x.22659] 
[0.x.22660] 
[0.x.22661] 
[0.x.22662] 
[0.x.22663] 
[0.x.22664] 
[0.x.22665] 
[0.x.22666] 
[0.x.22667] 
[0.x.22668] 
[0.x.22669] 
[0.x.22670] 
[0.x.22671] 
[0.x.22672] 
[0.x.22673] 
[0.x.22674] 
[0.x.22675] 
[0.x.22676] 
//
[0.x.22677] 
[0.x.22678] 
[0.x.22679] 
[0.x.22680] 
//
[0.x.22681] 
[0.x.22682] 
[0.x.22683] 
[0.x.22684] 
//
[0.x.22685] 
[0.x.22686] 
//
[0.x.22687] 
[0.x.22688] 
[0.x.22689] 
[0.x.22690] 
[0.x.22691] 
//
[0.x.22692] 
[0.x.22693] 
[0.x.22694] 
[0.x.22695] 
[0.x.22696] 
//
[0.x.22697] 
[0.x.22698] 
[0.x.22699] 
//
[0.x.22700] 
//
[0.x.22701] 
[0.x.22702] 
[0.x.22703] 
[0.x.22704] 
//[2.x.2941] 
//
// This function is to assemble the linear system for the saturation transport equation. It calls, if necessary, two other member functions: assemble_saturation_matrix() and assemble_saturation_rhs(). The former function then assembles the saturation matrix that only needs to be changed occasionally. On the other hand, the latter function that assembles the right hand side must be called at every saturation time step.
//
[0.x.22705] 
[0.x.22706] 
[0.x.22707] 
[0.x.22708] 
[0.x.22709] 
[0.x.22710] 
[0.x.22711] 
[0.x.22712] 
//
[0.x.22713] 
[0.x.22714] 
[0.x.22715] 
//
//  [2.x.2942] 
//
// This function is easily understood since it only forms a simple mass matrix for the left hand side of the saturation linear system by basis functions phi_i_s and phi_j_s only. Finally, as usual, we enter the local contribution into the global matrix by specifying the position in local_dof_indices. This is done by letting the AffineConstraints class do the insertion of the cell matrix elements to the global matrix, which already condenses the hanging node constraints.
//
[0.x.22716] 
[0.x.22717] 
[0.x.22718] 
[0.x.22719] 
//
[0.x.22720] 
[0.x.22721] 
[0.x.22722] 
//
[0.x.22723] 
//
[0.x.22724] 
//
[0.x.22725] 
[0.x.22726] 
//
[0.x.22727] 
//
[0.x.22728] 
[0.x.22729] 
[0.x.22730] 
[0.x.22731] 
[0.x.22732] 
//
[0.x.22733] 
[0.x.22734] 
[0.x.22735] 
[0.x.22736] 
[0.x.22737] 
[0.x.22738] 
[0.x.22739] 
[0.x.22740] 
[0.x.22741] 
[0.x.22742] 
[0.x.22743] 
[0.x.22744] 
//
[0.x.22745] 
[0.x.22746] 
[0.x.22747] 
[0.x.22748] 
[0.x.22749] 
//
//  [2.x.2943] 
//
// This function is to assemble the right hand side of the saturation transport equation. Before going about it, we have to create two FEValues objects for the Darcy and saturation systems respectively and, in addition, two FEFaceValues objects for the two systems because we have a boundary integral term in the weak form of saturation equation. For the FEFaceValues object of the saturation system, we also require normal vectors, which we request using the update_normal_vectors flag.
//
// Next, before looping over all the cells, we have to compute some parameters (e.g. global_u_infty, global_S_variation, and global_Omega_diameter) that the artificial viscosity  [2.x.2944]  needs. This is largely the same as was done in  [2.x.2945] , so you may see there for more information.
//
// The real works starts with the loop over all the saturation and Darcy cells to put the local contributions into the global vector. In this loop, in order to simplify the implementation, we split some of the work into two helper functions: assemble_saturation_rhs_cell_term and assemble_saturation_rhs_boundary_term.  We note that we insert cell or boundary contributions into the global vector in the two functions rather than in this present function.
//
[0.x.22750] 
[0.x.22751] 
[0.x.22752] 
[0.x.22753] 
[0.x.22754] 
//
[0.x.22755] 
[0.x.22756] 
[0.x.22757] 
[0.x.22758] 
[0.x.22759] 
[0.x.22760] 
[0.x.22761] 
[0.x.22762] 
[0.x.22763] 
[0.x.22764] 
[0.x.22765] 
[0.x.22766] 
[0.x.22767] 
[0.x.22768] 
[0.x.22769] 
[0.x.22770] 
[0.x.22771] 
//
[0.x.22772] 
[0.x.22773] 
[0.x.22774] 
//
[0.x.22775] 
[0.x.22776] 
[0.x.22777] 
[0.x.22778] 
[0.x.22779] 
//
[0.x.22780] 
[0.x.22781] 
[0.x.22782] 
[0.x.22783] 
[0.x.22784] 
[0.x.22785] 
[0.x.22786] 
//
[0.x.22787] 
//
[0.x.22788] 
[0.x.22789] 
[0.x.22790] 
[0.x.22791] 
[0.x.22792] 
//
[0.x.22793] 
[0.x.22794] 
[0.x.22795] 
[0.x.22796] 
[0.x.22797] 
[0.x.22798] 
[0.x.22799] 
[0.x.22800] 
[0.x.22801] 
[0.x.22802] 
[0.x.22803] 
//
//  [2.x.2946] 
//
// This function takes care of integrating the cell terms of the right hand side of the saturation equation, and then assembling it into the global right hand side vector. Given the discussion in the introduction, the form of these contributions is clear. The only tricky part is getting the artificial viscosity and all that is necessary to compute it. The first half of the function is devoted to this task.
//
// The last part of the function is copying the local contributions into the global vector with position specified in local_dof_indices.
//
[0.x.22804] 
[0.x.22805] 
[0.x.22806] 
[0.x.22807] 
[0.x.22808] 
[0.x.22809] 
[0.x.22810] 
[0.x.22811] 
[0.x.22812] 
[0.x.22813] 
//
[0.x.22814] 
[0.x.22815] 
[0.x.22816] 
[0.x.22817] 
[0.x.22818] 
[0.x.22819] 
[0.x.22820] 
//
[0.x.22821] 
[0.x.22822] 
[0.x.22823] 
[0.x.22824] 
[0.x.22825] 
[0.x.22826] 
[0.x.22827] 
[0.x.22828] 
[0.x.22829] 
[0.x.22830] 
//
[0.x.22831] 
[0.x.22832] 
[0.x.22833] 
[0.x.22834] 
[0.x.22835] 
[0.x.22836] 
[0.x.22837] 
[0.x.22838] 
[0.x.22839] 
//
[0.x.22840] 
//
[0.x.22841] 
[0.x.22842] 
[0.x.22843] 
[0.x.22844] 
[0.x.22845] 
[0.x.22846] 
[0.x.22847] 
//
[0.x.22848] 
[0.x.22849] 
[0.x.22850] 
//
[0.x.22851] 
[0.x.22852] 
[0.x.22853] 
[0.x.22854] 
[0.x.22855] 
[0.x.22856] 
[0.x.22857] 
[0.x.22858] 
//
[0.x.22859] 
[0.x.22860] 
[0.x.22861] 
[0.x.22862] 
//[2.x.2947] 
//
// The next function is responsible for the boundary integral terms in the right hand side form of the saturation equation.  For these, we have to compute the upwinding flux on the global boundary faces, i.e. we impose Dirichlet boundary conditions weakly only on inflow parts of the global boundary. As before, this has been described in  [2.x.2948]  so we refrain from giving more descriptions about that.
//
[0.x.22863] 
[0.x.22864] 
[0.x.22865] 
[0.x.22866] 
[0.x.22867] 
[0.x.22868] 
[0.x.22869] 
[0.x.22870] 
[0.x.22871] 
//
[0.x.22872] 
//
[0.x.22873] 
[0.x.22874] 
[0.x.22875] 
[0.x.22876] 
//
[0.x.22877] 
[0.x.22878] 
[0.x.22879] 
[0.x.22880] 
//
[0.x.22881] 
[0.x.22882] 
[0.x.22883] 
//
[0.x.22884] 
[0.x.22885] 
[0.x.22886] 
[0.x.22887] 
[0.x.22888] 
//
[0.x.22889] 
[0.x.22890] 
//
[0.x.22891] 
//
[0.x.22892] 
[0.x.22893] 
[0.x.22894] 
[0.x.22895] 
[0.x.22896] 
[0.x.22897] 
[0.x.22898] 
[0.x.22899] 
[0.x.22900] 
[0.x.22901] 
[0.x.22902] 
[0.x.22903] 
[0.x.22904] 
[0.x.22905] 
//[2.x.2949] 
//
// This function implements the operator splitting algorithm, i.e. in each time step it either re-computes the solution of the Darcy system or extrapolates velocity/pressure from previous time steps, then determines the size of the time step, and then updates the saturation variable. The implementation largely follows similar code in  [2.x.2950] . It is, next to the run() function, the central one in this program.
//
// At the beginning of the function, we ask whether to solve the pressure-velocity part by evaluating the a posteriori criterion (see the following function). If necessary, we will solve the pressure-velocity part using the GMRES solver with the Schur complement block preconditioner as is described in the introduction.
//
[0.x.22906] 
[0.x.22907] 
[0.x.22908] 
[0.x.22909] 
[0.x.22910] 
//
[0.x.22911] 
[0.x.22912] 
[0.x.22913] 
[0.x.22914] 
//
[0.x.22915] 
[0.x.22916] 
//
[0.x.22917] 
[0.x.22918] 
[0.x.22919] 
[0.x.22920] 
[0.x.22921] 
//
[0.x.22922] 
[0.x.22923] 
[0.x.22924] 
[0.x.22925] 
//
[0.x.22926] 
[0.x.22927] 
//
[0.x.22928] 
[0.x.22929] 
[0.x.22930] 
[0.x.22931] 
//
[0.x.22932] 
[0.x.22933] 
[0.x.22934] 
//
[0.x.22935] 
//
[0.x.22936] 
//
[0.x.22937] 
[0.x.22938] 
[0.x.22939] 
//
[0.x.22940] 
[0.x.22941] 
[0.x.22942] 
//
[0.x.22943] 
[0.x.22944] 
[0.x.22945] 
[0.x.22946] 
//
// On the other hand, if we have decided that we don't want to compute the solution of the Darcy system for the current time step, then we need to simply extrapolate the previous two Darcy solutions to the same time as we would have computed the velocity/pressure at. We do a simple linear extrapolation, i.e. given the current length  [2.x.2951]  of the macro time step from the time when we last computed the Darcy solution to now (given by  [2.x.2952] ), and  [2.x.2953]  the length of the last macro time step (given by  [2.x.2954] ), then we get  [2.x.2955] , where  [2.x.2956]  and  [2.x.2957]  are the last two computed Darcy solutions. We can implement this formula using just two lines of code.
//
// Note that the algorithm here only works if we have at least two previously computed Darcy solutions from which we can extrapolate to the current time, and this is ensured by requiring re-computation of the Darcy solution for the first 2 time steps.
//
[0.x.22947] 
[0.x.22948] 
[0.x.22949] 
[0.x.22950] 
[0.x.22951] 
[0.x.22952] 
[0.x.22953] 
//
// With the so computed velocity vector, compute the optimal time step based on the CFL criterion discussed in the introduction...
//
[0.x.22954] 
[0.x.22955] 
//
[0.x.22956] 
[0.x.22957] 
[0.x.22958] 
[0.x.22959] 
[0.x.22960] 
[0.x.22961] 
[0.x.22962] 
//
// ...and then also update the length of the macro time steps we use while we're dealing with time step sizes. In particular, this involves: (i) If we have just recomputed the Darcy solution, then the length of the previous macro time step is now fixed and the length of the current macro time step is, up to now, simply the length of the current (micro) time step. (ii) If we have not recomputed the Darcy solution, then the length of the current macro time step has just grown by  [2.x.2958] .
//
[0.x.22963] 
[0.x.22964] 
[0.x.22965] 
[0.x.22966] 
[0.x.22967] 
[0.x.22968] 
[0.x.22969] 
//
// The last step in this function is to recompute the saturation solution based on the velocity field we've just obtained. This naturally happens in every time step, and we don't skip any of these computations. At the end of computing the saturation, we project back into the allowed interval  [2.x.2959]  to make sure our solution remains physical.
//
[0.x.22970] 
[0.x.22971] 
//
[0.x.22972] 
//
[0.x.22973] 
[0.x.22974] 
[0.x.22975] 
//
[0.x.22976] 
[0.x.22977] 
//
[0.x.22978] 
[0.x.22979] 
[0.x.22980] 
[0.x.22981] 
//
[0.x.22982] 
[0.x.22983] 
//
[0.x.22984] 
[0.x.22985] 
[0.x.22986] 
[0.x.22987] 
//[2.x.2960] 
//
// The next function does the refinement and coarsening of the mesh. It does its work in three blocks: (i) Compute refinement indicators by looking at the gradient of a solution vector extrapolated linearly from the previous two using the respective sizes of the time step (or taking the only solution we have if this is the first time step). (ii) Flagging those cells for refinement and coarsening where the gradient is larger or smaller than a certain threshold, preserving minimal and maximal levels of mesh refinement. (iii) Transferring the solution from the old to the new mesh. None of this is particularly difficult.
//
[0.x.22988] 
[0.x.22989] 
[0.x.22990] 
[0.x.22991] 
[0.x.22992] 
[0.x.22993] 
[0.x.22994] 
[0.x.22995] 
[0.x.22996] 
[0.x.22997] 
[0.x.22998] 
//
[0.x.22999] 
[0.x.23000] 
[0.x.23001] 
[0.x.23002] 
[0.x.23003] 
[0.x.23004] 
//
[0.x.23005] 
[0.x.23006] 
[0.x.23007] 
[0.x.23008] 
[0.x.23009] 
[0.x.23010] 
//
[0.x.23011] 
[0.x.23012] 
[0.x.23013] 
//
[0.x.23014] 
[0.x.23015] 
[0.x.23016] 
[0.x.23017] 
[0.x.23018] 
[0.x.23019] 
//
[0.x.23020] 
[0.x.23021] 
[0.x.23022] 
[0.x.23023] 
[0.x.23024] 
[0.x.23025] 
[0.x.23026] 
[0.x.23027] 
[0.x.23028] 
[0.x.23029] 
[0.x.23030] 
//
[0.x.23031] 
//
[0.x.23032] 
[0.x.23033] 
[0.x.23034] 
[0.x.23035] 
[0.x.23036] 
//
[0.x.23037] 
[0.x.23038] 
[0.x.23039] 
//
[0.x.23040] 
[0.x.23041] 
//
[0.x.23042] 
[0.x.23043] 
//
[0.x.23044] 
[0.x.23045] 
//
[0.x.23046] 
//
[0.x.23047] 
[0.x.23048] 
//
[0.x.23049] 
[0.x.23050] 
[0.x.23051] 
[0.x.23052] 
[0.x.23053] 
//
[0.x.23054] 
[0.x.23055] 
[0.x.23056] 
//
[0.x.23057] 
[0.x.23058] 
[0.x.23059] 
[0.x.23060] 
//
[0.x.23061] 
[0.x.23062] 
[0.x.23063] 
[0.x.23064] 
//
[0.x.23065] 
[0.x.23066] 
//
[0.x.23067] 
[0.x.23068] 
//
[0.x.23069] 
[0.x.23070] 
[0.x.23071] 
//
//  [2.x.2961] 
//
// This function generates graphical output. It is in essence a copy of the implementation in  [2.x.2962] .
//
[0.x.23072] 
[0.x.23073] 
[0.x.23074] 
[0.x.23075] 
[0.x.23076] 
[0.x.23077] 
[0.x.23078] 
[0.x.23079] 
[0.x.23080] 
//
[0.x.23081] 
//
[0.x.23082] 
[0.x.23083] 
[0.x.23084] 
[0.x.23085] 
[0.x.23086] 
[0.x.23087] 
[0.x.23088] 
//
[0.x.23089] 
[0.x.23090] 
[0.x.23091] 
[0.x.23092] 
//
[0.x.23093] 
[0.x.23094] 
[0.x.23095] 
[0.x.23096] 
[0.x.23097] 
[0.x.23098] 
//
[0.x.23099] 
[0.x.23100] 
[0.x.23101] 
[0.x.23102] 
[0.x.23103] 
[0.x.23104] 
[0.x.23105] 
[0.x.23106] 
[0.x.23107] 
[0.x.23108] 
[0.x.23109] 
[0.x.23110] 
[0.x.23111] 
[0.x.23112] 
[0.x.23113] 
[0.x.23114] 
[0.x.23115] 
[0.x.23116] 
[0.x.23117] 
[0.x.23118] 
[0.x.23119] 
[0.x.23120] 
[0.x.23121] 
[0.x.23122] 
[0.x.23123] 
[0.x.23124] 
[0.x.23125] 
//
[0.x.23126] 
[0.x.23127] 
[0.x.23128] 
[0.x.23129] 
[0.x.23130] 
[0.x.23131] 
[0.x.23132] 
//
[0.x.23133] 
//
[0.x.23134] 
[0.x.23135] 
[0.x.23136] 
[0.x.23137] 
[0.x.23138] 
//
[0.x.23139] 
//
[0.x.23140] 
[0.x.23141] 
[0.x.23142] 
[0.x.23143] 
[0.x.23144] 
//
//  [2.x.2963] 
//[2.x.2964] 
//
// This function implements the a posteriori criterion for adaptive operator splitting. The function is relatively straightforward given the way we have implemented other functions above and given the formula for the criterion derived in the paper.
//
// If one decides that one wants the original IMPES method in which the Darcy equation is solved in every time step, then this can be achieved by setting the threshold value  [2.x.2965]  (with a default of  [2.x.2966] ) to zero, thereby forcing the function to always return true.
//
// Finally, note that the function returns true unconditionally for the first two time steps to ensure that we have always solved the Darcy system at least twice when skipping its solution, thereby allowing us to extrapolate the velocity from the last two solutions in  [2.x.2967] .
//
[0.x.23145] 
[0.x.23146] 
[0.x.23147] 
[0.x.23148] 
[0.x.23149] 
[0.x.23150] 
//
[0.x.23151] 
[0.x.23152] 
//
[0.x.23153] 
[0.x.23154] 
[0.x.23155] 
//
[0.x.23156] 
[0.x.23157] 
//
[0.x.23158] 
//
[0.x.23159] 
//
[0.x.23160] 
[0.x.23161] 
[0.x.23162] 
[0.x.23163] 
//
[0.x.23164] 
[0.x.23165] 
[0.x.23166] 
[0.x.23167] 
[0.x.23168] 
//
[0.x.23169] 
[0.x.23170] 
//
[0.x.23171] 
[0.x.23172] 
[0.x.23173] 
[0.x.23174] 
[0.x.23175] 
[0.x.23176] 
//
[0.x.23177] 
[0.x.23178] 
[0.x.23179] 
//
[0.x.23180] 
[0.x.23181] 
[0.x.23182] 
[0.x.23183] 
//
[0.x.23184] 
[0.x.23185] 
[0.x.23186] 
[0.x.23187] 
[0.x.23188] 
//
[0.x.23189] 
[0.x.23190] 
//
//  [2.x.2968] 
//
// The next function simply makes sure that the saturation values always remain within the physically reasonable range of  [2.x.2969] . While the continuous equations guarantee that this is so, the discrete equations don't. However, if we allow the discrete solution to escape this range we get into trouble because terms like  [2.x.2970]  and  [2.x.2971]  will produce unreasonable results (e.g.  [2.x.2972]  for  [2.x.2973] , which would imply that the wetting fluid phase flows [1.x.92] the direction of the bulk fluid velocity)). Consequently, at the end of each time step, we simply project the saturation field back into the physically reasonable region.
//
[0.x.23191] 
[0.x.23192] 
[0.x.23193] 
[0.x.23194] 
[0.x.23195] 
[0.x.23196] 
[0.x.23197] 
[0.x.23198] 
[0.x.23199] 
//
//  [2.x.2974] 
//
// Another simpler helper function: Compute the maximum of the total velocity times the derivative of the fraction flow function, i.e., compute  [2.x.2975] . This term is used in both the computation of the time step as well as in normalizing the entropy-residual term in the artificial viscosity.
//
[0.x.23200] 
[0.x.23201] 
[0.x.23202] 
[0.x.23203] 
[0.x.23204] 
//
[0.x.23205] 
[0.x.23206] 
[0.x.23207] 
[0.x.23208] 
//
[0.x.23209] 
[0.x.23210] 
[0.x.23211] 
//
[0.x.23212] 
//
[0.x.23213] 
[0.x.23214] 
[0.x.23215] 
[0.x.23216] 
[0.x.23217] 
[0.x.23218] 
[0.x.23219] 
//
[0.x.23220] 
[0.x.23221] 
[0.x.23222] 
[0.x.23223] 
//
[0.x.23224] 
[0.x.23225] 
[0.x.23226] 
[0.x.23227] 
[0.x.23228] 
//
[0.x.23229] 
[0.x.23230] 
//
[0.x.23231] 
[0.x.23232] 
[0.x.23233] 
[0.x.23234] 
//
[0.x.23235] 
[0.x.23236] 
//[2.x.2976] 
//
// For computing the stabilization term, we need to know the range of the saturation variable. Unlike in  [2.x.2977] , this range is trivially bounded by the interval  [2.x.2978]  but we can do a bit better by looping over a collection of quadrature points and seeing what the values are there. If we can, i.e., if there are at least two timesteps around, we can even take the values extrapolated to the next time step.
//
// As before, the function is taken with minimal modifications from  [2.x.2979] .
//
[0.x.23237] 
[0.x.23238] 
[0.x.23239] 
[0.x.23240] 
[0.x.23241] 
[0.x.23242] 
//
[0.x.23243] 
[0.x.23244] 
[0.x.23245] 
//
[0.x.23246] 
[0.x.23247] 
[0.x.23248] 
[0.x.23249] 
//
[0.x.23250] 
[0.x.23251] 
[0.x.23252] 
[0.x.23253] 
[0.x.23254] 
[0.x.23255] 
[0.x.23256] 
//
[0.x.23257] 
[0.x.23258] 
[0.x.23259] 
[0.x.23260] 
[0.x.23261] 
//
[0.x.23262] 
[0.x.23263] 
[0.x.23264] 
[0.x.23265] 
//
[0.x.23266] 
[0.x.23267] 
[0.x.23268] 
[0.x.23269] 
[0.x.23270] 
[0.x.23271] 
//
[0.x.23272] 
[0.x.23273] 
[0.x.23274] 
[0.x.23275] 
[0.x.23276] 
//
[0.x.23277] 
[0.x.23278] 
[0.x.23279] 
//
[0.x.23280] 
[0.x.23281] 
[0.x.23282] 
[0.x.23283] 
//
[0.x.23284] 
[0.x.23285] 
[0.x.23286] 
//
//  [2.x.2980] 
//
// The final tool function is used to compute the artificial viscosity on a given cell. This isn't particularly complicated if you have the formula for it in front of you, and looking at the implementation in  [2.x.2981] . The major difference to that tutorial program is that the velocity here is not simply  [2.x.2982]  but  [2.x.2983]  and some of the formulas need to be adjusted accordingly.
//
[0.x.23287] 
[0.x.23288] 
[0.x.23289] 
[0.x.23290] 
[0.x.23291] 
[0.x.23292] 
[0.x.23293] 
[0.x.23294] 
[0.x.23295] 
[0.x.23296] 
[0.x.23297] 
[0.x.23298] 
[0.x.23299] 
//
[0.x.23300] 
[0.x.23301] 
//
[0.x.23302] 
//
[0.x.23303] 
[0.x.23304] 
//
[0.x.23305] 
//
[0.x.23306] 
[0.x.23307] 
[0.x.23308] 
[0.x.23309] 
[0.x.23310] 
//
[0.x.23311] 
[0.x.23312] 
[0.x.23313] 
//
[0.x.23314] 
[0.x.23315] 
//
[0.x.23316] 
[0.x.23317] 
[0.x.23318] 
//
[0.x.23319] 
[0.x.23320] 
[0.x.23321] 
[0.x.23322] 
//
[0.x.23323] 
[0.x.23324] 
[0.x.23325] 
[0.x.23326] 
[0.x.23327] 
//
[0.x.23328] 
[0.x.23329] 
[0.x.23330] 
[0.x.23331] 
//
[0.x.23332] 
[0.x.23333] 
[0.x.23334] 
[0.x.23335] 
[0.x.23336] 
[0.x.23337] 
//[2.x.2984] 
//
// This function is, besides  [2.x.2985] , the primary function of this program as it controls the time iteration as well as when the solution is written into output files and when to do mesh refinement.
//
// With the exception of the startup code that loops back to the beginning of the function through the  [2.x.2986]  label, everything should be relatively straightforward. In any case, it mimics the corresponding function in  [2.x.2987] .
//
[0.x.23338] 
[0.x.23339] 
[0.x.23340] 
[0.x.23341] 
[0.x.23342] 
//
[0.x.23343] 
[0.x.23344] 
[0.x.23345] 
//
[0.x.23346] 
//
[0.x.23347] 
//
[0.x.23348] 
//
[0.x.23349] 
[0.x.23350] 
[0.x.23351] 
[0.x.23352] 
[0.x.23353] 
//
[0.x.23354] 
[0.x.23355] 
//
[0.x.23356] 
//
[0.x.23357] 
[0.x.23358] 
[0.x.23359] 
[0.x.23360] 
//
[0.x.23361] 
//
[0.x.23362] 
//
[0.x.23363] 
[0.x.23364] 
//
[0.x.23365] 
[0.x.23366] 
[0.x.23367] 
//
[0.x.23368] 
[0.x.23369] 
[0.x.23370] 
[0.x.23371] 
[0.x.23372] 
[0.x.23373] 
//
[0.x.23374] 
[0.x.23375] 
//
[0.x.23376] 
[0.x.23377] 
[0.x.23378] 
[0.x.23379] 
[0.x.23380] 
[0.x.23381] 
//
//  [2.x.2988] 
//
// The main function looks almost the same as in all other programs. The need to initialize the MPI subsystem for a program that uses Trilinos -- even for programs that do not actually run in parallel -- is explained in  [2.x.2989] .
//
[0.x.23382] 
[0.x.23383] 
[0.x.23384] 
[0.x.23385] 
[0.x.23386] 
[0.x.23387] 
//
[0.x.23388] 
[0.x.23389] 
//
// This program can only be run in serial. Otherwise, throw an exception.
//
[0.x.23390] 
[0.x.23391] 
[0.x.23392] 
//
[0.x.23393] 
[0.x.23394] 
[0.x.23395] 
[0.x.23396] 
[0.x.23397] 
[0.x.23398] 
[0.x.23399] 
[0.x.23400] 
[0.x.23401] 
[0.x.23402] 
[0.x.23403] 
[0.x.23404] 
[0.x.23405] 
[0.x.23406] 
//
[0.x.23407] 
[0.x.23408] 
[0.x.23409] 
[0.x.23410] 
[0.x.23411] 
[0.x.23412] 
[0.x.23413] 
[0.x.23414] 
[0.x.23415] 
[0.x.23416] 
[0.x.23417] 
[0.x.23418] 
[0.x.23419] 
[0.x.23420] 
//
[0.x.23421] 
[0.x.23422] 
[0.x.23423] 
[0.x.23424] 
[0.x.23425] 
[0.x.23426] 
[0.x.23427] 
[0.x.23428] 
[0.x.23429] 
[0.x.23430] 
[0.x.23431] 
[0.x.23432] 
[0.x.23433] 
[0.x.23434] 
[0.x.23435] 
[0.x.23436] 
[0.x.23437] 
//
[0.x.23438] 
[0.x.23439] 
[0.x.23440] 
[0.x.23441] 
//
// We start by including all the necessary deal.II header files and some C++ related ones. They have been discussed in detail in previous tutorial programs, so you need only refer to past tutorials for details.
//
[0.x.23442] 
[0.x.23443] 
[0.x.23444] 
[0.x.23445] 
[0.x.23446] 
[0.x.23447] 
[0.x.23448] 
[0.x.23449] 
[0.x.23450] 
[0.x.23451] 
//
// This header gives us the functionality to store data at quadrature points
//
[0.x.23452] 
//
[0.x.23453] 
[0.x.23454] 
[0.x.23455] 
[0.x.23456] 
//
[0.x.23457] 
[0.x.23458] 
[0.x.23459] 
[0.x.23460] 
[0.x.23461] 
[0.x.23462] 
//
[0.x.23463] 
[0.x.23464] 
[0.x.23465] 
[0.x.23466] 
[0.x.23467] 
[0.x.23468] 
[0.x.23469] 
[0.x.23470] 
[0.x.23471] 
//
// Here are the headers necessary to use the LinearOperator class. These are also all conveniently packaged into a single header file, namely <deal.II/lac/linear_operator_tools.h> but we list those specifically required here for the sake of transparency.
//
[0.x.23472] 
[0.x.23473] 
//
[0.x.23474] 
[0.x.23475] 
//
// Defined in these two headers are some operations that are pertinent to finite strain elasticity. The first will help us compute some kinematic quantities, and the second provides some stanard tensor definitions.
//
[0.x.23476] 
[0.x.23477] 
//
[0.x.23478] 
[0.x.23479] 
//
// We then stick everything that relates to this tutorial program into a namespace of its own, and import all the deal.II function and class names into it:
//
[0.x.23480] 
[0.x.23481] 
[0.x.23482] 
//[2.x.2990] 
//
// There are several parameters that can be set in the code so we set up a ParameterHandler object to read in the choices at run-time.
//
[0.x.23483] 
[0.x.23484] 
//[2.x.2991] 
//
// As mentioned in the introduction, a different order interpolation should be used for the displacement  [2.x.2992]  than for the pressure  [2.x.2993]  and the dilatation  [2.x.2994] .  Choosing  [2.x.2995]  and  [2.x.2996]  as discontinuous (constant) functions at the element level leads to the mean-dilatation method. The discontinuous approximation allows  [2.x.2997]  and  [2.x.2998]  to be condensed out and a classical displacement based method is recovered. Here we specify the polynomial order used to approximate the solution. The quadrature order should be adjusted accordingly.
//
[0.x.23485] 
[0.x.23486] 
[0.x.23487] 
[0.x.23488] 
//
[0.x.23489] 
//
[0.x.23490] 
[0.x.23491] 
//
[0.x.23492] 
[0.x.23493] 
[0.x.23494] 
[0.x.23495] 
[0.x.23496] 
[0.x.23497] 
[0.x.23498] 
[0.x.23499] 
//
[0.x.23500] 
[0.x.23501] 
[0.x.23502] 
[0.x.23503] 
[0.x.23504] 
[0.x.23505] 
[0.x.23506] 
//
[0.x.23507] 
[0.x.23508] 
[0.x.23509] 
[0.x.23510] 
[0.x.23511] 
[0.x.23512] 
[0.x.23513] 
[0.x.23514] 
[0.x.23515] 
//[2.x.2999] 
//
// Make adjustments to the problem geometry and the applied load.  Since the problem modelled here is quite specific, the load scale can be altered to specific values to compare with the results given in the literature.
//
[0.x.23516] 
[0.x.23517] 
[0.x.23518] 
[0.x.23519] 
[0.x.23520] 
//
[0.x.23521] 
//
[0.x.23522] 
[0.x.23523] 
//
[0.x.23524] 
[0.x.23525] 
[0.x.23526] 
[0.x.23527] 
[0.x.23528] 
[0.x.23529] 
[0.x.23530] 
[0.x.23531] 
//
[0.x.23532] 
[0.x.23533] 
[0.x.23534] 
[0.x.23535] 
//
[0.x.23536] 
[0.x.23537] 
[0.x.23538] 
[0.x.23539] 
[0.x.23540] 
[0.x.23541] 
[0.x.23542] 
//
[0.x.23543] 
[0.x.23544] 
[0.x.23545] 
[0.x.23546] 
[0.x.23547] 
[0.x.23548] 
[0.x.23549] 
[0.x.23550] 
[0.x.23551] 
[0.x.23552] 
//[2.x.3000] 
//
// We also need the shear modulus  [2.x.3001]  and Poisson ration  [2.x.3002]  for the neo-Hookean material.
//
[0.x.23553] 
[0.x.23554] 
[0.x.23555] 
[0.x.23556] 
//
[0.x.23557] 
//
[0.x.23558] 
[0.x.23559] 
//
[0.x.23560] 
[0.x.23561] 
[0.x.23562] 
[0.x.23563] 
[0.x.23564] 
[0.x.23565] 
[0.x.23566] 
[0.x.23567] 
//
[0.x.23568] 
[0.x.23569] 
[0.x.23570] 
[0.x.23571] 
[0.x.23572] 
[0.x.23573] 
[0.x.23574] 
//
[0.x.23575] 
[0.x.23576] 
[0.x.23577] 
[0.x.23578] 
[0.x.23579] 
[0.x.23580] 
[0.x.23581] 
[0.x.23582] 
[0.x.23583] 
//[2.x.3003] 
//
// Next, we choose both solver and preconditioner settings.  The use of an effective preconditioner is critical to ensure convergence when a large nonlinear motion occurs within a Newton increment.
//
[0.x.23584] 
[0.x.23585] 
[0.x.23586] 
[0.x.23587] 
[0.x.23588] 
[0.x.23589] 
[0.x.23590] 
[0.x.23591] 
//
[0.x.23592] 
//
[0.x.23593] 
[0.x.23594] 
//
[0.x.23595] 
[0.x.23596] 
[0.x.23597] 
[0.x.23598] 
[0.x.23599] 
[0.x.23600] 
[0.x.23601] 
[0.x.23602] 
//
[0.x.23603] 
[0.x.23604] 
[0.x.23605] 
[0.x.23606] 
//
[0.x.23607] 
[0.x.23608] 
[0.x.23609] 
[0.x.23610] 
[0.x.23611] 
//
[0.x.23612] 
[0.x.23613] 
[0.x.23614] 
[0.x.23615] 
//
[0.x.23616] 
[0.x.23617] 
[0.x.23618] 
[0.x.23619] 
//
[0.x.23620] 
[0.x.23621] 
[0.x.23622] 
[0.x.23623] 
[0.x.23624] 
[0.x.23625] 
[0.x.23626] 
//
[0.x.23627] 
[0.x.23628] 
[0.x.23629] 
[0.x.23630] 
[0.x.23631] 
[0.x.23632] 
[0.x.23633] 
[0.x.23634] 
[0.x.23635] 
[0.x.23636] 
[0.x.23637] 
[0.x.23638] 
[0.x.23639] 
//[2.x.3004] 
//
// A Newton-Raphson scheme is used to solve the nonlinear system of governing equations.  We now define the tolerances and the maximum number of iterations for the Newton-Raphson nonlinear solver.
//
[0.x.23640] 
[0.x.23641] 
[0.x.23642] 
[0.x.23643] 
[0.x.23644] 
//
[0.x.23645] 
//
[0.x.23646] 
[0.x.23647] 
//
[0.x.23648] 
[0.x.23649] 
[0.x.23650] 
[0.x.23651] 
[0.x.23652] 
[0.x.23653] 
[0.x.23654] 
[0.x.23655] 
//
[0.x.23656] 
[0.x.23657] 
[0.x.23658] 
[0.x.23659] 
//
[0.x.23660] 
[0.x.23661] 
[0.x.23662] 
[0.x.23663] 
[0.x.23664] 
[0.x.23665] 
[0.x.23666] 
//
[0.x.23667] 
[0.x.23668] 
[0.x.23669] 
[0.x.23670] 
[0.x.23671] 
[0.x.23672] 
[0.x.23673] 
[0.x.23674] 
[0.x.23675] 
[0.x.23676] 
//[2.x.3005] 
//
// Set the timestep size  [2.x.3006]  and the simulation end-time.
//
[0.x.23677] 
[0.x.23678] 
[0.x.23679] 
[0.x.23680] 
//
[0.x.23681] 
//
[0.x.23682] 
[0.x.23683] 
//
[0.x.23684] 
[0.x.23685] 
[0.x.23686] 
[0.x.23687] 
[0.x.23688] 
//
[0.x.23689] 
[0.x.23690] 
[0.x.23691] 
[0.x.23692] 
[0.x.23693] 
[0.x.23694] 
[0.x.23695] 
//
[0.x.23696] 
[0.x.23697] 
[0.x.23698] 
[0.x.23699] 
[0.x.23700] 
[0.x.23701] 
[0.x.23702] 
[0.x.23703] 
[0.x.23704] 
//[2.x.3007] 
//
// Finally we consolidate all of the above structures into a single container that holds all of our run-time selections.
//
[0.x.23705] 
[0.x.23706] 
[0.x.23707] 
[0.x.23708] 
[0.x.23709] 
[0.x.23710] 
//
[0.x.23711] 
[0.x.23712] 
//
[0.x.23713] 
//
[0.x.23714] 
[0.x.23715] 
//
[0.x.23716] 
[0.x.23717] 
[0.x.23718] 
[0.x.23719] 
[0.x.23720] 
[0.x.23721] 
[0.x.23722] 
//
[0.x.23723] 
[0.x.23724] 
[0.x.23725] 
[0.x.23726] 
[0.x.23727] 
[0.x.23728] 
[0.x.23729] 
[0.x.23730] 
[0.x.23731] 
//
[0.x.23732] 
[0.x.23733] 
[0.x.23734] 
[0.x.23735] 
[0.x.23736] 
[0.x.23737] 
[0.x.23738] 
[0.x.23739] 
[0.x.23740] 
[0.x.23741] 
//[2.x.3008] 
//
// A simple class to store time data. Its functioning is transparent so no discussion is necessary. For simplicity we assume a constant time step size.
//
[0.x.23742] 
[0.x.23743] 
[0.x.23744] 
[0.x.23745] 
[0.x.23746] 
[0.x.23747] 
[0.x.23748] 
[0.x.23749] 
[0.x.23750] 
//
[0.x.23751] 
//
[0.x.23752] 
[0.x.23753] 
[0.x.23754] 
[0.x.23755] 
[0.x.23756] 
[0.x.23757] 
[0.x.23758] 
[0.x.23759] 
[0.x.23760] 
[0.x.23761] 
[0.x.23762] 
[0.x.23763] 
[0.x.23764] 
[0.x.23765] 
[0.x.23766] 
[0.x.23767] 
[0.x.23768] 
[0.x.23769] 
[0.x.23770] 
[0.x.23771] 
[0.x.23772] 
//
[0.x.23773] 
[0.x.23774] 
[0.x.23775] 
[0.x.23776] 
[0.x.23777] 
[0.x.23778] 
//[2.x.3009] 
//
// As discussed in the Introduction, Neo-Hookean materials are a type of hyperelastic materials.  The entire domain is assumed to be composed of a compressible neo-Hookean material.  This class defines the behavior of this material within a three-field formulation.  Compressible neo-Hookean materials can be described by a strain-energy function (SEF)  [2.x.3010] .
//
// The isochoric response is given by  [2.x.3011]  where  [2.x.3012]  and  [2.x.3013]  is the first invariant of the left- or right-isochoric Cauchy-Green deformation tensors. That is  [2.x.3014] . In this example the SEF that governs the volumetric response is defined as  [2.x.3015] , where  [2.x.3016]  is the [1.x.93] and  [2.x.3017]  is [1.x.94].
//
// The following class will be used to characterize the material we work with, and provides a central point that one would need to modify if one were to implement a different material model. For it to work, we will store one object of this type per quadrature point, and in each of these objects store the current state (characterized by the values or measures  of the three fields) so that we can compute the elastic coefficients linearized around the current state.
//
[0.x.23779] 
[0.x.23780] 
[0.x.23781] 
[0.x.23782] 
[0.x.23783] 
[0.x.23784] 
[0.x.23785] 
[0.x.23786] 
[0.x.23787] 
[0.x.23788] 
[0.x.23789] 
[0.x.23790] 
[0.x.23791] 
[0.x.23792] 
//
// We update the material model with various deformation dependent data based on  [2.x.3018]  and the pressure  [2.x.3019]  and dilatation  [2.x.3020] , and at the end of the function include a physical check for internal consistency:
//
[0.x.23793] 
[0.x.23794] 
[0.x.23795] 
[0.x.23796] 
[0.x.23797] 
[0.x.23798] 
[0.x.23799] 
[0.x.23800] 
[0.x.23801] 
//
[0.x.23802] 
[0.x.23803] 
//
// The second function determines the Kirchhoff stress  [2.x.3021] 
[0.x.23804] 
[0.x.23805] 
[0.x.23806] 
[0.x.23807] 
//
// The fourth-order elasticity tensor in the spatial setting  [2.x.3022]  is calculated from the SEF  [2.x.3023]  as  [2.x.3024]  where  [2.x.3025] 
[0.x.23808] 
[0.x.23809] 
[0.x.23810] 
[0.x.23811] 
//
// Derivative of the volumetric free energy with respect to  [2.x.3026]  return  [2.x.3027] 
[0.x.23812] 
[0.x.23813] 
[0.x.23814] 
[0.x.23815] 
//
// Second derivative of the volumetric free energy wrt  [2.x.3028] . We need the following computation explicitly in the tangent so we make it public.  We calculate  [2.x.3029] 
[0.x.23816] 
[0.x.23817] 
[0.x.23818] 
[0.x.23819] 
//
// The next few functions return various data that we choose to store with the material:
//
[0.x.23820] 
[0.x.23821] 
[0.x.23822] 
[0.x.23823] 
//
[0.x.23824] 
[0.x.23825] 
[0.x.23826] 
[0.x.23827] 
//
[0.x.23828] 
[0.x.23829] 
[0.x.23830] 
[0.x.23831] 
//
[0.x.23832] 
//
// Define constitutive model parameters  [2.x.3030]  (bulk modulus) and the neo-Hookean model parameter  [2.x.3031] :
//
[0.x.23833] 
[0.x.23834] 
//
// Model specific data that is convenient to store with the material:
//
[0.x.23835] 
[0.x.23836] 
[0.x.23837] 
[0.x.23838] 
//
// The following functions are used internally in determining the result of some of the public functions above. The first one determines the volumetric Kirchhoff stress  [2.x.3032] :
//
[0.x.23839] 
[0.x.23840] 
[0.x.23841] 
[0.x.23842] 
//
// Next, determine the isochoric Kirchhoff stress  [2.x.3033] :
//
[0.x.23843] 
[0.x.23844] 
[0.x.23845] 
[0.x.23846] 
//
// Then, determine the fictitious Kirchhoff stress  [2.x.3034] :
//
[0.x.23847] 
[0.x.23848] 
[0.x.23849] 
[0.x.23850] 
//
// Calculate the volumetric part of the tangent  [2.x.3035] :
//
[0.x.23851] 
[0.x.23852] 
[0.x.23853] 
[0.x.23854] 
[0.x.23855] 
[0.x.23856] 
//
// Calculate the isochoric part of the tangent  [2.x.3036] :
//
[0.x.23857] 
[0.x.23858] 
[0.x.23859] 
[0.x.23860] 
[0.x.23861] 
[0.x.23862] 
[0.x.23863] 
[0.x.23864] 
[0.x.23865] 
//
[0.x.23866] 
[0.x.23867] 
[0.x.23868] 
[0.x.23869] 
[0.x.23870] 
[0.x.23871] 
//
// Calculate the fictitious elasticity tensor  [2.x.3037] . For the material model chosen this is simply zero:
//
[0.x.23872] 
[0.x.23873] 
[0.x.23874] 
[0.x.23875] 
[0.x.23876] 
//[2.x.3038] 
//
// As seen in  [2.x.3039] , the  [2.x.3040]  class offers a method for storing data at the quadrature points.  Here each quadrature point holds a pointer to a material description.  Thus, different material models can be used in different regions of the domain.  Among other data, we choose to store the Kirchhoff stress  [2.x.3041]  and the tangent  [2.x.3042]  for the quadrature points.
//
[0.x.23877] 
[0.x.23878] 
[0.x.23879] 
[0.x.23880] 
[0.x.23881] 
[0.x.23882] 
[0.x.23883] 
[0.x.23884] 
[0.x.23885] 
[0.x.23886] 
[0.x.23887] 
//
[0.x.23888] 
//
// The first function is used to create a material object and to initialize all tensors correctly: The second one updates the stored values and stresses based on the current deformation measure  [2.x.3043] , pressure  [2.x.3044]  and dilation  [2.x.3045]  field values.
//
[0.x.23889] 
[0.x.23890] 
[0.x.23891] 
[0.x.23892] 
[0.x.23893] 
[0.x.23894] 
[0.x.23895] 
//
// To this end, we calculate the deformation gradient  [2.x.3046]  from the displacement gradient  [2.x.3047] , i.e.  [2.x.3048]  and then let the material model associated with this quadrature point update itself. When computing the deformation gradient, we have to take care with which data types we compare the sum  [2.x.3049] : Since  [2.x.3050]  has data type SymmetricTensor, just writing  [2.x.3051]  would convert the second argument to a symmetric tensor, perform the sum, and then cast the result to a Tensor (i.e., the type of a possibly nonsymmetric tensor). However, since  [2.x.3052]  is nonsymmetric in general, the conversion to SymmetricTensor will fail. We can avoid this back and forth by converting  [2.x.3053]  to Tensor first, and then performing the addition as between nonsymmetric tensors:
//
[0.x.23896] 
[0.x.23897] 
[0.x.23898] 
[0.x.23899] 
[0.x.23900] 
[0.x.23901] 
//
// The material has been updated so we now calculate the Kirchhoff stress  [2.x.3054] , the tangent  [2.x.3055]  and the first and second derivatives of the volumetric free energy.
//
// We also store the inverse of the deformation gradient since we frequently use it:
//
[0.x.23902] 
[0.x.23903] 
[0.x.23904] 
[0.x.23905] 
[0.x.23906] 
[0.x.23907] 
//
// We offer an interface to retrieve certain data.  Here are the kinematic variables:
//
[0.x.23908] 
[0.x.23909] 
[0.x.23910] 
[0.x.23911] 
//
[0.x.23912] 
[0.x.23913] 
[0.x.23914] 
[0.x.23915] 
//
[0.x.23916] 
[0.x.23917] 
[0.x.23918] 
[0.x.23919] 
//
// ...and the kinetic variables.  These are used in the material and global tangent matrix and residual assembly operations:
//
[0.x.23920] 
[0.x.23921] 
[0.x.23922] 
[0.x.23923] 
//
[0.x.23924] 
[0.x.23925] 
[0.x.23926] 
[0.x.23927] 
//
[0.x.23928] 
[0.x.23929] 
[0.x.23930] 
[0.x.23931] 
//
[0.x.23932] 
[0.x.23933] 
[0.x.23934] 
[0.x.23935] 
//
// And finally the tangent:
//
[0.x.23936] 
[0.x.23937] 
[0.x.23938] 
[0.x.23939] 
//
// In terms of member functions, this class stores for the quadrature point it represents a copy of a material type in case different materials are used in different regions of the domain, as well as the inverse of the deformation gradient...
//
[0.x.23940] 
[0.x.23941] 
//
[0.x.23942] 
//
// ... and stress-type variables along with the tangent  [2.x.3056] :
//
[0.x.23943] 
[0.x.23944] 
[0.x.23945] 
//
[0.x.23946] 
[0.x.23947] 
//[2.x.3057] 
//
// The Solid class is the central class in that it represents the problem at hand. It follows the usual scheme in that all it really has is a constructor, destructor and a  [2.x.3058]  function that dispatches all the work to private functions of this class:
//
[0.x.23948] 
[0.x.23949] 
[0.x.23950] 
[0.x.23951] 
[0.x.23952] 
//
[0.x.23953] 
//
[0.x.23954] 
//
// In the private section of this class, we first forward declare a number of objects that are used in parallelizing work using the WorkStream object (see the  [2.x.3059]  module for more information on this).
//
// We declare such structures for the computation of tangent (stiffness) matrix and right hand side vector, static condensation, and for updating quadrature points:
//
[0.x.23955] 
[0.x.23956] 
//
[0.x.23957] 
[0.x.23958] 
//
[0.x.23959] 
[0.x.23960] 
//
// We start the collection of member functions with one that builds the grid:
//
[0.x.23961] 
//
// Set up the finite element system to be solved:
//
[0.x.23962] 
//
[0.x.23963] 
//
// Create Dirichlet constraints for the incremental displacement field:
//
[0.x.23964] 
//
// Several functions to assemble the system and right hand side matrices using multithreading. Each of them comes as a wrapper function, one that is executed to do the work in the WorkStream model on one cell, and one that copies the work done on this one cell into the global object that represents it:
//
[0.x.23965] 
//
[0.x.23966] 
[0.x.23967] 
[0.x.23968] 
[0.x.23969] 
//
// And similar to perform global static condensation:
//
[0.x.23970] 
//
[0.x.23971] 
[0.x.23972] 
[0.x.23973] 
[0.x.23974] 
//
[0.x.23975] 
//
// Create and update the quadrature points. Here, no data needs to be copied into a global object, so the copy_local_to_global function is empty:
//
[0.x.23976] 
//
[0.x.23977] 
//
[0.x.23978] 
[0.x.23979] 
[0.x.23980] 
[0.x.23981] 
//
[0.x.23982] 
[0.x.23983] 
//
// Solve for the displacement using a Newton-Raphson method. We break this function into the nonlinear loop and the function that solves the linearized Newton-Raphson step:
//
[0.x.23984] 
//
[0.x.23985] 
[0.x.23986] 
//
// Solution retrieval as well as post-processing and writing data to file:
//
[0.x.23987] 
[0.x.23988] 
//
[0.x.23989] 
//
// Finally, some member variables that describe the current state: A collection of the parameters used to describe the problem setup...
//
[0.x.23990] 
//
// ...the volume of the reference configuration...
//
[0.x.23991] 
//
// ...and description of the geometry on which the problem is solved:
//
[0.x.23992] 
//
// Also, keep track of the current time and the time spent evaluating certain functions
//
[0.x.23993] 
[0.x.23994] 
//
// A storage object for quadrature point information. As opposed to  [2.x.3060] , deal.II's native quadrature point data manager is employed here.
//
[0.x.23995] 
[0.x.23996] 
[0.x.23997] 
//
// A description of the finite-element system including the displacement polynomial degree, the degree-of-freedom handler, number of DoFs per cell and the extractor objects used to retrieve information from the solution vectors:
//
[0.x.23998] 
[0.x.23999] 
[0.x.24000] 
[0.x.24001] 
[0.x.24002] 
[0.x.24003] 
[0.x.24004] 
//
// Description of how the block-system is arranged. There are 3 blocks, the first contains a vector DOF  [2.x.3061]  while the other two describe scalar DOFs,  [2.x.3062]  and  [2.x.3063] .
//
[0.x.24005] 
[0.x.24006] 
[0.x.24007] 
[0.x.24008] 
[0.x.24009] 
//
[0.x.24010] 
[0.x.24011] 
[0.x.24012] 
[0.x.24013] 
[0.x.24014] 
[0.x.24015] 
//
[0.x.24016] 
[0.x.24017] 
[0.x.24018] 
[0.x.24019] 
//
// Rules for Gauss-quadrature on both the cell and faces. The number of quadrature points on both cells and faces is recorded.
//
[0.x.24020] 
[0.x.24021] 
[0.x.24022] 
[0.x.24023] 
//
// Objects that store the converged solution and right-hand side vectors, as well as the tangent matrix. There is an AffineConstraints object used to keep track of constraints.  We make use of a sparsity pattern designed for a block system.
//
[0.x.24024] 
[0.x.24025] 
[0.x.24026] 
[0.x.24027] 
[0.x.24028] 
//
// Then define a number of variables to store norms and update norms and normalization factors.
//
[0.x.24029] 
[0.x.24030] 
[0.x.24031] 
[0.x.24032] 
[0.x.24033] 
[0.x.24034] 
[0.x.24035] 
[0.x.24036] 
//
[0.x.24037] 
[0.x.24038] 
[0.x.24039] 
[0.x.24040] 
[0.x.24041] 
[0.x.24042] 
[0.x.24043] 
[0.x.24044] 
[0.x.24045] 
[0.x.24046] 
[0.x.24047] 
[0.x.24048] 
[0.x.24049] 
[0.x.24050] 
[0.x.24051] 
[0.x.24052] 
[0.x.24053] 
[0.x.24054] 
//
[0.x.24055] 
[0.x.24056] 
//
[0.x.24057] 
[0.x.24058] 
//
// Methods to calculate error measures
//
[0.x.24059] 
//
[0.x.24060] 
[0.x.24061] 
//
[0.x.24062] 
//
// Compute the volume in the spatial configuration
//
[0.x.24063] 
//
// Print information to screen in a pleasing way...
//
[0.x.24064] 
//
[0.x.24065] 
[0.x.24066] 
//[2.x.3064] 
//[2.x.3065] 
//
// We initialize the Solid class using data extracted from the parameter file.
//
[0.x.24067] 
[0.x.24068] 
[0.x.24069] 
[0.x.24070] 
[0.x.24071] 
[0.x.24072] 
[0.x.24073] 
[0.x.24074] 
[0.x.24075] 
//
// The Finite Element System is composed of dim continuous displacement DOFs, and discontinuous pressure and dilatation DOFs. In an attempt to satisfy the Babuska-Brezzi or LBB stability conditions (see Hughes (2000)), we setup a  [2.x.3066]  system.  [2.x.3067]  elements satisfy this condition, while  [2.x.3068]  elements do not. However, it has been shown that the latter demonstrate good convergence characteristics nonetheless.
//
[0.x.24076] 
[0.x.24077] 
[0.x.24078] 
[0.x.24079] 
[0.x.24080] 
[0.x.24081] 
[0.x.24082] 
[0.x.24083] 
[0.x.24084] 
[0.x.24085] 
[0.x.24086] 
[0.x.24087] 
[0.x.24088] 
[0.x.24089] 
[0.x.24090] 
[0.x.24091] 
[0.x.24092] 
[0.x.24093] 
[0.x.24094] 
[0.x.24095] 
[0.x.24096] 
[0.x.24097] 
//
// In solving the quasi-static problem, the time becomes a loading parameter, i.e. we increasing the loading linearly with time, making the two concepts interchangeable. We choose to increment time linearly using a constant time step size.
//
// We start the function with preprocessing, setting the initial dilatation values, and then output the initial grid before starting the simulation  proper with the first time (and loading) increment.
//
// Care must be taken (or at least some thought given) when imposing the constraint  [2.x.3069]  on the initial solution field. The constraint corresponds to the determinant of the deformation gradient in the undeformed configuration, which is the identity tensor. We use FE_DGPMonomial bases to interpolate the dilatation field, thus we can't simply set the corresponding dof to unity as they correspond to the monomial coefficients. Thus we use the  [2.x.3070]  function to do the work for us. The  [2.x.3071]  function requires an argument indicating the hanging node constraints. We have none in this program So we have to create a constraint object. In its original state, constraint objects are unsorted, and have to be sorted (using the  [2.x.3072]  function) before they can be used. Have a look at  [2.x.3073]  for more information. We only need to enforce the initial condition on the dilatation. In order to do this, we make use of a ComponentSelectFunction which acts as a mask and sets the J_component of n_components to 1. This is exactly what we want. Have a look at its usage in  [2.x.3074]  for more information.
//
[0.x.24098] 
[0.x.24099] 
[0.x.24100] 
[0.x.24101] 
[0.x.24102] 
[0.x.24103] 
[0.x.24104] 
[0.x.24105] 
//
[0.x.24106] 
//
[0.x.24107] 
[0.x.24108] 
[0.x.24109] 
[0.x.24110] 
[0.x.24111] 
//
// We then declare the incremental solution update  [2.x.3075]  and start the loop over the time domain.
//
// At the beginning, we reset the solution update for this time step...
//
[0.x.24112] 
[0.x.24113] 
[0.x.24114] 
[0.x.24115] 
//
// ...solve the current time step and update total solution vector  [2.x.3076] ...
//
[0.x.24116] 
[0.x.24117] 
//
// ...and plot the results before moving on happily to the next time step:
//
[0.x.24118] 
[0.x.24119] 
[0.x.24120] 
[0.x.24121] 
//[2.x.3077] 
//[2.x.3078] 
//
// The first group of private member functions is related to parallelization. We use the Threading Building Blocks library (TBB) to perform as many computationally intensive distributed tasks as possible. In particular, we assemble the tangent matrix and right hand side vector, the static condensation contributions, and update data stored at the quadrature points using TBB. Our main tool for this is the WorkStream class (see the  [2.x.3079]  threads module for more information).
//
// Firstly we deal with the tangent matrix and right-hand side assembly structures. The PerTaskData object stores local contributions to the global system.
//
[0.x.24122] 
[0.x.24123] 
[0.x.24124] 
[0.x.24125] 
[0.x.24126] 
[0.x.24127] 
//
[0.x.24128] 
[0.x.24129] 
[0.x.24130] 
[0.x.24131] 
[0.x.24132] 
//
[0.x.24133] 
[0.x.24134] 
[0.x.24135] 
[0.x.24136] 
[0.x.24137] 
[0.x.24138] 
//
// On the other hand, the ScratchData object stores the larger objects such as the shape-function values array ( [2.x.3080] ) and a shape function gradient and symmetric gradient vector which we will use during the assembly.
//
[0.x.24139] 
[0.x.24140] 
[0.x.24141] 
[0.x.24142] 
[0.x.24143] 
//
[0.x.24144] 
[0.x.24145] 
[0.x.24146] 
//
[0.x.24147] 
[0.x.24148] 
[0.x.24149] 
[0.x.24150] 
[0.x.24151] 
[0.x.24152] 
[0.x.24153] 
[0.x.24154] 
[0.x.24155] 
[0.x.24156] 
[0.x.24157] 
[0.x.24158] 
[0.x.24159] 
[0.x.24160] 
//
[0.x.24161] 
[0.x.24162] 
[0.x.24163] 
[0.x.24164] 
[0.x.24165] 
[0.x.24166] 
[0.x.24167] 
[0.x.24168] 
[0.x.24169] 
[0.x.24170] 
[0.x.24171] 
//
[0.x.24172] 
[0.x.24173] 
[0.x.24174] 
[0.x.24175] 
[0.x.24176] 
[0.x.24177] 
[0.x.24178] 
[0.x.24179] 
[0.x.24180] 
[0.x.24181] 
[0.x.24182] 
[0.x.24183] 
[0.x.24184] 
[0.x.24185] 
[0.x.24186] 
[0.x.24187] 
[0.x.24188] 
[0.x.24189] 
[0.x.24190] 
[0.x.24191] 
//
// Then we define structures to assemble the statically condensed tangent matrix. Recall that we wish to solve for a displacement-based formulation. We do the condensation at the element level as the  [2.x.3081]  and  [2.x.3082]  fields are element-wise discontinuous.  As these operations are matrix-based, we need to setup a number of matrices to store the local contributions from a number of the tangent matrix sub-blocks.  We place these in the PerTaskData struct.
//
// We choose not to reset any data in the  [2.x.3083]  function as the matrix extraction and replacement tools will take care of this
//
[0.x.24192] 
[0.x.24193] 
[0.x.24194] 
[0.x.24195] 
[0.x.24196] 
//
[0.x.24197] 
[0.x.24198] 
[0.x.24199] 
[0.x.24200] 
[0.x.24201] 
[0.x.24202] 
[0.x.24203] 
[0.x.24204] 
[0.x.24205] 
//
[0.x.24206] 
[0.x.24207] 
[0.x.24208] 
[0.x.24209] 
[0.x.24210] 
[0.x.24211] 
[0.x.24212] 
[0.x.24213] 
[0.x.24214] 
[0.x.24215] 
[0.x.24216] 
[0.x.24217] 
[0.x.24218] 
[0.x.24219] 
[0.x.24220] 
[0.x.24221] 
//
[0.x.24222] 
[0.x.24223] 
[0.x.24224] 
//
// The ScratchData object for the operations we wish to perform here is empty since we need no temporary data, but it still needs to be defined for the current implementation of TBB in deal.II.  So we create a dummy struct for this purpose.
//
[0.x.24225] 
[0.x.24226] 
[0.x.24227] 
[0.x.24228] 
[0.x.24229] 
[0.x.24230] 
//
// And finally we define the structures to assist with updating the quadrature point information. Similar to the SC assembly process, we do not need the PerTaskData object (since there is nothing to store here) but must define one nonetheless. Note that this is because for the operation that we have here -- updating the data on quadrature points -- the operation is purely local: the things we do on every cell get consumed on every cell, without any global aggregation operation as is usually the case when using the WorkStream class. The fact that we still have to define a per-task data structure points to the fact that the WorkStream class may be ill-suited to this operation (we could, in principle simply create a new task using  [2.x.3084]  for each cell) but there is not much harm done to doing it this way anyway. Furthermore, should there be different material models associated with a quadrature point, requiring varying levels of computational expense, then the method used here could be advantageous.
//
[0.x.24231] 
[0.x.24232] 
[0.x.24233] 
[0.x.24234] 
[0.x.24235] 
[0.x.24236] 
//
// The ScratchData object will be used to store an alias for the solution vector so that we don't have to copy this large data structure. We then define a number of vectors to extract the solution values and gradients at the quadrature points.
//
[0.x.24237] 
[0.x.24238] 
[0.x.24239] 
[0.x.24240] 
//
[0.x.24241] 
[0.x.24242] 
[0.x.24243] 
//
[0.x.24244] 
//
[0.x.24245] 
[0.x.24246] 
[0.x.24247] 
[0.x.24248] 
[0.x.24249] 
[0.x.24250] 
[0.x.24251] 
[0.x.24252] 
[0.x.24253] 
[0.x.24254] 
//
[0.x.24255] 
[0.x.24256] 
[0.x.24257] 
[0.x.24258] 
[0.x.24259] 
[0.x.24260] 
[0.x.24261] 
[0.x.24262] 
[0.x.24263] 
//
[0.x.24264] 
[0.x.24265] 
[0.x.24266] 
[0.x.24267] 
[0.x.24268] 
[0.x.24269] 
[0.x.24270] 
[0.x.24271] 
[0.x.24272] 
[0.x.24273] 
[0.x.24274] 
//[2.x.3085] 
//
// On to the first of the private member functions. Here we create the triangulation of the domain, for which we choose the scaled cube with each face given a boundary ID number.  The grid must be refined at least once for the indentation problem.
//
// We then determine the volume of the reference configuration and print it for comparison:
//
[0.x.24275] 
[0.x.24276] 
[0.x.24277] 
[0.x.24278] 
[0.x.24279] 
[0.x.24280] 
[0.x.24281] 
[0.x.24282] 
[0.x.24283] 
[0.x.24284] 
//
[0.x.24285] 
[0.x.24286] 
//
// Since we wish to apply a Neumann BC to a patch on the top surface, we must find the cell faces in this part of the domain and mark them with a distinct boundary ID number.  The faces we are looking for are on the +y surface and will get boundary ID 6 (zero through five are already used when creating the six faces of the cube domain):
//
[0.x.24287] 
[0.x.24288] 
[0.x.24289] 
[0.x.24290] 
[0.x.24291] 
[0.x.24292] 
[0.x.24293] 
[0.x.24294] 
[0.x.24295] 
[0.x.24296] 
[0.x.24297] 
[0.x.24298] 
[0.x.24299] 
[0.x.24300] 
[0.x.24301] 
[0.x.24302] 
[0.x.24303] 
[0.x.24304] 
[0.x.24305] 
[0.x.24306] 
//[2.x.3086] 
//
// Next we describe how the FE system is setup.  We first determine the number of components per block. Since the displacement is a vector component, the first dim components belong to it, while the next two describe scalar pressure and dilatation DOFs.
//
[0.x.24307] 
[0.x.24308] 
[0.x.24309] 
[0.x.24310] 
//
[0.x.24311] 
[0.x.24312] 
[0.x.24313] 
[0.x.24314] 
//
// The DOF handler is then initialized and we renumber the grid in an efficient manner. We also record the number of DOFs per block.
//
[0.x.24315] 
[0.x.24316] 
[0.x.24317] 
//
[0.x.24318] 
[0.x.24319] 
//
[0.x.24320] 
[0.x.24321] 
[0.x.24322] 
[0.x.24323] 
[0.x.24324] 
//
// Setup the sparsity pattern and tangent matrix
//
[0.x.24325] 
[0.x.24326] 
[0.x.24327] 
[0.x.24328] 
[0.x.24329] 
//
[0.x.24330] 
//
[0.x.24331] 
[0.x.24332] 
[0.x.24333] 
//
[0.x.24334] 
[0.x.24335] 
[0.x.24336] 
//
[0.x.24337] 
[0.x.24338] 
[0.x.24339] 
[0.x.24340] 
//
// The global system matrix initially has the following structure [1.x.95] We optimize the sparsity pattern to reflect this structure and prevent unnecessary data creation for the right-diagonal block components.
//
[0.x.24341] 
[0.x.24342] 
[0.x.24343] 
[0.x.24344] 
[0.x.24345] 
[0.x.24346] 
[0.x.24347] 
[0.x.24348] 
[0.x.24349] 
[0.x.24350] 
[0.x.24351] 
[0.x.24352] 
[0.x.24353] 
//
[0.x.24354] 
//
// We then set up storage vectors
//
[0.x.24355] 
[0.x.24356] 
//
[0.x.24357] 
[0.x.24358] 
//
// ...and finally set up the quadrature point history:
//
[0.x.24359] 
//
[0.x.24360] 
[0.x.24361] 
//[2.x.3087]  Next we compute some information from the FE system that describes which local element DOFs are attached to which block component.  This is used later to extract sub-blocks from the global matrix.
//
// In essence, all we need is for the FESystem object to indicate to which block component a DOF on the reference cell is attached to.  Currently, the interpolation fields are setup such that 0 indicates a displacement DOF, 1 a pressure DOF and 2 a dilatation DOF.
//
[0.x.24362] 
[0.x.24363] 
[0.x.24364] 
[0.x.24365] 
[0.x.24366] 
[0.x.24367] 
//
[0.x.24368] 
[0.x.24369] 
[0.x.24370] 
[0.x.24371] 
[0.x.24372] 
[0.x.24373] 
[0.x.24374] 
[0.x.24375] 
[0.x.24376] 
[0.x.24377] 
[0.x.24378] 
[0.x.24379] 
[0.x.24380] 
[0.x.24381] 
[0.x.24382] 
//[2.x.3088]  The method used to store quadrature information is already described in  [2.x.3089] . Here we implement a similar setup for a SMP machine.
//
// Firstly the actual QPH data objects are created. This must be done only once the grid is refined to its finest level.
//
[0.x.24383] 
[0.x.24384] 
[0.x.24385] 
[0.x.24386] 
//
[0.x.24387] 
[0.x.24388] 
[0.x.24389] 
//
// Next we setup the initial quadrature point data. Note that when the quadrature point data is retrieved, it is returned as a vector of smart pointers.
//
[0.x.24390] 
[0.x.24391] 
[0.x.24392] 
[0.x.24393] 
[0.x.24394] 
//
[0.x.24395] 
[0.x.24396] 
[0.x.24397] 
[0.x.24398] 
//[2.x.3090]  As the update of QP information occurs frequently and involves a number of expensive operations, we define a multithreaded approach to distributing the task across a number of CPU cores.
//
// To start this, we first we need to obtain the total solution as it stands at this Newton increment and then create the initial copy of the scratch and copy data objects:
//
[0.x.24399] 
[0.x.24400] 
[0.x.24401] 
[0.x.24402] 
[0.x.24403] 
[0.x.24404] 
//
[0.x.24405] 
[0.x.24406] 
//
[0.x.24407] 
[0.x.24408] 
[0.x.24409] 
//
// We then pass them and the one-cell update function to the WorkStream to be processed:
//
[0.x.24410] 
[0.x.24411] 
[0.x.24412] 
[0.x.24413] 
[0.x.24414] 
[0.x.24415] 
//
[0.x.24416] 
[0.x.24417] 
//
// Now we describe how we extract data from the solution vector and pass it along to each QP storage object for processing.
//
[0.x.24418] 
[0.x.24419] 
[0.x.24420] 
[0.x.24421] 
[0.x.24422] 
[0.x.24423] 
[0.x.24424] 
[0.x.24425] 
[0.x.24426] 
//
[0.x.24427] 
[0.x.24428] 
[0.x.24429] 
[0.x.24430] 
[0.x.24431] 
[0.x.24432] 
//
[0.x.24433] 
//
// We first need to find the values and gradients at quadrature points inside the current cell and then we update each local QP using the displacement gradient and total pressure and dilatation solution values:
//
[0.x.24434] 
[0.x.24435] 
[0.x.24436] 
[0.x.24437] 
[0.x.24438] 
[0.x.24439] 
[0.x.24440] 
//
[0.x.24441] 
[0.x.24442] 
[0.x.24443] 
[0.x.24444] 
[0.x.24445] 
[0.x.24446] 
//[2.x.3091] 
//
// The next function is the driver method for the Newton-Raphson scheme. At its top we create a new vector to store the current Newton update step, reset the error storage objects and print solver header.
//
[0.x.24447] 
[0.x.24448] 
[0.x.24449] 
[0.x.24450] 
[0.x.24451] 
[0.x.24452] 
//
[0.x.24453] 
//
[0.x.24454] 
[0.x.24455] 
[0.x.24456] 
[0.x.24457] 
[0.x.24458] 
[0.x.24459] 
//
[0.x.24460] 
//
// We now perform a number of Newton iterations to iteratively solve the nonlinear problem.  Since the problem is fully nonlinear and we are using a full Newton method, the data stored in the tangent matrix and right-hand side vector is not reusable and must be cleared at each Newton step. We then initially build the linear system and check for convergence (and store this value in the first iteration). The unconstrained DOFs of the rhs vector hold the out-of-balance forces, and collectively determine whether or not the equilibrium solution has been attained.
//
// Although for this particular problem we could potentially construct the RHS vector before assembling the system matrix, for the sake of extensibility we choose not to do so. The benefit to assembling the RHS vector and system matrix separately is that the latter is an expensive operation and we can potentially avoid an extra assembly process by not assembling the tangent matrix when convergence is attained. However, this makes parallelizing the code using MPI more difficult. Furthermore, when extending the problem to the transient case additional contributions to the RHS may result from the time discretization and application of constraints for the velocity and acceleration fields.
//
[0.x.24461] 
[0.x.24462] 
[0.x.24463] 
[0.x.24464] 
[0.x.24465] 
//
// We construct the linear system, but hold off on solving it (a step that should be significantly more expensive than assembly):
//
[0.x.24466] 
[0.x.24467] 
//
// We can now determine the normalized residual error and check for solution convergence:
//
[0.x.24468] 
[0.x.24469] 
[0.x.24470] 
//
[0.x.24471] 
[0.x.24472] 
//
[0.x.24473] 
[0.x.24474] 
[0.x.24475] 
[0.x.24476] 
[0.x.24477] 
//
[0.x.24478] 
[0.x.24479] 
//
// If we have decided that we want to continue with the iteration, we solve the linearized system:
//
[0.x.24480] 
[0.x.24481] 
//
// We can now determine the normalized Newton update error:
//
[0.x.24482] 
[0.x.24483] 
[0.x.24484] 
//
[0.x.24485] 
[0.x.24486] 
//
// Lastly, since we implicitly accept the solution step we can perform the actual update of the solution increment for the current time step, update all quadrature point information pertaining to this new displacement and stress state and continue iterating:
//
[0.x.24487] 
[0.x.24488] 
//
[0.x.24489] 
[0.x.24490] 
[0.x.24491] 
[0.x.24492] 
[0.x.24493] 
[0.x.24494] 
[0.x.24495] 
[0.x.24496] 
[0.x.24497] 
//
// At the end, if it turns out that we have in fact done more iterations than the parameter file allowed, we raise an exception that can be caught in the main() function. The call <code>AssertThrow(condition, exc_object)</code> is in essence equivalent to <code>if (!cond) throw exc_object;</code> but the former form fills certain fields in the exception object that identify the location (filename and line number) where the exception was raised to make it simpler to identify where the problem happened.
//
[0.x.24498] 
[0.x.24499] 
[0.x.24500] 
//[2.x.3092] 
//
// This program prints out data in a nice table that is updated on a per-iteration basis. The next two functions set up the table header and footer:
//
[0.x.24501] 
[0.x.24502] 
[0.x.24503] 
[0.x.24504] 
//
[0.x.24505] 
[0.x.24506] 
[0.x.24507] 
//
[0.x.24508] 
[0.x.24509] 
[0.x.24510] 
[0.x.24511] 
//
[0.x.24512] 
[0.x.24513] 
[0.x.24514] 
[0.x.24515] 
//
[0.x.24516] 
[0.x.24517] 
[0.x.24518] 
[0.x.24519] 
//
[0.x.24520] 
[0.x.24521] 
[0.x.24522] 
//
[0.x.24523] 
//
[0.x.24524] 
[0.x.24525] 
[0.x.24526] 
[0.x.24527] 
[0.x.24528] 
[0.x.24529] 
[0.x.24530] 
[0.x.24531] 
[0.x.24532] 
//[2.x.3093] 
//
// Calculate the volume of the domain in the spatial configuration
//
[0.x.24533] 
[0.x.24534] 
[0.x.24535] 
[0.x.24536] 
//
[0.x.24537] 
//
[0.x.24538] 
[0.x.24539] 
[0.x.24540] 
//
// In contrast to that which was previously called for, in this instance the quadrature point data is specifically non-modifiable since we will only be accessing data. We ensure that the right get_data function is called by marking this update function as constant.
//
[0.x.24541] 
[0.x.24542] 
[0.x.24543] 
//
[0.x.24544] 
[0.x.24545] 
[0.x.24546] 
[0.x.24547] 
//
[0.x.24548] 
[0.x.24549] 
[0.x.24550] 
[0.x.24551] 
[0.x.24552] 
[0.x.24553] 
//
// Calculate how well the dilatation  [2.x.3094]  agrees with  [2.x.3095]  from the  [2.x.3096]  error  [2.x.3097] . We also return the ratio of the current volume of the domain to the reference volume. This is of interest for incompressible media where we want to check how well the isochoric constraint has been enforced.
//
[0.x.24554] 
[0.x.24555] 
[0.x.24556] 
[0.x.24557] 
//
[0.x.24558] 
//
[0.x.24559] 
[0.x.24560] 
[0.x.24561] 
//
[0.x.24562] 
[0.x.24563] 
[0.x.24564] 
//
[0.x.24565] 
[0.x.24566] 
[0.x.24567] 
[0.x.24568] 
[0.x.24569] 
[0.x.24570] 
[0.x.24571] 
//
[0.x.24572] 
[0.x.24573] 
[0.x.24574] 
//
[0.x.24575] 
[0.x.24576] 
[0.x.24577] 
//[2.x.3098] 
//
// Determine the true residual error for the problem.  That is, determine the error in the residual for the unconstrained degrees of freedom.  Note that to do so, we need to ignore constrained DOFs by setting the residual in these vector components to zero.
//
[0.x.24578] 
[0.x.24579] 
[0.x.24580] 
[0.x.24581] 
//
[0.x.24582] 
[0.x.24583] 
[0.x.24584] 
//
[0.x.24585] 
[0.x.24586] 
[0.x.24587] 
[0.x.24588] 
[0.x.24589] 
//[2.x.3099] 
//
// Determine the true Newton update error for the problem
//
[0.x.24590] 
[0.x.24591] 
[0.x.24592] 
[0.x.24593] 
[0.x.24594] 
[0.x.24595] 
[0.x.24596] 
[0.x.24597] 
//
[0.x.24598] 
[0.x.24599] 
[0.x.24600] 
[0.x.24601] 
[0.x.24602] 
//
//  [2.x.3100] 
//
// This function provides the total solution, which is valid at any Newton step. This is required as, to reduce computational error, the total solution is only updated at the end of the timestep.
//
[0.x.24603] 
[0.x.24604] 
[0.x.24605] 
[0.x.24606] 
[0.x.24607] 
[0.x.24608] 
[0.x.24609] 
[0.x.24610] 
//[2.x.3101] 
//
// Since we use TBB for assembly, we simply setup a copy of the data structures required for the process and pass them, along with the assembly functions to the WorkStream object for processing. Note that we must ensure that the matrix and RHS vector are reset before any assembly operations can occur. Furthermore, since we are describing a problem with Neumann BCs, we will need the face normals and so must specify this in the face update flags.
//
[0.x.24611] 
[0.x.24612] 
[0.x.24613] 
[0.x.24614] 
[0.x.24615] 
//
[0.x.24616] 
[0.x.24617] 
//
[0.x.24618] 
[0.x.24619] 
[0.x.24620] 
[0.x.24621] 
//
[0.x.24622] 
[0.x.24623] 
//
// The syntax used here to pass data to the WorkStream class is discussed in  [2.x.3102] .
//
[0.x.24624] 
[0.x.24625] 
[0.x.24626] 
[0.x.24627] 
[0.x.24628] 
[0.x.24629] 
[0.x.24630] 
[0.x.24631] 
[0.x.24632] 
[0.x.24633] 
[0.x.24634] 
[0.x.24635] 
[0.x.24636] 
[0.x.24637] 
[0.x.24638] 
[0.x.24639] 
//
[0.x.24640] 
[0.x.24641] 
//
// Of course, we still have to define how we assemble the tangent matrix contribution for a single cell.  We first need to reset and initialize some of the scratch data structures and retrieve some basic information regarding the DOF numbering on this cell.  We can precalculate the cell shape function values and gradients. Note that the shape function gradients are defined with regard to the current configuration.  That is  [2.x.3103] .
//
[0.x.24642] 
[0.x.24643] 
[0.x.24644] 
[0.x.24645] 
[0.x.24646] 
[0.x.24647] 
[0.x.24648] 
[0.x.24649] 
[0.x.24650] 
[0.x.24651] 
//
[0.x.24652] 
[0.x.24653] 
[0.x.24654] 
//
[0.x.24655] 
[0.x.24656] 
[0.x.24657] 
[0.x.24658] 
[0.x.24659] 
[0.x.24660] 
[0.x.24661] 
//
[0.x.24662] 
[0.x.24663] 
[0.x.24664] 
[0.x.24665] 
[0.x.24666] 
[0.x.24667] 
[0.x.24668] 
[0.x.24669] 
[0.x.24670] 
[0.x.24671] 
[0.x.24672] 
[0.x.24673] 
[0.x.24674] 
[0.x.24675] 
[0.x.24676] 
[0.x.24677] 
[0.x.24678] 
//
// Now we build the local cell stiffness matrix and RHS vector. Since the global and local system matrices are symmetric, we can exploit this property by building only the lower half of the local matrix and copying the values to the upper half.  So we only assemble half of the  [2.x.3104] ,  [2.x.3105] ,  [2.x.3106]  blocks, while the whole  [2.x.3107] ,  [2.x.3108] ,  [2.x.3109]  blocks are built.
//
// In doing so, we first extract some configuration dependent variables from our quadrature history objects for the current quadrature point.
//
[0.x.24679] 
[0.x.24680] 
[0.x.24681] 
[0.x.24682] 
[0.x.24683] 
[0.x.24684] 
[0.x.24685] 
[0.x.24686] 
[0.x.24687] 
[0.x.24688] 
[0.x.24689] 
[0.x.24690] 
[0.x.24691] 
//
// These two tensors store some precomputed data. Their use will explained shortly.
//
[0.x.24692] 
[0.x.24693] 
//
// Next we define some aliases to make the assembly process easier to follow.
//
[0.x.24694] 
[0.x.24695] 
[0.x.24696] 
[0.x.24697] 
[0.x.24698] 
//
[0.x.24699] 
[0.x.24700] 
[0.x.24701] 
[0.x.24702] 
[0.x.24703] 
//
//   We first compute the contributions   from the internal forces.  Note, by   definition of the rhs as the negative   of the residual, these contributions   are subtracted.
//
[0.x.24704] 
[0.x.24705] 
[0.x.24706] 
[0.x.24707] 
[0.x.24708] 
[0.x.24709] 
[0.x.24710] 
[0.x.24711] 
//
//   Before we go into the inner loop, we have one final chance to   introduce some optimizations. We've already taken into account   the symmetry of the system, and we can now precompute some   common terms that are repeatedly applied in the inner loop.   We won't be excessive here, but will rather focus on expensive   operations, namely those involving the rank-4 material stiffness   tensor and the rank-2 stress tensor.     What we may observe is that both of these tensors are contracted   with shape function gradients indexed on the "i" DoF. This   implies that this particular operation remains constant as we   loop over the "j" DoF. For that reason, we can extract this from   the inner loop and save the many operations that, for each   quadrature point and DoF index "i" and repeated over index "j"   are required to double contract a rank-2 symmetric tensor with a   rank-4 symmetric tensor, and a rank-1 tensor with a rank-2   tensor.     At the loss of some readability, this small change will reduce   the assembly time of the symmetrized system by about half when   using the simulation default parameters, and becomes more   significant as the h-refinement level increases.
//
[0.x.24712] 
[0.x.24713] 
[0.x.24714] 
[0.x.24715] 
[0.x.24716] 
//
//   Now we're prepared to compute the tangent matrix contributions:
//
[0.x.24717] 
[0.x.24718] 
[0.x.24719] 
[0.x.24720] 
[0.x.24721] 
[0.x.24722] 
[0.x.24723] 
//
//       This is the  [2.x.3110]        contribution. It comprises a material contribution, and a       geometrical stress contribution which is only added along       the local matrix diagonals:
//
[0.x.24724] 
[0.x.24725] 
//
//           The material contribution:
//
[0.x.24726] 
[0.x.24727] 
//
//           The geometrical stress contribution:
//
[0.x.24728] 
[0.x.24729] 
[0.x.24730] 
[0.x.24731] 
//
//       Next is the  [2.x.3111]        contribution
//
[0.x.24732] 
[0.x.24733] 
[0.x.24734] 
[0.x.24735] 
[0.x.24736] 
//
//       and lastly the  [2.x.3112]  and  [2.x.3113]  contributions:
//
[0.x.24737] 
[0.x.24738] 
[0.x.24739] 
[0.x.24740] 
[0.x.24741] 
[0.x.24742] 
[0.x.24743] 
[0.x.24744] 
[0.x.24745] 
[0.x.24746] 
//
// Next we assemble the Neumann contribution. We first check to see it the cell face exists on a boundary on which a traction is applied and add the contribution if this is the case.
//
[0.x.24747] 
[0.x.24748] 
[0.x.24749] 
[0.x.24750] 
//
[0.x.24751] 
[0.x.24752] 
[0.x.24753] 
[0.x.24754] 
[0.x.24755] 
//
//     Using the face normal at this quadrature point we specify the     traction in reference configuration. For this problem, a     defined pressure is applied in the reference configuration.     The direction of the applied traction is assumed not to     evolve with the deformation of the domain. The traction is     defined using the first Piola-Kirchhoff stress is simply      [2.x.3114]  We use the time variable to     linearly ramp up the pressure load.         Note that the contributions to the right hand side vector we     compute here only exist in the displacement components of the     vector.
//
[0.x.24756] 
[0.x.24757] 
[0.x.24758] 
[0.x.24759] 
[0.x.24760] 
//
[0.x.24761] 
[0.x.24762] 
[0.x.24763] 
[0.x.24764] 
//
[0.x.24765] 
[0.x.24766] 
[0.x.24767] 
[0.x.24768] 
[0.x.24769] 
[0.x.24770] 
[0.x.24771] 
//
[0.x.24772] 
[0.x.24773] 
[0.x.24774] 
[0.x.24775] 
[0.x.24776] 
//
// Finally, we need to copy the lower half of the local matrix into the upper half:
//
[0.x.24777] 
[0.x.24778] 
[0.x.24779] 
[0.x.24780] 
[0.x.24781] 
//
//  [2.x.3115]  The constraints for this problem are simple to describe. In this particular example, the boundary values will be calculated for the two first iterations of Newton's algorithm. In general, one would build non-homogeneous constraints in the zeroth iteration (that is, when `apply_dirichlet_bc == true` in the code block that follows) and build only the corresponding homogeneous constraints in the following step. While the current example has only homogeneous constraints, previous experiences have shown that a common error is forgetting to add the extra condition when refactoring the code to specific uses. This could lead to errors that are hard to debug. In this spirit, we choose to make the code more verbose in terms of what operations are performed at each Newton step.
//
[0.x.24782] 
[0.x.24783] 
[0.x.24784] 
//
// Since we (a) are dealing with an iterative Newton method, (b) are using an incremental formulation for the displacement, and (c) apply the constraints to the incremental displacement field, any non-homogeneous constraints on the displacement update should only be specified at the zeroth iteration. No subsequent contributions are to be made since the constraints will be exactly satisfied after that iteration.
//
[0.x.24785] 
//
// Furthermore, after the first Newton iteration within a timestep, the constraints remain the same and we do not need to modify or rebuild them so long as we do not clear the  [2.x.3116]  object.
//
[0.x.24786] 
[0.x.24787] 
[0.x.24788] 
[0.x.24789] 
[0.x.24790] 
//
[0.x.24791] 
//
[0.x.24792] 
[0.x.24793] 
//
// At the zeroth Newton iteration we wish to apply the full set of non-homogeneous and homogeneous constraints that represent the boundary conditions on the displacement increment. Since in general the constraints may be different at each time step, we need to clear the constraints matrix and completely rebuild it. An example case would be if a surface is accelerating; in such a scenario the change in displacement is non-constant between each time step.
//
[0.x.24794] 
//
// The boundary conditions for the indentation problem in 3D are as follows: On the -x, -y and -z faces (IDs 0,2,4) we set up a symmetry condition to allow only planar movement while the +x and +z faces (IDs 1,5) are traction free. In this contrived problem, part of the +y face (ID 3) is set to have no motion in the x- and z-component. Finally, as described earlier, the other part of the +y face has an the applied pressure but is also constrained in the x- and z-directions.
//
// In the following, we will have to tell the function interpolation boundary values which components of the solution vector should be constrained (i.e., whether it's the x-, y-, z-displacements or combinations thereof). This is done using ComponentMask objects (see  [2.x.3117] ) which we can get from the finite element if we provide it with an extractor object for the component we wish to select. To this end we first set up such extractor objects and later use it when generating the relevant component masks:
//
[0.x.24795] 
[0.x.24796] 
//
[0.x.24797] 
[0.x.24798] 
//
[0.x.24799] 
[0.x.24800] 
[0.x.24801] 
[0.x.24802] 
[0.x.24803] 
[0.x.24804] 
[0.x.24805] 
[0.x.24806] 
[0.x.24807] 
//
[0.x.24808] 
[0.x.24809] 
[0.x.24810] 
[0.x.24811] 
[0.x.24812] 
[0.x.24813] 
[0.x.24814] 
//
[0.x.24815] 
[0.x.24816] 
[0.x.24817] 
//
[0.x.24818] 
[0.x.24819] 
//
[0.x.24820] 
[0.x.24821] 
[0.x.24822] 
[0.x.24823] 
[0.x.24824] 
[0.x.24825] 
[0.x.24826] 
[0.x.24827] 
[0.x.24828] 
[0.x.24829] 
//
[0.x.24830] 
[0.x.24831] 
[0.x.24832] 
[0.x.24833] 
[0.x.24834] 
[0.x.24835] 
[0.x.24836] 
//
[0.x.24837] 
[0.x.24838] 
//
[0.x.24839] 
[0.x.24840] 
[0.x.24841] 
[0.x.24842] 
[0.x.24843] 
[0.x.24844] 
[0.x.24845] 
[0.x.24846] 
[0.x.24847] 
[0.x.24848] 
[0.x.24849] 
[0.x.24850] 
[0.x.24851] 
//
[0.x.24852] 
[0.x.24853] 
[0.x.24854] 
[0.x.24855] 
[0.x.24856] 
[0.x.24857] 
[0.x.24858] 
[0.x.24859] 
[0.x.24860] 
//
[0.x.24861] 
[0.x.24862] 
[0.x.24863] 
[0.x.24864] 
[0.x.24865] 
[0.x.24866] 
[0.x.24867] 
[0.x.24868] 
[0.x.24869] 
[0.x.24870] 
[0.x.24871] 
//
// As all Dirichlet constraints are fulfilled exactly after the zeroth Newton iteration, we want to ensure that no further modification are made to those entries. This implies that we want to convert all non-homogeneous Dirichlet constraints into homogeneous ones.
//
// In this example the procedure to do this is quite straightforward, and in fact we can (and will) circumvent any unnecessary operations when only homogeneous boundary conditions are applied. In a more general problem one should be mindful of hanging node and periodic constraints, which may also introduce some inhomogeneities. It might then be advantageous to keep disparate objects for the different types of constraints, and merge them together once the homogeneous Dirichlet constraints have been constructed.
//
[0.x.24872] 
[0.x.24873] 
//
//   Since the affine constraints were finalized at the previous   Newton iteration, they may not be modified directly. So   we need to copy them to another temporary object and make   modification there. Once we're done, we'll transfer them   back to the main  [2.x.3118]  object.
//
[0.x.24874] 
[0.x.24875] 
[0.x.24876] 
[0.x.24877] 
//
[0.x.24878] 
[0.x.24879] 
[0.x.24880] 
[0.x.24881] 
//
[0.x.24882] 
[0.x.24883] 
//[2.x.3119]  Solving the entire block system is a bit problematic as there are no contributions to the  [2.x.3120]  block, rendering it noninvertible (when using an iterative solver). Since the pressure and dilatation variables DOFs are discontinuous, we can condense them out to form a smaller displacement-only system which we will then solve and subsequently post-process to retrieve the pressure and dilatation solutions.
//
// The static condensation process could be performed at a global level but we need the inverse of one of the blocks. However, since the pressure and dilatation variables are discontinuous, the static condensation (SC) operation can also be done on a per-cell basis and we can produce the inverse of the block-diagonal  [2.x.3121]  block by inverting the local blocks. We can again use TBB to do this since each operation will be independent of one another.
//
// Using the TBB via the WorkStream class, we assemble the contributions to form   [2.x.3122]  from each element's contributions. These contributions are then added to the global stiffness matrix. Given this description, the following two functions should be clear:
//
[0.x.24884] 
[0.x.24885] 
[0.x.24886] 
[0.x.24887] 
[0.x.24888] 
//
[0.x.24889] 
[0.x.24890] 
[0.x.24891] 
[0.x.24892] 
[0.x.24893] 
//
[0.x.24894] 
[0.x.24895] 
[0.x.24896] 
[0.x.24897] 
[0.x.24898] 
[0.x.24899] 
//
[0.x.24900] 
[0.x.24901] 
//
[0.x.24902] 
[0.x.24903] 
[0.x.24904] 
[0.x.24905] 
[0.x.24906] 
[0.x.24907] 
[0.x.24908] 
[0.x.24909] 
[0.x.24910] 
//
// Now we describe the static condensation process. As per usual, we must first find out which global numbers the degrees of freedom on this cell have and reset some data structures:
//
[0.x.24911] 
[0.x.24912] 
[0.x.24913] 
[0.x.24914] 
[0.x.24915] 
[0.x.24916] 
[0.x.24917] 
[0.x.24918] 
[0.x.24919] 
//
// We now extract the contribution of the dofs associated with the current cell to the global stiffness matrix.  The discontinuous nature of the  [2.x.3123]  and  [2.x.3124]  interpolations mean that their is no coupling of the local contributions at the global level. This is not the case with the  [2.x.3125]  dof.  In other words,  [2.x.3126] ,  [2.x.3127]  and  [2.x.3128] , when extracted from the global stiffness matrix are the element contributions.  This is not the case for  [2.x.3129] .
//
// Note: A lower-case symbol is used to denote element stiffness matrices.
//
// Currently the matrix corresponding to the dof associated with the current element (denoted somewhat loosely as  [2.x.3130] ) is of the form: [1.x.96]
//
// We now need to modify it such that it appear as [1.x.97] with  [2.x.3131]  where  [2.x.3132]  and  [2.x.3133] .
//
// At this point, we need to take note of the fact that global data already exists in the  [2.x.3134] ,  [2.x.3135]  and   [2.x.3136]  sub-blocks.  So if we are to modify them, we must account for the data that is already there (i.e. simply add to it or remove it if necessary).  Since the copy_local_to_global operation is a "+=" operation, we need to take this into account
//
// For the  [2.x.3137]  block in particular, this means that contributions have been added from the surrounding cells, so we need to be careful when we manipulate this block.  We can't just erase the sub-blocks.
//
// This is the strategy we will employ to get the sub-blocks we want:
//
//
//
// -  [2.x.3138] : Since we don't have access to  [2.x.3139] , but we know its contribution is added to the global  [2.x.3140]  matrix, we just want to add the element wise static-condensation  [2.x.3141] .
//
//
//
// -  [2.x.3142] :                      Similarly,  [2.x.3143]  exists in          the subblock. Since the copy          operation is a += operation, we          need to subtract the existing           [2.x.3144]                       submatrix in addition to          "adding" that which we wish to          replace it with.
//
//
//
// -  [2.x.3145] :              Since the global matrix          is symmetric, this block is the          same as the one above and we          can simply use               [2.x.3146]           as a substitute for this one.
//
// We first extract element data from the system matrix. So first we get the entire subblock for the cell, then extract  [2.x.3147]  for the dofs associated with the current element
//
[0.x.24920] 
[0.x.24921] 
[0.x.24922] 
//
// and next the local matrices for  [2.x.3148] 
//[2.x.3149]  and  [2.x.3150] :
//
[0.x.24923] 
[0.x.24924] 
[0.x.24925] 
[0.x.24926] 
[0.x.24927] 
[0.x.24928] 
[0.x.24929] 
[0.x.24930] 
[0.x.24931] 
//
// To get the inverse of  [2.x.3151] , we invert it directly.  This operation is relatively inexpensive since  [2.x.3152]  since block-diagonal.
//
[0.x.24932] 
//
// Now we can make condensation terms to add to the  [2.x.3153]  block and put them in the cell local matrix     [2.x.3154] :
//
[0.x.24933] 
//[2.x.3155] 
[0.x.24934] 
//[2.x.3156] 
[0.x.24935] 
//[2.x.3157] 
[0.x.24936] 
[0.x.24937] 
[0.x.24938] 
[0.x.24939] 
//
// Next we place  [2.x.3158]  in the  [2.x.3159]  block for post-processing.  Note again that we need to remove the contribution that already exists there.
//
[0.x.24940] 
[0.x.24941] 
[0.x.24942] 
[0.x.24943] 
[0.x.24944] 
//[2.x.3160]  We now have all of the necessary components to use one of two possible methods to solve the linearised system. The first is to perform static condensation on an element level, which requires some alterations to the tangent matrix and RHS vector. Alternatively, the full block system can be solved by performing condensation on a global level. Below we implement both approaches.
//
[0.x.24945] 
[0.x.24946] 
[0.x.24947] 
[0.x.24948] 
[0.x.24949] 
[0.x.24950] 
//
[0.x.24951] 
[0.x.24952] 
//
// Firstly, here is the approach using the (permanent) augmentation of the tangent matrix. For the following, recall that [1.x.98] and  [1.x.99]  and thus  [1.x.100]  where  [1.x.101]
//
// At the top, we allocate two temporary vectors to help with the static condensation, and variables to store the number of linear solver iterations and the (hopefully converged) residual.
//
[0.x.24953] 
[0.x.24954] 
//
// In the first step of this function, we solve for the incremental displacement  [2.x.3161] .  To this end, we perform static condensation to make     [2.x.3162]  and put  [2.x.3163]  in the original  [2.x.3164]  block. That is, we make  [2.x.3165] .
//
[0.x.24955] 
[0.x.24956] 
//
//               [2.x.3166] 
[0.x.24957] 
[0.x.24958] 
//[2.x.3167] 
[0.x.24959] 
[0.x.24960] 
//[2.x.3168] 
[0.x.24961] 
[0.x.24962] 
//[2.x.3169] 
[0.x.24963] 
[0.x.24964] 
//[2.x.3170] 
[0.x.24965] 
[0.x.24966] 
//[2.x.3171] 
[0.x.24967] 
//
[0.x.24968] 
[0.x.24969] 
[0.x.24970] 
[0.x.24971] 
[0.x.24972] 
[0.x.24973] 
[0.x.24974] 
[0.x.24975] 
[0.x.24976] 
//
[0.x.24977] 
//
[0.x.24978] 
[0.x.24979] 
//
//     We've chosen by default a SSOR preconditioner as it appears to     provide the fastest solver convergence characteristics for this     problem on a single-thread machine.  However, this might not be     true for different problem sizes.
//
[0.x.24980] 
[0.x.24981] 
[0.x.24982] 
[0.x.24983] 
//
[0.x.24984] 
[0.x.24985] 
[0.x.24986] 
[0.x.24987] 
//
[0.x.24988] 
[0.x.24989] 
[0.x.24990] 
[0.x.24991] 
[0.x.24992] 
//
//     Otherwise if the problem is small     enough, a direct solver can be     utilised.
//
[0.x.24993] 
[0.x.24994] 
[0.x.24995] 
[0.x.24996] 
//
[0.x.24997] 
[0.x.24998] 
[0.x.24999] 
[0.x.25000] 
[0.x.25001] 
//
[0.x.25002] 
[0.x.25003] 
//
// Now that we have the displacement update, distribute the constraints back to the Newton update:
//
[0.x.25004] 
//
[0.x.25005] 
[0.x.25006] 
//
// The next step after solving the displacement problem is to post-process to get the dilatation solution from the substitution:     [2.x.3172] 
[0.x.25007] 
//[2.x.3173] 
[0.x.25008] 
[0.x.25009] 
//[2.x.3174] 
[0.x.25010] 
//[2.x.3175] 
[0.x.25011] 
//[2.x.3176] 
[0.x.25012] 
[0.x.25013] 
[0.x.25014] 
//
// we ensure here that any Dirichlet constraints are distributed on the updated solution:
//
[0.x.25015] 
//
// Finally we solve for the pressure update with the substitution:     [2.x.3177] 
[0.x.25016] 
//[2.x.3178] 
[0.x.25017] 
[0.x.25018] 
//[2.x.3179] 
[0.x.25019] 
//[2.x.3180] 
[0.x.25020] 
//
// and finally....     [2.x.3181] 
[0.x.25021] 
[0.x.25022] 
[0.x.25023] 
//
// We are now at the end, so we distribute all constrained dofs back to the Newton update:
//
[0.x.25024] 
//
[0.x.25025] 
[0.x.25026] 
[0.x.25027] 
[0.x.25028] 
[0.x.25029] 
//
[0.x.25030] 
[0.x.25031] 
//
[0.x.25032] 
[0.x.25033] 
//
//   Manual condensation of the dilatation and pressure fields on   a local level, and subsequent post-processing, took quite a   bit of effort to achieve. To recap, we had to produce the   inverse matrix    [2.x.3182] , which   was permanently written into the global tangent matrix. We then   permanently modified  [2.x.3183]  to produce    [2.x.3184] . This involved the   extraction and manipulation of local sub-blocks of the tangent   matrix. After solving for the displacement, the individual   matrix-vector operations required to solve for dilatation and   pressure were carefully implemented. Contrast these many sequence   of steps to the much simpler and transparent implementation using   functionality provided by the LinearOperator class.
//
//   For ease of later use, we define some aliases for   blocks in the RHS vector
//
[0.x.25034] 
[0.x.25035] 
[0.x.25036] 
//
//   ... and for blocks in the Newton update vector.
//
[0.x.25037] 
[0.x.25038] 
[0.x.25039] 
//
//   We next define some linear operators for the tangent matrix   sub-blocks We will exploit the symmetry of the system, so not all   blocks are required.
//
[0.x.25040] 
[0.x.25041] 
[0.x.25042] 
[0.x.25043] 
[0.x.25044] 
[0.x.25045] 
[0.x.25046] 
[0.x.25047] 
[0.x.25048] 
[0.x.25049] 
//
//   We then construct a LinearOperator that represents the inverse of   (square block)    [2.x.3185] . Since it is   diagonal (or, when a higher order ansatz it used, nearly   diagonal), a Jacobi preconditioner is suitable.
//
[0.x.25050] 
[0.x.25051] 
[0.x.25052] 
[0.x.25053] 
[0.x.25054] 
[0.x.25055] 
[0.x.25056] 
[0.x.25057] 
[0.x.25058] 
[0.x.25059] 
[0.x.25060] 
[0.x.25061] 
[0.x.25062] 
[0.x.25063] 
//
//   Now we can construct that transpose of    [2.x.3186]  and a   linear operator that represents the condensed operations    [2.x.3187]  and    [2.x.3188]  and the final   augmented matrix    [2.x.3189] .   Note that the schur_complement() operator could also be of use   here, but for clarity and the purpose of demonstrating the   similarities between the formulation and implementation of the   linear solution scheme, we will perform these operations   manually.
//
[0.x.25064] 
[0.x.25065] 
[0.x.25066] 
[0.x.25067] 
//
//   Lastly, we define an operator for inverse of augmented stiffness   matrix, namely  [2.x.3190] . Note   that the preconditioner for the augmented stiffness matrix is   different to the case when we use static condensation. In this   instance, the preconditioner is based on a non-modified    [2.x.3191] , while with the first approach we   actually modified the entries of this sub-block. However, since    [2.x.3192]  and    [2.x.3193]  operate on the same space, it remains   adequate for this problem.
//
[0.x.25068] 
[0.x.25069] 
[0.x.25070] 
[0.x.25071] 
[0.x.25072] 
[0.x.25073] 
[0.x.25074] 
[0.x.25075] 
[0.x.25076] 
[0.x.25077] 
[0.x.25078] 
[0.x.25079] 
[0.x.25080] 
[0.x.25081] 
[0.x.25082] 
[0.x.25083] 
[0.x.25084] 
//
//   Now we are in a position to solve for the displacement field.   We can nest the linear operations, and the result is immediately   written to the Newton update vector.   It is clear that the implementation closely mimics the derivation   stated in the introduction.
//
[0.x.25085] 
[0.x.25086] 
//
[0.x.25087] 
//
//   The operations need to post-process for the dilatation and   pressure fields are just as easy to express.
//
[0.x.25088] 
[0.x.25089] 
//
[0.x.25090] 
[0.x.25091] 
//
[0.x.25092] 
[0.x.25093] 
[0.x.25094] 
[0.x.25095] 
[0.x.25096] 
//
//   Solve the full block system with   a direct solver. As it is relatively   robust, it may be immune to problem   arising from the presence of the zero    [2.x.3194]    block.
//
[0.x.25097] 
[0.x.25098] 
[0.x.25099] 
//
[0.x.25100] 
[0.x.25101] 
//
[0.x.25102] 
[0.x.25103] 
[0.x.25104] 
[0.x.25105] 
//
[0.x.25106] 
//
// Finally, we again ensure here that any Dirichlet constraints are distributed on the updated solution:
//
[0.x.25107] 
[0.x.25108] 
//
[0.x.25109] 
[0.x.25110] 
//[2.x.3195]  Here we present how the results are written to file to be viewed using ParaView or VisIt. The method is similar to that shown in previous tutorials so will not be discussed in detail.
//
[0.x.25111] 
[0.x.25112] 
[0.x.25113] 
[0.x.25114] 
[0.x.25115] 
[0.x.25116] 
[0.x.25117] 
[0.x.25118] 
[0.x.25119] 
[0.x.25120] 
[0.x.25121] 
//
[0.x.25122] 
[0.x.25123] 
[0.x.25124] 
//
[0.x.25125] 
[0.x.25126] 
[0.x.25127] 
//
[0.x.25128] 
[0.x.25129] 
[0.x.25130] 
[0.x.25131] 
[0.x.25132] 
//
// Since we are dealing with a large deformation problem, it would be nice to display the result on a displaced grid!  The MappingQEulerian class linked with the DataOut class provides an interface through which this can be achieved without physically moving the grid points in the Triangulation object ourselves.  We first need to copy the solution to a temporary vector and then create the Eulerian mapping. We also specify the polynomial degree to the DataOut object in order to produce a more refined output data set when higher order polynomials are used.
//
[0.x.25133] 
[0.x.25134] 
[0.x.25135] 
[0.x.25136] 
[0.x.25137] 
//
[0.x.25138] 
[0.x.25139] 
[0.x.25140] 
[0.x.25141] 
//
[0.x.25142] 
//[2.x.3196]  Lastly we provide the main driver function which appears no different to the other tutorials.
//
[0.x.25143] 
[0.x.25144] 
[0.x.25145] 
//
[0.x.25146] 
[0.x.25147] 
[0.x.25148] 
[0.x.25149] 
[0.x.25150] 
[0.x.25151] 
[0.x.25152] 
[0.x.25153] 
[0.x.25154] 
[0.x.25155] 
[0.x.25156] 
[0.x.25157] 
[0.x.25158] 
[0.x.25159] 
[0.x.25160] 
[0.x.25161] 
[0.x.25162] 
//
[0.x.25163] 
[0.x.25164] 
[0.x.25165] 
[0.x.25166] 
[0.x.25167] 
[0.x.25168] 
[0.x.25169] 
[0.x.25170] 
[0.x.25171] 
[0.x.25172] 
[0.x.25173] 
[0.x.25174] 
[0.x.25175] 
[0.x.25176] 
//
[0.x.25177] 
[0.x.25178] 
[0.x.25179] 
[0.x.25180] 
[0.x.25181] 
[0.x.25182] 
[0.x.25183] 
[0.x.25184] 
[0.x.25185] 
[0.x.25186] 
[0.x.25187] 
[0.x.25188] 
[0.x.25189] 
[0.x.25190] 
[0.x.25191] 
[0.x.25192] 
//
[0.x.25193] 
[0.x.25194] 
[0.x.25195] 
[0.x.25196] 
[0.x.25197] 
//
// This example program is a slight modification of  [2.x.3197]  running in parallel using Trilinos to demonstrate the usage of periodic boundary conditions in deal.II. We thus omit to discuss the majority of the source code and only comment on the parts that deal with periodicity constraints. For the rest have a look at  [2.x.3198]  and the full source code at the bottom.
//
// In order to implement periodic boundary conditions only two functions have to be modified:
//
// -  [2.x.3199] :   To populate an AffineConstraints object with periodicity constraints
//
// -  [2.x.3200] :   To supply a distributed triangulation with periodicity information.
//
// The rest of the program is identical to  [2.x.3201] , so let us skip this part and only show these two functions in the following. (The full program can be found in the "Plain program" section below, though.)
//
//  [2.x.3202]  SKIP
//
[0.x.25198] 
//
[0.x.25199] 
//
[0.x.25200] 
[0.x.25201] 
//
[0.x.25202] 
[0.x.25203] 
[0.x.25204] 
[0.x.25205] 
[0.x.25206] 
//
[0.x.25207] 
[0.x.25208] 
//
[0.x.25209] 
[0.x.25210] 
//
[0.x.25211] 
[0.x.25212] 
[0.x.25213] 
//
[0.x.25214] 
[0.x.25215] 
[0.x.25216] 
//
[0.x.25217] 
[0.x.25218] 
[0.x.25219] 
//
[0.x.25220] 
[0.x.25221] 
[0.x.25222] 
[0.x.25223] 
[0.x.25224] 
[0.x.25225] 
//
[0.x.25226] 
[0.x.25227] 
[0.x.25228] 
[0.x.25229] 
[0.x.25230] 
[0.x.25231] 
[0.x.25232] 
//
[0.x.25233] 
//
[0.x.25234] 
//
[0.x.25235] 
[0.x.25236] 
[0.x.25237] 
//
[0.x.25238] 
[0.x.25239] 
[0.x.25240] 
//
[0.x.25241] 
//
[0.x.25242] 
//
[0.x.25243] 
[0.x.25244] 
//
[0.x.25245] 
//
[0.x.25246] 
[0.x.25247] 
//
[0.x.25248] 
[0.x.25249] 
[0.x.25250] 
[0.x.25251] 
[0.x.25252] 
[0.x.25253] 
[0.x.25254] 
//
[0.x.25255] 
[0.x.25256] 
//
[0.x.25257] 
[0.x.25258] 
[0.x.25259] 
//
[0.x.25260] 
[0.x.25261] 
[0.x.25262] 
[0.x.25263] 
[0.x.25264] 
[0.x.25265] 
[0.x.25266] 
//
[0.x.25267] 
[0.x.25268] 
//
[0.x.25269] 
[0.x.25270] 
[0.x.25271] 
[0.x.25272] 
[0.x.25273] 
[0.x.25274] 
[0.x.25275] 
//
[0.x.25276] 
[0.x.25277] 
[0.x.25278] 
[0.x.25279] 
[0.x.25280] 
[0.x.25281] 
[0.x.25282] 
//
[0.x.25283] 
[0.x.25284] 
//
[0.x.25285] 
[0.x.25286] 
[0.x.25287] 
//
[0.x.25288] 
[0.x.25289] 
[0.x.25290] 
[0.x.25291] 
[0.x.25292] 
[0.x.25293] 
//
[0.x.25294] 
[0.x.25295] 
[0.x.25296] 
[0.x.25297] 
//
[0.x.25298] 
[0.x.25299] 
[0.x.25300] 
[0.x.25301] 
[0.x.25302] 
[0.x.25303] 
[0.x.25304] 
//
[0.x.25305] 
[0.x.25306] 
[0.x.25307] 
[0.x.25308] 
[0.x.25309] 
[0.x.25310] 
[0.x.25311] 
[0.x.25312] 
//
[0.x.25313] 
[0.x.25314] 
//
[0.x.25315] 
[0.x.25316] 
[0.x.25317] 
//
[0.x.25318] 
[0.x.25319] 
[0.x.25320] 
//
[0.x.25321] 
[0.x.25322] 
[0.x.25323] 
[0.x.25324] 
[0.x.25325] 
[0.x.25326] 
[0.x.25327] 
[0.x.25328] 
[0.x.25329] 
[0.x.25330] 
[0.x.25331] 
//
[0.x.25332] 
[0.x.25333] 
[0.x.25334] 
[0.x.25335] 
[0.x.25336] 
[0.x.25337] 
[0.x.25338] 
[0.x.25339] 
//
[0.x.25340] 
[0.x.25341] 
[0.x.25342] 
[0.x.25343] 
//
[0.x.25344] 
[0.x.25345] 
[0.x.25346] 
[0.x.25347] 
[0.x.25348] 
[0.x.25349] 
[0.x.25350] 
[0.x.25351] 
[0.x.25352] 
//
[0.x.25353] 
[0.x.25354] 
//
[0.x.25355] 
[0.x.25356] 
[0.x.25357] 
[0.x.25358] 
[0.x.25359] 
[0.x.25360] 
[0.x.25361] 
//
[0.x.25362] 
[0.x.25363] 
[0.x.25364] 
[0.x.25365] 
[0.x.25366] 
[0.x.25367] 
[0.x.25368] 
[0.x.25369] 
[0.x.25370] 
[0.x.25371] 
[0.x.25372] 
[0.x.25373] 
//
[0.x.25374] 
[0.x.25375] 
[0.x.25376] 
[0.x.25377] 
[0.x.25378] 
[0.x.25379] 
[0.x.25380] 
[0.x.25381] 
[0.x.25382] 
//
[0.x.25383] 
[0.x.25384] 
[0.x.25385] 
[0.x.25386] 
[0.x.25387] 
[0.x.25388] 
[0.x.25389] 
[0.x.25390] 
[0.x.25391] 
[0.x.25392] 
//[2.x.3203] 
//[2.x.3204] 
[0.x.25393] 
[0.x.25394] 
[0.x.25395] 
[0.x.25396] 
[0.x.25397] 
[0.x.25398] 
//
[0.x.25399] 
[0.x.25400] 
//
// Before we can prescribe periodicity constraints, we need to ensure that cells on opposite sides of the domain but connected by periodic faces are part of the ghost layer if one of them is stored on the local processor. At this point we need to think about how we want to prescribe periodicity. The vertices  [2.x.3205]  of a face on the left boundary should be matched to the vertices  [2.x.3206]  of a face on the lower boundary given by  [2.x.3207]  where the rotation matrix  [2.x.3208]  and the offset  [2.x.3209]  are given by [1.x.102] The data structure we are saving the resulting information into is here based on the Triangulation.
//
[0.x.25401] 
[0.x.25402] 
[0.x.25403] 
//
[0.x.25404] 
[0.x.25405] 
[0.x.25406] 
//
[0.x.25407] 
[0.x.25408] 
[0.x.25409] 
[0.x.25410] 
[0.x.25411] 
[0.x.25412] 
[0.x.25413] 
//
// Now telling the triangulation about the desired periodicity is particularly easy by just calling  [2.x.3210] 
[0.x.25414] 
//
[0.x.25415] 
[0.x.25416] 
//
[0.x.25417] 
[0.x.25418] 
[0.x.25419] 
[0.x.25420] 
//
[0.x.25421] 
[0.x.25422] 
[0.x.25423] 
//
[0.x.25424] 
[0.x.25425] 
[0.x.25426] 
//
[0.x.25427] 
[0.x.25428] 
[0.x.25429] 
[0.x.25430] 
[0.x.25431] 
//
[0.x.25432] 
[0.x.25433] 
[0.x.25434] 
[0.x.25435] 
[0.x.25436] 
[0.x.25437] 
[0.x.25438] 
//
[0.x.25439] 
[0.x.25440] 
//
[0.x.25441] 
//
[0.x.25442] 
[0.x.25443] 
[0.x.25444] 
[0.x.25445] 
[0.x.25446] 
[0.x.25447] 
[0.x.25448] 
[0.x.25449] 
[0.x.25450] 
[0.x.25451] 
[0.x.25452] 
[0.x.25453] 
[0.x.25454] 
//
// After we provided the mesh with the necessary information for the periodicity constraints, we are now able to actual create them. For describing the matching we are using the same approach as before, i.e., the  [2.x.3211]  of a face on the left boundary should be matched to the vertices  [2.x.3212]  of a face on the lower boundary given by  [2.x.3213]  where the rotation matrix  [2.x.3214]  and the offset  [2.x.3215]  are given by [1.x.103] These two objects not only describe how faces should be matched but also in which sense the solution should be transformed from  [2.x.3216]  to  [2.x.3217] .
//
[0.x.25455] 
[0.x.25456] 
[0.x.25457] 
//
[0.x.25458] 
//
// For setting up the constraints, we first store the periodicity information in an auxiliary object of type  [2.x.3218] 
//[2.x.3219]  </code>. The periodic boundaries have the boundary indicators 2 (x=0) and 3 (y=0). All the other parameters we have set up before. In this case the direction does not matter. Due to  [2.x.3220]  this is exactly what we want.
//
[0.x.25459] 
[0.x.25460] 
[0.x.25461] 
//
[0.x.25462] 
//
[0.x.25463] 
[0.x.25464] 
[0.x.25465] 
[0.x.25466] 
[0.x.25467] 
[0.x.25468] 
[0.x.25469] 
//
// Next, we need to provide information on which vector valued components of the solution should be rotated. Since we choose here to just constraint the velocity and this starts at the first component of the solution vector, we simply insert a 0:
//
[0.x.25470] 
[0.x.25471] 
//
// After setting up all the information in periodicity_vector all we have to do is to tell make_periodicity_constraints to create the desired constraints.
//
[0.x.25472] 
[0.x.25473] 
[0.x.25474] 
[0.x.25475] 
[0.x.25476] 
//
[0.x.25477] 
[0.x.25478] 
[0.x.25479] 
[0.x.25480] 
[0.x.25481] 
[0.x.25482] 
[0.x.25483] 
[0.x.25484] 
[0.x.25485] 
[0.x.25486] 
[0.x.25487] 
[0.x.25488] 
[0.x.25489] 
//
[0.x.25490] 
//
[0.x.25491] 
[0.x.25492] 
[0.x.25493] 
[0.x.25494] 
[0.x.25495] 
//
[0.x.25496] 
[0.x.25497] 
[0.x.25498] 
[0.x.25499] 
[0.x.25500] 
[0.x.25501] 
[0.x.25502] 
//
[0.x.25503] 
[0.x.25504] 
[0.x.25505] 
[0.x.25506] 
[0.x.25507] 
[0.x.25508] 
[0.x.25509] 
//
[0.x.25510] 
//
[0.x.25511] 
[0.x.25512] 
//
[0.x.25513] 
[0.x.25514] 
[0.x.25515] 
[0.x.25516] 
[0.x.25517] 
[0.x.25518] 
//
[0.x.25519] 
[0.x.25520] 
[0.x.25521] 
[0.x.25522] 
[0.x.25523] 
[0.x.25524] 
[0.x.25525] 
//
[0.x.25526] 
[0.x.25527] 
[0.x.25528] 
[0.x.25529] 
[0.x.25530] 
[0.x.25531] 
[0.x.25532] 
//
[0.x.25533] 
//
[0.x.25534] 
[0.x.25535] 
//
[0.x.25536] 
[0.x.25537] 
[0.x.25538] 
[0.x.25539] 
[0.x.25540] 
//
// The rest of the program is then again identical to  [2.x.3221] . We will omit it here now, but as before, you can find these parts in the "Plain program" section below.
//
//  [2.x.3222]  SKIP
//
[0.x.25541] 
[0.x.25542] 
[0.x.25543] 
[0.x.25544] 
[0.x.25545] 
[0.x.25546] 
//
[0.x.25547] 
//
[0.x.25548] 
[0.x.25549] 
[0.x.25550] 
[0.x.25551] 
[0.x.25552] 
//
[0.x.25553] 
//
[0.x.25554] 
//
[0.x.25555] 
[0.x.25556] 
[0.x.25557] 
[0.x.25558] 
//
[0.x.25559] 
//
[0.x.25560] 
[0.x.25561] 
//
[0.x.25562] 
[0.x.25563] 
//
[0.x.25564] 
[0.x.25565] 
[0.x.25566] 
//
[0.x.25567] 
[0.x.25568] 
[0.x.25569] 
[0.x.25570] 
[0.x.25571] 
[0.x.25572] 
[0.x.25573] 
//
[0.x.25574] 
[0.x.25575] 
//
[0.x.25576] 
[0.x.25577] 
[0.x.25578] 
[0.x.25579] 
[0.x.25580] 
[0.x.25581] 
[0.x.25582] 
[0.x.25583] 
[0.x.25584] 
//
[0.x.25585] 
[0.x.25586] 
[0.x.25587] 
[0.x.25588] 
[0.x.25589] 
[0.x.25590] 
[0.x.25591] 
[0.x.25592] 
[0.x.25593] 
//
[0.x.25594] 
[0.x.25595] 
[0.x.25596] 
//
[0.x.25597] 
[0.x.25598] 
[0.x.25599] 
[0.x.25600] 
[0.x.25601] 
[0.x.25602] 
[0.x.25603] 
//
[0.x.25604] 
[0.x.25605] 
[0.x.25606] 
[0.x.25607] 
[0.x.25608] 
[0.x.25609] 
[0.x.25610] 
//
[0.x.25611] 
[0.x.25612] 
[0.x.25613] 
[0.x.25614] 
[0.x.25615] 
[0.x.25616] 
[0.x.25617] 
[0.x.25618] 
[0.x.25619] 
[0.x.25620] 
//
[0.x.25621] 
[0.x.25622] 
//
[0.x.25623] 
[0.x.25624] 
//
[0.x.25625] 
[0.x.25626] 
[0.x.25627] 
[0.x.25628] 
[0.x.25629] 
//
[0.x.25630] 
[0.x.25631] 
[0.x.25632] 
[0.x.25633] 
[0.x.25634] 
[0.x.25635] 
//
[0.x.25636] 
[0.x.25637] 
//
[0.x.25638] 
[0.x.25639] 
[0.x.25640] 
[0.x.25641] 
[0.x.25642] 
[0.x.25643] 
//
[0.x.25644] 
[0.x.25645] 
//
[0.x.25646] 
[0.x.25647] 
[0.x.25648] 
//
[0.x.25649] 
[0.x.25650] 
//
[0.x.25651] 
[0.x.25652] 
[0.x.25653] 
[0.x.25654] 
[0.x.25655] 
[0.x.25656] 
//
[0.x.25657] 
//
[0.x.25658] 
[0.x.25659] 
[0.x.25660] 
//
[0.x.25661] 
[0.x.25662] 
[0.x.25663] 
[0.x.25664] 
//
[0.x.25665] 
//
[0.x.25666] 
[0.x.25667] 
[0.x.25668] 
[0.x.25669] 
//
[0.x.25670] 
[0.x.25671] 
[0.x.25672] 
[0.x.25673] 
[0.x.25674] 
[0.x.25675] 
//
[0.x.25676] 
[0.x.25677] 
[0.x.25678] 
[0.x.25679] 
[0.x.25680] 
//
[0.x.25681] 
[0.x.25682] 
[0.x.25683] 
[0.x.25684] 
[0.x.25685] 
[0.x.25686] 
[0.x.25687] 
[0.x.25688] 
[0.x.25689] 
[0.x.25690] 
[0.x.25691] 
//
[0.x.25692] 
[0.x.25693] 
[0.x.25694] 
//
[0.x.25695] 
[0.x.25696] 
[0.x.25697] 
[0.x.25698] 
//
[0.x.25699] 
[0.x.25700] 
[0.x.25701] 
[0.x.25702] 
[0.x.25703] 
[0.x.25704] 
[0.x.25705] 
[0.x.25706] 
//
[0.x.25707] 
[0.x.25708] 
[0.x.25709] 
[0.x.25710] 
//
[0.x.25711] 
[0.x.25712] 
[0.x.25713] 
[0.x.25714] 
//
[0.x.25715] 
[0.x.25716] 
[0.x.25717] 
[0.x.25718] 
//
[0.x.25719] 
[0.x.25720] 
//
[0.x.25721] 
//
[0.x.25722] 
[0.x.25723] 
//
[0.x.25724] 
[0.x.25725] 
//
[0.x.25726] 
//
[0.x.25727] 
[0.x.25728] 
[0.x.25729] 
[0.x.25730] 
//
[0.x.25731] 
[0.x.25732] 
[0.x.25733] 
[0.x.25734] 
[0.x.25735] 
[0.x.25736] 
//
[0.x.25737] 
[0.x.25738] 
[0.x.25739] 
[0.x.25740] 
[0.x.25741] 
[0.x.25742] 
[0.x.25743] 
[0.x.25744] 
[0.x.25745] 
[0.x.25746] 
[0.x.25747] 
[0.x.25748] 
[0.x.25749] 
[0.x.25750] 
[0.x.25751] 
//
[0.x.25752] 
[0.x.25753] 
[0.x.25754] 
[0.x.25755] 
[0.x.25756] 
[0.x.25757] 
[0.x.25758] 
[0.x.25759] 
[0.x.25760] 
[0.x.25761] 
[0.x.25762] 
[0.x.25763] 
[0.x.25764] 
[0.x.25765] 
//
[0.x.25766] 
[0.x.25767] 
//[2.x.3223] 
[0.x.25768] 
[0.x.25769] 
[0.x.25770] 
[0.x.25771] 
[0.x.25772] 
[0.x.25773] 
[0.x.25774] 
[0.x.25775] 
[0.x.25776] 
[0.x.25777] 
[0.x.25778] 
[0.x.25779] 
[0.x.25780] 
[0.x.25781] 
//
[0.x.25782] 
[0.x.25783] 
[0.x.25784] 
//[2.x.3224] 
//
// The include files for this program are the same as for many others before. The only new one is the one that declares FE_Nothing as discussed in the introduction. The ones in the hp directory have already been discussed in  [2.x.3225] .
//
[0.x.25785] 
[0.x.25786] 
[0.x.25787] 
[0.x.25788] 
//
[0.x.25789] 
[0.x.25790] 
[0.x.25791] 
[0.x.25792] 
[0.x.25793] 
//
[0.x.25794] 
[0.x.25795] 
[0.x.25796] 
//
[0.x.25797] 
//
[0.x.25798] 
[0.x.25799] 
[0.x.25800] 
[0.x.25801] 
//
[0.x.25802] 
[0.x.25803] 
//
[0.x.25804] 
[0.x.25805] 
[0.x.25806] 
//
[0.x.25807] 
[0.x.25808] 
//
[0.x.25809] 
[0.x.25810] 
[0.x.25811] 
//[2.x.3226] 
//
// This is the main class. It is, if you want, a combination of  [2.x.3227]  and  [2.x.3228]  in that it has member variables that either address the global problem (the Triangulation and DoFHandler objects, as well as the  [2.x.3229]  and various linear algebra objects) or that pertain to either the elasticity or Stokes sub-problems. The general structure of the class, however, is like that of most of the other programs implementing stationary problems.
//
// There are a few helper functions (<code>cell_is_in_fluid_domain, cell_is_in_solid_domain</code>) of self-explanatory nature (operating on the symbolic names for the two subdomains that will be used as material_ids for cells belonging to the subdomains, as explained in the introduction) and a few functions (<code>make_grid, set_active_fe_indices, assemble_interface_terms</code>) that have been broken out of other functions that can be found in many of the other tutorial programs and that will be discussed as we get to their implementation.
//
// The final set of variables ( [2.x.3230] ) describes the material properties used for the two physics models.
//
[0.x.25812] 
[0.x.25813] 
[0.x.25814] 
[0.x.25815] 
[0.x.25816] 
[0.x.25817] 
[0.x.25818] 
//
[0.x.25819] 
[0.x.25820] 
[0.x.25821] 
[0.x.25822] 
[0.x.25823] 
[0.x.25824] 
//
[0.x.25825] 
[0.x.25826] 
//
[0.x.25827] 
[0.x.25828] 
//
[0.x.25829] 
[0.x.25830] 
[0.x.25831] 
[0.x.25832] 
[0.x.25833] 
[0.x.25834] 
[0.x.25835] 
[0.x.25836] 
[0.x.25837] 
[0.x.25838] 
[0.x.25839] 
[0.x.25840] 
[0.x.25841] 
[0.x.25842] 
//
[0.x.25843] 
[0.x.25844] 
//
[0.x.25845] 
[0.x.25846] 
[0.x.25847] 
[0.x.25848] 
[0.x.25849] 
//
[0.x.25850] 
//
[0.x.25851] 
[0.x.25852] 
//
[0.x.25853] 
[0.x.25854] 
//
[0.x.25855] 
[0.x.25856] 
[0.x.25857] 
[0.x.25858] 
//[2.x.3231] 
//
// The following class does as its name suggests. The boundary values for the velocity are  [2.x.3232]  in 2d and  [2.x.3233]  in 3d, respectively. The remaining boundary conditions for this problem are all homogeneous and have been discussed in the introduction. The right hand side forcing term is zero for both the fluid and the solid so we don't need an extra class for it.
//
[0.x.25859] 
[0.x.25860] 
[0.x.25861] 
[0.x.25862] 
[0.x.25863] 
[0.x.25864] 
[0.x.25865] 
//
[0.x.25866] 
[0.x.25867] 
//
[0.x.25868] 
[0.x.25869] 
[0.x.25870] 
//
[0.x.25871] 
[0.x.25872] 
[0.x.25873] 
[0.x.25874] 
[0.x.25875] 
[0.x.25876] 
//
[0.x.25877] 
[0.x.25878] 
[0.x.25879] 
[0.x.25880] 
[0.x.25881] 
[0.x.25882] 
[0.x.25883] 
[0.x.25884] 
[0.x.25885] 
[0.x.25886] 
//
[0.x.25887] 
[0.x.25888] 
//
[0.x.25889] 
[0.x.25890] 
[0.x.25891] 
[0.x.25892] 
[0.x.25893] 
[0.x.25894] 
[0.x.25895] 
//
//  [2.x.3234] 
//[2.x.3235] 
//
// Let's now get to the implementation of the primary class of this program. The first few functions are the constructor and the helper functions that can be used to determine which part of the domain a cell is in. Given the discussion of these topics in the introduction, their implementation is rather obvious. In the constructor, note that we have to construct the  [2.x.3236]  object from the base elements for Stokes and elasticity; using the  [2.x.3237]  function assigns them spots zero and one in this collection, an order that we have to remember and use consistently in the rest of the program.
//
[0.x.25896] 
[0.x.25897] 
[0.x.25898] 
[0.x.25899] 
[0.x.25900] 
[0.x.25901] 
[0.x.25902] 
[0.x.25903] 
[0.x.25904] 
[0.x.25905] 
[0.x.25906] 
[0.x.25907] 
[0.x.25908] 
[0.x.25909] 
[0.x.25910] 
[0.x.25911] 
[0.x.25912] 
[0.x.25913] 
[0.x.25914] 
[0.x.25915] 
[0.x.25916] 
[0.x.25917] 
[0.x.25918] 
[0.x.25919] 
[0.x.25920] 
[0.x.25921] 
[0.x.25922] 
//
[0.x.25923] 
[0.x.25924] 
[0.x.25925] 
[0.x.25926] 
[0.x.25927] 
[0.x.25928] 
//
[0.x.25929] 
[0.x.25930] 
[0.x.25931] 
[0.x.25932] 
[0.x.25933] 
[0.x.25934] 
//[2.x.3238] 
//
// The next pair of functions deals with generating a mesh and making sure all flags that denote subdomains are correct.  [2.x.3239] , as discussed in the introduction, generates an  [2.x.3240]  mesh (or an  [2.x.3241]  mesh in 3d) to make sure that each coarse mesh cell is completely within one of the subdomains. After generating this mesh, we loop over its boundary and set the boundary indicator to one at the top boundary, the only place where we set nonzero Dirichlet boundary conditions. After this, we loop again over all cells to set the material indicator &mdash; used to denote which part of the domain we are in, to either the fluid or solid indicator.
//
[0.x.25935] 
[0.x.25936] 
[0.x.25937] 
[0.x.25938] 
//
[0.x.25939] 
[0.x.25940] 
[0.x.25941] 
[0.x.25942] 
//
[0.x.25943] 
[0.x.25944] 
[0.x.25945] 
[0.x.25946] 
[0.x.25947] 
[0.x.25948] 
[0.x.25949] 
[0.x.25950] 
[0.x.25951] 
//
// The second part of this pair of functions determines which finite element to use on each cell. Above we have set the material indicator for each coarse mesh cell, and as mentioned in the introduction, this information is inherited from mother to child cell upon mesh refinement.
//
// In other words, whenever we have refined (or created) the mesh, we can rely on the material indicators to be a correct description of which part of the domain a cell is in. We then use this to set the active FE index of the cell to the corresponding element of the  [2.x.3242]  member variable of this class: zero for fluid cells, one for solid cells.
//
[0.x.25952] 
[0.x.25953] 
[0.x.25954] 
[0.x.25955] 
[0.x.25956] 
[0.x.25957] 
[0.x.25958] 
[0.x.25959] 
[0.x.25960] 
[0.x.25961] 
[0.x.25962] 
[0.x.25963] 
[0.x.25964] 
//[2.x.3243] 
//
// The next step is to setup the data structures for the linear system. To this end, we first have to set the active FE indices with the function immediately above, then distribute degrees of freedom, and then determine constraints on the linear system. The latter includes hanging node constraints as usual, but also the inhomogeneous boundary values at the top fluid boundary, and zero boundary values along the perimeter of the solid subdomain.
//
[0.x.25965] 
[0.x.25966] 
[0.x.25967] 
[0.x.25968] 
[0.x.25969] 
//
[0.x.25970] 
[0.x.25971] 
[0.x.25972] 
//
[0.x.25973] 
[0.x.25974] 
[0.x.25975] 
[0.x.25976] 
[0.x.25977] 
[0.x.25978] 
[0.x.25979] 
//
[0.x.25980] 
[0.x.25981] 
[0.x.25982] 
[0.x.25983] 
[0.x.25984] 
[0.x.25985] 
[0.x.25986] 
[0.x.25987] 
//
// There are more constraints we have to handle, though: we have to make sure that the velocity is zero at the interface between fluid and solid. The following piece of code was already presented in the introduction:
//
[0.x.25988] 
[0.x.25989] 
[0.x.25990] 
[0.x.25991] 
[0.x.25992] 
[0.x.25993] 
[0.x.25994] 
[0.x.25995] 
[0.x.25996] 
//
[0.x.25997] 
[0.x.25998] 
[0.x.25999] 
[0.x.26000] 
[0.x.26001] 
[0.x.26002] 
[0.x.26003] 
[0.x.26004] 
[0.x.26005] 
[0.x.26006] 
[0.x.26007] 
[0.x.26008] 
[0.x.26009] 
[0.x.26010] 
[0.x.26011] 
//
[0.x.26012] 
[0.x.26013] 
[0.x.26014] 
[0.x.26015] 
[0.x.26016] 
[0.x.26017] 
[0.x.26018] 
[0.x.26019] 
[0.x.26020] 
[0.x.26021] 
[0.x.26022] 
[0.x.26023] 
//
// At the end of all this, we can declare to the constraints object that we now have all constraints ready to go and that the object can rebuild its internal data structures for better efficiency:
//
[0.x.26024] 
//
[0.x.26025] 
[0.x.26026] 
[0.x.26027] 
[0.x.26028] 
//
// In the rest of this function we create a sparsity pattern as discussed extensively in the introduction, and use it to initialize the matrix; then also set vectors to their correct sizes:
//
[0.x.26029] 
[0.x.26030] 
//
[0.x.26031] 
[0.x.26032] 
[0.x.26033] 
[0.x.26034] 
//
[0.x.26035] 
[0.x.26036] 
[0.x.26037] 
[0.x.26038] 
[0.x.26039] 
[0.x.26040] 
[0.x.26041] 
//
[0.x.26042] 
[0.x.26043] 
[0.x.26044] 
//
[0.x.26045] 
[0.x.26046] 
[0.x.26047] 
[0.x.26048] 
[0.x.26049] 
[0.x.26050] 
[0.x.26051] 
//
[0.x.26052] 
//
[0.x.26053] 
[0.x.26054] 
[0.x.26055] 
//
//  [2.x.3244] 
//
// Following is the central function of this program: the one that assembles the linear system. It has a long section of setting up auxiliary functions at the beginning: from creating the quadrature formulas and setting up the FEValues, FEFaceValues and FESubfaceValues objects necessary to integrate the cell terms as well as the interface terms for the case where cells along the interface come together at same size or with differing levels of refinement...
//
[0.x.26056] 
[0.x.26057] 
[0.x.26058] 
[0.x.26059] 
[0.x.26060] 
//
[0.x.26061] 
[0.x.26062] 
//
[0.x.26063] 
[0.x.26064] 
[0.x.26065] 
//
[0.x.26066] 
[0.x.26067] 
[0.x.26068] 
[0.x.26069] 
//
[0.x.26070] 
[0.x.26071] 
//
[0.x.26072] 
[0.x.26073] 
[0.x.26074] 
[0.x.26075] 
[0.x.26076] 
[0.x.26077] 
[0.x.26078] 
[0.x.26079] 
[0.x.26080] 
[0.x.26081] 
[0.x.26082] 
[0.x.26083] 
[0.x.26084] 
[0.x.26085] 
[0.x.26086] 
[0.x.26087] 
[0.x.26088] 
//
// ...to objects that are needed to describe the local contributions to the global linear system...
//
[0.x.26089] 
[0.x.26090] 
[0.x.26091] 
//
[0.x.26092] 
[0.x.26093] 
[0.x.26094] 
[0.x.26095] 
//
[0.x.26096] 
[0.x.26097] 
[0.x.26098] 
//
[0.x.26099] 
//
// ...to variables that allow us to extract certain components of the shape functions and cache their values rather than having to recompute them at every quadrature point:
//
[0.x.26100] 
[0.x.26101] 
[0.x.26102] 
//
[0.x.26103] 
[0.x.26104] 
[0.x.26105] 
[0.x.26106] 
//
[0.x.26107] 
[0.x.26108] 
[0.x.26109] 
//
// Then comes the main loop over all cells and, as in  [2.x.3245] , the initialization of the  [2.x.3246]  object for the current cell and the extraction of a FEValues object that is appropriate for the current cell:
//
[0.x.26110] 
[0.x.26111] 
[0.x.26112] 
//
[0.x.26113] 
//
[0.x.26114] 
[0.x.26115] 
[0.x.26116] 
//
// With all of this done, we continue to assemble the cell terms for cells that are part of the Stokes and elastic regions. While we could in principle do this in one formula, in effect implementing the one bilinear form stated in the introduction, we realize that our finite element spaces are chosen in such a way that on each cell, one set of variables (either velocities and pressure, or displacements) are always zero, and consequently a more efficient way of computing local integrals is to do only what's necessary based on an  [2.x.3247]  clause that tests which part of the domain we are in.
//
// The actual computation of the local matrix is the same as in  [2.x.3248]  as well as that given in the  [2.x.3249]  documentation module for the elasticity equations:
//
[0.x.26117] 
[0.x.26118] 
[0.x.26119] 
[0.x.26120] 
//
[0.x.26121] 
[0.x.26122] 
[0.x.26123] 
[0.x.26124] 
[0.x.26125] 
[0.x.26126] 
[0.x.26127] 
[0.x.26128] 
[0.x.26129] 
[0.x.26130] 
//
[0.x.26131] 
[0.x.26132] 
[0.x.26133] 
[0.x.26134] 
[0.x.26135] 
[0.x.26136] 
[0.x.26137] 
[0.x.26138] 
[0.x.26139] 
[0.x.26140] 
[0.x.26141] 
[0.x.26142] 
[0.x.26143] 
[0.x.26144] 
[0.x.26145] 
//
[0.x.26146] 
[0.x.26147] 
[0.x.26148] 
[0.x.26149] 
[0.x.26150] 
[0.x.26151] 
[0.x.26152] 
[0.x.26153] 
[0.x.26154] 
//
[0.x.26155] 
[0.x.26156] 
[0.x.26157] 
[0.x.26158] 
[0.x.26159] 
[0.x.26160] 
[0.x.26161] 
[0.x.26162] 
[0.x.26163] 
[0.x.26164] 
[0.x.26165] 
[0.x.26166] 
[0.x.26167] 
[0.x.26168] 
[0.x.26169] 
//
// Once we have the contributions from cell integrals, we copy them into the global matrix (taking care of constraints right away, through the  [2.x.3250]  function). Note that we have not written anything into the  [2.x.3251]  variable, though we still need to pass it along since the elimination of nonzero boundary values requires the modification of local and consequently also global right hand side values:
//
[0.x.26170] 
[0.x.26171] 
[0.x.26172] 
[0.x.26173] 
[0.x.26174] 
[0.x.26175] 
[0.x.26176] 
//
// The more interesting part of this function is where we see about face terms along the interface between the two subdomains. To this end, we first have to make sure that we only assemble them once even though a loop over all faces of all cells would encounter each part of the interface twice. We arbitrarily make the decision that we will only evaluate interface terms if the current cell is part of the solid subdomain and if, consequently, a face is not at the boundary and the potential neighbor behind it is part of the fluid domain. Let's start with these conditions:
//
[0.x.26177] 
[0.x.26178] 
[0.x.26179] 
[0.x.26180] 
//
//       At this point we know that the current cell is a candidate       for integration and that a neighbor behind face        [2.x.3252]  exists. There are now three possibilities:            
//
// - The neighbor is at the same refinement level and has no         children.      
//
// - The neighbor has children.      
//
// - The neighbor is coarser.             In all three cases, we are only interested in it if it is       part of the fluid subdomain. So let us start with the first       and simplest case: if the neighbor is at the same level,       has no children, and is a fluid cell, then the two cells       share a boundary that is part of the interface along which       we want to integrate interface terms. All we have to do is       initialize two FEFaceValues object with the current face       and the face of the neighboring cell (note how we find out       which face of the neighboring cell borders on the current       cell) and pass things off to the function that evaluates       the interface terms (the third through fifth arguments to       this function provide it with scratch arrays). The result       is then again copied into the global matrix, using a       function that knows that the DoF indices of rows and       columns of the local matrix result from different cells:
//
[0.x.26181] 
[0.x.26182] 
[0.x.26183] 
[0.x.26184] 
[0.x.26185] 
[0.x.26186] 
[0.x.26187] 
//
[0.x.26188] 
[0.x.26189] 
[0.x.26190] 
[0.x.26191] 
[0.x.26192] 
[0.x.26193] 
//
[0.x.26194] 
[0.x.26195] 
[0.x.26196] 
[0.x.26197] 
[0.x.26198] 
[0.x.26199] 
[0.x.26200] 
//
//       The second case is if the neighbor has further children. In       that case, we have to loop over all the children of the       neighbor to see if they are part of the fluid subdomain. If       they are, then we integrate over the common interface,       which is a face for the neighbor and a subface of the       current cell, requiring us to use an FEFaceValues for the       neighbor and an FESubfaceValues for the current cell:
//
[0.x.26201] 
[0.x.26202] 
[0.x.26203] 
[0.x.26204] 
[0.x.26205] 
[0.x.26206] 
[0.x.26207] 
[0.x.26208] 
[0.x.26209] 
[0.x.26210] 
[0.x.26211] 
[0.x.26212] 
[0.x.26213] 
//
[0.x.26214] 
[0.x.26215] 
[0.x.26216] 
[0.x.26217] 
[0.x.26218] 
[0.x.26219] 
//
[0.x.26220] 
[0.x.26221] 
[0.x.26222] 
[0.x.26223] 
[0.x.26224] 
[0.x.26225] 
[0.x.26226] 
[0.x.26227] 
[0.x.26228] 
//
//       The last option is that the neighbor is coarser. In that       case we have to use an FESubfaceValues object for the       neighbor and a FEFaceValues for the current cell; the rest       is the same as before:
//
[0.x.26229] 
[0.x.26230] 
[0.x.26231] 
[0.x.26232] 
[0.x.26233] 
[0.x.26234] 
[0.x.26235] 
[0.x.26236] 
//
[0.x.26237] 
[0.x.26238] 
[0.x.26239] 
[0.x.26240] 
[0.x.26241] 
[0.x.26242] 
//
[0.x.26243] 
[0.x.26244] 
[0.x.26245] 
[0.x.26246] 
[0.x.26247] 
[0.x.26248] 
[0.x.26249] 
[0.x.26250] 
[0.x.26251] 
[0.x.26252] 
//
// In the function that assembles the global system, we passed computing interface terms to a separate function we discuss here. The key is that even though we can't predict the combination of FEFaceValues and FESubfaceValues objects, they are both derived from the FEFaceValuesBase class and consequently we don't have to care: the function is simply called with two such objects denoting the values of the shape functions on the quadrature points of the two sides of the face. We then do what we always do: we fill the scratch arrays with the values of shape functions and their derivatives, and then loop over all entries of the matrix to compute the local integrals. The details of the bilinear form we evaluate here are given in the introduction.
//
[0.x.26253] 
[0.x.26254] 
[0.x.26255] 
[0.x.26256] 
[0.x.26257] 
[0.x.26258] 
[0.x.26259] 
[0.x.26260] 
[0.x.26261] 
[0.x.26262] 
[0.x.26263] 
[0.x.26264] 
[0.x.26265] 
[0.x.26266] 
//
[0.x.26267] 
[0.x.26268] 
[0.x.26269] 
//
[0.x.26270] 
[0.x.26271] 
[0.x.26272] 
[0.x.26273] 
[0.x.26274] 
//
[0.x.26275] 
[0.x.26276] 
[0.x.26277] 
[0.x.26278] 
[0.x.26279] 
[0.x.26280] 
[0.x.26281] 
[0.x.26282] 
[0.x.26283] 
[0.x.26284] 
//
[0.x.26285] 
[0.x.26286] 
[0.x.26287] 
[0.x.26288] 
[0.x.26289] 
[0.x.26290] 
[0.x.26291] 
[0.x.26292] 
[0.x.26293] 
//[2.x.3253] 
//
// As discussed in the introduction, we use a rather trivial solver here: we just pass the linear system off to the SparseDirectUMFPACK direct solver (see, for example,  [2.x.3254] ). The only thing we have to do after solving is ensure that hanging node and boundary value constraints are correct.
//
[0.x.26294] 
[0.x.26295] 
[0.x.26296] 
[0.x.26297] 
[0.x.26298] 
[0.x.26299] 
//
[0.x.26300] 
[0.x.26301] 
//
//  [2.x.3255] 
//
// Generating graphical output is rather trivial here: all we have to do is identify which components of the solution vector belong to scalars and/or vectors (see, for example,  [2.x.3256]  for a previous example), and then pass it all on to the DataOut class:
//
[0.x.26302] 
[0.x.26303] 
[0.x.26304] 
[0.x.26305] 
[0.x.26306] 
[0.x.26307] 
[0.x.26308] 
[0.x.26309] 
//
[0.x.26310] 
[0.x.26311] 
[0.x.26312] 
[0.x.26313] 
[0.x.26314] 
[0.x.26315] 
[0.x.26316] 
[0.x.26317] 
//
[0.x.26318] 
[0.x.26319] 
//
[0.x.26320] 
[0.x.26321] 
[0.x.26322] 
[0.x.26323] 
[0.x.26324] 
//
[0.x.26325] 
[0.x.26326] 
[0.x.26327] 
[0.x.26328] 
//[2.x.3257] 
//
// The next step is to refine the mesh. As was discussed in the introduction, this is a bit tricky primarily because the fluid and the solid subdomains use variables that have different physical dimensions and for which the absolute magnitude of error estimates is consequently not directly comparable. We will therefore have to scale them. At the top of the function, we therefore first compute error estimates for the different variables separately (using the velocities but not the pressure for the fluid domain, and the displacements in the solid domain):
//
[0.x.26329] 
[0.x.26330] 
[0.x.26331] 
[0.x.26332] 
[0.x.26333] 
[0.x.26334] 
[0.x.26335] 
//
[0.x.26336] 
[0.x.26337] 
//
[0.x.26338] 
[0.x.26339] 
[0.x.26340] 
//
[0.x.26341] 
[0.x.26342] 
[0.x.26343] 
[0.x.26344] 
[0.x.26345] 
[0.x.26346] 
[0.x.26347] 
[0.x.26348] 
//
[0.x.26349] 
[0.x.26350] 
[0.x.26351] 
[0.x.26352] 
[0.x.26353] 
[0.x.26354] 
[0.x.26355] 
[0.x.26356] 
//
// We then normalize error estimates by dividing by their norm and scale the fluid error indicators by a factor of 4 as discussed in the introduction. The results are then added together into a vector that contains error indicators for all cells:
//
[0.x.26357] 
[0.x.26358] 
[0.x.26359] 
[0.x.26360] 
//
[0.x.26361] 
//
[0.x.26362] 
[0.x.26363] 
//
// The second to last part of the function, before actually refining the mesh, involves a heuristic that we have already mentioned in the introduction: because the solution is discontinuous, the KellyErrorEstimator class gets all confused about cells that sit at the boundary between subdomains: it believes that the error is large there because the jump in the gradient is large, even though this is entirely expected and a feature that is in fact present in the exact solution as well and therefore not indicative of any numerical error.
//
// Consequently, we set the error indicators to zero for all cells at the interface; the conditions determining which cells this affects are slightly awkward because we have to account for the possibility of adaptively refined meshes, meaning that the neighboring cell can be coarser than the current one, or could in fact be refined some more. The structure of these nested conditions is much the same as we encountered when assembling interface terms in  [2.x.3258] .
//
[0.x.26364] 
[0.x.26365] 
[0.x.26366] 
[0.x.26367] 
[0.x.26368] 
[0.x.26369] 
[0.x.26370] 
[0.x.26371] 
[0.x.26372] 
[0.x.26373] 
[0.x.26374] 
[0.x.26375] 
[0.x.26376] 
[0.x.26377] 
[0.x.26378] 
[0.x.26379] 
[0.x.26380] 
[0.x.26381] 
[0.x.26382] 
[0.x.26383] 
[0.x.26384] 
[0.x.26385] 
[0.x.26386] 
[0.x.26387] 
[0.x.26388] 
[0.x.26389] 
[0.x.26390] 
[0.x.26391] 
[0.x.26392] 
[0.x.26393] 
//
[0.x.26394] 
[0.x.26395] 
[0.x.26396] 
[0.x.26397] 
[0.x.26398] 
[0.x.26399] 
//
//  [2.x.3259] 
//
// This is, as usual, the function that controls the overall flow of operation. If you've read through tutorial programs  [2.x.3260]  through  [2.x.3261] , for example, then you are already quite familiar with the following structure:
//
[0.x.26400] 
[0.x.26401] 
[0.x.26402] 
[0.x.26403] 
//
[0.x.26404] 
[0.x.26405] 
[0.x.26406] 
[0.x.26407] 
//
[0.x.26408] 
[0.x.26409] 
//
[0.x.26410] 
//
[0.x.26411] 
[0.x.26412] 
//
[0.x.26413] 
[0.x.26414] 
//
[0.x.26415] 
[0.x.26416] 
//
[0.x.26417] 
[0.x.26418] 
[0.x.26419] 
[0.x.26420] 
//
//  [2.x.3262] 
//
// This, final, function contains pretty much exactly what most of the other tutorial programs have:
//
[0.x.26421] 
[0.x.26422] 
[0.x.26423] 
[0.x.26424] 
[0.x.26425] 
//
[0.x.26426] 
[0.x.26427] 
[0.x.26428] 
[0.x.26429] 
[0.x.26430] 
[0.x.26431] 
[0.x.26432] 
[0.x.26433] 
[0.x.26434] 
[0.x.26435] 
[0.x.26436] 
[0.x.26437] 
[0.x.26438] 
[0.x.26439] 
//
[0.x.26440] 
[0.x.26441] 
[0.x.26442] 
[0.x.26443] 
[0.x.26444] 
[0.x.26445] 
[0.x.26446] 
[0.x.26447] 
[0.x.26448] 
[0.x.26449] 
[0.x.26450] 
[0.x.26451] 
[0.x.26452] 
[0.x.26453] 
//
[0.x.26454] 
[0.x.26455] 
[0.x.26456] 
[0.x.26457] 
[0.x.26458] 
[0.x.26459] 
[0.x.26460] 
[0.x.26461] 
[0.x.26462] 
[0.x.26463] 
[0.x.26464] 
[0.x.26465] 
[0.x.26466] 
[0.x.26467] 
[0.x.26468] 
[0.x.26469] 
//
[0.x.26470] 
[0.x.26471] 
[0.x.26472] 
[0.x.26473] 
[0.x.26474] 
[0.x.26475] 
[0.x.26476] 
//[2.x.3263] 
//
// The first few include files have already been used in the previous example, so we will not explain their meaning here again. The principal structure of the program is very similar to that of, for example,  [2.x.3264]  and so we include many of the same header files.
//
[0.x.26477] 
[0.x.26478] 
//
[0.x.26479] 
[0.x.26480] 
[0.x.26481] 
[0.x.26482] 
[0.x.26483] 
[0.x.26484] 
//
[0.x.26485] 
[0.x.26486] 
//
[0.x.26487] 
[0.x.26488] 
[0.x.26489] 
//
[0.x.26490] 
[0.x.26491] 
//
[0.x.26492] 
[0.x.26493] 
//
// The two most interesting header files will be these two:
//
[0.x.26494] 
[0.x.26495] 
//
// The first of these is responsible for providing the class FEInterfaceValues that can be used to evaluate quantities such as the jump or average of shape functions (or their gradients) across interfaces between cells. This class will be quite useful in evaluating the penalty terms that appear in the C0IP formulation.
//
[0.x.26496] 
[0.x.26497] 
[0.x.26498] 
//
[0.x.26499] 
[0.x.26500] 
[0.x.26501] 
//
// In the following namespace, let us define the exact solution against which we will compare the numerically computed one. It has the form  [2.x.3265]  (only the 2d case is implemented), and the namespace also contains a class that corresponds to the right hand side that produces this solution.
//
[0.x.26502] 
[0.x.26503] 
[0.x.26504] 
//
[0.x.26505] 
[0.x.26506] 
[0.x.26507] 
[0.x.26508] 
[0.x.26509] 
//
[0.x.26510] 
[0.x.26511] 
[0.x.26512] 
[0.x.26513] 
[0.x.26514] 
//
[0.x.26515] 
[0.x.26516] 
[0.x.26517] 
[0.x.26518] 
[0.x.26519] 
[0.x.26520] 
[0.x.26521] 
[0.x.26522] 
[0.x.26523] 
//
[0.x.26524] 
[0.x.26525] 
[0.x.26526] 
[0.x.26527] 
[0.x.26528] 
[0.x.26529] 
[0.x.26530] 
[0.x.26531] 
[0.x.26532] 
//
[0.x.26533] 
[0.x.26534] 
[0.x.26535] 
[0.x.26536] 
[0.x.26537] 
[0.x.26538] 
//
[0.x.26539] 
[0.x.26540] 
[0.x.26541] 
[0.x.26542] 
[0.x.26543] 
//
[0.x.26544] 
[0.x.26545] 
//
[0.x.26546] 
[0.x.26547] 
[0.x.26548] 
[0.x.26549] 
[0.x.26550] 
[0.x.26551] 
//
//  [2.x.3266] 
//
// The following is the principal class of this tutorial program. It has the structure of many of the other tutorial programs and there should really be nothing particularly surprising about its contents or the constructor that follows it.
//
[0.x.26552] 
[0.x.26553] 
[0.x.26554] 
[0.x.26555] 
[0.x.26556] 
//
[0.x.26557] 
//
[0.x.26558] 
[0.x.26559] 
[0.x.26560] 
[0.x.26561] 
[0.x.26562] 
[0.x.26563] 
[0.x.26564] 
//
[0.x.26565] 
//
[0.x.26566] 
//
[0.x.26567] 
[0.x.26568] 
[0.x.26569] 
//
[0.x.26570] 
[0.x.26571] 
//
[0.x.26572] 
[0.x.26573] 
[0.x.26574] 
//
[0.x.26575] 
[0.x.26576] 
[0.x.26577] 
[0.x.26578] 
[0.x.26579] 
[0.x.26580] 
//
// Next up are the functions that create the initial mesh (a once refined unit square) and set up the constraints, vectors, and matrices on each mesh. Again, both of these are essentially unchanged from many previous tutorial programs.
//
[0.x.26581] 
[0.x.26582] 
[0.x.26583] 
[0.x.26584] 
[0.x.26585] 
//
[0.x.26586] 
[0.x.26587] 
[0.x.26588] 
[0.x.26589] 
[0.x.26590] 
//
[0.x.26591] 
[0.x.26592] 
[0.x.26593] 
[0.x.26594] 
//
[0.x.26595] 
[0.x.26596] 
//
[0.x.26597] 
[0.x.26598] 
//
[0.x.26599] 
[0.x.26600] 
[0.x.26601] 
[0.x.26602] 
[0.x.26603] 
//
[0.x.26604] 
[0.x.26605] 
[0.x.26606] 
[0.x.26607] 
//
[0.x.26608] 
[0.x.26609] 
[0.x.26610] 
//
//  [2.x.3267] 
//
// The following pieces of code are more interesting. They all relate to the assembly of the linear system. While assembling the cell-interior terms is not of great difficulty -- that works in essence like the assembly of the corresponding terms of the Laplace equation, and you have seen how this works in  [2.x.3268]  or  [2.x.3269] , for example -- the difficulty is with the penalty terms in the formulation. These require the evaluation of gradients of shape functions at interfaces of cells. At the least, one would therefore need to use two FEFaceValues objects, but if one of the two sides is adaptively refined, then one actually needs an FEFaceValues and one FESubfaceValues objects; one also needs to keep track which shape functions live where, and finally we need to ensure that every face is visited only once. All of this is a substantial overhead to the logic we really want to implement (namely the penalty terms in the bilinear form). As a consequence, we will make use of the FEInterfaceValues class -- a helper class in deal.II that allows us to abstract away the two FEFaceValues or FESubfaceValues objects and directly access what we really care about: jumps, averages, etc.
//
// But this doesn't yet solve our problem of having to keep track of which faces we have already visited when we loop over all cells and all of their faces. To make this process simpler, we use the  [2.x.3270]  function that provides a simple interface for this task: Based on the ideas outlined in the WorkStream namespace documentation,  [2.x.3271]  requires three functions that do work on cells, interior faces, and boundary faces. These functions work on scratch objects for intermediate results, and then copy the result of their computations into copy data objects from where a copier function copies them into the global matrix and right hand side objects.
//
// The following structures then provide the scratch and copy objects that are necessary for this approach. You may look up the WorkStream namespace as well as the  [2.x.3272]  "Parallel computing with multiple processors" module for more information on how they typically work.
//
[0.x.26611] 
[0.x.26612] 
[0.x.26613] 
[0.x.26614] 
[0.x.26615] 
[0.x.26616] 
[0.x.26617] 
[0.x.26618] 
[0.x.26619] 
[0.x.26620] 
[0.x.26621] 
[0.x.26622] 
[0.x.26623] 
[0.x.26624] 
//
[0.x.26625] 
[0.x.26626] 
[0.x.26627] 
[0.x.26628] 
[0.x.26629] 
[0.x.26630] 
[0.x.26631] 
[0.x.26632] 
[0.x.26633] 
[0.x.26634] 
//
[0.x.26635] 
[0.x.26636] 
[0.x.26637] 
//
[0.x.26638] 
[0.x.26639] 
[0.x.26640] 
[0.x.26641] 
[0.x.26642] 
[0.x.26643] 
[0.x.26644] 
//
[0.x.26645] 
//
[0.x.26646] 
//
[0.x.26647] 
//
[0.x.26648] 
//
[0.x.26649] 
//
[0.x.26650] 
[0.x.26651] 
[0.x.26652] 
[0.x.26653] 
[0.x.26654] 
//
[0.x.26655] 
[0.x.26656] 
[0.x.26657] 
[0.x.26658] 
[0.x.26659] 
//
// The more interesting part is where we actually assemble the linear system. Fundamentally, this function has five parts:
//
// - The definition of the `cell_worker` lambda function, a small   function that is defined within the `assemble_system()`   function and that will be responsible for computing the local   integrals on an individual cell. It will work on a copy of the   `ScratchData` class and put its results into the corresponding   `CopyData` object.
//
// - The definition of the `face_worker` lambda function that does   the integration of all terms that live on the interfaces between   cells.
//
// - The definition of the `boundary_worker` function that does the   same but for cell faces located on the boundary of the domain.
//
// - The definition of the `copier` function that is responsible   for copying all of the data the previous three functions have   put into copy objects for a single cell, into the global matrix   and right hand side.
//
// The fifth part is the one where we bring all of this together.
//
// Let us go through each of these pieces necessary for the assembly in turns.
//
[0.x.26660] 
[0.x.26661] 
[0.x.26662] 
[0.x.26663] 
//
// The first piece is the `cell_worker` that does the assembly on the cell interiors. It is a (lambda) function that takes a cell (input), a scratch object, and a copy object (output) as arguments. It looks like the assembly functions of many other of the tutorial programs, or at least the body of the loop over all cells.
//
// The terms we integrate here are the cell contribution [1.x.104] to the global matrix, and [1.x.105] to the right hand side vector.
//
// We use the same technique as used in the assembly of  [2.x.3273]  to accelerate the function: Instead of calling `fe_values.shape_hessian(i, qpoint)` in the innermost loop, we create a variable `hessian_i` that evaluates this value once in the loop over `i` and re-use the so-evaluated value in the loop over `j`. For symmetry, we do the same with a variable `hessian_j`, although it is indeed only used once and we could have left the call to `fe_values.shape_hessian(j,qpoint)` in the instruction that computes the scalar product between the two terms.
//
[0.x.26664] 
[0.x.26665] 
[0.x.26666] 
[0.x.26667] 
[0.x.26668] 
//
[0.x.26669] 
[0.x.26670] 
//
[0.x.26671] 
//
[0.x.26672] 
//
[0.x.26673] 
[0.x.26674] 
//
[0.x.26675] 
[0.x.26676] 
[0.x.26677] 
[0.x.26678] 
[0.x.26679] 
[0.x.26680] 
[0.x.26681] 
//
[0.x.26682] 
[0.x.26683] 
[0.x.26684] 
[0.x.26685] 
//
[0.x.26686] 
[0.x.26687] 
[0.x.26688] 
[0.x.26689] 
[0.x.26690] 
//
[0.x.26691] 
[0.x.26692] 
[0.x.26693] 
[0.x.26694] 
[0.x.26695] 
[0.x.26696] 
[0.x.26697] 
[0.x.26698] 
//
// The next building block is the one that assembles penalty terms on each of the interior faces of the mesh. As described in the documentation of  [2.x.3274]  this function receives arguments that denote a cell and its neighboring cell, as well as (for each of the two cells) the face (and potentially sub-face) we have to integrate over. Again, we also get a scratch object, and a copy object for putting the results in.
//
// The function has three parts itself. At the top, we initialize the FEInterfaceValues object and create a new  [2.x.3275]  object to store our input in. This gets pushed to the end of the `copy_data.face_data` variable. We need to do this because the number of faces (or subfaces) over which we integrate for a given cell differs from cell to cell, and the sizes of these matrices also differ, depending on what degrees of freedom are adjacent to the face or subface. As discussed in the documentation of  [2.x.3276]  the copy object is reset every time a new cell is visited, so that what we push to the end of `copy_data.face_data()` is really all that the later `copier` function gets to see when it copies the contributions of each cell to the global matrix and right hand side objects.
//
[0.x.26699] 
[0.x.26700] 
[0.x.26701] 
[0.x.26702] 
[0.x.26703] 
[0.x.26704] 
[0.x.26705] 
[0.x.26706] 
[0.x.26707] 
[0.x.26708] 
[0.x.26709] 
//
[0.x.26710] 
[0.x.26711] 
//
[0.x.26712] 
[0.x.26713] 
//
[0.x.26714] 
[0.x.26715] 
[0.x.26716] 
//
// The second part deals with determining what the penalty parameter should be. By looking at the units of the various terms in the bilinear form, it is clear that the penalty has to have the form  [2.x.3277]  (i.e., one over length scale), but it is not a priori obvious how one should choose the dimension-less number  [2.x.3278] . From the discontinuous Galerkin theory for the Laplace equation, one might conjecture that the right choice is  [2.x.3279]  is the right choice, where  [2.x.3280]  is the polynomial degree of the finite element used. We will discuss this choice in a bit more detail in the results section of this program.
//
// In the formula above,  [2.x.3281]  is the size of cell  [2.x.3282] . But this is not quite so straightforward either: If one uses highly stretched cells, then a more involved theory says that  [2.x.3283]  should be replaced by the diameter of cell  [2.x.3284]  normal to the direction of the edge in question.  It turns out that there is a function in deal.II for that. Secondly,  [2.x.3285]  may be different when viewed from the two different sides of a face.
//
// To stay on the safe side, we take the maximum of the two values. We will note that it is possible that this computation has to be further adjusted if one were to use hanging nodes resulting from adaptive mesh refinement.
//
[0.x.26717] 
[0.x.26718] 
[0.x.26719] 
[0.x.26720] 
[0.x.26721] 
[0.x.26722] 
[0.x.26723] 
[0.x.26724] 
//
// Finally, and as usual, we loop over the quadrature points and indices `i` and `j` to add up the contributions of this face or sub-face. These are then stored in the `copy_data.face_data` object created above. As for the cell worker, we pull the evaluation of averages and jumps out of the loops if possible, introducing local variables that store these results. The assembly then only needs to use these local variables in the innermost loop. Regarding the concrete formula this code implements, recall that the interface terms of the bilinear form were as follows: [1.x.106]
//
[0.x.26725] 
[0.x.26726] 
[0.x.26727] 
[0.x.26728] 
[0.x.26729] 
//
[0.x.26730] 
[0.x.26731] 
[0.x.26732] 
[0.x.26733] 
[0.x.26734] 
[0.x.26735] 
//
[0.x.26736] 
[0.x.26737] 
[0.x.26738] 
[0.x.26739] 
[0.x.26740] 
[0.x.26741] 
//
[0.x.26742] 
[0.x.26743] 
[0.x.26744] 
[0.x.26745] 
[0.x.26746] 
[0.x.26747] 
[0.x.26748] 
[0.x.26749] 
[0.x.26750] 
[0.x.26751] 
[0.x.26752] 
[0.x.26753] 
[0.x.26754] 
[0.x.26755] 
//
// The third piece is to do the same kind of assembly for faces that are at the boundary. The idea is the same as above, of course, with only the difference that there are now penalty terms that also go into the right hand side.
//
// As before, the first part of the function simply sets up some helper objects:
//
[0.x.26756] 
[0.x.26757] 
[0.x.26758] 
[0.x.26759] 
[0.x.26760] 
[0.x.26761] 
[0.x.26762] 
[0.x.26763] 
//
[0.x.26764] 
[0.x.26765] 
//
[0.x.26766] 
[0.x.26767] 
[0.x.26768] 
[0.x.26769] 
//
[0.x.26770] 
//
[0.x.26771] 
[0.x.26772] 
[0.x.26773] 
//
[0.x.26774] 
[0.x.26775] 
[0.x.26776] 
//
// Positively, because we now only deal with one cell adjacent to the face (as we are on the boundary), the computation of the penalty factor  [2.x.3286]  is substantially simpler:
//
[0.x.26777] 
[0.x.26778] 
[0.x.26779] 
[0.x.26780] 
[0.x.26781] 
//
// The third piece is the assembly of terms. This is now slightly more involved since these contains both terms for the matrix and for the right hand side. The former is exactly the same as for the interior faces stated above if one just defines the jump and average appropriately (which is what the FEInterfaceValues class does). The latter requires us to evaluate the boundary conditions  [2.x.3287] , which in the current case (where we know the exact solution) we compute from  [2.x.3288] . The term to be added to the right hand side vector is then  [2.x.3289] .
//
[0.x.26782] 
[0.x.26783] 
[0.x.26784] 
//
[0.x.26785] 
[0.x.26786] 
[0.x.26787] 
[0.x.26788] 
[0.x.26789] 
[0.x.26790] 
//
[0.x.26791] 
[0.x.26792] 
[0.x.26793] 
[0.x.26794] 
[0.x.26795] 
[0.x.26796] 
//
[0.x.26797] 
[0.x.26798] 
[0.x.26799] 
//
//                                      
//
[0.x.26800] 
[0.x.26801] 
//
//                                      
//
[0.x.26802] 
[0.x.26803] 
[0.x.26804] 
[0.x.26805] 
[0.x.26806] 
[0.x.26807] 
//
[0.x.26808] 
[0.x.26809] 
[0.x.26810] 
[0.x.26811] 
[0.x.26812] 
[0.x.26813] 
[0.x.26814] 
[0.x.26815] 
[0.x.26816] 
[0.x.26817] 
[0.x.26818] 
[0.x.26819] 
//
// Part 4 is a small function that copies the data produced by the cell, interior, and boundary face assemblers above into the global matrix and right hand side vector. There really is not very much to do here: We distribute the cell matrix and right hand side contributions as we have done in almost all of the other tutorial programs using the constraints objects. We then also have to do the same for the face matrix contributions that have gained content for the faces (interior and boundary) and that the `face_worker` and `boundary_worker` have added to the `copy_data.face_data` array.
//
[0.x.26820] 
[0.x.26821] 
[0.x.26822] 
[0.x.26823] 
[0.x.26824] 
[0.x.26825] 
//
[0.x.26826] 
[0.x.26827] 
[0.x.26828] 
[0.x.26829] 
[0.x.26830] 
[0.x.26831] 
[0.x.26832] 
//
// Having set all of this up, what remains is to just create a scratch and copy data object and call the  [2.x.3290]  function that then goes over all cells and faces, calls the respective workers on them, and then the copier function that puts things into the global matrix and right hand side. As an additional benefit,  [2.x.3291]  does all of this in parallel, using as many processor cores as your machine happens to have.
//
[0.x.26833] 
[0.x.26834] 
[0.x.26835] 
[0.x.26836] 
[0.x.26837] 
[0.x.26838] 
[0.x.26839] 
[0.x.26840] 
[0.x.26841] 
[0.x.26842] 
[0.x.26843] 
[0.x.26844] 
[0.x.26845] 
[0.x.26846] 
[0.x.26847] 
[0.x.26848] 
[0.x.26849] 
[0.x.26850] 
[0.x.26851] 
[0.x.26852] 
[0.x.26853] 
[0.x.26854] 
[0.x.26855] 
//
//  [2.x.3292] 
//
// The show is essentially over at this point: The remaining functions are not overly interesting or novel. The first one simply uses a direct solver to solve the linear system (see also  [2.x.3293] ):
//
[0.x.26856] 
[0.x.26857] 
[0.x.26858] 
[0.x.26859] 
//
[0.x.26860] 
[0.x.26861] 
[0.x.26862] 
//
[0.x.26863] 
[0.x.26864] 
//
// The next function evaluates the error between the computed solution and the exact solution (which is known here because we have chosen the right hand side and boundary values in a way so that we know the corresponding solution). In the first two code blocks below, we compute the error in the  [2.x.3294]  norm and the  [2.x.3295]  semi-norm.
//
[0.x.26865] 
[0.x.26866] 
[0.x.26867] 
[0.x.26868] 
[0.x.26869] 
[0.x.26870] 
[0.x.26871] 
[0.x.26872] 
[0.x.26873] 
[0.x.26874] 
[0.x.26875] 
[0.x.26876] 
[0.x.26877] 
[0.x.26878] 
[0.x.26879] 
[0.x.26880] 
[0.x.26881] 
[0.x.26882] 
[0.x.26883] 
//
[0.x.26884] 
[0.x.26885] 
[0.x.26886] 
[0.x.26887] 
[0.x.26888] 
[0.x.26889] 
[0.x.26890] 
[0.x.26891] 
[0.x.26892] 
[0.x.26893] 
[0.x.26894] 
[0.x.26895] 
[0.x.26896] 
[0.x.26897] 
[0.x.26898] 
[0.x.26899] 
//
// Now also compute an approximation to the  [2.x.3296]  seminorm error. The actual  [2.x.3297]  seminorm would require us to integrate second derivatives of the solution  [2.x.3298] , but given the Lagrange shape functions we use,  [2.x.3299]  of course has kinks at the interfaces between cells, and consequently second derivatives are singular at interfaces. As a consequence, we really only integrate over the interior of cells and ignore the interface contributions. This is *not* an equivalent norm to the energy norm for the problem, but still gives us an idea of how fast the error converges.
//
// We note that one could address this issue by defining a norm that is equivalent to the energy norm. This would involve adding up not only the integrals over cell interiors as we do below, but also adding penalty terms for the jump of the derivative of  [2.x.3300]  across interfaces, with an appropriate scaling of the two kinds of terms. We will leave this for later work.
//
[0.x.26900] 
[0.x.26901] 
[0.x.26902] 
[0.x.26903] 
//
[0.x.26904] 
[0.x.26905] 
[0.x.26906] 
[0.x.26907] 
[0.x.26908] 
//
[0.x.26909] 
[0.x.26910] 
//
[0.x.26911] 
[0.x.26912] 
[0.x.26913] 
[0.x.26914] 
[0.x.26915] 
[0.x.26916] 
[0.x.26917] 
[0.x.26918] 
//
[0.x.26919] 
[0.x.26920] 
[0.x.26921] 
[0.x.26922] 
[0.x.26923] 
[0.x.26924] 
[0.x.26925] 
[0.x.26926] 
[0.x.26927] 
//
[0.x.26928] 
[0.x.26929] 
[0.x.26930] 
[0.x.26931] 
[0.x.26932] 
//
// Equally uninteresting is the function that generates graphical output. It looks exactly like the one in  [2.x.3301] , for example.
//
[0.x.26933] 
[0.x.26934] 
[0.x.26935] 
[0.x.26936] 
[0.x.26937] 
//
[0.x.26938] 
//
[0.x.26939] 
[0.x.26940] 
[0.x.26941] 
//
[0.x.26942] 
[0.x.26943] 
[0.x.26944] 
[0.x.26945] 
[0.x.26946] 
//
// The same is true for the `run()` function: Just like in previous programs.
//
[0.x.26947] 
[0.x.26948] 
[0.x.26949] 
[0.x.26950] 
//
[0.x.26951] 
[0.x.26952] 
[0.x.26953] 
[0.x.26954] 
//
[0.x.26955] 
[0.x.26956] 
//
[0.x.26957] 
[0.x.26958] 
//
[0.x.26959] 
//
[0.x.26960] 
[0.x.26961] 
[0.x.26962] 
[0.x.26963] 
[0.x.26964] 
//
//  [2.x.3302] 
//
// Finally for the `main()` function. There is, again, not very much to see here: It looks like the ones in previous tutorial programs. There is a variable that allows selecting the polynomial degree of the element we want to use for solving the equation. Because the C0IP formulation we use requires the element degree to be at least two, we check with an assertion that whatever one sets for the polynomial degree actually makes sense.
//
[0.x.26965] 
[0.x.26966] 
[0.x.26967] 
[0.x.26968] 
[0.x.26969] 
[0.x.26970] 
//
[0.x.26971] 
[0.x.26972] 
[0.x.26973] 
[0.x.26974] 
[0.x.26975] 
//
[0.x.26976] 
[0.x.26977] 
[0.x.26978] 
[0.x.26979] 
[0.x.26980] 
[0.x.26981] 
[0.x.26982] 
[0.x.26983] 
[0.x.26984] 
[0.x.26985] 
[0.x.26986] 
[0.x.26987] 
[0.x.26988] 
[0.x.26989] 
//
[0.x.26990] 
[0.x.26991] 
[0.x.26992] 
[0.x.26993] 
[0.x.26994] 
[0.x.26995] 
[0.x.26996] 
[0.x.26997] 
[0.x.26998] 
[0.x.26999] 
[0.x.27000] 
[0.x.27001] 
[0.x.27002] 
[0.x.27003] 
//
[0.x.27004] 
[0.x.27005] 
[0.x.27006] 
[0.x.27007] 
[0.x.27008] 
[0.x.27009] 
[0.x.27010] 
[0.x.27011] 
[0.x.27012] 
[0.x.27013] 
[0.x.27014] 
[0.x.27015] 
[0.x.27016] 
[0.x.27017] 
[0.x.27018] 
[0.x.27019] 
//
[0.x.27020] 
[0.x.27021] 
[0.x.27022] 
//
// The necessary files from the deal.II library.
//
[0.x.27023] 
[0.x.27024] 
[0.x.27025] 
[0.x.27026] 
[0.x.27027] 
[0.x.27028] 
[0.x.27029] 
[0.x.27030] 
[0.x.27031] 
[0.x.27032] 
[0.x.27033] 
[0.x.27034] 
[0.x.27035] 
[0.x.27036] 
[0.x.27037] 
[0.x.27038] 
//
// This includes the data structures for the efficient implementation of matrix-free methods.
//
[0.x.27039] 
[0.x.27040] 
[0.x.27041] 
//
[0.x.27042] 
[0.x.27043] 
[0.x.27044] 
//
[0.x.27045] 
[0.x.27046] 
[0.x.27047] 
//
// We start by defining two global variables to collect all parameters subject to changes at one place: One for the dimension and one for the finite element degree. The dimension is used in the main function as a template argument for the actual classes (like in all other deal.II programs), whereas the degree of the finite element is more crucial, as it is passed as a template argument to the implementation of the Sine-Gordon operator. Therefore, it needs to be a compile-time constant.
//
[0.x.27048] 
[0.x.27049] 
//[2.x.3303] 
//
// The  [2.x.3304]  class implements the cell-based operation that is needed in each time step. This nonlinear operation can be implemented straight-forwardly based on the  [2.x.3305]  class, in the same way as a linear operation would be treated by this implementation of the finite element operator application. We apply two template arguments to the class, one for the dimension and one for the degree of the finite element. This is a difference to other functions in deal.II where only the dimension is a template argument. This is necessary to provide the inner loops in  [2.x.3306]  with information about loop lengths etc., which is essential for efficiency. On the other hand, it makes it more challenging to implement the degree as a run-time parameter.
//
[0.x.27050] 
[0.x.27051] 
[0.x.27052] 
[0.x.27053] 
[0.x.27054] 
[0.x.27055] 
//
[0.x.27056] 
[0.x.27057] 
[0.x.27058] 
//
[0.x.27059] 
[0.x.27060] 
[0.x.27061] 
[0.x.27062] 
//
[0.x.27063] 
[0.x.27064] 
[0.x.27065] 
[0.x.27066] 
[0.x.27067] 
[0.x.27068] 
//
//  [2.x.3307] 
//
// This is the constructor of the SineGordonOperation class. It receives a reference to the MatrixFree holding the problem information and the time step size as input parameters. The initialization routine sets up the mass matrix. Since we use Gauss-Lobatto elements, the mass matrix is a diagonal matrix and can be stored as a vector. The computation of the mass matrix diagonal is simple to achieve with the data structures provided by FEEvaluation: Just loop over all cell batches, i.e., collections of cells due to SIMD vectorization, and integrate over the function that is constant one on all quadrature points by using the  [2.x.3308]  function with  [2.x.3309]  argument at the slot for values. Finally, we invert the diagonal entries to have the inverse mass matrix directly available in each time step.
//
[0.x.27069] 
[0.x.27070] 
[0.x.27071] 
[0.x.27072] 
[0.x.27073] 
[0.x.27074] 
[0.x.27075] 
[0.x.27076] 
//
[0.x.27077] 
[0.x.27078] 
//
[0.x.27079] 
[0.x.27080] 
[0.x.27081] 
[0.x.27082] 
[0.x.27083] 
[0.x.27084] 
[0.x.27085] 
[0.x.27086] 
//
[0.x.27087] 
[0.x.27088] 
[0.x.27089] 
[0.x.27090] 
[0.x.27091] 
[0.x.27092] 
[0.x.27093] 
[0.x.27094] 
//
//  [2.x.3310] 
//
// This operator implements the core operation of the program, the integration over a range of cells for the nonlinear operator of the Sine-Gordon problem. The implementation is based on the FEEvaluation class as in  [2.x.3311] . Due to the special structure in Gauss-Lobatto elements, certain operations become simpler, in particular the evaluation of shape function values on quadrature points which is simply the injection of the values of cell degrees of freedom. The MatrixFree class detects possible structure of the finite element at quadrature points when initializing, which is then automatically used by FEEvaluation for selecting the most appropriate numerical kernel.
//
// The nonlinear function that we have to evaluate for the time stepping routine includes the value of the function at the present time  [2.x.3312]  as well as the value at the previous time step  [2.x.3313]  Both values are passed to the operator in the collection of source vectors  [2.x.3314]  which is simply a  [2.x.3315]  of pointers to the actual solution vectors. This construct of collecting several source vectors into one is necessary as the cell loop in  [2.x.3316]  takes exactly one source and one destination vector, even if we happen to use many vectors like the two in this case. Note that the cell loop accepts any valid class for input and output, which does not only include vectors but general data types.  However, only in case it encounters a  [2.x.3317]  or a  [2.x.3318]  collecting these vectors, it calls functions that exchange ghost data due to MPI at the beginning and the end of the loop. In the loop over the cells, we first have to read in the values in the vectors related to the local values.  Then, we evaluate the value and the gradient of the current solution vector and the values of the old vector at the quadrature points. Next, we combine the terms in the scheme in the loop over the quadrature points. Finally, we integrate the result against the test function and accumulate the result to the global solution vector  [2.x.3319]  dst.
//
[0.x.27095] 
[0.x.27096] 
[0.x.27097] 
[0.x.27098] 
[0.x.27099] 
[0.x.27100] 
[0.x.27101] 
[0.x.27102] 
[0.x.27103] 
[0.x.27104] 
[0.x.27105] 
[0.x.27106] 
[0.x.27107] 
//
[0.x.27108] 
[0.x.27109] 
//
[0.x.27110] 
[0.x.27111] 
//
[0.x.27112] 
[0.x.27113] 
[0.x.27114] 
[0.x.27115] 
//
[0.x.27116] 
[0.x.27117] 
[0.x.27118] 
[0.x.27119] 
[0.x.27120] 
//
[0.x.27121] 
[0.x.27122] 
[0.x.27123] 
[0.x.27124] 
//
// [2.x.3320] 
//
// This function performs the time stepping routine based on the cell-local strategy. Note that we need to set the destination vector to zero before we add the integral contributions of the current time step (via the  [2.x.3321]  call). In this tutorial, we let the cell-loop do the zero operation via the fifth `true` argument passed to  [2.x.3322]  The loop can schedule the zero operation closer to the operations on vector entries for supported vector entries, thereby possibly increasing data locality (the vector entries that first get zeroed are later re-used in the `distribute_local_to_global()` call). The structure of the cell loop is implemented in the cell finite element operator class. On each cell it applies the routine defined as the  [2.x.3323]  method of the class  [2.x.3324] . One could also provide a function with the same signature that is not part of a class. Finally, the result of the integration is multiplied by the inverse mass matrix.
//
[0.x.27125] 
[0.x.27126] 
[0.x.27127] 
[0.x.27128] 
[0.x.27129] 
[0.x.27130] 
[0.x.27131] 
[0.x.27132] 
[0.x.27133] 
//
// [2.x.3325] 
//
// We define a time-dependent function that is used as initial value. Different solutions can be obtained by varying the starting time. This function, taken from  [2.x.3326] , would represent an analytic solution in 1D for all times, but is merely used for setting some starting solution of interest here. More elaborate choices that could test the convergence of this program are given in  [2.x.3327] .
//
[0.x.27134] 
[0.x.27135] 
[0.x.27136] 
[0.x.27137] 
[0.x.27138] 
[0.x.27139] 
[0.x.27140] 
[0.x.27141] 
[0.x.27142] 
[0.x.27143] 
[0.x.27144] 
[0.x.27145] 
//
[0.x.27146] 
[0.x.27147] 
[0.x.27148] 
[0.x.27149] 
[0.x.27150] 
[0.x.27151] 
[0.x.27152] 
[0.x.27153] 
[0.x.27154] 
[0.x.27155] 
[0.x.27156] 
//
//  [2.x.3328] 
//
// This is the main class that builds on the class in  [2.x.3329] .  However, we replaced the SparseMatrix<double> class by the MatrixFree class to store the geometry data. Also, we use a distributed triangulation in this example.
//
[0.x.27157] 
[0.x.27158] 
[0.x.27159] 
[0.x.27160] 
[0.x.27161] 
[0.x.27162] 
//
[0.x.27163] 
[0.x.27164] 
//
[0.x.27165] 
[0.x.27166] 
//
[0.x.27167] 
[0.x.27168] 
[0.x.27169] 
[0.x.27170] 
[0.x.27171] 
[0.x.27172] 
[0.x.27173] 
//
[0.x.27174] 
//
[0.x.27175] 
[0.x.27176] 
//
[0.x.27177] 
//
[0.x.27178] 
[0.x.27179] 
//
[0.x.27180] 
[0.x.27181] 
[0.x.27182] 
[0.x.27183] 
[0.x.27184] 
[0.x.27185] 
//[2.x.3330] 
//
// This is the constructor of the SineGordonProblem class. The time interval and time step size are defined here. Moreover, we use the degree of the finite element that we defined at the top of the program to initialize a FE_Q finite element based on Gauss-Lobatto support points. These points are convenient because in conjunction with a QGaussLobatto quadrature rule of the same order they give a diagonal mass matrix without compromising accuracy too much (note that the integration is inexact, though), see also the discussion in the introduction. Note that FE_Q selects the Gauss-Lobatto nodal points by default due to their improved conditioning versus equidistant points. To make things more explicit, we state the selection of the nodal points nonetheless.
//
[0.x.27186] 
[0.x.27187] 
[0.x.27188] 
[0.x.27189] 
[0.x.27190] 
[0.x.27191] 
[0.x.27192] 
[0.x.27193] 
[0.x.27194] 
[0.x.27195] 
[0.x.27196] 
[0.x.27197] 
[0.x.27198] 
[0.x.27199] 
[0.x.27200] 
[0.x.27201] 
[0.x.27202] 
//[2.x.3331] 
//
// As in  [2.x.3332]  this functions sets up a cube grid in  [2.x.3333]  dimensions of extent  [2.x.3334] . We refine the mesh more in the center of the domain since the solution is concentrated there. We first refine all cells whose center is within a radius of 11, and then refine once more for a radius 6.  This simple ad hoc refinement could be done better by adapting the mesh to the solution using error estimators during the time stepping as done in other example programs, and using  [2.x.3335]  to transfer the solution to the new mesh.
//
[0.x.27203] 
[0.x.27204] 
[0.x.27205] 
[0.x.27206] 
[0.x.27207] 
[0.x.27208] 
[0.x.27209] 
[0.x.27210] 
[0.x.27211] 
[0.x.27212] 
[0.x.27213] 
[0.x.27214] 
[0.x.27215] 
[0.x.27216] 
//
[0.x.27217] 
[0.x.27218] 
[0.x.27219] 
[0.x.27220] 
[0.x.27221] 
[0.x.27222] 
[0.x.27223] 
[0.x.27224] 
//
[0.x.27225] 
[0.x.27226] 
[0.x.27227] 
[0.x.27228] 
[0.x.27229] 
[0.x.27230] 
[0.x.27231] 
//
[0.x.27232] 
//
[0.x.27233] 
[0.x.27234] 
//
// We generate hanging node constraints for ensuring continuity of the solution. As in  [2.x.3336] , we need to equip the constraint matrix with the IndexSet of locally relevant degrees of freedom to avoid it to consume too much memory for big problems. Next, the <code> MatrixFree </code> object for the problem is set up. Note that we specify a particular scheme for shared-memory parallelization (hence one would use multithreading for intra-node parallelism and not MPI; we here choose the standard option &mdash; if we wanted to disable shared memory parallelization even in case where there is more than one TBB thread available in the program, we would choose  [2.x.3337]  Also note that, instead of using the default QGauss quadrature argument, we supply a QGaussLobatto quadrature formula to enable the desired behavior. Finally, three solution vectors are initialized. MatrixFree expects a particular layout of ghost indices (as it handles index access in MPI-local numbers that need to match between the vector and MatrixFree), so we just ask it to initialize the vectors to be sure the ghost exchange is properly handled.
//
[0.x.27235] 
[0.x.27236] 
[0.x.27237] 
[0.x.27238] 
[0.x.27239] 
//
[0.x.27240] 
[0.x.27241] 
[0.x.27242] 
//
[0.x.27243] 
[0.x.27244] 
[0.x.27245] 
[0.x.27246] 
[0.x.27247] 
//
[0.x.27248] 
[0.x.27249] 
[0.x.27250] 
[0.x.27251] 
//
// [2.x.3338] 
//
// This function prints the norm of the solution and writes the solution vector to a file. The norm is standard (except for the fact that we need to accumulate the norms over all processors for the parallel grid which we do via the  [2.x.3339]  function), and the second is similar to what we did in  [2.x.3340]  or  [2.x.3341] . Note that we can use the same vector for output as the one used during computations: The vectors in the matrix-free framework always provide full information on all locally owned cells (this is what is needed in the local evaluations, too), including ghost vector entries on these cells. This is the only data that is needed in the  [2.x.3342]  function as well as in DataOut. The only action to take at this point is to make sure that the vector updates its ghost values before we read from them, and to reset ghost values once done. This is a feature present only in the  [2.x.3343]  class. Distributed vectors with PETSc and Trilinos, on the other hand, need to be copied to special vectors including ghost values (see the relevant section in  [2.x.3344] ). If we also wanted to access all degrees of freedom on ghost cells (e.g. when computing error estimators that use the jump of solution over cell boundaries), we would need more information and create a vector initialized with locally relevant dofs just as in  [2.x.3345] . Observe also that we need to distribute constraints for output
//
// - they are not filled during computations (rather, they are interpolated on the fly in the matrix-free method  [2.x.3346] 
[0.x.27252] 
[0.x.27253] 
[0.x.27254] 
[0.x.27255] 
[0.x.27256] 
//
[0.x.27257] 
[0.x.27258] 
[0.x.27259] 
[0.x.27260] 
[0.x.27261] 
[0.x.27262] 
[0.x.27263] 
[0.x.27264] 
[0.x.27265] 
[0.x.27266] 
[0.x.27267] 
[0.x.27268] 
[0.x.27269] 
//
[0.x.27270] 
[0.x.27271] 
[0.x.27272] 
//
[0.x.27273] 
//
[0.x.27274] 
[0.x.27275] 
[0.x.27276] 
//
[0.x.27277] 
[0.x.27278] 
//
[0.x.27279] 
[0.x.27280] 
//[2.x.3347] 
//
// This function is called by the main function and steps into the subroutines of the class.
//
// After printing some information about the parallel setup, the first action is to set up the grid and the cell operator. Then, the time step is computed from the CFL number given in the constructor and the finest mesh size. The finest mesh size is computed as the diameter of the last cell in the triangulation, which is the last cell on the finest level of the mesh. This is only possible for meshes where all elements on a level have the same size, otherwise, one needs to loop over all cells. Note that we need to query all the processors for their finest cell since not all processors might hold a region where the mesh is at the finest level. Then, we readjust the time step a little to hit the final time exactly.
//
[0.x.27281] 
[0.x.27282] 
[0.x.27283] 
[0.x.27284] 
[0.x.27285] 
[0.x.27286] 
[0.x.27287] 
[0.x.27288] 
[0.x.27289] 
[0.x.27290] 
[0.x.27291] 
[0.x.27292] 
[0.x.27293] 
[0.x.27294] 
[0.x.27295] 
[0.x.27296] 
[0.x.27297] 
//
[0.x.27298] 
[0.x.27299] 
[0.x.27300] 
[0.x.27301] 
[0.x.27302] 
[0.x.27303] 
[0.x.27304] 
[0.x.27305] 
[0.x.27306] 
//
// Next the initial value is set. Since we have a two-step time stepping method, we also need a value of the solution at time-time_step. For accurate results, one would need to compute this from the time derivative of the solution at initial time, but here we ignore this difficulty and just set it to the initial value function at that artificial time.
//
// We then go on by writing the initial state to file and collecting the two starting solutions in a  [2.x.3348]  of pointers that get later consumed by the  [2.x.3349]  function. Next, an instance of the  [2.x.3350]  based on the finite element degree specified at the top of this file is set up.
//
[0.x.27307] 
[0.x.27308] 
[0.x.27309] 
[0.x.27310] 
[0.x.27311] 
[0.x.27312] 
[0.x.27313] 
[0.x.27314] 
[0.x.27315] 
//
[0.x.27316] 
[0.x.27317] 
//
[0.x.27318] 
[0.x.27319] 
//
// Now loop over the time steps. In each iteration, we shift the solution vectors by one and call the `apply` function of the `SineGordonOperator` class. Then, we write the solution to a file. We clock the wall times for the computational time needed as wall as the time needed to create the output and report the numbers when the time stepping is finished.
//
// Note how this shift is implemented: We simply call the swap method on the two vectors which swaps only some pointers without the need to copy data around, a relatively expensive operation within an explicit time stepping method. Let us see what happens in more detail: First, we exchange  [2.x.3351] , which means that  [2.x.3352]  gets  [2.x.3353] , which is what we expect. Similarly,  [2.x.3354]  in the next step. After this,  [2.x.3355]  holds  [2.x.3356] , but that will be overwritten during this step.
//
[0.x.27320] 
//
[0.x.27321] 
[0.x.27322] 
[0.x.27323] 
[0.x.27324] 
[0.x.27325] 
[0.x.27326] 
[0.x.27327] 
[0.x.27328] 
[0.x.27329] 
[0.x.27330] 
[0.x.27331] 
//
[0.x.27332] 
[0.x.27333] 
[0.x.27334] 
//
[0.x.27335] 
[0.x.27336] 
[0.x.27337] 
[0.x.27338] 
[0.x.27339] 
//
[0.x.27340] 
[0.x.27341] 
//
[0.x.27342] 
[0.x.27343] 
//
[0.x.27344] 
[0.x.27345] 
[0.x.27346] 
[0.x.27347] 
//
//  [2.x.3357] 
//
// As in  [2.x.3358] , we initialize MPI at the start of the program. Since we will in general mix MPI parallelization with threads, we also set the third argument in MPI_InitFinalize that controls the number of threads to an invalid number, which means that the TBB library chooses the number of threads automatically, typically to the number of available cores in the system. As an alternative, you can also set this number manually if you want to set a specific number of threads (e.g. when MPI-only is required).
//
[0.x.27348] 
[0.x.27349] 
[0.x.27350] 
[0.x.27351] 
//
[0.x.27352] 
[0.x.27353] 
//
[0.x.27354] 
[0.x.27355] 
[0.x.27356] 
[0.x.27357] 
[0.x.27358] 
[0.x.27359] 
[0.x.27360] 
[0.x.27361] 
[0.x.27362] 
[0.x.27363] 
[0.x.27364] 
[0.x.27365] 
[0.x.27366] 
[0.x.27367] 
[0.x.27368] 
[0.x.27369] 
//
[0.x.27370] 
[0.x.27371] 
[0.x.27372] 
[0.x.27373] 
[0.x.27374] 
[0.x.27375] 
[0.x.27376] 
[0.x.27377] 
[0.x.27378] 
[0.x.27379] 
[0.x.27380] 
[0.x.27381] 
[0.x.27382] 
[0.x.27383] 
//
[0.x.27384] 
[0.x.27385] 
[0.x.27386] 
[0.x.27387] 
[0.x.27388] 
[0.x.27389] 
[0.x.27390] 
[0.x.27391] 
[0.x.27392] 
[0.x.27393] 
[0.x.27394] 
[0.x.27395] 
[0.x.27396] 
[0.x.27397] 
[0.x.27398] 
[0.x.27399] 
//
[0.x.27400] 
[0.x.27401] 
[0.x.27402] 
//
// This tutorial program is odd in the sense that, unlike for most other steps, the introduction already provides most of the information on how to use the various strategies to generate meshes. Consequently, there is little that remains to be commented on here, and we intersperse the code with relatively little text. In essence, the code here simply provides a reference implementation of what has already been described in the introduction.
//
//  [2.x.3359] 
[0.x.27403] 
[0.x.27404] 
[0.x.27405] 
[0.x.27406] 
[0.x.27407] 
[0.x.27408] 
//
[0.x.27409] 
[0.x.27410] 
//
[0.x.27411] 
//
[0.x.27412] 
//[2.x.3360] 
//
// The following function generates some output for any of the meshes we will be generating in the remainder of this program. In particular, it generates the following information:
//
//
//
// - Some general information about the number of space dimensions in which   this mesh lives and its number of cells.
//
// - The number of boundary faces that use each boundary indicator, so that   it can be compared with what we expect.
//
// Finally, the function outputs the mesh in VTU format that can easily be visualized in Paraview or VisIt.
//
[0.x.27413] 
[0.x.27414] 
[0.x.27415] 
[0.x.27416] 
[0.x.27417] 
[0.x.27418] 
[0.x.27419] 
//
// Next loop over all faces of all cells and find how often each boundary indicator is used (recall that if you access an element of a  [2.x.3361]  object that doesn't exist, it is implicitly created and default initialized -- to zero, in the current case -- before we then increment it):
//
[0.x.27420] 
[0.x.27421] 
[0.x.27422] 
[0.x.27423] 
[0.x.27424] 
//
[0.x.27425] 
[0.x.27426] 
[0.x.27427] 
[0.x.27428] 
[0.x.27429] 
[0.x.27430] 
[0.x.27431] 
[0.x.27432] 
//
// Finally, produce a graphical representation of the mesh to an output file:
//
[0.x.27433] 
[0.x.27434] 
[0.x.27435] 
[0.x.27436] 
[0.x.27437] 
//[2.x.3362] 
//[2.x.3363] 
//
// In this first example, we show how to load the mesh for which we have discussed in the introduction how to generate it. This follows the same pattern as used in  [2.x.3364]  to load a mesh, although there it was written in a different file format (UCD instead of MSH).
//
[0.x.27438] 
[0.x.27439] 
[0.x.27440] 
//
[0.x.27441] 
[0.x.27442] 
[0.x.27443] 
[0.x.27444] 
//
[0.x.27445] 
[0.x.27446] 
//[2.x.3365] 
//
// Here, we first create two triangulations and then merge them into one.  As discussed in the introduction, it is important to ensure that the vertices at the common interface are located at the same coordinates.
//
[0.x.27447] 
[0.x.27448] 
[0.x.27449] 
[0.x.27450] 
//
[0.x.27451] 
[0.x.27452] 
[0.x.27453] 
[0.x.27454] 
[0.x.27455] 
[0.x.27456] 
[0.x.27457] 
[0.x.27458] 
//
[0.x.27459] 
[0.x.27460] 
//
[0.x.27461] 
[0.x.27462] 
//[2.x.3366] 
//
// In this function, we move vertices of a mesh. This is simpler than one usually expects: if you ask a cell using  [2.x.3367]  for the coordinates of its  [2.x.3368] th vertex, it doesn't just provide the location of this vertex but in fact a reference to the location where these coordinates are stored. We can then modify the value stored there.
//
// So this is what we do in the first part of this function: We create a square of geometry  [2.x.3369]  with a circular hole with radius 0.25 located at the origin. We then loop over all cells and all vertices and if a vertex has a  [2.x.3370]  coordinate equal to one, we move it upward by 0.5.
//
// Note that this sort of procedure does not usually work this way because one will typically encounter the same vertices multiple times and may move them more than once. It works here because we select the vertices we want to use based on their geometric location, and a vertex moved once will fail this test in the future. A more general approach to this problem would have been to keep a  [2.x.3371]  of those vertex indices that we have already moved (which we can obtain using  [2.x.3372]  and only move those vertices whose index isn't in the set yet.
//
[0.x.27463] 
[0.x.27464] 
[0.x.27465] 
[0.x.27466] 
//
[0.x.27467] 
[0.x.27468] 
[0.x.27469] 
[0.x.27470] 
[0.x.27471] 
[0.x.27472] 
[0.x.27473] 
[0.x.27474] 
[0.x.27475] 
//
// In the second step we will refine the mesh twice. To do this correctly, we should place new points on the interior boundary along the surface of a circle centered at the origin. Fortunately,  [2.x.3373]  already attaches a Manifold object to the interior boundary, so we do not need to do anything but refine the mesh (see the [1.x.107] for a fully worked example where we  [2.x.3374] do [2.x.3375]  attach a Manifold object).
//
[0.x.27476] 
[0.x.27477] 
[0.x.27478] 
//
// There is one snag to doing things as shown above: If one moves the nodes on the boundary as shown here, one often ends up with cells in the interior that are badly distorted since the interior nodes were not moved around. This is not that much of a problem in the current case since the mesh did not contain any internal nodes when the nodes were moved -- it was the coarse mesh and it so happened that all vertices are at the boundary. It's also the case that the movement we had here was, compared to the average cell size not overly dramatic. Nevertheless, sometimes one does want to move vertices by a significant distance, and in that case one needs to move internal nodes as well. One way to do that automatically is to call the function  [2.x.3376]  that takes a set of transformed vertex coordinates and moves all of the other vertices in such a way that the resulting mesh has, in some sense, a small distortion.
//
//  [2.x.3377] 
//
// This example takes the initial grid from the previous function and simply extrudes it into the third space dimension:
//
[0.x.27479] 
[0.x.27480] 
[0.x.27481] 
[0.x.27482] 
[0.x.27483] 
//
[0.x.27484] 
[0.x.27485] 
[0.x.27486] 
//[2.x.3378] 
//
// This and the next example first create a mesh and then transform it by moving every node of the mesh according to a function that takes a point and returns a mapped point. In this case, we transform  [2.x.3379] .
//
//  [2.x.3380]  takes a triangulation and an argument that can be called like a function taking a Point and returning a Point. There are different ways of providing such an argument: It could be a pointer to a function; it could be an object of a class that has an `operator()`; it could be a lambda function; or it could be anything that is described via a  [2.x.3381]  object.
//
// Decidedly the more modern way is to use a lambda function that takes a Point and returns a Point, and that is what we do in the following:
//
[0.x.27487] 
[0.x.27488] 
[0.x.27489] 
[0.x.27490] 
[0.x.27491] 
[0.x.27492] 
[0.x.27493] 
[0.x.27494] 
[0.x.27495] 
[0.x.27496] 
//
[0.x.27497] 
[0.x.27498] 
[0.x.27499] 
[0.x.27500] 
[0.x.27501] 
[0.x.27502] 
[0.x.27503] 
//
//  [2.x.3382] 
//
// In this second example of transforming points from an original to a new mesh, we will use the mapping  [2.x.3383] . To make things more interesting, rather than doing so in a single function as in the previous example, we here create an object with an  [2.x.3384]  that will be called by  [2.x.3385]  Of course, this object may in reality be much more complex: the object may have member variables that play a role in computing the new locations of vertices.
//
[0.x.27504] 
[0.x.27505] 
[0.x.27506] 
[0.x.27507] 
[0.x.27508] 
[0.x.27509] 
//
[0.x.27510] 
[0.x.27511] 
[0.x.27512] 
[0.x.27513] 
[0.x.27514] 
//
[0.x.27515] 
[0.x.27516] 
[0.x.27517] 
[0.x.27518] 
[0.x.27519] 
[0.x.27520] 
[0.x.27521] 
[0.x.27522] 
[0.x.27523] 
//
[0.x.27524] 
[0.x.27525] 
[0.x.27526] 
//[2.x.3386] 
//
// In this last example, we create a mesh and then distort its (interior) vertices by a random perturbation. This is not something you want to do for production computations (because results are generally better on meshes with "nicely shaped" cells than on the deformed cells produced by  [2.x.3387]  but it is a useful tool for testing discretizations and codes to make sure they don't work just by accident because the mesh happens to be uniformly structured and supporting superconvergence properties.
//
[0.x.27527] 
[0.x.27528] 
[0.x.27529] 
[0.x.27530] 
[0.x.27531] 
[0.x.27532] 
[0.x.27533] 
[0.x.27534] 
[0.x.27535] 
//
[0.x.27536] 
[0.x.27537] 
[0.x.27538] 
//[2.x.3388] 
//
// Finally, the main function. There isn't much to do here, only to call all the various functions we wrote above.
//
[0.x.27539] 
[0.x.27540] 
[0.x.27541] 
[0.x.27542] 
[0.x.27543] 
[0.x.27544] 
[0.x.27545] 
[0.x.27546] 
[0.x.27547] 
[0.x.27548] 
[0.x.27549] 
[0.x.27550] 
[0.x.27551] 
[0.x.27552] 
[0.x.27553] 
[0.x.27554] 
[0.x.27555] 
[0.x.27556] 
[0.x.27557] 
[0.x.27558] 
[0.x.27559] 
[0.x.27560] 
[0.x.27561] 
//
[0.x.27562] 
[0.x.27563] 
[0.x.27564] 
[0.x.27565] 
[0.x.27566] 
[0.x.27567] 
[0.x.27568] 
[0.x.27569] 
[0.x.27570] 
[0.x.27571] 
[0.x.27572] 
[0.x.27573] 
[0.x.27574] 
[0.x.27575] 
[0.x.27576] 
[0.x.27577] 
[0.x.27578] 
[0.x.27579] 
[0.x.27580] 
[0.x.27581] 
[0.x.27582] 
[0.x.27583] 
[0.x.27584] 
[0.x.27585] 
[0.x.27586] 
[0.x.27587] 
[0.x.27588] 
[0.x.27589] 
[0.x.27590] 
//
[0.x.27591] 
[0.x.27592] 
[0.x.27593] 
//[2.x.3389] 
//
// Again, the first few include files are already known, so we won't comment on them:
//
[0.x.27594] 
[0.x.27595] 
[0.x.27596] 
[0.x.27597] 
[0.x.27598] 
[0.x.27599] 
[0.x.27600] 
[0.x.27601] 
[0.x.27602] 
[0.x.27603] 
[0.x.27604] 
[0.x.27605] 
[0.x.27606] 
[0.x.27607] 
[0.x.27608] 
[0.x.27609] 
[0.x.27610] 
//
// This one is new. We want to read a triangulation from disk, and the class which does this is declared in the following file:
//
[0.x.27611] 
//
// We will use a circular domain, and the object describing the boundary of it comes from this file:
//
[0.x.27612] 
//
// This is C++ ...
//
[0.x.27613] 
[0.x.27614] 
//
// Finally, this has been discussed in previous tutorial programs before:
//
[0.x.27615] 
//[2.x.3390] 
//
// The main class is mostly as in the previous example. The most visible change is that the function  [2.x.3391]  has been removed, since creating the grid is now done in the  [2.x.3392]  function and the rest of its functionality is now in  [2.x.3393] . Apart from this, everything is as before.
//
[0.x.27616] 
[0.x.27617] 
[0.x.27618] 
[0.x.27619] 
[0.x.27620] 
[0.x.27621] 
//
[0.x.27622] 
[0.x.27623] 
[0.x.27624] 
[0.x.27625] 
[0.x.27626] 
//
[0.x.27627] 
[0.x.27628] 
[0.x.27629] 
//
[0.x.27630] 
[0.x.27631] 
//
[0.x.27632] 
[0.x.27633] 
[0.x.27634] 
//[2.x.3394] 
//
// In  [2.x.3395] , we showed how to use non-constant boundary values and right hand side.  In this example, we want to use a variable coefficient in the elliptic operator instead. Since we have a function which just depends on the point in space we can do things a bit more simply and use a plain function instead of inheriting from Function.
//
// This is the implementation of the coefficient function for a single point. We let it return 20 if the distance to the origin is less than 0.5, and 1 otherwise.
//
[0.x.27635] 
[0.x.27636] 
[0.x.27637] 
[0.x.27638] 
[0.x.27639] 
[0.x.27640] 
[0.x.27641] 
[0.x.27642] 
//[2.x.3396] 
//[2.x.3397] 
//
// This function is as before.
//
[0.x.27643] 
[0.x.27644] 
[0.x.27645] 
[0.x.27646] 
[0.x.27647] 
//
//  [2.x.3398] 
//
// This is the function  [2.x.3399]  from the previous example, minus the generation of the grid. Everything else is unchanged:
//
[0.x.27648] 
[0.x.27649] 
[0.x.27650] 
[0.x.27651] 
//
[0.x.27652] 
[0.x.27653] 
//
[0.x.27654] 
[0.x.27655] 
[0.x.27656] 
//
[0.x.27657] 
//
[0.x.27658] 
[0.x.27659] 
[0.x.27660] 
//
//  [2.x.3400] 
//
// As in the previous examples, this function is not changed much with regard to its functionality, but there are still some optimizations which we will show. For this, it is important to note that if efficient solvers are used (such as the preconditioned CG method), assembling the matrix and right hand side can take a comparable time, and you should think about using one or two optimizations at some places.
//
// The first parts of the function are completely unchanged from before:
//
[0.x.27661] 
[0.x.27662] 
[0.x.27663] 
[0.x.27664] 
//
[0.x.27665] 
[0.x.27666] 
[0.x.27667] 
[0.x.27668] 
//
[0.x.27669] 
//
[0.x.27670] 
[0.x.27671] 
//
[0.x.27672] 
//
// Next is the typical loop over all cells to compute local contributions and then to transfer them into the global matrix and vector. The only change in this part, compared to  [2.x.3401] , is that we will use the  [2.x.3402]  function defined above to compute the coefficient value at each quadrature point.
//
[0.x.27673] 
[0.x.27674] 
[0.x.27675] 
[0.x.27676] 
//
[0.x.27677] 
//
[0.x.27678] 
[0.x.27679] 
[0.x.27680] 
[0.x.27681] 
[0.x.27682] 
[0.x.27683] 
[0.x.27684] 
[0.x.27685] 
[0.x.27686] 
[0.x.27687] 
[0.x.27688] 
[0.x.27689] 
//
[0.x.27690] 
[0.x.27691] 
[0.x.27692] 
[0.x.27693] 
[0.x.27694] 
//
[0.x.27695] 
[0.x.27696] 
[0.x.27697] 
[0.x.27698] 
[0.x.27699] 
[0.x.27700] 
[0.x.27701] 
//
[0.x.27702] 
[0.x.27703] 
[0.x.27704] 
//
// With the matrix so built, we use zero boundary values again:
//
[0.x.27705] 
[0.x.27706] 
[0.x.27707] 
[0.x.27708] 
[0.x.27709] 
[0.x.27710] 
[0.x.27711] 
[0.x.27712] 
[0.x.27713] 
[0.x.27714] 
//[2.x.3403] 
//
// The solution process again looks mostly like in the previous examples. However, we will now use a preconditioned conjugate gradient algorithm. It is not very difficult to make this change. In fact, the only thing we have to alter is that we need an object which will act as a preconditioner. We will use SSOR (symmetric successive overrelaxation), with a relaxation factor of 1.2. For this purpose, the  [2.x.3404]  class has a function which does one SSOR step, and we need to package the address of this function together with the matrix on which it should act (which is the matrix to be inverted) and the relaxation factor into one object. The  [2.x.3405]  class does this for us. ( [2.x.3406]  class takes a template argument denoting the matrix type it is supposed to work on. The default value is  [2.x.3407] , which is exactly what we need here, so we simply stick with the default and do not specify anything in the angle brackets.)
//
// Note that for the present case, SSOR doesn't really perform much better than most other preconditioners (though better than no preconditioning at all). A brief comparison of different preconditioners is presented in the Results section of the next tutorial program,  [2.x.3408] .
//
// With this, the rest of the function is trivial: instead of the  [2.x.3409]  object we have created before, we now use the preconditioner we have declared, and the CG solver will do the rest for us:
//
[0.x.27715] 
[0.x.27716] 
[0.x.27717] 
[0.x.27718] 
[0.x.27719] 
//
[0.x.27720] 
[0.x.27721] 
//
[0.x.27722] 
//
[0.x.27723] 
[0.x.27724] 
[0.x.27725] 
//[2.x.3410] 
//
// Writing output to a file is mostly the same as for the previous tutorial. The only difference is that we now need to construct a different filename for each refinement cycle.
//
// The function writes the output in VTU format, a variation of the VTK format that requires less disk space because it compresses the data. Of course, there are many other formats supported by the DataOut class if you desire to use a program for visualization that doesn't understand VTK or VTU.
//
[0.x.27726] 
[0.x.27727] 
[0.x.27728] 
[0.x.27729] 
//
[0.x.27730] 
[0.x.27731] 
//
[0.x.27732] 
//
[0.x.27733] 
[0.x.27734] 
[0.x.27735] 
//
//  [2.x.3411] 
//
// The second to last thing in this program is the definition of the  [2.x.3412]  function. In contrast to the previous programs, we will compute on a sequence of meshes that after each iteration is globally refined. The function therefore consists of a loop over 6 cycles. In each cycle, we first print the cycle number, and then have to decide what to do with the mesh. If this is not the first cycle, we simply refine the existing mesh once globally. Before running through these cycles, however, we have to generate a mesh:
//
// In previous examples, we have already used some of the functions from the  [2.x.3413]  class. Here we would like to read a grid from a file where the cells are stored and which may originate from someone else, or may be the product of a mesh generator tool.
//
// In order to read a grid from a file, we generate an object of data type GridIn and associate the triangulation to it (i.e. we tell it to fill our triangulation object when we ask it to read the file). Then we open the respective file and initialize the triangulation with the data in the file:
//
[0.x.27736] 
[0.x.27737] 
[0.x.27738] 
[0.x.27739] 
[0.x.27740] 
[0.x.27741] 
//
// We would now like to read the file. However, the input file is only for a two-dimensional triangulation, while this function is a template for arbitrary dimension. Since this is only a demonstration program, we will not use different input files for the different dimensions, but rather quickly kill the whole program if we are not in 2D. Of course, since the main function below assumes that we are working in two dimensions we could skip this check, in this version of the program, without any ill effects.
//
// It turns out that more than 90 per cent of programming errors are invalid function parameters such as invalid array sizes, etc, so we use assertions heavily throughout deal.II to catch such mistakes. For this, the  [2.x.3414]  macro is a good choice, since it makes sure that the condition which is given as first argument is valid, and if not throws an exception (its second argument) which will usually terminate the program giving information where the error occurred and what the reason was. (A longer discussion of what exactly the  [2.x.3415]  macro does can be found in the  [2.x.3416]  "exception documentation module".) This generally reduces the time to find programming errors dramatically and we have found assertions an invaluable means to program fast.
//
// On the other hand, all these checks (there are over 10,000 of them in the library at present) should not slow down the program too much if you want to do large computations. To this end, the  [2.x.3417]  macro is only used in debug mode and expands to nothing if in optimized mode. Therefore, while you test your program on small problems and debug it, the assertions will tell you where the problems are. Once your program is stable, you can switch off debugging and the program will run your real computations without the assertions and at maximum speed. More precisely: turning off all the checks in the library (which prevent you from calling functions with wrong arguments, walking off of arrays, etc.) by compiling your program in optimized mode usually makes things run about four times faster. Even though optimized programs are more performant, we still recommend developing in debug mode since it allows the library to find lots of common programming errors automatically. For those who want to try: The way to switch from debug mode to optimized mode is to recompile your program with the command <code>make release</code>. The output of the  [2.x.3418]  program should now indicate to you that the program is now compiled in optimized mode, and it will later also be linked to libraries that have been compiled for optimized mode. In order to switch back to debug mode, simply recompile with the command  [2.x.3419] .
//
[0.x.27742] 
//
// ExcInternalError is a globally defined exception, which may be thrown whenever something is terribly wrong. Usually, one would like to use more specific exceptions, and particular in this case one would of course try to do something else if  [2.x.3420]  is not equal to two, e.g. create a grid using library functions. Aborting a program is usually not a good idea and assertions should really only be used for exceptional cases which should not occur, but might due to stupidity of the programmer, user, or someone else. The situation above is not a very clever use of Assert, but again: this is a tutorial and it might be worth to show what not to do, after all.
//
// So if we got past the assertion, we know that dim==2, and we can now actually read the grid. It is in UCD (unstructured cell data) format (though the convention is to use the suffix  [2.x.3421]  for UCD files):
//
[0.x.27743] 
//
// If you like to use another input format, you have to use one of the other  [2.x.3422]  function. (See the documentation of the  [2.x.3423]  class to find out what input formats are presently supported.)
//
// The grid in the file describes a circle. Therefore we have to use a manifold object which tells the triangulation where to put new points on the boundary when the grid is refined. Unlike  [2.x.3424] , since GridIn does not know that the domain has a circular boundary (unlike  [2.x.3425]  we have to explicitly attach a manifold to the boundary after creating the triangulation to get the correct result when we refine the mesh.
//
[0.x.27744] 
[0.x.27745] 
[0.x.27746] 
//
[0.x.27747] 
[0.x.27748] 
[0.x.27749] 
//
[0.x.27750] 
[0.x.27751] 
//
// Now that we have a mesh for sure, we write some output and do all the things that we have already seen in the previous examples.
//
[0.x.27752] 
[0.x.27753] 
[0.x.27754] 
[0.x.27755] 
[0.x.27756] 
[0.x.27757] 
//
[0.x.27758] 
[0.x.27759] 
[0.x.27760] 
[0.x.27761] 
[0.x.27762] 
[0.x.27763] 
//[2.x.3426] 
//
// The main function looks mostly like the one in the previous example, so we won't comment on it further:
//
[0.x.27764] 
[0.x.27765] 
[0.x.27766] 
[0.x.27767] 
[0.x.27768] 
[0.x.27769] 
[0.x.27770] 
[0.x.27771] 
[0.x.27772] 
[0.x.27773] 
[0.x.27774] 
[0.x.27775] 
[0.x.27776] 
[0.x.27777] 
[0.x.27778] 
[0.x.27779] 
[0.x.27780] 
[0.x.27781] 
[0.x.27782] 
[0.x.27783] 
//
[0.x.27784] 
[0.x.27785] 
[0.x.27786] 
[0.x.27787] 
[0.x.27788] 
[0.x.27789] 
//[2.x.3427] 
//
// The include files are a combination of  [2.x.3428] ,  [2.x.3429] , and  [2.x.3430] :
//
[0.x.27790] 
[0.x.27791] 
[0.x.27792] 
[0.x.27793] 
[0.x.27794] 
[0.x.27795] 
[0.x.27796] 
[0.x.27797] 
[0.x.27798] 
[0.x.27799] 
[0.x.27800] 
[0.x.27801] 
[0.x.27802] 
[0.x.27803] 
[0.x.27804] 
[0.x.27805] 
[0.x.27806] 
[0.x.27807] 
//
// We use the same strategy as in  [2.x.3431]  to switch between PETSc and Trilinos:
//
[0.x.27808] 
//
// Comment the following preprocessor definition in or out if you have PETSc and Trilinos installed and you prefer using PETSc in this example:
//
[0.x.27809] 
//
[0.x.27810] 
[0.x.27811] 
[0.x.27812] 
[0.x.27813] 
[0.x.27814] 
[0.x.27815] 
[0.x.27816] 
[0.x.27817] 
[0.x.27818] 
[0.x.27819] 
[0.x.27820] 
[0.x.27821] 
//
[0.x.27822] 
[0.x.27823] 
[0.x.27824] 
[0.x.27825] 
[0.x.27826] 
[0.x.27827] 
[0.x.27828] 
[0.x.27829] 
[0.x.27830] 
[0.x.27831] 
[0.x.27832] 
[0.x.27833] 
[0.x.27834] 
//
// The following files are used to assemble the error estimator like in  [2.x.3432] :
//
[0.x.27835] 
[0.x.27836] 
//
[0.x.27837] 
//[2.x.3433] 
//
// MatrixFree operators must use the  [2.x.3434]  vector type. Here we define operations which copy to and from Trilinos vectors for compatibility with the matrix-based code. Note that this functionality does not currently exist for PETSc vector types, so Trilinos must be installed to use the MatrixFree solver in this tutorial.
//
[0.x.27838] 
[0.x.27839] 
[0.x.27840] 
[0.x.27841] 
[0.x.27842] 
[0.x.27843] 
[0.x.27844] 
[0.x.27845] 
[0.x.27846] 
[0.x.27847] 
[0.x.27848] 
[0.x.27849] 
[0.x.27850] 
[0.x.27851] 
[0.x.27852] 
[0.x.27853] 
[0.x.27854] 
//
[0.x.27855] 
[0.x.27856] 
[0.x.27857] 
[0.x.27858] 
[0.x.27859] 
[0.x.27860] 
[0.x.27861] 
[0.x.27862] 
[0.x.27863] 
[0.x.27864] 
[0.x.27865] 
[0.x.27866] 
[0.x.27867] 
[0.x.27868] 
[0.x.27869] 
[0.x.27870] 
//
// Let's move on to the description of the problem we want to solve. We set the right-hand side function to 1.0. The  [2.x.3435]  function returning a VectorizedArray is used by the matrix-free code path.
//
[0.x.27871] 
[0.x.27872] 
[0.x.27873] 
[0.x.27874] 
[0.x.27875] 
[0.x.27876] 
[0.x.27877] 
[0.x.27878] 
[0.x.27879] 
//
[0.x.27880] 
[0.x.27881] 
[0.x.27882] 
[0.x.27883] 
[0.x.27884] 
[0.x.27885] 
[0.x.27886] 
[0.x.27887] 
//
// This next class represents the diffusion coefficient. We use a variable coefficient which is 100.0 at any point where at least one coordinate is less than -0.5, and 1.0 at all other points. As above, a separate value() returning a VectorizedArray is used for the matrix-free code. An  [2.x.3436]  average() function computes the arithmetic average for a set of points.
//
[0.x.27888] 
[0.x.27889] 
[0.x.27890] 
[0.x.27891] 
[0.x.27892] 
[0.x.27893] 
//
[0.x.27894] 
[0.x.27895] 
[0.x.27896] 
//
[0.x.27897] 
[0.x.27898] 
//
// When using a coefficient in the MatrixFree framework, we also need a function that creates a Table of coefficient values for a set of cells provided by the MatrixFree operator argument here.
//
[0.x.27899] 
[0.x.27900] 
[0.x.27901] 
[0.x.27902] 
//
[0.x.27903] 
[0.x.27904] 
[0.x.27905] 
[0.x.27906] 
[0.x.27907] 
[0.x.27908] 
[0.x.27909] 
[0.x.27910] 
[0.x.27911] 
[0.x.27912] 
//
[0.x.27913] 
[0.x.27914] 
[0.x.27915] 
[0.x.27916] 
[0.x.27917] 
[0.x.27918] 
[0.x.27919] 
[0.x.27920] 
[0.x.27921] 
[0.x.27922] 
[0.x.27923] 
[0.x.27924] 
[0.x.27925] 
[0.x.27926] 
[0.x.27927] 
[0.x.27928] 
//
[0.x.27929] 
[0.x.27930] 
//
[0.x.27931] 
[0.x.27932] 
[0.x.27933] 
[0.x.27934] 
[0.x.27935] 
[0.x.27936] 
[0.x.27937] 
[0.x.27938] 
[0.x.27939] 
//
[0.x.27940] 
[0.x.27941] 
//
[0.x.27942] 
[0.x.27943] 
[0.x.27944] 
[0.x.27945] 
[0.x.27946] 
[0.x.27947] 
[0.x.27948] 
[0.x.27949] 
//
[0.x.27950] 
//
[0.x.27951] 
[0.x.27952] 
//
[0.x.27953] 
//
[0.x.27954] 
[0.x.27955] 
[0.x.27956] 
//
[0.x.27957] 
[0.x.27958] 
[0.x.27959] 
[0.x.27960] 
//
[0.x.27961] 
[0.x.27962] 
//
[0.x.27963] 
[0.x.27964] 
//
//  [2.x.3437] 
//
// We will use ParameterHandler to pass in parameters at runtime.  The structure  [2.x.3438]  parses and stores these parameters to be queried throughout the program.
//
[0.x.27965] 
[0.x.27966] 
[0.x.27967] 
//
[0.x.27968] 
[0.x.27969] 
[0.x.27970] 
[0.x.27971] 
[0.x.27972] 
[0.x.27973] 
//
[0.x.27974] 
//
[0.x.27975] 
[0.x.27976] 
[0.x.27977] 
[0.x.27978] 
[0.x.27979] 
[0.x.27980] 
//
[0.x.27981] 
[0.x.27982] 
[0.x.27983] 
[0.x.27984] 
[0.x.27985] 
[0.x.27986] 
[0.x.27987] 
[0.x.27988] 
[0.x.27989] 
[0.x.27990] 
[0.x.27991] 
[0.x.27992] 
[0.x.27993] 
[0.x.27994] 
[0.x.27995] 
[0.x.27996] 
[0.x.27997] 
[0.x.27998] 
[0.x.27999] 
[0.x.28000] 
[0.x.28001] 
[0.x.28002] 
[0.x.28003] 
[0.x.28004] 
[0.x.28005] 
//
[0.x.28006] 
[0.x.28007] 
[0.x.28008] 
[0.x.28009] 
[0.x.28010] 
[0.x.28011] 
[0.x.28012] 
[0.x.28013] 
[0.x.28014] 
[0.x.28015] 
[0.x.28016] 
[0.x.28017] 
//
[0.x.28018] 
[0.x.28019] 
[0.x.28020] 
[0.x.28021] 
[0.x.28022] 
[0.x.28023] 
[0.x.28024] 
[0.x.28025] 
[0.x.28026] 
[0.x.28027] 
//
[0.x.28028] 
[0.x.28029] 
[0.x.28030] 
[0.x.28031] 
[0.x.28032] 
[0.x.28033] 
[0.x.28034] 
[0.x.28035] 
//
[0.x.28036] 
[0.x.28037] 
[0.x.28038] 
[0.x.28039] 
[0.x.28040] 
//
[0.x.28041] 
[0.x.28042] 
//
//  [2.x.3439] 
//
// This is the main class of the program. It looks very similar to  [2.x.3440] ,  [2.x.3441] , and  [2.x.3442] . For the MatrixFree setup, we use the  [2.x.3443]  class which defines `local_apply()`, `compute_diagonal()`, and `set_coefficient()` functions internally. Note that the polynomial degree is a template parameter of this class. This is necessary for the matrix-free code.
//
[0.x.28043] 
[0.x.28044] 
[0.x.28045] 
[0.x.28046] 
[0.x.28047] 
[0.x.28048] 
//
[0.x.28049] 
//
// We will use the following types throughout the program. First the matrix-based types, after that the matrix-free classes. For the matrix-free implementation, we use  [2.x.3444]  for the level operators.
//
[0.x.28050] 
[0.x.28051] 
[0.x.28052] 
[0.x.28053] 
//
[0.x.28054] 
[0.x.28055] 
[0.x.28056] 
[0.x.28057] 
[0.x.28058] 
[0.x.28059] 
[0.x.28060] 
[0.x.28061] 
[0.x.28062] 
[0.x.28063] 
[0.x.28064] 
[0.x.28065] 
//
[0.x.28066] 
[0.x.28067] 
//
[0.x.28068] 
[0.x.28069] 
[0.x.28070] 
[0.x.28071] 
[0.x.28072] 
[0.x.28073] 
[0.x.28074] 
[0.x.28075] 
[0.x.28076] 
//
[0.x.28077] 
//
[0.x.28078] 
[0.x.28079] 
//
[0.x.28080] 
[0.x.28081] 
[0.x.28082] 
//
[0.x.28083] 
//
[0.x.28084] 
[0.x.28085] 
[0.x.28086] 
//
[0.x.28087] 
[0.x.28088] 
[0.x.28089] 
[0.x.28090] 
[0.x.28091] 
//
[0.x.28092] 
[0.x.28093] 
[0.x.28094] 
//
[0.x.28095] 
//
[0.x.28096] 
[0.x.28097] 
//
// The only interesting part about the constructor is that we construct the multigrid hierarchy unless we use AMG. For that, we need to parse the run time parameters before this constructor completes.
//
[0.x.28098] 
[0.x.28099] 
[0.x.28100] 
[0.x.28101] 
[0.x.28102] 
[0.x.28103] 
[0.x.28104] 
[0.x.28105] 
[0.x.28106] 
[0.x.28107] 
[0.x.28108] 
[0.x.28109] 
[0.x.28110] 
[0.x.28111] 
[0.x.28112] 
[0.x.28113] 
[0.x.28114] 
[0.x.28115] 
[0.x.28116] 
//
//  [2.x.3445] 
//
// Unlike  [2.x.3446]  and  [2.x.3447] , we split the set up into two parts, setup_system() and setup_multigrid(). Here is the typical setup_system() function for the active mesh found in most tutorials. For matrix-free, the active mesh set up is similar to  [2.x.3448] ; for matrix-based (GMG and AMG solvers), the setup is similar to  [2.x.3449] .
//
[0.x.28117] 
[0.x.28118] 
[0.x.28119] 
[0.x.28120] 
//
[0.x.28121] 
//
[0.x.28122] 
[0.x.28123] 
//
[0.x.28124] 
[0.x.28125] 
[0.x.28126] 
[0.x.28127] 
//
[0.x.28128] 
[0.x.28129] 
[0.x.28130] 
//
[0.x.28131] 
[0.x.28132] 
[0.x.28133] 
[0.x.28134] 
[0.x.28135] 
[0.x.28136] 
[0.x.28137] 
[0.x.28138] 
[0.x.28139] 
[0.x.28140] 
[0.x.28141] 
[0.x.28142] 
[0.x.28143] 
[0.x.28144] 
[0.x.28145] 
[0.x.28146] 
//
[0.x.28147] 
//
[0.x.28148] 
[0.x.28149] 
[0.x.28150] 
//
[0.x.28151] 
[0.x.28152] 
//
[0.x.28153] 
[0.x.28154] 
[0.x.28155] 
[0.x.28156] 
[0.x.28157] 
[0.x.28158] 
//
[0.x.28159] 
[0.x.28160] 
[0.x.28161] 
[0.x.28162] 
//
[0.x.28163] 
[0.x.28164] 
[0.x.28165] 
[0.x.28166] 
[0.x.28167] 
[0.x.28168] 
[0.x.28169] 
[0.x.28170] 
[0.x.28171] 
[0.x.28172] 
[0.x.28173] 
[0.x.28174] 
[0.x.28175] 
//
[0.x.28176] 
[0.x.28177] 
//
[0.x.28178] 
[0.x.28179] 
[0.x.28180] 
[0.x.28181] 
//[2.x.3450] 
//
// This function does the multilevel setup for both matrix-free and matrix-based GMG. The matrix-free setup is similar to that of  [2.x.3451] , and the matrix-based is similar to  [2.x.3452] , except we must use appropriate distributed sparsity patterns.
//
// The function is not called for the AMG approach, but to err on the safe side, the main `switch` statement of this function nevertheless makes sure that the function only operates on known multigrid settings by throwing an assertion if the function were called for anything other than the two geometric multigrid methods.
//
[0.x.28182] 
[0.x.28183] 
[0.x.28184] 
[0.x.28185] 
//
[0.x.28186] 
//
[0.x.28187] 
[0.x.28188] 
//
[0.x.28189] 
[0.x.28190] 
//
[0.x.28191] 
//
[0.x.28192] 
[0.x.28193] 
[0.x.28194] 
[0.x.28195] 
[0.x.28196] 
//
[0.x.28197] 
[0.x.28198] 
[0.x.28199] 
[0.x.28200] 
[0.x.28201] 
[0.x.28202] 
[0.x.28203] 
[0.x.28204] 
[0.x.28205] 
[0.x.28206] 
[0.x.28207] 
//
[0.x.28208] 
[0.x.28209] 
[0.x.28210] 
[0.x.28211] 
[0.x.28212] 
[0.x.28213] 
[0.x.28214] 
[0.x.28215] 
[0.x.28216] 
[0.x.28217] 
[0.x.28218] 
[0.x.28219] 
[0.x.28220] 
[0.x.28221] 
//
[0.x.28222] 
[0.x.28223] 
[0.x.28224] 
//
[0.x.28225] 
[0.x.28226] 
[0.x.28227] 
//
[0.x.28228] 
[0.x.28229] 
//
[0.x.28230] 
[0.x.28231] 
//
[0.x.28232] 
[0.x.28233] 
[0.x.28234] 
[0.x.28235] 
[0.x.28236] 
[0.x.28237] 
//
[0.x.28238] 
[0.x.28239] 
[0.x.28240] 
[0.x.28241] 
[0.x.28242] 
[0.x.28243] 
//
[0.x.28244] 
[0.x.28245] 
[0.x.28246] 
[0.x.28247] 
[0.x.28248] 
[0.x.28249] 
[0.x.28250] 
[0.x.28251] 
[0.x.28252] 
[0.x.28253] 
//
[0.x.28254] 
[0.x.28255] 
[0.x.28256] 
[0.x.28257] 
[0.x.28258] 
[0.x.28259] 
[0.x.28260] 
[0.x.28261] 
[0.x.28262] 
[0.x.28263] 
[0.x.28264] 
[0.x.28265] 
//
[0.x.28266] 
[0.x.28267] 
[0.x.28268] 
[0.x.28269] 
//
[0.x.28270] 
[0.x.28271] 
[0.x.28272] 
[0.x.28273] 
[0.x.28274] 
[0.x.28275] 
[0.x.28276] 
[0.x.28277] 
[0.x.28278] 
[0.x.28279] 
[0.x.28280] 
[0.x.28281] 
[0.x.28282] 
//
[0.x.28283] 
[0.x.28284] 
[0.x.28285] 
[0.x.28286] 
[0.x.28287] 
[0.x.28288] 
[0.x.28289] 
[0.x.28290] 
[0.x.28291] 
[0.x.28292] 
[0.x.28293] 
//
[0.x.28294] 
[0.x.28295] 
[0.x.28296] 
[0.x.28297] 
[0.x.28298] 
[0.x.28299] 
[0.x.28300] 
[0.x.28301] 
[0.x.28302] 
[0.x.28303] 
[0.x.28304] 
//
[0.x.28305] 
[0.x.28306] 
[0.x.28307] 
[0.x.28308] 
//[2.x.3453] 
//
// The assembly is split into three parts: `assemble_system()`, `assemble_multigrid()`, and `assemble_rhs()`. The `assemble_system()` function here assembles and stores the (global) system matrix and the right-hand side for the matrix-based methods. It is similar to the assembly in  [2.x.3454] .
//
// Note that the matrix-free method does not execute this function as it does not need to assemble a matrix, and it will instead assemble the right-hand side in assemble_rhs().
//
[0.x.28309] 
[0.x.28310] 
[0.x.28311] 
[0.x.28312] 
//
[0.x.28313] 
//
[0.x.28314] 
[0.x.28315] 
[0.x.28316] 
[0.x.28317] 
//
[0.x.28318] 
[0.x.28319] 
//
[0.x.28320] 
[0.x.28321] 
//
[0.x.28322] 
//
[0.x.28323] 
[0.x.28324] 
[0.x.28325] 
//
[0.x.28326] 
[0.x.28327] 
[0.x.28328] 
[0.x.28329] 
[0.x.28330] 
//
[0.x.28331] 
//
[0.x.28332] 
[0.x.28333] 
[0.x.28334] 
//
[0.x.28335] 
[0.x.28336] 
[0.x.28337] 
[0.x.28338] 
[0.x.28339] 
[0.x.28340] 
[0.x.28341] 
[0.x.28342] 
[0.x.28343] 
//
[0.x.28344] 
[0.x.28345] 
[0.x.28346] 
[0.x.28347] 
[0.x.28348] 
//
[0.x.28349] 
[0.x.28350] 
[0.x.28351] 
[0.x.28352] 
[0.x.28353] 
[0.x.28354] 
[0.x.28355] 
//
[0.x.28356] 
[0.x.28357] 
[0.x.28358] 
//[2.x.3455] 
//
// The following function assembles and stores the multilevel matrices for the matrix-based GMG method. This function is similar to the one found in  [2.x.3456] , only here it works for distributed meshes. This difference amounts to adding a condition that we only assemble on locally owned level cells and a call to compress() for each matrix that is built.
//
[0.x.28359] 
[0.x.28360] 
[0.x.28361] 
[0.x.28362] 
//
[0.x.28363] 
//
[0.x.28364] 
[0.x.28365] 
[0.x.28366] 
[0.x.28367] 
//
[0.x.28368] 
[0.x.28369] 
//
[0.x.28370] 
//
[0.x.28371] 
//
[0.x.28372] 
//
[0.x.28373] 
[0.x.28374] 
[0.x.28375] 
[0.x.28376] 
[0.x.28377] 
[0.x.28378] 
[0.x.28379] 
[0.x.28380] 
[0.x.28381] 
[0.x.28382] 
[0.x.28383] 
[0.x.28384] 
[0.x.28385] 
//
[0.x.28386] 
[0.x.28387] 
//
[0.x.28388] 
[0.x.28389] 
[0.x.28390] 
[0.x.28391] 
[0.x.28392] 
//
[0.x.28393] 
[0.x.28394] 
//
[0.x.28395] 
[0.x.28396] 
[0.x.28397] 
[0.x.28398] 
[0.x.28399] 
[0.x.28400] 
//
[0.x.28401] 
//
[0.x.28402] 
[0.x.28403] 
//
[0.x.28404] 
[0.x.28405] 
[0.x.28406] 
[0.x.28407] 
[0.x.28408] 
[0.x.28409] 
[0.x.28410] 
[0.x.28411] 
//
[0.x.28412] 
[0.x.28413] 
[0.x.28414] 
[0.x.28415] 
[0.x.28416] 
[0.x.28417] 
//
//  [2.x.3457] 
//
// The final function in this triptych assembles the right-hand side vector for the matrix-free method -- because in the matrix-free framework, we don't have to assemble the matrix and can get away with only assembling the right hand side. We could do this by extracting the code from the `assemble_system()` function above that deals with the right hand side, but we decide instead to go all in on the matrix-free approach and do the assembly using that way as well.
//
// The result is a function that is similar to the one found in the "Use  [2.x.3458]  to avoid resolving constraints" subsection in the "Possibilities for extensions" section of  [2.x.3459] .
//
// The reason for this function is that the MatrixFree operators do not take into account non-homogeneous Dirichlet constraints, instead treating all Dirichlet constraints as homogeneous. To account for this, the right-hand side here is assembled as the residual  [2.x.3460] , where  [2.x.3461]  is a zero vector except in the Dirichlet values. Then when solving, we have that the solution is  [2.x.3462] . This can be seen as a Newton iteration on a linear system with initial guess  [2.x.3463] . The CG solve in the `solve()` function below computes  [2.x.3464]  and the call to `constraints.distribute()` (which directly follows) adds the  [2.x.3465] .
//
// Obviously, since we are considering a problem with zero Dirichlet boundary, we could have taken a similar approach to  [2.x.3466]  `assemble_rhs()`, but this additional work allows us to change the problem declaration if we so choose.
//
// This function has two parts in the integration loop: applying the negative of matrix  [2.x.3467]  to  [2.x.3468]  by submitting the negative of the gradient, and adding the right-hand side contribution by submitting the value  [2.x.3469] . We must be sure to use `read_dof_values_plain()` for evaluating  [2.x.3470]  as `read_dof_vaues()` would set all Dirichlet values to zero.
//
// Finally, the system_rhs vector is of type  [2.x.3471]  but the MatrixFree class only work for  [2.x.3472]   Therefore we must compute the right-hand side using MatrixFree functionality and then use the functions in the `ChangeVectorType` namespace to copy it to the correct type.
//
[0.x.28418] 
[0.x.28419] 
[0.x.28420] 
[0.x.28421] 
//
[0.x.28422] 
[0.x.28423] 
[0.x.28424] 
[0.x.28425] 
//
[0.x.28426] 
[0.x.28427] 
[0.x.28428] 
[0.x.28429] 
[0.x.28430] 
[0.x.28431] 
//
[0.x.28432] 
//
[0.x.28433] 
[0.x.28434] 
//
[0.x.28435] 
[0.x.28436] 
[0.x.28437] 
[0.x.28438] 
[0.x.28439] 
[0.x.28440] 
[0.x.28441] 
//
[0.x.28442] 
[0.x.28443] 
[0.x.28444] 
[0.x.28445] 
[0.x.28446] 
[0.x.28447] 
[0.x.28448] 
[0.x.28449] 
//
[0.x.28450] 
[0.x.28451] 
[0.x.28452] 
[0.x.28453] 
//
[0.x.28454] 
//
[0.x.28455] 
[0.x.28456] 
//
//  [2.x.3473] 
//
// Here we set up the multigrid preconditioner, test the timing of a single V-cycle, and solve the linear system. Unsurprisingly, this is one of the places where the three methods differ the most.
//
[0.x.28457] 
[0.x.28458] 
[0.x.28459] 
[0.x.28460] 
//
[0.x.28461] 
[0.x.28462] 
//
[0.x.28463] 
//
// The solver for the matrix-free GMG method is similar to  [2.x.3474] , apart from adding some interface matrices in complete analogy to  [2.x.3475] .
//
[0.x.28464] 
[0.x.28465] 
[0.x.28466] 
[0.x.28467] 
[0.x.28468] 
//
[0.x.28469] 
[0.x.28470] 
//
[0.x.28471] 
[0.x.28472] 
[0.x.28473] 
[0.x.28474] 
[0.x.28475] 
[0.x.28476] 
[0.x.28477] 
[0.x.28478] 
//
[0.x.28479] 
[0.x.28480] 
[0.x.28481] 
[0.x.28482] 
[0.x.28483] 
[0.x.28484] 
[0.x.28485] 
[0.x.28486] 
[0.x.28487] 
//
[0.x.28488] 
//
[0.x.28489] 
[0.x.28490] 
[0.x.28491] 
[0.x.28492] 
[0.x.28493] 
[0.x.28494] 
[0.x.28495] 
[0.x.28496] 
//
[0.x.28497] 
[0.x.28498] 
[0.x.28499] 
//
[0.x.28500] 
[0.x.28501] 
[0.x.28502] 
[0.x.28503] 
//
// Copy the solution vector and right-hand side from  [2.x.3476]  to  [2.x.3477]  so that we can solve.
//
[0.x.28504] 
[0.x.28505] 
[0.x.28506] 
[0.x.28507] 
//
[0.x.28508] 
[0.x.28509] 
[0.x.28510] 
//
// Timing for 1 V-cycle.
//
[0.x.28511] 
[0.x.28512] 
[0.x.28513] 
[0.x.28514] 
[0.x.28515] 
[0.x.28516] 
//
// Solve the linear system, update the ghost values of the solution, copy back to  [2.x.3478]  and distribute constraints.
//
[0.x.28517] 
[0.x.28518] 
//
[0.x.28519] 
[0.x.28520] 
[0.x.28521] 
[0.x.28522] 
[0.x.28523] 
[0.x.28524] 
//
[0.x.28525] 
[0.x.28526] 
[0.x.28527] 
//
[0.x.28528] 
[0.x.28529] 
//
// Solver for the matrix-based GMG method, similar to  [2.x.3479] , only using a Jacobi smoother instead of a SOR smoother (which is not implemented in parallel).
//
[0.x.28530] 
[0.x.28531] 
[0.x.28532] 
//
[0.x.28533] 
[0.x.28534] 
//
[0.x.28535] 
[0.x.28536] 
[0.x.28537] 
[0.x.28538] 
[0.x.28539] 
[0.x.28540] 
[0.x.28541] 
[0.x.28542] 
//
[0.x.28543] 
[0.x.28544] 
//
[0.x.28545] 
[0.x.28546] 
[0.x.28547] 
[0.x.28548] 
[0.x.28549] 
[0.x.28550] 
[0.x.28551] 
[0.x.28552] 
[0.x.28553] 
//
[0.x.28554] 
//
[0.x.28555] 
[0.x.28556] 
[0.x.28557] 
//
[0.x.28558] 
[0.x.28559] 
[0.x.28560] 
//
[0.x.28561] 
[0.x.28562] 
//
[0.x.28563] 
//
// Timing for 1 V-cycle.
//
[0.x.28564] 
[0.x.28565] 
[0.x.28566] 
[0.x.28567] 
[0.x.28568] 
[0.x.28569] 
//
// Solve the linear system and distribute constraints.
//
[0.x.28570] 
[0.x.28571] 
//
[0.x.28572] 
[0.x.28573] 
[0.x.28574] 
[0.x.28575] 
[0.x.28576] 
[0.x.28577] 
//
[0.x.28578] 
//
[0.x.28579] 
[0.x.28580] 
//
// Solver for the AMG method, similar to  [2.x.3480] .
//
[0.x.28581] 
[0.x.28582] 
[0.x.28583] 
//
[0.x.28584] 
[0.x.28585] 
//
[0.x.28586] 
[0.x.28587] 
[0.x.28588] 
[0.x.28589] 
[0.x.28590] 
[0.x.28591] 
[0.x.28592] 
[0.x.28593] 
[0.x.28594] 
//
[0.x.28595] 
//
[0.x.28596] 
[0.x.28597] 
//
// Timing for 1 V-cycle.
//
[0.x.28598] 
[0.x.28599] 
[0.x.28600] 
[0.x.28601] 
[0.x.28602] 
[0.x.28603] 
//
// Solve the linear system and distribute constraints.
//
[0.x.28604] 
[0.x.28605] 
//
[0.x.28606] 
[0.x.28607] 
[0.x.28608] 
[0.x.28609] 
[0.x.28610] 
[0.x.28611] 
[0.x.28612] 
//
[0.x.28613] 
[0.x.28614] 
//
[0.x.28615] 
[0.x.28616] 
[0.x.28617] 
//
[0.x.28618] 
[0.x.28619] 
[0.x.28620] 
//[2.x.3481] 
//
// We use the FEInterfaceValues class to assemble an error estimator to decide which cells to refine. See the exact definition of the cell and face integrals in the introduction. To use the method, we define Scratch and Copy objects for the  [2.x.3482]  with much of the following code being in essence as was set up in  [2.x.3483]  already (or at least similar in spirit).
//
[0.x.28621] 
[0.x.28622] 
[0.x.28623] 
[0.x.28624] 
[0.x.28625] 
[0.x.28626] 
[0.x.28627] 
[0.x.28628] 
[0.x.28629] 
[0.x.28630] 
[0.x.28631] 
[0.x.28632] 
[0.x.28633] 
[0.x.28634] 
//
[0.x.28635] 
[0.x.28636] 
[0.x.28637] 
[0.x.28638] 
[0.x.28639] 
[0.x.28640] 
[0.x.28641] 
[0.x.28642] 
[0.x.28643] 
[0.x.28644] 
//
[0.x.28645] 
[0.x.28646] 
[0.x.28647] 
//
[0.x.28648] 
[0.x.28649] 
[0.x.28650] 
[0.x.28651] 
[0.x.28652] 
[0.x.28653] 
//
[0.x.28654] 
//
[0.x.28655] 
[0.x.28656] 
[0.x.28657] 
[0.x.28658] 
[0.x.28659] 
//
[0.x.28660] 
[0.x.28661] 
[0.x.28662] 
[0.x.28663] 
//
[0.x.28664] 
[0.x.28665] 
[0.x.28666] 
[0.x.28667] 
//
[0.x.28668] 
[0.x.28669] 
[0.x.28670] 
[0.x.28671] 
[0.x.28672] 
//
[0.x.28673] 
//
[0.x.28674] 
//
[0.x.28675] 
//
// Assembler for cell residual  [2.x.3484] 
[0.x.28676] 
[0.x.28677] 
[0.x.28678] 
[0.x.28679] 
[0.x.28680] 
//
[0.x.28681] 
[0.x.28682] 
//
[0.x.28683] 
//
[0.x.28684] 
[0.x.28685] 
//
[0.x.28686] 
//
[0.x.28687] 
[0.x.28688] 
[0.x.28689] 
[0.x.28690] 
[0.x.28691] 
[0.x.28692] 
//
[0.x.28693] 
[0.x.28694] 
[0.x.28695] 
//
// Assembler for face term  [2.x.3485] 
[0.x.28696] 
[0.x.28697] 
[0.x.28698] 
[0.x.28699] 
[0.x.28700] 
[0.x.28701] 
[0.x.28702] 
[0.x.28703] 
[0.x.28704] 
[0.x.28705] 
[0.x.28706] 
//
[0.x.28707] 
[0.x.28708] 
//
[0.x.28709] 
[0.x.28710] 
//
[0.x.28711] 
[0.x.28712] 
//
[0.x.28713] 
//
[0.x.28714] 
[0.x.28715] 
[0.x.28716] 
[0.x.28717] 
[0.x.28718] 
[0.x.28719] 
//
[0.x.28720] 
//
[0.x.28721] 
[0.x.28722] 
[0.x.28723] 
[0.x.28724] 
[0.x.28725] 
[0.x.28726] 
[0.x.28727] 
//
[0.x.28728] 
[0.x.28729] 
//
[0.x.28730] 
[0.x.28731] 
[0.x.28732] 
[0.x.28733] 
//
[0.x.28734] 
[0.x.28735] 
[0.x.28736] 
//
[0.x.28737] 
[0.x.28738] 
[0.x.28739] 
[0.x.28740] 
//
[0.x.28741] 
[0.x.28742] 
[0.x.28743] 
[0.x.28744] 
[0.x.28745] 
[0.x.28746] 
[0.x.28747] 
[0.x.28748] 
[0.x.28749] 
//
// We need to assemble each interior face once but we need to make sure that both processes assemble the face term between a locally owned and a ghost cell. This is achieved by setting the  [2.x.3486]  flag. We need to do this, because we do not communicate the error estimator contributions here.
//
[0.x.28750] 
[0.x.28751] 
[0.x.28752] 
[0.x.28753] 
[0.x.28754] 
[0.x.28755] 
[0.x.28756] 
[0.x.28757] 
[0.x.28758] 
//
//                        /*boundary_worker= [2.x.3487] nullptr,
//
[0.x.28759] 
//
[0.x.28760] 
[0.x.28761] 
[0.x.28762] 
[0.x.28763] 
[0.x.28764] 
[0.x.28765] 
//[2.x.3488] 
//
// We use the cell-wise estimator stored in the vector  [2.x.3489]  and refine a fixed number of cells (chosen here to roughly double the number of DoFs in each step).
//
[0.x.28766] 
[0.x.28767] 
[0.x.28768] 
[0.x.28769] 
//
[0.x.28770] 
[0.x.28771] 
[0.x.28772] 
//
[0.x.28773] 
[0.x.28774] 
//[2.x.3490] 
//
// The output_results() function is similar to the ones found in many of the tutorials (see  [2.x.3491]  for example).
//
[0.x.28775] 
[0.x.28776] 
[0.x.28777] 
[0.x.28778] 
//
[0.x.28779] 
[0.x.28780] 
[0.x.28781] 
[0.x.28782] 
[0.x.28783] 
//
[0.x.28784] 
[0.x.28785] 
[0.x.28786] 
//
[0.x.28787] 
[0.x.28788] 
[0.x.28789] 
[0.x.28790] 
//
[0.x.28791] 
[0.x.28792] 
[0.x.28793] 
[0.x.28794] 
//
[0.x.28795] 
[0.x.28796] 
[0.x.28797] 
//
[0.x.28798] 
//
[0.x.28799] 
[0.x.28800] 
//
[0.x.28801] 
[0.x.28802] 
//[2.x.3492] 
//
// As in most tutorials, this function calls the various functions defined above to setup, assemble, solve, and output the results.
//
[0.x.28803] 
[0.x.28804] 
[0.x.28805] 
[0.x.28806] 
[0.x.28807] 
[0.x.28808] 
[0.x.28809] 
[0.x.28810] 
//
[0.x.28811] 
[0.x.28812] 
//
// We only output level cell data for the GMG methods (same with DoF data below). Note that the partition efficiency is irrelevant for AMG since the level hierarchy is not distributed or used during the computation.
//
[0.x.28813] 
[0.x.28814] 
[0.x.28815] 
[0.x.28816] 
[0.x.28817] 
[0.x.28818] 
[0.x.28819] 
//
[0.x.28820] 
//
// Only set up the multilevel hierarchy for GMG.
//
[0.x.28821] 
[0.x.28822] 
[0.x.28823] 
//
[0.x.28824] 
[0.x.28825] 
[0.x.28826] 
[0.x.28827] 
[0.x.28828] 
[0.x.28829] 
[0.x.28830] 
[0.x.28831] 
[0.x.28832] 
[0.x.28833] 
[0.x.28834] 
[0.x.28835] 
//
// For the matrix-free method, we only assemble the right-hand side. For both matrix-based methods, we assemble both active matrix and right-hand side, and only assemble the multigrid matrices for matrix-based GMG.
//
[0.x.28836] 
[0.x.28837] 
[0.x.28838] 
[0.x.28839] 
[0.x.28840] 
[0.x.28841] 
[0.x.28842] 
[0.x.28843] 
//
[0.x.28844] 
[0.x.28845] 
//
[0.x.28846] 
[0.x.28847] 
//
[0.x.28848] 
[0.x.28849] 
[0.x.28850] 
[0.x.28851] 
//[2.x.3493] 
//
// This is a similar main function to  [2.x.3494] , with the exception that we require the user to pass a .prm file as a sole command line argument (see  [2.x.3495]  and the documentation of the ParameterHandler class for a complete discussion of parameter files).
//
[0.x.28852] 
[0.x.28853] 
[0.x.28854] 
[0.x.28855] 
//
[0.x.28856] 
[0.x.28857] 
[0.x.28858] 
//
[0.x.28859] 
[0.x.28860] 
[0.x.28861] 
//
[0.x.28862] 
[0.x.28863] 
[0.x.28864] 
[0.x.28865] 
[0.x.28866] 
[0.x.28867] 
//
[0.x.28868] 
[0.x.28869] 
//
[0.x.28870] 
[0.x.28871] 
[0.x.28872] 
[0.x.28873] 
//
[0.x.28874] 
[0.x.28875] 
//
[0.x.28876] 
[0.x.28877] 
[0.x.28878] 
[0.x.28879] 
[0.x.28880] 
[0.x.28881] 
[0.x.28882] 
[0.x.28883] 
[0.x.28884] 
[0.x.28885] 
[0.x.28886] 
[0.x.28887] 
[0.x.28888] 
[0.x.28889] 
[0.x.28890] 
[0.x.28891] 
[0.x.28892] 
[0.x.28893] 
[0.x.28894] 
[0.x.28895] 
[0.x.28896] 
[0.x.28897] 
[0.x.28898] 
[0.x.28899] 
[0.x.28900] 
[0.x.28901] 
[0.x.28902] 
[0.x.28903] 
[0.x.28904] 
[0.x.28905] 
[0.x.28906] 
//
[0.x.28907] 
[0.x.28908] 
[0.x.28909] 
[0.x.28910] 
[0.x.28911] 
[0.x.28912] 
[0.x.28913] 
[0.x.28914] 
[0.x.28915] 
[0.x.28916] 
[0.x.28917] 
[0.x.28918] 
[0.x.28919] 
[0.x.28920] 
[0.x.28921] 
[0.x.28922] 
//
[0.x.28923] 
[0.x.28924] 
[0.x.28925] 
[0.x.28926] 
//[2.x.3496] 
//
// Most of the deal.II include files have already been covered in previous examples and are not commented on.
//
[0.x.28927] 
[0.x.28928] 
[0.x.28929] 
[0.x.28930] 
[0.x.28931] 
[0.x.28932] 
[0.x.28933] 
[0.x.28934] 
[0.x.28935] 
[0.x.28936] 
[0.x.28937] 
[0.x.28938] 
[0.x.28939] 
[0.x.28940] 
[0.x.28941] 
[0.x.28942] 
[0.x.28943] 
[0.x.28944] 
[0.x.28945] 
[0.x.28946] 
[0.x.28947] 
[0.x.28948] 
[0.x.28949] 
[0.x.28950] 
[0.x.28951] 
[0.x.28952] 
//
// However, we do have a few new includes for the example. The first one defines finite element spaces on the faces of the triangulation, which we refer to as the 'skeleton'. These finite elements do not have any support on the element interior, and they represent polynomials that have a single value on each codimension-1 surface, but admit discontinuities on codimension-2 surfaces.
//
[0.x.28953] 
//
// The second new file we include defines a new type of sparse matrix.  The regular  [2.x.3497]  type stores indices to all non-zero entries.  The  [2.x.3498]  takes advantage of the coupled nature of DG solutions.  It stores an index to a matrix sub-block of a specified size.  In the HDG context, this sub-block-size is actually the number of degrees of freedom per face defined by the skeleton solution field. This reduces the memory consumption of the matrix by up to one third and results in similar speedups when using the matrix in solvers.
//
[0.x.28954] 
//
// The final new include for this example deals with data output.  Since we have a finite element field defined on the skeleton of the mesh, we would like to visualize what that solution actually is. DataOutFaces does exactly this; the interface is the almost the same as the familiar DataOut, but the output only has codimension-1 data for the simulation.
//
[0.x.28955] 
//
[0.x.28956] 
//
// We start by putting all of our classes into their own namespace.
//
[0.x.28957] 
[0.x.28958] 
[0.x.28959] 
//[2.x.3499] 
//
// The structure of the analytic solution is the same as in  [2.x.3500] . There are two exceptions. Firstly, we also create a solution for the 3d case, and secondly, we scale the solution so its norm is of order unity for all values of the solution width.
//
[0.x.28960] 
[0.x.28961] 
[0.x.28962] 
[0.x.28963] 
[0.x.28964] 
[0.x.28965] 
[0.x.28966] 
[0.x.28967] 
//
[0.x.28968] 
[0.x.28969] 
[0.x.28970] 
[0.x.28971] 
//
[0.x.28972] 
[0.x.28973] 
[0.x.28974] 
[0.x.28975] 
//
[0.x.28976] 
[0.x.28977] 
[0.x.28978] 
[0.x.28979] 
[0.x.28980] 
[0.x.28981] 
//
[0.x.28982] 
[0.x.28983] 
//
[0.x.28984] 
[0.x.28985] 
[0.x.28986] 
[0.x.28987] 
[0.x.28988] 
[0.x.28989] 
[0.x.28990] 
[0.x.28991] 
[0.x.28992] 
[0.x.28993] 
[0.x.28994] 
[0.x.28995] 
[0.x.28996] 
[0.x.28997] 
//
[0.x.28998] 
[0.x.28999] 
[0.x.29000] 
//
[0.x.29001] 
[0.x.29002] 
[0.x.29003] 
[0.x.29004] 
[0.x.29005] 
[0.x.29006] 
[0.x.29007] 
[0.x.29008] 
//
[0.x.29009] 
[0.x.29010] 
[0.x.29011] 
[0.x.29012] 
[0.x.29013] 
//
[0.x.29014] 
[0.x.29015] 
[0.x.29016] 
[0.x.29017] 
//
// This class implements a function where the scalar solution and its negative gradient are collected together. This function is used when computing the error of the HDG approximation and its implementation is to simply call value and gradient function of the Solution class.
//
[0.x.29018] 
[0.x.29019] 
[0.x.29020] 
[0.x.29021] 
[0.x.29022] 
[0.x.29023] 
[0.x.29024] 
//
[0.x.29025] 
[0.x.29026] 
[0.x.29027] 
[0.x.29028] 
[0.x.29029] 
[0.x.29030] 
[0.x.29031] 
[0.x.29032] 
[0.x.29033] 
[0.x.29034] 
[0.x.29035] 
//
// Next comes the implementation of the convection velocity. As described in the introduction, we choose a velocity field that is  [2.x.3501]  in 2D and  [2.x.3502]  in 3D. This gives a divergence-free velocity field.
//
[0.x.29036] 
[0.x.29037] 
[0.x.29038] 
[0.x.29039] 
[0.x.29040] 
[0.x.29041] 
[0.x.29042] 
//
[0.x.29043] 
[0.x.29044] 
[0.x.29045] 
[0.x.29046] 
[0.x.29047] 
[0.x.29048] 
[0.x.29049] 
[0.x.29050] 
[0.x.29051] 
[0.x.29052] 
[0.x.29053] 
[0.x.29054] 
[0.x.29055] 
[0.x.29056] 
[0.x.29057] 
[0.x.29058] 
[0.x.29059] 
[0.x.29060] 
[0.x.29061] 
[0.x.29062] 
[0.x.29063] 
[0.x.29064] 
[0.x.29065] 
//
// The last function we implement is the right hand side for the manufactured solution. It is very similar to  [2.x.3503] , with the exception that we now have a convection term instead of the reaction term. Since the velocity field is incompressible, i.e.,  [2.x.3504] , the advection term simply reads  [2.x.3505] .
//
[0.x.29066] 
[0.x.29067] 
[0.x.29068] 
[0.x.29069] 
[0.x.29070] 
[0.x.29071] 
[0.x.29072] 
[0.x.29073] 
[0.x.29074] 
[0.x.29075] 
[0.x.29076] 
[0.x.29077] 
[0.x.29078] 
//
[0.x.29079] 
[0.x.29080] 
[0.x.29081] 
[0.x.29082] 
[0.x.29083] 
[0.x.29084] 
//
[0.x.29085] 
[0.x.29086] 
[0.x.29087] 
[0.x.29088] 
//
//  [2.x.3506] 
//
// The HDG solution procedure follows closely that of  [2.x.3507] . The major difference is the use of three different sets of DoFHandler and FE objects, along with the ChunkSparseMatrix and the corresponding solutions vectors. We also use WorkStream to enable a multithreaded local solution process which exploits the embarrassingly parallel nature of the local solver. For WorkStream, we define the local operations on a cell and a copy function into the global matrix and vector. We do this both for the assembly (which is run twice, once when we generate the system matrix and once when we compute the element-interior solutions from the skeleton values) and for the postprocessing where we extract a solution that converges at higher order.
//
[0.x.29089] 
[0.x.29090] 
[0.x.29091] 
[0.x.29092] 
[0.x.29093] 
[0.x.29094] 
[0.x.29095] 
[0.x.29096] 
[0.x.29097] 
//
[0.x.29098] 
[0.x.29099] 
//
[0.x.29100] 
[0.x.29101] 
[0.x.29102] 
[0.x.29103] 
[0.x.29104] 
[0.x.29105] 
[0.x.29106] 
//
// Data for the assembly and solution of the primal variables.
//
[0.x.29107] 
[0.x.29108] 
//
// Post-processing the solution to obtain  [2.x.3508]  is an element-by-element procedure; as such, we do not need to assemble any global data and do not declare any 'task data' for WorkStream to use.
//
[0.x.29109] 
//
// The following three functions are used by WorkStream to do the actual work of the program.
//
[0.x.29110] 
[0.x.29111] 
[0.x.29112] 
[0.x.29113] 
//
[0.x.29114] 
//
[0.x.29115] 
[0.x.29116] 
[0.x.29117] 
[0.x.29118] 
//
[0.x.29119] 
//
// The 'local' solutions are interior to each element.  These represent the primal solution field  [2.x.3509]  as well as the auxiliary field  [2.x.3510] .
//
[0.x.29120] 
[0.x.29121] 
[0.x.29122] 
//
// The new finite element type and corresponding  [2.x.3511]  are used for the global skeleton solution that couples the element-level local solutions.
//
[0.x.29123] 
[0.x.29124] 
[0.x.29125] 
[0.x.29126] 
//
// As stated in the introduction, HDG solutions can be post-processed to attain superconvergence rates of  [2.x.3512] .  The post-processed solution is a discontinuous finite element solution representing the primal variable on the interior of each cell.  We define a FE type of degree  [2.x.3513]  to represent this post-processed solution, which we only use for output after constructing it.
//
[0.x.29127] 
[0.x.29128] 
[0.x.29129] 
//
// The degrees of freedom corresponding to the skeleton strongly enforce Dirichlet boundary conditions, just as in a continuous Galerkin finite element method. We can enforce the boundary conditions in an analogous manner via an AffineConstraints object. In addition, hanging nodes are handled in the same way as for continuous finite elements: For the face elements which only define degrees of freedom on the face, this process sets the solution on the refined side to coincide with the representation on the coarse side.
//
// Note that for HDG, the elimination of hanging nodes is not the only possibility &mdash; in terms of the HDG theory, one could also use the unknowns from the refined side and express the local solution on the coarse side through the trace values on the refined side. However, such a setup is not as easily implemented in terms of deal.II loops and not further analyzed.
//
[0.x.29130] 
//
// The usage of the ChunkSparseMatrix class is similar to the usual sparse matrices: You need a sparsity pattern of type ChunkSparsityPattern and the actual matrix object. When creating the sparsity pattern, we just have to additionally pass the size of local blocks.
//
[0.x.29131] 
[0.x.29132] 
//
// Same as  [2.x.3514] :
//
[0.x.29133] 
[0.x.29134] 
[0.x.29135] 
//[2.x.3515] 
//[2.x.3516]  The constructor is similar to those in other examples, with the exception of handling multiple DoFHandler and FiniteElement objects. Note that we create a system of finite elements for the local DG part, including the gradient/flux part and the scalar part.
//
[0.x.29136] 
[0.x.29137] 
[0.x.29138] 
[0.x.29139] 
[0.x.29140] 
[0.x.29141] 
[0.x.29142] 
[0.x.29143] 
[0.x.29144] 
[0.x.29145] 
//
//  [2.x.3517]  The system for an HDG solution is setup in an analogous manner to most of the other tutorial programs.  We are careful to distribute dofs with all of our DoFHandler objects.  The  [2.x.3518]  and  [2.x.3519]  objects go with the global skeleton solution.
//
[0.x.29146] 
[0.x.29147] 
[0.x.29148] 
[0.x.29149] 
[0.x.29150] 
[0.x.29151] 
//
[0.x.29152] 
[0.x.29153] 
//
[0.x.29154] 
[0.x.29155] 
//
[0.x.29156] 
[0.x.29157] 
//
[0.x.29158] 
[0.x.29159] 
[0.x.29160] 
[0.x.29161] 
[0.x.29162] 
[0.x.29163] 
[0.x.29164] 
[0.x.29165] 
[0.x.29166] 
[0.x.29167] 
//
// When creating the chunk sparsity pattern, we first create the usual dynamic sparsity pattern and then set the chunk size, which is equal to the number of dofs on a face, when copying this into the final sparsity pattern.
//
[0.x.29168] 
[0.x.29169] 
[0.x.29170] 
[0.x.29171] 
[0.x.29172] 
[0.x.29173] 
[0.x.29174] 
//
//  [2.x.3520]  Next comes the definition of the local data structures for the parallel assembly. The first structure  [2.x.3521]  contains the local vector and matrix that are written into the global matrix, whereas the ScratchData contains all data that we need for the local assembly. There is one variable worth noting here, namely the boolean variable  [2.x.3522]  trace_reconstruct. As mentioned in the introduction, we solve the HDG system in two steps. First, we create a linear system for the skeleton system where we condense the local part into it via the Schur complement  [2.x.3523] . Then, we solve for the local part using the skeleton solution. For these two steps, we need the same matrices on the elements twice, which we want to compute by two assembly steps. Since most of the code is similar, we do this with the same function but only switch between the two based on a flag that we set when starting the assembly. Since we need to pass this information on to the local worker routines, we store it once in the task data.
//
[0.x.29175] 
[0.x.29176] 
[0.x.29177] 
[0.x.29178] 
[0.x.29179] 
[0.x.29180] 
//
[0.x.29181] 
//
[0.x.29182] 
[0.x.29183] 
[0.x.29184] 
[0.x.29185] 
[0.x.29186] 
[0.x.29187] 
[0.x.29188] 
//
//  [2.x.3524] 
//[2.x.3525]  contains persistent data for each thread within WorkStream.  The FEValues, matrix, and vector objects should be familiar by now.  There are two objects that need to be discussed:  [2.x.3526]  int> > fe_local_support_on_face` and  [2.x.3527]  int> > fe_support_on_face`.  These are used to indicate whether or not the finite elements chosen have support (non-zero values) on a given face of the reference cell for the local part associated to  [2.x.3528]  and the skeleton part  [2.x.3529]  We extract this information in the constructor and store it once for all cells that we work on.  Had we not stored this information, we would be forced to assemble a large number of zero terms on each cell, which would significantly slow the program.
//
[0.x.29189] 
[0.x.29190] 
[0.x.29191] 
[0.x.29192] 
[0.x.29193] 
[0.x.29194] 
//
[0.x.29195] 
[0.x.29196] 
[0.x.29197] 
[0.x.29198] 
[0.x.29199] 
[0.x.29200] 
//
[0.x.29201] 
[0.x.29202] 
[0.x.29203] 
[0.x.29204] 
[0.x.29205] 
[0.x.29206] 
//
[0.x.29207] 
[0.x.29208] 
//
[0.x.29209] 
[0.x.29210] 
[0.x.29211] 
//
[0.x.29212] 
[0.x.29213] 
[0.x.29214] 
[0.x.29215] 
[0.x.29216] 
[0.x.29217] 
[0.x.29218] 
[0.x.29219] 
[0.x.29220] 
[0.x.29221] 
[0.x.29222] 
[0.x.29223] 
[0.x.29224] 
[0.x.29225] 
[0.x.29226] 
[0.x.29227] 
[0.x.29228] 
[0.x.29229] 
[0.x.29230] 
[0.x.29231] 
[0.x.29232] 
[0.x.29233] 
[0.x.29234] 
[0.x.29235] 
[0.x.29236] 
[0.x.29237] 
[0.x.29238] 
[0.x.29239] 
[0.x.29240] 
[0.x.29241] 
[0.x.29242] 
[0.x.29243] 
[0.x.29244] 
[0.x.29245] 
//
[0.x.29246] 
[0.x.29247] 
[0.x.29248] 
[0.x.29249] 
[0.x.29250] 
[0.x.29251] 
[0.x.29252] 
//
[0.x.29253] 
[0.x.29254] 
[0.x.29255] 
[0.x.29256] 
[0.x.29257] 
[0.x.29258] 
[0.x.29259] 
[0.x.29260] 
[0.x.29261] 
[0.x.29262] 
[0.x.29263] 
[0.x.29264] 
[0.x.29265] 
[0.x.29266] 
[0.x.29267] 
[0.x.29268] 
[0.x.29269] 
[0.x.29270] 
[0.x.29271] 
[0.x.29272] 
[0.x.29273] 
[0.x.29274] 
[0.x.29275] 
[0.x.29276] 
[0.x.29277] 
[0.x.29278] 
[0.x.29279] 
//
//  [2.x.3530] 
//[2.x.3531]  contains the data used by WorkStream when post-processing the local solution  [2.x.3532] .  It is similar, but much simpler, than  [2.x.3533] 
[0.x.29280] 
[0.x.29281] 
[0.x.29282] 
[0.x.29283] 
[0.x.29284] 
//
[0.x.29285] 
[0.x.29286] 
[0.x.29287] 
//
[0.x.29288] 
[0.x.29289] 
//
[0.x.29290] 
[0.x.29291] 
[0.x.29292] 
[0.x.29293] 
[0.x.29294] 
[0.x.29295] 
[0.x.29296] 
[0.x.29297] 
[0.x.29298] 
[0.x.29299] 
[0.x.29300] 
[0.x.29301] 
[0.x.29302] 
//
[0.x.29303] 
[0.x.29304] 
[0.x.29305] 
[0.x.29306] 
[0.x.29307] 
[0.x.29308] 
[0.x.29309] 
[0.x.29310] 
[0.x.29311] 
[0.x.29312] 
[0.x.29313] 
[0.x.29314] 
[0.x.29315] 
[0.x.29316] 
//
//  [2.x.3534]  The  [2.x.3535]  function is similar to the one on  [2.x.3536] , where the quadrature formula and the update flags are set up, and then  [2.x.3537]  is used to do the work in a multi-threaded manner.  The  [2.x.3538]  input parameter is used to decide whether we are solving for the global skeleton solution (false) or the local solution (true).
//
// One thing worth noting for the multi-threaded execution of assembly is the fact that the local computations in `assemble_system_one_cell()` call into BLAS and LAPACK functions if those are available in deal.II. Thus, the underlying BLAS/LAPACK library must support calls from multiple threads at the same time. Most implementations do support this, but some libraries need to be built in a specific way to avoid problems. For example, OpenBLAS compiled without multithreading inside the BLAS/LAPACK calls needs to built with a flag called `USE_LOCKING` set to true.
//
[0.x.29317] 
[0.x.29318] 
[0.x.29319] 
[0.x.29320] 
[0.x.29321] 
//
[0.x.29322] 
[0.x.29323] 
//
[0.x.29324] 
//
[0.x.29325] 
[0.x.29326] 
//
[0.x.29327] 
[0.x.29328] 
[0.x.29329] 
[0.x.29330] 
[0.x.29331] 
[0.x.29332] 
[0.x.29333] 
[0.x.29334] 
//
[0.x.29335] 
[0.x.29336] 
[0.x.29337] 
[0.x.29338] 
[0.x.29339] 
[0.x.29340] 
[0.x.29341] 
[0.x.29342] 
//
//  [2.x.3539]  The real work of the HDG program is done by  [2.x.3540]  Assembling the local matrices  [2.x.3541]  is done here, along with the local contributions of the global matrix  [2.x.3542] .
//
[0.x.29343] 
[0.x.29344] 
[0.x.29345] 
[0.x.29346] 
[0.x.29347] 
[0.x.29348] 
//
// Construct iterator for dof_handler_local for FEValues reinit function.
//
[0.x.29349] 
[0.x.29350] 
[0.x.29351] 
[0.x.29352] 
//
[0.x.29353] 
[0.x.29354] 
[0.x.29355] 
[0.x.29356] 
//
[0.x.29357] 
[0.x.29358] 
//
[0.x.29359] 
[0.x.29360] 
//
[0.x.29361] 
[0.x.29362] 
[0.x.29363] 
[0.x.29364] 
[0.x.29365] 
[0.x.29366] 
[0.x.29367] 
[0.x.29368] 
[0.x.29369] 
[0.x.29370] 
//
// We first compute the cell-interior contribution to  [2.x.3543]  matrix (referred to as matrix  [2.x.3544]  in the introduction) corresponding to local-local coupling, as well as the local right-hand-side vector.  We store the values at each quadrature point for the basis functions, the right-hand-side value, and the convection velocity, in order to have quick access to these fields.
//
[0.x.29371] 
[0.x.29372] 
[0.x.29373] 
[0.x.29374] 
[0.x.29375] 
[0.x.29376] 
[0.x.29377] 
[0.x.29378] 
[0.x.29379] 
[0.x.29380] 
[0.x.29381] 
[0.x.29382] 
[0.x.29383] 
[0.x.29384] 
[0.x.29385] 
[0.x.29386] 
[0.x.29387] 
[0.x.29388] 
[0.x.29389] 
[0.x.29390] 
[0.x.29391] 
[0.x.29392] 
[0.x.29393] 
[0.x.29394] 
[0.x.29395] 
[0.x.29396] 
[0.x.29397] 
[0.x.29398] 
//
// Face terms are assembled on all faces of all elements. This is in contrast to more traditional DG methods, where each face is only visited once in the assembly procedure.
//
[0.x.29399] 
[0.x.29400] 
[0.x.29401] 
[0.x.29402] 
//
// The already obtained  [2.x.3545]  values are needed when solving for the local variables.
//
[0.x.29403] 
[0.x.29404] 
[0.x.29405] 
//
[0.x.29406] 
[0.x.29407] 
[0.x.29408] 
[0.x.29409] 
[0.x.29410] 
[0.x.29411] 
[0.x.29412] 
[0.x.29413] 
[0.x.29414] 
//
//   Here we compute the stabilization parameter discussed in the   introduction: since the diffusion is one and the diffusion   length scale is set to 1/5, it simply results in a contribution   of 5 for the diffusion part and the magnitude of convection   through the element boundary in a centered scheme for the   convection part.
//
[0.x.29415] 
//
//   We store the non-zero flux and scalar values, making use of the   support_on_face information we created in  [2.x.3546] 
[0.x.29416] 
[0.x.29417] 
[0.x.29418] 
[0.x.29419] 
[0.x.29420] 
[0.x.29421] 
[0.x.29422] 
[0.x.29423] 
[0.x.29424] 
[0.x.29425] 
[0.x.29426] 
//
//   When  [2.x.3547]  we are preparing to assemble the   system for the skeleton variable  [2.x.3548] . If this is the case,   we must assemble all local matrices associated with the problem:   local-local, local-face, face-local, and face-face.  The   face-face matrix is stored as  [2.x.3549]  so that   it can be assembled into the global system by  [2.x.3550]    copy_local_to_global.
//
[0.x.29427] 
[0.x.29428] 
[0.x.29429] 
[0.x.29430] 
[0.x.29431] 
[0.x.29432] 
[0.x.29433] 
[0.x.29434] 
[0.x.29435] 
[0.x.29436] 
[0.x.29437] 
[0.x.29438] 
[0.x.29439] 
[0.x.29440] 
[0.x.29441] 
[0.x.29442] 
[0.x.29443] 
[0.x.29444] 
[0.x.29445] 
[0.x.29446] 
[0.x.29447] 
[0.x.29448] 
[0.x.29449] 
//
//             Note the sign of the face_no-local matrix.  We negate             the sign during assembly here so that we can use the              [2.x.3551]  with addition when computing the             Schur complement.
//
[0.x.29450] 
[0.x.29451] 
[0.x.29452] 
[0.x.29453] 
[0.x.29454] 
[0.x.29455] 
//
[0.x.29456] 
[0.x.29457] 
[0.x.29458] 
[0.x.29459] 
[0.x.29460] 
[0.x.29461] 
[0.x.29462] 
[0.x.29463] 
[0.x.29464] 
[0.x.29465] 
[0.x.29466] 
[0.x.29467] 
[0.x.29468] 
[0.x.29469] 
[0.x.29470] 
[0.x.29471] 
//
[0.x.29472] 
[0.x.29473] 
[0.x.29474] 
[0.x.29475] 
[0.x.29476] 
[0.x.29477] 
[0.x.29478] 
[0.x.29479] 
[0.x.29480] 
[0.x.29481] 
[0.x.29482] 
[0.x.29483] 
[0.x.29484] 
[0.x.29485] 
[0.x.29486] 
[0.x.29487] 
[0.x.29488] 
[0.x.29489] 
[0.x.29490] 
//
//   This last term adds the contribution of the term  [2.x.3552]  to the local matrix. As opposed   to the face matrices above, we need it in both assembly stages.
//
[0.x.29491] 
[0.x.29492] 
[0.x.29493] 
[0.x.29494] 
[0.x.29495] 
[0.x.29496] 
[0.x.29497] 
[0.x.29498] 
[0.x.29499] 
[0.x.29500] 
[0.x.29501] 
[0.x.29502] 
[0.x.29503] 
[0.x.29504] 
//
//   When  [2.x.3553]  we are solving for the local   solutions on an element by element basis.  The local   right-hand-side is calculated by replacing the basis functions  [2.x.3554]    tr_phi in the  [2.x.3555]  computation by the computed values  [2.x.3556]    trace_values.  Of course, the sign of the matrix is now minus   since we have moved everything to the other side of the equation.
//
[0.x.29505] 
[0.x.29506] 
[0.x.29507] 
[0.x.29508] 
[0.x.29509] 
[0.x.29510] 
[0.x.29511] 
[0.x.29512] 
[0.x.29513] 
[0.x.29514] 
[0.x.29515] 
[0.x.29516] 
[0.x.29517] 
[0.x.29518] 
//
// Once assembly of all of the local contributions is complete, we must either: (1) assemble the global system, or (2) compute the local solution values and save them. In either case, the first step is to invert the local-local matrix.
//
[0.x.29519] 
//
// For (1), we compute the Schur complement and add it to the  [2.x.3557]  cell_matrix, matrix  [2.x.3558]  in the introduction.
//
[0.x.29520] 
[0.x.29521] 
[0.x.29522] 
[0.x.29523] 
[0.x.29524] 
[0.x.29525] 
[0.x.29526] 
[0.x.29527] 
[0.x.29528] 
//
// For (2), we are simply solving (ll_matrix).(solution_local) = (l_rhs). Hence, we multiply  [2.x.3559]  by our already inverted local-local matrix and store the result using the  [2.x.3560]  function.
//
[0.x.29529] 
[0.x.29530] 
[0.x.29531] 
[0.x.29532] 
[0.x.29533] 
[0.x.29534] 
//
//  [2.x.3561]  If we are in the first step of the solution, i.e.  [2.x.3562]  then we assemble the local matrices into the global system.
//
[0.x.29535] 
[0.x.29536] 
[0.x.29537] 
[0.x.29538] 
[0.x.29539] 
[0.x.29540] 
[0.x.29541] 
[0.x.29542] 
[0.x.29543] 
[0.x.29544] 
//
//  [2.x.3563]  The skeleton solution is solved for by using a BiCGStab solver with identity preconditioner.
//
[0.x.29545] 
[0.x.29546] 
[0.x.29547] 
[0.x.29548] 
[0.x.29549] 
[0.x.29550] 
[0.x.29551] 
//
[0.x.29552] 
[0.x.29553] 
//
[0.x.29554] 
[0.x.29555] 
//
[0.x.29556] 
//
// Once we have solved for the skeleton solution, we can solve for the local solutions in an element-by-element fashion.  We do this by re-using the same  [2.x.3564]  function but switching  [2.x.3565]  to true.
//
[0.x.29557] 
[0.x.29558] 
//
//  [2.x.3566] 
//
// The postprocess method serves two purposes. First, we want to construct a post-processed scalar variables in the element space of degree  [2.x.3567]  that we hope will converge at order  [2.x.3568] . This is again an element-by-element process and only involves the scalar solution as well as the gradient on the local cell. To do this, we introduce the already defined scratch data together with some update flags and run the work stream to do this in parallel.
//
// Secondly, we want to compute discretization errors just as we did in  [2.x.3569] . The overall procedure is similar with calls to  [2.x.3570]  The difference is in how we compute the errors for the scalar variable and the gradient variable. In  [2.x.3571] , we did this by computing  [2.x.3572]  or  [2.x.3573]  contributions. Here, we have a DoFHandler with these two contributions computed and sorted by their vector component,  [2.x.3574]  for the gradient and  [2.x.3575]  for the scalar. To compute their value, we hence use a ComponentSelectFunction with either of them, together with the  [2.x.3576]  SolutionAndGradient class introduced above that contains the analytic parts of either of them. Eventually, we also compute the L2-error of the post-processed solution and add the results into the convergence table.
//
[0.x.29559] 
[0.x.29560] 
[0.x.29561] 
[0.x.29562] 
[0.x.29563] 
[0.x.29564] 
[0.x.29565] 
[0.x.29566] 
//
[0.x.29567] 
[0.x.29568] 
//
[0.x.29569] 
[0.x.29570] 
[0.x.29571] 
[0.x.29572] 
[0.x.29573] 
[0.x.29574] 
[0.x.29575] 
[0.x.29576] 
[0.x.29577] 
[0.x.29578] 
[0.x.29579] 
[0.x.29580] 
//
[0.x.29581] 
//
[0.x.29582] 
[0.x.29583] 
[0.x.29584] 
[0.x.29585] 
[0.x.29586] 
[0.x.29587] 
[0.x.29588] 
[0.x.29589] 
[0.x.29590] 
[0.x.29591] 
[0.x.29592] 
[0.x.29593] 
//
[0.x.29594] 
[0.x.29595] 
[0.x.29596] 
[0.x.29597] 
[0.x.29598] 
[0.x.29599] 
[0.x.29600] 
[0.x.29601] 
[0.x.29602] 
[0.x.29603] 
[0.x.29604] 
[0.x.29605] 
[0.x.29606] 
//
[0.x.29607] 
[0.x.29608] 
[0.x.29609] 
[0.x.29610] 
[0.x.29611] 
[0.x.29612] 
[0.x.29613] 
[0.x.29614] 
[0.x.29615] 
[0.x.29616] 
//
[0.x.29617] 
[0.x.29618] 
//
[0.x.29619] 
[0.x.29620] 
[0.x.29621] 
//
[0.x.29622] 
[0.x.29623] 
[0.x.29624] 
//
[0.x.29625] 
[0.x.29626] 
[0.x.29627] 
[0.x.29628] 
//
//  [2.x.3577] 
//
// This is the actual work done for the postprocessing. According to the discussion in the introduction, we need to set up a system that projects the gradient part of the DG solution onto the gradient of the post-processed variable. Moreover, we need to set the average of the new post-processed variable to equal the average of the scalar DG solution on the cell.
//
// More technically speaking, the projection of the gradient is a system that would potentially fills our  [2.x.3578]  times  [2.x.3579]  matrix but is singular (the sum of all rows would be zero because the constant function has zero gradient). Therefore, we take one row away and use it for imposing the average of the scalar value. We pick the first row for the scalar part, even though we could pick any row for  [2.x.3580]  elements. However, had we used FE_DGP elements instead, the first row would correspond to the constant part already and deleting e.g. the last row would give us a singular system. This way, our program can also be used for those elements.
//
[0.x.29629] 
[0.x.29630] 
[0.x.29631] 
[0.x.29632] 
[0.x.29633] 
[0.x.29634] 
[0.x.29635] 
[0.x.29636] 
[0.x.29637] 
[0.x.29638] 
//
[0.x.29639] 
[0.x.29640] 
//
[0.x.29641] 
[0.x.29642] 
//
[0.x.29643] 
[0.x.29644] 
//
[0.x.29645] 
[0.x.29646] 
[0.x.29647] 
[0.x.29648] 
//
[0.x.29649] 
[0.x.29650] 
[0.x.29651] 
[0.x.29652] 
[0.x.29653] 
[0.x.29654] 
[0.x.29655] 
[0.x.29656] 
[0.x.29657] 
[0.x.29658] 
[0.x.29659] 
[0.x.29660] 
//
[0.x.29661] 
[0.x.29662] 
[0.x.29663] 
[0.x.29664] 
[0.x.29665] 
[0.x.29666] 
[0.x.29667] 
[0.x.29668] 
[0.x.29669] 
[0.x.29670] 
[0.x.29671] 
[0.x.29672] 
[0.x.29673] 
[0.x.29674] 
[0.x.29675] 
[0.x.29676] 
[0.x.29677] 
[0.x.29678] 
[0.x.29679] 
//
// Having assembled all terms, we can again go on and solve the linear system. We invert the matrix and then multiply the inverse by the right hand side. An alternative (and more numerically stable) method would have been to only factorize the matrix and apply the factorization.
//
[0.x.29680] 
[0.x.29681] 
[0.x.29682] 
[0.x.29683] 
//
//  [2.x.3581]  We have 3 sets of results that we would like to output:  the local solution, the post-processed local solution, and the skeleton solution. The former 2 both 'live' on element volumes, whereas the latter lives on codimension-1 surfaces of the triangulation.  Our  [2.x.3582]  function writes all local solutions to the same vtk file, even though they correspond to different DoFHandler objects.  The graphical output for the skeleton variable is done through use of the DataOutFaces class.
//
[0.x.29684] 
[0.x.29685] 
[0.x.29686] 
[0.x.29687] 
[0.x.29688] 
[0.x.29689] 
[0.x.29690] 
[0.x.29691] 
[0.x.29692] 
[0.x.29693] 
[0.x.29694] 
[0.x.29695] 
[0.x.29696] 
[0.x.29697] 
[0.x.29698] 
//
[0.x.29699] 
[0.x.29700] 
//
[0.x.29701] 
[0.x.29702] 
[0.x.29703] 
[0.x.29704] 
//
[0.x.29705] 
//
// We first define the names and types of the local solution, and add the data to  [2.x.3583] 
[0.x.29706] 
[0.x.29707] 
[0.x.29708] 
[0.x.29709] 
[0.x.29710] 
[0.x.29711] 
[0.x.29712] 
[0.x.29713] 
[0.x.29714] 
[0.x.29715] 
[0.x.29716] 
//
// The second data item we add is the post-processed solution. In this case, it is a single scalar variable belonging to a different DoFHandler.
//
[0.x.29717] 
[0.x.29718] 
[0.x.29719] 
[0.x.29720] 
[0.x.29721] 
[0.x.29722] 
[0.x.29723] 
//
[0.x.29724] 
[0.x.29725] 
//
[0.x.29726] 
[0.x.29727] 
[0.x.29728] 
[0.x.29729] 
//
// The  [2.x.3584]  class works analogously to the  [2.x.3585]  that defines the solution on the skeleton of the triangulation.  We treat it as such here, and the code is similar to that above.
//
[0.x.29730] 
[0.x.29731] 
[0.x.29732] 
[0.x.29733] 
//
[0.x.29734] 
[0.x.29735] 
[0.x.29736] 
[0.x.29737] 
//
[0.x.29738] 
[0.x.29739] 
[0.x.29740] 
//[2.x.3586] 
//
// We implement two different refinement cases for HDG, just as in  [2.x.3587] : adaptive_refinement and global_refinement.  The global_refinement option recreates the entire triangulation every time. This is because we want to use a finer sequence of meshes than what we would get with one refinement step, namely 2, 3, 4, 6, 8, 12, 16, ... elements per direction.
//
// The adaptive_refinement mode uses the  [2.x.3588]  to give a decent indication of the non-regular regions in the scalar local solutions.
//
[0.x.29741] 
[0.x.29742] 
[0.x.29743] 
[0.x.29744] 
[0.x.29745] 
[0.x.29746] 
[0.x.29747] 
[0.x.29748] 
[0.x.29749] 
[0.x.29750] 
[0.x.29751] 
[0.x.29752] 
[0.x.29753] 
[0.x.29754] 
[0.x.29755] 
[0.x.29756] 
[0.x.29757] 
[0.x.29758] 
[0.x.29759] 
[0.x.29760] 
[0.x.29761] 
//
[0.x.29762] 
[0.x.29763] 
[0.x.29764] 
[0.x.29765] 
//
[0.x.29766] 
[0.x.29767] 
[0.x.29768] 
[0.x.29769] 
[0.x.29770] 
[0.x.29771] 
[0.x.29772] 
[0.x.29773] 
[0.x.29774] 
[0.x.29775] 
//
[0.x.29776] 
[0.x.29777] 
//
[0.x.29778] 
//
[0.x.29779] 
[0.x.29780] 
//
[0.x.29781] 
[0.x.29782] 
[0.x.29783] 
[0.x.29784] 
[0.x.29785] 
//
// Just as in  [2.x.3589] , we set the boundary indicator of two of the faces to 1 where we want to specify Neumann boundary conditions instead of Dirichlet conditions. Since we re-create the triangulation every time for global refinement, the flags are set in every refinement step, not just at the beginning.
//
[0.x.29786] 
[0.x.29787] 
[0.x.29788] 
[0.x.29789] 
[0.x.29790] 
[0.x.29791] 
[0.x.29792] 
//[2.x.3590]  The functionality here is basically the same as  [2.x.3591] . We loop over 10 cycles, refining the grid on each one.  At the end, convergence tables are created.
//
[0.x.29793] 
[0.x.29794] 
[0.x.29795] 
[0.x.29796] 
[0.x.29797] 
[0.x.29798] 
//
[0.x.29799] 
[0.x.29800] 
[0.x.29801] 
[0.x.29802] 
[0.x.29803] 
[0.x.29804] 
[0.x.29805] 
//
// There is one minor change for the convergence table compared to  [2.x.3592] : Since we did not refine our mesh by a factor two in each cycle (but rather used the sequence 2, 3, 4, 6, 8, 12, ...), we need to tell the convergence rate evaluation about this. We do this by setting the number of cells as a reference column and additionally specifying the dimension of the problem, which gives the necessary information for the relation between number of cells and mesh size.
//
[0.x.29806] 
[0.x.29807] 
[0.x.29808] 
[0.x.29809] 
[0.x.29810] 
[0.x.29811] 
[0.x.29812] 
[0.x.29813] 
[0.x.29814] 
[0.x.29815] 
[0.x.29816] 
//
[0.x.29817] 
//
[0.x.29818] 
[0.x.29819] 
[0.x.29820] 
//
[0.x.29821] 
[0.x.29822] 
//
// Now for the three calls to the main class in complete analogy to  [2.x.3593] .
//
[0.x.29823] 
[0.x.29824] 
[0.x.29825] 
[0.x.29826] 
[0.x.29827] 
[0.x.29828] 
//
[0.x.29829] 
[0.x.29830] 
//
[0.x.29831] 
[0.x.29832] 
//
[0.x.29833] 
[0.x.29834] 
[0.x.29835] 
[0.x.29836] 
//
[0.x.29837] 
[0.x.29838] 
//
[0.x.29839] 
[0.x.29840] 
//
[0.x.29841] 
[0.x.29842] 
[0.x.29843] 
[0.x.29844] 
//
[0.x.29845] 
[0.x.29846] 
//
[0.x.29847] 
[0.x.29848] 
[0.x.29849] 
[0.x.29850] 
[0.x.29851] 
[0.x.29852] 
[0.x.29853] 
[0.x.29854] 
[0.x.29855] 
[0.x.29856] 
[0.x.29857] 
[0.x.29858] 
[0.x.29859] 
[0.x.29860] 
[0.x.29861] 
[0.x.29862] 
[0.x.29863] 
[0.x.29864] 
[0.x.29865] 
[0.x.29866] 
[0.x.29867] 
[0.x.29868] 
[0.x.29869] 
[0.x.29870] 
[0.x.29871] 
[0.x.29872] 
[0.x.29873] 
[0.x.29874] 
//
[0.x.29875] 
[0.x.29876] 
[0.x.29877] 
[0.x.29878] 
[0.x.29879] 
[0.x.29880] 
[0.x.29881] 
[0.x.29882] 
[0.x.29883] 
[0.x.29884] 
[0.x.29885] 
[0.x.29886] 
[0.x.29887] 
[0.x.29888] 
[0.x.29889] 
[0.x.29890] 
//
[0.x.29891] 
[0.x.29892] 
[0.x.29893] 
//[2.x.3594] 
//
// The first task as usual is to include the functionality of these well-known deal.II library files and some C++ header files.
//
[0.x.29894] 
[0.x.29895] 
[0.x.29896] 
//
[0.x.29897] 
[0.x.29898] 
[0.x.29899] 
//
[0.x.29900] 
[0.x.29901] 
//
[0.x.29902] 
[0.x.29903] 
//
[0.x.29904] 
[0.x.29905] 
//
[0.x.29906] 
[0.x.29907] 
//
[0.x.29908] 
[0.x.29909] 
[0.x.29910] 
[0.x.29911] 
//
// This is the only include file that is new: It includes all the Runge-Kutta methods.
//
[0.x.29912] 
//
// The next step is like in all previous tutorial programs: We put everything into a namespace of its own and then import the deal.II classes and functions into it.
//
[0.x.29913] 
[0.x.29914] 
[0.x.29915] 
//[2.x.3595] 
//
// The next piece is the declaration of the main class. Most of the functions in this class are not new and have been explained in previous tutorials. The only interesting functions are  [2.x.3596]  and  [2.x.3597]  evaluates the diffusion equation,  [2.x.3598] , at a given time and a given  [2.x.3599] .  [2.x.3600]  evaluates  [2.x.3601]  or equivalently  [2.x.3602]  at a given time, for a given  [2.x.3603]  and  [2.x.3604] . This function is needed when an implicit method is used.
//
[0.x.29916] 
[0.x.29917] 
[0.x.29918] 
[0.x.29919] 
//
[0.x.29920] 
//
[0.x.29921] 
[0.x.29922] 
//
[0.x.29923] 
//
[0.x.29924] 
//
[0.x.29925] 
[0.x.29926] 
//
[0.x.29927] 
[0.x.29928] 
[0.x.29929] 
//
[0.x.29930] 
[0.x.29931] 
[0.x.29932] 
//
// The next three functions are the drivers for the explicit methods, the implicit methods, and the embedded explicit methods respectively. The driver function for embedded explicit methods returns the number of steps executed given that it only takes the number of time steps passed as an argument as a hint, but internally computed the optimal time step itself.
//
[0.x.29933] 
[0.x.29934] 
[0.x.29935] 
[0.x.29936] 
//
[0.x.29937] 
[0.x.29938] 
[0.x.29939] 
[0.x.29940] 
//
[0.x.29941] 
[0.x.29942] 
[0.x.29943] 
[0.x.29944] 
[0.x.29945] 
//
[0.x.29946] 
//
[0.x.29947] 
[0.x.29948] 
//
[0.x.29949] 
//
[0.x.29950] 
//
[0.x.29951] 
//
[0.x.29952] 
//
[0.x.29953] 
//
[0.x.29954] 
[0.x.29955] 
[0.x.29956] 
//
[0.x.29957] 
//
[0.x.29958] 
[0.x.29959] 
//
// We choose quadratic finite elements and we initialize the parameters.
//
[0.x.29960] 
[0.x.29961] 
[0.x.29962] 
[0.x.29963] 
[0.x.29964] 
[0.x.29965] 
[0.x.29966] 
//
//  [2.x.3605]  Now, we create the constraint matrix and the sparsity pattern. Then, we initialize the matrices and the solution vector.
//
[0.x.29967] 
[0.x.29968] 
[0.x.29969] 
//
[0.x.29970] 
[0.x.29971] 
[0.x.29972] 
[0.x.29973] 
[0.x.29974] 
//
[0.x.29975] 
[0.x.29976] 
[0.x.29977] 
//
[0.x.29978] 
[0.x.29979] 
[0.x.29980] 
[0.x.29981] 
[0.x.29982] 
//
//  [2.x.3606]  In this function, we compute  [2.x.3607]  and the mass matrix  [2.x.3608] . The mass matrix is then inverted using a direct solver; the  [2.x.3609]  variable will then store the inverse of the mass matrix so that  [2.x.3610]  can be applied to a vector using the  [2.x.3611]  function of that object. (Internally, UMFPACK does not really store the inverse of the matrix, but its LU factors; applying the inverse matrix is then equivalent to doing one forward and one backward solves with these two factors, which has the same complexity as applying an explicit inverse of the matrix).
//
[0.x.29983] 
[0.x.29984] 
[0.x.29985] 
[0.x.29986] 
//
[0.x.29987] 
//
[0.x.29988] 
[0.x.29989] 
[0.x.29990] 
//
[0.x.29991] 
[0.x.29992] 
//
[0.x.29993] 
[0.x.29994] 
//
[0.x.29995] 
//
[0.x.29996] 
[0.x.29997] 
[0.x.29998] 
[0.x.29999] 
//
[0.x.30000] 
//
[0.x.30001] 
[0.x.30002] 
[0.x.30003] 
[0.x.30004] 
[0.x.30005] 
[0.x.30006] 
[0.x.30007] 
[0.x.30008] 
[0.x.30009] 
[0.x.30010] 
[0.x.30011] 
[0.x.30012] 
[0.x.30013] 
[0.x.30014] 
[0.x.30015] 
[0.x.30016] 
//
[0.x.30017] 
//
[0.x.30018] 
[0.x.30019] 
[0.x.30020] 
[0.x.30021] 
[0.x.30022] 
[0.x.30023] 
[0.x.30024] 
//
[0.x.30025] 
[0.x.30026] 
//
//  [2.x.3612] 
//
// In this function, the source term of the equation for a given time and a given point is computed.
//
[0.x.30027] 
[0.x.30028] 
[0.x.30029] 
[0.x.30030] 
[0.x.30031] 
[0.x.30032] 
//
[0.x.30033] 
[0.x.30034] 
[0.x.30035] 
[0.x.30036] 
[0.x.30037] 
[0.x.30038] 
//
//  [2.x.3613] 
//
// Next, we evaluate the weak form of the diffusion equation at a given time  [2.x.3614]  and for a given vector  [2.x.3615] . In other words, as outlined in the introduction, we evaluate  [2.x.3616] . For this, we have to apply the matrix  [2.x.3617]  (previously computed and stored in the variable  [2.x.3618] ) to  [2.x.3619]  and then add the source term which we integrate as we usually do. (Integrating up the solution could be done using  [2.x.3620]  if you wanted to save a few lines of code, or wanted to take advantage of doing the integration in parallel.) The result is then multiplied by  [2.x.3621] .
//
[0.x.30039] 
[0.x.30040] 
[0.x.30041] 
[0.x.30042] 
[0.x.30043] 
[0.x.30044] 
//
[0.x.30045] 
//
[0.x.30046] 
[0.x.30047] 
[0.x.30048] 
[0.x.30049] 
//
[0.x.30050] 
[0.x.30051] 
//
[0.x.30052] 
//
[0.x.30053] 
//
[0.x.30054] 
[0.x.30055] 
[0.x.30056] 
//
[0.x.30057] 
//
[0.x.30058] 
[0.x.30059] 
[0.x.30060] 
[0.x.30061] 
[0.x.30062] 
[0.x.30063] 
[0.x.30064] 
[0.x.30065] 
[0.x.30066] 
//
[0.x.30067] 
//
[0.x.30068] 
[0.x.30069] 
[0.x.30070] 
[0.x.30071] 
//
[0.x.30072] 
[0.x.30073] 
//
[0.x.30074] 
[0.x.30075] 
//[2.x.3622] 
//
// We compute  [2.x.3623] . This is done in several steps:  
//
// - compute  [2.x.3624]   
//
// - invert the matrix to get  [2.x.3625]   
//
// - compute  [2.x.3626]   
//
// - compute  [2.x.3627]   
//
// - return z.
//
[0.x.30076] 
[0.x.30077] 
[0.x.30078] 
[0.x.30079] 
[0.x.30080] 
//
[0.x.30081] 
[0.x.30082] 
//
[0.x.30083] 
//
[0.x.30084] 
[0.x.30085] 
//
[0.x.30086] 
[0.x.30087] 
//
[0.x.30088] 
[0.x.30089] 
//
//  [2.x.3628] 
//
// The following function then outputs the solution in vtu files indexed by the number of the time step and the name of the time stepping method. Of course, the (exact) result should really be the same for all time stepping method, but the output here at least allows us to compare them.
//
[0.x.30090] 
[0.x.30091] 
[0.x.30092] 
[0.x.30093] 
[0.x.30094] 
//
[0.x.30095] 
[0.x.30096] 
[0.x.30097] 
[0.x.30098] 
[0.x.30099] 
[0.x.30100] 
[0.x.30101] 
[0.x.30102] 
[0.x.30103] 
[0.x.30104] 
[0.x.30105] 
[0.x.30106] 
[0.x.30107] 
[0.x.30108] 
[0.x.30109] 
[0.x.30110] 
[0.x.30111] 
[0.x.30112] 
[0.x.30113] 
[0.x.30114] 
[0.x.30115] 
[0.x.30116] 
[0.x.30117] 
[0.x.30118] 
[0.x.30119] 
[0.x.30120] 
[0.x.30121] 
[0.x.30122] 
[0.x.30123] 
[0.x.30124] 
[0.x.30125] 
[0.x.30126] 
[0.x.30127] 
[0.x.30128] 
[0.x.30129] 
[0.x.30130] 
[0.x.30131] 
[0.x.30132] 
[0.x.30133] 
[0.x.30134] 
[0.x.30135] 
[0.x.30136] 
[0.x.30137] 
[0.x.30138] 
[0.x.30139] 
[0.x.30140] 
[0.x.30141] 
[0.x.30142] 
[0.x.30143] 
[0.x.30144] 
[0.x.30145] 
[0.x.30146] 
[0.x.30147] 
[0.x.30148] 
[0.x.30149] 
[0.x.30150] 
[0.x.30151] 
[0.x.30152] 
[0.x.30153] 
[0.x.30154] 
[0.x.30155] 
[0.x.30156] 
//
[0.x.30157] 
//
[0.x.30158] 
[0.x.30159] 
//
[0.x.30160] 
//
[0.x.30161] 
//
[0.x.30162] 
[0.x.30163] 
[0.x.30164] 
[0.x.30165] 
[0.x.30166] 
//
[0.x.30167] 
//
[0.x.30168] 
[0.x.30169] 
[0.x.30170] 
[0.x.30171] 
[0.x.30172] 
[0.x.30173] 
[0.x.30174] 
[0.x.30175] 
[0.x.30176] 
[0.x.30177] 
[0.x.30178] 
[0.x.30179] 
//[2.x.3629] 
//
// This function is the driver for all the explicit methods. At the top it initializes the time stepping and the solution (by setting it to zero and then ensuring that boundary value and hanging node constraints are respected; of course, with the mesh we use here, hanging node constraints are not in fact an issue). It then calls  [2.x.3630]  which performs one time step. Time is stored and incremented through a DiscreteTime object.
//
// For explicit methods,  [2.x.3631]  needs to evaluate  [2.x.3632] , i.e, it needs  [2.x.3633] . Because  [2.x.3634]  is a member function, it needs to be bound to  [2.x.3635] . After each evolution step, we again apply the correct boundary values and hanging node constraints.
//
// Finally, the solution is output every 10 time steps.
//
[0.x.30180] 
[0.x.30181] 
[0.x.30182] 
[0.x.30183] 
[0.x.30184] 
[0.x.30185] 
[0.x.30186] 
//
[0.x.30187] 
[0.x.30188] 
//
[0.x.30189] 
[0.x.30190] 
[0.x.30191] 
[0.x.30192] 
[0.x.30193] 
[0.x.30194] 
[0.x.30195] 
[0.x.30196] 
[0.x.30197] 
[0.x.30198] 
[0.x.30199] 
[0.x.30200] 
[0.x.30201] 
[0.x.30202] 
//
[0.x.30203] 
//
[0.x.30204] 
[0.x.30205] 
[0.x.30206] 
[0.x.30207] 
[0.x.30208] 
[0.x.30209] 
//
//  [2.x.3636]  This function is equivalent to  [2.x.3637]  but for implicit methods. When using implicit methods, we need to evaluate  [2.x.3638]  and  [2.x.3639]  for which we use the two member functions previously introduced.
//
[0.x.30210] 
[0.x.30211] 
[0.x.30212] 
[0.x.30213] 
[0.x.30214] 
[0.x.30215] 
[0.x.30216] 
//
[0.x.30217] 
[0.x.30218] 
//
[0.x.30219] 
[0.x.30220] 
[0.x.30221] 
[0.x.30222] 
[0.x.30223] 
[0.x.30224] 
[0.x.30225] 
[0.x.30226] 
[0.x.30227] 
[0.x.30228] 
[0.x.30229] 
[0.x.30230] 
[0.x.30231] 
[0.x.30232] 
[0.x.30233] 
[0.x.30234] 
[0.x.30235] 
//
[0.x.30236] 
//
[0.x.30237] 
[0.x.30238] 
[0.x.30239] 
[0.x.30240] 
[0.x.30241] 
[0.x.30242] 
//
//  [2.x.3640]  This function is the driver for the embedded explicit methods. It requires more parameters:  
//
// - coarsen_param: factor multiplying the current time step when the error   is below the threshold.  
//
// - refine_param: factor multiplying the current time step when the error   is above the threshold.  
//
// - min_delta: smallest time step acceptable.  
//
// - max_delta: largest time step acceptable.  
//
// - refine_tol: threshold above which the time step is refined.  
//
// - coarsen_tol: threshold below which the time step is coarsen.
//
// Embedded methods use a guessed time step. If the error using this time step is too large, the time step will be reduced. If the error is below the threshold, a larger time step will be tried for the next time step.  [2.x.3641]  is the guessed time step produced by the embedded method. In summary, time step size is potentially modified in three ways:  
//
// - Reducing or increasing time step size within      [2.x.3642]   
//
// - Using the calculated  [2.x.3643] .  
//
// - Automatically adjusting the step size of the last time step to ensure     simulation ends precisely at  [2.x.3644] . This adjustment     is handled inside the DiscreteTime instance.
//
[0.x.30243] 
[0.x.30244] 
[0.x.30245] 
[0.x.30246] 
[0.x.30247] 
[0.x.30248] 
[0.x.30249] 
[0.x.30250] 
[0.x.30251] 
[0.x.30252] 
[0.x.30253] 
[0.x.30254] 
[0.x.30255] 
[0.x.30256] 
//
[0.x.30257] 
[0.x.30258] 
//
[0.x.30259] 
[0.x.30260] 
[0.x.30261] 
[0.x.30262] 
[0.x.30263] 
[0.x.30264] 
[0.x.30265] 
[0.x.30266] 
[0.x.30267] 
[0.x.30268] 
[0.x.30269] 
[0.x.30270] 
[0.x.30271] 
[0.x.30272] 
[0.x.30273] 
[0.x.30274] 
[0.x.30275] 
[0.x.30276] 
[0.x.30277] 
[0.x.30278] 
[0.x.30279] 
[0.x.30280] 
//
[0.x.30281] 
//
[0.x.30282] 
[0.x.30283] 
[0.x.30284] 
[0.x.30285] 
//
[0.x.30286] 
[0.x.30287] 
[0.x.30288] 
//
[0.x.30289] 
[0.x.30290] 
//
//  [2.x.3645] 
//
// The following is the main function of the program. At the top, we create the grid (a [0,5]x[0,5] square) and refine it four times to get a mesh that has 16 by 16 cells, for a total of 256.  We then set the boundary indicator to 1 for those parts of the boundary where  [2.x.3646]  and  [2.x.3647] .
//
[0.x.30291] 
[0.x.30292] 
[0.x.30293] 
[0.x.30294] 
//
[0.x.30295] 
[0.x.30296] 
[0.x.30297] 
[0.x.30298] 
[0.x.30299] 
[0.x.30300] 
[0.x.30301] 
[0.x.30302] 
[0.x.30303] 
//
// Next, we set up the linear systems and fill them with content so that they can be used throughout the time stepping process:
//
[0.x.30304] 
//
[0.x.30305] 
//
// Finally, we solve the diffusion problem using several of the Runge-Kutta methods implemented in namespace TimeStepping, each time outputting the error at the end time. (As explained in the introduction, since the exact solution is zero at the final time, the error equals the numerical solution and can be computed by just taking the  [2.x.3648]  norm of the solution vector.)
//
[0.x.30306] 
[0.x.30307] 
[0.x.30308] 
[0.x.30309] 
//
[0.x.30310] 
[0.x.30311] 
[0.x.30312] 
[0.x.30313] 
[0.x.30314] 
[0.x.30315] 
[0.x.30316] 
//
[0.x.30317] 
[0.x.30318] 
[0.x.30319] 
[0.x.30320] 
[0.x.30321] 
[0.x.30322] 
//
[0.x.30323] 
[0.x.30324] 
[0.x.30325] 
[0.x.30326] 
[0.x.30327] 
[0.x.30328] 
[0.x.30329] 
//
[0.x.30330] 
[0.x.30331] 
[0.x.30332] 
[0.x.30333] 
[0.x.30334] 
[0.x.30335] 
[0.x.30336] 
//
[0.x.30337] 
[0.x.30338] 
[0.x.30339] 
[0.x.30340] 
[0.x.30341] 
[0.x.30342] 
//
[0.x.30343] 
[0.x.30344] 
[0.x.30345] 
[0.x.30346] 
[0.x.30347] 
[0.x.30348] 
//
[0.x.30349] 
[0.x.30350] 
[0.x.30351] 
[0.x.30352] 
[0.x.30353] 
[0.x.30354] 
[0.x.30355] 
//
[0.x.30356] 
[0.x.30357] 
[0.x.30358] 
[0.x.30359] 
[0.x.30360] 
[0.x.30361] 
[0.x.30362] 
[0.x.30363] 
//
[0.x.30364] 
[0.x.30365] 
[0.x.30366] 
[0.x.30367] 
[0.x.30368] 
[0.x.30369] 
[0.x.30370] 
//
[0.x.30371] 
[0.x.30372] 
[0.x.30373] 
[0.x.30374] 
[0.x.30375] 
[0.x.30376] 
[0.x.30377] 
//
[0.x.30378] 
[0.x.30379] 
[0.x.30380] 
[0.x.30381] 
[0.x.30382] 
[0.x.30383] 
[0.x.30384] 
//
[0.x.30385] 
[0.x.30386] 
[0.x.30387] 
[0.x.30388] 
[0.x.30389] 
[0.x.30390] 
[0.x.30391] 
[0.x.30392] 
[0.x.30393] 
//
//  [2.x.3649] 
//
// The following  [2.x.3650]  function is similar to previous examples and need not be commented on.
//
[0.x.30394] 
[0.x.30395] 
[0.x.30396] 
[0.x.30397] 
[0.x.30398] 
[0.x.30399] 
[0.x.30400] 
[0.x.30401] 
[0.x.30402] 
[0.x.30403] 
[0.x.30404] 
[0.x.30405] 
[0.x.30406] 
[0.x.30407] 
[0.x.30408] 
[0.x.30409] 
[0.x.30410] 
[0.x.30411] 
[0.x.30412] 
[0.x.30413] 
[0.x.30414] 
[0.x.30415] 
[0.x.30416] 
[0.x.30417] 
[0.x.30418] 
[0.x.30419] 
[0.x.30420] 
[0.x.30421] 
[0.x.30422] 
[0.x.30423] 
[0.x.30424] 
[0.x.30425] 
//
[0.x.30426] 
[0.x.30427] 
[0.x.30428] 
[0.x.30429] 
[0.x.30430] 
[0.x.30431] 
[0.x.30432] 
[0.x.30433] 
[0.x.30434] 
[0.x.30435] 
[0.x.30436] 
[0.x.30437] 
[0.x.30438] 
[0.x.30439] 
[0.x.30440] 
[0.x.30441] 
//
[0.x.30442] 
[0.x.30443] 
[0.x.30444] 
[0.x.30445] 
[0.x.30446] 
//
// Let us start with the include files we need here. Obviously, we need the ones that describe the triangulation ( [2.x.3651] ), and that allow us to create and output triangulations ( [2.x.3652]  and  [2.x.3653] ). Furthermore, we need the header file that declares the Manifold and ChartManifold classes that we will need to describe the geometry ( [2.x.3654] ). We will then also need the  [2.x.3655]  function from the last of the following header files; the purpose for this function will become discussed at the point where we use it.
//
[0.x.30447] 
[0.x.30448] 
[0.x.30449] 
[0.x.30450] 
[0.x.30451] 
//
// The remainder of the include files relate to reading the topography data. As explained in the introduction, we will read it from a file and then use the  [2.x.3656]  class that is declared in the first of the following header files. Because the data is large, the file we read from is stored as gzip compressed data and we make use of some BOOST-provided functionality to read directly from gzipped data.
//
[0.x.30452] 
//
[0.x.30453] 
[0.x.30454] 
[0.x.30455] 
//
[0.x.30456] 
[0.x.30457] 
[0.x.30458] 
//
// The final part of the top matter is to open a namespace into which to put everything, and then to import the dealii namespace into it.
//
[0.x.30459] 
[0.x.30460] 
[0.x.30461] 
//[2.x.3657] 
//
// The first significant part of this program is the class that describes the topography  [2.x.3658]  as a function of longitude and latitude. As discussed in the introduction, we will make our life a bit easier here by not writing the class in the most general way possible but by only writing it for the particular purpose we are interested in here: interpolating data obtained from one very specific data file that contains information about a particular area of the world for which we know the extents.
//
// The general layout of the class has been discussed already above. Following is its declaration, including three static member functions that we will need in initializing the  [2.x.3659]  member variable.
//
[0.x.30462] 
[0.x.30463] 
[0.x.30464] 
[0.x.30465] 
//
[0.x.30466] 
//
[0.x.30467] 
[0.x.30468] 
//
[0.x.30469] 
[0.x.30470] 
//
// Let us move to the implementation of the class. The interesting parts of the class are the constructor and the  [2.x.3660]  function. The former initializes the  [2.x.3661]  member variable and we will use the constructor that requires us to pass in the end points of the 2-dimensional data set we want to interpolate (which are here given by the intervals  [2.x.3662] , using the trick of switching end points discussed in the introduction, and  [2.x.3663] , both given in degrees), the number of intervals into which the data is split (379 in latitude direction and 219 in longitude direction, for a total of  [2.x.3664]  data points), and a Table object that contains the data. The data then of course has size  [2.x.3665]  and we initialize it by providing an iterator to the first of the 83,600 elements of a  [2.x.3666]  object returned by the  [2.x.3667]  function below. Note that all of the member functions we call here are static because (i) they do not access any member variables of the class, and (ii) because they are called at a time when the object is not initialized fully anyway.
//
[0.x.30471] 
[0.x.30472] 
[0.x.30473] 
[0.x.30474] 
[0.x.30475] 
[0.x.30476] 
//
[0.x.30477] 
[0.x.30478] 
[0.x.30479] 
[0.x.30480] 
[0.x.30481] 
//
// The only other function of greater interest is the  [2.x.3668]  function. It returns a temporary vector that contains all 83,600 data points describing the altitude and is read from the file  [2.x.3669] . Because the file is compressed by gzip, we cannot just read it through an object of type  [2.x.3670]  but there are convenient methods in the BOOST library (see http:www.boost.org) that allows us to read from compressed files without first having to uncompress it on disk. The result is, basically, just another input stream that, for all practical purposes, looks just like the ones we always use.
//
// When reading the data, we read the three columns but throw ignore the first two. The datum in the last column is appended to an array that we the return and that will be copied into the table from which  [2.x.3671]  is initialized. Since the BOOST.iostreams library does not provide a very useful exception when the input file does not exist, is not readable, or does not contain the correct number of data lines, we catch all exceptions it may produce and create our own one. To this end, in the  [2.x.3672]  clause, we let the program run into an  [2.x.3673]  statement. Since the condition is always false, this always triggers an exception. In other words, this is equivalent to writing  [2.x.3674]  but it also fills certain fields in the exception object that will later be printed on the screen identifying the function, file and line where the exception happened.
//
[0.x.30482] 
[0.x.30483] 
[0.x.30484] 
//
// create a stream where we read from gzipped data
//
[0.x.30485] 
[0.x.30486] 
[0.x.30487] 
//
[0.x.30488] 
[0.x.30489] 
[0.x.30490] 
[0.x.30491] 
[0.x.30492] 
[0.x.30493] 
//
[0.x.30494] 
[0.x.30495] 
[0.x.30496] 
[0.x.30497] 
[0.x.30498] 
[0.x.30499] 
[0.x.30500] 
[0.x.30501] 
[0.x.30502] 
//
[0.x.30503] 
[0.x.30504] 
//[2.x.3675] 
//
// The following class is then the main one of this program. Its structure has been described in much detail in the introduction and does not need much introduction any more.
//
[0.x.30505] 
[0.x.30506] 
[0.x.30507] 
[0.x.30508] 
//
[0.x.30509] 
//
[0.x.30510] 
//
[0.x.30511] 
[0.x.30512] 
[0.x.30513] 
//
[0.x.30514] 
//
[0.x.30515] 
[0.x.30516] 
//
[0.x.30517] 
[0.x.30518] 
[0.x.30519] 
//
[0.x.30520] 
[0.x.30521] 
//
// The implementation, as well, is pretty straightforward if you have read the introduction. In particular, both of the pull back and push forward functions are just concatenations of the respective functions of the WGS 84 and topography mappings:
//
[0.x.30522] 
[0.x.30523] 
[0.x.30524] 
[0.x.30525] 
//
[0.x.30526] 
[0.x.30527] 
[0.x.30528] 
[0.x.30529] 
//
// The next function is required by the interface of the Manifold base class, and allows cloning the AfricaGeometry class. Notice that, while the function returns a  [2.x.3676]  we internally create a `unique_ptr<AfricaGeometry>`. In other words, the library requires a pointer-to-base-class, which we provide by creating a pointer-to-derived-class.
//
[0.x.30530] 
[0.x.30531] 
[0.x.30532] 
[0.x.30533] 
//
// The following two functions then define the forward and inverse transformations that correspond to the WGS 84 reference shape of Earth. The forward transform follows the formula shown in the introduction. The inverse transform is significantly more complicated and is, at the very least, not intuitive. It also suffers from the fact that it returns an angle that at the end of the function we need to clip back into the interval  [2.x.3677]  if it should have escaped from there.
//
[0.x.30534] 
[0.x.30535] 
[0.x.30536] 
[0.x.30537] 
[0.x.30538] 
//
[0.x.30539] 
[0.x.30540] 
//
[0.x.30541] 
[0.x.30542] 
[0.x.30543] 
[0.x.30544] 
//
[0.x.30545] 
[0.x.30546] 
[0.x.30547] 
[0.x.30548] 
[0.x.30549] 
[0.x.30550] 
[0.x.30551] 
[0.x.30552] 
[0.x.30553] 
[0.x.30554] 
[0.x.30555] 
[0.x.30556] 
[0.x.30557] 
[0.x.30558] 
[0.x.30559] 
//
[0.x.30560] 
[0.x.30561] 
[0.x.30562] 
[0.x.30563] 
[0.x.30564] 
[0.x.30565] 
[0.x.30566] 
[0.x.30567] 
[0.x.30568] 
[0.x.30569] 
[0.x.30570] 
//
// In contrast, the topography transformations follow exactly the description in the introduction. There is not consequently not much to add:
//
[0.x.30571] 
[0.x.30572] 
[0.x.30573] 
[0.x.30574] 
[0.x.30575] 
[0.x.30576] 
[0.x.30577] 
[0.x.30578] 
//
[0.x.30579] 
[0.x.30580] 
[0.x.30581] 
[0.x.30582] 
[0.x.30583] 
[0.x.30584] 
[0.x.30585] 
//[2.x.3678] 
//
// Having so described the properties of the geometry, not it is time to deal with the mesh used to discretize it. To this end, we create objects for the geometry and triangulation, and then proceed to create a  [2.x.3679]  rectangular mesh that corresponds to the reference domain  [2.x.3680] . We choose this number of subdivisions because it leads to cells that are roughly like cubes instead of stretched in one direction or another.
//
// Of course, we are not actually interested in meshing the reference domain. We are interested in meshing the real domain. Consequently, we will use the  [2.x.3681]  function that simply moves every point of a triangulation according to a given transformation. The transformation function it wants is a function that takes as its single argument a point in the reference domain and returns the corresponding location in the domain that we want to map to. This is, of course, exactly the push forward function of the geometry we use. We wrap it by a lambda function to obtain the kind of function object required for the transformation.
//
[0.x.30586] 
[0.x.30587] 
[0.x.30588] 
[0.x.30589] 
//
[0.x.30590] 
[0.x.30591] 
[0.x.30592] 
[0.x.30593] 
[0.x.30594] 
[0.x.30595] 
[0.x.30596] 
[0.x.30597] 
[0.x.30598] 
[0.x.30599] 
//
[0.x.30600] 
[0.x.30601] 
[0.x.30602] 
[0.x.30603] 
[0.x.30604] 
[0.x.30605] 
//
// The next step is to explain to the triangulation to use our geometry object whenever a new point is needed upon refining the mesh. We do this by telling the triangulation to use our geometry for everything that has manifold indicator zero, and then proceed to mark all cells and their bounding faces and edges with manifold indicator zero. This ensures that the triangulation consults our geometry object every time a new vertex is needed. Since manifold indicators are inherited from mother to children, this also happens after several recursive refinement steps.
//
[0.x.30606] 
[0.x.30607] 
[0.x.30608] 
//
// The last step is to refine the mesh beyond its initial  [2.x.3682]  coarse mesh. We could just refine globally a number of times, but since for the purpose of this tutorial program we're really only interested in what is happening close to the surface, we just refine 6 times all of the cells that have a face at a boundary with indicator 5. Looking this up in the documentation of the  [2.x.3683]  function we have used above reveals that boundary indicator 5 corresponds to the top surface of the domain (and this is what the last  [2.x.3684]  argument in the call to  [2.x.3685]  above meant: to "color" the boundaries by assigning each boundary a unique boundary indicator).
//
[0.x.30609] 
[0.x.30610] 
[0.x.30611] 
[0.x.30612] 
[0.x.30613] 
[0.x.30614] 
[0.x.30615] 
[0.x.30616] 
[0.x.30617] 
[0.x.30618] 
//
[0.x.30619] 
[0.x.30620] 
[0.x.30621] 
[0.x.30622] 
[0.x.30623] 
//
// Having done this all, we can now output the mesh into a file of its own:
//
[0.x.30624] 
[0.x.30625] 
[0.x.30626] 
[0.x.30627] 
[0.x.30628] 
[0.x.30629] 
//
//  [2.x.3686] 
//
// Finally, the main function, which follows the same scheme used in all tutorial programs starting with  [2.x.3687] . There isn't much to do here, only to call the single  [2.x.3688]  function.
//
[0.x.30630] 
[0.x.30631] 
[0.x.30632] 
[0.x.30633] 
[0.x.30634] 
[0.x.30635] 
[0.x.30636] 
[0.x.30637] 
[0.x.30638] 
[0.x.30639] 
[0.x.30640] 
[0.x.30641] 
[0.x.30642] 
[0.x.30643] 
[0.x.30644] 
[0.x.30645] 
[0.x.30646] 
//
[0.x.30647] 
[0.x.30648] 
[0.x.30649] 
[0.x.30650] 
[0.x.30651] 
[0.x.30652] 
[0.x.30653] 
[0.x.30654] 
[0.x.30655] 
[0.x.30656] 
[0.x.30657] 
[0.x.30658] 
[0.x.30659] 
[0.x.30660] 
[0.x.30661] 
[0.x.30662] 
[0.x.30663] 
[0.x.30664] 
[0.x.30665] 
[0.x.30666] 
[0.x.30667] 
[0.x.30668] 
[0.x.30669] 
[0.x.30670] 
[0.x.30671] 
[0.x.30672] 
[0.x.30673] 
[0.x.30674] 
[0.x.30675] 
[0.x.30676] 
[0.x.30677] 
//[2.x.3689] 
//
// We start with including a bunch of files that we will use in the various parts of the program. Most of them have been discussed in previous tutorials already:
//
[0.x.30678] 
[0.x.30679] 
[0.x.30680] 
[0.x.30681] 
[0.x.30682] 
[0.x.30683] 
//
// These are the headers of the opencascade support classes and functions. Notice that these will contain sensible data only if you compiled your deal.II library with support for OpenCASCADE, i.e., specifying  [2.x.3690]  and  [2.x.3691]  when calling  [2.x.3692]  during deal.II configuration.
//
[0.x.30684] 
[0.x.30685] 
//
// Finally, a few C++ standard header files
//
[0.x.30686] 
[0.x.30687] 
[0.x.30688] 
[0.x.30689] 
//
// We isolate the rest of the program in its own namespace
//
[0.x.30690] 
[0.x.30691] 
[0.x.30692] 
//
//  [2.x.3693] 
//
// This is the main class. All it really does is store names for input and output files, and a triangulation. It then provides a function that generates such a triangulation from a coarse mesh, using one of the strategies discussed in the introduction and listed in the enumeration type at the top of the class.
//
// The member functions of this class are similar to what you can find in most of the other tutorial programs in the setup stage of the grid for the simulations.
//
[0.x.30693] 
[0.x.30694] 
[0.x.30695] 
[0.x.30696] 
[0.x.30697] 
[0.x.30698] 
[0.x.30699] 
[0.x.30700] 
[0.x.30701] 
//
[0.x.30702] 
[0.x.30703] 
[0.x.30704] 
[0.x.30705] 
[0.x.30706] 
//
[0.x.30707] 
//
[0.x.30708] 
[0.x.30709] 
//
[0.x.30710] 
//
[0.x.30711] 
//
[0.x.30712] 
//
[0.x.30713] 
[0.x.30714] 
[0.x.30715] 
//
[0.x.30716] 
[0.x.30717] 
//[2.x.3694] 
//
// The constructor of the TriangulationOnCAD class is very simple. The input arguments are strings for the input and output file names, and the enumeration type that determines which kind of surface projector is used in the mesh refinement cycles (see below for details).
//
[0.x.30718] 
[0.x.30719] 
[0.x.30720] 
[0.x.30721] 
[0.x.30722] 
[0.x.30723] 
[0.x.30724] 
[0.x.30725] 
[0.x.30726] 
[0.x.30727] 
//[2.x.3695] 
//
// The following function represents the core of this program.  In this function we import the CAD shape upon which we want to generate and refine our triangulation. We assume that the CAD surface is contained in the  [2.x.3696]  file (we provide an example IGES file in the input directory called "input/DTMB-5415_bulbous_bow.iges" that represents the bulbous bow of a ship). The presence of several convex and concave high curvature regions makes the geometry we provided a particularly meaningful example.
//
// After importing the hull bow surface, we extract some of the curves and surfaces composing it, and use them to generate a set of projectors. Such projectors define the rules the Triangulation has to follow to position each new node during cell refinement.
//
// To initialize the Triangulation, as done in previous tutorial programs, we import a pre-existing grid saved in VTK format. We assume here that the user has generated a coarse mesh externally, which matches the IGES geometry. At the moment of writing this tutorial, the deal.II library does not automatically support generation of such meshes, but there are several tools which can provide you with reasonable initial meshes starting from CAD files. In our example, the imported mesh is composed of a single quadrilateral cell whose vertices have been placed on the CAD shape.
//
// After importing both the IGES geometry and the initial mesh, we assign the projectors previously discussed to each of the edges and cells which will have to be refined on the CAD surface.
//
// In this tutorial, we will test the three different CAD surface projectors described in the introduction, and will analyze the results obtained with each of them.  As mentioned, each of these projection strategies has been implemented in a different class, and objects of these types can be assigned to a triangulation using the  [2.x.3697]  method.
//
// The following function then first imports the given CAD file. The function arguments are a string containing the desired file name, and a scale factor. In this example, the scale factor is set to 1e-3, as the original geometry is written in millimeters (which is the typical unit of measure for most IGES files), while we prefer to work in meters.  The output of the function is an object of OpenCASCADE generic topological shape class, namely a  [2.x.3698] 
[0.x.30728] 
[0.x.30729] 
[0.x.30730] 
//
// Each CAD geometrical object is defined along with a tolerance, which indicates possible inaccuracy of its placement. For instance, the tolerance  [2.x.3699]  of a vertex indicates that it can be located in any point contained in a sphere centered in the nominal position and having radius  [2.x.3700]  While projecting a point onto a surface (which will in turn have its tolerance) we must keep in mind that the precision of the projection will be limited by the tolerance with which the surface is built.
//
// The following method extracts the tolerance of the given shape and makes it a bit bigger to stay our of trouble:
//
[0.x.30731] 
//
// We now want to extract a set of composite sub-shapes from the generic shape. In particular, each face of the CAD file is composed of a trimming curve of type  [2.x.3701]  which is the collection of  [2.x.3702]  that compose the boundary of a surface, and a NURBS description of the surface itself. We will use a line projector to associate the boundary of our Triangulation to the wire delimiting the surface.  To extract all compound sub-shapes, like wires, shells, or solids, we resort to a method of the OpenCASCADE namespace.  The input of  [2.x.3703]  is a shape and a set of empty  [2.x.3704]  of subshapes, which will be filled with all compound shapes found in the given topological shape:
//
[0.x.30732] 
[0.x.30733] 
[0.x.30734] 
[0.x.30735] 
[0.x.30736] 
//
[0.x.30737] 
[0.x.30738] 
//
// The next few steps are more familiar, and allow us to import an existing mesh from an external VTK file, and convert it to a deal triangulation.
//
[0.x.30739] 
//
[0.x.30740] 
//
[0.x.30741] 
[0.x.30742] 
[0.x.30743] 
//
// We output this initial mesh saving it as the refinement step 0.
//
[0.x.30744] 
//
// The mesh imported has a single, two-dimensional cell located in three-dimensional space. We now want to ensure that it is refined according to the CAD geometry imported above. This this end, we get an iterator to that cell and assign to it the manifold_id 1 (see  [2.x.3705]  "this glossary entry"). We also get an iterator to its four faces, and assign each of them the manifold_id 2:
//
[0.x.30745] 
[0.x.30746] 
//
[0.x.30747] 
[0.x.30748] 
//
// Once both the CAD geometry and the initial mesh have been imported and digested, we use the CAD surfaces and curves to define the projectors and assign them to the manifold ids just specified.
//
// A first projector is defined using the single wire contained in our CAD file.  The ArclengthProjectionLineManifold will make sure that every mesh edge located on the wire is refined with a point that lies on the wire and splits it into two equal arcs lying between the edge vertices. We first check that the wires vector contains at least one element and then create a Manifold object for it.
//
// Once the projector is created, we then assign it to all the parts of the triangulation with manifold_id = 2:
//
[0.x.30749] 
[0.x.30750] 
[0.x.30751] 
[0.x.30752] 
//
[0.x.30753] 
[0.x.30754] 
//
[0.x.30755] 
//
// The surface projector is created according to what is specified with the  [2.x.3706]  option of the constructor. In particular, if the surface_projection_kind value equals  [2.x.3707]  we select the  [2.x.3708]  The new mesh points will then initially be generated at the barycenter of the cell/edge considered, and then projected on the CAD surface along its normal direction.  The NormalProjectionManifold constructor only needs a shape and a tolerance, and we then assign it to the triangulation for use with all parts that manifold having id 1:
//
[0.x.30756] 
[0.x.30757] 
[0.x.30758] 
[0.x.30759] 
[0.x.30760] 
[0.x.30761] 
[0.x.30762] 
//
[0.x.30763] 
[0.x.30764] 
//[2.x.3709]  surface_projection_kind value is  [2.x.3710]  we select the  [2.x.3711]  class. The new mesh points will then initially be generated at the barycenter of the cell/edge considered, and then projected on the CAD surface along a direction that is specified to the  [2.x.3712]  constructor. In this case, the projection is done along the y-axis.
//
[0.x.30765] 
[0.x.30766] 
[0.x.30767] 
[0.x.30768] 
[0.x.30769] 
[0.x.30770] 
[0.x.30771] 
//
[0.x.30772] 
[0.x.30773] 
//
// As a third option, if  [2.x.3713]  value is  [2.x.3714]  we select the  [2.x.3715]  The new mesh points will again initially be generated at the barycenter of the cell/edge considered, and then projected on the CAD surface along a direction that is an estimate of the mesh normal direction. The  [2.x.3716]  constructor only requires a shape (containing at least a face) and a tolerance.
//
[0.x.30774] 
[0.x.30775] 
[0.x.30776] 
[0.x.30777] 
[0.x.30778] 
//
[0.x.30779] 
[0.x.30780] 
//
// Finally, we use good software cleanliness by ensuring that this really covers all possible options of the  [2.x.3717]  statement. If we get any other value, we simply abort the program:
//
[0.x.30781] 
[0.x.30782] 
[0.x.30783] 
[0.x.30784] 
//[2.x.3718] 
//
// This function globally refines the mesh. In other tutorials, it would typically also distribute degrees of freedom, and resize matrices and vectors. These tasks are not carried out here, since we are not running any simulation on the Triangulation produced.
//
// While the function looks innocent, this is where most of the work we are interested in for this tutorial program actually happens. In particular, when refining the quads and lines that define the surface of the ship's hull, the Triangulation class will ask the various objects we have assigned to handle individual manifold ids for where the new vertices should lie.
//
[0.x.30785] 
[0.x.30786] 
[0.x.30787] 
[0.x.30788] 
//
//  [2.x.3719] 
//
// Outputting the results of our computations is a rather mechanical task. All the components of this function have been discussed before:
//
[0.x.30789] 
[0.x.30790] 
[0.x.30791] 
[0.x.30792] 
[0.x.30793] 
[0.x.30794] 
[0.x.30795] 
[0.x.30796] 
//[2.x.3720] 
//
// This is the main function. It should be self explanatory in its briefness:
//
[0.x.30797] 
[0.x.30798] 
[0.x.30799] 
//
[0.x.30800] 
[0.x.30801] 
[0.x.30802] 
[0.x.30803] 
[0.x.30804] 
[0.x.30805] 
[0.x.30806] 
[0.x.30807] 
//[2.x.3721] 
//
// This is the main function of this program. It is in its basic structure like all previous tutorial programs, but runs the main class through the three possibilities of new vertex placement:
//
[0.x.30808] 
[0.x.30809] 
[0.x.30810] 
[0.x.30811] 
[0.x.30812] 
//
[0.x.30813] 
[0.x.30814] 
//
[0.x.30815] 
[0.x.30816] 
[0.x.30817] 
[0.x.30818] 
[0.x.30819] 
[0.x.30820] 
[0.x.30821] 
[0.x.30822] 
[0.x.30823] 
[0.x.30824] 
[0.x.30825] 
[0.x.30826] 
[0.x.30827] 
[0.x.30828] 
[0.x.30829] 
[0.x.30830] 
//
[0.x.30831] 
[0.x.30832] 
[0.x.30833] 
[0.x.30834] 
[0.x.30835] 
[0.x.30836] 
[0.x.30837] 
[0.x.30838] 
[0.x.30839] 
[0.x.30840] 
[0.x.30841] 
[0.x.30842] 
[0.x.30843] 
[0.x.30844] 
[0.x.30845] 
[0.x.30846] 
//
[0.x.30847] 
[0.x.30848] 
[0.x.30849] 
[0.x.30850] 
[0.x.30851] 
[0.x.30852] 
[0.x.30853] 
[0.x.30854] 
[0.x.30855] 
[0.x.30856] 
[0.x.30857] 
[0.x.30858] 
[0.x.30859] 
[0.x.30860] 
[0.x.30861] 
[0.x.30862] 
[0.x.30863] 
[0.x.30864] 
[0.x.30865] 
[0.x.30866] 
[0.x.30867] 
[0.x.30868] 
[0.x.30869] 
[0.x.30870] 
[0.x.30871] 
[0.x.30872] 
[0.x.30873] 
[0.x.30874] 
[0.x.30875] 
//
[0.x.30876] 
[0.x.30877] 
[0.x.30878] 
[0.x.30879] 
[0.x.30880] 
[0.x.30881] 
[0.x.30882] 
[0.x.30883] 
[0.x.30884] 
[0.x.30885] 
[0.x.30886] 
[0.x.30887] 
[0.x.30888] 
[0.x.30889] 
//
[0.x.30890] 
[0.x.30891] 
[0.x.30892] 
[0.x.30893] 
[0.x.30894] 
[0.x.30895] 
[0.x.30896] 
[0.x.30897] 
[0.x.30898] 
[0.x.30899] 
[0.x.30900] 
[0.x.30901] 
[0.x.30902] 
[0.x.30903] 
[0.x.30904] 
[0.x.30905] 
//
[0.x.30906] 
[0.x.30907] 
[0.x.30908] 
//
[0.x.30909] 
[0.x.30910] 
[0.x.30911] 
//
// The following chunk out code is identical to  [2.x.3722]  and allows switching between PETSc and Trilinos:
//
[0.x.30912] 
//
[0.x.30913] 
//
[0.x.30914] 
[0.x.30915] 
[0.x.30916] 
[0.x.30917] 
[0.x.30918] 
[0.x.30919] 
[0.x.30920] 
[0.x.30921] 
[0.x.30922] 
[0.x.30923] 
[0.x.30924] 
[0.x.30925] 
//
[0.x.30926] 
[0.x.30927] 
[0.x.30928] 
[0.x.30929] 
[0.x.30930] 
[0.x.30931] 
[0.x.30932] 
//
[0.x.30933] 
[0.x.30934] 
[0.x.30935] 
[0.x.30936] 
//
[0.x.30937] 
[0.x.30938] 
[0.x.30939] 
[0.x.30940] 
[0.x.30941] 
[0.x.30942] 
[0.x.30943] 
[0.x.30944] 
[0.x.30945] 
[0.x.30946] 
[0.x.30947] 
[0.x.30948] 
//
[0.x.30949] 
[0.x.30950] 
[0.x.30951] 
[0.x.30952] 
[0.x.30953] 
[0.x.30954] 
//
[0.x.30955] 
[0.x.30956] 
[0.x.30957] 
//
[0.x.30958] 
[0.x.30959] 
[0.x.30960] 
//[2.x.3723] 
//
// We need a few helper classes to represent our solver strategy described in the introduction.
//
[0.x.30961] 
[0.x.30962] 
//
// This class exposes the action of applying the inverse of a giving matrix via the function  [2.x.3724]  Internally, the inverse is not formed explicitly. Instead, a linear solver with CG is performed. This class extends the InverseMatrix class in  [2.x.3725]  with an option to specify a preconditioner, and to allow for different vector types in the vmult function.
//
[0.x.30963] 
[0.x.30964] 
[0.x.30965] 
[0.x.30966] 
[0.x.30967] 
//
[0.x.30968] 
[0.x.30969] 
//
[0.x.30970] 
[0.x.30971] 
[0.x.30972] 
[0.x.30973] 
//
[0.x.30974] 
[0.x.30975] 
[0.x.30976] 
[0.x.30977] 
[0.x.30978] 
[0.x.30979] 
[0.x.30980] 
//
[0.x.30981] 
[0.x.30982] 
[0.x.30983] 
[0.x.30984] 
[0.x.30985] 
[0.x.30986] 
[0.x.30987] 
[0.x.30988] 
[0.x.30989] 
//
[0.x.30990] 
[0.x.30991] 
[0.x.30992] 
[0.x.30993] 
[0.x.30994] 
[0.x.30995] 
[0.x.30996] 
[0.x.30997] 
[0.x.30998] 
//
// The class A template class for a simple block diagonal preconditioner for 2x2 matrices.
//
[0.x.30999] 
[0.x.31000] 
[0.x.31001] 
[0.x.31002] 
[0.x.31003] 
[0.x.31004] 
//
[0.x.31005] 
[0.x.31006] 
//
[0.x.31007] 
[0.x.31008] 
[0.x.31009] 
[0.x.31010] 
//
[0.x.31011] 
[0.x.31012] 
[0.x.31013] 
[0.x.31014] 
[0.x.31015] 
[0.x.31016] 
[0.x.31017] 
//
[0.x.31018] 
[0.x.31019] 
[0.x.31020] 
[0.x.31021] 
[0.x.31022] 
[0.x.31023] 
[0.x.31024] 
[0.x.31025] 
//
[0.x.31026] 
//[2.x.3726] 
//
// The following classes represent the right hand side and the exact solution for the test problem.
//
[0.x.31027] 
[0.x.31028] 
[0.x.31029] 
[0.x.31030] 
[0.x.31031] 
[0.x.31032] 
[0.x.31033] 
//
[0.x.31034] 
[0.x.31035] 
[0.x.31036] 
//
[0.x.31037] 
[0.x.31038] 
[0.x.31039] 
[0.x.31040] 
[0.x.31041] 
[0.x.31042] 
//
[0.x.31043] 
[0.x.31044] 
[0.x.31045] 
[0.x.31046] 
[0.x.31047] 
[0.x.31048] 
[0.x.31049] 
[0.x.31050] 
[0.x.31051] 
[0.x.31052] 
[0.x.31053] 
[0.x.31054] 
[0.x.31055] 
[0.x.31056] 
[0.x.31057] 
//
[0.x.31058] 
[0.x.31059] 
[0.x.31060] 
[0.x.31061] 
[0.x.31062] 
[0.x.31063] 
[0.x.31064] 
//
[0.x.31065] 
[0.x.31066] 
[0.x.31067] 
//
[0.x.31068] 
[0.x.31069] 
[0.x.31070] 
[0.x.31071] 
[0.x.31072] 
[0.x.31073] 
//
[0.x.31074] 
[0.x.31075] 
[0.x.31076] 
[0.x.31077] 
[0.x.31078] 
[0.x.31079] 
[0.x.31080] 
[0.x.31081] 
[0.x.31082] 
[0.x.31083] 
[0.x.31084] 
[0.x.31085] 
[0.x.31086] 
[0.x.31087] 
[0.x.31088] 
[0.x.31089] 
[0.x.31090] 
[0.x.31091] 
[0.x.31092] 
[0.x.31093] 
[0.x.31094] 
[0.x.31095] 
//
//  [2.x.3727] 
//
// The main class is very similar to  [2.x.3728] , except that matrices and vectors are now block versions, and we store a  [2.x.3729]  for owned and relevant DoFs instead of a single IndexSet. We have exactly two IndexSets, one for all velocity unknowns and one for all pressure unknowns.
//
[0.x.31096] 
[0.x.31097] 
[0.x.31098] 
[0.x.31099] 
[0.x.31100] 
//
[0.x.31101] 
//
[0.x.31102] 
[0.x.31103] 
[0.x.31104] 
[0.x.31105] 
[0.x.31106] 
[0.x.31107] 
[0.x.31108] 
//
[0.x.31109] 
[0.x.31110] 
[0.x.31111] 
//
[0.x.31112] 
[0.x.31113] 
[0.x.31114] 
//
[0.x.31115] 
[0.x.31116] 
//
[0.x.31117] 
//
[0.x.31118] 
[0.x.31119] 
[0.x.31120] 
[0.x.31121] 
//
[0.x.31122] 
[0.x.31123] 
[0.x.31124] 
//
[0.x.31125] 
[0.x.31126] 
[0.x.31127] 
[0.x.31128] 
[0.x.31129] 
[0.x.31130] 
[0.x.31131] 
[0.x.31132] 
[0.x.31133] 
[0.x.31134] 
[0.x.31135] 
[0.x.31136] 
[0.x.31137] 
[0.x.31138] 
[0.x.31139] 
[0.x.31140] 
[0.x.31141] 
[0.x.31142] 
//
// The Kovasnay flow is defined on the domain [-0.5, 1.5]^2, which we create by passing the min and max values to  [2.x.3730] 
[0.x.31143] 
[0.x.31144] 
[0.x.31145] 
[0.x.31146] 
[0.x.31147] 
[0.x.31148] 
//[2.x.3731] 
//
// The construction of the block matrices and vectors is new compared to  [2.x.3732]  and is different compared to serial codes like  [2.x.3733] , because we need to supply the set of rows that belong to our processor.
//
[0.x.31149] 
[0.x.31150] 
[0.x.31151] 
[0.x.31152] 
//
[0.x.31153] 
//
// Put all dim velocities into block 0 and the pressure into block 1, then reorder the unknowns by block. Finally count how many unknowns we have per block.
//
[0.x.31154] 
[0.x.31155] 
[0.x.31156] 
//
[0.x.31157] 
[0.x.31158] 
//
[0.x.31159] 
[0.x.31160] 
//
[0.x.31161] 
[0.x.31162] 
//
// We split up the IndexSet for locally owned and locally relevant DoFs into two IndexSets based on how we want to create the block matrices and vectors.
//
[0.x.31163] 
[0.x.31164] 
[0.x.31165] 
[0.x.31166] 
//
[0.x.31167] 
[0.x.31168] 
[0.x.31169] 
[0.x.31170] 
[0.x.31171] 
//
// Setting up the constraints for boundary conditions and hanging nodes is identical to  [2.x.3734] . Even though we don't have any hanging nodes because we only perform global refinement, it is still a good idea to put this function call in, in case adaptive refinement gets introduced later.
//
[0.x.31172] 
[0.x.31173] 
//
[0.x.31174] 
[0.x.31175] 
[0.x.31176] 
[0.x.31177] 
[0.x.31178] 
[0.x.31179] 
[0.x.31180] 
[0.x.31181] 
[0.x.31182] 
//
// Now we create the system matrix based on a BlockDynamicSparsityPattern. We know that we won't have coupling between different velocity components (because we use the laplace and not the deformation tensor) and no coupling between pressure with its test functions, so we use a Table to communicate this coupling information to  [2.x.3735] 
[0.x.31183] 
[0.x.31184] 
//
[0.x.31185] 
[0.x.31186] 
[0.x.31187] 
[0.x.31188] 
[0.x.31189] 
[0.x.31190] 
[0.x.31191] 
[0.x.31192] 
[0.x.31193] 
//
[0.x.31194] 
//
[0.x.31195] 
[0.x.31196] 
//
[0.x.31197] 
[0.x.31198] 
[0.x.31199] 
[0.x.31200] 
[0.x.31201] 
//
[0.x.31202] 
[0.x.31203] 
//
// The preconditioner matrix has a different coupling (we only fill in the 1,1 block with the mass matrix), otherwise this code is identical to the construction of the system_matrix above.
//
[0.x.31204] 
[0.x.31205] 
//
[0.x.31206] 
[0.x.31207] 
[0.x.31208] 
[0.x.31209] 
[0.x.31210] 
[0.x.31211] 
[0.x.31212] 
//
[0.x.31213] 
//
[0.x.31214] 
[0.x.31215] 
[0.x.31216] 
[0.x.31217] 
[0.x.31218] 
[0.x.31219] 
[0.x.31220] 
[0.x.31221] 
[0.x.31222] 
//
//                               owned_partitioning,
//
[0.x.31223] 
[0.x.31224] 
[0.x.31225] 
//
// Finally, we construct the block vectors with the right sizes. The function call with two  [2.x.3736]  will create a ghosted vector.
//
[0.x.31226] 
[0.x.31227] 
[0.x.31228] 
[0.x.31229] 
[0.x.31230] 
//
//  [2.x.3737] 
//
// This function assembles the system matrix, the preconditioner matrix, and the right hand side. The code is pretty standard.
//
[0.x.31231] 
[0.x.31232] 
[0.x.31233] 
[0.x.31234] 
//
[0.x.31235] 
[0.x.31236] 
[0.x.31237] 
//
[0.x.31238] 
//
[0.x.31239] 
[0.x.31240] 
[0.x.31241] 
[0.x.31242] 
//
[0.x.31243] 
[0.x.31244] 
//
[0.x.31245] 
[0.x.31246] 
[0.x.31247] 
//
[0.x.31248] 
[0.x.31249] 
//
[0.x.31250] 
[0.x.31251] 
[0.x.31252] 
//
[0.x.31253] 
[0.x.31254] 
[0.x.31255] 
//
[0.x.31256] 
[0.x.31257] 
[0.x.31258] 
[0.x.31259] 
[0.x.31260] 
[0.x.31261] 
//
[0.x.31262] 
[0.x.31263] 
[0.x.31264] 
[0.x.31265] 
[0.x.31266] 
[0.x.31267] 
[0.x.31268] 
[0.x.31269] 
[0.x.31270] 
[0.x.31271] 
[0.x.31272] 
//
[0.x.31273] 
[0.x.31274] 
[0.x.31275] 
[0.x.31276] 
[0.x.31277] 
[0.x.31278] 
[0.x.31279] 
[0.x.31280] 
[0.x.31281] 
//
[0.x.31282] 
[0.x.31283] 
[0.x.31284] 
//
[0.x.31285] 
[0.x.31286] 
[0.x.31287] 
[0.x.31288] 
[0.x.31289] 
[0.x.31290] 
//
[0.x.31291] 
[0.x.31292] 
[0.x.31293] 
[0.x.31294] 
[0.x.31295] 
[0.x.31296] 
//
[0.x.31297] 
[0.x.31298] 
[0.x.31299] 
[0.x.31300] 
//
[0.x.31301] 
[0.x.31302] 
[0.x.31303] 
[0.x.31304] 
//
//  [2.x.3738] 
//
// This function solves the linear system with MINRES with a block diagonal preconditioner and AMG for the two diagonal blocks as described in the introduction. The preconditioner applies a v cycle to the 0,0 block and a CG with the mass matrix for the 1,1 block (the Schur complement).
//
[0.x.31305] 
[0.x.31306] 
[0.x.31307] 
[0.x.31308] 
//
[0.x.31309] 
[0.x.31310] 
[0.x.31311] 
//
[0.x.31312] 
[0.x.31313] 
[0.x.31314] 
[0.x.31315] 
[0.x.31316] 
//
[0.x.31317] 
[0.x.31318] 
[0.x.31319] 
//
[0.x.31320] 
[0.x.31321] 
[0.x.31322] 
[0.x.31323] 
[0.x.31324] 
//
// The InverseMatrix is used to solve for the mass matrix:
//
[0.x.31325] 
[0.x.31326] 
[0.x.31327] 
//
// This constructs the block preconditioner based on the preconditioners for the individual blocks defined above.
//
[0.x.31328] 
[0.x.31329] 
[0.x.31330] 
//
// With that, we can finally set up the linear solver and solve the system:
//
[0.x.31331] 
[0.x.31332] 
//
[0.x.31333] 
//
[0.x.31334] 
[0.x.31335] 
//
[0.x.31336] 
//
[0.x.31337] 
[0.x.31338] 
[0.x.31339] 
[0.x.31340] 
//
[0.x.31341] 
[0.x.31342] 
//
[0.x.31343] 
//
// Like in  [2.x.3739] , we subtract the mean pressure to allow error computations against our reference solution, which has a mean value of zero.
//
[0.x.31344] 
[0.x.31345] 
[0.x.31346] 
[0.x.31347] 
[0.x.31348] 
[0.x.31349] 
[0.x.31350] 
[0.x.31351] 
[0.x.31352] 
//
//  [2.x.3740] 
//
// The remainder of the code that deals with mesh refinement, output, and the main loop is pretty standard.
//
[0.x.31353] 
[0.x.31354] 
[0.x.31355] 
[0.x.31356] 
//
[0.x.31357] 
[0.x.31358] 
//
[0.x.31359] 
[0.x.31360] 
[0.x.31361] 
[0.x.31362] 
[0.x.31363] 
[0.x.31364] 
[0.x.31365] 
//
[0.x.31366] 
[0.x.31367] 
//
[0.x.31368] 
[0.x.31369] 
[0.x.31370] 
[0.x.31371] 
[0.x.31372] 
[0.x.31373] 
[0.x.31374] 
//
[0.x.31375] 
[0.x.31376] 
[0.x.31377] 
[0.x.31378] 
//
[0.x.31379] 
[0.x.31380] 
[0.x.31381] 
[0.x.31382] 
[0.x.31383] 
[0.x.31384] 
[0.x.31385] 
//
[0.x.31386] 
[0.x.31387] 
[0.x.31388] 
[0.x.31389] 
//
[0.x.31390] 
[0.x.31391] 
[0.x.31392] 
//
[0.x.31393] 
[0.x.31394] 
[0.x.31395] 
[0.x.31396] 
[0.x.31397] 
[0.x.31398] 
[0.x.31399] 
//
[0.x.31400] 
[0.x.31401] 
[0.x.31402] 
[0.x.31403] 
[0.x.31404] 
[0.x.31405] 
//
[0.x.31406] 
[0.x.31407] 
[0.x.31408] 
//
[0.x.31409] 
[0.x.31410] 
[0.x.31411] 
[0.x.31412] 
[0.x.31413] 
[0.x.31414] 
[0.x.31415] 
[0.x.31416] 
[0.x.31417] 
[0.x.31418] 
[0.x.31419] 
[0.x.31420] 
//
[0.x.31421] 
[0.x.31422] 
[0.x.31423] 
[0.x.31424] 
//
[0.x.31425] 
//
[0.x.31426] 
[0.x.31427] 
[0.x.31428] 
//
[0.x.31429] 
[0.x.31430] 
[0.x.31431] 
[0.x.31432] 
[0.x.31433] 
[0.x.31434] 
[0.x.31435] 
[0.x.31436] 
[0.x.31437] 
[0.x.31438] 
[0.x.31439] 
[0.x.31440] 
//
[0.x.31441] 
[0.x.31442] 
[0.x.31443] 
[0.x.31444] 
//
[0.x.31445] 
//
[0.x.31446] 
[0.x.31447] 
//
[0.x.31448] 
[0.x.31449] 
[0.x.31450] 
[0.x.31451] 
[0.x.31452] 
//
[0.x.31453] 
[0.x.31454] 
//
[0.x.31455] 
[0.x.31456] 
[0.x.31457] 
[0.x.31458] 
//
[0.x.31459] 
[0.x.31460] 
[0.x.31461] 
[0.x.31462] 
[0.x.31463] 
[0.x.31464] 
//
[0.x.31465] 
//
[0.x.31466] 
[0.x.31467] 
[0.x.31468] 
[0.x.31469] 
[0.x.31470] 
[0.x.31471] 
[0.x.31472] 
[0.x.31473] 
[0.x.31474] 
[0.x.31475] 
[0.x.31476] 
[0.x.31477] 
[0.x.31478] 
[0.x.31479] 
//
[0.x.31480] 
[0.x.31481] 
[0.x.31482] 
[0.x.31483] 
[0.x.31484] 
[0.x.31485] 
[0.x.31486] 
[0.x.31487] 
[0.x.31488] 
[0.x.31489] 
[0.x.31490] 
[0.x.31491] 
[0.x.31492] 
[0.x.31493] 
//
[0.x.31494] 
[0.x.31495] 
[0.x.31496] 
[0.x.31497] 
[0.x.31498] 
[0.x.31499] 
[0.x.31500] 
[0.x.31501] 
[0.x.31502] 
[0.x.31503] 
[0.x.31504] 
[0.x.31505] 
[0.x.31506] 
[0.x.31507] 
[0.x.31508] 
[0.x.31509] 
//
[0.x.31510] 
[0.x.31511] 
[0.x.31512] 
//[2.x.3741] 
[0.x.31513] 
[0.x.31514] 
[0.x.31515] 
[0.x.31516] 
//
[0.x.31517] 
[0.x.31518] 
[0.x.31519] 
[0.x.31520] 
[0.x.31521] 
[0.x.31522] 
[0.x.31523] 
[0.x.31524] 
[0.x.31525] 
//
[0.x.31526] 
[0.x.31527] 
[0.x.31528] 
[0.x.31529] 
//
[0.x.31530] 
[0.x.31531] 
[0.x.31532] 
//
[0.x.31533] 
[0.x.31534] 
[0.x.31535] 
//
[0.x.31536] 
[0.x.31537] 
[0.x.31538] 
[0.x.31539] 
//
[0.x.31540] 
//
[0.x.31541] 
[0.x.31542] 
//
// We need to include the following file to do timings:
//
[0.x.31543] 
//
// This includes the files necessary for us to use geometric Multigrid
//
[0.x.31544] 
[0.x.31545] 
[0.x.31546] 
[0.x.31547] 
[0.x.31548] 
[0.x.31549] 
//
[0.x.31550] 
[0.x.31551] 
//
[0.x.31552] 
[0.x.31553] 
[0.x.31554] 
//
// In order to make it easy to switch between the different solvers that are being used, we declare an enum that can be passed as an argument to the constructor of the main class.
//
[0.x.31555] 
[0.x.31556] 
[0.x.31557] 
[0.x.31558] 
[0.x.31559] 
[0.x.31560] 
//[2.x.3742] 
//
// The class Solution is used to define the boundary conditions and to compute errors of the numerical solution. Note that we need to define the values and gradients in order to compute L2 and H1 errors. Here we decided to separate the implementations for 2d and 3d using template specialization.
//
// Note that the first dim components are the velocity components and the last is the pressure.
//
[0.x.31561] 
[0.x.31562] 
[0.x.31563] 
[0.x.31564] 
[0.x.31565] 
[0.x.31566] 
[0.x.31567] 
[0.x.31568] 
[0.x.31569] 
[0.x.31570] 
[0.x.31571] 
[0.x.31572] 
[0.x.31573] 
//
[0.x.31574] 
[0.x.31575] 
[0.x.31576] 
[0.x.31577] 
[0.x.31578] 
//
[0.x.31579] 
[0.x.31580] 
[0.x.31581] 
//
[0.x.31582] 
[0.x.31583] 
[0.x.31584] 
[0.x.31585] 
[0.x.31586] 
[0.x.31587] 
//
[0.x.31588] 
[0.x.31589] 
//
[0.x.31590] 
[0.x.31591] 
[0.x.31592] 
[0.x.31593] 
[0.x.31594] 
//
[0.x.31595] 
[0.x.31596] 
[0.x.31597] 
[0.x.31598] 
//
[0.x.31599] 
[0.x.31600] 
[0.x.31601] 
[0.x.31602] 
[0.x.31603] 
[0.x.31604] 
[0.x.31605] 
[0.x.31606] 
//
[0.x.31607] 
[0.x.31608] 
//
// Note that for the gradient we need to return a Tensor<1,dim>
//
[0.x.31609] 
[0.x.31610] 
[0.x.31611] 
[0.x.31612] 
[0.x.31613] 
//
[0.x.31614] 
[0.x.31615] 
[0.x.31616] 
//
[0.x.31617] 
[0.x.31618] 
[0.x.31619] 
[0.x.31620] 
[0.x.31621] 
[0.x.31622] 
[0.x.31623] 
[0.x.31624] 
[0.x.31625] 
[0.x.31626] 
[0.x.31627] 
[0.x.31628] 
[0.x.31629] 
[0.x.31630] 
[0.x.31631] 
[0.x.31632] 
//
[0.x.31633] 
[0.x.31634] 
//
[0.x.31635] 
[0.x.31636] 
[0.x.31637] 
[0.x.31638] 
[0.x.31639] 
//
[0.x.31640] 
[0.x.31641] 
[0.x.31642] 
[0.x.31643] 
//
[0.x.31644] 
[0.x.31645] 
[0.x.31646] 
[0.x.31647] 
[0.x.31648] 
[0.x.31649] 
[0.x.31650] 
[0.x.31651] 
[0.x.31652] 
[0.x.31653] 
[0.x.31654] 
[0.x.31655] 
[0.x.31656] 
[0.x.31657] 
[0.x.31658] 
[0.x.31659] 
[0.x.31660] 
[0.x.31661] 
[0.x.31662] 
[0.x.31663] 
[0.x.31664] 
[0.x.31665] 
[0.x.31666] 
[0.x.31667] 
[0.x.31668] 
//
[0.x.31669] 
[0.x.31670] 
//
// Implementation of  [2.x.3743] . See the introduction for more information.
//
[0.x.31671] 
[0.x.31672] 
[0.x.31673] 
[0.x.31674] 
[0.x.31675] 
[0.x.31676] 
[0.x.31677] 
//
[0.x.31678] 
[0.x.31679] 
[0.x.31680] 
//
[0.x.31681] 
[0.x.31682] 
[0.x.31683] 
[0.x.31684] 
[0.x.31685] 
//
[0.x.31686] 
[0.x.31687] 
[0.x.31688] 
[0.x.31689] 
[0.x.31690] 
[0.x.31691] 
[0.x.31692] 
[0.x.31693] 
[0.x.31694] 
//
[0.x.31695] 
[0.x.31696] 
//
[0.x.31697] 
[0.x.31698] 
[0.x.31699] 
[0.x.31700] 
[0.x.31701] 
//
[0.x.31702] 
[0.x.31703] 
[0.x.31704] 
[0.x.31705] 
[0.x.31706] 
[0.x.31707] 
[0.x.31708] 
[0.x.31709] 
[0.x.31710] 
[0.x.31711] 
[0.x.31712] 
[0.x.31713] 
[0.x.31714] 
[0.x.31715] 
[0.x.31716] 
//
[0.x.31717] 
[0.x.31718] 
//
//  [2.x.3744] 
//
// In the following, we will implement a preconditioner that expands on the ideas discussed in the Results section of  [2.x.3745] . Specifically, we 1. use an upper block-triangular preconditioner because we want to use right preconditioning. 2. optionally allow using an inner solver for the velocity block instead of a single preconditioner application. 3. do not use InverseMatrix but explicitly call SolverCG. This approach is also used in the ASPECT code (see https:aspect.geodynamics.org) that solves the Stokes equations in the context of simulating convection in the earth mantle, and which has been used to solve problems on many thousands of processors.
//
// The bool flag  [2.x.3746]  in the constructor allows us to either apply the preconditioner for the velocity block once or use an inner iterative solver for a more accurate approximation instead.
//
// Notice how we keep track of the sum of the inner iterations (preconditioner applications).
//
[0.x.31719] 
[0.x.31720] 
[0.x.31721] 
[0.x.31722] 
[0.x.31723] 
[0.x.31724] 
[0.x.31725] 
[0.x.31726] 
[0.x.31727] 
[0.x.31728] 
//
[0.x.31729] 
//
[0.x.31730] 
[0.x.31731] 
//
[0.x.31732] 
[0.x.31733] 
[0.x.31734] 
[0.x.31735] 
[0.x.31736] 
//
[0.x.31737] 
[0.x.31738] 
//
[0.x.31739] 
[0.x.31740] 
[0.x.31741] 
[0.x.31742] 
[0.x.31743] 
[0.x.31744] 
[0.x.31745] 
[0.x.31746] 
[0.x.31747] 
[0.x.31748] 
[0.x.31749] 
[0.x.31750] 
[0.x.31751] 
[0.x.31752] 
[0.x.31753] 
[0.x.31754] 
//
[0.x.31755] 
[0.x.31756] 
[0.x.31757] 
[0.x.31758] 
[0.x.31759] 
[0.x.31760] 
[0.x.31761] 
//
// First solve with the approximation for S
//
[0.x.31762] 
[0.x.31763] 
[0.x.31764] 
//
[0.x.31765] 
[0.x.31766] 
[0.x.31767] 
[0.x.31768] 
[0.x.31769] 
//
[0.x.31770] 
[0.x.31771] 
[0.x.31772] 
//
// Second, apply the top right block (B^T)
//
[0.x.31773] 
[0.x.31774] 
[0.x.31775] 
[0.x.31776] 
[0.x.31777] 
//
// Finally, either solve with the top left block or just apply one preconditioner sweep
//
[0.x.31778] 
[0.x.31779] 
[0.x.31780] 
[0.x.31781] 
//
[0.x.31782] 
[0.x.31783] 
[0.x.31784] 
[0.x.31785] 
[0.x.31786] 
//
[0.x.31787] 
[0.x.31788] 
[0.x.31789] 
[0.x.31790] 
[0.x.31791] 
[0.x.31792] 
[0.x.31793] 
[0.x.31794] 
//[2.x.3747] 
//
// This is the main class of the problem.
//
[0.x.31795] 
[0.x.31796] 
[0.x.31797] 
[0.x.31798] 
[0.x.31799] 
[0.x.31800] 
[0.x.31801] 
//
[0.x.31802] 
[0.x.31803] 
[0.x.31804] 
[0.x.31805] 
[0.x.31806] 
[0.x.31807] 
[0.x.31808] 
//
[0.x.31809] 
[0.x.31810] 
//
[0.x.31811] 
[0.x.31812] 
[0.x.31813] 
[0.x.31814] 
[0.x.31815] 
//
[0.x.31816] 
//
[0.x.31817] 
[0.x.31818] 
[0.x.31819] 
//
[0.x.31820] 
[0.x.31821] 
//
[0.x.31822] 
[0.x.31823] 
[0.x.31824] 
[0.x.31825] 
//
[0.x.31826] 
[0.x.31827] 
//
[0.x.31828] 
[0.x.31829] 
[0.x.31830] 
//
[0.x.31831] 
[0.x.31832] 
[0.x.31833] 
[0.x.31834] 
//
// Finite element for the velocity only:
//
[0.x.31835] 
[0.x.31836] 
//
// Finite element for the whole system:
//
[0.x.31837] 
[0.x.31838] 
[0.x.31839] 
[0.x.31840] 
[0.x.31841] 
//
//  [2.x.3748] 
//
// This function sets up the DoFHandler, matrices, vectors, and Multigrid structures (if needed).
//
[0.x.31842] 
[0.x.31843] 
[0.x.31844] 
[0.x.31845] 
//
[0.x.31846] 
[0.x.31847] 
//
// The main DoFHandler only needs active DoFs, so we are not calling distribute_mg_dofs() here
//
[0.x.31848] 
//
// This block structure separates the dim velocity components from the pressure component (used for reordering). Note that we have 2 instead of dim+1 blocks like in  [2.x.3749] , because our FESystem is nested and the dim velocity components appear as one block.
//
[0.x.31849] 
[0.x.31850] 
[0.x.31851] 
//
// Velocities start at component 0:
//
[0.x.31852] 
//
// ILU behaves better if we apply a reordering to reduce fillin. There is no advantage in doing this for the other solvers.
//
[0.x.31853] 
[0.x.31854] 
[0.x.31855] 
[0.x.31856] 
[0.x.31857] 
//
// This ensures that all velocities DoFs are enumerated before the pressure unknowns. This allows us to use blocks for vectors and matrices and allows us to get the same DoF numbering for dof_handler and velocity_dof_handler.
//
[0.x.31858] 
//
[0.x.31859] 
[0.x.31860] 
[0.x.31861] 
[0.x.31862] 
[0.x.31863] 
[0.x.31864] 
//
// This distributes the active dofs and multigrid dofs for the velocity space in a separate DoFHandler as described in the introduction.
//
[0.x.31865] 
[0.x.31866] 
//
// The following block of code initializes the MGConstrainedDofs (using the boundary conditions for the velocity), and the sparsity patterns and matrices for each level. The resize() function of MGLevelObject<T> will destroy all existing contained objects.
//
[0.x.31867] 
[0.x.31868] 
//
[0.x.31869] 
[0.x.31870] 
[0.x.31871] 
[0.x.31872] 
[0.x.31873] 
//
[0.x.31874] 
[0.x.31875] 
[0.x.31876] 
//
[0.x.31877] 
[0.x.31878] 
[0.x.31879] 
[0.x.31880] 
[0.x.31881] 
[0.x.31882] 
//
[0.x.31883] 
[0.x.31884] 
[0.x.31885] 
[0.x.31886] 
//
[0.x.31887] 
[0.x.31888] 
[0.x.31889] 
[0.x.31890] 
//
[0.x.31891] 
[0.x.31892] 
//
// The following makes use of a component mask for interpolation of the boundary values for the velocity only, which is further explained in the vector valued dealii  [2.x.3750]  tutorial.
//
[0.x.31893] 
[0.x.31894] 
[0.x.31895] 
[0.x.31896] 
[0.x.31897] 
[0.x.31898] 
//
// As discussed in the introduction, we need to fix one degree of freedom of the pressure variable to ensure solvability of the problem. We do this here by marking the first pressure dof, which has index n_u as a constrained dof.
//
[0.x.31899] 
[0.x.31900] 
//
[0.x.31901] 
[0.x.31902] 
//
[0.x.31903] 
[0.x.31904] 
[0.x.31905] 
[0.x.31906] 
//
[0.x.31907] 
[0.x.31908] 
[0.x.31909] 
[0.x.31910] 
[0.x.31911] 
[0.x.31912] 
//
[0.x.31913] 
[0.x.31914] 
[0.x.31915] 
//[2.x.3751] 
//
// In this function, the system matrix is assembled. We assemble the pressure mass matrix in the (1,1) block (if needed) and move it out of this location at the end of this function.
//
[0.x.31916] 
[0.x.31917] 
[0.x.31918] 
[0.x.31919] 
[0.x.31920] 
[0.x.31921] 
//
// If true, we will assemble the pressure mass matrix in the (1,1) block:
//
[0.x.31922] 
[0.x.31923] 
//
[0.x.31924] 
//
[0.x.31925] 
[0.x.31926] 
[0.x.31927] 
[0.x.31928] 
//
[0.x.31929] 
//
[0.x.31930] 
//
[0.x.31931] 
[0.x.31932] 
//
[0.x.31933] 
//
[0.x.31934] 
[0.x.31935] 
//
[0.x.31936] 
[0.x.31937] 
//
[0.x.31938] 
[0.x.31939] 
[0.x.31940] 
//
[0.x.31941] 
[0.x.31942] 
[0.x.31943] 
[0.x.31944] 
[0.x.31945] 
//
[0.x.31946] 
[0.x.31947] 
//
[0.x.31948] 
[0.x.31949] 
[0.x.31950] 
[0.x.31951] 
[0.x.31952] 
[0.x.31953] 
[0.x.31954] 
[0.x.31955] 
[0.x.31956] 
//
[0.x.31957] 
[0.x.31958] 
[0.x.31959] 
[0.x.31960] 
[0.x.31961] 
[0.x.31962] 
[0.x.31963] 
[0.x.31964] 
[0.x.31965] 
[0.x.31966] 
[0.x.31967] 
//
[0.x.31968] 
[0.x.31969] 
[0.x.31970] 
[0.x.31971] 
[0.x.31972] 
[0.x.31973] 
//
[0.x.31974] 
[0.x.31975] 
[0.x.31976] 
//
[0.x.31977] 
[0.x.31978] 
[0.x.31979] 
[0.x.31980] 
[0.x.31981] 
[0.x.31982] 
[0.x.31983] 
//
[0.x.31984] 
[0.x.31985] 
[0.x.31986] 
[0.x.31987] 
[0.x.31988] 
[0.x.31989] 
[0.x.31990] 
//[2.x.3752] 
//
// Here, like in  [2.x.3753] , we have a function that assembles the level and interface matrices necessary for the multigrid preconditioner.
//
[0.x.31991] 
[0.x.31992] 
[0.x.31993] 
[0.x.31994] 
[0.x.31995] 
[0.x.31996] 
[0.x.31997] 
//
[0.x.31998] 
//
[0.x.31999] 
//
[0.x.32000] 
[0.x.32001] 
[0.x.32002] 
[0.x.32003] 
//
[0.x.32004] 
[0.x.32005] 
//
[0.x.32006] 
//
[0.x.32007] 
//
[0.x.32008] 
//
[0.x.32009] 
//
[0.x.32010] 
[0.x.32011] 
[0.x.32012] 
[0.x.32013] 
[0.x.32014] 
[0.x.32015] 
[0.x.32016] 
[0.x.32017] 
[0.x.32018] 
[0.x.32019] 
[0.x.32020] 
//
[0.x.32021] 
[0.x.32022] 
//
[0.x.32023] 
[0.x.32024] 
[0.x.32025] 
//
// This iterator goes over all cells (not just active)
//
[0.x.32026] 
[0.x.32027] 
[0.x.32028] 
[0.x.32029] 
//
[0.x.32030] 
[0.x.32031] 
[0.x.32032] 
[0.x.32033] 
//
[0.x.32034] 
[0.x.32035] 
[0.x.32036] 
[0.x.32037] 
[0.x.32038] 
[0.x.32039] 
[0.x.32040] 
//
[0.x.32041] 
[0.x.32042] 
[0.x.32043] 
//
[0.x.32044] 
//
[0.x.32045] 
[0.x.32046] 
//
[0.x.32047] 
[0.x.32048] 
[0.x.32049] 
[0.x.32050] 
[0.x.32051] 
[0.x.32052] 
[0.x.32053] 
//
[0.x.32054] 
[0.x.32055] 
[0.x.32056] 
[0.x.32057] 
[0.x.32058] 
[0.x.32059] 
//[2.x.3754] 
//
// This function sets up things differently based on if you want to use ILU or GMG as a preconditioner.  Both methods share the same solver (FGMRES) but require a different preconditioner to be initialized. Here we time not only the entire solve function, but we separately time the setup of the preconditioner as well as the solve itself.
//
[0.x.32060] 
[0.x.32061] 
[0.x.32062] 
[0.x.32063] 
[0.x.32064] 
//
[0.x.32065] 
[0.x.32066] 
[0.x.32067] 
[0.x.32068] 
//
[0.x.32069] 
[0.x.32070] 
//
[0.x.32071] 
[0.x.32072] 
//
[0.x.32073] 
[0.x.32074] 
[0.x.32075] 
[0.x.32076] 
[0.x.32077] 
//
[0.x.32078] 
[0.x.32079] 
[0.x.32080] 
//
// Here we must make sure to solve for the residual with "good enough" accuracy
//
[0.x.32081] 
[0.x.32082] 
[0.x.32083] 
[0.x.32084] 
//
// This is used to pass whether or not we want to solve for A inside the preconditioner.  One could change this to false to see if there is still convergence and if so does the program then run faster or slower
//
[0.x.32085] 
//
[0.x.32086] 
//
[0.x.32087] 
[0.x.32088] 
[0.x.32089] 
[0.x.32090] 
//
[0.x.32091] 
[0.x.32092] 
//
[0.x.32093] 
[0.x.32094] 
//
[0.x.32095] 
[0.x.32096] 
//
[0.x.32097] 
[0.x.32098] 
[0.x.32099] 
[0.x.32100] 
[0.x.32101] 
[0.x.32102] 
//
[0.x.32103] 
[0.x.32104] 
//
[0.x.32105] 
[0.x.32106] 
//
[0.x.32107] 
[0.x.32108] 
[0.x.32109] 
[0.x.32110] 
[0.x.32111] 
[0.x.32112] 
[0.x.32113] 
[0.x.32114] 
[0.x.32115] 
//
// Transfer operators between levels
//
[0.x.32116] 
[0.x.32117] 
//
// Setup coarse grid solver
//
[0.x.32118] 
[0.x.32119] 
[0.x.32120] 
[0.x.32121] 
//
[0.x.32122] 
[0.x.32123] 
[0.x.32124] 
[0.x.32125] 
//
// Multigrid, when used as a preconditioner for CG, needs to be a symmetric operator, so the smoother must be symmetric
//
[0.x.32126] 
//
[0.x.32127] 
[0.x.32128] 
[0.x.32129] 
//
// Now, we are ready to set up the V-cycle operator and the multilevel preconditioner.
//
[0.x.32130] 
[0.x.32131] 
[0.x.32132] 
//
[0.x.32133] 
[0.x.32134] 
//
[0.x.32135] 
[0.x.32136] 
[0.x.32137] 
//
[0.x.32138] 
[0.x.32139] 
[0.x.32140] 
[0.x.32141] 
[0.x.32142] 
[0.x.32143] 
[0.x.32144] 
[0.x.32145] 
[0.x.32146] 
[0.x.32147] 
//
[0.x.32148] 
[0.x.32149] 
//
[0.x.32150] 
[0.x.32151] 
[0.x.32152] 
[0.x.32153] 
[0.x.32154] 
[0.x.32155] 
[0.x.32156] 
//
[0.x.32157] 
//
[0.x.32158] 
[0.x.32159] 
[0.x.32160] 
[0.x.32161] 
[0.x.32162] 
[0.x.32163] 
[0.x.32164] 
[0.x.32165] 
[0.x.32166] 
[0.x.32167] 
//[2.x.3755] 
//
// This function computes the L2 and H1 errors of the solution. For this, we need to make sure the pressure has mean zero.
//
[0.x.32168] 
[0.x.32169] 
[0.x.32170] 
//
// Compute the mean pressure  [2.x.3756]  and then subtract it from each pressure coefficient. This will result in a pressure with mean value zero. Here we make use of the fact that the pressure is component  [2.x.3757]  and that the finite element space is nodal.
//
[0.x.32171] 
[0.x.32172] 
[0.x.32173] 
[0.x.32174] 
[0.x.32175] 
//
[0.x.32176] 
[0.x.32177] 
[0.x.32178] 
//
[0.x.32179] 
[0.x.32180] 
[0.x.32181] 
[0.x.32182] 
[0.x.32183] 
[0.x.32184] 
[0.x.32185] 
[0.x.32186] 
//
[0.x.32187] 
[0.x.32188] 
[0.x.32189] 
[0.x.32190] 
//
[0.x.32191] 
[0.x.32192] 
[0.x.32193] 
[0.x.32194] 
[0.x.32195] 
[0.x.32196] 
[0.x.32197] 
//
[0.x.32198] 
[0.x.32199] 
[0.x.32200] 
[0.x.32201] 
//
[0.x.32202] 
[0.x.32203] 
[0.x.32204] 
[0.x.32205] 
[0.x.32206] 
[0.x.32207] 
[0.x.32208] 
//
[0.x.32209] 
[0.x.32210] 
[0.x.32211] 
[0.x.32212] 
//
[0.x.32213] 
[0.x.32214] 
[0.x.32215] 
[0.x.32216] 
[0.x.32217] 
//[2.x.3758] 
//
// This function generates graphical output like it is done in  [2.x.3759] .
//
[0.x.32218] 
[0.x.32219] 
[0.x.32220] 
[0.x.32221] 
[0.x.32222] 
[0.x.32223] 
//
[0.x.32224] 
[0.x.32225] 
[0.x.32226] 
[0.x.32227] 
[0.x.32228] 
//
[0.x.32229] 
[0.x.32230] 
[0.x.32231] 
[0.x.32232] 
[0.x.32233] 
[0.x.32234] 
[0.x.32235] 
//
[0.x.32236] 
[0.x.32237] 
[0.x.32238] 
[0.x.32239] 
//
//  [2.x.3760] 
//
// The last step in the Stokes class is, as usual, the function that generates the initial grid and calls the other functions in the respective order.
//
[0.x.32240] 
[0.x.32241] 
[0.x.32242] 
[0.x.32243] 
[0.x.32244] 
//
[0.x.32245] 
[0.x.32246] 
[0.x.32247] 
[0.x.32248] 
[0.x.32249] 
[0.x.32250] 
//
[0.x.32251] 
[0.x.32252] 
[0.x.32253] 
[0.x.32254] 
//
[0.x.32255] 
[0.x.32256] 
//
[0.x.32257] 
[0.x.32258] 
//
[0.x.32259] 
[0.x.32260] 
//
[0.x.32261] 
[0.x.32262] 
[0.x.32263] 
//
[0.x.32264] 
[0.x.32265] 
//
[0.x.32266] 
[0.x.32267] 
//
[0.x.32268] 
//
[0.x.32269] 
//
[0.x.32270] 
[0.x.32271] 
[0.x.32272] 
//
[0.x.32273] 
[0.x.32274] 
[0.x.32275] 
[0.x.32276] 
[0.x.32277] 
//[2.x.3761] 
[0.x.32278] 
[0.x.32279] 
[0.x.32280] 
[0.x.32281] 
[0.x.32282] 
//
[0.x.32283] 
[0.x.32284] 
//
// options for SolverType: UMFPACK FGMRES_ILU FGMRES_GMG
//
[0.x.32285] 
//
[0.x.32286] 
[0.x.32287] 
[0.x.32288] 
[0.x.32289] 
[0.x.32290] 
[0.x.32291] 
[0.x.32292] 
[0.x.32293] 
[0.x.32294] 
[0.x.32295] 
[0.x.32296] 
[0.x.32297] 
[0.x.32298] 
//
[0.x.32299] 
[0.x.32300] 
[0.x.32301] 
[0.x.32302] 
[0.x.32303] 
[0.x.32304] 
[0.x.32305] 
[0.x.32306] 
[0.x.32307] 
[0.x.32308] 
[0.x.32309] 
[0.x.32310] 
[0.x.32311] 
[0.x.32312] 
//
[0.x.32313] 
[0.x.32314] 
[0.x.32315] 
[0.x.32316] 
[0.x.32317] 
[0.x.32318] 
[0.x.32319] 
[0.x.32320] 
[0.x.32321] 
[0.x.32322] 
[0.x.32323] 
[0.x.32324] 
[0.x.32325] 
[0.x.32326] 
[0.x.32327] 
[0.x.32328] 
[0.x.32329] 
[0.x.32330] 
[0.x.32331] 
//[2.x.3762] 
//
// As usual, we start by including some well-known files:
//
[0.x.32332] 
[0.x.32333] 
[0.x.32334] 
[0.x.32335] 
//
[0.x.32336] 
[0.x.32337] 
[0.x.32338] 
[0.x.32339] 
[0.x.32340] 
[0.x.32341] 
[0.x.32342] 
[0.x.32343] 
//
[0.x.32344] 
[0.x.32345] 
[0.x.32346] 
[0.x.32347] 
//
[0.x.32348] 
[0.x.32349] 
[0.x.32350] 
//
[0.x.32351] 
[0.x.32352] 
[0.x.32353] 
//
[0.x.32354] 
[0.x.32355] 
[0.x.32356] 
[0.x.32357] 
//
// To transfer solutions between meshes, this file is included:
//
[0.x.32358] 
//
// This file includes UMFPACK: the direct solver:
//
[0.x.32359] 
//
// And the one for ILU preconditioner:
//
[0.x.32360] 
//
[0.x.32361] 
[0.x.32362] 
//
[0.x.32363] 
[0.x.32364] 
[0.x.32365] 
//[2.x.3763] 
//
// This class manages the matrices and vectors described in the introduction: in particular, we store a BlockVector for the current solution, current Newton update, and the line search update.  We also store two AffineConstraints objects: one which enforces the Dirichlet boundary conditions and one that sets all boundary values to zero. The first constrains the solution vector while the second constraints the updates (i.e., we never update boundary values, so we force the relevant update vector values to be zero).
//
[0.x.32366] 
[0.x.32367] 
[0.x.32368] 
[0.x.32369] 
[0.x.32370] 
[0.x.32371] 
//
[0.x.32372] 
[0.x.32373] 
//
[0.x.32374] 
//
[0.x.32375] 
//
[0.x.32376] 
//
[0.x.32377] 
//
[0.x.32378] 
//
[0.x.32379] 
//
[0.x.32380] 
//
[0.x.32381] 
//
[0.x.32382] 
[0.x.32383] 
[0.x.32384] 
[0.x.32385] 
[0.x.32386] 
//
[0.x.32387] 
//
[0.x.32388] 
[0.x.32389] 
[0.x.32390] 
[0.x.32391] 
//
[0.x.32392] 
[0.x.32393] 
[0.x.32394] 
//
[0.x.32395] 
[0.x.32396] 
//
[0.x.32397] 
[0.x.32398] 
[0.x.32399] 
//
[0.x.32400] 
[0.x.32401] 
[0.x.32402] 
[0.x.32403] 
[0.x.32404] 
//[2.x.3764] 
//
// In this problem we set the velocity along the upper surface of the cavity to be one and zero on the other three walls. The right hand side function is zero so we do not need to set the right hand side function in this tutorial. The number of components of the boundary function is  [2.x.3765] . We will ultimately use  [2.x.3766]  to set boundary values, which requires the boundary value functions to have the same number of components as the solution, even if all are not used. Put another way: to make this function happy we define boundary values for the pressure even though we will never actually use them.
//
[0.x.32405] 
[0.x.32406] 
[0.x.32407] 
[0.x.32408] 
[0.x.32409] 
[0.x.32410] 
[0.x.32411] 
[0.x.32412] 
[0.x.32413] 
[0.x.32414] 
//
[0.x.32415] 
[0.x.32416] 
[0.x.32417] 
[0.x.32418] 
[0.x.32419] 
[0.x.32420] 
[0.x.32421] 
[0.x.32422] 
//
[0.x.32423] 
[0.x.32424] 
//[2.x.3767] 
//
// As discussed in the introduction, the preconditioner in Krylov iterative methods is implemented as a matrix-vector product operator. In practice, the Schur complement preconditioner is decomposed as a product of three matrices (as presented in the first section). The  [2.x.3768]  in the first factor involves a solve for the linear system  [2.x.3769] . Here we solve this system via a direct solver for simplicity. The computation involved in the second factor is a simple matrix-vector multiplication. The Schur complement  [2.x.3770]  can be well approximated by the pressure mass matrix and its inverse can be obtained through an inexact solver. Because the pressure mass matrix is symmetric and positive definite, we can use CG to solve the corresponding linear system.
//
[0.x.32425] 
[0.x.32426] 
[0.x.32427] 
[0.x.32428] 
[0.x.32429] 
[0.x.32430] 
[0.x.32431] 
[0.x.32432] 
[0.x.32433] 
//
[0.x.32434] 
//
[0.x.32435] 
[0.x.32436] 
[0.x.32437] 
[0.x.32438] 
[0.x.32439] 
[0.x.32440] 
[0.x.32441] 
[0.x.32442] 
//
// We can notice that the initialization of the inverse of the matrix at the top left corner is completed in the constructor. If so, every application of the preconditioner then no longer requires the computation of the matrix factors.
//
[0.x.32443] 
[0.x.32444] 
[0.x.32445] 
[0.x.32446] 
[0.x.32447] 
[0.x.32448] 
[0.x.32449] 
[0.x.32450] 
[0.x.32451] 
[0.x.32452] 
[0.x.32453] 
[0.x.32454] 
[0.x.32455] 
[0.x.32456] 
[0.x.32457] 
//
[0.x.32458] 
[0.x.32459] 
[0.x.32460] 
[0.x.32461] 
[0.x.32462] 
[0.x.32463] 
//
[0.x.32464] 
[0.x.32465] 
[0.x.32466] 
//
[0.x.32467] 
[0.x.32468] 
[0.x.32469] 
[0.x.32470] 
[0.x.32471] 
[0.x.32472] 
[0.x.32473] 
//
[0.x.32474] 
[0.x.32475] 
[0.x.32476] 
[0.x.32477] 
[0.x.32478] 
//
[0.x.32479] 
[0.x.32480] 
//[2.x.3771] 
//[2.x.3772] 
//
// The constructor of this class looks very similar to the one in  [2.x.3773] . The only difference is the viscosity and the Augmented Lagrangian coefficient  [2.x.3774] .
//
[0.x.32481] 
[0.x.32482] 
[0.x.32483] 
[0.x.32484] 
[0.x.32485] 
[0.x.32486] 
[0.x.32487] 
[0.x.32488] 
[0.x.32489] 
//[2.x.3775] 
//
// This function initializes the DoFHandler enumerating the degrees of freedom and constraints on the current mesh.
//
[0.x.32490] 
[0.x.32491] 
[0.x.32492] 
[0.x.32493] 
[0.x.32494] 
//
// The first step is to associate DoFs with a given mesh.
//
[0.x.32495] 
//
// We renumber the components to have all velocity DoFs come before the pressure DoFs to be able to split the solution vector in two blocks which are separately accessed in the block preconditioner.
//
[0.x.32496] 
[0.x.32497] 
[0.x.32498] 
//
[0.x.32499] 
[0.x.32500] 
[0.x.32501] 
[0.x.32502] 
//
// In Newton's scheme, we first apply the boundary condition on the solution obtained from the initial step. To make sure the boundary conditions remain satisfied during Newton's iteration, zero boundary conditions are used for the update  [2.x.3776] . Therefore we set up two different constraint objects.
//
[0.x.32503] 
[0.x.32504] 
[0.x.32505] 
//
[0.x.32506] 
[0.x.32507] 
[0.x.32508] 
[0.x.32509] 
[0.x.32510] 
[0.x.32511] 
[0.x.32512] 
[0.x.32513] 
//
[0.x.32514] 
[0.x.32515] 
//
[0.x.32516] 
[0.x.32517] 
[0.x.32518] 
[0.x.32519] 
[0.x.32520] 
[0.x.32521] 
[0.x.32522] 
[0.x.32523] 
[0.x.32524] 
//
[0.x.32525] 
[0.x.32526] 
[0.x.32527] 
[0.x.32528] 
[0.x.32529] 
//[2.x.3777] 
//
// On each mesh the SparsityPattern and the size of the linear system are different. This function initializes them after mesh refinement.
//
[0.x.32530] 
[0.x.32531] 
[0.x.32532] 
[0.x.32533] 
[0.x.32534] 
[0.x.32535] 
[0.x.32536] 
[0.x.32537] 
//
[0.x.32538] 
//
[0.x.32539] 
[0.x.32540] 
[0.x.32541] 
[0.x.32542] 
//[2.x.3778] 
//
// This function builds the system matrix and right hand side that we currently work on. The  [2.x.3779]  argument is used to determine which set of constraints we apply (nonzero for the initial step and zero for the others). The  [2.x.3780]  argument determines whether to assemble the whole system or only the right hand side vector, respectively.
//
[0.x.32543] 
[0.x.32544] 
[0.x.32545] 
[0.x.32546] 
[0.x.32547] 
[0.x.32548] 
//
[0.x.32549] 
//
[0.x.32550] 
//
[0.x.32551] 
[0.x.32552] 
[0.x.32553] 
[0.x.32554] 
//
[0.x.32555] 
[0.x.32556] 
//
[0.x.32557] 
[0.x.32558] 
//
[0.x.32559] 
[0.x.32560] 
//
[0.x.32561] 
//
// For the linearized system, we create temporary storage for present velocity and gradient, and present pressure. In practice, they are all obtained through their shape functions at quadrature points.
//
[0.x.32562] 
[0.x.32563] 
[0.x.32564] 
//
[0.x.32565] 
[0.x.32566] 
[0.x.32567] 
[0.x.32568] 
//
[0.x.32569] 
[0.x.32570] 
[0.x.32571] 
//
[0.x.32572] 
[0.x.32573] 
//
[0.x.32574] 
[0.x.32575] 
//
[0.x.32576] 
[0.x.32577] 
//
[0.x.32578] 
[0.x.32579] 
//
// The assembly is similar to  [2.x.3781] . An additional term with gamma as a coefficient is the Augmented Lagrangian (AL), which is assembled via grad-div stabilization.  As we discussed in the introduction, the bottom right block of the system matrix should be zero. Since the pressure mass matrix is used while creating the preconditioner, we assemble it here and then move it into a separate SparseMatrix at the end (same as in  [2.x.3782] ).
//
[0.x.32580] 
[0.x.32581] 
[0.x.32582] 
[0.x.32583] 
[0.x.32584] 
[0.x.32585] 
[0.x.32586] 
[0.x.32587] 
[0.x.32588] 
//
[0.x.32589] 
[0.x.32590] 
[0.x.32591] 
[0.x.32592] 
[0.x.32593] 
[0.x.32594] 
[0.x.32595] 
[0.x.32596] 
[0.x.32597] 
[0.x.32598] 
[0.x.32599] 
[0.x.32600] 
[0.x.32601] 
[0.x.32602] 
[0.x.32603] 
[0.x.32604] 
[0.x.32605] 
[0.x.32606] 
//
[0.x.32607] 
[0.x.32608] 
[0.x.32609] 
[0.x.32610] 
[0.x.32611] 
[0.x.32612] 
[0.x.32613] 
[0.x.32614] 
[0.x.32615] 
[0.x.32616] 
[0.x.32617] 
[0.x.32618] 
[0.x.32619] 
//
[0.x.32620] 
//
[0.x.32621] 
[0.x.32622] 
//
[0.x.32623] 
[0.x.32624] 
[0.x.32625] 
[0.x.32626] 
[0.x.32627] 
[0.x.32628] 
[0.x.32629] 
[0.x.32630] 
[0.x.32631] 
[0.x.32632] 
[0.x.32633] 
[0.x.32634] 
[0.x.32635] 
[0.x.32636] 
[0.x.32637] 
//
[0.x.32638] 
[0.x.32639] 
//
// Finally we move pressure mass matrix into a separate matrix:
//
[0.x.32640] 
[0.x.32641] 
//
// Note that settings this pressure block to zero is not identical to not assembling anything in this block, because this operation here will (incorrectly) delete diagonal entries that come in from hanging node constraints for pressure DoFs. This means that our whole system matrix will have rows that are completely zero. Luckily, FGMRES handles these rows without any problem.
//
[0.x.32642] 
[0.x.32643] 
[0.x.32644] 
//
[0.x.32645] 
[0.x.32646] 
[0.x.32647] 
[0.x.32648] 
[0.x.32649] 
//
[0.x.32650] 
[0.x.32651] 
[0.x.32652] 
[0.x.32653] 
[0.x.32654] 
//[2.x.3783] 
//
// In this function, we use FGMRES together with the block preconditioner, which is defined at the beginning of the program, to solve the linear system. What we obtain at this step is the solution vector. If this is the initial step, the solution vector gives us an initial guess for the Navier Stokes equations. For the initial step, nonzero constraints are applied in order to make sure boundary conditions are satisfied. In the following steps, we will solve for the Newton update so zero constraints are used.
//
[0.x.32655] 
[0.x.32656] 
[0.x.32657] 
[0.x.32658] 
[0.x.32659] 
//
[0.x.32660] 
[0.x.32661] 
[0.x.32662] 
//
[0.x.32663] 
[0.x.32664] 
[0.x.32665] 
[0.x.32666] 
//
[0.x.32667] 
[0.x.32668] 
[0.x.32669] 
[0.x.32670] 
[0.x.32671] 
[0.x.32672] 
//
[0.x.32673] 
[0.x.32674] 
//
[0.x.32675] 
[0.x.32676] 
//[2.x.3784] 
//
// After finding a good initial guess on the coarse mesh, we hope to decrease the error through refining the mesh. Here we do adaptive refinement similar to  [2.x.3785]  except that we use the Kelly estimator on the velocity only. We also need to transfer the current solution to the next mesh using the SolutionTransfer class.
//
[0.x.32677] 
[0.x.32678] 
[0.x.32679] 
[0.x.32680] 
[0.x.32681] 
[0.x.32682] 
[0.x.32683] 
[0.x.32684] 
[0.x.32685] 
[0.x.32686] 
[0.x.32687] 
[0.x.32688] 
//
[0.x.32689] 
[0.x.32690] 
[0.x.32691] 
[0.x.32692] 
//
[0.x.32693] 
[0.x.32694] 
[0.x.32695] 
[0.x.32696] 
//
// First the DoFHandler is set up and constraints are generated. Then we create a temporary BlockVector  [2.x.3786] , whose size is according with the solution on the new mesh.
//
[0.x.32697] 
//
[0.x.32698] 
//
// Transfer solution from coarse to fine mesh and apply boundary value constraints to the new transferred solution. Note that present_solution is still a vector corresponding to the old mesh.
//
[0.x.32699] 
[0.x.32700] 
//
// Finally set up matrix and vectors and set the present_solution to the interpolated data.
//
[0.x.32701] 
[0.x.32702] 
[0.x.32703] 
//[2.x.3787] 
//
// This function implements the Newton iteration with given tolerance, maximum number of iterations, and the number of mesh refinements to do.
//
// The argument  [2.x.3788]  tells us whether  [2.x.3789]  is necessary, and which part, system matrix or right hand side vector, should be assembled. If we do a line search, the right hand side is already assembled while checking the residual norm in the last iteration. Therefore, we just need to assemble the system matrix at the current iteration. The last argument  [2.x.3790]  determines whether or not graphical output should be produced.
//
[0.x.32704] 
[0.x.32705] 
[0.x.32706] 
[0.x.32707] 
[0.x.32708] 
[0.x.32709] 
[0.x.32710] 
[0.x.32711] 
[0.x.32712] 
//
[0.x.32713] 
[0.x.32714] 
[0.x.32715] 
[0.x.32716] 
[0.x.32717] 
[0.x.32718] 
[0.x.32719] 
[0.x.32720] 
//
[0.x.32721] 
[0.x.32722] 
[0.x.32723] 
[0.x.32724] 
[0.x.32725] 
[0.x.32726] 
[0.x.32727] 
[0.x.32728] 
[0.x.32729] 
[0.x.32730] 
[0.x.32731] 
[0.x.32732] 
[0.x.32733] 
[0.x.32734] 
[0.x.32735] 
[0.x.32736] 
[0.x.32737] 
[0.x.32738] 
[0.x.32739] 
[0.x.32740] 
[0.x.32741] 
[0.x.32742] 
[0.x.32743] 
[0.x.32744] 
[0.x.32745] 
//
//       To make sure our solution is getting close to the exact       solution, we let the solution be updated with a weight        [2.x.3791]  such that the new residual is smaller       than the one of last step, which is done in the following       loop. This is the same line search algorithm used in        [2.x.3792] .
//
[0.x.32746] 
[0.x.32747] 
[0.x.32748] 
[0.x.32749] 
[0.x.32750] 
[0.x.32751] 
[0.x.32752] 
[0.x.32753] 
[0.x.32754] 
[0.x.32755] 
[0.x.32756] 
[0.x.32757] 
[0.x.32758] 
[0.x.32759] 
[0.x.32760] 
[0.x.32761] 
[0.x.32762] 
[0.x.32763] 
[0.x.32764] 
[0.x.32765] 
[0.x.32766] 
//
[0.x.32767] 
[0.x.32768] 
[0.x.32769] 
[0.x.32770] 
//
[0.x.32771] 
[0.x.32772] 
[0.x.32773] 
[0.x.32774] 
//
[0.x.32775] 
[0.x.32776] 
[0.x.32777] 
[0.x.32778] 
[0.x.32779] 
[0.x.32780] 
//[2.x.3793] 
//
// This function will provide us with an initial guess by using a continuation method as we discussed in the introduction. The Reynolds number is increased  [2.x.3794] by-step until we reach the target value. By experiment, the solution to Stokes is good enough to be the initial guess of NSE with Reynolds number 1000 so we start there.  To make sure the solution from previous problem is close enough to the next one, the step size must be small enough.
//
[0.x.32781] 
[0.x.32782] 
[0.x.32783] 
[0.x.32784] 
//
[0.x.32785] 
//
[0.x.32786] 
[0.x.32787] 
[0.x.32788] 
[0.x.32789] 
[0.x.32790] 
[0.x.32791] 
[0.x.32792] 
[0.x.32793] 
[0.x.32794] 
[0.x.32795] 
//[2.x.3795] 
//
// This function is the same as in  [2.x.3796]  except that we choose a name for the output file that also contains the Reynolds number (i.e., the inverse of the viscosity in the current context).
//
[0.x.32796] 
[0.x.32797] 
[0.x.32798] 
[0.x.32799] 
[0.x.32800] 
[0.x.32801] 
//
[0.x.32802] 
[0.x.32803] 
[0.x.32804] 
[0.x.32805] 
[0.x.32806] 
[0.x.32807] 
[0.x.32808] 
[0.x.32809] 
[0.x.32810] 
[0.x.32811] 
[0.x.32812] 
[0.x.32813] 
//
[0.x.32814] 
[0.x.32815] 
[0.x.32816] 
[0.x.32817] 
//[2.x.3797] 
//
// In our test case, we do not know the analytical solution. This function outputs the velocity components along  [2.x.3798]  and  [2.x.3799]  so they can be compared with data from the literature.
//
[0.x.32818] 
[0.x.32819] 
[0.x.32820] 
[0.x.32821] 
[0.x.32822] 
[0.x.32823] 
//
[0.x.32824] 
[0.x.32825] 
[0.x.32826] 
//
[0.x.32827] 
//
[0.x.32828] 
[0.x.32829] 
[0.x.32830] 
//
[0.x.32831] 
[0.x.32832] 
[0.x.32833] 
//
[0.x.32834] 
[0.x.32835] 
[0.x.32836] 
[0.x.32837] 
[0.x.32838] 
//[2.x.3800] 
//
// This is the last step of this program. In this part, we generate the grid and run the other functions respectively. The max refinement can be set by the argument.
//
[0.x.32839] 
[0.x.32840] 
[0.x.32841] 
[0.x.32842] 
[0.x.32843] 
//
[0.x.32844] 
//
// If the viscosity is smaller than  [2.x.3801] , we have to first search for an initial guess via a continuation method. What we should notice is the search is always on the initial mesh, that is the  [2.x.3802]  mesh in this program. After that, we just do the same as we did when viscosity is larger than  [2.x.3803] : run Newton's iteration, refine the mesh, transfer solutions, and repeat.
//
[0.x.32845] 
[0.x.32846] 
[0.x.32847] 
[0.x.32848] 
[0.x.32849] 
[0.x.32850] 
[0.x.32851] 
[0.x.32852] 
[0.x.32853] 
[0.x.32854] 
[0.x.32855] 
[0.x.32856] 
//
// When the viscosity is larger than 1/1000, the solution to Stokes equations is good enough as an initial guess. If so, we do not need to search for the initial guess using a continuation method. Newton's iteration can be started directly.
//
[0.x.32857] 
[0.x.32858] 
[0.x.32859] 
[0.x.32860] 
//
[0.x.32861] 
[0.x.32862] 
[0.x.32863] 
[0.x.32864] 
[0.x.32865] 
//
[0.x.32866] 
[0.x.32867] 
[0.x.32868] 
[0.x.32869] 
[0.x.32870] 
[0.x.32871] 
[0.x.32872] 
[0.x.32873] 
[0.x.32874] 
[0.x.32875] 
[0.x.32876] 
[0.x.32877] 
[0.x.32878] 
[0.x.32879] 
[0.x.32880] 
[0.x.32881] 
[0.x.32882] 
[0.x.32883] 
[0.x.32884] 
[0.x.32885] 
[0.x.32886] 
[0.x.32887] 
[0.x.32888] 
[0.x.32889] 
[0.x.32890] 
[0.x.32891] 
[0.x.32892] 
[0.x.32893] 
[0.x.32894] 
[0.x.32895] 
[0.x.32896] 
[0.x.32897] 
[0.x.32898] 
[0.x.32899] 
[0.x.32900] 
[0.x.32901] 
[0.x.32902] 
[0.x.32903] 
[0.x.32904] 
[0.x.32905] 
[0.x.32906] 
[0.x.32907] 
[0.x.32908] 
[0.x.32909] 
[0.x.32910] 
[0.x.32911] 
[0.x.32912] 
[0.x.32913] 
//[2.x.3804]  The program starts with the usual include files, all of which you should have seen before by now:
//
[0.x.32914] 
[0.x.32915] 
[0.x.32916] 
[0.x.32917] 
[0.x.32918] 
[0.x.32919] 
[0.x.32920] 
[0.x.32921] 
[0.x.32922] 
[0.x.32923] 
[0.x.32924] 
[0.x.32925] 
[0.x.32926] 
[0.x.32927] 
[0.x.32928] 
[0.x.32929] 
[0.x.32930] 
[0.x.32931] 
[0.x.32932] 
[0.x.32933] 
//
[0.x.32934] 
[0.x.32935] 
//
// Then the usual placing of all content of this program into a namespace and the importation of the deal.II namespace into the one we will work in:
//
[0.x.32936] 
[0.x.32937] 
[0.x.32938] 
//[2.x.3805] 
//
// Then the main class. It looks very much like the corresponding classes in  [2.x.3806]  or  [2.x.3807] , with the only exception that the matrices and vectors and everything else related to the linear system are now storing elements of type  [2.x.3808]  instead of just `double`.
//
[0.x.32939] 
[0.x.32940] 
[0.x.32941] 
[0.x.32942] 
[0.x.32943] 
[0.x.32944] 
//
[0.x.32945] 
[0.x.32946] 
[0.x.32947] 
[0.x.32948] 
[0.x.32949] 
[0.x.32950] 
//
[0.x.32951] 
[0.x.32952] 
[0.x.32953] 
//
[0.x.32954] 
//
[0.x.32955] 
[0.x.32956] 
[0.x.32957] 
//
[0.x.32958] 
[0.x.32959] 
//
[0.x.32960] 
[0.x.32961] 
[0.x.32962] 
//
[0.x.32963] 
[0.x.32964] 
//
//  [2.x.3809] 
//
// Before we go on filling in the details of the main class, let us define the equation data corresponding to the problem, i.e. initial values, as well as a right hand side class. (We will reuse the initial conditions also for the boundary values, which we simply keep constant.) We do so using classes derived from the Function class template that has been used many times before, so the following should not look surprising. The only point of interest is that we here have a complex-valued problem, so we have to provide the second template argument of the Function class (which would otherwise default to `double`). Furthermore, the return type of the `value()` functions is then of course also complex.
//
// What precisely these functions return has been discussed at the end of the Introduction section.
//
[0.x.32965] 
[0.x.32966] 
[0.x.32967] 
[0.x.32968] 
[0.x.32969] 
[0.x.32970] 
[0.x.32971] 
//
[0.x.32972] 
[0.x.32973] 
[0.x.32974] 
//
[0.x.32975] 
[0.x.32976] 
[0.x.32977] 
[0.x.32978] 
[0.x.32979] 
[0.x.32980] 
//
[0.x.32981] 
[0.x.32982] 
//
[0.x.32983] 
[0.x.32984] 
[0.x.32985] 
[0.x.32986] 
//
[0.x.32987] 
[0.x.32988] 
[0.x.32989] 
//
[0.x.32990] 
[0.x.32991] 
[0.x.32992] 
[0.x.32993] 
[0.x.32994] 
//
[0.x.32995] 
[0.x.32996] 
//
[0.x.32997] 
[0.x.32998] 
//
[0.x.32999] 
[0.x.33000] 
[0.x.33001] 
[0.x.33002] 
[0.x.33003] 
[0.x.33004] 
[0.x.33005] 
[0.x.33006] 
//
[0.x.33007] 
[0.x.33008] 
[0.x.33009] 
[0.x.33010] 
[0.x.33011] 
[0.x.33012] 
//
[0.x.33013] 
[0.x.33014] 
//
//  [2.x.3810] 
//
// We start by specifying the implementation of the constructor of the class. There is nothing of surprise to see here except perhaps that we choose quadratic ( [2.x.3811] ) Lagrange elements -- the solution is expected to be smooth, so we choose a higher polynomial degree than the bare minimum.
//
[0.x.33015] 
[0.x.33016] 
[0.x.33017] 
[0.x.33018] 
[0.x.33019] 
[0.x.33020] 
[0.x.33021] 
[0.x.33022] 
[0.x.33023] 
//[2.x.3812] 
//
// The next function is the one that sets up the mesh, DoFHandler, and matrices and vectors at the beginning of the program, i.e. before the first time step. The first few lines are pretty much standard if you've read through the tutorial programs at least up to  [2.x.3813] :
//
[0.x.33024] 
[0.x.33025] 
[0.x.33026] 
[0.x.33027] 
[0.x.33028] 
//
[0.x.33029] 
[0.x.33030] 
//
[0.x.33031] 
//
[0.x.33032] 
[0.x.33033] 
[0.x.33034] 
//
[0.x.33035] 
[0.x.33036] 
[0.x.33037] 
//
[0.x.33038] 
[0.x.33039] 
//
[0.x.33040] 
[0.x.33041] 
//
[0.x.33042] 
[0.x.33043] 
//
// Next, we assemble the relevant matrices. The way we have written the Crank-Nicolson discretization of the spatial step of the Strang splitting (i.e., the second of the three partial steps in each time step), we were led to the linear system  [2.x.3814] . In other words, there are two matrices in play here -- one for the left and one for the right hand side. We build these matrices separately. (One could avoid building the right hand side matrix and instead just form the *action* of the matrix on  [2.x.3815]  in each time step. This may or may not be more efficient, but efficiency is not foremost on our minds for this program.)
//
[0.x.33044] 
[0.x.33045] 
[0.x.33046] 
[0.x.33047] 
//
[0.x.33048] 
[0.x.33049] 
[0.x.33050] 
[0.x.33051] 
//
[0.x.33052] 
[0.x.33053] 
//
[0.x.33054] 
[0.x.33055] 
[0.x.33056] 
[0.x.33057] 
//
[0.x.33058] 
[0.x.33059] 
[0.x.33060] 
//
[0.x.33061] 
[0.x.33062] 
[0.x.33063] 
[0.x.33064] 
//
[0.x.33065] 
//
[0.x.33066] 
[0.x.33067] 
//
[0.x.33068] 
[0.x.33069] 
[0.x.33070] 
[0.x.33071] 
[0.x.33072] 
[0.x.33073] 
[0.x.33074] 
//
[0.x.33075] 
[0.x.33076] 
[0.x.33077] 
[0.x.33078] 
[0.x.33079] 
[0.x.33080] 
[0.x.33081] 
[0.x.33082] 
[0.x.33083] 
//
[0.x.33084] 
[0.x.33085] 
[0.x.33086] 
[0.x.33087] 
[0.x.33088] 
[0.x.33089] 
[0.x.33090] 
[0.x.33091] 
[0.x.33092] 
[0.x.33093] 
[0.x.33094] 
[0.x.33095] 
//
[0.x.33096] 
[0.x.33097] 
[0.x.33098] 
[0.x.33099] 
[0.x.33100] 
[0.x.33101] 
[0.x.33102] 
[0.x.33103] 
[0.x.33104] 
//[2.x.3816] 
//
// Having set up all data structures above, we are now in a position to implement the partial steps that form the Strang splitting scheme. We start with the half-step to advance the phase, and that is used as the first and last part of each time step.
//
// To this end, recall that for the first half step, we needed to compute  [2.x.3817] . Here,  [2.x.3818]  and   [2.x.3819]  are functions of space and correspond to the output of the previous complete time step and the result of the first of the three part steps, respectively. A corresponding solution must be computed for the third of the part steps, i.e.  [2.x.3820] , where  [2.x.3821]  is the result of the time step as a whole, and its input  [2.x.3822]  is the result of the spatial step of the Strang splitting.
//
// An important realization is that while  [2.x.3823]  may be a finite element function (i.e., is piecewise polynomial), this may not necessarily be the case for the "rotated" function in which we have updated the phase using the exponential factor (recall that the amplitude of that function remains constant as part of that step). In other words, we could *compute*  [2.x.3824]  at every point  [2.x.3825] , but we can't represent it on a mesh because it is not a piecewise polynomial function. The best we can do in a discrete setting is to compute a projection or interpolation. In other words, we can compute  [2.x.3826]  where  [2.x.3827]  is a projection or interpolation operator. The situation is particularly simple if we choose the interpolation: Then, all we need to compute is the value of the right hand side *at the node points* and use these as nodal values for the vector  [2.x.3828]  of degrees of freedom. This is easily done because evaluating the right hand side at node points for a Lagrange finite element as used here requires us to only look at a single (complex-valued) entry of the node vector. In other words, what we need to do is to compute  [2.x.3829]  where  [2.x.3830]  loops over all of the entries of our solution vector. This is what the function below does -- in fact, it doesn't even use separate vectors for  [2.x.3831]  and  [2.x.3832] , but just updates the same vector as appropriate.
//
[0.x.33105] 
[0.x.33106] 
[0.x.33107] 
[0.x.33108] 
[0.x.33109] 
[0.x.33110] 
[0.x.33111] 
//
[0.x.33112] 
[0.x.33113] 
[0.x.33114] 
[0.x.33115] 
//
// The next step is to solve for the linear system in each time step, i.e., the second half step of the Strang splitting we use. Recall that it had the form  [2.x.3833]  where  [2.x.3834]  and  [2.x.3835]  are the matrices we assembled earlier.
//
// The way we solve this here is using a direct solver. We first form the right hand side  [2.x.3836]  using the  [2.x.3837]  function and put the result into the `system_rhs` variable. We then call  [2.x.3838]  which takes as argument the matrix  [2.x.3839]  and the right hand side vector and returns the solution in the same vector `system_rhs`. The final step is then to put the solution so computed back into the `solution` variable.
//
[0.x.33116] 
[0.x.33117] 
[0.x.33118] 
[0.x.33119] 
//
[0.x.33120] 
[0.x.33121] 
//
[0.x.33122] 
[0.x.33123] 
//
//  [2.x.3840] 
//
// The last of the helper functions and classes we ought to discuss are the ones that create graphical output. The result of running the half and full steps for the local and spatial parts of the Strang splitting is that we have updated the `solution` vector  [2.x.3841]  to the correct value at the end of each time step. Its entries contain complex numbers for the solution at the nodes of the finite element mesh.
//
// Complex numbers are not easily visualized. We can output their real and imaginary parts, i.e., the fields  [2.x.3842]  and  [2.x.3843] , and that is exactly what the DataOut class does when one attaches as complex-valued vector via  [2.x.3844]  and then calls  [2.x.3845]  That is indeed what we do below.
//
// But oftentimes we are not particularly interested in real and imaginary parts of the solution vector, but instead in derived quantities such as the magnitude  [2.x.3846]  and phase angle  [2.x.3847]  of the solution. In the context of quantum systems such as here, the magnitude itself is not so interesting, but instead it is the "amplitude",  [2.x.3848]  that is a physical property: it corresponds to the probability density of finding a particle in a particular place of state. The way to put computed quantities into output files for visualization -- as used in numerous previous tutorial programs -- is to use the facilities of the DataPostprocessor and derived classes. Specifically, both the amplitude of a complex number and its phase angles are scalar quantities, and so the DataPostprocessorScalar class is the right tool to base what we want to do on.
//
// Consequently, what we do here is to implement two classes `ComplexAmplitude` and `ComplexPhase` that compute for each point at which DataOut decides to generate output, the amplitudes  [2.x.3849]  and phases  [2.x.3850]  of the solution for visualization. There is a fair amount of boiler-plate code below, with the only interesting parts of the first of these two classes being how its `evaluate_vector_field()` function computes the `computed_quantities` object.
//
// (There is also the rather awkward fact that the [1.x.108] function does not compute what one would naively imagine, namely  [2.x.3851] , but returns  [2.x.3852]  instead. It's certainly quite confusing to have a standard function mis-named in such a way...)
//
[0.x.33124] 
[0.x.33125] 
[0.x.33126] 
[0.x.33127] 
[0.x.33128] 
[0.x.33129] 
[0.x.33130] 
//
[0.x.33131] 
[0.x.33132] 
[0.x.33133] 
[0.x.33134] 
//
[0.x.33135] 
[0.x.33136] 
[0.x.33137] 
[0.x.33138] 
//
[0.x.33139] 
[0.x.33140] 
[0.x.33141] 
[0.x.33142] 
[0.x.33143] 
[0.x.33144] 
[0.x.33145] 
[0.x.33146] 
//
[0.x.33147] 
[0.x.33148] 
[0.x.33149] 
[0.x.33150] 
[0.x.33151] 
[0.x.33152] 
//
[0.x.33153] 
[0.x.33154] 
[0.x.33155] 
[0.x.33156] 
[0.x.33157] 
//
// The second of these postprocessor classes computes the phase angle of the complex-valued solution at each point. In other words, if we represent  [2.x.3853] , then this class computes  [2.x.3854] . The function [1.x.109] does this for us, and returns the angle as a real number between  [2.x.3855]  and  [2.x.3856] .
//
// For reasons that we will explain in detail in the results section, we do not actually output this value at each location where output is generated. Rather, we take the maximum over all evaluation points of the phase and then fill each evaluation point's output field with this maximum -- in essence, we output the phase angle as a piecewise constant field, where each cell has its own constant value. The reasons for this will become clear once you read through the discussion further down below.
//
[0.x.33158] 
[0.x.33159] 
[0.x.33160] 
[0.x.33161] 
[0.x.33162] 
//
[0.x.33163] 
[0.x.33164] 
[0.x.33165] 
[0.x.33166] 
//
[0.x.33167] 
[0.x.33168] 
[0.x.33169] 
[0.x.33170] 
//
[0.x.33171] 
[0.x.33172] 
[0.x.33173] 
[0.x.33174] 
[0.x.33175] 
[0.x.33176] 
[0.x.33177] 
[0.x.33178] 
//
[0.x.33179] 
[0.x.33180] 
[0.x.33181] 
[0.x.33182] 
[0.x.33183] 
[0.x.33184] 
[0.x.33185] 
//
[0.x.33186] 
[0.x.33187] 
[0.x.33188] 
[0.x.33189] 
[0.x.33190] 
[0.x.33191] 
//
[0.x.33192] 
[0.x.33193] 
[0.x.33194] 
//
[0.x.33195] 
//
// Having so implemented these post-processors, we create output as we always do. As in many other time-dependent tutorial programs, we attach flags to DataOut that indicate the number of the time step and the current simulation time.
//
[0.x.33196] 
[0.x.33197] 
[0.x.33198] 
[0.x.33199] 
[0.x.33200] 
//
[0.x.33201] 
//
[0.x.33202] 
[0.x.33203] 
[0.x.33204] 
[0.x.33205] 
[0.x.33206] 
//
[0.x.33207] 
//
[0.x.33208] 
[0.x.33209] 
[0.x.33210] 
[0.x.33211] 
[0.x.33212] 
//
//  [2.x.3857] 
//
// The remaining step is how we set up the overall logic for this program. It's really relatively simple: Set up the data structures; interpolate the initial conditions onto finite element space; then iterate over all time steps, and on each time step perform the three parts of the Strang splitting method. Every tenth time step, we generate graphical output. That's it.
//
[0.x.33213] 
[0.x.33214] 
[0.x.33215] 
[0.x.33216] 
[0.x.33217] 
//
[0.x.33218] 
[0.x.33219] 
[0.x.33220] 
//
[0.x.33221] 
[0.x.33222] 
[0.x.33223] 
[0.x.33224] 
//
[0.x.33225] 
[0.x.33226] 
//
[0.x.33227] 
[0.x.33228] 
[0.x.33229] 
//
[0.x.33230] 
[0.x.33231] 
[0.x.33232] 
[0.x.33233] 
[0.x.33234] 
//
//  [2.x.3858] 
//
// The rest is again boiler plate and exactly as in almost all of the previous tutorial programs:
//
[0.x.33235] 
[0.x.33236] 
[0.x.33237] 
[0.x.33238] 
[0.x.33239] 
//
[0.x.33240] 
[0.x.33241] 
[0.x.33242] 
[0.x.33243] 
[0.x.33244] 
[0.x.33245] 
[0.x.33246] 
[0.x.33247] 
[0.x.33248] 
[0.x.33249] 
[0.x.33250] 
[0.x.33251] 
[0.x.33252] 
[0.x.33253] 
[0.x.33254] 
[0.x.33255] 
[0.x.33256] 
[0.x.33257] 
[0.x.33258] 
[0.x.33259] 
[0.x.33260] 
[0.x.33261] 
[0.x.33262] 
[0.x.33263] 
[0.x.33264] 
[0.x.33265] 
[0.x.33266] 
[0.x.33267] 
[0.x.33268] 
[0.x.33269] 
[0.x.33270] 
[0.x.33271] 
[0.x.33272] 
[0.x.33273] 
[0.x.33274] 
[0.x.33275] 
[0.x.33276] 
[0.x.33277] 
[0.x.33278] 
[0.x.33279] 
[0.x.33280] 
[0.x.33281] 
[0.x.33282] 
[0.x.33283] 
//
[0.x.33284] 
[0.x.33285] 
[0.x.33286] 
//
// The include files are essentially the same as in  [2.x.3859] , with the exception of the finite element class FE_DGQHermite instead of FE_Q. All functionality for matrix-free computations on face integrals is already contained in `fe_evaluation.h`.
//
[0.x.33287] 
[0.x.33288] 
[0.x.33289] 
[0.x.33290] 
//
[0.x.33291] 
[0.x.33292] 
[0.x.33293] 
[0.x.33294] 
[0.x.33295] 
[0.x.33296] 
//
[0.x.33297] 
[0.x.33298] 
//
[0.x.33299] 
[0.x.33300] 
[0.x.33301] 
//
[0.x.33302] 
[0.x.33303] 
[0.x.33304] 
[0.x.33305] 
[0.x.33306] 
[0.x.33307] 
//
[0.x.33308] 
//
[0.x.33309] 
[0.x.33310] 
//
[0.x.33311] 
[0.x.33312] 
//
[0.x.33313] 
[0.x.33314] 
[0.x.33315] 
//
// As in  [2.x.3860] , we collect the dimension and polynomial degree as constants here at the top of the program for simplicity. As opposed to  [2.x.3861] , we choose a really high order method this time with degree 8 where any implementation not using sum factorization would become prohibitively slow compared to the implementation with MatrixFree which provides an efficiency that is essentially the same as at degrees two or three. Furthermore, all classes in this tutorial program are templated, so it would be easy to select the degree at run time from an input file or a command-line argument by adding instantiations of the appropriate degrees in the `main()` function.
//
[0.x.33316] 
[0.x.33317] 
//[2.x.3862] 
//
// In analogy to  [2.x.3863] , we define an analytic solution that we try to reproduce with our discretization. Since the aim of this tutorial is to show matrix-free methods, we choose one of the simplest possibilities, namely a cosine function whose derivatives are simple enough for us to compute analytically. Further down, the wave number 2.4 we select here will be matched with the domain extent in  [2.x.3864] -direction that is 2.5, such that we obtain a periodic solution at  [2.x.3865]  including  [2.x.3866]  or three full wave revolutions in the cosine. The first function defines the solution and its gradient for expressing the analytic solution for the Dirichlet and Neumann boundary conditions, respectively. Furthermore, a class representing the negative Laplacian of the solution is used to represent the right hand side (forcing) function that we use to match the given analytic solution in the discretized version (manufactured solution).
//
[0.x.33318] 
[0.x.33319] 
[0.x.33320] 
[0.x.33321] 
[0.x.33322] 
[0.x.33323] 
[0.x.33324] 
[0.x.33325] 
[0.x.33326] 
[0.x.33327] 
[0.x.33328] 
[0.x.33329] 
//
[0.x.33330] 
[0.x.33331] 
[0.x.33332] 
[0.x.33333] 
[0.x.33334] 
[0.x.33335] 
[0.x.33336] 
[0.x.33337] 
[0.x.33338] 
[0.x.33339] 
[0.x.33340] 
[0.x.33341] 
[0.x.33342] 
[0.x.33343] 
[0.x.33344] 
[0.x.33345] 
[0.x.33346] 
//
[0.x.33347] 
[0.x.33348] 
[0.x.33349] 
[0.x.33350] 
[0.x.33351] 
[0.x.33352] 
[0.x.33353] 
[0.x.33354] 
[0.x.33355] 
[0.x.33356] 
[0.x.33357] 
[0.x.33358] 
[0.x.33359] 
[0.x.33360] 
//
//  [2.x.3867] 
//
// The `LaplaceOperator` class is similar to the respective class in  [2.x.3868] . A significant difference is that we do not derive the class from  [2.x.3869]  because we want to present some additional features of  [2.x.3870]  that are not available in the general-purpose class  [2.x.3871]  We derive the class from the Subscriptor class to be able to use the operator within the Chebyshev preconditioner because that preconditioner stores the underlying matrix via a SmartPointer.
//
// Given that we implement a complete matrix interface by hand, we need to add an `initialize()` function, an `m()` function, a `vmult()` function, and a `Tvmult()` function that were previously provided by  [2.x.3872]  Our LaplaceOperator also contains a member function `get_penalty_factor()` that centralizes the selection of the penalty parameter in the symmetric interior penalty method according to  [2.x.3873] .
//
[0.x.33361] 
[0.x.33362] 
[0.x.33363] 
[0.x.33364] 
[0.x.33365] 
//
[0.x.33366] 
//
[0.x.33367] 
//
[0.x.33368] 
//
[0.x.33369] 
//
[0.x.33370] 
[0.x.33371] 
//
[0.x.33372] 
//
[0.x.33373] 
[0.x.33374] 
//
[0.x.33375] 
[0.x.33376] 
//
[0.x.33377] 
[0.x.33378] 
[0.x.33379] 
[0.x.33380] 
//
[0.x.33381] 
[0.x.33382] 
[0.x.33383] 
[0.x.33384] 
[0.x.33385] 
[0.x.33386] 
//
[0.x.33387] 
[0.x.33388] 
[0.x.33389] 
[0.x.33390] 
[0.x.33391] 
//
[0.x.33392] 
[0.x.33393] 
[0.x.33394] 
[0.x.33395] 
[0.x.33396] 
//
[0.x.33397] 
[0.x.33398] 
//
// The `%PreconditionBlockJacobi` class defines our custom preconditioner for this problem. As opposed to  [2.x.3874]  which was based on the matrix diagonal, we here compute an approximate inversion of the diagonal blocks in the discontinuous Galerkin method by using the so-called fast diagonalization method discussed in the introduction.
//
[0.x.33399] 
[0.x.33400] 
[0.x.33401] 
[0.x.33402] 
[0.x.33403] 
//
[0.x.33404] 
[0.x.33405] 
[0.x.33406] 
[0.x.33407] 
//
[0.x.33408] 
//
[0.x.33409] 
[0.x.33410] 
//
[0.x.33411] 
[0.x.33412] 
[0.x.33413] 
[0.x.33414] 
[0.x.33415] 
//
[0.x.33416] 
[0.x.33417] 
[0.x.33418] 
[0.x.33419] 
[0.x.33420] 
[0.x.33421] 
[0.x.33422] 
//
// This free-standing function is used in both the `LaplaceOperator` and `%PreconditionBlockJacobi` classes to adjust the ghost range. This function is necessary because some of the vectors that the `vmult()` functions are supplied with are not initialized properly with  [2.x.3875]  that includes the correct layout of ghost entries, but instead comes from the MGTransferMatrixFree class that has no notion on the ghost selection of the matrix-free classes. To avoid index confusion, we must adjust the ghost range before actually doing something with these vectors. Since the vectors are kept around in the multigrid smoother and transfer classes, a vector whose ghost range has once been adjusted will remain in this state throughout the lifetime of the object, so we can use a shortcut at the start of the function to see whether the partitioner object of the distributed vector, which is stored as a shared pointer, is the same as the layout expected by MatrixFree, which is stored in a data structure accessed by  [2.x.3876]  where the 0 indicates the DoFHandler number from which this was extracted; we only use a single DoFHandler in MatrixFree, so the only valid number is 0 here.
//
[0.x.33423] 
[0.x.33424] 
[0.x.33425] 
[0.x.33426] 
[0.x.33427] 
[0.x.33428] 
[0.x.33429] 
[0.x.33430] 
//
[0.x.33431] 
[0.x.33432] 
[0.x.33433] 
[0.x.33434] 
[0.x.33435] 
[0.x.33436] 
//
// The next five functions to clear and initialize the `LaplaceOperator` class, to return the shared pointer holding the MatrixFree data container, as well as the correct initialization of the vector and operator sizes are the same as in  [2.x.3877]  or rather  [2.x.3878] 
[0.x.33437] 
[0.x.33438] 
[0.x.33439] 
[0.x.33440] 
[0.x.33441] 
//
[0.x.33442] 
[0.x.33443] 
[0.x.33444] 
[0.x.33445] 
[0.x.33446] 
[0.x.33447] 
//
[0.x.33448] 
[0.x.33449] 
[0.x.33450] 
[0.x.33451] 
[0.x.33452] 
[0.x.33453] 
//
[0.x.33454] 
[0.x.33455] 
[0.x.33456] 
[0.x.33457] 
[0.x.33458] 
[0.x.33459] 
//
[0.x.33460] 
[0.x.33461] 
[0.x.33462] 
[0.x.33463] 
[0.x.33464] 
[0.x.33465] 
//
// This function implements the action of the LaplaceOperator on a vector `src` and stores the result in the vector `dst`. When compared to  [2.x.3879] , there are four new features present in this call.
//
// The first new feature is the `adjust_ghost_range_if_necessary` function mentioned above that is needed to fit the vectors to the layout expected by FEEvaluation and FEFaceEvaluation in the cell and face functions.
//
// The second new feature is the fact that we do not implement a `vmult_add()` function as we did in  [2.x.3880]  (through the virtual function  [2.x.3881]  but directly implement a `vmult()` functionality. Since both cell and face integrals will sum into the destination vector, we must of course zero the vector somewhere. For DG elements, we are given two options &ndash; one is to use  [2.x.3882]  instead of  [2.x.3883]  in the `apply_cell` function below. This works because the loop layout in MatrixFree is such that cell integrals always touch a given vector entry before the face integrals. However, this really only works for fully discontinuous bases where every cell has its own degrees of freedom, without any sharing with neighboring results. An alternative setup, the one chosen here, is to let the  [2.x.3884]  take care of zeroing the vector. This can be thought of as simply calling `dst = 0;` somewhere in the code. The implementation is more involved for supported vectors such as  [2.x.3885]  because we aim to not zero the whole vector at once. Doing the zero operation on a small enough pieces of a few thousands of vector entries has the advantage that the vector entries that get zeroed remain in caches before they are accessed again in  [2.x.3886]  and  [2.x.3887]  Since matrix-free operator evaluation is really fast, just zeroing a large vector can amount to up to a 25% of the operator evaluation time, and we obviously want to avoid this cost. This option of zeroing the vector is also available for  [2.x.3888]  and for continuous bases, even though it was not used in the  [2.x.3889]  or  [2.x.3890]  tutorial programs.
//
// The third new feature is the way we provide the functions to compute on cells, inner faces, and boundary faces: The class MatrixFree has a function called `loop` that takes three function pointers to the three cases, allowing to separate the implementations of different things. As explained in  [2.x.3891] , these function pointers can be  [2.x.3892]  objects or member functions of a class. In this case, we use pointers to member functions.
//
// The final new feature are the last two arguments of type  [2.x.3893]  that can be given to  [2.x.3894]  This class passes the type of data access for face integrals to the MPI data exchange routines  [2.x.3895]  and  [2.x.3896]  of the parallel vectors. The purpose is to not send all degrees of freedom of a neighboring element, but to reduce the amount of data to what is really needed for the computations at hand. The data exchange is a real bottleneck in particular for high-degree DG methods, therefore a more restrictive way of exchange is often beneficial. The enum field  [2.x.3897]  can take the value `none`, which means that no face integrals at all are done, which would be analogous to  [2.x.3898]  the value `values` meaning that only shape function values (but no derivatives) are used on faces, and the value `gradients` when also first derivatives on faces are accessed besides the values. A value `unspecified` means that all degrees of freedom will be exchanged for the faces that are located at the processor boundaries and designated to be worked on at the local processor.
//
// To see how the data can be reduced, think of the case of the nodal element FE_DGQ with node points on the element surface, where only  [2.x.3899]  degrees of freedom contribute to the values on a face for polynomial degree  [2.x.3900]  in  [2.x.3901]  space dimensions, out of the  [2.x.3902]  degrees of freedom of a cell. A similar reduction is also possible for the interior penalty method that evaluates values and first derivatives on the faces. When using a Hermite-like basis in 1D, only up to two basis functions contribute to the value and derivative. The class FE_DGQHermite implements a tensor product of this concept, as discussed in the introduction. Thus, only  [2.x.3903]  degrees of freedom must be exchanged for each face, which is a clear win once  [2.x.3904]  gets larger than four or five. Note that this reduced exchange of FE_DGQHermite is valid also on meshes with curved boundaries, as the derivatives are taken on the reference element, whereas the geometry only mixes them on the inside. Thus, this is different from the attempt to obtain  [2.x.3905]  continuity with continuous Hermite-type shape functions where the non-Cartesian case changes the picture significantly. Obviously, on non-Cartesian meshes the derivatives also include tangential derivatives of shape functions beyond the normal derivative, but those only need the function values on the element surface, too. Should the element not provide any compression, the loop automatically exchanges all entries for the affected cells.
//
[0.x.33466] 
[0.x.33467] 
[0.x.33468] 
[0.x.33469] 
[0.x.33470] 
[0.x.33471] 
[0.x.33472] 
[0.x.33473] 
[0.x.33474] 
[0.x.33475] 
[0.x.33476] 
[0.x.33477] 
[0.x.33478] 
//
//               /*zero_dst = [2.x.3906] true,
//
[0.x.33479] 
[0.x.33480] 
[0.x.33481] 
//
// Since the Laplacian is symmetric, the `Tvmult()` (needed by the multigrid smoother interfaces) operation is simply forwarded to the `vmult()` case.
//
[0.x.33482] 
[0.x.33483] 
[0.x.33484] 
[0.x.33485] 
[0.x.33486] 
[0.x.33487] 
[0.x.33488] 
//
// The cell operation is very similar to  [2.x.3907] . We do not use a coefficient here, though. The second difference is that we replaced the two steps of  [2.x.3908]  followed by  [2.x.3909]  by a single function call  [2.x.3910]  which internally calls the sequence of the two individual methods. Likewise,  [2.x.3911]  implements the sequence of  [2.x.3912]  followed by  [2.x.3913]  In this case, these new functions merely save two lines of code. However, we use them for the analogy with FEFaceEvaluation where they are more important as explained below.
//
[0.x.33489] 
[0.x.33490] 
[0.x.33491] 
[0.x.33492] 
[0.x.33493] 
[0.x.33494] 
[0.x.33495] 
[0.x.33496] 
[0.x.33497] 
[0.x.33498] 
[0.x.33499] 
[0.x.33500] 
[0.x.33501] 
[0.x.33502] 
[0.x.33503] 
[0.x.33504] 
[0.x.33505] 
//
// The face operation implements the terms of the interior penalty method in analogy to  [2.x.3914] , as explained in the introduction. We need two evaluator objects for this task, one for handling the solution that comes from the cell on one of the two sides of an interior face, and one for handling the solution from the other side. The evaluators for face integrals are called FEFaceEvaluation and take a boolean argument in the second slot of the constructor to indicate which of the two sides the evaluator should belong two. In FEFaceEvaluation and MatrixFree, we call one of the two sides the `interior` one and the other the `exterior` one. The name `exterior` refers to the fact that the evaluator from both sides will return the same normal vector. For the `interior` side, the normal vector points outwards, whereas it points inwards on the other side, and is opposed to the outer normal vector of that cell. Apart from the new class name, we again get a range of items to work with in analogy to what was discussed in  [2.x.3915] , but for the interior faces in this case. Note that the data structure of MatrixFree forms batches of faces that are analogous to the batches of cells for the cell integrals. All faces within a batch involve different cell numbers but have the face number within the reference cell, have the same refinement configuration (no refinement or the same subface), and the same orientation, to keep SIMD operations simple and efficient.
//
// Note that there is no implied meaning in interior versus exterior except the logic decision of the orientation of the normal, which is pretty random internally. One can in no way rely on a certain pattern of assigning interior versus exterior flags, as the decision is made for the sake of access regularity and uniformity in the MatrixFree setup routines. Since most sane DG methods are conservative, i.e., fluxes look the same from both sides of an interface, the mathematics are unaltered if the interior/exterior flags are switched and normal vectors get the opposite sign.
//
[0.x.33506] 
[0.x.33507] 
[0.x.33508] 
[0.x.33509] 
[0.x.33510] 
[0.x.33511] 
[0.x.33512] 
[0.x.33513] 
[0.x.33514] 
[0.x.33515] 
[0.x.33516] 
[0.x.33517] 
[0.x.33518] 
//
// On a given batch of faces, we first update the pointers to the current face and then access the vector. As mentioned above, we combine the vector access with the evaluation. In the case of face integrals, the data access into the vector can be reduced for the special case of an FE_DGQHermite basis as explained for the data exchange above: Since only  [2.x.3916]  out of the  [2.x.3917]  cell degrees of freedom get multiplied by a non-zero value or derivative of a shape function, this structure can be utilized for the evaluation, significantly reducing the data access. The reduction of the data access is not only beneficial because it reduces the data in flight and thus helps caching, but also because the data access to faces is often more irregular than for cell integrals when gathering values from cells that are farther apart in the index list of cells.
//
[0.x.33519] 
[0.x.33520] 
[0.x.33521] 
[0.x.33522] 
[0.x.33523] 
[0.x.33524] 
[0.x.33525] 
[0.x.33526] 
//
// The next two statements compute the penalty parameter for the interior penalty method. As explained in the introduction, we would like to have a scaling like  [2.x.3918]  of the length  [2.x.3919]  normal to the face. For a general non-Cartesian mesh, this length must be computed by the product of the inverse Jacobian times the normal vector in real coordinates. From this vector of `dim` components, we must finally pick the component that is oriented normal to the reference cell. In the geometry data stored in MatrixFree, a permutation of the components in the Jacobian is applied such that this latter direction is always the last component `dim-1` (this is beneficial because reference-cell derivative sorting can be made agnostic of the direction of the face). This means that we can simply access the last entry `dim-1` and must not look up the local face number in `data.get_face_info(face).interior_face_no` and `data.get_face_info(face).exterior_face_no`. Finally, we must also take the absolute value of these factors as the normal could point into either positive or negative direction.
//
[0.x.33527] 
[0.x.33528] 
[0.x.33529] 
[0.x.33530] 
[0.x.33531] 
[0.x.33532] 
[0.x.33533] 
//
// In the loop over the quadrature points, we eventually compute all contributions to the interior penalty scheme. According to the formulas in the introduction, the value of the test function gets multiplied by the difference of the jump in the solution times the penalty parameter and the average of the normal derivative in real space. Since the two evaluators for interior and exterior sides get different signs due to the jump, we pass the result with a different sign here. The normal derivative of the test function gets multiplied by the negative jump in the solution between the interior and exterior side. This term, coined adjoint consistency term, must also include the factor of  [2.x.3920]  in the code in accordance with its relation to the primal consistency term that gets the factor of one half due to the average in the test function slot.
//
[0.x.33534] 
[0.x.33535] 
[0.x.33536] 
[0.x.33537] 
[0.x.33538] 
[0.x.33539] 
[0.x.33540] 
[0.x.33541] 
[0.x.33542] 
[0.x.33543] 
//
[0.x.33544] 
[0.x.33545] 
//
[0.x.33546] 
[0.x.33547] 
[0.x.33548] 
//
// Once we are done with the loop over quadrature points, we can do the sum factorization operations for the integration loops on faces and sum the results into the result vector, using the `integrate_scatter` function. The name `scatter` reflects the distribution of the vector data into scattered positions in the vector using the same pattern as in `gather_evaluate`. Like before, the combined integrate + write operation allows us to reduce the data access.
//
[0.x.33549] 
[0.x.33550] 
[0.x.33551] 
[0.x.33552] 
[0.x.33553] 
[0.x.33554] 
[0.x.33555] 
[0.x.33556] 
//
// The boundary face function follows by and large the interior face function. The only difference is the fact that we do not have a separate FEFaceEvaluation object that provides us with exterior values  [2.x.3921] , but we must define them from the boundary conditions and interior values  [2.x.3922] . As explained in the introduction, we use  [2.x.3923]  and  [2.x.3924]  on Dirichlet boundaries and  [2.x.3925]  and  [2.x.3926]  on Neumann boundaries. Since this operation implements the homogeneous part, i.e., the matrix-vector product, we must neglect the boundary functions  [2.x.3927]  and  [2.x.3928]  here, and added them to the right hand side in  [2.x.3929]  Note that due to extension of the solution  [2.x.3930]  to the exterior via  [2.x.3931] , we can keep all factors  [2.x.3932]  the same as in the inner face function, see also the discussion in  [2.x.3933] .
//
// There is one catch at this point: The implementation below uses a boolean variable `is_dirichlet` to switch between the Dirichlet and the Neumann cases. However, we solve a problem where we also want to impose periodic boundary conditions on some boundaries, namely along those in the  [2.x.3934]  direction. One might wonder how those conditions should be handled here. The answer is that MatrixFree automatically treats periodic boundaries as what they are technically, namely an inner face where the solution values of two adjacent cells meet and must be treated by proper numerical fluxes. Thus, all the faces on the periodic boundaries will appear in the `apply_face()` function and not in this one.
//
[0.x.33557] 
[0.x.33558] 
[0.x.33559] 
[0.x.33560] 
[0.x.33561] 
[0.x.33562] 
[0.x.33563] 
[0.x.33564] 
[0.x.33565] 
[0.x.33566] 
[0.x.33567] 
[0.x.33568] 
[0.x.33569] 
[0.x.33570] 
[0.x.33571] 
//
[0.x.33572] 
[0.x.33573] 
[0.x.33574] 
[0.x.33575] 
[0.x.33576] 
//
[0.x.33577] 
//
[0.x.33578] 
[0.x.33579] 
[0.x.33580] 
[0.x.33581] 
[0.x.33582] 
[0.x.33583] 
[0.x.33584] 
[0.x.33585] 
[0.x.33586] 
[0.x.33587] 
[0.x.33588] 
[0.x.33589] 
[0.x.33590] 
[0.x.33591] 
[0.x.33592] 
[0.x.33593] 
[0.x.33594] 
[0.x.33595] 
[0.x.33596] 
[0.x.33597] 
[0.x.33598] 
[0.x.33599] 
//
// Next we turn to the preconditioner initialization. As explained in the introduction, we want to construct an (approximate) inverse of the cell matrices from a product of 1D mass and Laplace matrices. Our first task is to compute the 1D matrices, which we do by first creating a 1D finite element. Instead of anticipating FE_DGQHermite<1> here, we get the finite element's name from DoFHandler, replace the  [2.x.3935]  argument (2 or 3) by 1 to create a 1D name, and construct the 1D element by using FETools.
//
[0.x.33600] 
[0.x.33601] 
[0.x.33602] 
[0.x.33603] 
[0.x.33604] 
//
[0.x.33605] 
[0.x.33606] 
[0.x.33607] 
//
// As for computing the 1D matrices on the unit element, we simply write down what a typical assembly procedure over rows and columns of the matrix as well as the quadrature points would do. We select the same Laplace matrices once and for all using the coefficients 0.5 for interior faces (but possibly scaled differently in different directions as a result of the mesh). Thus, we make a slight mistake at the Dirichlet boundary (where the correct factor would be 1 for the derivative terms and 2 for the penalty term, see  [2.x.3936] ) or at the Neumann boundary where the factor should be zero. Since we only use this class as a smoother inside a multigrid scheme, this error is not going to have any significant effect and merely affects smoothing quality.
//
[0.x.33608] 
[0.x.33609] 
[0.x.33610] 
[0.x.33611] 
[0.x.33612] 
[0.x.33613] 
[0.x.33614] 
[0.x.33615] 
[0.x.33616] 
//
[0.x.33617] 
[0.x.33618] 
[0.x.33619] 
[0.x.33620] 
[0.x.33621] 
[0.x.33622] 
[0.x.33623] 
[0.x.33624] 
[0.x.33625] 
[0.x.33626] 
[0.x.33627] 
[0.x.33628] 
[0.x.33629] 
[0.x.33630] 
[0.x.33631] 
[0.x.33632] 
//
// The left and right boundary terms assembled by the next two statements appear to have somewhat arbitrary signs, but those are correct as can be verified by looking at  [2.x.3937]  and inserting the value -1 and 1 for the normal vector in the 1D case.
//
[0.x.33633] 
[0.x.33634] 
[0.x.33635] 
[0.x.33636] 
[0.x.33637] 
[0.x.33638] 
[0.x.33639] 
//
[0.x.33640] 
[0.x.33641] 
[0.x.33642] 
[0.x.33643] 
[0.x.33644] 
[0.x.33645] 
[0.x.33646] 
//
[0.x.33647] 
[0.x.33648] 
//
// Next, we go through the cells and pass the scaled matrices to TensorProductMatrixSymmetricSum to actually compute the generalized eigenvalue problem for representing the inverse: Since the matrix approximation is constructed as  [2.x.3938]  and the weights are constant for each element, we can apply all weights on the Laplace matrix and simply keep the mass matrices unscaled. In the loop over cells, we want to make use of the geometry compression provided by the MatrixFree class and check if the current geometry is the same as on the last cell batch, in which case there is nothing to do. This compression can be accessed by  [2.x.3939]  once `reinit()` has been called.
//
// Once we have accessed the inverse Jacobian through the FEEvaluation access function (we take the one for the zeroth quadrature point as they should be the same on all quadrature points for a Cartesian cell), we check that it is diagonal and then extract the determinant of the original Jacobian, i.e., the inverse of the determinant of the inverse Jacobian, and set the weight as  [2.x.3940]  according to the 1D Laplacian times  [2.x.3941]  copies of the mass matrix.
//
[0.x.33649] 
[0.x.33650] 
[0.x.33651] 
[0.x.33652] 
[0.x.33653] 
[0.x.33654] 
//
[0.x.33655] 
[0.x.33656] 
//
[0.x.33657] 
[0.x.33658] 
//
[0.x.33659] 
[0.x.33660] 
[0.x.33661] 
[0.x.33662] 
[0.x.33663] 
[0.x.33664] 
//
[0.x.33665] 
[0.x.33666] 
[0.x.33667] 
[0.x.33668] 
//
[0.x.33669] 
[0.x.33670] 
[0.x.33671] 
[0.x.33672] 
[0.x.33673] 
//
//   Once we know the factor by which we should scale the Laplace   matrix, we apply this weight to the unscaled DG Laplace matrix   and send the array to the class TensorProductMatrixSymmetricSum   for computing the generalized eigenvalue problem mentioned in   the introduction.
//
[0.x.33674] 
[0.x.33675] 
[0.x.33676] 
[0.x.33677] 
[0.x.33678] 
[0.x.33679] 
[0.x.33680] 
[0.x.33681] 
[0.x.33682] 
[0.x.33683] 
[0.x.33684] 
//
// The vmult function for the approximate block-Jacobi preconditioner is very simple in the DG context: We simply need to read the values of the current cell batch, apply the inverse for the given entry in the array of tensor product matrix, and write the result back. In this loop, we overwrite the content in `dst` rather than first setting the entries to zero. This is legitimate for a DG method because every cell has independent degrees of freedom. Furthermore, we manually write out the loop over all cell batches, rather than going through  [2.x.3942]  We do this because we know that we are not going to need data exchange over the MPI network here as all computations are done on the cells held locally on each processor.
//
[0.x.33685] 
[0.x.33686] 
[0.x.33687] 
[0.x.33688] 
[0.x.33689] 
[0.x.33690] 
[0.x.33691] 
//
[0.x.33692] 
[0.x.33693] 
[0.x.33694] 
[0.x.33695] 
[0.x.33696] 
[0.x.33697] 
[0.x.33698] 
[0.x.33699] 
[0.x.33700] 
[0.x.33701] 
[0.x.33702] 
[0.x.33703] 
[0.x.33704] 
//
// The definition of the LaplaceProblem class is very similar to  [2.x.3943] . One difference is the fact that we add the element degree as a template argument to the class, which would allow us to more easily include more than one degree in the same program by creating different instances in the `main()` function. The second difference is the selection of the element, FE_DGQHermite, which is specialized for this kind of equations.
//
[0.x.33705] 
[0.x.33706] 
[0.x.33707] 
[0.x.33708] 
[0.x.33709] 
[0.x.33710] 
//
[0.x.33711] 
[0.x.33712] 
[0.x.33713] 
[0.x.33714] 
[0.x.33715] 
//
[0.x.33716] 
[0.x.33717] 
[0.x.33718] 
[0.x.33719] 
[0.x.33720] 
//
[0.x.33721] 
[0.x.33722] 
//
[0.x.33723] 
//
[0.x.33724] 
[0.x.33725] 
//
[0.x.33726] 
[0.x.33727] 
//
[0.x.33728] 
[0.x.33729] 
//
[0.x.33730] 
[0.x.33731] 
[0.x.33732] 
[0.x.33733] 
//
[0.x.33734] 
[0.x.33735] 
[0.x.33736] 
[0.x.33737] 
[0.x.33738] 
[0.x.33739] 
[0.x.33740] 
[0.x.33741] 
[0.x.33742] 
[0.x.33743] 
[0.x.33744] 
[0.x.33745] 
[0.x.33746] 
[0.x.33747] 
[0.x.33748] 
[0.x.33749] 
[0.x.33750] 
[0.x.33751] 
[0.x.33752] 
[0.x.33753] 
[0.x.33754] 
//
// The setup function differs in two aspects from  [2.x.3944] . The first is that we do not need to interpolate any constraints for the discontinuous ansatz space, and simply pass a dummy AffineConstraints object into  [2.x.3945]  The second change arises because we need to tell MatrixFree to also initialize the data structures for faces. We do this by setting update flags for the inner and boundary faces, respectively. On the boundary faces, we need both the function values, their gradients, JxW values (for integration), the normal vectors, and quadrature points (for the evaluation of the boundary conditions), whereas we only need shape function values, gradients, JxW values, and normal vectors for interior faces. The face data structures in MatrixFree are always built as soon as one of `mapping_update_flags_inner_faces` or `mapping_update_flags_boundary_faces` are different from the default value `update_default` of UpdateFlags.
//
[0.x.33755] 
[0.x.33756] 
[0.x.33757] 
[0.x.33758] 
[0.x.33759] 
//
[0.x.33760] 
[0.x.33761] 
//
[0.x.33762] 
[0.x.33763] 
//
[0.x.33764] 
[0.x.33765] 
//
[0.x.33766] 
[0.x.33767] 
[0.x.33768] 
[0.x.33769] 
//
[0.x.33770] 
[0.x.33771] 
//
[0.x.33772] 
[0.x.33773] 
[0.x.33774] 
[0.x.33775] 
[0.x.33776] 
[0.x.33777] 
[0.x.33778] 
[0.x.33779] 
[0.x.33780] 
[0.x.33781] 
[0.x.33782] 
[0.x.33783] 
[0.x.33784] 
[0.x.33785] 
[0.x.33786] 
[0.x.33787] 
[0.x.33788] 
//
[0.x.33789] 
[0.x.33790] 
//
[0.x.33791] 
[0.x.33792] 
[0.x.33793] 
[0.x.33794] 
//
[0.x.33795] 
[0.x.33796] 
//
[0.x.33797] 
[0.x.33798] 
[0.x.33799] 
[0.x.33800] 
[0.x.33801] 
[0.x.33802] 
[0.x.33803] 
[0.x.33804] 
[0.x.33805] 
[0.x.33806] 
[0.x.33807] 
[0.x.33808] 
[0.x.33809] 
[0.x.33810] 
[0.x.33811] 
[0.x.33812] 
[0.x.33813] 
[0.x.33814] 
[0.x.33815] 
//
[0.x.33816] 
[0.x.33817] 
[0.x.33818] 
[0.x.33819] 
[0.x.33820] 
[0.x.33821] 
//
// The computation of the right hand side is a bit more complicated than in  [2.x.3946] . The cell term now consists of the negative Laplacian of the analytical solution, `RightHandSide`, for which we need to first split up the Point of VectorizedArray fields, i.e., a batch of points, into a single point by evaluating all lanes in the VectorizedArray separately. Remember that the number of lanes depends on the hardware; it could be 1 for systems that do not offer vectorization (or where deal.II does not have intrinsics), but it could also be 8 or 16 on AVX-512 of recent Intel architectures.
//
[0.x.33822] 
[0.x.33823] 
[0.x.33824] 
[0.x.33825] 
[0.x.33826] 
[0.x.33827] 
[0.x.33828] 
[0.x.33829] 
[0.x.33830] 
[0.x.33831] 
[0.x.33832] 
[0.x.33833] 
[0.x.33834] 
[0.x.33835] 
[0.x.33836] 
[0.x.33837] 
[0.x.33838] 
[0.x.33839] 
[0.x.33840] 
[0.x.33841] 
[0.x.33842] 
[0.x.33843] 
[0.x.33844] 
[0.x.33845] 
[0.x.33846] 
[0.x.33847] 
[0.x.33848] 
[0.x.33849] 
//
// Secondly, we also need to apply the Dirichlet and Neumann boundary conditions. This function is the missing part of to the function  [2.x.3947]  function once the exterior solution values  [2.x.3948]  and  [2.x.3949]  on Dirichlet boundaries and  [2.x.3950]  and  [2.x.3951]  on Neumann boundaries are inserted and expanded in terms of the boundary functions  [2.x.3952]  and  [2.x.3953] . One thing to remember is that we move the boundary conditions to the right hand side, so the sign is the opposite from what we imposed on the solution part.
//
// We could have issued both the cell and the boundary part through a  [2.x.3954]  part, but we choose to manually write the full loop over all faces to learn how the index layout of face indices is set up in MatrixFree: Both the inner faces and the boundary faces share the index range, and all batches of inner faces have lower numbers than the batches of boundary cells. A single index for both variants allows us to easily use the same data structure FEFaceEvaluation for both cases that attaches to the same data field, just at different positions. The number of inner face batches (where a batch is due to the combination of several faces into one for vectorization) is given by  [2.x.3955]  whereas the number of boundary face batches is given by  [2.x.3956] 
[0.x.33850] 
[0.x.33851] 
[0.x.33852] 
[0.x.33853] 
[0.x.33854] 
[0.x.33855] 
//
[0.x.33856] 
[0.x.33857] 
[0.x.33858] 
[0.x.33859] 
[0.x.33860] 
//
[0.x.33861] 
[0.x.33862] 
[0.x.33863] 
[0.x.33864] 
[0.x.33865] 
[0.x.33866] 
[0.x.33867] 
//
[0.x.33868] 
[0.x.33869] 
[0.x.33870] 
[0.x.33871] 
[0.x.33872] 
//
//       The MatrixFree class lets us query the boundary_id of the       current face batch. Remember that MatrixFree sets up the       batches for vectorization such that all faces within a       batch have the same properties, which includes their       `boundary_id`. Thus, we can query that id here for the       current face index `face` and either impose the Dirichlet       case (where we add something to the function value) or the       Neumann case (where we add something to the normal       derivative).
//
[0.x.33873] 
[0.x.33874] 
[0.x.33875] 
[0.x.33876] 
[0.x.33877] 
[0.x.33878] 
[0.x.33879] 
[0.x.33880] 
[0.x.33881] 
[0.x.33882] 
[0.x.33883] 
[0.x.33884] 
[0.x.33885] 
[0.x.33886] 
[0.x.33887] 
[0.x.33888] 
[0.x.33889] 
[0.x.33890] 
[0.x.33891] 
//
// Since we have manually run the loop over cells rather than using  [2.x.3957]  we must not forget to perform the data exchange with MPI
//
// - or actually, we would not need that for DG elements here because each cell carries its own degrees of freedom and cell and boundary integrals only evaluate quantities on the locally owned cells. The coupling to neighboring subdomain only comes in by the inner face integrals, which we have not done here. That said, it does not hurt to call this function here, so we do it as a reminder of what happens inside  [2.x.3958] 
[0.x.33892] 
[0.x.33893] 
[0.x.33894] 
[0.x.33895] 
[0.x.33896] 
//
// The `solve()` function is copied almost verbatim from  [2.x.3959] . We set up the same multigrid ingredients, namely the level transfer, a smoother, and a coarse grid solver. The only difference is the fact that we do not use the diagonal of the Laplacian for the preconditioner of the Chebyshev iteration used for smoothing, but instead our newly resolved class `%PreconditionBlockJacobi`. The mechanisms are the same, though.
//
[0.x.33897] 
[0.x.33898] 
[0.x.33899] 
[0.x.33900] 
[0.x.33901] 
[0.x.33902] 
[0.x.33903] 
[0.x.33904] 
[0.x.33905] 
[0.x.33906] 
//
[0.x.33907] 
[0.x.33908] 
[0.x.33909] 
[0.x.33910] 
[0.x.33911] 
[0.x.33912] 
[0.x.33913] 
[0.x.33914] 
[0.x.33915] 
[0.x.33916] 
[0.x.33917] 
[0.x.33918] 
[0.x.33919] 
[0.x.33920] 
[0.x.33921] 
[0.x.33922] 
[0.x.33923] 
[0.x.33924] 
[0.x.33925] 
[0.x.33926] 
[0.x.33927] 
[0.x.33928] 
[0.x.33929] 
[0.x.33930] 
[0.x.33931] 
[0.x.33932] 
[0.x.33933] 
[0.x.33934] 
[0.x.33935] 
//
[0.x.33936] 
[0.x.33937] 
[0.x.33938] 
//
[0.x.33939] 
[0.x.33940] 
//
[0.x.33941] 
[0.x.33942] 
//
[0.x.33943] 
[0.x.33944] 
[0.x.33945] 
[0.x.33946] 
//
[0.x.33947] 
[0.x.33948] 
[0.x.33949] 
[0.x.33950] 
[0.x.33951] 
[0.x.33952] 
//
[0.x.33953] 
[0.x.33954] 
[0.x.33955] 
//
[0.x.33956] 
[0.x.33957] 
[0.x.33958] 
//
// Since we have solved a problem with analytic solution, we want to verify the correctness of our implementation by computing the L2 error of the numerical result against the analytic solution.
//
[0.x.33959] 
[0.x.33960] 
[0.x.33961] 
[0.x.33962] 
[0.x.33963] 
[0.x.33964] 
[0.x.33965] 
[0.x.33966] 
[0.x.33967] 
[0.x.33968] 
[0.x.33969] 
[0.x.33970] 
[0.x.33971] 
[0.x.33972] 
[0.x.33973] 
[0.x.33974] 
//
// The `run()` function sets up the initial grid and then runs the multigrid program in the usual way. As a domain, we choose a rectangle with periodic boundary conditions in the  [2.x.3960] -direction, a Dirichlet condition on the front face in  [2.x.3961]  direction (i.e., the face with index number 2, with boundary id equal to 0), and Neumann conditions on the back face as well as the two faces in  [2.x.3962]  direction for the 3D case (with boundary id equal to 1). The extent of the domain is a bit different in the  [2.x.3963]  direction (where we want to achieve a periodic solution given the definition of `Solution`) as compared to the  [2.x.3964]  and  [2.x.3965]  directions.
//
[0.x.33975] 
[0.x.33976] 
[0.x.33977] 
[0.x.33978] 
[0.x.33979] 
[0.x.33980] 
[0.x.33981] 
[0.x.33982] 
[0.x.33983] 
[0.x.33984] 
[0.x.33985] 
[0.x.33986] 
//
[0.x.33987] 
[0.x.33988] 
[0.x.33989] 
[0.x.33990] 
[0.x.33991] 
[0.x.33992] 
[0.x.33993] 
[0.x.33994] 
[0.x.33995] 
[0.x.33996] 
[0.x.33997] 
[0.x.33998] 
[0.x.33999] 
[0.x.34000] 
[0.x.34001] 
[0.x.34002] 
//
[0.x.34003] 
[0.x.34004] 
[0.x.34005] 
[0.x.34006] 
[0.x.34007] 
[0.x.34008] 
//
[0.x.34009] 
[0.x.34010] 
[0.x.34011] 
[0.x.34012] 
[0.x.34013] 
[0.x.34014] 
[0.x.34015] 
[0.x.34016] 
[0.x.34017] 
[0.x.34018] 
[0.x.34019] 
//
// There is nothing unexpected in the `main()` function. We call `MPI_Init()` through the `MPI_InitFinalize` class, pass on the two parameters on the dimension and the degree set at the top of the file, and run the Laplace problem.
//
[0.x.34020] 
[0.x.34021] 
[0.x.34022] 
[0.x.34023] 
[0.x.34024] 
//
[0.x.34025] 
//
[0.x.34026] 
[0.x.34027] 
[0.x.34028] 
[0.x.34029] 
[0.x.34030] 
[0.x.34031] 
[0.x.34032] 
[0.x.34033] 
[0.x.34034] 
[0.x.34035] 
[0.x.34036] 
[0.x.34037] 
[0.x.34038] 
[0.x.34039] 
[0.x.34040] 
[0.x.34041] 
[0.x.34042] 
[0.x.34043] 
[0.x.34044] 
[0.x.34045] 
[0.x.34046] 
[0.x.34047] 
[0.x.34048] 
[0.x.34049] 
[0.x.34050] 
[0.x.34051] 
[0.x.34052] 
[0.x.34053] 
//
[0.x.34054] 
[0.x.34055] 
[0.x.34056] 
[0.x.34057] 
[0.x.34058] 
[0.x.34059] 
[0.x.34060] 
[0.x.34061] 
[0.x.34062] 
[0.x.34063] 
[0.x.34064] 
[0.x.34065] 
[0.x.34066] 
[0.x.34067] 
[0.x.34068] 
[0.x.34069] 
//
[0.x.34070] 
[0.x.34071] 
[0.x.34072] 
//[2.x.3966] 
//
// The first few files have already been covered in previous examples and will thus not be further commented on.
//
[0.x.34073] 
//
[0.x.34074] 
[0.x.34075] 
//
[0.x.34076] 
//
[0.x.34077] 
[0.x.34078] 
//
[0.x.34079] 
[0.x.34080] 
[0.x.34081] 
[0.x.34082] 
[0.x.34083] 
[0.x.34084] 
//
[0.x.34085] 
[0.x.34086] 
//
[0.x.34087] 
//
// From the following include file we will import the declaration of H1-conforming finite element shape functions. This family of finite elements is called  [2.x.3967] , and was used in all examples before already to define the usual bi- or tri-linear elements, but we will now use it for bi-quadratic elements:
//
[0.x.34088] 
//
// We will not read the grid from a file as in the previous example, but generate it using a function of the library. However, we will want to write out the locally refined grids (just the grid, not the solution) in each step, so we need the following include file instead of  [2.x.3968] :
//
[0.x.34089] 
//
// When using locally refined grids, we will get so-called <code>hanging nodes</code>. However, the standard finite element methods assumes that the discrete solution spaces be continuous, so we need to make sure that the degrees of freedom on hanging nodes conform to some constraints such that the global solution is continuous. We are also going to store the boundary conditions in this object. The following file contains a class which is used to handle these constraints:
//
[0.x.34090] 
//
// In order to refine our grids locally, we need a function from the library that decides which cells to flag for refinement or coarsening based on the error indicators we have computed. This function is defined here:
//
[0.x.34091] 
//
// Finally, we need a simple way to actually compute the refinement indicators based on some error estimate. While in general, adaptivity is very problem-specific, the error indicator in the following file often yields quite nicely adapted grids for a wide class of problems.
//
[0.x.34092] 
//
// Finally, this is as in previous programs:
//
[0.x.34093] 
//[2.x.3969] 
//
// The main class is again almost unchanged. Two additions, however, are made: we have added the  [2.x.3970]  function, which is used to adaptively refine the grid (instead of the global refinement in the previous examples), and a variable which will hold the constraints.
//
[0.x.34094] 
[0.x.34095] 
[0.x.34096] 
[0.x.34097] 
[0.x.34098] 
//
[0.x.34099] 
//
[0.x.34100] 
[0.x.34101] 
[0.x.34102] 
[0.x.34103] 
[0.x.34104] 
[0.x.34105] 
//
[0.x.34106] 
//
[0.x.34107] 
[0.x.34108] 
//
// This is the new variable in the main class. We need an object which holds a list of constraints to hold the hanging nodes and the boundary conditions.
//
[0.x.34109] 
//
[0.x.34110] 
[0.x.34111] 
//
[0.x.34112] 
[0.x.34113] 
[0.x.34114] 
//[2.x.3971] 
//
// The implementation of nonconstant coefficients is copied verbatim from  [2.x.3972] :
//
[0.x.34115] 
[0.x.34116] 
[0.x.34117] 
[0.x.34118] 
[0.x.34119] 
[0.x.34120] 
[0.x.34121] 
[0.x.34122] 
//
//  [2.x.3973] 
//[2.x.3974] 
//
// The constructor of this class is mostly the same as before, but this time we want to use the quadratic element. To do so, we only have to replace the constructor argument (which was  [2.x.3975]  in all previous examples) by the desired polynomial degree (here  [2.x.3976] ):
//
[0.x.34123] 
[0.x.34124] 
[0.x.34125] 
[0.x.34126] 
[0.x.34127] 
//
//  [2.x.3977] 
//
// The next function sets up all the variables that describe the linear finite element problem, such as the DoFHandler, matrices, and vectors. The difference to what we did in  [2.x.3978]  is only that we now also have to take care of hanging node constraints. These constraints are handled almost exclusively by the library, i.e. you only need to know that they exist and how to get them, but you do not have to know how they are formed or what exactly is done with them.
//
// At the beginning of the function, you find all the things that are the same as in  [2.x.3979] : setting up the degrees of freedom (this time we have quadratic elements, but there is no difference from a user code perspective to the linear -- or any other degree, for that matter -- case), generating the sparsity pattern, and initializing the solution and right hand side vectors. Note that the sparsity pattern will have significantly more entries per row now, since there are now 9 degrees of freedom per cell (rather than only four), that can couple with each other.
//
[0.x.34128] 
[0.x.34129] 
[0.x.34130] 
[0.x.34131] 
//
[0.x.34132] 
[0.x.34133] 
//
// We may now populate the AffineConstraints object with the hanging node constraints. Since we will call this function in a loop we first clear the current set of constraints from the last system and then compute new ones:
//
[0.x.34134] 
[0.x.34135] 
//
// Now we are ready to interpolate the boundary values with indicator 0 (the whole boundary) and store the resulting constraints in our  [2.x.3980]  object. Note that we do not to apply the boundary conditions after assembly, like we did in earlier steps: instead we put all constraints on our function space in the AffineConstraints object. We can add constraints to the AffineConstraints object in either order: if two constraints conflict then the constraint matrix either abort or throw an exception via the Assert macro.
//
[0.x.34136] 
[0.x.34137] 
[0.x.34138] 
[0.x.34139] 
//
// After all constraints have been added, they need to be sorted and rearranged to perform some actions more efficiently. This postprocessing is done using the  [2.x.3981]  function, after which no further constraints may be added any more:
//
[0.x.34140] 
//
// Now we first build our compressed sparsity pattern like we did in the previous examples. Nevertheless, we do not copy it to the final sparsity pattern immediately.  Note that we call a variant of make_sparsity_pattern that takes the AffineConstraints object as the third argument. We are letting the routine know that we will never write into the locations given by  [2.x.3982]  by setting the argument  [2.x.3983]  to false (in other words, that we will never write into entries of the matrix that correspond to constrained degrees of freedom). If we were to condense the constraints after assembling, we would have to pass  [2.x.3984]  instead because then we would first write into these locations only to later set them to zero again during condensation.
//
[0.x.34141] 
[0.x.34142] 
[0.x.34143] 
[0.x.34144] 
//
//                                  /*keep_constrained_dofs =  [2.x.3985]  false);
//
// Now all non-zero entries of the matrix are known (i.e. those from regularly assembling the matrix and those that were introduced by eliminating constraints). We may copy our intermediate object to the sparsity pattern:
//
[0.x.34145] 
//
// We may now, finally, initialize the sparse matrix:
//
[0.x.34146] 
[0.x.34147] 
//[2.x.3986] 
//
// Next, we have to assemble the matrix. However, to copy the local matrix and vector on each cell into the global system, we are no longer using a hand-written loop. Instead, we use  [2.x.3987]  that internally executes this loop while performing Gaussian elimination on rows and columns corresponding to constrained degrees on freedom.
//
// The rest of the code that forms the local contributions remains unchanged. It is worth noting, however, that under the hood several things are different than before. First, the variable  [2.x.3988]  and return value of  [2.x.3989]  now are 9 each, where they were 4 before. Introducing such variables as abbreviations is a good strategy to make code work with different elements without having to change too much code. Secondly, the  [2.x.3990]  object of course needs to do other things as well, since the shape functions are now quadratic, rather than linear, in each coordinate variable. Again, however, this is something that is completely handled by the library.
//
[0.x.34148] 
[0.x.34149] 
[0.x.34150] 
[0.x.34151] 
//
[0.x.34152] 
[0.x.34153] 
[0.x.34154] 
[0.x.34155] 
//
[0.x.34156] 
//
[0.x.34157] 
[0.x.34158] 
//
[0.x.34159] 
//
[0.x.34160] 
[0.x.34161] 
[0.x.34162] 
[0.x.34163] 
//
[0.x.34164] 
//
[0.x.34165] 
[0.x.34166] 
[0.x.34167] 
[0.x.34168] 
[0.x.34169] 
[0.x.34170] 
[0.x.34171] 
[0.x.34172] 
[0.x.34173] 
[0.x.34174] 
[0.x.34175] 
[0.x.34176] 
//
[0.x.34177] 
[0.x.34178] 
[0.x.34179] 
[0.x.34180] 
[0.x.34181] 
//
// Finally, transfer the contributions from  [2.x.3991]  and  [2.x.3992]  into the global objects.
//
[0.x.34182] 
[0.x.34183] 
[0.x.34184] 
[0.x.34185] 
//
// Now we are done assembling the linear system. The constraint matrix took care of applying the boundary conditions and also eliminated hanging node constraints. The constrained nodes are still in the linear system (there is a nonzero entry, chosen in a way that the matrix is well conditioned, on the diagonal of the matrix and all other entries for this line are set to zero) but the computed values are invalid (i.e., the corresponding entries in  [2.x.3993]  are currently meaningless). We compute the correct values for these nodes at the end of the  [2.x.3994]  function.
//
[0.x.34186] 
//[2.x.3995] 
//
// We continue with gradual improvements. The function that solves the linear system again uses the SSOR preconditioner, and is again unchanged except that we have to incorporate hanging node constraints. As mentioned above, the degrees of freedom from the AffineConstraints object corresponding to hanging node constraints and boundary values have been removed from the linear system by giving the rows and columns of the matrix a special treatment. This way, the values for these degrees of freedom have wrong, but well-defined values after solving the linear system. What we then have to do is to use the constraints to assign to them the values that they should have. This process, called  [2.x.3996]  constraints, computes the values of constrained nodes from the values of the unconstrained ones, and requires only a single additional function call that you find at the end of this function:
//
[0.x.34187] 
[0.x.34188] 
[0.x.34189] 
[0.x.34190] 
[0.x.34191] 
//
[0.x.34192] 
[0.x.34193] 
//
[0.x.34194] 
//
[0.x.34195] 
[0.x.34196] 
//[2.x.3997] 
//
// We use a sophisticated error estimation scheme to refine the mesh instead of global refinement. We will use the KellyErrorEstimator class which implements an error estimator for the Laplace equation; it can in principle handle variable coefficients, but we will not use these advanced features, but rather use its most simple form since we are not interested in quantitative results but only in a quick way to generate locally refined grids.
//
// Although the error estimator derived by Kelly et al. was originally developed for the Laplace equation, we have found that it is also well suited to quickly generate locally refined grids for a wide class of problems. This error estimator uses the solution gradient's jump at cell faces (which is a measure for the second derivatives) and scales it by the size of the cell. It is therefore a measure for the local smoothness of the solution at the place of each cell and it is thus understandable that it yields reasonable grids also for hyperbolic transport problems or the wave equation as well, although these grids are certainly suboptimal compared to approaches specially tailored to the problem. This error estimator may therefore be understood as a quick way to test an adaptive program.
//
// The way the estimator works is to take a  [2.x.3998]  object describing the degrees of freedom and a vector of values for each degree of freedom as input and compute a single indicator value for each active cell of the triangulation (i.e. one value for each of the active cells). To do so, it needs two additional pieces of information: a face quadrature formula, i.e., a quadrature formula on  [2.x.3999]  dimensional objects. We use a 3-point Gauss rule again, a choice that is consistent and appropriate with the bi-quadratic finite element shape functions in this program. (What constitutes a suitable quadrature rule here of course depends on knowledge of the way the error estimator evaluates the solution field. As said above, the jump of the gradient is integrated over each face, which would be a quadratic function on each face for the quadratic elements in use in this example. In fact, however, it is the square of the jump of the gradient, as explained in the documentation of that class, and that is a quartic function, for which a 3 point Gauss formula is sufficient since it integrates polynomials up to order 5 exactly.)
//
// Secondly, the function wants a list of boundary indicators for those boundaries where we have imposed Neumann values of the kind  [2.x.4000] , along with a function  [2.x.4001]  for each such boundary. This information is represented by a map from boundary indicators to function objects describing the Neumann boundary values. In the present example program, we do not use Neumann boundary values, so this map is empty, and in fact constructed using the default constructor of the map in the place where the function call expects the respective function argument.
//
// The output is a vector of values for all active cells. While it may make sense to compute the [1.x.110] of a solution degree of freedom very accurately, it is usually not necessary to compute the [1.x.111] corresponding to the solution on a cell particularly accurately. We therefore typically use a vector of floats instead of a vector of doubles to represent error indicators.
//
[0.x.34197] 
[0.x.34198] 
[0.x.34199] 
[0.x.34200] 
//
[0.x.34201] 
[0.x.34202] 
[0.x.34203] 
[0.x.34204] 
[0.x.34205] 
//
// The above function returned one error indicator value for each cell in the  [2.x.4002]  array. Refinement is now done as follows: refine those 30 per cent of the cells with the highest error values, and coarsen the 3 per cent of cells with the lowest values.
//
// One can easily verify that if the second number were zero, this would approximately result in a doubling of cells in each step in two space dimensions, since for each of the 30 per cent of cells, four new would be replaced, while the remaining 70 per cent of cells remain untouched. In practice, some more cells are usually produced since it is disallowed that a cell is refined twice while the neighbor cell is not refined; in that case, the neighbor cell would be refined as well.
//
// In many applications, the number of cells to be coarsened would be set to something larger than only three per cent. A non-zero value is useful especially if for some reason the initial (coarse) grid is already rather refined. In that case, it might be necessary to refine it in some regions, while coarsening in some other regions is useful. In our case here, the initial grid is very coarse, so coarsening is only necessary in a few regions where over-refinement may have taken place. Thus a small, non-zero value is appropriate here.
//
// The following function now takes these refinement indicators and flags some cells of the triangulation for refinement or coarsening using the method described above. It is from a class that implements several different algorithms to refine a triangulation based on cell-wise error indicators.
//
[0.x.34206] 
[0.x.34207] 
[0.x.34208] 
[0.x.34209] 
//
// After the previous function has exited, some cells are flagged for refinement, and some other for coarsening. The refinement or coarsening itself is not performed by now, however, since there are cases where further modifications of these flags is useful. Here, we don't want to do any such thing, so we can tell the triangulation to perform the actions for which the cells are flagged:
//
[0.x.34210] 
[0.x.34211] 
//[2.x.4003] 
//
// At the end of computations on each grid, and just before we continue the next cycle with mesh refinement, we want to output the results from this cycle.
//
// We have already seen in  [2.x.4004]  how this can be achieved for the mesh itself. Here, we change a few things:  [2.x.4005] 
//[2.x.4006] We use two different formats: gnuplot and VTU. [2.x.4007] 
//[2.x.4008] We embed the cycle number in the output file name. [2.x.4009] 
//[2.x.4010] For gnuplot output, we set up a  [2.x.4011]  object to   provide a few extra visualization arguments so that edges appear   curved. This is explained in further detail in  [2.x.4012] . [2.x.4013] 
//[2.x.4014] 
[0.x.34212] 
[0.x.34213] 
[0.x.34214] 
[0.x.34215] 
[0.x.34216] 
[0.x.34217] 
[0.x.34218] 
[0.x.34219] 
[0.x.34220] 
[0.x.34221] 
[0.x.34222] 
//
[0.x.34223] 
[0.x.34224] 
[0.x.34225] 
[0.x.34226] 
[0.x.34227] 
//
[0.x.34228] 
[0.x.34229] 
[0.x.34230] 
[0.x.34231] 
//[2.x.4015] 
//
// The final function before  [2.x.4016]  is again the main driver of the class,  [2.x.4017] . It is similar to the one of  [2.x.4018] , except that we generate a file in the program again instead of reading it from disk, in that we adaptively instead of globally refine the mesh, and that we output the solution on the final mesh in the present function.
//
// The first block in the main loop of the function deals with mesh generation. If this is the first cycle of the program, instead of reading the grid from a file on disk as in the previous example, we now again create it using a library function. The domain is again a circle with center at the origin and a radius of one (these are the two hidden arguments to the function, which have default values).
//
// You will notice by looking at the coarse grid that it is of inferior quality than the one which we read from the file in the previous example: the cells are less equally formed. However, using the library function this program works in any space dimension, which was not the case before.
//
// In case we find that this is not the first cycle, we want to refine the grid. Unlike the global refinement employed in the last example program, we now use the adaptive procedure described above.
//
// The rest of the loop looks as before:
//
[0.x.34232] 
[0.x.34233] 
[0.x.34234] 
[0.x.34235] 
[0.x.34236] 
[0.x.34237] 
//
[0.x.34238] 
[0.x.34239] 
[0.x.34240] 
[0.x.34241] 
[0.x.34242] 
[0.x.34243] 
[0.x.34244] 
//
[0.x.34245] 
[0.x.34246] 
//
[0.x.34247] 
//
[0.x.34248] 
[0.x.34249] 
//
[0.x.34250] 
[0.x.34251] 
[0.x.34252] 
[0.x.34253] 
[0.x.34254] 
//[2.x.4019] 
//
// The main function is unaltered in its functionality from the previous example, but we have taken a step of additional caution. Sometimes, something goes wrong (such as insufficient disk space upon writing an output file, not enough memory when trying to allocate a vector or a matrix, or if we can't read from or write to a file for whatever reason), and in these cases the library will throw exceptions. Since these are run-time problems, not programming errors that can be fixed once and for all, this kind of exceptions is not switched off in optimized mode, in contrast to the  [2.x.4020]  macro which we have used to test against programming errors. If uncaught, these exceptions propagate the call tree up to the  [2.x.4021]  function, and if they are not caught there either, the program is aborted. In many cases, like if there is not enough memory or disk space, we can't do anything but we can at least print some text trying to explain the reason why the program failed. A way to do so is shown in the following. It is certainly useful to write any larger program in this way, and you can do so by more or less copying this function except for the  [2.x.4022]  block that actually encodes the functionality particular to the present application.
//
[0.x.34255] 
[0.x.34256] 
//
// The general idea behind the layout of this function is as follows: let's try to run the program as we did before...
//
[0.x.34257] 
[0.x.34258] 
[0.x.34259] 
[0.x.34260] 
[0.x.34261] 
//
// ...and if this should fail, try to gather as much information as possible. Specifically, if the exception that was thrown is an object of a class that is derived from the C++ standard class  [2.x.4023]  member function to get a string which describes the reason why the exception was thrown.
//
// The deal.II exception classes are all derived from the standard class, and in particular, the  [2.x.4024]  function will return approximately the same string as would be generated if the exception was thrown using the  [2.x.4025]  macro. You have seen the output of such an exception in the previous example, and you then know that it contains the file and line number of where the exception occurred, and some other information. This is also what the following statements would print.
//
// Apart from this, there isn't much that we can do except exiting the program with an error code (this is what the  [2.x.4026]  does):
//
[0.x.34262] 
[0.x.34263] 
[0.x.34264] 
[0.x.34265] 
[0.x.34266] 
[0.x.34267] 
[0.x.34268] 
[0.x.34269] 
[0.x.34270] 
[0.x.34271] 
[0.x.34272] 
//
[0.x.34273] 
[0.x.34274] 
//
// If the exception that was thrown somewhere was not an object of a class derived from the standard  [2.x.4027]  class, then we can't do anything at all. We then simply print an error message and exit.
//
[0.x.34275] 
[0.x.34276] 
[0.x.34277] 
[0.x.34278] 
[0.x.34279] 
[0.x.34280] 
[0.x.34281] 
[0.x.34282] 
[0.x.34283] 
[0.x.34284] 
[0.x.34285] 
[0.x.34286] 
//
// If we got to this point, there was no exception which propagated up to the main function (there may have been exceptions, but they were caught somewhere in the program or the library). Therefore, the program performed as was expected and we can return without error.
//
[0.x.34287] 
[0.x.34288] 
[0.x.34289] 
[0.x.34290] 
[0.x.34291] 
[0.x.34292] 
[0.x.34293] 
[0.x.34294] 
[0.x.34295] 
[0.x.34296] 
[0.x.34297] 
[0.x.34298] 
[0.x.34299] 
[0.x.34300] 
[0.x.34301] 
[0.x.34302] 
[0.x.34303] 
[0.x.34304] 
[0.x.34305] 
[0.x.34306] 
//[2.x.4028]  Most of these have been introduced elsewhere, we'll comment only on the new ones.
//
[0.x.34307] 
[0.x.34308] 
[0.x.34309] 
//
// The parameter acceptor class is the first novelty of this tutorial program: in general parameter files are used to steer the execution of a program at run time. While even a simple approach saves compile time, as the same executable can be run with different parameter settings, it can become difficult to handle hundreds of parameters simultaneously while maintaining compatibility between different programs. This is where the class ParameterAcceptor proves useful.
//
// This class is used to define a public interface for classes that want to use a single global ParameterHandler to handle parameters. The class provides a static ParameterHandler member, namely  [2.x.4029]  and implements the "Command design pattern" (see, for example, E. Gamma, R. Helm, R. Johnson, J. Vlissides, Design Patterns: Elements of Reusable Object-Oriented Software, Addison-Wesley Professional, 1994. https:goo.gl/FNYByc).
//
// ParameterAcceptor provides a global subscription mechanism. Whenever an object of a class derived from ParameterAcceptor is constructed, a pointer to that object-of-derived-type is registered, together with a section entry in the parameter file. Such registry is traversed upon invocation of the single function  [2.x.4030]  which in turn makes sure that all classes stored in the global registry declare the parameters they will be using, and after having declared them, it reads the content of `file.prm` to parse the actual parameters.
//
// If you call the method  [2.x.4031]  for each of the parameters you want to use in your code, there is nothing else you need to do. If you are using an already existing class that provides the two functions `declare_parameters` and `parse_parameters`, you can still use ParameterAcceptor, by encapsulating the existing class into a ParameterAcceptorProxy class.
//
// In this example, we'll use both strategies, using ParameterAcceptorProxy for deal.II classes, and deriving our own parameter classes directly from ParameterAcceptor.
//
[0.x.34310] 
//
[0.x.34311] 
[0.x.34312] 
[0.x.34313] 
//
// The other new include file is the one that contains the  [2.x.4032]  class. The structure of deal.II, as many modern numerical libraries, is organized following a Directed Acyclic Graph (DAG). A DAG is a directed graph with topological ordering: each node structurally represents an object, and is connected to non-root nodes by one (or more) oriented edges, from the parent to the child. The most significant example of this structure is the Triangulation and its  [2.x.4033]  structure. From a Triangulation (the main node), we can access each cell (children nodes of the triangulation). From the cells themselves we can access over all vertices of the cell. In this simple example, the DAG structure can be represented as three node types (the triangulation, the cell iterator, and the vertex) connected by oriented edges from the triangulation to the cell iterators, and from the cell iterator to the vertices. This has several advantages, but it intrinsically creates asymmetries, making certain operations fast and their inverse very slow: finding the vertices of a cell has low computational cost, and can be done by simply traversing the DAG, while finding all the cells that share a vertex requires a non-trivial computation unless a new DAG data structure is added that represents the inverse search.
//
// Since inverse operations are usually not needed in a finite element code, these are implemented in GridTools without the use of extra data structures related to the Triangulation which would make them much faster. One such data structure, for example, is a map from the vertices of a Triangulation to all cells that share those vertices, which would reduce the computations needed to answer to the previous question.
//
// Some methods, for example  [2.x.4034]  make heavy usage of these non-standard operations. If you need to call these methods more than once, it becomes convenient to store those data structures somewhere.  [2.x.4035]  does exactly this, giving you access to previously computed objects, or computing them on the fly (and then storing them inside the class for later use), and making sure that whenever the Triangulation is updated, also the relevant data structures are recomputed.
//
[0.x.34314] 
//
[0.x.34315] 
[0.x.34316] 
[0.x.34317] 
//
// In this example, we will be using a reference domain to describe an embedded Triangulation, deformed through a finite element vector field.
//
// The next two include files contain the definition of two classes that can be used in these cases. MappingQEulerian allows one to describe a domain through a *displacement* field, based on a FESystem[FE_Q(p)^spacedim] finite element space. The second is a little more generic, and allows you to use arbitrary vector FiniteElement spaces, as long as they provide a *continuous*
// description of your domain. In this case, the description is done through the actual *deformation* field, rather than a *displacement* field.
//
// Which one is used depends on how the user wants to specify the reference domain, and/or the actual configuration. We'll provide both options, and experiment a little in the results section of this tutorial program.
//
[0.x.34318] 
[0.x.34319] 
//
[0.x.34320] 
//
// The parsed function class is another new entry. It allows one to create a Function object, starting from a string in a parameter file which is parsed into an object that you can use anywhere deal.II accepts a Function (for example, for interpolation, boundary conditions, etc.).
//
[0.x.34321] 
//
[0.x.34322] 
[0.x.34323] 
[0.x.34324] 
//
// This is the last new entry for this tutorial program. The namespace NonMatching contains a few methods that are useful when performing computations on non-matching grids, or on curves that are not aligned with the underlying mesh.
//
// We'll discuss its use in detail later on in the `setup_coupling` method.
//
[0.x.34325] 
//
[0.x.34326] 
[0.x.34327] 
[0.x.34328] 
[0.x.34329] 
[0.x.34330] 
[0.x.34331] 
[0.x.34332] 
[0.x.34333] 
//
[0.x.34334] 
[0.x.34335] 
//
[0.x.34336] 
[0.x.34337] 
[0.x.34338] 
//[2.x.4036] 
//
// In the DistributedLagrangeProblem, we need two parameters describing the dimensions of the domain  [2.x.4037]  (`dim`) and of the domain  [2.x.4038]  (`spacedim`).
//
// These will be used to initialize a Triangulation<dim,spacedim> (for  [2.x.4039] ) and a Triangulation<spacedim,spacedim> (for  [2.x.4040] ).
//
// A novelty with respect to other tutorial programs is the heavy use of  [2.x.4041]  These behave like classical pointers, with the advantage of doing automatic house-keeping: the contained object is automatically destroyed as soon as the unique_ptr goes out of scope, even if it is inside a container or there's an exception. Moreover it does not allow for duplicate pointers, which prevents ownership problems. We do this, because we want to be able to i) construct the problem, ii) read the parameters, and iii) initialize all objects according to what is specified in a parameter file.
//
// We construct the parameters of our problem in the internal class `Parameters`, derived from ParameterAcceptor. The `DistributedLagrangeProblem` class takes a const reference to a `Parameters` object, so that it is not possible to modify the parameters from within the DistributedLagrangeProblem class itself.
//
// We could have initialized the parameters first, and then pass the parameters to the DistributedLagrangeProblem assuming all entries are set to the desired values, but this has two disadvantages:
//
//
//
// - We should not make assumptions on how the user initializes a class that is not under our direct control. If the user fails to initialize the class, we should notice and throw an exception;
//
//
//
// - Not all objects that need to read parameters from a parameter file may be available when we construct the Parameters; this is often the case for complex programs, with multiple physics, or where we reuse existing code in some external classes. We simulate this by keeping some "complex" objects, like ParsedFunction objects, inside the `DistributedLagrangeProblem` instead of inside the `Parameters`.
//
// Here we assume that upon construction, the classes that build up our problem are not usable yet. Parsing the parameter file is what ensures we have all ingredients to build up our classes, and we design them so that if parsing fails, or is not executed, the run is aborted.
//
[0.x.34339] 
[0.x.34340] 
[0.x.34341] 
[0.x.34342] 
//
// The `Parameters` class is derived from ParameterAcceptor. This allows us to use the  [2.x.4042]  method in its constructor.
//
// The members of this function are all non-const, but the `DistributedLagrangeProblem` class takes a const reference to a `Parameters` object: this ensures that parameters are not modified from within the `DistributedLagrangeProblem` class.
//
[0.x.34343] 
[0.x.34344] 
[0.x.34345] 
[0.x.34346] 
//
// The parameters now described can all be set externally using a parameter file: if no parameter file is present when running the executable, the program will create a "parameters.prm" file with the default values defined here, and then abort to give the user a chance to modify the parameters.prm file.
//
// Initial refinement for the embedding grid, corresponding to the domain  [2.x.4043] .
//
[0.x.34347] 
//
// The interaction between the embedded grid  [2.x.4044]  and the embedding grid  [2.x.4045]  is handled through the computation of  [2.x.4046] , which involves all cells of  [2.x.4047]  overlapping with parts of  [2.x.4048] : a higher refinement of such cells might improve quality of our computations. For this reason we define `delta_refinement`: if it is greater than zero, then we mark each cell of the space grid that contains a vertex of the embedded grid and its neighbors, execute the refinement, and repeat this process `delta_refinement` times.
//
[0.x.34348] 
//
// Starting refinement of the embedded grid, corresponding to the domain  [2.x.4049] .
//
[0.x.34349] 
//
// The list of boundary ids where we impose homogeneous Dirichlet boundary conditions. On the remaining boundary ids (if any), we impose homogeneous Neumann boundary conditions. As a default problem we have zero Dirichlet boundary conditions on  [2.x.4050] 
[0.x.34350] 
//
// FiniteElement degree of the embedding space:  [2.x.4051] 
[0.x.34351] 
//
// FiniteElement degree of the embedded space:  [2.x.4052] 
[0.x.34352] 
//
// FiniteElement degree of the space used to describe the deformation of the embedded domain
//
[0.x.34353] 
//
// Order of the quadrature formula used to integrate the coupling
//
[0.x.34354] 
//
// If set to true, then the embedded configuration function is interpreted as a displacement function
//
[0.x.34355] 
//
// Level of verbosity to use in the output
//
[0.x.34356] 
//
// A flag to keep track if we were initialized or not
//
[0.x.34357] 
[0.x.34358] 
//
[0.x.34359] 
//
// Entry point for the DistributedLagrangeProblem
//
[0.x.34360] 
//
[0.x.34361] 
//
// Object containing the actual parameters
//
[0.x.34362] 
//
// The following functions are similar to all other tutorial programs, with the exception that we now need to set up things for two different families of objects, namely the ones related to the *embedding* grids, and the ones related to the *embedded* one.
//
[0.x.34363] 
//
[0.x.34364] 
//
[0.x.34365] 
//
// The only unconventional function we have here is the `setup_coupling()` method, used to generate the sparsity patter for the coupling matrix  [2.x.4053] .
//
[0.x.34366] 
//
[0.x.34367] 
//
[0.x.34368] 
//
[0.x.34369] 
//
// first we gather all the objects related to the embedding space geometry
//
[0.x.34370] 
[0.x.34371] 
[0.x.34372] 
[0.x.34373] 
[0.x.34374] 
//
// Then the ones related to the embedded grid, with the DoFHandler associated to the Lagrange multiplier `lambda`
//
[0.x.34375] 
[0.x.34376] 
[0.x.34377] 
//
// And finally, everything that is needed to *deform* the embedded triangulation
//
[0.x.34378] 
[0.x.34379] 
[0.x.34380] 
//
// The ParameterAcceptorProxy class is a "transparent" wrapper derived from both ParameterAcceptor and the type passed as its template parameter. At construction, the arguments are split into two parts: the first argument is an  [2.x.4054]  forwarded to the ParameterAcceptor class, and containing the name of the section that should be used for this class, while all the remaining arguments are forwarded to the constructor of the templated type, in this case, to the  [2.x.4055]  constructor.
//
// This class allows you to use existing classes in conjunction with the ParameterAcceptor registration mechanism, provided that those classes have the members `declare_parameters()` and `parse_parameters()`.
//
// This is the case here, making it fairly easy to exploit the  [2.x.4056]  class: instead of requiring users to create new Function objects in their code for the RHS, boundary functions, etc., (like it is done in most of the other tutorials), here we allow the user to use deal.II interface to muParser (http:muparser.beltoforion.de), where the specification of the function is not done at compile time, but at run time, using a string that is parsed into an actual Function object.
//
// In this case, the `embedded_configuration_function` is a vector valued Function that can be interpreted as either a *deformation* or a *displacement* according to the boolean value of `parameters.use_displacement`. The number of components is specified later on in the construction.
//
[0.x.34381] 
[0.x.34382] 
//
[0.x.34383] 
//
// We do the same thing to specify the value of the function  [2.x.4057] , which is what we want our solution to be in the embedded space. In this case the Function is a scalar one.
//
[0.x.34384] 
[0.x.34385] 
//
// Similarly to what we have done with the  [2.x.4058]  class, we repeat the same for the ReductionControl class, allowing us to specify all possible stopping criteria for the Schur complement iterative solver we'll use later on.
//
[0.x.34386] 
//
// Next we gather all SparsityPattern, SparseMatrix, and Vector objects we'll need
//
[0.x.34387] 
[0.x.34388] 
//
[0.x.34389] 
[0.x.34390] 
//
[0.x.34391] 
//
[0.x.34392] 
[0.x.34393] 
//
[0.x.34394] 
[0.x.34395] 
[0.x.34396] 
//
// The TimerOutput class is used to provide some statistics on the performance of our program.
//
[0.x.34397] 
[0.x.34398] 
//[2.x.4059] 
//
// At construction time, we initialize also the ParameterAcceptor class, with the section name we want our problem to use when parsing the parameter file.
//
// Parameter files can be organized into section/subsection/etc.: this has the advantage that defined objects share parameters when sharing the same section/subsection/etc. ParameterAcceptor allows to specify the section name using Unix conventions on paths. If the section name starts with a slash ("/"), then the section is interpreted as an *absolute path*, ParameterAcceptor enters a subsection for each directory in the path, using the last name it encountered as the landing subsection for the current class.
//
// For example, if you construct your class using `ParameterAcceptor("/first/second/third/My Class")`, the parameters will be organized as follows:
//
// [1.x.112]
//
// Internally, the *current path* stored in ParameterAcceptor is now considered to be "/first/second/third/", i.e. when you specify an absolute path, ParameterAcceptor *changes* the current section to the current path, i.e. to the path of the section name until the *last* "/".
//
// You can now construct another class derived from ParameterAcceptor using a relative path (e.g., `ParameterAcceptor("My Other Class")`) instead of the absolute one (e.g. `ParameterAcceptor("/first/second/third/My Other Class")`), obtaining: [1.x.113]
//
// If the section name *ends* with a slash then subsequent classes will interpret this as a full path: for example, similar to the one above, if we have two classes, one initialized with `ParameterAcceptor("/first/second/third/My Class/")` and the other with `ParameterAcceptor("My Other Class")`, then the resulting parameter file will look like:
//
// [1.x.114]
//
// We are going to exploit this, by making our `Parameters` the *parent* of all subsequently constructed classes. Since most of the other classes are members of `DistributedLagrangeProblem` this allows, for example, to construct two `DistributedLagrangeProblem` for two different dimensions, without having conflicts in the parameters for the two problems.
//
[0.x.34399] 
[0.x.34400] 
[0.x.34401] 
[0.x.34402] 
[0.x.34403] 
[0.x.34404] 
//
// The  [2.x.4060]  function does a few things:
//
//
//
// - enters the subsection specified at construction time to ParameterAcceptor
//
//
//
// - calls the  [2.x.4061]  function
//
//
//
// - calls any signal you may have attached to  [2.x.4062] 
//
//
//
// - leaves the subsection
//
// In turn,  [2.x.4063] 
//
//
//
// - declares an entry in the parameter handler for the given variable;
//
//
//
// - takes the current value of the variable
//
//
//
// - transforms it to a string, used as the default value for the parameter file
//
//
//
// - attaches an *action* to  [2.x.4064]  that monitors when a file is parsed, or when an entry is set, and when this happens, it updates the value of the variable passed to `add_parameter()` by setting it to whatever was specified in the input file (of course, after the input file has been parsed and the text representation converted to the type of the variable).
//
[0.x.34405] 
//
[0.x.34406] 
[0.x.34407] 
//
[0.x.34408] 
[0.x.34409] 
//
[0.x.34410] 
[0.x.34411] 
//
[0.x.34412] 
//
[0.x.34413] 
[0.x.34414] 
//
[0.x.34415] 
[0.x.34416] 
//
[0.x.34417] 
[0.x.34418] 
//
[0.x.34419] 
//
[0.x.34420] 
//
// Once the parameter file has been parsed, then the parameters are good to go. Set the internal variable `initialized` to true.
//
[0.x.34421] 
[0.x.34422] 
//
// The constructor is pretty standard, with the exception of the `ParameterAcceptorProxy` objects, as explained earlier.
//
[0.x.34423] 
[0.x.34424] 
[0.x.34425] 
[0.x.34426] 
[0.x.34427] 
[0.x.34428] 
[0.x.34429] 
[0.x.34430] 
[0.x.34431] 
//
// Here is a way to set default values for a ParameterAcceptor class that was constructed using ParameterAcceptorProxy.
//
// In this case, we set the default deformation of the embedded grid to be a circle with radius  [2.x.4065]  and center  [2.x.4066] , we set the default value for the embedded_value_function to be the constant one, and specify some sensible values for the SolverControl object.
//
// It is fundamental for  [2.x.4067]  to be embedded: from the definition of  [2.x.4068]  is clear that, if  [2.x.4069] , certain rows of the matrix  [2.x.4070]  will be zero. This would be a problem, as the Schur complement method requires  [2.x.4071]  to have full column rank.
//
[0.x.34432] 
[0.x.34433] 
[0.x.34434] 
//
[0.x.34435] 
[0.x.34436] 
[0.x.34437] 
//
[0.x.34438] 
[0.x.34439] 
//
[0.x.34440] 
[0.x.34441] 
[0.x.34442] 
[0.x.34443] 
[0.x.34444] 
[0.x.34445] 
//[2.x.4072] 
//
// The function  [2.x.4073]  is used to set up the finite element spaces. Notice how  [2.x.4074]  is used to create objects wrapped inside  [2.x.4075]  objects.
//
[0.x.34446] 
[0.x.34447] 
[0.x.34448] 
[0.x.34449] 
//
// Initializing  [2.x.4076] : constructing the Triangulation and wrapping it into a  [2.x.4077]  object
//
[0.x.34450] 
//
// Next, we actually create the triangulation using  [2.x.4078]  The last argument is set to true: this activates colorization (i.e., assigning different boundary indicators to different parts of the boundary), which we use to assign the Dirichlet and Neumann conditions.
//
[0.x.34451] 
//
// Once we constructed a Triangulation, we refine it globally according to the specifications in the parameter file, and construct a  [2.x.4079]  with it.
//
[0.x.34452] 
[0.x.34453] 
[0.x.34454] 
//
// The same is done with the embedded grid. Since the embedded grid is deformed, we first need to setup the deformation mapping. We do so in the following few lines:
//
[0.x.34455] 
[0.x.34456] 
[0.x.34457] 
//
[0.x.34458] 
[0.x.34459] 
[0.x.34460] 
[0.x.34461] 
//
[0.x.34462] 
[0.x.34463] 
//
[0.x.34464] 
[0.x.34465] 
//
// Once we have defined a finite dimensional space for the deformation, we interpolate the `embedded_configuration_function` defined in the parameter file:
//
[0.x.34466] 
[0.x.34467] 
[0.x.34468] 
//
// Now we can interpret it according to what the user has specified in the parameter file: as a displacement, in which case we construct a mapping that *displaces* the position of each support point of our configuration finite element space by the specified amount on the corresponding configuration vector, or as an absolution position.
//
// In the first case, the class MappingQEulerian offers its services, while in the second one, we'll use the class MappingFEField. They are in fact very similar. MappingQEulerian will only work for systems of FE_Q finite element spaces, where the displacement vector is stored in the first `spacedim` components of the FESystem, and the degree given as a parameter at construction time, must match the degree of the first `spacedim` components.
//
// The class MappingFEField is slightly more general, in that it allows you to select arbitrary FiniteElement types when constructing your approximation. Naturally some choices may (or may not) make sense, according to the type of FiniteElement you choose. MappingFEField implements the pure iso-parametric concept, and can be used, for example, to implement iso-geometric analysis codes in deal.II, by combining it with the FE_Bernstein finite element class. In this example, we'll use the two interchangeably, by taking into account the fact that one configuration will be a `displacement`, while the other will be an absolute `deformation` field.
//
[0.x.34469] 
[0.x.34470] 
[0.x.34471] 
[0.x.34472] 
[0.x.34473] 
[0.x.34474] 
[0.x.34475] 
[0.x.34476] 
[0.x.34477] 
[0.x.34478] 
//
[0.x.34479] 
//
// In this tutorial program we not only refine  [2.x.4080]  globally, but also allow a local refinement depending on the position of  [2.x.4081] , according to the value of `parameters.delta_refinement`, that we use to decide how many rounds of local refinement we should do on  [2.x.4082] , corresponding to the position of  [2.x.4083] .
//
// With the mapping in place, it is now possible to query what is the location of all support points associated with the `embedded_dh`, by calling the method  [2.x.4084] 
//
// This method has two variants. One that does *not* take a Mapping, and one that takes a Mapping. If you use the second type, like we are doing in this case, the support points are computed through the specified mapping, which can manipulate them accordingly.
//
// This is precisely what the `embedded_mapping` is there for.
//
[0.x.34480] 
[0.x.34481] 
[0.x.34482] 
[0.x.34483] 
[0.x.34484] 
//
// Once we have the support points of the embedded finite element space, we would like to identify what cells of the embedding space contain what support point, to get a chance at refining the embedding grid where it is necessary, i.e., where the embedded grid is. This can be done manually, by looping over each support point, and then calling the method  [2.x.4085]  for each cell of the embedding space, until we find one that returns points in the unit reference cell, or it can be done in a more intelligent way.
//
// The  [2.x.4086]  is a possible option that performs the above task in a cheaper way, by first identifying the closest vertex of the embedding Triangulation to the target point, and then by calling  [2.x.4087]  only for those cells that share the found vertex.
//
// In fact, there are algorithms in the GridTools namespace that exploit a  [2.x.4088]  object, and possibly a KDTree object to speed up these operations as much as possible.
//
// The simplest way to exploit the maximum speed is by calling a specialized method,  [2.x.4089]  that will store a lot of useful information and data structures during the first point search, and then reuse all of this for subsequent points.
//
//  [2.x.4090]  returns a tuple where the first element is a vector of cells containing the input points, in this case support_points. For refinement, this is the only information we need, and this is exactly what happens now.
//
// When we need to assemble a coupling matrix, however, we'll also need the reference location of each point to evaluate the basis functions of the embedding space. The other elements of the tuple returned by  [2.x.4091]  allow you to reconstruct, for each point, what cell contains it, and what is the location in the reference cell of the given point. Since this information is better grouped into cells, then this is what the algorithm returns: a tuple, containing a vector of all cells that have at least one point in them, together with a list of all reference points and their corresponding index in the original vector.
//
// In the following loop, we will be ignoring all returned objects except the first, identifying all cells contain at least one support point of the embedded space. This allows for a simple adaptive refinement strategy: refining these cells and their neighbors.
//
// Notice that we need to do some sanity checks, in the sense that we want to have an embedding grid which is well refined around the embedded grid, but where two consecutive support points lie either in the same cell, or in neighbor embedding cells.
//
// This is only possible if we ensure that the smallest cell size of the embedding grid is nonetheless bigger than the largest cell size of the embedded grid. Since users can modify both levels of refinements, as well as the amount of local refinement they want around the embedded grid, we make sure that the resulting meshes satisfy our requirements, and if this is not the case, we bail out with an exception.
//
[0.x.34485] 
[0.x.34486] 
[0.x.34487] 
[0.x.34488] 
[0.x.34489] 
[0.x.34490] 
[0.x.34491] 
[0.x.34492] 
[0.x.34493] 
[0.x.34494] 
[0.x.34495] 
[0.x.34496] 
[0.x.34497] 
[0.x.34498] 
[0.x.34499] 
//
// In order to construct a well posed coupling interpolation operator  [2.x.4092] , there are some constraints on the relative dimension of the grids between the embedding and the embedded domains. The coupling operator  [2.x.4093]  and the spaces  [2.x.4094]  and  [2.x.4095]  have to satisfy an inf-sup condition in order for the problem to have a solution. It turns out that the non-matching  [2.x.4096]  projection satisfies such inf-sup, provided that the spaces  [2.x.4097]  and  [2.x.4098]  are compatible between each other (for example, provided that they are chosen to be the ones described in the introduction).
//
// However, the *discrete* inf-sup condition must also hold. No complications arise here, but it turns out that the discrete inf-sup constant deteriorates when the non-matching grids have local diameters that are too far away from each other. In particular, it turns out that if you choose an embedding grid which is *finer* with respect to the embedded grid, the inf-sup constant deteriorates much more than if you let the embedded grid be finer.
//
// In order to avoid issues, in this tutorial we will throw an exception if the parameters chosen by the user are such that the maximal diameter of the embedded grid is greater than the minimal diameter of the embedding grid.
//
// This choice guarantees that almost every cell of the embedded grid spans no more than two cells of the embedding grid, with some rare exceptions, that are negligible in terms of the resulting inf-sup.
//
[0.x.34500] 
[0.x.34501] 
[0.x.34502] 
[0.x.34503] 
//
[0.x.34504] 
[0.x.34505] 
[0.x.34506] 
[0.x.34507] 
[0.x.34508] 
[0.x.34509] 
[0.x.34510] 
//
[0.x.34511] 
[0.x.34512] 
[0.x.34513] 
[0.x.34514] 
[0.x.34515] 
[0.x.34516] 
[0.x.34517] 
//[2.x.4099]  has been refined and we can now set up its DoFs
//
[0.x.34518] 
[0.x.34519] 
//
// We now set up the DoFs of  [2.x.4100]  and  [2.x.4101] : since they are fundamentally independent (except for the fact that  [2.x.4102] 's mesh is more refined "around"  [2.x.4103] ) the procedure is standard.
//
[0.x.34520] 
[0.x.34521] 
[0.x.34522] 
[0.x.34523] 
[0.x.34524] 
[0.x.34525] 
[0.x.34526] 
//
[0.x.34527] 
[0.x.34528] 
[0.x.34529] 
[0.x.34530] 
[0.x.34531] 
[0.x.34532] 
[0.x.34533] 
//
// By definition the stiffness matrix involves only  [2.x.4104] 's DoFs
//
[0.x.34534] 
[0.x.34535] 
[0.x.34536] 
[0.x.34537] 
[0.x.34538] 
[0.x.34539] 
//
[0.x.34540] 
[0.x.34541] 
//
[0.x.34542] 
[0.x.34543] 
[0.x.34544] 
[0.x.34545] 
[0.x.34546] 
[0.x.34547] 
[0.x.34548] 
//
// By definition the rhs of the system we're solving involves only a zero vector and  [2.x.4105] , which is computed using only  [2.x.4106] 's DoFs
//
[0.x.34549] 
[0.x.34550] 
[0.x.34551] 
//
[0.x.34552] 
[0.x.34553] 
//
// Creating the coupling sparsity pattern is a complex operation, but it can be easily done using the  [2.x.4107]  which requires the two DoFHandler objects, the quadrature points for the coupling, a DynamicSparsityPattern (which then needs to be copied into the sparsity one, as usual), the component mask for the embedding and embedded Triangulation (which we leave empty) and the mappings for both the embedding and the embedded Triangulation.
//
[0.x.34554] 
[0.x.34555] 
[0.x.34556] 
[0.x.34557] 
//
[0.x.34558] 
//
[0.x.34559] 
//
[0.x.34560] 
[0.x.34561] 
[0.x.34562] 
[0.x.34563] 
[0.x.34564] 
[0.x.34565] 
[0.x.34566] 
[0.x.34567] 
[0.x.34568] 
[0.x.34569] 
[0.x.34570] 
[0.x.34571] 
//[2.x.4108] 
//
// The following function creates the matrices: as noted before computing the stiffness matrix and the rhs is a standard procedure.
//
[0.x.34572] 
[0.x.34573] 
[0.x.34574] 
[0.x.34575] 
[0.x.34576] 
//
// Embedding stiffness matrix  [2.x.4109] , and the right hand side  [2.x.4110] .
//
[0.x.34577] 
[0.x.34578] 
[0.x.34579] 
[0.x.34580] 
[0.x.34581] 
[0.x.34582] 
//
[0.x.34583] 
[0.x.34584] 
[0.x.34585] 
[0.x.34586] 
[0.x.34587] 
[0.x.34588] 
[0.x.34589] 
[0.x.34590] 
[0.x.34591] 
//
// To compute the coupling matrix we use the  [2.x.4111]  tool, which works similarly to  [2.x.4112] 
[0.x.34592] 
[0.x.34593] 
[0.x.34594] 
[0.x.34595] 
[0.x.34596] 
[0.x.34597] 
[0.x.34598] 
[0.x.34599] 
[0.x.34600] 
[0.x.34601] 
//
[0.x.34602] 
[0.x.34603] 
[0.x.34604] 
[0.x.34605] 
[0.x.34606] 
[0.x.34607] 
//[2.x.4113] 
//
// All parts have been assembled: we solve the system using the Schur complement method
//
[0.x.34608] 
[0.x.34609] 
[0.x.34610] 
[0.x.34611] 
//
// Start by creating the inverse stiffness matrix
//
[0.x.34612] 
[0.x.34613] 
//
// Initializing the operators, as described in the introduction
//
[0.x.34614] 
[0.x.34615] 
[0.x.34616] 
//
[0.x.34617] 
//
// Using the Schur complement method
//
[0.x.34618] 
[0.x.34619] 
[0.x.34620] 
//
[0.x.34621] 
//
[0.x.34622] 
//
[0.x.34623] 
[0.x.34624] 
//
// The following function simply generates standard result output on two separate files, one for each mesh.
//
[0.x.34625] 
[0.x.34626] 
[0.x.34627] 
[0.x.34628] 
//
[0.x.34629] 
//
[0.x.34630] 
//
[0.x.34631] 
[0.x.34632] 
[0.x.34633] 
[0.x.34634] 
[0.x.34635] 
//
// The only difference between the two output routines is that in the second case, we want to output the data on the current configuration, and not on the reference one. This is possible by passing the actual embedded_mapping to the  [2.x.4114]  function. The mapping will take care of outputting the result on the actual deformed configuration.
//
[0.x.34636] 
//
[0.x.34637] 
//
[0.x.34638] 
[0.x.34639] 
[0.x.34640] 
[0.x.34641] 
[0.x.34642] 
[0.x.34643] 
[0.x.34644] 
//
// Similar to all other tutorial programs, the `run()` function simply calls all other methods in the correct order. Nothing special to note, except that we check if parsing was done before we actually attempt to run our program.
//
[0.x.34645] 
[0.x.34646] 
[0.x.34647] 
[0.x.34648] 
[0.x.34649] 
//
[0.x.34650] 
[0.x.34651] 
[0.x.34652] 
[0.x.34653] 
[0.x.34654] 
[0.x.34655] 
[0.x.34656] 
//
[0.x.34657] 
[0.x.34658] 
[0.x.34659] 
[0.x.34660] 
[0.x.34661] 
[0.x.34662] 
//
[0.x.34663] 
//
// Differently to what happens in other tutorial programs, here we use ParameterAcceptor style of initialization, i.e., all objects are first constructed, and then a single call to the static method  [2.x.4115]  is issued to fill all parameters of the classes that are derived from ParameterAcceptor.
//
// We check if the user has specified a parameter file name to use when the program was launched. If so, try to read that parameter file, otherwise, try to read the file "parameters.prm".
//
// If the parameter file that was specified (implicitly or explicitly) does not exist,  [2.x.4116]  will create one for you, and exit the program.
//
[0.x.34664] 
[0.x.34665] 
//
[0.x.34666] 
[0.x.34667] 
[0.x.34668] 
[0.x.34669] 
[0.x.34670] 
//
[0.x.34671] 
[0.x.34672] 
[0.x.34673] 
[0.x.34674] 
[0.x.34675] 
[0.x.34676] 
[0.x.34677] 
[0.x.34678] 
[0.x.34679] 
[0.x.34680] 
[0.x.34681] 
[0.x.34682] 
[0.x.34683] 
[0.x.34684] 
[0.x.34685] 
[0.x.34686] 
[0.x.34687] 
[0.x.34688] 
[0.x.34689] 
[0.x.34690] 
[0.x.34691] 
[0.x.34692] 
[0.x.34693] 
[0.x.34694] 
[0.x.34695] 
[0.x.34696] 
[0.x.34697] 
[0.x.34698] 
[0.x.34699] 
[0.x.34700] 
[0.x.34701] 
[0.x.34702] 
[0.x.34703] 
[0.x.34704] 
[0.x.34705] 
[0.x.34706] 
[0.x.34707] 
[0.x.34708] 
[0.x.34709] 
[0.x.34710] 
[0.x.34711] 
[0.x.34712] 
[0.x.34713] 
[0.x.34714] 
//
[0.x.34715] 
[0.x.34716] 
//[2.x.4117]  This program is based on  [2.x.4118] ,  [2.x.4119]  and  [2.x.4120] , so most of the following header files are familiar. We need the following, of which only the one that imports the FE_DGRaviartThomas class (namely, `deal.II/fe/fe_dg_vector.h`) is really new; the FE_DGRaviartThomas implements the "broken" Raviart-Thomas space discussed in the introduction:
//
[0.x.34717] 
[0.x.34718] 
[0.x.34719] 
[0.x.34720] 
[0.x.34721] 
[0.x.34722] 
[0.x.34723] 
[0.x.34724] 
[0.x.34725] 
[0.x.34726] 
[0.x.34727] 
[0.x.34728] 
[0.x.34729] 
[0.x.34730] 
[0.x.34731] 
[0.x.34732] 
[0.x.34733] 
[0.x.34734] 
[0.x.34735] 
[0.x.34736] 
[0.x.34737] 
[0.x.34738] 
[0.x.34739] 
[0.x.34740] 
[0.x.34741] 
[0.x.34742] 
[0.x.34743] 
[0.x.34744] 
//
[0.x.34745] 
[0.x.34746] 
//
// Our first step, as always, is to put everything related to this tutorial program into its own namespace:
//
[0.x.34747] 
[0.x.34748] 
[0.x.34749] 
//[2.x.4121] 
//
// This is the main class of this program. We will solve for the numerical pressure in the interior and on faces using the weak Galerkin (WG) method, and calculate the  [2.x.4122]  error of pressure. In the post-processing step, we will also calculate  [2.x.4123] -errors of the velocity and flux.
//
// The structure of the class is not fundamentally different from that of previous tutorial programs, so there is little need to comment on the details with one exception: The class has a member variable `fe_dgrt` that corresponds to the "broken" Raviart-Thomas space mentioned in the introduction. There is a matching `dof_handler_dgrt` that represents a global enumeration of a finite element field created from this element, and a vector `darcy_velocity` that holds nodal values for this field. We will use these three variables after solving for the pressure to compute a postprocessed velocity field for which we can then evaluate the error and which we can output for visualization.
//
[0.x.34750] 
[0.x.34751] 
[0.x.34752] 
[0.x.34753] 
[0.x.34754] 
[0.x.34755] 
//
[0.x.34756] 
[0.x.34757] 
[0.x.34758] 
[0.x.34759] 
[0.x.34760] 
[0.x.34761] 
[0.x.34762] 
[0.x.34763] 
[0.x.34764] 
//
[0.x.34765] 
//
[0.x.34766] 
[0.x.34767] 
//
[0.x.34768] 
//
[0.x.34769] 
[0.x.34770] 
//
[0.x.34771] 
[0.x.34772] 
//
[0.x.34773] 
[0.x.34774] 
[0.x.34775] 
[0.x.34776] 
//
//  [2.x.4124] 
//
// Next, we define the coefficient matrix  [2.x.4125]  (here, the identity matrix), Dirichlet boundary conditions, the right-hand side  [2.x.4126] , and the exact solution that corresponds to these choices for  [2.x.4127]  and  [2.x.4128] , namely  [2.x.4129] .
//
[0.x.34777] 
[0.x.34778] 
[0.x.34779] 
[0.x.34780] 
[0.x.34781] 
[0.x.34782] 
[0.x.34783] 
//
[0.x.34784] 
[0.x.34785] 
[0.x.34786] 
//
[0.x.34787] 
[0.x.34788] 
[0.x.34789] 
[0.x.34790] 
[0.x.34791] 
[0.x.34792] 
[0.x.34793] 
[0.x.34794] 
[0.x.34795] 
//
[0.x.34796] 
[0.x.34797] 
[0.x.34798] 
[0.x.34799] 
[0.x.34800] 
[0.x.34801] 
[0.x.34802] 
//
[0.x.34803] 
[0.x.34804] 
[0.x.34805] 
//
[0.x.34806] 
[0.x.34807] 
[0.x.34808] 
[0.x.34809] 
[0.x.34810] 
[0.x.34811] 
//
[0.x.34812] 
[0.x.34813] 
[0.x.34814] 
[0.x.34815] 
[0.x.34816] 
[0.x.34817] 
[0.x.34818] 
//
[0.x.34819] 
[0.x.34820] 
[0.x.34821] 
[0.x.34822] 
[0.x.34823] 
[0.x.34824] 
[0.x.34825] 
//
// The class that implements the exact pressure solution has an oddity in that we implement it as a vector-valued one with two components. (We say that it has two components in the constructor where we call the constructor of the base Function class.) In the `value()` function, we do not test for the value of the `component` argument, which implies that we return the same value for both components of the vector-valued function. We do this because we describe the finite element in use in this program as a vector-valued system that contains the interior and the interface pressures, and when we compute errors, we will want to use the same pressure solution to test both of these components.
//
[0.x.34826] 
[0.x.34827] 
[0.x.34828] 
[0.x.34829] 
[0.x.34830] 
[0.x.34831] 
[0.x.34832] 
//
[0.x.34833] 
[0.x.34834] 
[0.x.34835] 
//
[0.x.34836] 
[0.x.34837] 
[0.x.34838] 
[0.x.34839] 
[0.x.34840] 
[0.x.34841] 
//
[0.x.34842] 
[0.x.34843] 
[0.x.34844] 
[0.x.34845] 
[0.x.34846] 
[0.x.34847] 
[0.x.34848] 
//
[0.x.34849] 
[0.x.34850] 
//
[0.x.34851] 
[0.x.34852] 
[0.x.34853] 
[0.x.34854] 
[0.x.34855] 
[0.x.34856] 
[0.x.34857] 
[0.x.34858] 
[0.x.34859] 
[0.x.34860] 
//
//  [2.x.4130] 
//[2.x.4131] 
//
// In this constructor, we create a finite element space for vector valued functions, which will here include the ones used for the interior and interface pressures,  [2.x.4132]  and  [2.x.4133] .
//
[0.x.34861] 
[0.x.34862] 
[0.x.34863] 
[0.x.34864] 
[0.x.34865] 
[0.x.34866] 
[0.x.34867] 
//
//  [2.x.4134] 
//
// We generate a mesh on the unit square domain and refine it.
//
[0.x.34868] 
[0.x.34869] 
[0.x.34870] 
[0.x.34871] 
[0.x.34872] 
//
[0.x.34873] 
[0.x.34874] 
[0.x.34875] 
[0.x.34876] 
[0.x.34877] 
//
//  [2.x.4135] 
//
// After we have created the mesh above, we distribute degrees of freedom and resize matrices and vectors. The only piece of interest in this function is how we interpolate the boundary values for the pressure. Since the pressure consists of interior and interface components, we need to make sure that we only interpolate onto that component of the vector-valued solution space that corresponds to the interface pressures (as these are the only ones that are defined on the boundary of the domain). We do this via a component mask object for only the interface pressures.
//
[0.x.34878] 
[0.x.34879] 
[0.x.34880] 
[0.x.34881] 
[0.x.34882] 
//
[0.x.34883] 
[0.x.34884] 
//
[0.x.34885] 
[0.x.34886] 
//
[0.x.34887] 
[0.x.34888] 
[0.x.34889] 
[0.x.34890] 
[0.x.34891] 
[0.x.34892] 
[0.x.34893] 
[0.x.34894] 
[0.x.34895] 
[0.x.34896] 
[0.x.34897] 
[0.x.34898] 
//
// In the bilinear form, there is no integration term over faces between two neighboring cells, so we can just use  [2.x.4136]  to calculate the sparse matrix.
//
[0.x.34899] 
[0.x.34900] 
[0.x.34901] 
//
[0.x.34902] 
[0.x.34903] 
//
//  [2.x.4137] 
//
// This function is more interesting. As detailed in the introduction, the assembly of the linear system requires us to evaluate the weak gradient of the shape functions, which is an element in the Raviart-Thomas space. As a consequence, we need to define a Raviart-Thomas finite element object, and have FEValues objects that evaluate it at quadrature points. We then need to compute the matrix  [2.x.4138]  on every cell  [2.x.4139] , for which we need the matrices  [2.x.4140]  and  [2.x.4141]  mentioned in the introduction.
//
// A point that may not be obvious is that in all previous tutorial programs, we have always called  [2.x.4142]  with a cell iterator from a DoFHandler. This is so that one can call functions such as  [2.x.4143]  that extract the values of a finite element function (represented by a vector of DoF values) on the quadrature points of a cell. For this operation to work, one needs to know which vector elements correspond to the degrees of freedom on a given cell -- i.e., exactly the kind of information and operation provided by the DoFHandler class.
//
// We could create a DoFHandler object for the "broken" Raviart-Thomas space (using the FE_DGRT class), but we really don't want to here: At least in the current function, we have no need for any globally defined degrees of freedom associated with this broken space, but really only need to reference the shape functions of such a space on the current cell. As a consequence, we use the fact that one can call  [2.x.4144]  also with cell iterators into Triangulation objects (rather than DoFHandler objects). In this case, FEValues can of course only provide us with information that only references information about cells, rather than degrees of freedom enumerated on these cells. So we can't use  [2.x.4145]  but we can use  [2.x.4146]  to obtain the values of shape functions at quadrature points on the current cell. It is this kind of functionality we will make use of below. The variable that will give us this information about the Raviart-Thomas functions below is then the `fe_values_rt` (and corresponding `fe_face_values_rt`) object.
//
// Given this introduction, the following declarations should be pretty obvious:
//
[0.x.34904] 
[0.x.34905] 
[0.x.34906] 
[0.x.34907] 
[0.x.34908] 
//
[0.x.34909] 
[0.x.34910] 
[0.x.34911] 
[0.x.34912] 
[0.x.34913] 
[0.x.34914] 
[0.x.34915] 
[0.x.34916] 
[0.x.34917] 
//
[0.x.34918] 
[0.x.34919] 
[0.x.34920] 
[0.x.34921] 
[0.x.34922] 
[0.x.34923] 
[0.x.34924] 
[0.x.34925] 
[0.x.34926] 
[0.x.34927] 
[0.x.34928] 
//
[0.x.34929] 
[0.x.34930] 
//
[0.x.34931] 
[0.x.34932] 
//
[0.x.34933] 
//
[0.x.34934] 
[0.x.34935] 
//
[0.x.34936] 
[0.x.34937] 
//
[0.x.34938] 
//
// Next, let us declare the various cell matrices discussed in the introduction:
//
[0.x.34939] 
[0.x.34940] 
[0.x.34941] 
[0.x.34942] 
[0.x.34943] 
[0.x.34944] 
//
// We need  [2.x.4147]  to access the  [2.x.4148]  and  [2.x.4149]  component of the shape functions.
//
[0.x.34945] 
[0.x.34946] 
[0.x.34947] 
//
// This finally gets us in position to loop over all cells. On each cell, we will first calculate the various cell matrices used to construct the local matrix -- as they depend on the cell in question, they need to be re-computed on each cell. We need shape functions for the Raviart-Thomas space as well, for which we need to create first an iterator to the cell of the triangulation, which we can obtain by assignment from the cell pointing into the DoFHandler.
//
[0.x.34948] 
[0.x.34949] 
[0.x.34950] 
//
[0.x.34951] 
[0.x.34952] 
[0.x.34953] 
//
[0.x.34954] 
[0.x.34955] 
[0.x.34956] 
[0.x.34957] 
//
// The first cell matrix we will compute is the mass matrix for the Raviart-Thomas space.  Hence, we need to loop over all the quadrature points for the velocity FEValues object.
//
[0.x.34958] 
[0.x.34959] 
[0.x.34960] 
[0.x.34961] 
[0.x.34962] 
[0.x.34963] 
[0.x.34964] 
[0.x.34965] 
[0.x.34966] 
[0.x.34967] 
[0.x.34968] 
[0.x.34969] 
//
// Next we take the inverse of this matrix by using  [2.x.4150]  It will be used to calculate the coefficient matrix  [2.x.4151]  later. It is worth recalling later that `cell_matrix_M` actually contains the *inverse*
// of  [2.x.4152]  after this call.
//
[0.x.34970] 
//
// From the introduction, we know that the right hand side  [2.x.4153]  of the equation that defines  [2.x.4154]  is the difference between a face integral and a cell integral. Here, we approximate the negative of the contribution in the interior. Each component of this matrix is the integral of a product between a basis function of the polynomial space and the divergence of a basis function of the Raviart-Thomas space. These basis functions are defined in the interior.
//
[0.x.34971] 
[0.x.34972] 
[0.x.34973] 
[0.x.34974] 
[0.x.34975] 
[0.x.34976] 
[0.x.34977] 
[0.x.34978] 
[0.x.34979] 
[0.x.34980] 
//
[0.x.34981] 
[0.x.34982] 
[0.x.34983] 
[0.x.34984] 
//
// Next, we approximate the integral on faces by quadrature. Each component is the integral of a product between a basis function of the polynomial space and the dot product of a basis function of the Raviart-Thomas space and the normal vector. So we loop over all the faces of the element and obtain the normal vector.
//
[0.x.34985] 
[0.x.34986] 
[0.x.34987] 
[0.x.34988] 
//
[0.x.34989] 
[0.x.34990] 
[0.x.34991] 
//
[0.x.34992] 
[0.x.34993] 
[0.x.34994] 
[0.x.34995] 
[0.x.34996] 
[0.x.34997] 
[0.x.34998] 
[0.x.34999] 
//
[0.x.35000] 
[0.x.35001] 
[0.x.35002] 
[0.x.35003] 
[0.x.35004] 
[0.x.35005] 
//[2.x.4155]  is then the matrix product between the transpose of  [2.x.4156]  and the inverse of the mass matrix (where this inverse is stored in  [2.x.4157] 
[0.x.35006] 
//
// Finally we can compute the local matrix  [2.x.4158] .  Element  [2.x.4159]  is given by  [2.x.4160] . We have calculated the coefficients  [2.x.4161]  in the previous step, and so obtain the following after suitably re-arranging the loops:
//
[0.x.35007] 
[0.x.35008] 
[0.x.35009] 
[0.x.35010] 
[0.x.35011] 
[0.x.35012] 
[0.x.35013] 
[0.x.35014] 
[0.x.35015] 
[0.x.35016] 
[0.x.35017] 
//
[0.x.35018] 
[0.x.35019] 
[0.x.35020] 
[0.x.35021] 
[0.x.35022] 
[0.x.35023] 
[0.x.35024] 
[0.x.35025] 
//
// Next, we calculate the right hand side,  [2.x.4162] :
//
[0.x.35026] 
[0.x.35027] 
[0.x.35028] 
[0.x.35029] 
[0.x.35030] 
[0.x.35031] 
[0.x.35032] 
//
// The last step is to distribute components of the local matrix into the system matrix and transfer components of the cell right hand side into the system right hand side:
//
[0.x.35033] 
[0.x.35034] 
[0.x.35035] 
[0.x.35036] 
[0.x.35037] 
//
//  [2.x.4163] 
//
// This step is rather trivial and the same as in many previous tutorial programs:
//
[0.x.35038] 
[0.x.35039] 
[0.x.35040] 
[0.x.35041] 
[0.x.35042] 
[0.x.35043] 
[0.x.35044] 
[0.x.35045] 
//[2.x.4164] 
//
// In this function, compute the velocity field from the pressure solution previously computed. The velocity is defined as  [2.x.4165] , which requires us to compute many of the same terms as in the assembly of the system matrix. There are also the matrices  [2.x.4166]  we need to assemble (see the introduction) but they really just follow the same kind of pattern.
//
// Computing the same matrices here as we have already done in the `assemble_system()` function is of course wasteful in terms of CPU time. Likewise, we copy some of the code from there to this function, and this is also generally a poor idea. A better implementation might provide for a function that encapsulates this duplicated code. One could also think of using the classic trade-off between computing efficiency and memory efficiency to only compute the  [2.x.4167]  matrices once per cell during the assembly, storing them somewhere on the side, and re-using them here. (This is what  [2.x.4168]  does, for example, where the `assemble_system()` function takes an argument that determines whether the local matrices are recomputed, and a similar approach -- maybe with storing local matrices elsewhere -- could be adapted for the current program.)
//
[0.x.35046] 
[0.x.35047] 
[0.x.35048] 
[0.x.35049] 
//
[0.x.35050] 
[0.x.35051] 
//
[0.x.35052] 
[0.x.35053] 
[0.x.35054] 
[0.x.35055] 
//
[0.x.35056] 
[0.x.35057] 
[0.x.35058] 
[0.x.35059] 
[0.x.35060] 
//
[0.x.35061] 
[0.x.35062] 
[0.x.35063] 
[0.x.35064] 
[0.x.35065] 
//
[0.x.35066] 
[0.x.35067] 
[0.x.35068] 
[0.x.35069] 
[0.x.35070] 
[0.x.35071] 
//
[0.x.35072] 
[0.x.35073] 
//
[0.x.35074] 
[0.x.35075] 
//
[0.x.35076] 
//
[0.x.35077] 
[0.x.35078] 
[0.x.35079] 
//
[0.x.35080] 
[0.x.35081] 
[0.x.35082] 
[0.x.35083] 
[0.x.35084] 
//
[0.x.35085] 
[0.x.35086] 
//
[0.x.35087] 
[0.x.35088] 
//
[0.x.35089] 
[0.x.35090] 
[0.x.35091] 
//
// In the introduction, we explained how to calculate the numerical velocity on the cell. We need the pressure solution values on each cell, coefficients of the Gram matrix and coefficients of the  [2.x.4169]  projection. We have already calculated the global solution, so we will extract the cell solution from the global solution. The coefficients of the Gram matrix have been calculated when we assembled the system matrix for the pressures. We will do the same way here. For the coefficients of the projection, we do matrix multiplication, i.e., the inverse of the Gram matrix times the matrix with  [2.x.4170]  as components. Then, we multiply all these coefficients and call them beta. The numerical velocity is the product of beta and the basis functions of the Raviart-Thomas space.
//
[0.x.35092] 
[0.x.35093] 
[0.x.35094] 
[0.x.35095] 
[0.x.35096] 
[0.x.35097] 
[0.x.35098] 
//
[0.x.35099] 
[0.x.35100] 
//
// The component of this  [2.x.4171]  is the integral of  [2.x.4172] .  [2.x.4173]  is the Gram matrix.
//
[0.x.35101] 
[0.x.35102] 
[0.x.35103] 
[0.x.35104] 
[0.x.35105] 
[0.x.35106] 
[0.x.35107] 
[0.x.35108] 
[0.x.35109] 
[0.x.35110] 
//
[0.x.35111] 
[0.x.35112] 
//
[0.x.35113] 
[0.x.35114] 
[0.x.35115] 
//
// To compute the matrix  [2.x.4174]  mentioned in the introduction, we then need to evaluate  [2.x.4175]  as explained in the introduction:
//
[0.x.35116] 
[0.x.35117] 
//
// Then we also need, again, to compute the matrix  [2.x.4176]  that is used to evaluate the weak discrete gradient. This is the exact same code as used in the assembly of the system matrix, so we just copy it from there:
//
[0.x.35118] 
[0.x.35119] 
[0.x.35120] 
[0.x.35121] 
[0.x.35122] 
[0.x.35123] 
[0.x.35124] 
[0.x.35125] 
[0.x.35126] 
[0.x.35127] 
//
[0.x.35128] 
[0.x.35129] 
[0.x.35130] 
[0.x.35131] 
//
[0.x.35132] 
[0.x.35133] 
[0.x.35134] 
[0.x.35135] 
//
[0.x.35136] 
[0.x.35137] 
[0.x.35138] 
//
[0.x.35139] 
[0.x.35140] 
[0.x.35141] 
[0.x.35142] 
[0.x.35143] 
[0.x.35144] 
[0.x.35145] 
[0.x.35146] 
//
[0.x.35147] 
[0.x.35148] 
[0.x.35149] 
[0.x.35150] 
[0.x.35151] 
[0.x.35152] 
[0.x.35153] 
//
// Finally, we need to extract the pressure unknowns that correspond to the current cell:
//
[0.x.35154] 
//
// We are now in a position to compute the local velocity unknowns (with respect to the Raviart-Thomas space we are projecting the term  [2.x.4177]  into):
//
[0.x.35155] 
[0.x.35156] 
[0.x.35157] 
[0.x.35158] 
[0.x.35159] 
[0.x.35160] 
//
// We compute Darcy velocity. This is same as cell_velocity but used to graph Darcy velocity.
//
[0.x.35161] 
[0.x.35162] 
[0.x.35163] 
[0.x.35164] 
[0.x.35165] 
[0.x.35166] 
[0.x.35167] 
[0.x.35168] 
//
//  [2.x.4178] 
//
// This part is to calculate the  [2.x.4179]  error of the pressure.  We define a vector that holds the norm of the error on each cell. Next, we use  [2.x.4180]  to compute the error in the  [2.x.4181]  norm on each cell. However, we really only care about the error in the interior component of the solution vector (we can't even evaluate the interface pressures at the quadrature points because these are all located in the interior of cells) and consequently have to use a weight function that ensures that the interface component of the solution variable is ignored. This is done by using the ComponentSelectFunction whose arguments indicate which component we want to select (component zero, i.e., the interior pressures) and how many components there are in total (two).
//
[0.x.35169] 
[0.x.35170] 
[0.x.35171] 
[0.x.35172] 
[0.x.35173] 
[0.x.35174] 
[0.x.35175] 
[0.x.35176] 
[0.x.35177] 
[0.x.35178] 
[0.x.35179] 
[0.x.35180] 
//
[0.x.35181] 
[0.x.35182] 
[0.x.35183] 
//
//  [2.x.4182] 
//
// In this function, we evaluate  [2.x.4183]  errors for the velocity on each cell, and  [2.x.4184]  errors for the flux on faces. The function relies on the `compute_postprocessed_velocity()` function having previous computed, which computes the velocity field based on the pressure solution that has previously been computed.
//
// We are going to evaluate velocities on each cell and calculate the difference between numerical and exact velocities.
//
[0.x.35184] 
[0.x.35185] 
[0.x.35186] 
[0.x.35187] 
[0.x.35188] 
//
[0.x.35189] 
[0.x.35190] 
[0.x.35191] 
[0.x.35192] 
[0.x.35193] 
//
[0.x.35194] 
[0.x.35195] 
[0.x.35196] 
[0.x.35197] 
[0.x.35198] 
[0.x.35199] 
//
[0.x.35200] 
[0.x.35201] 
[0.x.35202] 
//
[0.x.35203] 
[0.x.35204] 
//
[0.x.35205] 
//
[0.x.35206] 
//
[0.x.35207] 
[0.x.35208] 
//
// Having previously computed the postprocessed velocity, we here only have to extract the corresponding values on each cell and face and compare it to the exact values.
//
[0.x.35209] 
[0.x.35210] 
[0.x.35211] 
//
// First compute the  [2.x.4185]  error between the postprocessed velocity field and the exact one:
//
[0.x.35212] 
[0.x.35213] 
[0.x.35214] 
[0.x.35215] 
[0.x.35216] 
[0.x.35217] 
[0.x.35218] 
[0.x.35219] 
//
[0.x.35220] 
[0.x.35221] 
[0.x.35222] 
[0.x.35223] 
[0.x.35224] 
//
// For reconstructing the flux we need the size of cells and faces. Since fluxes are calculated on faces, we have the loop over all four faces of each cell. To calculate the face velocity, we extract values at the quadrature points from the `darcy_velocity` which we have computed previously. Then, we calculate the squared velocity error in normal direction. Finally, we calculate the  [2.x.4186]  flux error on the cell by appropriately scaling with face and cell areas and add it to the global error.
//
[0.x.35225] 
[0.x.35226] 
[0.x.35227] 
[0.x.35228] 
[0.x.35229] 
[0.x.35230] 
[0.x.35231] 
//
[0.x.35232] 
[0.x.35233] 
[0.x.35234] 
[0.x.35235] 
[0.x.35236] 
[0.x.35237] 
//
[0.x.35238] 
[0.x.35239] 
//
[0.x.35240] 
[0.x.35241] 
[0.x.35242] 
[0.x.35243] 
[0.x.35244] 
[0.x.35245] 
[0.x.35246] 
[0.x.35247] 
[0.x.35248] 
[0.x.35249] 
//
// After adding up errors over all cells and faces, we take the square root and get the  [2.x.4187]  errors of velocity and flux. These we output to screen.
//
[0.x.35250] 
[0.x.35251] 
[0.x.35252] 
//
[0.x.35253] 
[0.x.35254] 
[0.x.35255] 
//[2.x.4188] 
//
// We have two sets of results to output: the interior solution and the skeleton solution. We use  [2.x.4189]  to visualize interior results. The graphical output for the skeleton results is done by using the DataOutFaces class.
//
// In both of the output files, both the interior and the face variables are stored. For the interface output, the output file simply contains the interpolation of the interior pressures onto the faces, but because it is undefined which of the two interior pressure variables you get from the two adjacent cells, it is best to ignore the interior pressure in the interface output file. Conversely, for the cell interior output file, it is of course impossible to show any interface pressures  [2.x.4190] , because these are only available on interfaces and not cell interiors. Consequently, you will see them shown as an invalid value (such as an infinity).
//
// For the cell interior output, we also want to output the velocity variables. This is a bit tricky since it lives on the same mesh but uses a different DoFHandler object (the pressure variables live on the `dof_handler` object, the Darcy velocity on the `dof_handler_dgrt` object). Fortunately, there are variations of the  [2.x.4191]  function that allow specifying which DoFHandler a vector corresponds to, and consequently we can visualize the data from both DoFHandler objects within the same file.
//
[0.x.35256] 
[0.x.35257] 
[0.x.35258] 
[0.x.35259] 
[0.x.35260] 
//
// First attach the pressure solution to the DataOut object:
//
[0.x.35261] 
[0.x.35262] 
[0.x.35263] 
//
// Then do the same with the Darcy velocity field, and continue with writing everything out into a file.
//
[0.x.35264] 
[0.x.35265] 
[0.x.35266] 
[0.x.35267] 
[0.x.35268] 
[0.x.35269] 
[0.x.35270] 
[0.x.35271] 
[0.x.35272] 
//
[0.x.35273] 
[0.x.35274] 
[0.x.35275] 
[0.x.35276] 
//
[0.x.35277] 
[0.x.35278] 
[0.x.35279] 
[0.x.35280] 
[0.x.35281] 
[0.x.35282] 
[0.x.35283] 
[0.x.35284] 
[0.x.35285] 
//[2.x.4192] 
//
// This is the final function of the main class. It calls the other functions of our class.
//
[0.x.35286] 
[0.x.35287] 
[0.x.35288] 
[0.x.35289] 
[0.x.35290] 
[0.x.35291] 
[0.x.35292] 
[0.x.35293] 
[0.x.35294] 
[0.x.35295] 
[0.x.35296] 
[0.x.35297] 
[0.x.35298] 
[0.x.35299] 
//
[0.x.35300] 
//[2.x.4193] 
//
// This is the main function. We can change the dimension here to run in 3d.
//
[0.x.35301] 
[0.x.35302] 
[0.x.35303] 
[0.x.35304] 
[0.x.35305] 
[0.x.35306] 
[0.x.35307] 
[0.x.35308] 
[0.x.35309] 
[0.x.35310] 
[0.x.35311] 
[0.x.35312] 
[0.x.35313] 
[0.x.35314] 
[0.x.35315] 
[0.x.35316] 
[0.x.35317] 
[0.x.35318] 
[0.x.35319] 
[0.x.35320] 
[0.x.35321] 
[0.x.35322] 
[0.x.35323] 
[0.x.35324] 
[0.x.35325] 
[0.x.35326] 
[0.x.35327] 
[0.x.35328] 
[0.x.35329] 
[0.x.35330] 
[0.x.35331] 
[0.x.35332] 
//
[0.x.35333] 
[0.x.35334] 
[0.x.35335] 
[0.x.35336] 
[0.x.35337] 
[0.x.35338] 
[0.x.35339] 
[0.x.35340] 
[0.x.35341] 
[0.x.35342] 
[0.x.35343] 
[0.x.35344] 
[0.x.35345] 
[0.x.35346] 
[0.x.35347] 
[0.x.35348] 
//
[0.x.35349] 
[0.x.35350] 
[0.x.35351] 
//[2.x.4194] 
//
// Most of the include files we need for this program have already been discussed in previous programs, in particular in  [2.x.4195] .
//
[0.x.35352] 
[0.x.35353] 
//
[0.x.35354] 
[0.x.35355] 
[0.x.35356] 
[0.x.35357] 
//
[0.x.35358] 
[0.x.35359] 
//
[0.x.35360] 
[0.x.35361] 
[0.x.35362] 
//
[0.x.35363] 
[0.x.35364] 
//
[0.x.35365] 
[0.x.35366] 
[0.x.35367] 
[0.x.35368] 
[0.x.35369] 
[0.x.35370] 
//
[0.x.35371] 
[0.x.35372] 
//
[0.x.35373] 
[0.x.35374] 
//
// The following header provides the Tensor class that we use to represent the material properties.
//
[0.x.35375] 
//
// The following header is necessary for the HDF5 interface of deal.II.
//
[0.x.35376] 
//
// This header is required for the function  [2.x.4196]  that we use to evaluate the result of the simulation.
//
[0.x.35377] 
//
// We need these headers for the function  [2.x.4197]  that we use in the function  [2.x.4198] 
[0.x.35378] 
[0.x.35379] 
//
[0.x.35380] 
[0.x.35381] 
[0.x.35382] 
//[2.x.4199]  The following classes are used to store the parameters of the simulation.
//
//  [2.x.4200]  This class is used to define the force pulse on the left side of the structure:
//
[0.x.35383] 
[0.x.35384] 
[0.x.35385] 
[0.x.35386] 
[0.x.35387] 
//
[0.x.35388] 
[0.x.35389] 
//
[0.x.35390] 
//
// The variable `data` is the  [2.x.4201]  in which all the simulation results will be stored. Note that the variables  [2.x.4202] 
//[2.x.4203] 
//[2.x.4204]  and  [2.x.4205]  point to the same group of the HDF5 file. When a  [2.x.4206]  is copied, it will point to the same group of the HDF5 file.
//
[0.x.35391] 
//
// The simulation parameters are stored in `data` as HDF5 attributes. The following attributes are defined in the jupyter notebook, stored in `data` as HDF5 attributes and then read by the constructor.
//
[0.x.35392] 
[0.x.35393] 
[0.x.35394] 
[0.x.35395] 
[0.x.35396] 
[0.x.35397] 
//
[0.x.35398] 
//
// In this particular simulation the force has only a  [2.x.4207]  component,  [2.x.4208] .
//
[0.x.35399] 
[0.x.35400] 
//[2.x.4209]  This class is used to define the shape of the Perfectly Matches Layer (PML) to absorb waves traveling towards the boundary:
//
[0.x.35401] 
[0.x.35402] 
[0.x.35403] 
[0.x.35404] 
[0.x.35405] 
//
[0.x.35406] 
[0.x.35407] 
//
[0.x.35408] 
//[2.x.4210]  in which all the simulation results will be stored.
//
[0.x.35409] 
//
// The same as before, the following attributes are defined in the jupyter notebook, stored in `data` as HDF5 attributes and then read by the constructor.
//
[0.x.35410] 
[0.x.35411] 
[0.x.35412] 
[0.x.35413] 
[0.x.35414] 
[0.x.35415] 
[0.x.35416] 
[0.x.35417] 
[0.x.35418] 
[0.x.35419] 
[0.x.35420] 
//
//  [2.x.4211]  This class is used to define the mass density.
//
[0.x.35421] 
[0.x.35422] 
[0.x.35423] 
[0.x.35424] 
[0.x.35425] 
//
[0.x.35426] 
[0.x.35427] 
//
[0.x.35428] 
//[2.x.4212]  in which all the simulation results will be stored.
//
[0.x.35429] 
//
// The same as before, the following attributes are defined in the jupyter notebook, stored in `data` as HDF5 attributes and then read by the constructor.
//
[0.x.35430] 
[0.x.35431] 
[0.x.35432] 
[0.x.35433] 
[0.x.35434] 
[0.x.35435] 
[0.x.35436] 
[0.x.35437] 
[0.x.35438] 
[0.x.35439] 
//
//  [2.x.4213]  This class contains all the parameters that will be used in the simulation.
//
[0.x.35440] 
[0.x.35441] 
[0.x.35442] 
[0.x.35443] 
[0.x.35444] 
//[2.x.4214]  in which all the simulation results will be stored.
//
[0.x.35445] 
//
// The same as before, the following attributes are defined in the jupyter notebook, stored in `data` as HDF5 attributes and then read by the constructor.
//
[0.x.35446] 
[0.x.35447] 
[0.x.35448] 
[0.x.35449] 
[0.x.35450] 
[0.x.35451] 
[0.x.35452] 
[0.x.35453] 
[0.x.35454] 
[0.x.35455] 
[0.x.35456] 
[0.x.35457] 
[0.x.35458] 
[0.x.35459] 
[0.x.35460] 
[0.x.35461] 
//
[0.x.35462] 
[0.x.35463] 
[0.x.35464] 
//
//  [2.x.4215]  The calculation of the mass and stiffness matrices is very expensive. These matrices are the same for all the frequency steps. The right hand side vector is also the same for all the frequency steps. We use this class to store these objects and re-use them at each frequency step. Note that here we don't store the assembled mass and stiffness matrices and right hand sides, but instead the data for a single cell. `QuadratureCache` class is very similar to the `PointHistory` class that has been used in  [2.x.4216] .
//
[0.x.35465] 
[0.x.35466] 
[0.x.35467] 
[0.x.35468] 
[0.x.35469] 
//
[0.x.35470] 
[0.x.35471] 
//
[0.x.35472] 
//
// We store the mass and stiffness matrices in the variables mass_coefficient and stiffness_coefficient. We store as well the right_hand_side and JxW values which are going to be the same for all the frequency steps.
//
[0.x.35473] 
[0.x.35474] 
[0.x.35475] 
[0.x.35476] 
[0.x.35477] 
//
//  [2.x.4217] 
//
// This function returns the stiffness tensor of the material. For the sake of simplicity we consider the stiffness to be isotropic and homogeneous; only the density  [2.x.4218]  depends on the position. As we have previously shown in  [2.x.4219] , if the stiffness is isotropic and homogeneous, the stiffness coefficients  [2.x.4220]  can be expressed as a function of the two coefficients  [2.x.4221]  and  [2.x.4222] . The coefficient tensor reduces to [1.x.115]
//
[0.x.35478] 
[0.x.35479] 
[0.x.35480] 
[0.x.35481] 
[0.x.35482] 
[0.x.35483] 
[0.x.35484] 
[0.x.35485] 
[0.x.35486] 
[0.x.35487] 
[0.x.35488] 
[0.x.35489] 
[0.x.35490] 
[0.x.35491] 
[0.x.35492] 
//
//  [2.x.4223] 
//
// Next let's declare the main class of this program. Its structure is very similar to the  [2.x.4224]  tutorial program. The main differences are:
//
// - The sweep over the frequency values.
//
// - We save the stiffness and mass matrices in `quadrature_cache` and   use them for each frequency step.
//
// - We store the measured energy by the probe for each frequency step in the   HDF5 file.
//
[0.x.35493] 
[0.x.35494] 
[0.x.35495] 
[0.x.35496] 
[0.x.35497] 
[0.x.35498] 
//
[0.x.35499] 
[0.x.35500] 
[0.x.35501] 
[0.x.35502] 
[0.x.35503] 
[0.x.35504] 
[0.x.35505] 
[0.x.35506] 
//
//  This is called before every frequency step to set up a pristine state  for the cache variables.
//
[0.x.35507] 
//
// This function loops over the frequency vector and runs the simulation for each frequency step.
//
[0.x.35508] 
//
// The parameters are stored in this variable.
//
[0.x.35509] 
//
[0.x.35510] 
//
[0.x.35511] 
//
[0.x.35512] 
//
// We store the mass and stiffness matrices for each cell this vector.
//
[0.x.35513] 
//
[0.x.35514] 
[0.x.35515] 
//
[0.x.35516] 
[0.x.35517] 
//
[0.x.35518] 
//
[0.x.35519] 
[0.x.35520] 
[0.x.35521] 
//
// This vector contains the range of frequencies that we are going to simulate.
//
[0.x.35522] 
//
// This vector contains the coordinates  [2.x.4225]  of the points of the measurement probe.
//
[0.x.35523] 
//
// HDF5 datasets to store the frequency and `probe_positions` vectors.
//
[0.x.35524] 
[0.x.35525] 
//
// HDF5 dataset that stores the values of the energy measured by the probe.
//
[0.x.35526] 
//
[0.x.35527] 
[0.x.35528] 
[0.x.35529] 
//
//  [2.x.4226] 
//[2.x.4227] 
//
// The constructor reads all the parameters from the  [2.x.4228]  `data` using the  [2.x.4229]  function.
//
[0.x.35530] 
[0.x.35531] 
[0.x.35532] 
[0.x.35533] 
[0.x.35534] 
[0.x.35535] 
[0.x.35536] 
[0.x.35537] 
[0.x.35538] 
[0.x.35539] 
[0.x.35540] 
[0.x.35541] 
//
// This function defines the spatial shape of the force vector pulse which takes the form of a Gaussian function [1.x.116] where  [2.x.4230]  is the maximum amplitude that takes the force and  [2.x.4231]  and  [2.x.4232]  are the standard deviations for the  [2.x.4233]  and  [2.x.4234]  components. Note that the pulse has been cropped to  [2.x.4235]  and  [2.x.4236] .
//
[0.x.35542] 
[0.x.35543] 
[0.x.35544] 
[0.x.35545] 
[0.x.35546] 
[0.x.35547] 
[0.x.35548] 
[0.x.35549] 
[0.x.35550] 
[0.x.35551] 
[0.x.35552] 
[0.x.35553] 
[0.x.35554] 
[0.x.35555] 
[0.x.35556] 
[0.x.35557] 
[0.x.35558] 
[0.x.35559] 
[0.x.35560] 
[0.x.35561] 
[0.x.35562] 
[0.x.35563] 
[0.x.35564] 
[0.x.35565] 
[0.x.35566] 
//
//  [2.x.4237] 
//
// As before, the constructor reads all the parameters from the  [2.x.4238]  `data` using the  [2.x.4239]  function. As we have discussed, a quadratic turn-on of the PML has been defined in the jupyter notebook. It is possible to use a linear, cubic or another power degree by changing the parameter `pml_coeff_degree`. The parameters `pml_x` and `pml_y` can be used to turn on and off the `x` and `y` PMLs.
//
[0.x.35567] 
[0.x.35568] 
[0.x.35569] 
[0.x.35570] 
[0.x.35571] 
[0.x.35572] 
[0.x.35573] 
[0.x.35574] 
[0.x.35575] 
[0.x.35576] 
[0.x.35577] 
[0.x.35578] 
[0.x.35579] 
[0.x.35580] 
[0.x.35581] 
//
// The PML coefficient for the `x` component takes the form  [2.x.4240] 
[0.x.35582] 
[0.x.35583] 
[0.x.35584] 
[0.x.35585] 
[0.x.35586] 
[0.x.35587] 
//
[0.x.35588] 
[0.x.35589] 
[0.x.35590] 
[0.x.35591] 
[0.x.35592] 
[0.x.35593] 
[0.x.35594] 
[0.x.35595] 
[0.x.35596] 
[0.x.35597] 
//
[0.x.35598] 
[0.x.35599] 
[0.x.35600] 
[0.x.35601] 
[0.x.35602] 
[0.x.35603] 
[0.x.35604] 
[0.x.35605] 
[0.x.35606] 
[0.x.35607] 
//
[0.x.35608] 
[0.x.35609] 
[0.x.35610] 
//
//  [2.x.4241] 
//
// This class is used to define the mass density. As we have explaine before, a phononic superlattice cavity is formed by two [Distributed Reflector](https:en.wikipedia.org/wiki/Band_gap), mirrors and a  [2.x.4242]  cavity where  [2.x.4243]  is the acoustic wavelength. Acoustic DBRs are periodic structures where a set of bilayer stacks with contrasting physical properties (sound velocity index) is repeated  [2.x.4244]  times. The change of in the wave velocity is generated by alternating layers with different density.
//
[0.x.35611] 
[0.x.35612] 
[0.x.35613] 
[0.x.35614] 
[0.x.35615] 
[0.x.35616] 
[0.x.35617] 
[0.x.35618] 
[0.x.35619] 
[0.x.35620] 
[0.x.35621] 
[0.x.35622] 
[0.x.35623] 
[0.x.35624] 
//
// In order to increase the precision we use [subpixel smoothing](https:meep.readthedocs.io/en/latest/Subpixel_Smoothing/).
//
[0.x.35625] 
[0.x.35626] 
[0.x.35627] 
//
[0.x.35628] 
[0.x.35629] 
[0.x.35630] 
[0.x.35631] 
//
// The speed of sound is defined by [1.x.117] where  [2.x.4245]  is the effective elastic constant and  [2.x.4246]  the density. Here we consider the case in which the waveguide width is much smaller than the wavelength. In this case it can be shown that for the two dimensional case [1.x.118] and for the three dimensional case  [2.x.4247]  is equal to the Young's modulus. [1.x.119]
//
[0.x.35632] 
[0.x.35633] 
[0.x.35634] 
[0.x.35635] 
[0.x.35636] 
[0.x.35637] 
[0.x.35638] 
[0.x.35639] 
[0.x.35640] 
[0.x.35641] 
[0.x.35642] 
[0.x.35643] 
[0.x.35644] 
[0.x.35645] 
[0.x.35646] 
[0.x.35647] 
[0.x.35648] 
[0.x.35649] 
[0.x.35650] 
[0.x.35651] 
[0.x.35652] 
//
// The density  [2.x.4248]  takes the following form <img alt="Phononic superlattice cavity" src="https:www.dealii.org/images/steps/developer/ [2.x.4249] .04.svg" height="200" /> where the brown color represents material_a and the green color represents material_b.
//
[0.x.35653] 
[0.x.35654] 
[0.x.35655] 
[0.x.35656] 
[0.x.35657] 
[0.x.35658] 
[0.x.35659] 
[0.x.35660] 
[0.x.35661] 
[0.x.35662] 
[0.x.35663] 
[0.x.35664] 
[0.x.35665] 
[0.x.35666] 
[0.x.35667] 
[0.x.35668] 
[0.x.35669] 
//
// Here we define the [subpixel smoothing](https:meep.readthedocs.io/en/latest/Subpixel_Smoothing/) which improves the precision of the simulation.
//
[0.x.35670] 
[0.x.35671] 
[0.x.35672] 
[0.x.35673] 
[0.x.35674] 
[0.x.35675] 
[0.x.35676] 
[0.x.35677] 
[0.x.35678] 
[0.x.35679] 
[0.x.35680] 
[0.x.35681] 
[0.x.35682] 
[0.x.35683] 
[0.x.35684] 
[0.x.35685] 
[0.x.35686] 
[0.x.35687] 
//
// then the cavity
//
[0.x.35688] 
[0.x.35689] 
[0.x.35690] 
[0.x.35691] 
//
// the material_a layers
//
[0.x.35692] 
[0.x.35693] 
[0.x.35694] 
[0.x.35695] 
[0.x.35696] 
[0.x.35697] 
[0.x.35698] 
[0.x.35699] 
[0.x.35700] 
[0.x.35701] 
[0.x.35702] 
[0.x.35703] 
[0.x.35704] 
//
// the material_b layers
//
[0.x.35705] 
[0.x.35706] 
[0.x.35707] 
[0.x.35708] 
[0.x.35709] 
[0.x.35710] 
[0.x.35711] 
[0.x.35712] 
[0.x.35713] 
[0.x.35714] 
[0.x.35715] 
[0.x.35716] 
[0.x.35717] 
//
// and finally the default is material_a.
//
[0.x.35718] 
[0.x.35719] 
//
//  [2.x.4250] 
//
// The constructor reads all the parameters from the  [2.x.4251]  `data` using the  [2.x.4252]  function.
//
[0.x.35720] 
[0.x.35721] 
[0.x.35722] 
[0.x.35723] 
[0.x.35724] 
[0.x.35725] 
[0.x.35726] 
[0.x.35727] 
[0.x.35728] 
[0.x.35729] 
[0.x.35730] 
[0.x.35731] 
[0.x.35732] 
[0.x.35733] 
[0.x.35734] 
[0.x.35735] 
[0.x.35736] 
[0.x.35737] 
[0.x.35738] 
[0.x.35739] 
[0.x.35740] 
[0.x.35741] 
[0.x.35742] 
[0.x.35743] 
//
//  [2.x.4253] 
//
// We need to reserve enough space for the mass and stiffness matrices and the right hand side vector.
//
[0.x.35744] 
[0.x.35745] 
[0.x.35746] 
[0.x.35747] 
[0.x.35748] 
[0.x.35749] 
[0.x.35750] 
//
//  [2.x.4254] 
//[2.x.4255] 
//
// This is very similar to the constructor of  [2.x.4256] . In addition we create the HDF5 datasets `frequency_dataset`, `position_dataset` and `displacement`. Note the use of the `template` keyword for the creation of the HDF5 datasets. It is a C++ requirement to use the `template` keyword in order to treat `create_dataset` as a dependent template name.
//
[0.x.35751] 
[0.x.35752] 
[0.x.35753] 
[0.x.35754] 
[0.x.35755] 
[0.x.35756] 
[0.x.35757] 
[0.x.35758] 
[0.x.35759] 
[0.x.35760] 
[0.x.35761] 
[0.x.35762] 
[0.x.35763] 
[0.x.35764] 
[0.x.35765] 
[0.x.35766] 
[0.x.35767] 
[0.x.35768] 
[0.x.35769] 
[0.x.35770] 
[0.x.35771] 
[0.x.35772] 
[0.x.35773] 
[0.x.35774] 
[0.x.35775] 
[0.x.35776] 
[0.x.35777] 
[0.x.35778] 
[0.x.35779] 
[0.x.35780] 
[0.x.35781] 
//
//  [2.x.4257] 
//
// There is nothing new in this function, the only difference with  [2.x.4258]  is that we don't have to apply boundary conditions because we use the PMLs to truncate the domain.
//
[0.x.35782] 
[0.x.35783] 
[0.x.35784] 
[0.x.35785] 
//
[0.x.35786] 
//
[0.x.35787] 
[0.x.35788] 
//
[0.x.35789] 
[0.x.35790] 
[0.x.35791] 
//
[0.x.35792] 
//
[0.x.35793] 
[0.x.35794] 
[0.x.35795] 
//
[0.x.35796] 
//
[0.x.35797] 
//
[0.x.35798] 
[0.x.35799] 
[0.x.35800] 
[0.x.35801] 
[0.x.35802] 
//
[0.x.35803] 
[0.x.35804] 
[0.x.35805] 
[0.x.35806] 
[0.x.35807] 
//
//  [2.x.4259] 
//
// This function is also very similar to  [2.x.4260] , though there are notable differences. We assemble the system for each frequency/omega step. In the first step we set `calculate_quadrature_data = True` and we calculate the mass and stiffness matrices and the right hand side vector. In the subsequent steps we will use that data to accelerate the calculation.
//
[0.x.35808] 
[0.x.35809] 
[0.x.35810] 
[0.x.35811] 
[0.x.35812] 
//
[0.x.35813] 
[0.x.35814] 
[0.x.35815] 
[0.x.35816] 
[0.x.35817] 
[0.x.35818] 
//
[0.x.35819] 
[0.x.35820] 
//
[0.x.35821] 
//
// Here we store the value of the right hand side, rho and the PML.
//
[0.x.35822] 
[0.x.35823] 
[0.x.35824] 
[0.x.35825] 
//
// We calculate the stiffness tensor for the  [2.x.4261]  and  [2.x.4262]  that have been defined in the jupyter notebook. Note that contrary to  [2.x.4263]  the stiffness is constant among for the whole domain.
//
[0.x.35826] 
[0.x.35827] 
//
// We use the same method of  [2.x.4264]  for vector-valued problems.
//
[0.x.35828] 
//
[0.x.35829] 
[0.x.35830] 
[0.x.35831] 
[0.x.35832] 
[0.x.35833] 
//
// We have to calculate the values of the right hand side, rho and the PML only if we are going to calculate the mass and the stiffness matrices. Otherwise we can skip this calculation which considerably reduces the total calculation time.
//
[0.x.35834] 
[0.x.35835] 
[0.x.35836] 
//
[0.x.35837] 
[0.x.35838] 
[0.x.35839] 
[0.x.35840] 
[0.x.35841] 
[0.x.35842] 
[0.x.35843] 
//
// We have done this in  [2.x.4265] . Get a pointer to the quadrature cache data local to the present cell, and, as a defensive measure, make sure that this pointer is within the bounds of the global array:
//
[0.x.35844] 
[0.x.35845] 
[0.x.35846] 
[0.x.35847] 
[0.x.35848] 
[0.x.35849] 
[0.x.35850] 
[0.x.35851] 
//
//     The quadrature_data variable is used to store the mass and     stiffness matrices, the right hand side vector and the value     of `JxW`.
//
[0.x.35852] 
[0.x.35853] 
//
//     Below we declare the force vector and the parameters of the     PML  [2.x.4266]  and  [2.x.4267] .
//
[0.x.35854] 
[0.x.35855] 
[0.x.35856] 
//
//     The following block is calculated only in the first frequency     step.
//
[0.x.35857] 
[0.x.35858] 
//
//         Store the value of `JxW`.
//
[0.x.35859] 
//
[0.x.35860] 
[0.x.35861] 
//
//             Convert vectors to tensors and calculate xi
//
[0.x.35862] 
[0.x.35863] 
[0.x.35864] 
[0.x.35865] 
//
//         Here we calculate the  [2.x.4268]  and  [2.x.4269]          tensors.
//
[0.x.35866] 
[0.x.35867] 
[0.x.35868] 
[0.x.35869] 
[0.x.35870] 
[0.x.35871] 
[0.x.35872] 
[0.x.35873] 
[0.x.35874] 
[0.x.35875] 
[0.x.35876] 
[0.x.35877] 
[0.x.35878] 
[0.x.35879] 
//
[0.x.35880] 
[0.x.35881] 
[0.x.35882] 
[0.x.35883] 
[0.x.35884] 
[0.x.35885] 
//
[0.x.35886] 
[0.x.35887] 
[0.x.35888] 
[0.x.35889] 
[0.x.35890] 
[0.x.35891] 
//
//                 calculate the values of the mass matrix.
//
[0.x.35892] 
[0.x.35893] 
//
//                 Loop over the  [2.x.4270]  indices of the stiffness                 tensor.
//
[0.x.35894] 
[0.x.35895] 
[0.x.35896] 
[0.x.35897] 
[0.x.35898] 
[0.x.35899] 
//
//                           Here we calculate the stiffness matrix.                           Note that the stiffness matrix is not                           symmetric because of the PMLs. We use the                           gradient function (see the                           [documentation](https:www.dealii.org/current/doxygen/deal.II/group__vector__valued.html))                           which is a  [2.x.4271] .                           The matrix  [2.x.4272]  consists of entries                           [1.x.120]                           Note the position of the indices  [2.x.4273]  and                            [2.x.4274]  and the notation that we use in this                           tutorial:  [2.x.4275] . As the                           stiffness tensor is not symmetric, it is                           very easy to make a mistake.
//
[0.x.35900] 
[0.x.35901] 
[0.x.35902] 
[0.x.35903] 
[0.x.35904] 
//
//                 We save the value of the stiffness matrix in                 quadrature_data
//
[0.x.35905] 
[0.x.35906] 
[0.x.35907] 
//
//             and the value of the right hand side in             quadrature_data.
//
[0.x.35908] 
[0.x.35909] 
[0.x.35910] 
[0.x.35911] 
//
//     We loop again over the degrees of freedom of the cells to     calculate the system matrix. These loops are really quick     because we have already calculated the stiffness and mass     matrices, only the value of  [2.x.4276]  changes.
//
[0.x.35912] 
[0.x.35913] 
[0.x.35914] 
[0.x.35915] 
[0.x.35916] 
[0.x.35917] 
[0.x.35918] 
[0.x.35919] 
[0.x.35920] 
[0.x.35921] 
[0.x.35922] 
[0.x.35923] 
[0.x.35924] 
[0.x.35925] 
[0.x.35926] 
[0.x.35927] 
[0.x.35928] 
[0.x.35929] 
[0.x.35930] 
[0.x.35931] 
//
[0.x.35932] 
[0.x.35933] 
[0.x.35934] 
//[2.x.4277] 
//
// This is even more simple than in  [2.x.4278] . We use the parallel direct solver MUMPS which requires less options than an iterative solver. The drawback is that it does not scale very well. It is not straightforward to solve the Helmholtz equation with an iterative solver. The shifted Laplacian multigrid method is a well known approach to precondition this system, but this is beyond the scope of this tutorial.
//
[0.x.35935] 
[0.x.35936] 
[0.x.35937] 
[0.x.35938] 
[0.x.35939] 
[0.x.35940] 
//
[0.x.35941] 
[0.x.35942] 
[0.x.35943] 
//
[0.x.35944] 
[0.x.35945] 
[0.x.35946] 
[0.x.35947] 
[0.x.35948] 
//[2.x.4279] 
//
// We use this function to calculate the values of the position vector.
//
[0.x.35949] 
[0.x.35950] 
[0.x.35951] 
[0.x.35952] 
[0.x.35953] 
[0.x.35954] 
[0.x.35955] 
//
// Because of the way the operator + and
//
// - are overloaded to subtract two points, the following has to be done: `Point_b<dim> + (-Point_a<dim>)`
//
[0.x.35956] 
[0.x.35957] 
[0.x.35958] 
[0.x.35959] 
[0.x.35960] 
[0.x.35961] 
[0.x.35962] 
[0.x.35963] 
[0.x.35964] 
[0.x.35965] 
[0.x.35966] 
[0.x.35967] 
//[2.x.4280] 
//
// This function stores in the HDF5 file the measured energy by the probe.
//
[0.x.35968] 
[0.x.35969] 
[0.x.35970] 
[0.x.35971] 
[0.x.35972] 
//
// We store the displacement in the  [2.x.4281]  direction; the displacement in the  [2.x.4282]  direction is negligible.
//
[0.x.35973] 
//
// The vector coordinates contains the coordinates in the HDF5 file of the points of the probe that are located in locally owned cells. The vector displacement_data contains the value of the displacement at these points.
//
[0.x.35974] 
[0.x.35975] 
//
[0.x.35976] 
[0.x.35977] 
[0.x.35978] 
[0.x.35979] 
[0.x.35980] 
//
[0.x.35981] 
[0.x.35982] 
[0.x.35983] 
[0.x.35984] 
[0.x.35985] 
[0.x.35986] 
[0.x.35987] 
[0.x.35988] 
[0.x.35989] 
[0.x.35990] 
[0.x.35991] 
[0.x.35992] 
[0.x.35993] 
[0.x.35994] 
[0.x.35995] 
[0.x.35996] 
[0.x.35997] 
[0.x.35998] 
[0.x.35999] 
[0.x.36000] 
[0.x.36001] 
[0.x.36002] 
//
//   Then we can store the values of the displacement in the points of   the probe in `displacement_data`.
//
[0.x.36003] 
[0.x.36004] 
[0.x.36005] 
[0.x.36006] 
[0.x.36007] 
[0.x.36008] 
[0.x.36009] 
[0.x.36010] 
[0.x.36011] 
[0.x.36012] 
[0.x.36013] 
//
// We write the displacement data in the HDF5 file. The call  [2.x.4283]  is MPI collective which means that all the processes have to participate.
//
[0.x.36014] 
[0.x.36015] 
[0.x.36016] 
[0.x.36017] 
//
// Therefore even if the process has no data to write it has to participate in the collective call. For this we can use  [2.x.4284]  Note that we have to specify the data type, in this case  [2.x.4285] 
[0.x.36018] 
[0.x.36019] 
[0.x.36020] 
[0.x.36021] 
//
// If the variable `save_vtu_files` in the input file equals `True` then all the data will be saved as vtu. The procedure to write `vtu` files has been described in  [2.x.4286] .
//
[0.x.36022] 
[0.x.36023] 
[0.x.36024] 
[0.x.36025] 
[0.x.36026] 
[0.x.36027] 
//
[0.x.36028] 
[0.x.36029] 
[0.x.36030] 
[0.x.36031] 
[0.x.36032] 
[0.x.36033] 
[0.x.36034] 
[0.x.36035] 
[0.x.36036] 
//
[0.x.36037] 
[0.x.36038] 
[0.x.36039] 
[0.x.36040] 
[0.x.36041] 
//
[0.x.36042] 
[0.x.36043] 
[0.x.36044] 
[0.x.36045] 
[0.x.36046] 
[0.x.36047] 
[0.x.36048] 
[0.x.36049] 
[0.x.36050] 
[0.x.36051] 
[0.x.36052] 
[0.x.36053] 
[0.x.36054] 
[0.x.36055] 
//
//   And on the cells that we are not interested in, set the   respective value to a bogus value in order to make sure that if   we were somehow wrong about our assumption we would find out by   looking at the graphical output:
//
[0.x.36056] 
[0.x.36057] 
[0.x.36058] 
[0.x.36059] 
[0.x.36060] 
[0.x.36061] 
[0.x.36062] 
[0.x.36063] 
[0.x.36064] 
[0.x.36065] 
//
[0.x.36066] 
[0.x.36067] 
[0.x.36068] 
[0.x.36069] 
[0.x.36070] 
[0.x.36071] 
[0.x.36072] 
[0.x.36073] 
//
[0.x.36074] 
//
[0.x.36075] 
[0.x.36076] 
[0.x.36077] 
[0.x.36078] 
[0.x.36079] 
[0.x.36080] 
[0.x.36081] 
[0.x.36082] 
[0.x.36083] 
[0.x.36084] 
//
//  [2.x.4287] 
//
// This function writes the datasets that have not already been written.
//
[0.x.36085] 
[0.x.36086] 
[0.x.36087] 
//
// The vectors `frequency` and `position` are the same for all the processes. Therefore any of the processes can write the corresponding `datasets`. Because the call  [2.x.4288]  is MPI collective, the rest of the processes will have to call  [2.x.4289] 
[0.x.36088] 
[0.x.36089] 
[0.x.36090] 
[0.x.36091] 
[0.x.36092] 
[0.x.36093] 
[0.x.36094] 
[0.x.36095] 
[0.x.36096] 
[0.x.36097] 
[0.x.36098] 
//
//  [2.x.4290] 
//
// We use this function at the beginning of our computations to set up initial values of the cache variables. This function has been described in  [2.x.4291] . There are no differences with the function of  [2.x.4292] .
//
[0.x.36099] 
[0.x.36100] 
[0.x.36101] 
[0.x.36102] 
//
[0.x.36103] 
[0.x.36104] 
[0.x.36105] 
[0.x.36106] 
//
[0.x.36107] 
[0.x.36108] 
[0.x.36109] 
[0.x.36110] 
[0.x.36111] 
[0.x.36112] 
[0.x.36113] 
[0.x.36114] 
[0.x.36115] 
[0.x.36116] 
[0.x.36117] 
[0.x.36118] 
//
//  [2.x.4293] 
//
// For clarity we divide the function `run` of  [2.x.4294]  into the functions `run` and `frequency_sweep`. In the function `frequency_sweep` we place the iteration over the frequency vector.
//
[0.x.36119] 
[0.x.36120] 
[0.x.36121] 
[0.x.36122] 
[0.x.36123] 
[0.x.36124] 
[0.x.36125] 
[0.x.36126] 
[0.x.36127] 
[0.x.36128] 
//
[0.x.36129] 
[0.x.36130] 
[0.x.36131] 
[0.x.36132] 
[0.x.36133] 
[0.x.36134] 
[0.x.36135] 
[0.x.36136] 
//
[0.x.36137] 
[0.x.36138] 
//
//   Write the simulation parameters only once
//
[0.x.36139] 
[0.x.36140] 
[0.x.36141] 
[0.x.36142] 
[0.x.36143] 
//
// We calculate the frequency and omega values for this particular step.
//
[0.x.36144] 
[0.x.36145] 
[0.x.36146] 
[0.x.36147] 
[0.x.36148] 
[0.x.36149] 
[0.x.36150] 
//
// In the first frequency step we calculate the mass and stiffness matrices and the right hand side. In the subsequent frequency steps we will use those values. This improves considerably the calculation time.
//
[0.x.36151] 
[0.x.36152] 
[0.x.36153] 
//
[0.x.36154] 
[0.x.36155] 
//
[0.x.36156] 
[0.x.36157] 
[0.x.36158] 
[0.x.36159] 
[0.x.36160] 
//
//  [2.x.4295] 
//
// This function is very similar to the one in  [2.x.4296] .
//
[0.x.36161] 
[0.x.36162] 
[0.x.36163] 
[0.x.36164] 
[0.x.36165] 
[0.x.36166] 
[0.x.36167] 
[0.x.36168] 
//
[0.x.36169] 
[0.x.36170] 
[0.x.36171] 
[0.x.36172] 
[0.x.36173] 
[0.x.36174] 
[0.x.36175] 
[0.x.36176] 
[0.x.36177] 
[0.x.36178] 
[0.x.36179] 
[0.x.36180] 
[0.x.36181] 
[0.x.36182] 
[0.x.36183] 
[0.x.36184] 
[0.x.36185] 
[0.x.36186] 
[0.x.36187] 
[0.x.36188] 
[0.x.36189] 
[0.x.36190] 
[0.x.36191] 
[0.x.36192] 
[0.x.36193] 
[0.x.36194] 
[0.x.36195] 
//
[0.x.36196] 
//
[0.x.36197] 
//
[0.x.36198] 
//
[0.x.36199] 
//
[0.x.36200] 
[0.x.36201] 
[0.x.36202] 
//
//  [2.x.4297] 
//
// The main function is very similar to the one in  [2.x.4298] .
//
[0.x.36203] 
[0.x.36204] 
[0.x.36205] 
[0.x.36206] 
[0.x.36207] 
[0.x.36208] 
//
[0.x.36209] 
//
[0.x.36210] 
[0.x.36211] 
[0.x.36212] 
[0.x.36213] 
//
// Each of the simulations (displacement and calibration) is stored in a separate HDF5 group:
//
[0.x.36214] 
[0.x.36215] 
[0.x.36216] 
[0.x.36217] 
//
// For each of these two group names, we now create the group and put attributes into these groups. Specifically, these are:
//
// - The dimensions of the waveguide (in  [2.x.4299]  and  [2.x.4300]  directions)
//
// - The position of the probe (in  [2.x.4301]  and  [2.x.4302]  directions)
//
// - The number of points in the probe
//
// - The global refinement level
//
// - The cavity resonance frequency
//
// - The number of mirror pairs
//
// - The material properties
//
// - The force parameters
//
// - The PML parameters
//
// - The frequency parameters
//
[0.x.36218] 
//
[0.x.36219] 
[0.x.36220] 
[0.x.36221] 
[0.x.36222] 
[0.x.36223] 
[0.x.36224] 
[0.x.36225] 
[0.x.36226] 
[0.x.36227] 
//
[0.x.36228] 
[0.x.36229] 
[0.x.36230] 
//
[0.x.36231] 
[0.x.36232] 
[0.x.36233] 
[0.x.36234] 
//
[0.x.36235] 
[0.x.36236] 
[0.x.36237] 
[0.x.36238] 
[0.x.36239] 
[0.x.36240] 
[0.x.36241] 
[0.x.36242] 
[0.x.36243] 
[0.x.36244] 
//
[0.x.36245] 
[0.x.36246] 
[0.x.36247] 
[0.x.36248] 
[0.x.36249] 
[0.x.36250] 
[0.x.36251] 
//
[0.x.36252] 
[0.x.36253] 
[0.x.36254] 
[0.x.36255] 
[0.x.36256] 
[0.x.36257] 
//
[0.x.36258] 
[0.x.36259] 
[0.x.36260] 
[0.x.36261] 
[0.x.36262] 
[0.x.36263] 
[0.x.36264] 
[0.x.36265] 
[0.x.36266] 
[0.x.36267] 
[0.x.36268] 
//
[0.x.36269] 
[0.x.36270] 
[0.x.36271] 
[0.x.36272] 
[0.x.36273] 
[0.x.36274] 
//
[0.x.36275] 
[0.x.36276] 
//
[0.x.36277] 
//
// Displacement simulation. The parameters are read from the displacement HDF5 group and the results are saved in the same HDF5 group.
//
[0.x.36278] 
[0.x.36279] 
//
[0.x.36280] 
[0.x.36281] 
[0.x.36282] 
//
[0.x.36283] 
//
// Calibration simulation. The parameters are read from the calibration HDF5 group and the results are saved in the same HDF5 group.
//
[0.x.36284] 
[0.x.36285] 
//
[0.x.36286] 
[0.x.36287] 
[0.x.36288] 
[0.x.36289] 
[0.x.36290] 
[0.x.36291] 
[0.x.36292] 
[0.x.36293] 
[0.x.36294] 
[0.x.36295] 
[0.x.36296] 
[0.x.36297] 
[0.x.36298] 
[0.x.36299] 
[0.x.36300] 
//
[0.x.36301] 
[0.x.36302] 
[0.x.36303] 
[0.x.36304] 
[0.x.36305] 
[0.x.36306] 
[0.x.36307] 
[0.x.36308] 
[0.x.36309] 
[0.x.36310] 
[0.x.36311] 
[0.x.36312] 
[0.x.36313] 
[0.x.36314] 
//
[0.x.36315] 
[0.x.36316] 
[0.x.36317] 
[0.x.36318] 
[0.x.36319] 
[0.x.36320] 
[0.x.36321] 
[0.x.36322] 
[0.x.36323] 
[0.x.36324] 
[0.x.36325] 
[0.x.36326] 
[0.x.36327] 
[0.x.36328] 
[0.x.36329] 
[0.x.36330] 
[0.x.36331] 
[0.x.36332] 
[0.x.36333] 
[0.x.36334] 
//[2.x.4303] 
//
// Typical files needed for standard deal.II:
//
[0.x.36335] 
[0.x.36336] 
[0.x.36337] 
[0.x.36338] 
[0.x.36339] 
//
[0.x.36340] 
[0.x.36341] 
[0.x.36342] 
[0.x.36343] 
[0.x.36344] 
[0.x.36345] 
[0.x.36346] 
[0.x.36347] 
//
[0.x.36348] 
[0.x.36349] 
[0.x.36350] 
[0.x.36351] 
[0.x.36352] 
//
[0.x.36353] 
[0.x.36354] 
[0.x.36355] 
//
[0.x.36356] 
[0.x.36357] 
[0.x.36358] 
//
[0.x.36359] 
[0.x.36360] 
[0.x.36361] 
//
// Include all relevant multilevel files:
//
[0.x.36362] 
[0.x.36363] 
[0.x.36364] 
[0.x.36365] 
[0.x.36366] 
[0.x.36367] 
[0.x.36368] 
//
// C++:
//
[0.x.36369] 
[0.x.36370] 
[0.x.36371] 
[0.x.36372] 
//
// We will be using  [2.x.4304]  functionality for assembling matrices:
//
[0.x.36373] 
//[2.x.4305] 
//
// As always, we will be putting everything related to this program into a namespace of its own.
//
// Since we will be using the MeshWorker framework, the first step is to define the following structures needed by the assemble_cell() function used by  [2.x.4306]  `ScratchData` contains an FEValues object which is needed for assembling a cell's local contribution, while `CopyData` contains the output from a cell's local contribution and necessary information to copy that to the global system. (Their purpose is also explained in the documentation of the WorkStream class.)
//
[0.x.36374] 
[0.x.36375] 
[0.x.36376] 
//
[0.x.36377] 
[0.x.36378] 
[0.x.36379] 
[0.x.36380] 
[0.x.36381] 
[0.x.36382] 
[0.x.36383] 
[0.x.36384] 
[0.x.36385] 
[0.x.36386] 
//
[0.x.36387] 
[0.x.36388] 
[0.x.36389] 
[0.x.36390] 
[0.x.36391] 
[0.x.36392] 
//
[0.x.36393] 
[0.x.36394] 
//
[0.x.36395] 
[0.x.36396] 
[0.x.36397] 
//
[0.x.36398] 
[0.x.36399] 
//
[0.x.36400] 
[0.x.36401] 
[0.x.36402] 
[0.x.36403] 
//
//  [2.x.4307] 
//
// The second step is to define the classes that deal with run-time parameters to be read from an input file.
//
// We will use ParameterHandler to pass in parameters at runtime. The structure `Settings` parses and stores the parameters to be queried throughout the program.
//
[0.x.36404] 
[0.x.36405] 
[0.x.36406] 
[0.x.36407] 
[0.x.36408] 
[0.x.36409] 
[0.x.36410] 
[0.x.36411] 
[0.x.36412] 
//
[0.x.36413] 
//
[0.x.36414] 
[0.x.36415] 
[0.x.36416] 
[0.x.36417] 
[0.x.36418] 
[0.x.36419] 
[0.x.36420] 
[0.x.36421] 
//
[0.x.36422] 
[0.x.36423] 
//
//    /* First declare the parameters...  [2.x.4308] 
[0.x.36424] 
//
[0.x.36425] 
[0.x.36426] 
[0.x.36427] 
[0.x.36428] 
//
[0.x.36429] 
[0.x.36430] 
[0.x.36431] 
[0.x.36432] 
[0.x.36433] 
[0.x.36434] 
[0.x.36435] 
[0.x.36436] 
[0.x.36437] 
[0.x.36438] 
[0.x.36439] 
[0.x.36440] 
[0.x.36441] 
[0.x.36442] 
[0.x.36443] 
[0.x.36444] 
[0.x.36445] 
[0.x.36446] 
[0.x.36447] 
[0.x.36448] 
[0.x.36449] 
[0.x.36450] 
[0.x.36451] 
[0.x.36452] 
[0.x.36453] 
//
//    /* ...and then try to read their values from the input file:  [2.x.4309] 
[0.x.36454] 
[0.x.36455] 
[0.x.36456] 
[0.x.36457] 
[0.x.36458] 
[0.x.36459] 
//
[0.x.36460] 
//
[0.x.36461] 
[0.x.36462] 
[0.x.36463] 
[0.x.36464] 
//
[0.x.36465] 
[0.x.36466] 
[0.x.36467] 
[0.x.36468] 
[0.x.36469] 
[0.x.36470] 
[0.x.36471] 
[0.x.36472] 
[0.x.36473] 
[0.x.36474] 
[0.x.36475] 
[0.x.36476] 
[0.x.36477] 
//
[0.x.36478] 
[0.x.36479] 
[0.x.36480] 
//[2.x.4310] 
//
// The ordering in which cells and degrees of freedom are traversed will play a role in the speed of convergence for multiplicative methods. Here we define functions which return a specific ordering of cells to be used by the block smoothers.
//
// For each type of cell ordering, we define a function for the active mesh and one for a level mesh (i.e., for the cells at one level of a multigrid hierarchy). While the only reordering necessary for solving the system will be on the level meshes, we include the active reordering for visualization purposes in output_results().
//
// For the two downstream ordering functions, we first create an array with all of the relevant cells that we then sort in downstream direction using a "comparator" object. The output of the functions is then simply an array of the indices of the cells in the just computed order.
//
[0.x.36481] 
[0.x.36482] 
[0.x.36483] 
[0.x.36484] 
[0.x.36485] 
[0.x.36486] 
[0.x.36487] 
[0.x.36488] 
[0.x.36489] 
[0.x.36490] 
//
[0.x.36491] 
[0.x.36492] 
[0.x.36493] 
[0.x.36494] 
//
[0.x.36495] 
[0.x.36496] 
//
[0.x.36497] 
[0.x.36498] 
//
[0.x.36499] 
[0.x.36500] 
//
[0.x.36501] 
[0.x.36502] 
[0.x.36503] 
[0.x.36504] 
[0.x.36505] 
[0.x.36506] 
[0.x.36507] 
[0.x.36508] 
[0.x.36509] 
//
[0.x.36510] 
[0.x.36511] 
[0.x.36512] 
[0.x.36513] 
//
[0.x.36514] 
[0.x.36515] 
//
[0.x.36516] 
[0.x.36517] 
//
[0.x.36518] 
[0.x.36519] 
//
// The functions that produce a random ordering are similar in spirit in that they first put information about all cells into an array. But then, instead of sorting them, they shuffle the elements randomly using the facilities C++ offers to generate random numbers. The way this is done is by iterating over all elements of the array, drawing a random number for another element before that, and then exchanging these elements. The result is a random shuffle of the elements of the array.
//
[0.x.36520] 
[0.x.36521] 
[0.x.36522] 
[0.x.36523] 
[0.x.36524] 
[0.x.36525] 
[0.x.36526] 
[0.x.36527] 
[0.x.36528] 
//
[0.x.36529] 
[0.x.36530] 
[0.x.36531] 
[0.x.36532] 
//
[0.x.36533] 
[0.x.36534] 
//
[0.x.36535] 
[0.x.36536] 
[0.x.36537] 
[0.x.36538] 
[0.x.36539] 
[0.x.36540] 
[0.x.36541] 
[0.x.36542] 
//
[0.x.36543] 
[0.x.36544] 
[0.x.36545] 
[0.x.36546] 
//
[0.x.36547] 
[0.x.36548] 
//[2.x.4311] 
//
// The problem solved in this tutorial is an adaptation of Ex. 3.1.3 found on pg. 118 of [1.x.121]. The main difference being that we add a hole in the center of our domain with zero Dirichlet boundary conditions.
//
// For a complete description, we need classes that implement the zero right-hand side first (we could of course have just used  [2.x.4312] 
[0.x.36549] 
[0.x.36550] 
[0.x.36551] 
[0.x.36552] 
[0.x.36553] 
[0.x.36554] 
//
[0.x.36555] 
[0.x.36556] 
[0.x.36557] 
[0.x.36558] 
//
[0.x.36559] 
[0.x.36560] 
[0.x.36561] 
[0.x.36562] 
[0.x.36563] 
[0.x.36564] 
//
[0.x.36565] 
[0.x.36566] 
//
[0.x.36567] 
[0.x.36568] 
[0.x.36569] 
[0.x.36570] 
[0.x.36571] 
[0.x.36572] 
[0.x.36573] 
//
[0.x.36574] 
[0.x.36575] 
[0.x.36576] 
//
// We also have Dirichlet boundary conditions. On a connected portion of the outer, square boundary we set the value to 1, and we set the value to 0 everywhere else (including the inner, circular boundary):
//
[0.x.36577] 
[0.x.36578] 
[0.x.36579] 
[0.x.36580] 
[0.x.36581] 
[0.x.36582] 
//
[0.x.36583] 
[0.x.36584] 
[0.x.36585] 
[0.x.36586] 
//
[0.x.36587] 
[0.x.36588] 
[0.x.36589] 
[0.x.36590] 
[0.x.36591] 
[0.x.36592] 
//
// Set boundary to 1 if  [2.x.4313] , or if  [2.x.4314]  and  [2.x.4315] .
//
[0.x.36593] 
[0.x.36594] 
[0.x.36595] 
[0.x.36596] 
[0.x.36597] 
[0.x.36598] 
[0.x.36599] 
[0.x.36600] 
[0.x.36601] 
[0.x.36602] 
//
[0.x.36603] 
[0.x.36604] 
[0.x.36605] 
[0.x.36606] 
[0.x.36607] 
[0.x.36608] 
[0.x.36609] 
//
[0.x.36610] 
[0.x.36611] 
[0.x.36612] 
//
//  [2.x.4316] 
//
// The streamline diffusion method has a stabilization constant that we need to be able to compute. The choice of how this parameter is computed is taken from [1.x.122].
//
[0.x.36613] 
[0.x.36614] 
[0.x.36615] 
[0.x.36616] 
[0.x.36617] 
[0.x.36618] 
[0.x.36619] 
[0.x.36620] 
[0.x.36621] 
//
[0.x.36622] 
[0.x.36623] 
//[2.x.4317] 
//
// This is the main class of the program, and should look very similar to  [2.x.4318] . The major difference is that, since we are defining our multigrid smoother at runtime, we choose to define a function `create_smoother()` and a class object `mg_smoother` which is a  [2.x.4319]  to a smoother that is derived from MGSmoother. Note that for smoothers derived from RelaxationBlock, we must include a `smoother_data` object for each level. This will contain information about the cell ordering and the method of inverting cell matrices.
//
[0.x.36624] 
[0.x.36625] 
[0.x.36626] 
[0.x.36627] 
[0.x.36628] 
[0.x.36629] 
//
[0.x.36630] 
[0.x.36631] 
//
[0.x.36632] 
[0.x.36633] 
[0.x.36634] 
[0.x.36635] 
[0.x.36636] 
//
[0.x.36637] 
//
[0.x.36638] 
[0.x.36639] 
[0.x.36640] 
//
[0.x.36641] 
[0.x.36642] 
//
[0.x.36643] 
[0.x.36644] 
//
[0.x.36645] 
//
[0.x.36646] 
[0.x.36647] 
//
[0.x.36648] 
[0.x.36649] 
//
[0.x.36650] 
[0.x.36651] 
//
[0.x.36652] 
[0.x.36653] 
[0.x.36654] 
//
[0.x.36655] 
[0.x.36656] 
[0.x.36657] 
//
[0.x.36658] 
//
[0.x.36659] 
[0.x.36660] 
[0.x.36661] 
[0.x.36662] 
//
[0.x.36663] 
//
[0.x.36664] 
//
[0.x.36665] 
[0.x.36666] 
//
[0.x.36667] 
[0.x.36668] 
[0.x.36669] 
[0.x.36670] 
[0.x.36671] 
[0.x.36672] 
[0.x.36673] 
[0.x.36674] 
[0.x.36675] 
[0.x.36676] 
[0.x.36677] 
[0.x.36678] 
[0.x.36679] 
[0.x.36680] 
//[2.x.4320] 
//
// Here we first set up the DoFHandler, AffineConstraints, and SparsityPattern objects for both active and multigrid level meshes.
//
// We could renumber the active DoFs with the DoFRenumbering class, but the smoothers only act on multigrid levels and as such, this would not matter for the computations. Instead, we will renumber the DoFs on each multigrid level below.
//
[0.x.36681] 
[0.x.36682] 
[0.x.36683] 
[0.x.36684] 
//
[0.x.36685] 
//
[0.x.36686] 
[0.x.36687] 
//
[0.x.36688] 
[0.x.36689] 
//
[0.x.36690] 
[0.x.36691] 
[0.x.36692] 
[0.x.36693] 
[0.x.36694] 
//
[0.x.36695] 
[0.x.36696] 
[0.x.36697] 
[0.x.36698] 
//
//                                    /*keep_constrained_dofs =  [2.x.4321]  false);
//
[0.x.36699] 
[0.x.36700] 
//
[0.x.36701] 
//
// Having enumerated the global degrees of freedom as well as (in the last line above) the level degrees of freedom, let us renumber the level degrees of freedom to get a better smoother as explained in the introduction.  The first block below renumbers DoFs on each level in downstream or upstream direction if needed. This is only necessary for point smoothers (SOR and Jacobi) as the block smoothers operate on cells (see `create_smoother()`). The blocks below then also implement random numbering.
//
[0.x.36702] 
[0.x.36703] 
[0.x.36704] 
[0.x.36705] 
[0.x.36706] 
[0.x.36707] 
[0.x.36708] 
[0.x.36709] 
[0.x.36710] 
[0.x.36711] 
[0.x.36712] 
[0.x.36713] 
[0.x.36714] 
//
[0.x.36715] 
[0.x.36716] 
[0.x.36717] 
[0.x.36718] 
//
//                                         /*dof_wise_renumbering =  [2.x.4322]  true);
//
[0.x.36719] 
[0.x.36720] 
[0.x.36721] 
[0.x.36722] 
[0.x.36723] 
[0.x.36724] 
[0.x.36725] 
[0.x.36726] 
[0.x.36727] 
[0.x.36728] 
//
// The rest of the function just sets up data structures. The last lines of the code below is unlike the other GMG tutorials, as it sets up both the interface in and out matrices. We need this since our problem is non-symmetric.
//
[0.x.36729] 
[0.x.36730] 
//
[0.x.36731] 
//
[0.x.36732] 
[0.x.36733] 
[0.x.36734] 
[0.x.36735] 
[0.x.36736] 
[0.x.36737] 
[0.x.36738] 
[0.x.36739] 
//
[0.x.36740] 
[0.x.36741] 
[0.x.36742] 
[0.x.36743] 
[0.x.36744] 
[0.x.36745] 
[0.x.36746] 
[0.x.36747] 
[0.x.36748] 
[0.x.36749] 
[0.x.36750] 
[0.x.36751] 
[0.x.36752] 
[0.x.36753] 
[0.x.36754] 
[0.x.36755] 
[0.x.36756] 
//
[0.x.36757] 
[0.x.36758] 
[0.x.36759] 
[0.x.36760] 
[0.x.36761] 
//[2.x.4323] 
//
// Here we define the assembly of the linear system on each cell to be used by the mesh_loop() function below. This one function assembles the cell matrix for either an active or a level cell (whatever it is passed as its first argument), and only assembles a right-hand side if called with an active cell.
//
[0.x.36762] 
[0.x.36763] 
[0.x.36764] 
[0.x.36765] 
[0.x.36766] 
[0.x.36767] 
[0.x.36768] 
//
[0.x.36769] 
[0.x.36770] 
[0.x.36771] 
[0.x.36772] 
//
[0.x.36773] 
[0.x.36774] 
//
[0.x.36775] 
[0.x.36776] 
//
[0.x.36777] 
[0.x.36778] 
//
[0.x.36779] 
//
[0.x.36780] 
[0.x.36781] 
//
[0.x.36782] 
[0.x.36783] 
//
// If we are using streamline diffusion we must add its contribution to both the cell matrix and the cell right-hand side. If we are not using streamline diffusion, setting  [2.x.4324]  negates this contribution below and we are left with the standard, Galerkin finite element assembly.
//
[0.x.36784] 
[0.x.36785] 
[0.x.36786] 
[0.x.36787] 
[0.x.36788] 
[0.x.36789] 
//
[0.x.36790] 
[0.x.36791] 
[0.x.36792] 
[0.x.36793] 
[0.x.36794] 
//
//     The assembly of the local matrix has two parts. First     the Galerkin contribution:
//
[0.x.36795] 
[0.x.36796] 
[0.x.36797] 
[0.x.36798] 
[0.x.36799] 
[0.x.36800] 
[0.x.36801] 
[0.x.36802] 
[0.x.36803] 
//
//       and then the streamline diffusion contribution:
//
[0.x.36804] 
[0.x.36805] 
[0.x.36806] 
[0.x.36807] 
[0.x.36808] 
[0.x.36809] 
[0.x.36810] 
[0.x.36811] 
[0.x.36812] 
[0.x.36813] 
[0.x.36814] 
[0.x.36815] 
[0.x.36816] 
[0.x.36817] 
//
//     The same applies to the right hand side. First the     Galerkin contribution:
//
[0.x.36818] 
[0.x.36819] 
[0.x.36820] 
//
//       and then the streamline diffusion contribution:
//
[0.x.36821] 
[0.x.36822] 
[0.x.36823] 
[0.x.36824] 
[0.x.36825] 
[0.x.36826] 
//[2.x.4325] 
//
// Here we employ  [2.x.4326]  to go over cells and assemble the system_matrix, system_rhs, and all mg_matrices for us.
//
[0.x.36827] 
[0.x.36828] 
[0.x.36829] 
[0.x.36830] 
[0.x.36831] 
[0.x.36832] 
[0.x.36833] 
[0.x.36834] 
[0.x.36835] 
//
[0.x.36836] 
[0.x.36837] 
[0.x.36838] 
[0.x.36839] 
[0.x.36840] 
[0.x.36841] 
[0.x.36842] 
//
[0.x.36843] 
[0.x.36844] 
[0.x.36845] 
[0.x.36846] 
[0.x.36847] 
[0.x.36848] 
[0.x.36849] 
//
// Unlike the constraints for the active level, we choose to create constraint objects for each multigrid level local to this function since they are never needed elsewhere in the program.
//
[0.x.36850] 
[0.x.36851] 
[0.x.36852] 
[0.x.36853] 
[0.x.36854] 
[0.x.36855] 
[0.x.36856] 
[0.x.36857] 
[0.x.36858] 
[0.x.36859] 
[0.x.36860] 
[0.x.36861] 
[0.x.36862] 
[0.x.36863] 
[0.x.36864] 
//
[0.x.36865] 
[0.x.36866] 
[0.x.36867] 
[0.x.36868] 
[0.x.36869] 
[0.x.36870] 
//
[0.x.36871] 
[0.x.36872] 
[0.x.36873] 
[0.x.36874] 
[0.x.36875] 
//
// If  [2.x.4327]  is an `interface_out` dof pair, then  [2.x.4328]  is an `interface_in` dof pair. Note: For `interface_in`, we load the transpose of the interface entries, i.e., the entry for dof pair  [2.x.4329]  is stored in `interface_in(i,j)`. This is an optimization for the symmetric case which allows only one matrix to be used when setting the edge_matrices in solve(). Here, however, since our problem is non-symmetric, we must store both `interface_in` and `interface_out` matrices.
//
[0.x.36876] 
[0.x.36877] 
[0.x.36878] 
[0.x.36879] 
[0.x.36880] 
[0.x.36881] 
[0.x.36882] 
[0.x.36883] 
[0.x.36884] 
[0.x.36885] 
[0.x.36886] 
[0.x.36887] 
[0.x.36888] 
[0.x.36889] 
[0.x.36890] 
[0.x.36891] 
[0.x.36892] 
//
[0.x.36893] 
[0.x.36894] 
[0.x.36895] 
[0.x.36896] 
[0.x.36897] 
[0.x.36898] 
[0.x.36899] 
[0.x.36900] 
//[2.x.4330] 
//
// Next, we set up the smoother based on the settings in the `.prm` file. The two options that are of significance is the number of pre- and post-smoothing steps on each level of the multigrid v-cycle and the relaxation parameter.
//
// Since multiplicative methods tend to be more powerful than additive method, fewer smoothing steps are required to see convergence independent of mesh size. The same holds for block smoothers over point smoothers. This is reflected in the choice for the number of smoothing steps for each type of smoother below.
//
// The relaxation parameter for point smoothers is chosen based on trial and error, and reflects values necessary to keep the iteration counts in the GMRES solve constant (or as close as possible) as we refine the mesh. The two values given for both "Jacobi" and "SOR" in the `.prm` files are for degree 1 and degree 3 finite elements. If the user wants to change to another degree, they may need to adjust these numbers. For block smoothers, this parameter has a more straightforward interpretation, namely that for additive methods in 2D, a DoF can have a repeated contribution from up to 4 cells, therefore we must relax these methods by 0.25 to compensate. This is not an issue for multiplicative methods as each cell's inverse application carries new information to all its DoFs.
//
// Finally, as mentioned above, the point smoothers only operate on DoFs, and the block smoothers on cells, so only the block smoothers need to be given information regarding cell orderings. DoF ordering for point smoothers has already been taken care of in `setup_system()`.
//
[0.x.36901] 
[0.x.36902] 
[0.x.36903] 
[0.x.36904] 
[0.x.36905] 
[0.x.36906] 
//
[0.x.36907] 
[0.x.36908] 
[0.x.36909] 
[0.x.36910] 
[0.x.36911] 
[0.x.36912] 
[0.x.36913] 
[0.x.36914] 
[0.x.36915] 
[0.x.36916] 
[0.x.36917] 
[0.x.36918] 
[0.x.36919] 
[0.x.36920] 
[0.x.36921] 
[0.x.36922] 
[0.x.36923] 
[0.x.36924] 
[0.x.36925] 
[0.x.36926] 
[0.x.36927] 
[0.x.36928] 
[0.x.36929] 
[0.x.36930] 
[0.x.36931] 
[0.x.36932] 
[0.x.36933] 
//
[0.x.36934] 
[0.x.36935] 
[0.x.36936] 
[0.x.36937] 
[0.x.36938] 
//
[0.x.36939] 
[0.x.36940] 
[0.x.36941] 
//
[0.x.36942] 
[0.x.36943] 
[0.x.36944] 
[0.x.36945] 
[0.x.36946] 
[0.x.36947] 
[0.x.36948] 
[0.x.36949] 
[0.x.36950] 
//
[0.x.36951] 
[0.x.36952] 
[0.x.36953] 
[0.x.36954] 
[0.x.36955] 
[0.x.36956] 
//
[0.x.36957] 
[0.x.36958] 
[0.x.36959] 
[0.x.36960] 
//
[0.x.36961] 
[0.x.36962] 
//
[0.x.36963] 
[0.x.36964] 
[0.x.36965] 
[0.x.36966] 
//
[0.x.36967] 
[0.x.36968] 
[0.x.36969] 
//
[0.x.36970] 
[0.x.36971] 
[0.x.36972] 
[0.x.36973] 
[0.x.36974] 
[0.x.36975] 
[0.x.36976] 
[0.x.36977] 
[0.x.36978] 
[0.x.36979] 
[0.x.36980] 
[0.x.36981] 
[0.x.36982] 
[0.x.36983] 
[0.x.36984] 
[0.x.36985] 
[0.x.36986] 
[0.x.36987] 
[0.x.36988] 
[0.x.36989] 
[0.x.36990] 
[0.x.36991] 
[0.x.36992] 
[0.x.36993] 
[0.x.36994] 
[0.x.36995] 
//[2.x.4331] 
//
// Before we can solve the system, we must first set up the multigrid preconditioner. This requires the setup of the transfer between levels, the coarse matrix solver, and the smoother. This setup follows almost identically to  [2.x.4332] , the main difference being the various smoothers defined above and the fact that we need different interface edge matrices for in and out since our problem is non-symmetric. (In reality, for this tutorial these interface matrices are empty since we are only using global refinement, and thus have no refinement edges. However, we have still included both here since if one made the simple switch to an adaptively refined method, the program would still run correctly.)
//
// The last thing to note is that since our problem is non-symmetric, we must use an appropriate Krylov subspace method. We choose here to use GMRES since it offers the guarantee of residual reduction in each iteration. The major disavantage of GMRES is that, for each iteration, the number of stored temporary vectors increases by one, and one also needs to compute a scalar product with all previously stored vectors. This is rather expensive. This requirement is relaxed by using the restarted GMRES method which puts a cap on the number of vectors we are required to store at any one time (here we restart after 50 temporary vectors, or 48 iterations). This then has the disadvantage that we lose information we have gathered throughout the iteration and therefore we could see slower convergence. As a consequence, where to restart is a question of balancing memory consumption, CPU effort, and convergence speed. However, the goal of this tutorial is to have very low iteration counts by using a powerful GMG preconditioner, so we have picked the restart length such that all of the results shown below converge prior to restart happening, and thus we have a standard GMRES method. If the user is interested, another suitable method offered in deal.II would be BiCGStab.
//
[0.x.36996] 
[0.x.36997] 
[0.x.36998] 
[0.x.36999] 
[0.x.37000] 
[0.x.37001] 
[0.x.37002] 
//
[0.x.37003] 
[0.x.37004] 
[0.x.37005] 
//
[0.x.37006] 
[0.x.37007] 
[0.x.37008] 
[0.x.37009] 
//
[0.x.37010] 
//
[0.x.37011] 
[0.x.37012] 
[0.x.37013] 
//
[0.x.37014] 
[0.x.37015] 
[0.x.37016] 
//
[0.x.37017] 
[0.x.37018] 
[0.x.37019] 
//
[0.x.37020] 
[0.x.37021] 
[0.x.37022] 
[0.x.37023] 
//
[0.x.37024] 
[0.x.37025] 
[0.x.37026] 
[0.x.37027] 
//
[0.x.37028] 
[0.x.37029] 
[0.x.37030] 
//
[0.x.37031] 
//
[0.x.37032] 
[0.x.37033] 
//[2.x.4333] 
//
// The final function of interest generates graphical output. Here we output the solution and cell ordering in a .vtu format.
//
// At the top of the function, we generate an index for each cell to visualize the ordering used by the smoothers. Note that we do this only for the active cells instead of the levels, where the smoothers are actually used. For the point smoothers we renumber DoFs instead of cells, so this is only an approximation of what happens in reality. Finally, the random ordering is not the random ordering we actually use (see `create_smoother()` for that).
//
// The (integer) ordering of cells is then copied into a (floating point) vector for graphical output.
//
[0.x.37034] 
[0.x.37035] 
[0.x.37036] 
[0.x.37037] 
[0.x.37038] 
[0.x.37039] 
[0.x.37040] 
[0.x.37041] 
[0.x.37042] 
[0.x.37043] 
[0.x.37044] 
[0.x.37045] 
[0.x.37046] 
//
[0.x.37047] 
[0.x.37048] 
[0.x.37049] 
[0.x.37050] 
[0.x.37051] 
//
[0.x.37052] 
[0.x.37053] 
[0.x.37054] 
//
[0.x.37055] 
[0.x.37056] 
[0.x.37057] 
[0.x.37058] 
[0.x.37059] 
//
[0.x.37060] 
[0.x.37061] 
[0.x.37062] 
[0.x.37063] 
//
[0.x.37064] 
[0.x.37065] 
[0.x.37066] 
//
// The remainder of the function is then straightforward, given previous tutorial programs:
//
[0.x.37067] 
[0.x.37068] 
[0.x.37069] 
[0.x.37070] 
[0.x.37071] 
//
[0.x.37072] 
[0.x.37073] 
[0.x.37074] 
[0.x.37075] 
[0.x.37076] 
//[2.x.4334] 
//
// As in most tutorials, this function creates/refines the mesh and calls the various functions defined above to set up, assemble, solve, and output the results.
//
// In cycle zero, we generate the mesh for the on the square  [2.x.4335]  with a hole of radius 3/10 units centered at the origin. For objects with `manifold_id` equal to one (namely, the faces adjacent to the hole), we assign a spherical manifold.
//
[0.x.37077] 
[0.x.37078] 
[0.x.37079] 
[0.x.37080] 
[0.x.37081] 
[0.x.37082] 
[0.x.37083] 
//
[0.x.37084] 
[0.x.37085] 
[0.x.37086] 
[0.x.37087] 
[0.x.37088] 
//
[0.x.37089] 
[0.x.37090] 
[0.x.37091] 
//
[0.x.37092] 
//
[0.x.37093] 
//
[0.x.37094] 
[0.x.37095] 
[0.x.37096] 
[0.x.37097] 
[0.x.37098] 
//
[0.x.37099] 
//
[0.x.37100] 
//
[0.x.37101] 
[0.x.37102] 
//
[0.x.37103] 
[0.x.37104] 
[0.x.37105] 
[0.x.37106] 
//[2.x.4336] 
//
// Finally, the main function is like most tutorials. The only interesting bit is that we require the user to pass a `.prm` file as a sole command line argument. If no parameter file is given, the program will output the contents of a sample parameter file with all default values to the screen that the user can then copy and paste into their own `.prm` file.
//
[0.x.37107] 
[0.x.37108] 
[0.x.37109] 
[0.x.37110] 
[0.x.37111] 
[0.x.37112] 
//
[0.x.37113] 
[0.x.37114] 
[0.x.37115] 
[0.x.37116] 
[0.x.37117] 
[0.x.37118] 
[0.x.37119] 
[0.x.37120] 
[0.x.37121] 
[0.x.37122] 
[0.x.37123] 
[0.x.37124] 
[0.x.37125] 
[0.x.37126] 
[0.x.37127] 
[0.x.37128] 
[0.x.37129] 
[0.x.37130] 
[0.x.37131] 
[0.x.37132] 
[0.x.37133] 
[0.x.37134] 
[0.x.37135] 
[0.x.37136] 
[0.x.37137] 
[0.x.37138] 
[0.x.37139] 
[0.x.37140] 
//
[0.x.37141] 
[0.x.37142] 
[0.x.37143] 
[0.x.37144] 
[0.x.37145] 
[0.x.37146] 
[0.x.37147] 
[0.x.37148] 
[0.x.37149] 
[0.x.37150] 
[0.x.37151] 
[0.x.37152] 
[0.x.37153] 
[0.x.37154] 
[0.x.37155] 
[0.x.37156] 
//
[0.x.37157] 
[0.x.37158] 
//[2.x.4337] 
//
// The include files for this tutorial are essentially the same as in  [2.x.4338] . Importantly, the TransfiniteInterpolationManifold class we will be using is provided by `deal.II/grid/manifold_lib.h`.
//
[0.x.37159] 
//
[0.x.37160] 
[0.x.37161] 
[0.x.37162] 
[0.x.37163] 
[0.x.37164] 
//
[0.x.37165] 
[0.x.37166] 
[0.x.37167] 
[0.x.37168] 
//
[0.x.37169] 
[0.x.37170] 
[0.x.37171] 
//
[0.x.37172] 
[0.x.37173] 
//
[0.x.37174] 
[0.x.37175] 
[0.x.37176] 
//
[0.x.37177] 
//
// The only new include file is the one for the MappingQCache class.
//
[0.x.37178] 
//
[0.x.37179] 
[0.x.37180] 
[0.x.37181] 
//[2.x.4339] 
//
// In this tutorial program, we want to solve the Poisson equation with a coefficient that jumps along a sphere of radius 0.5, and using a constant right hand side of value  [2.x.4340] . (This setup is similar to  [2.x.4341]  and  [2.x.4342] , but the concrete values for the coefficient and the right hand side are different.) Due to the jump in the coefficient, the analytical solution must have a kink where the coefficient switches from one value to the other. To keep things simple, we select an analytical solution that is quadratic in all components, i.e.,  [2.x.4343]  in the ball of radius 0.5 and  [2.x.4344]  in the outer part of the domain. This analytical solution is compatible with the right hand side in case the coefficient is 0.5 in the inner ball and 5 outside. It is also continuous along the circle of radius 0.5.
//
[0.x.37182] 
[0.x.37183] 
[0.x.37184] 
[0.x.37185] 
[0.x.37186] 
[0.x.37187] 
[0.x.37188] 
[0.x.37189] 
[0.x.37190] 
[0.x.37191] 
[0.x.37192] 
[0.x.37193] 
//
[0.x.37194] 
[0.x.37195] 
[0.x.37196] 
[0.x.37197] 
[0.x.37198] 
[0.x.37199] 
[0.x.37200] 
[0.x.37201] 
[0.x.37202] 
[0.x.37203] 
//
[0.x.37204] 
[0.x.37205] 
[0.x.37206] 
[0.x.37207] 
[0.x.37208] 
[0.x.37209] 
[0.x.37210] 
[0.x.37211] 
//
//  [2.x.4345] 
//
// The implementation of the Poisson problem is very similar to what we used in the  [2.x.4346]  tutorial program. The two main differences are that we pass a mapping object to the various steps in the program in order to switch between two mapping representations as explained in the introduction, and the `timer` object (of type TimerOutput) that will be used for measuring the run times in the various cases. (The concept of mapping objects was first introduced in  [2.x.4347]  and  [2.x.4348] , in case you want to look up the use of these classes.)
//
[0.x.37212] 
[0.x.37213] 
[0.x.37214] 
[0.x.37215] 
[0.x.37216] 
[0.x.37217] 
//
[0.x.37218] 
[0.x.37219] 
[0.x.37220] 
[0.x.37221] 
[0.x.37222] 
[0.x.37223] 
//
[0.x.37224] 
[0.x.37225] 
[0.x.37226] 
//
[0.x.37227] 
[0.x.37228] 
[0.x.37229] 
[0.x.37230] 
[0.x.37231] 
//
[0.x.37232] 
[0.x.37233] 
//
// In the constructor, we set up the timer object to record wall times but be quiet during the normal execution. We will query it for timing details in the  [2.x.4349]  function. Furthermore, we select a relatively high polynomial degree of three for the finite element in use.
//
[0.x.37234] 
[0.x.37235] 
[0.x.37236] 
[0.x.37237] 
[0.x.37238] 
[0.x.37239] 
//
//  [2.x.4350] 
//
// The next function presents the typical usage of TransfiniteInterpolationManifold. The first step is to create the desired grid, which can be done by composition of two grids from GridGenerator. The inner ball mesh is simple enough: We run  [2.x.4351]  centered at the origin with radius 0.5 (third function argument). The second mesh is more interesting and constructed as follows: We want to have a mesh that is spherical in the interior but flat on the outer surface. Furthermore, the mesh topology of the inner ball should be compatible with the outer grid in the sense that their vertices coincide so as to allow the two grid to be merged. The grid coming out of  [2.x.4352]  fulfills the requirements on the inner side in case it is created with  [2.x.4353]  coarse cells (6 coarse cells in 3D which we are going to use) &ndash; this is the same number of cells as there are boundary faces for the ball. For the outer surface, we use the fact that the 6 faces on the surface of the shell without a manifold attached would degenerate to the surface of a cube. What we are still missing is the radius of the outer shell boundary. Since we desire a cube of extent  [2.x.4354]  and the 6-cell shell puts its 8 outer vertices at the 8 opposing diagonals, we must translate the points  [2.x.4355]  into a radius: Clearly, the radius must be  [2.x.4356]  in  [2.x.4357]  dimensions, i.e.,  [2.x.4358]  for the three-dimensional case we want to consider.
//
// Thus, we have a plan: After creating the inner triangulation for the ball and the one for the outer shell, we merge those two grids but remove all manifolds that the functions in GridGenerator may have set from the resulting triangulation, to ensure that we have full control over manifolds. In particular, we want additional points added on the boundary during refinement to follow a flat manifold description. To start the process of adding more appropriate manifold ids, we assign the manifold id 0 to all mesh entities (cells, faces, lines), which will later be associated with the TransfiniteInterpolationManifold. Then, we must identify the faces and lines that are along the sphere of radius 0.5 and mark them with a different manifold id, so as to then assign a SphericalManifold to those. We will choose the manifold id of 1. Since we have thrown away all manifolds that pre-existed after calling  [2.x.4359]  we manually go through the cells of the mesh and all their faces. We have found a face on the sphere if all four vertices have a radius of 0.5, or, as we write in the program, have  [2.x.4360] . Note that we call `cell->face(f)->set_all_manifold_ids(1)` to set the manifold id both on the faces and the surrounding lines. Furthermore, we want to distinguish the cells inside the ball and outside the ball by a material id for visualization, corresponding to the picture in the introduction.
//
[0.x.37240] 
[0.x.37241] 
[0.x.37242] 
[0.x.37243] 
[0.x.37244] 
//
[0.x.37245] 
[0.x.37246] 
[0.x.37247] 
//
[0.x.37248] 
//
[0.x.37249] 
[0.x.37250] 
//
[0.x.37251] 
[0.x.37252] 
[0.x.37253] 
[0.x.37254] 
[0.x.37255] 
[0.x.37256] 
[0.x.37257] 
[0.x.37258] 
[0.x.37259] 
[0.x.37260] 
[0.x.37261] 
[0.x.37262] 
[0.x.37263] 
[0.x.37264] 
[0.x.37265] 
[0.x.37266] 
[0.x.37267] 
[0.x.37268] 
//
// With all cells, faces and lines marked appropriately, we can attach the Manifold objects to those numbers. The entities with manifold id 1 will get a spherical manifold, whereas the other entities, which have the manifold id 0, will be assigned the TransfiniteInterpolationManifold. As mentioned in the introduction, we must explicitly initialize the manifold with the current mesh using a call to  [2.x.4361]  in order to pick up the coarse mesh cells and the manifolds attached to the boundaries of those cells. We also note that the manifold objects we create locally in this function are allowed to go out of scope (as they do at the end of the function scope), because the Triangulation object internally copies them.
//
// With all manifolds attached, we will finally go about and refine the mesh a few times to create a sufficiently large test case.
//
[0.x.37269] 
//
[0.x.37270] 
[0.x.37271] 
[0.x.37272] 
//
[0.x.37273] 
[0.x.37274] 
//
//  [2.x.4362] 
//
// The following function is well-known from other tutorials in that it enumerates the degrees of freedom, creates a constraint object and sets up a sparse matrix for the linear system. The only thing worth mentioning is the fact that the function receives a reference to a mapping object that we then pass to the  [2.x.4363]  function to ensure that our boundary values are evaluated on the high-order mesh used for assembly. In the present example, it does not really matter because the outer surfaces are flat, but for curved outer cells this leads to more accurate approximation of the boundary values.
//
[0.x.37275] 
[0.x.37276] 
[0.x.37277] 
[0.x.37278] 
[0.x.37279] 
[0.x.37280] 
[0.x.37281] 
[0.x.37282] 
//
[0.x.37283] 
[0.x.37284] 
//
[0.x.37285] 
//
[0.x.37286] 
[0.x.37287] 
[0.x.37288] 
//
[0.x.37289] 
[0.x.37290] 
//
[0.x.37291] 
[0.x.37292] 
//
[0.x.37293] 
[0.x.37294] 
//
[0.x.37295] 
[0.x.37296] 
[0.x.37297] 
//[2.x.4364] 
//
// The function that assembles the linear system is also well known from the previous tutorial programs. One thing to note is that we set the number of quadrature points to the polynomial degree plus two, not the degree plus one as in most other tutorials. This is because we expect some extra accuracy as the mapping also involves a degree one more than the polynomials for the solution.
//
// The only somewhat unusual code in the assembly is the way we compute the cell matrix. Rather than using three nested loop over the quadrature point index, the row, and the column of the matrix, we first collect the derivatives of the shape function, multiplied by the square root of the product of the coefficient and the integration factor `JxW` in a separate matrix `partial_matrix`. To compute the cell matrix, we then execute `cell_matrix = partial_matrix * transpose(partial_matrix)` in the line `partial_matrix.mTmult(cell_matrix, partial_matrix);`. To understand why this works, we realize that the matrix-matrix multiplication performs a summation over the columns of `partial_matrix`. If we denote the coefficient by  [2.x.4365] , the entries in the temporary matrix are  [2.x.4366] . If we take the product of the [1.x.123]th row with the [1.x.124]th column of that matrix, we compute a nested sum involving  [2.x.4367] , which is exactly the terms needed for the bilinear form of the Laplace equation.
//
// The reason for choosing this somewhat unusual scheme is due to the heavy work involved in computing the cell matrix for a relatively high polynomial degree in 3D. As we want to highlight the cost of the mapping in this tutorial program, we better do the assembly in an optimized way in order to not chase bottlenecks that have been solved by the community already. Matrix-matrix multiplication is one of the best optimized kernels in the HPC context, and the  [2.x.4368]  function will call into those optimized BLAS functions. If the user has provided a good BLAS library when configuring deal.II (like OpenBLAS or Intel's MKL), the computation of the cell matrix will execute close to the processor's peak arithmetic performance. As a side note, we mention that despite an optimized matrix-matrix multiplication, the current strategy is sub-optimal in terms of complexity as the work to be done is proportional to  [2.x.4369]  operations for degree  [2.x.4370]  (this also applies to the usual evaluation with FEValues). One could compute the cell matrix with  [2.x.4371]  operations by utilizing the tensor product structure of the shape functions, as is done by the matrix-free framework in deal.II. We refer to  [2.x.4372]  and the documentation of the tensor-product-aware evaluators FEEvaluation for details on how an even more efficient cell matrix computation could be realized.
//
[0.x.37298] 
[0.x.37299] 
[0.x.37300] 
[0.x.37301] 
//
[0.x.37302] 
[0.x.37303] 
[0.x.37304] 
[0.x.37305] 
[0.x.37306] 
[0.x.37307] 
//
[0.x.37308] 
[0.x.37309] 
//
[0.x.37310] 
[0.x.37311] 
[0.x.37312] 
[0.x.37313] 
//
[0.x.37314] 
[0.x.37315] 
[0.x.37316] 
[0.x.37317] 
//
[0.x.37318] 
[0.x.37319] 
[0.x.37320] 
[0.x.37321] 
[0.x.37322] 
[0.x.37323] 
[0.x.37324] 
[0.x.37325] 
[0.x.37326] 
[0.x.37327] 
[0.x.37328] 
[0.x.37329] 
[0.x.37330] 
[0.x.37331] 
[0.x.37332] 
[0.x.37333] 
//
[0.x.37334] 
//
[0.x.37335] 
[0.x.37336] 
[0.x.37337] 
[0.x.37338] 
[0.x.37339] 
//
//  [2.x.4373] 
//
// For solving the linear system, we pick a simple Jacobi-preconditioned conjugate gradient solver, similar to the settings in the early tutorials.
//
[0.x.37340] 
[0.x.37341] 
[0.x.37342] 
[0.x.37343] 
//
[0.x.37344] 
[0.x.37345] 
//
[0.x.37346] 
[0.x.37347] 
//
[0.x.37348] 
[0.x.37349] 
//
[0.x.37350] 
[0.x.37351] 
[0.x.37352] 
//
//  [2.x.4374] 
//
// In the next function we do various post-processing steps with the solution, all of which involve the mapping in one way or the other.
//
// The first operation we do is to write the solution as well as the material ids to a VTU file. This is similar to what was done in many other tutorial programs. The new ingredient presented in this tutorial program is that we want to ensure that the data written to the file used for visualization is actually a faithful representation of what is used internally by deal.II. That is because most of the visualization data formats only represent cells by their vertex coordinates, but have no way of representing the curved boundaries that are used in deal.II when using higher order mappings -- in other words, what you see in the visualization tool is not actually what you are computing on. (The same, incidentally, is true when using higher order shape functions: Most visualization tools only render bilinear/trilinear representations. This is discussed in detail in  [2.x.4375] 
//
// So we need to ensure that a high-order representation is written to the file. We need to consider two particular topics. Firstly, we tell the DataOut object via the  [2.x.4376]  that we intend to interpret the subdivisions of the elements as a high-order Lagrange polynomial rather than a collection of bilinear patches. Recent visualization programs, like ParaView version 5.5 or newer, can then render a high-order solution (see a [1.x.125] for more details). Secondly, we need to make sure that the mapping is passed to the  [2.x.4377]  method. Finally, the DataOut class only prints curved faces for [1.x.126] cells by default, so we need to ensure that also inner cells are printed in a curved representation via the mapping.
//
[0.x.37353] 
[0.x.37354] 
[0.x.37355] 
[0.x.37356] 
[0.x.37357] 
//
[0.x.37358] 
//
[0.x.37359] 
[0.x.37360] 
[0.x.37361] 
//
[0.x.37362] 
[0.x.37363] 
//
[0.x.37364] 
[0.x.37365] 
[0.x.37366] 
[0.x.37367] 
//
[0.x.37368] 
[0.x.37369] 
[0.x.37370] 
//
[0.x.37371] 
[0.x.37372] 
[0.x.37373] 
[0.x.37374] 
[0.x.37375] 
//
[0.x.37376] 
[0.x.37377] 
//
// The next operation in the postprocessing function is to compute the  [2.x.4378]  and  [2.x.4379]  errors against the analytical solution. As the analytical solution is a quadratic polynomial, we expect a very accurate result at this point. If we were solving on a simple mesh with planar faces and a coefficient whose jumps are aligned with the faces between cells, then we would expect the numerical result to coincide with the analytical solution up to roundoff accuracy. However, since we are using deformed cells following a sphere, which are only tracked by polynomials of degree 4 (one more than the degree for the finite elements), we will see that there is an error around  [2.x.4380] . We could get more accuracy by increasing the polynomial degree or refining the mesh.
//
[0.x.37378] 
[0.x.37379] 
//
[0.x.37380] 
//
[0.x.37381] 
[0.x.37382] 
[0.x.37383] 
[0.x.37384] 
[0.x.37385] 
[0.x.37386] 
[0.x.37387] 
[0.x.37388] 
[0.x.37389] 
//
[0.x.37390] 
[0.x.37391] 
[0.x.37392] 
[0.x.37393] 
[0.x.37394] 
[0.x.37395] 
[0.x.37396] 
[0.x.37397] 
[0.x.37398] 
[0.x.37399] 
//
// The final post-processing operation we do here is to compute an error estimate with the KellyErrorEstimator. We use the exact same settings as in the  [2.x.4381]  tutorial program, except for the fact that we also hand in the mapping to ensure that errors are evaluated along the curved element, consistent with the remainder of the program. However, we do not really use the result here to drive a mesh adaptation step (that would refine the mesh around the material interface along the sphere), as the focus here is on the cost of this operation.
//
[0.x.37400] 
[0.x.37401] 
//
[0.x.37402] 
[0.x.37403] 
[0.x.37404] 
[0.x.37405] 
[0.x.37406] 
[0.x.37407] 
[0.x.37408] 
[0.x.37409] 
[0.x.37410] 
[0.x.37411] 
[0.x.37412] 
[0.x.37413] 
//
//  [2.x.4382] 
//
// Finally, we define the `run()` function that controls how we want to execute this program (which is called by the main() function in the usual way). We start by calling the `create_grid()` function that sets up our geometry with the appropriate manifolds. We then run two instances of a solver chain, starting from the setup of the equations, the assembly of the linear system, its solution with a simple iterative solver, and the postprocessing discussed above. The two instances differ in the way they use the mapping. The first uses a conventional MappingQGeneric mapping object which we initialize to a degree one more than we use for the finite element &ndash; after all, we expect the geometry representation to be the bottleneck as the analytic solution is only a quadratic polynomial. (In reality, things are interlinked to quite some extent because the evaluation of the polynomials in real coordinates involves the mapping of a higher-degree polynomials, which represent some smooth rational functions. As a consequence, higher-degree polynomials still pay off, so it does not make sense to increase the degree of the mapping further.) Once the first pass is completed, we let the timer print a summary of the compute times of the individual stages.
//
[0.x.37414] 
[0.x.37415] 
[0.x.37416] 
[0.x.37417] 
//
[0.x.37418] 
[0.x.37419] 
[0.x.37420] 
[0.x.37421] 
[0.x.37422] 
//
[0.x.37423] 
[0.x.37424] 
[0.x.37425] 
[0.x.37426] 
[0.x.37427] 
//
[0.x.37428] 
[0.x.37429] 
[0.x.37430] 
//
// For the second instance, we instead set up the MappingQCache class. Its use is very simple: After constructing it (with the degree, given that we want it to show the correct degree functionality in other contexts), we fill the cache via the  [2.x.4383]  function. At this stage, we specify which mapping we want to use (obviously, the same MappingQGeneric as previously in order to repeat the same computations) for the cache, and then run through the same functions again, now handing in the modified mapping. In the end, we again print the accumulated wall times since the reset to see how the times compare to the original setting.
//
[0.x.37431] 
[0.x.37432] 
[0.x.37433] 
[0.x.37434] 
[0.x.37435] 
//
[0.x.37436] 
[0.x.37437] 
[0.x.37438] 
[0.x.37439] 
[0.x.37440] 
[0.x.37441] 
[0.x.37442] 
//
[0.x.37443] 
[0.x.37444] 
[0.x.37445] 
[0.x.37446] 
//
[0.x.37447] 
[0.x.37448] 
[0.x.37449] 
[0.x.37450] 
//
[0.x.37451] 
[0.x.37452] 
[0.x.37453] 
[0.x.37454] 
[0.x.37455] 
[0.x.37456] 
[0.x.37457] 
[0.x.37458] 
[0.x.37459] 
[0.x.37460] 
[0.x.37461] 
[0.x.37462] 
[0.x.37463] 
[0.x.37464] 
[0.x.37465] 
[0.x.37466] 
[0.x.37467] 
[0.x.37468] 
[0.x.37469] 
[0.x.37470] 
[0.x.37471] 
[0.x.37472] 
[0.x.37473] 
//
// First we include the typical headers of the deal.II library needed for this tutorial:
//
[0.x.37474] 
[0.x.37475] 
[0.x.37476] 
[0.x.37477] 
//
[0.x.37478] 
[0.x.37479] 
[0.x.37480] 
//
[0.x.37481] 
[0.x.37482] 
//
[0.x.37483] 
[0.x.37484] 
[0.x.37485] 
[0.x.37486] 
[0.x.37487] 
[0.x.37488] 
//
[0.x.37489] 
[0.x.37490] 
[0.x.37491] 
[0.x.37492] 
//
[0.x.37493] 
[0.x.37494] 
//
// In particular, we need to include the headers for the matrix-free framework:
//
[0.x.37495] 
[0.x.37496] 
[0.x.37497] 
[0.x.37498] 
//
// And since we want to use a geometric multigrid preconditioner, we need also the multilevel headers:
//
[0.x.37499] 
[0.x.37500] 
[0.x.37501] 
[0.x.37502] 
[0.x.37503] 
[0.x.37504] 
[0.x.37505] 
//
// Finally some common C++ headers for in and output:
//
[0.x.37506] 
[0.x.37507] 
//
[0.x.37508] 
[0.x.37509] 
[0.x.37510] 
//
//  [2.x.4384] 
//
// In the beginning we define the matrix-free operator for the Jacobian. As a guideline we follow the tutorials  [2.x.4385]  and  [2.x.4386] , where the precise interface of the  [2.x.4387]  class was extensively documented.
//
// Since we want to use the Jacobian as system matrix and pass it to the linear solver as well as to the multilevel preconditioner classes, we derive the  [2.x.4388]  class from the  [2.x.4389]  class, such that we have already the right interface. The two functions we need to override from the base class are the  [2.x.4390]  and the  [2.x.4391]  function. To allow preconditioning with float precision we define the number type as template argument.
//
// As mentioned already in the introduction, we need to evaluate the Jacobian  [2.x.4392]  at the last Newton step  [2.x.4393]  for the computation of the Newton update  [2.x.4394] . To get the information of the last Newton step  [2.x.4395]  we do pretty much the same as in  [2.x.4396] , where we stored the values of a coefficient function in a table  [2.x.4397]  once before we use the matrix-free operator. Instead of a function  [2.x.4398] , we here implement a function  [2.x.4399] .
//
// As additional private member functions of the  [2.x.4400]  we implement the  [2.x.4401]  and the  [2.x.4402]  function. The first one is the actual worker function for the matrix-vector application, which we pass to the  [2.x.4403]  in the  [2.x.4404]  function. The later one is the worker function to compute the diagonal, which we pass to the  [2.x.4405]  function.
//
// For better readability of the source code we further define an alias for the FEEvaluation object.
//
[0.x.37511] 
[0.x.37512] 
[0.x.37513] 
[0.x.37514] 
[0.x.37515] 
[0.x.37516] 
[0.x.37517] 
//
[0.x.37518] 
[0.x.37519] 
//
[0.x.37520] 
//
[0.x.37521] 
//
[0.x.37522] 
[0.x.37523] 
//
[0.x.37524] 
//
[0.x.37525] 
[0.x.37526] 
[0.x.37527] 
[0.x.37528] 
//
[0.x.37529] 
[0.x.37530] 
[0.x.37531] 
[0.x.37532] 
[0.x.37533] 
//
[0.x.37534] 
//
[0.x.37535] 
[0.x.37536] 
//
// The constructor of the  [2.x.4406]  just calls the constructor of the base class  [2.x.4407]  which is itself derived from the Subscriptor class.
//
[0.x.37537] 
[0.x.37538] 
[0.x.37539] 
[0.x.37540] 
[0.x.37541] 
//
// The  [2.x.4408]  function resets the table holding the values for the nonlinearity and call the  [2.x.4409]  function of the base class.
//
[0.x.37542] 
[0.x.37543] 
[0.x.37544] 
[0.x.37545] 
[0.x.37546] 
[0.x.37547] 
[0.x.37548] 
//
//  [2.x.4410] 
//
// The following  [2.x.4411]  function is based on the  [2.x.4412]  function from  [2.x.4413] . However, it does not evaluate a function object, but evaluates a vector representing a finite element function, namely the last Newton step needed for the Jacobian. Therefore we set up a FEEvaluation object and evaluate the finite element function in the quadrature points with the  [2.x.4414]  and  [2.x.4415]  functions. We store the evaluated values of the finite element function directly in the  [2.x.4416]  table.
//
// This will work well and in the  [2.x.4417]  function we can use the values stored in the table to apply the matrix-vector product. However, we can also optimize the implementation of the Jacobian at this stage. We can directly evaluate the nonlinear function  [2.x.4418]  and store these values in the table. This skips all evaluations of the nonlinearity in each call of the  [2.x.4419]  function.
//
[0.x.37549] 
[0.x.37550] 
[0.x.37551] 
[0.x.37552] 
[0.x.37553] 
[0.x.37554] 
//
[0.x.37555] 
//
[0.x.37556] 
[0.x.37557] 
[0.x.37558] 
[0.x.37559] 
[0.x.37560] 
//
[0.x.37561] 
[0.x.37562] 
[0.x.37563] 
[0.x.37564] 
[0.x.37565] 
[0.x.37566] 
//
//  [2.x.4420] 
//
// Now in the  [2.x.4421]  function, which actually implements the cell wise action of the system matrix, we can use the information of the last Newton step stored in the table  [2.x.4422] . The rest of this function is basically the same as in  [2.x.4423] . We set up the FEEvaluation object, gather and evaluate the values and gradients of the input vector  [2.x.4424] , submit the values and gradients according to the form of the Jacobian and finally call  [2.x.4425]  to perform the cell integration and distribute the local contributions into the global vector  [2.x.4426] .
//
[0.x.37567] 
[0.x.37568] 
[0.x.37569] 
[0.x.37570] 
[0.x.37571] 
[0.x.37572] 
[0.x.37573] 
[0.x.37574] 
//
[0.x.37575] 
[0.x.37576] 
[0.x.37577] 
[0.x.37578] 
[0.x.37579] 
//
[0.x.37580] 
//
[0.x.37581] 
[0.x.37582] 
[0.x.37583] 
//
[0.x.37584] 
[0.x.37585] 
[0.x.37586] 
[0.x.37587] 
[0.x.37588] 
//
[0.x.37589] 
[0.x.37590] 
[0.x.37591] 
[0.x.37592] 
[0.x.37593] 
//
// Next we use  [2.x.4427]  to perform the actual loop over all cells computing the cell contribution to the matrix-vector product.
//
[0.x.37594] 
[0.x.37595] 
[0.x.37596] 
[0.x.37597] 
[0.x.37598] 
[0.x.37599] 
[0.x.37600] 
//
//  [2.x.4428] 
//
// The internal worker function  [2.x.4429]  for the computation of the diagonal is similar to the above worker function  [2.x.4430] . However, as major difference we do not read values from a input vector or distribute any local results to an output vector. Instead the only input argument is the used FEEvaluation object.
//
[0.x.37601] 
[0.x.37602] 
[0.x.37603] 
[0.x.37604] 
[0.x.37605] 
[0.x.37606] 
[0.x.37607] 
//
[0.x.37608] 
//
[0.x.37609] 
//
[0.x.37610] 
[0.x.37611] 
[0.x.37612] 
[0.x.37613] 
[0.x.37614] 
//
[0.x.37615] 
[0.x.37616] 
//
// Finally we override the  [2.x.4431]  function of the base class of the  [2.x.4432] . Although the name of the function suggests just the computation of the diagonal, this function does a bit more. Because we only really need the inverse of the matrix diagonal elements for the Chebyshev smoother of the multigrid preconditioner, we compute the diagonal and store the inverse elements. Therefore we first initialize the  [2.x.4433] . Then we compute the diagonal by passing the worker function  [2.x.4434]  to the  [2.x.4435]  function. In the end we loop over the diagonal and invert the elements by hand. Note, that during this loop we catch the constrained DOFs and set them manually to one.
//
[0.x.37617] 
[0.x.37618] 
[0.x.37619] 
[0.x.37620] 
[0.x.37621] 
[0.x.37622] 
[0.x.37623] 
[0.x.37624] 
//
[0.x.37625] 
[0.x.37626] 
[0.x.37627] 
[0.x.37628] 
//
[0.x.37629] 
[0.x.37630] 
[0.x.37631] 
[0.x.37632] 
[0.x.37633] 
[0.x.37634] 
[0.x.37635] 
//
//  [2.x.4436] 
//
// After implementing the matrix-free operators we can now define the solver class for the [1.x.127]. This class is based on the common structure of all previous tutorial programs, in particular it is based on  [2.x.4437] , solving also a nonlinear problem. Since we are using the matrix-free framework, we no longer need an assemble_system function any more, instead the information of the matrix is rebuilt in every call of the  [2.x.4438]  function. However, for the application of the Newton scheme we need to assemble the right hand side of the linearized problems and compute the residuals. Therefore, we implement an additional function  [2.x.4439] , which we later call in the  [2.x.4440]  function. Finally, the typical  [2.x.4441]  function here implements the Newton method, whereas the solution of the linearized system is computed in the function  [2.x.4442] . As the MatrixFree framework handles the polynomial degree of the Lagrangian finite element method as a template parameter, we declare it also as a template parameter for the problem solver class.
//
[0.x.37636] 
[0.x.37637] 
[0.x.37638] 
[0.x.37639] 
[0.x.37640] 
//
[0.x.37641] 
//
[0.x.37642] 
[0.x.37643] 
//
[0.x.37644] 
//
[0.x.37645] 
[0.x.37646] 
[0.x.37647] 
//
[0.x.37648] 
[0.x.37649] 
[0.x.37650] 
[0.x.37651] 
[0.x.37652] 
//
[0.x.37653] 
//
[0.x.37654] 
//
[0.x.37655] 
//
[0.x.37656] 
//
[0.x.37657] 
//
[0.x.37658] 
//
// For the parallel computation we define a  [2.x.4443]  As the computational domain is a circle in 2D and a ball in 3D, we assign in addition to the SphericalManifold for boundary cells a TransfiniteInterpolationManifold object for the mapping of the inner cells, which takes care of the inner cells. In this example we use an isoparametric finite element approach and thus use the MappingQGeneric class. Note, that we could also create an instance of the MappingQ class and set the  [2.x.4444]  flags in the contructor call to  [2.x.4445] . For further details on the connection of MappingQ and MappingQGeneric you may read the detailed description of these classes.
//
[0.x.37659] 
[0.x.37660] 
//
// As usual we then define the Lagrangian finite elements FE_Q and a DoFHandler.
//
[0.x.37661] 
[0.x.37662] 
//
// For the linearized discrete system we define an AffineConstraints objects and the  [2.x.4446] , which is in this example represented as a matrix-free operator.
//
[0.x.37663] 
[0.x.37664] 
[0.x.37665] 
//
// The multilevel object is also based on the matrix-free operator for the Jacobian. Since we need to evaluate the Jacobian with the last Newton step, we also need to evaluate the level operator with the last Newton step for the preconditioner. Thus in addition to  [2.x.4447] , we also need a MGLevelObject to store the interpolated solution vector on each level. As in  [2.x.4448]  we use float precision for the preconditioner. Moreover, we define the MGTransferMatrixFree object as a class variable, since we need to set it up only once when the triangulation has changed and can then use it again in each Newton step.
//
[0.x.37666] 
[0.x.37667] 
[0.x.37668] 
[0.x.37669] 
[0.x.37670] 
//
// Of course we also need vectors holding the  [2.x.4449] , the  [2.x.4450] . In that way we can always store the last Newton step in the solution vector and just add the update to get the next Newton step.
//
[0.x.37671] 
[0.x.37672] 
[0.x.37673] 
//
// Finally we have a variable for the number of iterations of the linear solver.
//
[0.x.37674] 
//
// For the output in programs running in parallel with MPI, we use the ConditionalOStream class to avoid multiple output of the same data by different MPI ranks.
//
[0.x.37675] 
//
// Finally for the time measurement we use a TimerOutput object, which prints the elapsed CPU and wall times for each function in a nicely formatted table after the program has finished.
//
[0.x.37676] 
[0.x.37677] 
//
// The constructor of the  [2.x.4451]  initializes the class variables. In particular, we set up the multilevel support for the  [2.x.4452]  set the mapping degree equal to the finite element degree, initialize the ConditionalOStream and tell the TimerOutput that we want to see the wall times only on demand.
//
[0.x.37678] 
[0.x.37679] 
[0.x.37680] 
[0.x.37681] 
[0.x.37682] 
[0.x.37683] 
[0.x.37684] 
[0.x.37685] 
[0.x.37686] 
[0.x.37687] 
[0.x.37688] 
[0.x.37689] 
[0.x.37690] 
[0.x.37691] 
[0.x.37692] 
//
//  [2.x.4453] 
//
// As the computational domain we use the  [2.x.4454] -dimensional unit ball. We follow the instructions for the TransfiniteInterpolationManifold class and also assign a SphericalManifold for the boundary. Finally, we refine the initial mesh 3
//
// -  [2.x.4455]  times globally.
//
[0.x.37693] 
[0.x.37694] 
[0.x.37695] 
[0.x.37696] 
//
[0.x.37697] 
[0.x.37698] 
//
[0.x.37699] 
//
[0.x.37700] 
[0.x.37701] 
//
[0.x.37702] 
//
[0.x.37703] 
[0.x.37704] 
//
[0.x.37705] 
[0.x.37706] 
//
//  [2.x.4456] 
//
// The  [2.x.4457]  function is quasi identical to the one in  [2.x.4458] . The only differences are obviously the time measurement with only one  [2.x.4459]  instead of measuring each part individually, and more importantly the initialization of the MGLevelObject for the interpolated solution vector of the previous Newton step. Another important change is the setup of the MGTransferMatrixFree object, which we can reuse in each Newton step as the  [2.x.4460]  will not be not changed.
//
// Note how we can use the same MatrixFree object twice, for the  [2.x.4461]  and the multigrid preconditioner.
//
[0.x.37707] 
[0.x.37708] 
[0.x.37709] 
[0.x.37710] 
//
[0.x.37711] 
[0.x.37712] 
//
[0.x.37713] 
[0.x.37714] 
//
[0.x.37715] 
[0.x.37716] 
//
[0.x.37717] 
[0.x.37718] 
[0.x.37719] 
[0.x.37720] 
[0.x.37721] 
[0.x.37722] 
[0.x.37723] 
[0.x.37724] 
//
[0.x.37725] 
[0.x.37726] 
[0.x.37727] 
[0.x.37728] 
[0.x.37729] 
[0.x.37730] 
[0.x.37731] 
[0.x.37732] 
[0.x.37733] 
[0.x.37734] 
[0.x.37735] 
[0.x.37736] 
[0.x.37737] 
//
[0.x.37738] 
[0.x.37739] 
//
[0.x.37740] 
[0.x.37741] 
[0.x.37742] 
//
[0.x.37743] 
[0.x.37744] 
[0.x.37745] 
//
[0.x.37746] 
[0.x.37747] 
[0.x.37748] 
[0.x.37749] 
[0.x.37750] 
//
[0.x.37751] 
[0.x.37752] 
//
[0.x.37753] 
[0.x.37754] 
[0.x.37755] 
[0.x.37756] 
[0.x.37757] 
[0.x.37758] 
//
[0.x.37759] 
[0.x.37760] 
[0.x.37761] 
[0.x.37762] 
[0.x.37763] 
//
[0.x.37764] 
[0.x.37765] 
[0.x.37766] 
[0.x.37767] 
[0.x.37768] 
[0.x.37769] 
[0.x.37770] 
[0.x.37771] 
[0.x.37772] 
[0.x.37773] 
[0.x.37774] 
[0.x.37775] 
[0.x.37776] 
//
[0.x.37777] 
[0.x.37778] 
[0.x.37779] 
[0.x.37780] 
[0.x.37781] 
[0.x.37782] 
//
//  [2.x.4462] 
//
// Next we implement a function which evaluates the nonlinear discrete residual for a given input vector ( [2.x.4463] ). This function is then used for the assembly of the right hand side of the linearized system and later for the computation of the residual of the next Newton step to check if we already reached the error tolerance. As this function should not affect any class variable we define it as a constant function. Internally we exploit the fast finite element evaluation through the FEEvaluation class and the  [2.x.4464]  similar to  [2.x.4465] .
//
// First we create a pointer to the MatrixFree object, which is stored in the  [2.x.4466] . Then we pass the worker function  [2.x.4467]  for the cell wise evaluation of the residual together with the input and output vector to the  [2.x.4468]  In addition, we enable the zero out of the output vector in the loop, which is more efficient than calling <code>dst = 0.0</code> separately before.
//
// Note that with this approach we do not have to take care about the MPI related data exchange, since all the bookkeeping is done by the  [2.x.4469] 
[0.x.37783] 
[0.x.37784] 
[0.x.37785] 
[0.x.37786] 
[0.x.37787] 
[0.x.37788] 
//
[0.x.37789] 
[0.x.37790] 
[0.x.37791] 
//
//  [2.x.4470] 
//
// This is the internal worker function for the evaluation of the residual. Essentially it has the same structure as the  [2.x.4471]  function of the  [2.x.4472]  and evaluates the residual for the input vector  [2.x.4473]  on the given set of cells  [2.x.4474] . The difference to the above mentioned  [2.x.4475]  function is, that we split the  [2.x.4476]  function into  [2.x.4477]  and  [2.x.4478]  since the input vector might have constrained DOFs.
//
[0.x.37792] 
[0.x.37793] 
[0.x.37794] 
[0.x.37795] 
[0.x.37796] 
[0.x.37797] 
[0.x.37798] 
[0.x.37799] 
//
[0.x.37800] 
[0.x.37801] 
[0.x.37802] 
//
[0.x.37803] 
[0.x.37804] 
//
[0.x.37805] 
[0.x.37806] 
[0.x.37807] 
[0.x.37808] 
[0.x.37809] 
//
[0.x.37810] 
[0.x.37811] 
[0.x.37812] 
[0.x.37813] 
[0.x.37814] 
//
//  [2.x.4479] 
//
// Using the above function  [2.x.4480]  to evaluate the nonlinear residual, the assembly of the right hand side of the linearized system becomes now a very easy task. We just call the  [2.x.4481]  function and multiply the result with minus one.
//
// Experiences show that using the FEEvaluation class is much faster than a classical implementation with FEValues and co.
//
[0.x.37815] 
[0.x.37816] 
[0.x.37817] 
[0.x.37818] 
//
[0.x.37819] 
//
[0.x.37820] 
[0.x.37821] 
//
//  [2.x.4482] 
//
// According to  [2.x.4483]  the following function computes the norm of the nonlinear residual for the solution  [2.x.4484]  with the help of the  [2.x.4485]  function. The Newton step length  [2.x.4486]  becomes important if we would use an adaptive version of the Newton method. Then for example we would compute the residual for different step lengths and compare the residuals. However, for our problem the full Newton step with  [2.x.4487]  is the best we can do. An adaptive version of Newton's method becomes interesting if we have no good initial value. Note that in theory Newton's method converges with quadratic order, but only if we have an appropriate initial value. For unsuitable initial values the Newton method diverges even with quadratic order. A common way is then to use a damped version  [2.x.4488]  until the Newton step is good enough and the full Newton step can be performed. This was also discussed in  [2.x.4489] .
//
[0.x.37822] 
[0.x.37823] 
[0.x.37824] 
[0.x.37825] 
//
[0.x.37826] 
[0.x.37827] 
//
[0.x.37828] 
[0.x.37829] 
//
[0.x.37830] 
[0.x.37831] 
[0.x.37832] 
[0.x.37833] 
[0.x.37834] 
//
[0.x.37835] 
//
[0.x.37836] 
[0.x.37837] 
//
//  [2.x.4490] 
//
// In order to compute the Newton updates in each Newton step we solve the linear system with the CG algorithm together with a geometric multigrid preconditioner. For this we first set up the PreconditionMG object with a Chebyshev smoother like we did in  [2.x.4491] .
//
[0.x.37838] 
[0.x.37839] 
[0.x.37840] 
[0.x.37841] 
//
// We remember that the Jacobian depends on the last Newton step stored in the solution vector. So we update the ghost values of the Newton step and pass it to the  [2.x.4492]  to store the information.
//
[0.x.37842] 
//
[0.x.37843] 
//
// Next we also have to pass the last Newton step to the multilevel operators. Therefore, we need to interpolate the Newton step to all levels of the triangulation. This is done with the  [2.x.4493] 
[0.x.37844] 
//
// Now we can set up the preconditioner. We define the smoother and pass the interpolated vectors of the Newton step to the multilevel operators.
//
[0.x.37845] 
[0.x.37846] 
[0.x.37847] 
[0.x.37848] 
[0.x.37849] 
[0.x.37850] 
[0.x.37851] 
[0.x.37852] 
[0.x.37853] 
[0.x.37854] 
[0.x.37855] 
[0.x.37856] 
[0.x.37857] 
[0.x.37858] 
[0.x.37859] 
[0.x.37860] 
[0.x.37861] 
[0.x.37862] 
[0.x.37863] 
[0.x.37864] 
[0.x.37865] 
[0.x.37866] 
[0.x.37867] 
//
[0.x.37868] 
[0.x.37869] 
//
[0.x.37870] 
[0.x.37871] 
[0.x.37872] 
[0.x.37873] 
//
[0.x.37874] 
[0.x.37875] 
[0.x.37876] 
//
[0.x.37877] 
[0.x.37878] 
//
[0.x.37879] 
[0.x.37880] 
[0.x.37881] 
[0.x.37882] 
[0.x.37883] 
[0.x.37884] 
[0.x.37885] 
[0.x.37886] 
[0.x.37887] 
[0.x.37888] 
//
[0.x.37889] 
[0.x.37890] 
[0.x.37891] 
//
[0.x.37892] 
[0.x.37893] 
[0.x.37894] 
[0.x.37895] 
//
// Finally we set up the SolverControl and the SolverCG to solve the linearized problem for the current Newton update. An important fact of the implementation of SolverCG or also SolverGMRES is, that the vector holding the solution of the linear system (here  [2.x.4494] ) can be used to pass a starting value. In order to start the iterative solver always with a zero vector we reset the  [2.x.4495]  explicitly before calling  [2.x.4496]  Afterwards we distribute the Dirichlet boundary conditions stored in  [2.x.4497]  and store the number of iteration steps for the later output.
//
[0.x.37896] 
[0.x.37897] 
//
[0.x.37898] 
//
[0.x.37899] 
//
[0.x.37900] 
//
[0.x.37901] 
//
// Then for bookkeeping we zero out the ghost values.
//
[0.x.37902] 
[0.x.37903] 
//
//  [2.x.4498] 
//
// Now we implement the actual Newton solver for the nonlinear problem.
//
[0.x.37904] 
[0.x.37905] 
[0.x.37906] 
[0.x.37907] 
//
// We define a maximal number of Newton steps and tolerances for the convergence criterion. Usually, with good starting values, the Newton method converges in three to six steps, so maximal ten steps should be totally sufficient. As tolerances we use  [2.x.4499]  for the norm of the residual and  [2.x.4500]  for the norm of the Newton update. This seems a bit over the top, but we will see that, for our example, we will achieve these tolerances after a few steps.
//
[0.x.37908] 
[0.x.37909] 
[0.x.37910] 
//
[0.x.37911] 
[0.x.37912] 
//
// Now we start the actual Newton iteration.
//
[0.x.37913] 
[0.x.37914] 
//
// We assemble the right hand side of the linearized problem and compute the Newton update.
//
[0.x.37915] 
[0.x.37916] 
//
// Then we compute the errors, namely the norm of the Newton update and the residual. Note that at this point one could incorporate a step size control for the Newton method by varying the input parameter  [2.x.4501]  for the compute_residual function. However, here we just use  [2.x.4502]  equal to one for a plain Newton iteration.
//
[0.x.37917] 
[0.x.37918] 
//
// Next we advance the Newton step by adding the Newton update to the current Newton step.
//
[0.x.37919] 
//
// A short output will inform us on the current Newton step.
//
[0.x.37920] 
[0.x.37921] 
[0.x.37922] 
//
// After each Newton step we check the convergence criteria. If at least one of those is fulfilled we are done and end the loop. If we haven't found a satisfying solution after the maximal amount of Newton iterations, we inform the user about this shortcoming.
//
[0.x.37923] 
[0.x.37924] 
[0.x.37925] 
//
[0.x.37926] 
[0.x.37927] 
[0.x.37928] 
//
[0.x.37929] 
[0.x.37930] 
[0.x.37931] 
[0.x.37932] 
[0.x.37933] 
[0.x.37934] 
[0.x.37935] 
//
[0.x.37936] 
[0.x.37937] 
[0.x.37938] 
[0.x.37939] 
//
//  [2.x.4503] 
//
// The computation of the H1-seminorm of the solution can be done in the same way as in  [2.x.4504] . We update the ghost values and use the function  [2.x.4505]  In the end we gather all computations from all MPI ranks and return the norm.
//
[0.x.37940] 
[0.x.37941] 
[0.x.37942] 
[0.x.37943] 
//
[0.x.37944] 
//
[0.x.37945] 
[0.x.37946] 
[0.x.37947] 
[0.x.37948] 
[0.x.37949] 
[0.x.37950] 
[0.x.37951] 
//
[0.x.37952] 
//
[0.x.37953] 
[0.x.37954] 
[0.x.37955] 
[0.x.37956] 
//
//  [2.x.4506] 
//
// We generate the graphical output files in vtu format together with a pvtu master file at once by calling the  [2.x.4507]  function in the same way as in  [2.x.4508] . In addition, as in  [2.x.4509] , we query the  [2.x.4510]  of each cell and write the distribution of the triangulation among the MPI ranks into the output file. Finally, we generate the patches of the solution by calling  [2.x.4511]  However, since we have a computational domain with a curved boundary, we additionally pass the  [2.x.4512]  and the finite element degree as number of subdivision. But this is still not enough for the correct representation of the solution, for example in ParaView, because we attached a TransfiniteInterpolationManifold to the inner cells, which results in curved cells in the interior. Therefore we pass as third argument the  [2.x.4513]  option, such that also the inner cells use the corresponding manifold description to build the patches.
//
// Note that we could handle the higher order elements with the flag  [2.x.4514]  However, due to the limited compatibility to previous version of ParaView and the missing support by VisIt, we left this option for a future version.
//
[0.x.37957] 
[0.x.37958] 
[0.x.37959] 
[0.x.37960] 
[0.x.37961] 
[0.x.37962] 
//
[0.x.37963] 
//
[0.x.37964] 
[0.x.37965] 
[0.x.37966] 
//
[0.x.37967] 
[0.x.37968] 
[0.x.37969] 
[0.x.37970] 
[0.x.37971] 
[0.x.37972] 
//
[0.x.37973] 
[0.x.37974] 
[0.x.37975] 
//
[0.x.37976] 
[0.x.37977] 
[0.x.37978] 
[0.x.37979] 
[0.x.37980] 
//
[0.x.37981] 
[0.x.37982] 
//
//  [2.x.4515] 
//
// The last missing function of the solver class for the [1.x.128] is the run function. In the beginning we print information about the system specifications and the finite element space we use. The problem is solved several times on a successively refined mesh.
//
[0.x.37983] 
[0.x.37984] 
[0.x.37985] 
[0.x.37986] 
[0.x.37987] 
[0.x.37988] 
[0.x.37989] 
[0.x.37990] 
//
[0.x.37991] 
[0.x.37992] 
[0.x.37993] 
[0.x.37994] 
[0.x.37995] 
[0.x.37996] 
[0.x.37997] 
[0.x.37998] 
[0.x.37999] 
[0.x.38000] 
[0.x.38001] 
//
[0.x.38002] 
[0.x.38003] 
[0.x.38004] 
//
[0.x.38005] 
[0.x.38006] 
[0.x.38007] 
//
[0.x.38008] 
[0.x.38009] 
//
[0.x.38010] 
[0.x.38011] 
[0.x.38012] 
[0.x.38013] 
[0.x.38014] 
//
// The first task in actually solving the problem is to generate or refine the triangulation.
//
[0.x.38015] 
[0.x.38016] 
[0.x.38017] 
[0.x.38018] 
[0.x.38019] 
[0.x.38020] 
[0.x.38021] 
[0.x.38022] 
//
// Now we set up the system and solve the problem. These steps are accompanied by time measurement and textual output.
//
[0.x.38023] 
//
[0.x.38024] 
[0.x.38025] 
//
[0.x.38026] 
[0.x.38027] 
[0.x.38028] 
[0.x.38029] 
[0.x.38030] 
//
[0.x.38031] 
[0.x.38032] 
[0.x.38033] 
//
[0.x.38034] 
[0.x.38035] 
[0.x.38036] 
[0.x.38037] 
//
// After the problem was solved we compute the norm of the solution and generate the graphical output files.
//
[0.x.38038] 
[0.x.38039] 
[0.x.38040] 
//
[0.x.38041] 
[0.x.38042] 
//
// Finally after each cycle we print the timing information.
//
[0.x.38043] 
[0.x.38044] 
[0.x.38045] 
[0.x.38046] 
[0.x.38047] 
//
//  [2.x.4516] 
//
// As typical for programs running in parallel with MPI we set up the MPI framework and disable shared-memory parallelization by limiting the number of threads to one. Finally to run the solver for the [1.x.129] we create an object of the  [2.x.4517]  class and call the run function. Exemplarily we solve the problem once in 2D and once in 3D each with fourth-order Lagrangian finite elements.
//
[0.x.38048] 
[0.x.38049] 
[0.x.38050] 
[0.x.38051] 
[0.x.38052] 
//
[0.x.38053] 
//
[0.x.38054] 
[0.x.38055] 
[0.x.38056] 
[0.x.38057] 
//
[0.x.38058] 
[0.x.38059] 
[0.x.38060] 
[0.x.38061] 
[0.x.38062] 
[0.x.38063] 
[0.x.38064] 
[0.x.38065] 
[0.x.38066] 
[0.x.38067] 
[0.x.38068] 
[0.x.38069] 
[0.x.38070] 
[0.x.38071] 
[0.x.38072] 
[0.x.38073] 
[0.x.38074] 
[0.x.38075] 
[0.x.38076] 
[0.x.38077] 
[0.x.38078] 
[0.x.38079] 
[0.x.38080] 
[0.x.38081] 
[0.x.38082] 
[0.x.38083] 
[0.x.38084] 
[0.x.38085] 
[0.x.38086] 
[0.x.38087] 
//
[0.x.38088] 
[0.x.38089] 
[0.x.38090] 
[0.x.38091] 
[0.x.38092] 
[0.x.38093] 
[0.x.38094] 
[0.x.38095] 
[0.x.38096] 
[0.x.38097] 
[0.x.38098] 
[0.x.38099] 
[0.x.38100] 
[0.x.38101] 
[0.x.38102] 
[0.x.38103] 
//
[0.x.38104] 
[0.x.38105] 
[0.x.38106] 
//
// The include files are similar to the previous matrix-free tutorial programs  [2.x.4518] ,  [2.x.4519] , and  [2.x.4520] 
[0.x.38107] 
[0.x.38108] 
[0.x.38109] 
[0.x.38110] 
[0.x.38111] 
[0.x.38112] 
[0.x.38113] 
//
[0.x.38114] 
//
[0.x.38115] 
//
[0.x.38116] 
[0.x.38117] 
//
[0.x.38118] 
[0.x.38119] 
//
[0.x.38120] 
[0.x.38121] 
//
[0.x.38122] 
[0.x.38123] 
//
[0.x.38124] 
//
[0.x.38125] 
[0.x.38126] 
[0.x.38127] 
//
// The following file includes the CellwiseInverseMassMatrix data structure that we will use for the mass matrix inversion, the only new include file for this tutorial program:
//
[0.x.38128] 
//
[0.x.38129] 
[0.x.38130] 
[0.x.38131] 
//
// Similarly to the other matrix-free tutorial programs, we collect all parameters that control the execution of the program at the top of the file. Besides the dimension and polynomial degree we want to run with, we also specify a number of points in the Gaussian quadrature formula we want to use for the nonlinear terms in the Euler equations. Furthermore, we specify the time interval for the time-dependent problem, and implement two different test cases. The first one is an analytical solution in 2D, whereas the second is a channel flow around a cylinder as described in the introduction. Depending on the test case, we also change the final time up to which we run the simulation, and a variable `output_tick` that specifies in which intervals we want to write output (assuming that the tick is larger than the time step size).
//
[0.x.38132] 
[0.x.38133] 
[0.x.38134] 
[0.x.38135] 
[0.x.38136] 
//
[0.x.38137] 
//
[0.x.38138] 
[0.x.38139] 
[0.x.38140] 
//
// Next off are some details of the time integrator, namely a Courant number that scales the time step size in terms of the formula  [2.x.4521] , as well as a selection of a few low-storage Runge--Kutta methods. We specify the Courant number per stage of the Runge--Kutta scheme, as this gives a more realistic expression of the numerical cost for schemes of various numbers of stages.
//
[0.x.38141] 
[0.x.38142] 
[0.x.38143] 
[0.x.38144] 
[0.x.38145] 
[0.x.38146] 
[0.x.38147] 
[0.x.38148] 
[0.x.38149] 
//
// Eventually, we select a detail of the spatial discretization, namely the numerical flux (Riemann solver) at the faces between cells. For this program, we have implemented a modified variant of the Lax--Friedrichs flux and the Harten--Lax--van Leer (HLL) flux.
//
[0.x.38150] 
[0.x.38151] 
[0.x.38152] 
[0.x.38153] 
[0.x.38154] 
[0.x.38155] 
//
//  [2.x.4522] 
//
// We now define a class with the exact solution for the test case 0 and one with a background flow field for test case 1 of the channel. Given that the Euler equations are a problem with  [2.x.4523]  equations in  [2.x.4524]  dimensions, we need to tell the Function base class about the correct number of components.
//
[0.x.38156] 
[0.x.38157] 
[0.x.38158] 
[0.x.38159] 
[0.x.38160] 
[0.x.38161] 
[0.x.38162] 
//
[0.x.38163] 
[0.x.38164] 
[0.x.38165] 
//
// As far as the actual function implemented is concerned, the analytical test case is an isentropic vortex case (see e.g. the book by Hesthaven and Warburton, Example 6.1 in Section 6.6 on page 209) which fulfills the Euler equations with zero force term on the right hand side. Given that definition, we return either the density, the momentum, or the energy depending on which component is requested. Note that the original definition of the density involves the  [2.x.4525] -th power of some expression. Since  [2.x.4526]  has pretty slow implementations on some systems, we replace it by logarithm followed by exponentiation (of base 2), which is mathematically equivalent but usually much better optimized. This formula might lose accuracy in the last digits for very small numbers compared to  [2.x.4527]  but we are happy with it anyway, since small numbers map to data close to 1.
//
// For the channel test case, we simply select a density of 1, a velocity of 0.4 in  [2.x.4528]  direction and zero in the other directions, and an energy that corresponds to a speed of sound of 1.3 measured against the background velocity field, computed from the relation  [2.x.4529] .
//
[0.x.38166] 
[0.x.38167] 
[0.x.38168] 
[0.x.38169] 
[0.x.38170] 
//
[0.x.38171] 
[0.x.38172] 
[0.x.38173] 
[0.x.38174] 
[0.x.38175] 
[0.x.38176] 
//
[0.x.38177] 
[0.x.38178] 
[0.x.38179] 
[0.x.38180] 
[0.x.38181] 
[0.x.38182] 
[0.x.38183] 
[0.x.38184] 
[0.x.38185] 
[0.x.38186] 
[0.x.38187] 
//
[0.x.38188] 
[0.x.38189] 
[0.x.38190] 
[0.x.38191] 
[0.x.38192] 
[0.x.38193] 
[0.x.38194] 
[0.x.38195] 
[0.x.38196] 
[0.x.38197] 
[0.x.38198] 
[0.x.38199] 
[0.x.38200] 
[0.x.38201] 
//
[0.x.38202] 
[0.x.38203] 
[0.x.38204] 
[0.x.38205] 
[0.x.38206] 
[0.x.38207] 
[0.x.38208] 
[0.x.38209] 
[0.x.38210] 
[0.x.38211] 
[0.x.38212] 
//
[0.x.38213] 
[0.x.38214] 
[0.x.38215] 
[0.x.38216] 
[0.x.38217] 
//
//  [2.x.4530] 
//
// The next few lines implement a few low-storage variants of Runge--Kutta methods. These methods have specific Butcher tableaux with coefficients  [2.x.4531]  and  [2.x.4532]  as shown in the introduction. As usual in Runge--Kutta method, we can deduce time steps,  [2.x.4533]  from those coefficients. The main advantage of this kind of scheme is the fact that only two vectors are needed per stage, namely the accumulated part of the solution  [2.x.4534]  (that will hold the solution  [2.x.4535]  at the new time  [2.x.4536]  after the last stage), the update vector  [2.x.4537]  that gets evaluated during the stages, plus one vector  [2.x.4538]  to hold the evaluation of the operator. Such a Runge--Kutta setup reduces the memory storage and memory access. As the memory bandwidth is often the performance-limiting factor on modern hardware when the evaluation of the differential operator is well-optimized, performance can be improved over standard time integrators. This is true also when taking into account that a conventional Runge--Kutta scheme might allow for slightly larger time steps as more free parameters allow for better stability properties.
//
// In this tutorial programs, we concentrate on a few variants of low-storage schemes defined in the article by Kennedy, Carpenter, and Lewis (2000), as well as one variant described by Tselios and Simos (2007). There is a large series of other schemes available, which could be addressed by additional sets of coefficients or slightly different update formulas.
//
// We define a single class for the four integrators, distinguished by the enum described above. To each scheme, we then fill the vectors for the  [2.x.4539]  and  [2.x.4540]  to the given variables in the class.
//
[0.x.38218] 
[0.x.38219] 
[0.x.38220] 
[0.x.38221] 
[0.x.38222] 
[0.x.38223] 
//
// First comes the three-stage scheme of order three by Kennedy et al. (2000). While its stability region is significantly smaller than for the other schemes, it only involves three stages, so it is very competitive in terms of the work per stage.
//
[0.x.38224] 
[0.x.38225] 
[0.x.38226] 
[0.x.38227] 
[0.x.38228] 
[0.x.38229] 
[0.x.38230] 
//
//   The next scheme is a five-stage scheme of order four, again   defined in the paper by Kennedy et al. (2000).
//
[0.x.38231] 
[0.x.38232] 
[0.x.38233] 
[0.x.38234] 
[0.x.38235] 
//
//   The following scheme of seven stages and order four has been   explicitly derived for acoustics problems. It is a balance of   accuracy for imaginary eigenvalues among fourth order schemes,   combined with a large stability region. Since DG schemes are   dissipative among the highest frequencies, this does not   necessarily translate to the highest possible time step per   stage. In the context of the present tutorial program, the   numerical flux plays a crucial role in the dissipation and thus   also the maximal stable time step size. For the modified   Lax--Friedrichs flux, this scheme is similar to the   `stage_5_order_4` scheme in terms of step size per stage if only   stability is considered, but somewhat less efficient for the HLL   flux.
//
[0.x.38236] 
[0.x.38237] 
[0.x.38238] 
[0.x.38239] 
[0.x.38240] 
//
//   The last scheme included here is the nine-stage scheme of order   five from Kennedy et al. (2000). It is the most accurate among   the schemes used here, but the higher order of accuracy   sacrifices some stability, so the step length normalized per   stage is less than for the fourth order schemes.
//
[0.x.38241] 
[0.x.38242] 
[0.x.38243] 
[0.x.38244] 
[0.x.38245] 
//
[0.x.38246] 
[0.x.38247] 
[0.x.38248] 
[0.x.38249] 
[0.x.38250] 
[0.x.38251] 
[0.x.38252] 
[0.x.38253] 
//
[0.x.38254] 
[0.x.38255] 
[0.x.38256] 
[0.x.38257] 
//
// The main function of the time integrator is to go through the stages, evaluate the operator, prepare the  [2.x.4541]  vector for the next evaluation, and update the solution vector  [2.x.4542] . We hand off the work to the `pde_operator` involved in order to be able to merge the vector operations of the Runge--Kutta setup with the evaluation of the differential operator for better performance, so all we do here is to delegate the vectors and coefficients.
//
// We separately call the operator for the first stage because we need slightly modified arguments there: We evaluate the solution from the old solution  [2.x.4543]  rather than a  [2.x.4544]  vector, so the first argument is `solution`. We here let the stage vector  [2.x.4545]  also hold the temporary result of the evaluation, as it is not used otherwise. For all subsequent stages, we use the vector `vec_ki` as the second vector argument to store the result of the operator evaluation. Finally, when we are at the last stage, we must skip the computation of the vector  [2.x.4546]  as there is no coefficient  [2.x.4547]  available (nor will it be used).
//
[0.x.38258] 
[0.x.38259] 
[0.x.38260] 
[0.x.38261] 
[0.x.38262] 
[0.x.38263] 
[0.x.38264] 
[0.x.38265] 
[0.x.38266] 
//
[0.x.38267] 
[0.x.38268] 
[0.x.38269] 
[0.x.38270] 
[0.x.38271] 
[0.x.38272] 
[0.x.38273] 
//
[0.x.38274] 
[0.x.38275] 
[0.x.38276] 
[0.x.38277] 
[0.x.38278] 
[0.x.38279] 
[0.x.38280] 
[0.x.38281] 
[0.x.38282] 
[0.x.38283] 
[0.x.38284] 
[0.x.38285] 
[0.x.38286] 
[0.x.38287] 
//
[0.x.38288] 
[0.x.38289] 
[0.x.38290] 
[0.x.38291] 
[0.x.38292] 
//
//  [2.x.4548] 
//
// In the following functions, we implement the various problem-specific operators pertaining to the Euler equations. Each function acts on the vector of conserved variables  [2.x.4549]  that we hold in the solution vectors, and computes various derived quantities.
//
// First out is the computation of the velocity, that we derive from the momentum variable  [2.x.4550]  by division by  [2.x.4551] . One thing to note here is that we decorate all those functions with the keyword `DEAL_II_ALWAYS_INLINE`. This is a special macro that maps to a compiler-specific keyword that tells the compiler to never create a function call for any of those functions, and instead move the implementation [1.x.130] to where they are called. This is critical for performance because we call into some of those functions millions or billions of times: For example, we both use the velocity for the computation of the flux further down, but also for the computation of the pressure, and both of these places are evaluated at every quadrature point of every cell. Making sure these functions are inlined ensures not only that the processor does not have to execute a jump instruction into the function (and the corresponding return jump), but also that the compiler can re-use intermediate information from one function's context in code that comes after the place where the function was called. (We note that compilers are generally quite good at figuring out which functions to inline by themselves. Here is a place where compilers may or may not have figured it out by themselves but where we know for sure that inlining is a win.)
//
// Another trick we apply is a separate variable for the inverse density  [2.x.4552] . This enables the compiler to only perform a single division for the flux, despite the division being used at several places. As divisions are around ten to twenty times as expensive as multiplications or additions, avoiding redundant divisions is crucial for performance. We note that taking the inverse first and later multiplying with it is not equivalent to a division in floating point arithmetic due to roundoff effects, so the compiler is not allowed to exchange one way by the other with standard optimization flags. However, it is also not particularly difficult to write the code in the right way.
//
// To summarize, the chosen strategy of always inlining and careful definition of expensive arithmetic operations allows us to write compact code without passing all intermediate results around, despite making sure that the code maps to excellent machine code.
//
[0.x.38293] 
[0.x.38294] 
[0.x.38295] 
[0.x.38296] 
[0.x.38297] 
[0.x.38298] 
//
[0.x.38299] 
[0.x.38300] 
[0.x.38301] 
//
[0.x.38302] 
[0.x.38303] 
//
// The next function computes the pressure from the vector of conserved variables, using the formula  [2.x.4553] . As explained above, we use the velocity from the `euler_velocity()` function. Note that we need to specify the first template argument `dim` here because the compiler is not able to deduce it from the arguments of the tensor, whereas the second argument (number type) can be automatically deduced.
//
[0.x.38304] 
[0.x.38305] 
[0.x.38306] 
[0.x.38307] 
[0.x.38308] 
[0.x.38309] 
[0.x.38310] 
//
[0.x.38311] 
[0.x.38312] 
[0.x.38313] 
//
[0.x.38314] 
[0.x.38315] 
//
// Here is the definition of the Euler flux function, i.e., the definition of the actual equation. Given the velocity and pressure (that the compiler optimization will make sure are done only once), this is straight-forward given the equation stated in the introduction.
//
[0.x.38316] 
[0.x.38317] 
[0.x.38318] 
[0.x.38319] 
[0.x.38320] 
[0.x.38321] 
[0.x.38322] 
[0.x.38323] 
//
[0.x.38324] 
[0.x.38325] 
[0.x.38326] 
[0.x.38327] 
[0.x.38328] 
[0.x.38329] 
[0.x.38330] 
[0.x.38331] 
[0.x.38332] 
[0.x.38333] 
//
[0.x.38334] 
[0.x.38335] 
//
// This next function is a helper to simplify the implementation of the numerical flux, implementing the action of a tensor of tensors (with non-standard outer dimension of size `dim + 2`, so the standard overloads provided by deal.II's tensor classes do not apply here) with another tensor of the same inner dimension, i.e., a matrix-vector product.
//
[0.x.38336] 
[0.x.38337] 
[0.x.38338] 
[0.x.38339] 
[0.x.38340] 
[0.x.38341] 
[0.x.38342] 
[0.x.38343] 
[0.x.38344] 
[0.x.38345] 
[0.x.38346] 
//
// This function implements the numerical flux (Riemann solver). It gets the state from the two sides of an interface and the normal vector, oriented from the side of the solution  [2.x.4554]  towards the solution  [2.x.4555] . In finite volume methods which rely on piece-wise constant data, the numerical flux is the central ingredient as it is the only place where the physical information is entered. In DG methods, the numerical flux is less central due to the polynomials within the elements and the physical flux used there. As a result of higher-degree interpolation with consistent values from both sides in the limit of a continuous solution, the numerical flux can be seen as a control of the jump of the solution from both sides to weakly impose continuity. It is important to realize that a numerical flux alone cannot stabilize a high-order DG method in the presence of shocks, and thus any DG method must be combined with further shock-capturing techniques to handle those cases. In this tutorial, we focus on wave-like solutions of the Euler equations in the subsonic regime without strong discontinuities where our basic scheme is sufficient.
//
// Nonetheless, the numerical flux is decisive in terms of the numerical dissipation of the overall scheme and influences the admissible time step size with explicit Runge--Kutta methods. We consider two choices, a modified Lax--Friedrichs scheme and the widely used Harten--Lax--van Leer (HLL) flux. For both variants, we first need to get the velocities and pressures from both sides of the interface and evaluate the physical Euler flux.
//
// For the local Lax--Friedrichs flux, the definition is  [2.x.4556] , where the factor  [2.x.4557]  gives the maximal wave speed and  [2.x.4558]  is the speed of sound. Here, we choose two modifications of that expression for reasons of computational efficiency, given the small impact of the flux on the solution. For the above definition of the factor  [2.x.4559] , we would need to take four square roots, two for the two velocity norms and two for the speed of sound on either side. The first modification is hence to rather use  [2.x.4560]  as an estimate of the maximal speed (which is at most a factor of 2 away from the actual maximum, as shown in the introduction). This allows us to pull the square root out of the maximum and get away with a single square root computation. The second modification is to further relax on the parameter  [2.x.4561] ---the smaller it is, the smaller the dissipation factor (which is multiplied by the jump in  [2.x.4562] , which might result in a smaller or bigger dissipation in the end). This allows us to fit the spectrum into the stability region of the explicit Runge--Kutta integrator with bigger time steps. However, we cannot make dissipation too small because otherwise imaginary eigenvalues grow larger. Finally, the current conservative formulation is not energy-stable in the limit of  [2.x.4563]  as it is not skew-symmetric, and would need additional measures such as split-form DG schemes in that case.
//
// For the HLL flux, we follow the formula from literature, introducing an additional weighting of the two states from Lax--Friedrichs by a parameter  [2.x.4564] . It is derived from the physical transport directions of the Euler equations in terms of the current direction of velocity and sound speed. For the velocity, we here choose a simple arithmetic average which is sufficient for DG scenarios and moderate jumps in material parameters.
//
// Since the numerical flux is multiplied by the normal vector in the weak form, we multiply by the result by the normal vector for all terms in the equation. In these multiplications, the `operator*` defined above enables a compact notation similar to the mathematical definition.
//
// In this and the following functions, we use variable suffixes `_m` and `_p` to indicate quantities derived from  [2.x.4565]  and  [2.x.4566] , i.e., values "here" and "there" relative to the current cell when looking at a neighbor cell.
//
[0.x.38347] 
[0.x.38348] 
[0.x.38349] 
[0.x.38350] 
[0.x.38351] 
[0.x.38352] 
[0.x.38353] 
[0.x.38354] 
[0.x.38355] 
//
[0.x.38356] 
[0.x.38357] 
//
[0.x.38358] 
[0.x.38359] 
//
[0.x.38360] 
[0.x.38361] 
[0.x.38362] 
[0.x.38363] 
[0.x.38364] 
[0.x.38365] 
[0.x.38366] 
[0.x.38367] 
[0.x.38368] 
//
[0.x.38369] 
[0.x.38370] 
[0.x.38371] 
//
[0.x.38372] 
[0.x.38373] 
[0.x.38374] 
[0.x.38375] 
[0.x.38376] 
[0.x.38377] 
[0.x.38378] 
[0.x.38379] 
[0.x.38380] 
[0.x.38381] 
[0.x.38382] 
[0.x.38383] 
//
[0.x.38384] 
[0.x.38385] 
[0.x.38386] 
[0.x.38387] 
//
[0.x.38388] 
[0.x.38389] 
[0.x.38390] 
[0.x.38391] 
[0.x.38392] 
[0.x.38393] 
[0.x.38394] 
//
// This and the next function are helper functions to provide compact evaluation calls as multiple points get batched together via a VectorizedArray argument (see the  [2.x.4567]  tutorial for details). This function is used for the subsonic outflow boundary conditions where we need to set the energy component to a prescribed value. The next one requests the solution on all components and is used for inflow boundaries where all components of the solution are set.
//
[0.x.38395] 
[0.x.38396] 
[0.x.38397] 
[0.x.38398] 
[0.x.38399] 
[0.x.38400] 
[0.x.38401] 
[0.x.38402] 
[0.x.38403] 
[0.x.38404] 
[0.x.38405] 
[0.x.38406] 
[0.x.38407] 
[0.x.38408] 
[0.x.38409] 
[0.x.38410] 
//
[0.x.38411] 
[0.x.38412] 
[0.x.38413] 
[0.x.38414] 
[0.x.38415] 
[0.x.38416] 
[0.x.38417] 
[0.x.38418] 
[0.x.38419] 
[0.x.38420] 
[0.x.38421] 
[0.x.38422] 
[0.x.38423] 
[0.x.38424] 
[0.x.38425] 
[0.x.38426] 
[0.x.38427] 
//
//  [2.x.4568] 
//
// This class implements the evaluators for the Euler problem, in analogy to the `LaplaceOperator` class of  [2.x.4569]  or  [2.x.4570] . Since the present operator is non-linear and does not require a matrix interface (to be handed over to preconditioners), we skip the various `vmult` functions otherwise present in matrix-free operators and only implement an `apply` function as well as the combination of `apply` with the required vector updates for the low-storage Runge--Kutta time integrator mentioned above (called `perform_stage`). Furthermore, we have added three additional functions involving matrix-free routines, namely one to compute an estimate of the time step scaling (that is combined with the Courant number for the actual time step size) based on the velocity and speed of sound in the elements, one for the projection of solutions (specializing  [2.x.4571]  for the DG case), and one to compute the errors against a possible analytical solution or norms against some background state.
//
// The rest of the class is similar to other matrix-free tutorials. As discussed in the introduction, we provide a few functions to allow a user to pass in various forms of boundary conditions on different parts of the domain boundary marked by  [2.x.4572]  variables, as well as possible body forces.
//
[0.x.38428] 
[0.x.38429] 
[0.x.38430] 
[0.x.38431] 
[0.x.38432] 
//
[0.x.38433] 
//
[0.x.38434] 
[0.x.38435] 
//
[0.x.38436] 
[0.x.38437] 
//
[0.x.38438] 
[0.x.38439] 
[0.x.38440] 
//
[0.x.38441] 
//
[0.x.38442] 
//
[0.x.38443] 
[0.x.38444] 
[0.x.38445] 
//
[0.x.38446] 
[0.x.38447] 
[0.x.38448] 
[0.x.38449] 
[0.x.38450] 
[0.x.38451] 
[0.x.38452] 
[0.x.38453] 
//
[0.x.38454] 
[0.x.38455] 
//
[0.x.38456] 
[0.x.38457] 
[0.x.38458] 
//
[0.x.38459] 
[0.x.38460] 
//
[0.x.38461] 
[0.x.38462] 
//
[0.x.38463] 
[0.x.38464] 
//
[0.x.38465] 
//
[0.x.38466] 
[0.x.38467] 
[0.x.38468] 
[0.x.38469] 
[0.x.38470] 
[0.x.38471] 
//
[0.x.38472] 
[0.x.38473] 
[0.x.38474] 
[0.x.38475] 
[0.x.38476] 
//
[0.x.38477] 
[0.x.38478] 
[0.x.38479] 
[0.x.38480] 
[0.x.38481] 
//
[0.x.38482] 
[0.x.38483] 
[0.x.38484] 
[0.x.38485] 
[0.x.38486] 
//
[0.x.38487] 
[0.x.38488] 
[0.x.38489] 
[0.x.38490] 
[0.x.38491] 
[0.x.38492] 
//
[0.x.38493] 
[0.x.38494] 
[0.x.38495] 
[0.x.38496] 
//
// For the initialization of the Euler operator, we set up the MatrixFree variable contained in the class. This can be done given a mapping to describe possible curved boundaries as well as a DoFHandler object describing the degrees of freedom. Since we use a discontinuous Galerkin discretization in this tutorial program where no constraints are imposed strongly on the solution field, we do not need to pass in an AffineConstraints object and rather use a dummy for the construction. With respect to quadrature, we want to select two different ways of computing the underlying integrals: The first is a flexible one, based on a template parameter `n_points_1d` (that will be assigned the `n_q_points_1d` value specified at the top of this file). More accurate integration is necessary to avoid the aliasing problem due to the variable coefficients in the Euler operator. The second less accurate quadrature formula is a tight one based on `fe_degree+1` and needed for the inverse mass matrix. While that formula provides an exact inverse only on affine element shapes and not on deformed elements, it enables the fast inversion of the mass matrix by tensor product techniques, necessary to ensure optimal computational efficiency overall.
//
[0.x.38497] 
[0.x.38498] 
[0.x.38499] 
[0.x.38500] 
[0.x.38501] 
[0.x.38502] 
[0.x.38503] 
[0.x.38504] 
[0.x.38505] 
[0.x.38506] 
//
[0.x.38507] 
[0.x.38508] 
[0.x.38509] 
[0.x.38510] 
[0.x.38511] 
[0.x.38512] 
[0.x.38513] 
[0.x.38514] 
[0.x.38515] 
[0.x.38516] 
[0.x.38517] 
[0.x.38518] 
//
[0.x.38519] 
[0.x.38520] 
[0.x.38521] 
//
[0.x.38522] 
[0.x.38523] 
[0.x.38524] 
[0.x.38525] 
[0.x.38526] 
[0.x.38527] 
//
// The subsequent four member functions are the ones that must be called from outside to specify the various types of boundaries. For an inflow boundary, we must specify all components in terms of density  [2.x.4573] , momentum  [2.x.4574]  and energy  [2.x.4575] . Given this information, we then store the function alongside the respective boundary id in a map member variable of this class. Likewise, we proceed for the subsonic outflow boundaries (where we request a function as well, which we use to retrieve the energy) and for wall (no-penetration) boundaries where we impose zero normal velocity (no function necessary, so we only request the boundary id). For the present DG code where boundary conditions are solely applied as part of the weak form (during time integration), the call to set the boundary conditions can appear both before or after the `reinit()` call to this class. This is different from continuous finite element codes where the boundary conditions determine the content of the AffineConstraints object that is sent into MatrixFree for initialization, thus requiring to be set before the initialization of the matrix-free data structures.
//
// The checks added in each of the four function are used to ensure that boundary conditions are mutually exclusive on the various parts of the boundary, i.e., that a user does not accidentally designate a boundary as both an inflow and say a subsonic outflow boundary.
//
[0.x.38528] 
[0.x.38529] 
[0.x.38530] 
[0.x.38531] 
[0.x.38532] 
[0.x.38533] 
[0.x.38534] 
[0.x.38535] 
[0.x.38536] 
[0.x.38537] 
[0.x.38538] 
[0.x.38539] 
[0.x.38540] 
[0.x.38541] 
//
[0.x.38542] 
[0.x.38543] 
//
[0.x.38544] 
[0.x.38545] 
[0.x.38546] 
[0.x.38547] 
[0.x.38548] 
[0.x.38549] 
[0.x.38550] 
[0.x.38551] 
[0.x.38552] 
[0.x.38553] 
[0.x.38554] 
[0.x.38555] 
[0.x.38556] 
[0.x.38557] 
//
[0.x.38558] 
[0.x.38559] 
//
[0.x.38560] 
[0.x.38561] 
[0.x.38562] 
[0.x.38563] 
[0.x.38564] 
[0.x.38565] 
[0.x.38566] 
[0.x.38567] 
[0.x.38568] 
[0.x.38569] 
[0.x.38570] 
[0.x.38571] 
//
[0.x.38572] 
[0.x.38573] 
//
[0.x.38574] 
[0.x.38575] 
[0.x.38576] 
[0.x.38577] 
[0.x.38578] 
//
[0.x.38579] 
[0.x.38580] 
//
//  [2.x.4576] 
//
// Now we proceed to the local evaluators for the Euler problem. The evaluators are relatively simple and follow what has been presented in  [2.x.4577] ,  [2.x.4578] , or  [2.x.4579] . The first notable difference is the fact that we use an FEEvaluation with a non-standard number of quadrature points. Whereas we previously always set the number of quadrature points to equal the polynomial degree plus one (ensuring exact integration on affine element shapes), we now set the number quadrature points as a separate variable (e.g. the polynomial degree plus two or three halves of the polynomial degree) to more accurately handle nonlinear terms. Since the evaluator is fed with the appropriate loop lengths via the template argument and keeps the number of quadrature points in the whole cell in the variable  [2.x.4580]  we now automatically operate on the more accurate formula without further changes.
//
// The second difference is due to the fact that we are now evaluating a multi-component system, as opposed to the scalar systems considered previously. The matrix-free framework provides several ways to handle the multi-component case. The variant shown here utilizes an FEEvaluation object with multiple components embedded into it, specified by the fourth template argument `dim + 2` for the components in the Euler system. As a consequence, the return type of  [2.x.4581]  is not a scalar any more (that would return a VectorizedArray type, collecting data from several elements), but a Tensor of `dim+2` components. The functionality is otherwise similar to the scalar case; it is handled by a template specialization of a base class, called FEEvaluationAccess. An alternative variant would have been to use several FEEvaluation objects, a scalar one for the density, a vector-valued one with `dim` components for the momentum, and another scalar evaluator for the energy. To ensure that those components point to the correct part of the solution, the constructor of FEEvaluation takes three optional integer arguments after the required MatrixFree field, namely the number of the DoFHandler for multi-DoFHandler systems (taking the first by default), the number of the quadrature point in case there are multiple Quadrature objects (see more below), and as a third argument the component within a vector system. As we have a single vector for all components, we would go with the third argument, and set it to `0` for the density, `1` for the vector-valued momentum, and `dim+1` for the energy slot. FEEvaluation then picks the appropriate subrange of the solution vector during  [2.x.4582]  and  [2.x.4583]  or the more compact  [2.x.4584]  and  [2.x.4585]  calls.
//
// When it comes to the evaluation of the body force vector, we distinguish between two cases for efficiency reasons: In case we have a constant function (derived from  [2.x.4586]  we can precompute the value outside the loop over quadrature points and simply use the value everywhere. For a more general function, we instead need to call the `evaluate_function()` method we provided above; this path is more expensive because we need to access the memory associated with the quadrature point data.
//
// The rest follows the other tutorial programs. Since we have implemented all physics for the Euler equations in the separate `euler_flux()` function, all we have to do here is to call this function given the current solution evaluated at quadrature points, returned by `phi.get_value(q)`, and tell the FEEvaluation object to queue the flux for testing it by the gradients of the shape functions (which is a Tensor of outer `dim+2` components, each holding a tensor of `dim` components for the  [2.x.4587]  component of the Euler flux). One final thing worth mentioning is the order in which we queue the data for testing by the value of the test function, `phi.submit_value()`, in case we are given an external function: We must do this after calling `phi.get_value(q)`, because `get_value()` (reading the solution) and `submit_value()` (queuing the value for multiplication by the test function and summation over quadrature points) access the same underlying data field. Here it would be easy to achieve also without temporary variable `w_q` since there is no mixing between values and gradients. For more complicated setups, one has to first copy out e.g. both the value and gradient at a quadrature point and then queue results again by  [2.x.4588]  and  [2.x.4589] 
//
// As a final note, we mention that we do not use the first MatrixFree argument of this function, which is a call-back from  [2.x.4590]  The interfaces imposes the present list of arguments, but since we are in a member function where the MatrixFree object is already available as the `data` variable, we stick with that to avoid confusion.
//
[0.x.38581] 
[0.x.38582] 
[0.x.38583] 
[0.x.38584] 
[0.x.38585] 
[0.x.38586] 
[0.x.38587] 
[0.x.38588] 
//
[0.x.38589] 
[0.x.38590] 
[0.x.38591] 
//
[0.x.38592] 
[0.x.38593] 
[0.x.38594] 
//
[0.x.38595] 
[0.x.38596] 
[0.x.38597] 
[0.x.38598] 
//
[0.x.38599] 
[0.x.38600] 
[0.x.38601] 
[0.x.38602] 
[0.x.38603] 
[0.x.38604] 
[0.x.38605] 
[0.x.38606] 
[0.x.38607] 
[0.x.38608] 
//
[0.x.38609] 
[0.x.38610] 
[0.x.38611] 
[0.x.38612] 
[0.x.38613] 
//
[0.x.38614] 
[0.x.38615] 
[0.x.38616] 
//
[0.x.38617] 
[0.x.38618] 
[0.x.38619] 
[0.x.38620] 
[0.x.38621] 
[0.x.38622] 
[0.x.38623] 
//
// The next function concerns the computation of integrals on interior faces, where we need evaluators from both cells adjacent to the face. We associate the variable `phi_m` with the solution component  [2.x.4591]  and the variable `phi_p` with the solution component  [2.x.4592] . We distinguish the two sides in the constructor of FEFaceEvaluation by the second argument, with `true` for the interior side and `false` for the exterior side, with interior and exterior denoting the orientation with respect to the normal vector.
//
// Note that the calls  [2.x.4593]  and  [2.x.4594]  combine the access to the vectors and the sum factorization parts. This combined operation not only saves a line of code, but also contains an important optimization: Given that we use a nodal basis in terms of the Lagrange polynomials in the points of the Gauss-Lobatto quadrature formula, only  [2.x.4595]  out of the  [2.x.4596]  basis functions evaluate to non-zero on each face. Thus, the evaluator only accesses the necessary data in the vector and skips the parts which are multiplied by zero. If we had first read the vector, we would have needed to load all data from the vector, as the call in isolation would not know what data is required in subsequent operations. If the subsequent  [2.x.4597]  call requests values and derivatives, indeed all  [2.x.4598]  vector entries for each component are needed, as the normal derivative is nonzero for all basis functions.
//
// The arguments to the evaluators as well as the procedure is similar to the cell evaluation. We again use the more accurate (over-)integration scheme due to the nonlinear terms, specified as the third template argument in the list. At the quadrature points, we then go to our free-standing function for the numerical flux. It receives the solution evaluated at quadrature points from both sides (i.e.,  [2.x.4599]  and  [2.x.4600] ), as well as the normal vector onto the minus side. As explained above, the numerical flux is already multiplied by the normal vector from the minus side. We need to switch the sign because the boundary term comes with a minus sign in the weak form derived in the introduction. The flux is then queued for testing both on the minus sign and on the plus sign, with switched sign as the normal vector from the plus side is exactly opposed to the one from the minus side.
//
[0.x.38624] 
[0.x.38625] 
[0.x.38626] 
[0.x.38627] 
[0.x.38628] 
[0.x.38629] 
[0.x.38630] 
[0.x.38631] 
[0.x.38632] 
[0.x.38633] 
[0.x.38634] 
//
[0.x.38635] 
[0.x.38636] 
[0.x.38637] 
[0.x.38638] 
//
[0.x.38639] 
[0.x.38640] 
//
[0.x.38641] 
[0.x.38642] 
[0.x.38643] 
[0.x.38644] 
[0.x.38645] 
[0.x.38646] 
[0.x.38647] 
[0.x.38648] 
[0.x.38649] 
//
[0.x.38650] 
[0.x.38651] 
[0.x.38652] 
[0.x.38653] 
//
// For faces located at the boundary, we need to impose the appropriate boundary conditions. In this tutorial program, we implement four cases as mentioned above. (A fifth case, for supersonic outflow conditions is discussed in the "Results" section below.) The discontinuous Galerkin method imposes boundary conditions not as constraints, but only weakly. Thus, the various conditions are imposed by finding an appropriate [1.x.131] quantity  [2.x.4601]  that is then handed to the numerical flux function also used for the interior faces. In essence, we "pretend" a state on the outside of the domain in such a way that if that were reality, the solution of the PDE would satisfy the boundary conditions we want.
//
// For wall boundaries, we need to impose a no-normal-flux condition on the momentum variable, whereas we use a Neumann condition for the density and energy with  [2.x.4602]  and  [2.x.4603] . To achieve the no-normal flux condition, we set the exterior values to the interior values and subtract two times the velocity in wall-normal direction, i.e., in the direction of the normal vector.
//
// For inflow boundaries, we simply set the given Dirichlet data  [2.x.4604]  as a boundary value. An alternative would have been to use  [2.x.4605] , the so-called mirror principle.
//
// The imposition of outflow is essentially a Neumann condition, i.e., setting  [2.x.4606] . For the case of subsonic outflow, we still need to impose a value for the energy, which we derive from the respective function. A special step is needed for the case of [1.x.132], i.e., the case where there is a momentum flux into the domain on the Neumann portion. According to the literature (a fact that can be derived by appropriate energy arguments), we must switch to another variant of the flux on inflow parts, see Gravemeier, Comerford, Yoshihara, Ismail, Wall, "A novel formulation for Neumann inflow conditions in biomechanics", Int. J. Numer. Meth. Biomed. Eng., vol. 28 (2012). Here, the momentum term needs to be added once again, which corresponds to removing the flux contribution on the momentum variables. We do this in a post-processing step, and only for the case when we both are at an outflow boundary and the dot product between the normal vector and the momentum (or, equivalently, velocity) is negative. As we work on data of several quadrature points at once for SIMD vectorizations, we here need to explicitly loop over the array entries of the SIMD array.
//
// In the implementation below, we check for the various types of boundaries at the level of quadrature points. Of course, we could also have moved the decision out of the quadrature point loop and treat entire faces as of the same kind, which avoids some map/set lookups in the inner loop over quadrature points. However, the loss of efficiency is hardly noticeable, so we opt for the simpler code here. Also note that the final `else` clause will catch the case when some part of the boundary was not assigned any boundary condition via  [2.x.4607] 
[0.x.38654] 
[0.x.38655] 
[0.x.38656] 
[0.x.38657] 
[0.x.38658] 
[0.x.38659] 
[0.x.38660] 
[0.x.38661] 
//
[0.x.38662] 
[0.x.38663] 
[0.x.38664] 
[0.x.38665] 
//
[0.x.38666] 
[0.x.38667] 
[0.x.38668] 
[0.x.38669] 
//
[0.x.38670] 
[0.x.38671] 
[0.x.38672] 
//
[0.x.38673] 
//
[0.x.38674] 
[0.x.38675] 
[0.x.38676] 
[0.x.38677] 
[0.x.38678] 
[0.x.38679] 
[0.x.38680] 
[0.x.38681] 
[0.x.38682] 
[0.x.38683] 
[0.x.38684] 
[0.x.38685] 
[0.x.38686] 
[0.x.38687] 
[0.x.38688] 
[0.x.38689] 
[0.x.38690] 
[0.x.38691] 
[0.x.38692] 
[0.x.38693] 
[0.x.38694] 
[0.x.38695] 
[0.x.38696] 
[0.x.38697] 
[0.x.38698] 
[0.x.38699] 
[0.x.38700] 
[0.x.38701] 
[0.x.38702] 
//
[0.x.38703] 
//
[0.x.38704] 
[0.x.38705] 
[0.x.38706] 
[0.x.38707] 
[0.x.38708] 
[0.x.38709] 
[0.x.38710] 
//
[0.x.38711] 
[0.x.38712] 
//
[0.x.38713] 
[0.x.38714] 
[0.x.38715] 
//
// The next function implements the inverse mass matrix operation. The algorithms and rationale have been discussed extensively in the introduction, so we here limit ourselves to the technicalities of the  [2.x.4608]  class. It does similar operations as the forward evaluation of the mass matrix, except with a different interpolation matrix, representing the inverse  [2.x.4609]  factors. These represent a change of basis from the specified basis (in this case, the Lagrange basis in the points of the Gauss--Lobatto quadrature formula) to the Lagrange basis in the points of the Gauss quadrature formula. In the latter basis, we can apply the inverse of the point-wise `JxW` factor, i.e., the quadrature weight times the determinant of the Jacobian of the mapping from reference to real coordinates. Once this is done, the basis is changed back to the nodal Gauss-Lobatto basis again. All of these operations are done by the `apply()` function below. What we need to provide is the local fields to operate on (which we extract from the global vector by an FEEvaluation object) and write the results back to the destination vector of the mass matrix operation.
//
// One thing to note is that we added two integer arguments (that are optional) to the constructor of FEEvaluation, the first being 0 (selecting among the DoFHandler in multi-DoFHandler systems; here, we only have one) and the second being 1 to make the quadrature formula selection. As we use the quadrature formula 0 for the over-integration of nonlinear terms, we use the formula 1 with the default  [2.x.4610]  (or `fe_degree+1` in terms of the variable name) points for the mass matrix. This leads to square contributions to the mass matrix and ensures exact integration, as explained in the introduction.
//
[0.x.38716] 
[0.x.38717] 
[0.x.38718] 
[0.x.38719] 
[0.x.38720] 
[0.x.38721] 
[0.x.38722] 
[0.x.38723] 
[0.x.38724] 
[0.x.38725] 
//
[0.x.38726] 
[0.x.38727] 
[0.x.38728] 
[0.x.38729] 
//
[0.x.38730] 
//
[0.x.38731] 
[0.x.38732] 
[0.x.38733] 
//
//  [2.x.4611] 
//
// We now come to the function which implements the evaluation of the Euler operator as a whole, i.e.,  [2.x.4612] , calling into the local evaluators presented above. The steps should be clear from the previous code. One thing to note is that we need to adjust the time in the functions we have associated with the various parts of the boundary, in order to be consistent with the equation in case the boundary data is time-dependent. Then, we call  [2.x.4613]  to perform the cell and face integrals, including the necessary ghost data exchange in the `src` vector. The seventh argument to the function, `true`, specifies that we want to zero the `dst` vector as part of the loop, before we start accumulating integrals into it. This variant is preferred over explicitly calling `dst = 0.;` before the loop as the zeroing operation is done on a subrange of the vector in parts that are written by the integrals nearby. This enhances data locality and allows for caching, saving one roundtrip of vector data to main memory and enhancing performance. The last two arguments to the loop determine which data is exchanged: Since we only access the values of the shape functions one faces, typical of first-order hyperbolic problems, and since we have a nodal basis with nodes at the reference element surface, we only need to exchange those parts. This again saves precious memory bandwidth.
//
// Once the spatial operator  [2.x.4614]  is applied, we need to make a second round and apply the inverse mass matrix. Here, we call  [2.x.4615]  since only cell integrals appear. The cell loop is cheaper than the full loop as access only goes to the degrees of freedom associated with the locally owned cells, which is simply the locally owned degrees of freedom for DG discretizations. Thus, no ghost exchange is needed here.
//
// Around all these functions, we put timer scopes to record the computational time for statistics about the contributions of the various parts.
//
[0.x.38734] 
[0.x.38735] 
[0.x.38736] 
[0.x.38737] 
[0.x.38738] 
[0.x.38739] 
[0.x.38740] 
[0.x.38741] 
//
[0.x.38742] 
[0.x.38743] 
[0.x.38744] 
[0.x.38745] 
//
[0.x.38746] 
[0.x.38747] 
[0.x.38748] 
[0.x.38749] 
[0.x.38750] 
[0.x.38751] 
[0.x.38752] 
[0.x.38753] 
[0.x.38754] 
[0.x.38755] 
//
[0.x.38756] 
[0.x.38757] 
//
[0.x.38758] 
[0.x.38759] 
[0.x.38760] 
[0.x.38761] 
[0.x.38762] 
[0.x.38763] 
//
// Let us move to the function that does an entire stage of a Runge--Kutta update. It calls  [2.x.4616]  followed by some updates to the vectors, namely `next_ri = solution + factor_ai * k_i` and `solution += factor_solution * k_i`. Rather than performing these steps through the vector interfaces, we here present an alternative strategy that is faster on cache-based architectures. As the memory consumed by the vectors is often much larger than what fits into caches, the data has to effectively come from the slow RAM memory. The situation can be improved by loop fusion, i.e., performing both the updates to `next_ki` and `solution` within a single sweep. In that case, we would read the two vectors `rhs` and `solution` and write into `next_ki` and `solution`, compared to at least 4 reads and two writes in the baseline case. Here, we go one step further and perform the loop immediately when the mass matrix inversion has finished on a part of the vector.  [2.x.4617]  provides a mechanism to attach an  [2.x.4618]  both before the loop over cells first touches a vector entry (which we do not use here, but is e.g. used for zeroing the vector) and a second  [2.x.4619]  to be called after the loop last touches an entry. The callback is in form of a range over the given vector (in terms of the local index numbering in the MPI universe) that can be addressed by `local_element()` functions.
//
// For this second callback, we create a lambda that works on a range and write the respective update on this range. Ideally, we would add the `DEAL_II_OPENMP_SIMD_PRAGMA` before the local loop to suggest to the compiler to SIMD parallelize this loop (which means in practice that we ensure that there is no overlap, also called aliasing, between the index ranges of the pointers we use inside the loops). It turns out that at the time of this writing, GCC 7.2 fails to compile an OpenMP pragma inside a lambda function, so we comment this pragma out below. If your compiler is newer, you should be able to uncomment these lines again.
//
// Note that we select a different code path for the last Runge--Kutta stage when we do not need to update the `next_ri` vector. This strategy gives a considerable speedup. Whereas the inverse mass matrix and vector updates take more than 60% of the computational time with default vector updates on a 40-core machine, the percentage is around 35% with the more optimized variant. In other words, this is a speedup of around a third.
//
[0.x.38764] 
[0.x.38765] 
[0.x.38766] 
[0.x.38767] 
[0.x.38768] 
[0.x.38769] 
[0.x.38770] 
[0.x.38771] 
[0.x.38772] 
[0.x.38773] 
[0.x.38774] 
[0.x.38775] 
//
[0.x.38776] 
[0.x.38777] 
[0.x.38778] 
[0.x.38779] 
//
[0.x.38780] 
[0.x.38781] 
[0.x.38782] 
[0.x.38783] 
[0.x.38784] 
[0.x.38785] 
[0.x.38786] 
[0.x.38787] 
[0.x.38788] 
[0.x.38789] 
//
[0.x.38790] 
[0.x.38791] 
[0.x.38792] 
[0.x.38793] 
[0.x.38794] 
[0.x.38795] 
[0.x.38796] 
[0.x.38797] 
[0.x.38798] 
[0.x.38799] 
[0.x.38800] 
[0.x.38801] 
[0.x.38802] 
//
//              /* DEAL_II_OPENMP_SIMD_PRAGMA  [2.x.4620] 
[0.x.38803] 
[0.x.38804] 
[0.x.38805] 
[0.x.38806] 
[0.x.38807] 
[0.x.38808] 
[0.x.38809] 
[0.x.38810] 
[0.x.38811] 
//
//              /* DEAL_II_OPENMP_SIMD_PRAGMA  [2.x.4621] 
[0.x.38812] 
[0.x.38813] 
[0.x.38814] 
[0.x.38815] 
[0.x.38816] 
[0.x.38817] 
[0.x.38818] 
[0.x.38819] 
[0.x.38820] 
[0.x.38821] 
[0.x.38822] 
//
// Having discussed the implementation of the functions that deal with advancing the solution by one time step, let us now move to functions that implement other, ancillary operations. Specifically, these are functions that compute projections, evaluate errors, and compute the speed of information transport on a cell.
//
// The first of these functions is essentially equivalent to  [2.x.4622]  just much faster because it is specialized for DG elements where there is no need to set up and solve a linear system, as each element has independent basis functions. The reason why we show the code here, besides a small speedup of this non-critical operation, is that it shows additional functionality provided by  [2.x.4623] 
//
// The projection operation works as follows: If we denote the matrix of shape functions evaluated at quadrature points by  [2.x.4624] , the projection on cell  [2.x.4625]  is an operation of the form  [2.x.4626] , where  [2.x.4627]  is the diagonal matrix containing the determinant of the Jacobian times the quadrature weight (JxW),  [2.x.4628]  is the cell-wise mass matrix, and  [2.x.4629]  is the evaluation of the field to be projected onto quadrature points. (In reality the matrix  [2.x.4630]  has additional structure through the tensor product, as explained in the introduction.) This system can now equivalently be written as  [2.x.4631] . Now, the term  [2.x.4632]  and then  [2.x.4633]  cancel, resulting in the final expression  [2.x.4634] . This operation is implemented by  [2.x.4635]  The name is derived from the fact that this projection is simply the multiplication by  [2.x.4636] , a basis change from the nodal basis in the points of the Gaussian quadrature to the given finite element basis. Note that we call  [2.x.4637]  to write the result into the vector, overwriting previous content, rather than accumulating the results as typical in integration tasks -- we can do this because every vector entry has contributions from only a single cell for discontinuous Galerkin discretizations.
//
[0.x.38823] 
[0.x.38824] 
[0.x.38825] 
[0.x.38826] 
[0.x.38827] 
[0.x.38828] 
[0.x.38829] 
[0.x.38830] 
[0.x.38831] 
[0.x.38832] 
[0.x.38833] 
[0.x.38834] 
[0.x.38835] 
[0.x.38836] 
[0.x.38837] 
[0.x.38838] 
[0.x.38839] 
[0.x.38840] 
[0.x.38841] 
[0.x.38842] 
[0.x.38843] 
[0.x.38844] 
//
// The next function again repeats functionality also provided by the deal.II library, namely  [2.x.4638]  We here show the explicit code to highlight how the vectorization across several cells works and how to accumulate results via that interface: Recall that each [1.x.133] of the vectorized array holds data from a different cell. By the loop over all cell batches that are owned by the current MPI process, we could then fill a VectorizedArray of results; to obtain a global sum, we would need to further go on and sum across the entries in the SIMD array. However, such a procedure is not stable as the SIMD array could in fact not hold valid data for all its lanes. This happens when the number of locally owned cells is not a multiple of the SIMD width. To avoid invalid data, we must explicitly skip those invalid lanes when accessing the data. While one could imagine that we could make it work by simply setting the empty lanes to zero (and thus, not contribute to a sum), the situation is more complicated than that: What if we were to compute a velocity out of the momentum? Then, we would need to divide by the density, which is zero -- the result would consequently be NaN and contaminate the result. This trap is avoided by accumulating the results from the valid SIMD range as we loop through the cell batches, using the function  [2.x.4639]  to give us the number of lanes with valid data. It equals  [2.x.4640]  on most cells, but can be less on the last cell batch if the number of cells has a remainder compared to the SIMD width.
//
[0.x.38845] 
[0.x.38846] 
[0.x.38847] 
[0.x.38848] 
[0.x.38849] 
[0.x.38850] 
[0.x.38851] 
[0.x.38852] 
//
[0.x.38853] 
[0.x.38854] 
[0.x.38855] 
[0.x.38856] 
[0.x.38857] 
[0.x.38858] 
[0.x.38859] 
[0.x.38860] 
[0.x.38861] 
[0.x.38862] 
[0.x.38863] 
//
[0.x.38864] 
[0.x.38865] 
[0.x.38866] 
[0.x.38867] 
[0.x.38868] 
[0.x.38869] 
[0.x.38870] 
[0.x.38871] 
[0.x.38872] 
[0.x.38873] 
//
[0.x.38874] 
//
[0.x.38875] 
[0.x.38876] 
[0.x.38877] 
//
[0.x.38878] 
[0.x.38879] 
//
// This final function of the EulerOperator class is used to estimate the transport speed, scaled by the mesh size, that is relevant for setting the time step size in the explicit time integrator. In the Euler equations, there are two speeds of transport, namely the convective velocity  [2.x.4641]  and the propagation of sound waves with sound speed  [2.x.4642]  relative to the medium moving at velocity  [2.x.4643] .
//
// In the formula for the time step size, we are interested not by these absolute speeds, but by the amount of time it takes for information to cross a single cell. For information transported along with the medium,  [2.x.4644]  is scaled by the mesh size, so an estimate of the maximal velocity can be obtained by computing  [2.x.4645] , where  [2.x.4646]  is the Jacobian of the transformation from real to the reference domain. Note that  [2.x.4647]  returns the inverse and transpose Jacobian, representing the metric term from real to reference coordinates, so we do not need to transpose it again. We store this limit in the variable `convective_limit` in the code below.
//
// The sound propagation is isotropic, so we need to take mesh sizes in any direction into account. The appropriate mesh size scaling is then given by the minimal singular value of  [2.x.4648]  or, equivalently, the maximal singular value of  [2.x.4649] . Note that one could approximate this quantity by the minimal distance between vertices of a cell when ignoring curved cells. To get the maximal singular value of the Jacobian, the general strategy would be some LAPACK function. Since all we need here is an estimate, we can avoid the hassle of decomposing a tensor of VectorizedArray numbers into several matrices and go into an (expensive) eigenvalue function without vectorization, and instead use a few iterations (five in the code below) of the power method applied to  [2.x.4650] . The speed of convergence of this method depends on the ratio of the largest to the next largest eigenvalue and the initial guess, which is the vector of all ones. This might suggest that we get slow convergence on cells close to a cube shape where all lengths are almost the same. However, this slow convergence means that the result will sit between the two largest singular values, which both are close to the maximal value anyway. In all other cases, convergence will be quick. Thus, we can merely hardcode 5 iterations here and be confident that the result is good.
//
[0.x.38880] 
[0.x.38881] 
[0.x.38882] 
[0.x.38883] 
[0.x.38884] 
[0.x.38885] 
[0.x.38886] 
//
[0.x.38887] 
[0.x.38888] 
[0.x.38889] 
[0.x.38890] 
[0.x.38891] 
[0.x.38892] 
[0.x.38893] 
[0.x.38894] 
[0.x.38895] 
[0.x.38896] 
//
[0.x.38897] 
[0.x.38898] 
[0.x.38899] 
[0.x.38900] 
[0.x.38901] 
[0.x.38902] 
//
[0.x.38903] 
[0.x.38904] 
//
[0.x.38905] 
[0.x.38906] 
[0.x.38907] 
[0.x.38908] 
[0.x.38909] 
[0.x.38910] 
[0.x.38911] 
[0.x.38912] 
[0.x.38913] 
[0.x.38914] 
[0.x.38915] 
[0.x.38916] 
[0.x.38917] 
[0.x.38918] 
[0.x.38919] 
[0.x.38920] 
[0.x.38921] 
[0.x.38922] 
[0.x.38923] 
[0.x.38924] 
//
// Similarly to the previous function, we must make sure to accumulate speed only on the valid cells of a cell batch.
//
[0.x.38925] 
[0.x.38926] 
[0.x.38927] 
[0.x.38928] 
[0.x.38929] 
//
[0.x.38930] 
//
[0.x.38931] 
[0.x.38932] 
//
//  [2.x.4651] 
//
// This class combines the EulerOperator class with the time integrator and the usual global data structures such as FiniteElement and DoFHandler, to actually run the simulations of the Euler problem.
//
// The member variables are a triangulation, a finite element, a mapping (to create high-order curved surfaces, see e.g.  [2.x.4652] ), and a DoFHandler to describe the degrees of freedom. In addition, we keep an instance of the EulerOperator described above around, which will do all heavy lifting in terms of integrals, and some parameters for time integration like the current time or the time step size.
//
// Furthermore, we use a PostProcessor instance to write some additional information to the output file, in similarity to what was done in  [2.x.4653] . The interface of the DataPostprocessor class is intuitive, requiring us to provide information about what needs to be evaluated (typically only the values of the solution, except for the Schlieren plot that we only enable in 2D where it makes sense), and the names of what gets evaluated. Note that it would also be possible to extract most information by calculator tools within visualization programs such as ParaView, but it is so much more convenient to do it already when writing the output.
//
[0.x.38933] 
[0.x.38934] 
[0.x.38935] 
[0.x.38936] 
[0.x.38937] 
//
[0.x.38938] 
//
[0.x.38939] 
[0.x.38940] 
//
[0.x.38941] 
//
[0.x.38942] 
//
[0.x.38943] 
//
[0.x.38944] 
[0.x.38945] 
[0.x.38946] 
[0.x.38947] 
[0.x.38948] 
//
[0.x.38949] 
[0.x.38950] 
[0.x.38951] 
//
[0.x.38952] 
//
[0.x.38953] 
//
[0.x.38954] 
//
[0.x.38955] 
[0.x.38956] 
[0.x.38957] 
[0.x.38958] 
//
[0.x.38959] 
[0.x.38960] 
[0.x.38961] 
//
[0.x.38962] 
//
[0.x.38963] 
[0.x.38964] 
[0.x.38965] 
//
[0.x.38966] 
//
[0.x.38967] 
[0.x.38968] 
[0.x.38969] 
[0.x.38970] 
//
[0.x.38971] 
[0.x.38972] 
[0.x.38973] 
[0.x.38974] 
//
// For the main evaluation of the field variables, we first check that the lengths of the arrays equal the expected values (the lengths `2*dim+4` or `2*dim+5` are derived from the sizes of the names we specify in the get_names() function below). Then we loop over all evaluation points and fill the respective information: First we fill the primal solution variables of density  [2.x.4654] , momentum  [2.x.4655]  and energy  [2.x.4656] , then we compute the derived velocity  [2.x.4657] , the pressure  [2.x.4658] , the speed of sound  [2.x.4659] , as well as the Schlieren plot showing  [2.x.4660]  in case it is enabled. (See  [2.x.4661]  for another example where we create a Schlieren plot.)
//
[0.x.38975] 
[0.x.38976] 
[0.x.38977] 
[0.x.38978] 
[0.x.38979] 
[0.x.38980] 
//
[0.x.38981] 
[0.x.38982] 
[0.x.38983] 
//
[0.x.38984] 
[0.x.38985] 
[0.x.38986] 
[0.x.38987] 
[0.x.38988] 
[0.x.38989] 
//
[0.x.38990] 
[0.x.38991] 
[0.x.38992] 
[0.x.38993] 
[0.x.38994] 
//
[0.x.38995] 
[0.x.38996] 
[0.x.38997] 
//
[0.x.38998] 
[0.x.38999] 
[0.x.39000] 
[0.x.39001] 
//
[0.x.39002] 
[0.x.39003] 
[0.x.39004] 
[0.x.39005] 
[0.x.39006] 
//
[0.x.39007] 
[0.x.39008] 
[0.x.39009] 
[0.x.39010] 
[0.x.39011] 
[0.x.39012] 
[0.x.39013] 
[0.x.39014] 
//
[0.x.39015] 
[0.x.39016] 
//
[0.x.39017] 
[0.x.39018] 
//
// For the interpretation of quantities, we have scalar density, energy, pressure, speed of sound, and the Schlieren plot, and vectors for the momentum and the velocity.
//
[0.x.39019] 
[0.x.39020] 
[0.x.39021] 
[0.x.39022] 
[0.x.39023] 
[0.x.39024] 
[0.x.39025] 
[0.x.39026] 
[0.x.39027] 
[0.x.39028] 
[0.x.39029] 
//
[0.x.39030] 
[0.x.39031] 
[0.x.39032] 
//
[0.x.39033] 
[0.x.39034] 
//
// With respect to the necessary update flags, we only need the values for all quantities but the Schlieren plot, which is based on the density gradient.
//
[0.x.39035] 
[0.x.39036] 
[0.x.39037] 
[0.x.39038] 
[0.x.39039] 
[0.x.39040] 
[0.x.39041] 
[0.x.39042] 
//
// The constructor for this class is unsurprising: We set up a parallel triangulation based on the `MPI_COMM_WORLD` communicator, a vector finite element with `dim+2` components for density, momentum, and energy, a high-order mapping of the same degree as the underlying finite element, and initialize the time and time step to zero.
//
[0.x.39043] 
[0.x.39044] 
[0.x.39045] 
[0.x.39046] 
[0.x.39047] 
[0.x.39048] 
[0.x.39049] 
[0.x.39050] 
[0.x.39051] 
[0.x.39052] 
[0.x.39053] 
[0.x.39054] 
[0.x.39055] 
[0.x.39056] 
//
// As a mesh, this tutorial program implements two options, depending on the global variable `testcase`: For the analytical variant (`testcase==0`), the domain is  [2.x.4662] , with Dirichlet boundary conditions (inflow) all around the domain. For `testcase==1`, we set the domain to a cylinder in a rectangular box, derived from the flow past cylinder testcase for incompressible viscous flow by Sch&auml;fer and Turek (1996). Here, we have a larger variety of boundaries. The inflow part at the left of the channel is given the inflow type, for which we choose a constant inflow profile, whereas we set a subsonic outflow at the right. For the boundary around the cylinder (boundary id equal to 2) as well as the channel walls (boundary id equal to 3) we use the wall boundary type, which is no-normal flow. Furthermore, for the 3D cylinder we also add a gravity force in vertical direction. Having the base mesh in place (including the manifolds set by  [2.x.4663]  we can then perform the specified number of global refinements, create the unknown numbering from the DoFHandler, and hand the DoFHandler and Mapping objects to the initialization of the EulerOperator.
//
[0.x.39057] 
[0.x.39058] 
[0.x.39059] 
[0.x.39060] 
[0.x.39061] 
[0.x.39062] 
[0.x.39063] 
[0.x.39064] 
[0.x.39065] 
[0.x.39066] 
//
[0.x.39067] 
[0.x.39068] 
[0.x.39069] 
[0.x.39070] 
//
[0.x.39071] 
[0.x.39072] 
[0.x.39073] 
[0.x.39074] 
//
[0.x.39075] 
[0.x.39076] 
//
[0.x.39077] 
[0.x.39078] 
//
[0.x.39079] 
[0.x.39080] 
[0.x.39081] 
[0.x.39082] 
//
[0.x.39083] 
[0.x.39084] 
[0.x.39085] 
[0.x.39086] 
//
[0.x.39087] 
[0.x.39088] 
//
[0.x.39089] 
[0.x.39090] 
[0.x.39091] 
[0.x.39092] 
//
[0.x.39093] 
[0.x.39094] 
//
[0.x.39095] 
[0.x.39096] 
[0.x.39097] 
//
[0.x.39098] 
//
[0.x.39099] 
//
[0.x.39100] 
[0.x.39101] 
//
// In the following, we output some statistics about the problem. Because we often end up with quite large numbers of cells or degrees of freedom, we would like to print them with a comma to separate each set of three digits. This can be done via "locales", although the way this works is not particularly intuitive.  [2.x.4664]  explains this in slightly more detail.
//
[0.x.39102] 
[0.x.39103] 
[0.x.39104] 
[0.x.39105] 
[0.x.39106] 
[0.x.39107] 
[0.x.39108] 
[0.x.39109] 
[0.x.39110] 
//
// For output, we first let the Euler operator compute the errors of the numerical results. More precisely, we compute the error against the analytical result for the analytical solution case, whereas we compute the deviation against the background field with constant density and energy and constant velocity in  [2.x.4665]  direction for the second test case.
//
// The next step is to create output. This is similar to what is done in  [2.x.4666] : We let the postprocessor defined above control most of the output, except for the primal field that we write directly. For the analytical solution test case, we also perform another projection of the analytical solution and print the difference between that field and the numerical solution. Once we have defined all quantities to be written, we build the patches for output. Similarly to  [2.x.4667] , we create a high-order VTK output by setting the appropriate flag, which enables us to visualize fields of high polynomial degrees. Finally, we call the  [2.x.4668]  function to write the result to the given file name. This function uses special MPI parallel write facilities, which are typically more optimized for parallel file systems than the standard library's  [2.x.4669]  variants used in most other tutorial programs. A particularly nice feature of the `write_vtu_in_parallel()` function is the fact that it can combine output from all MPI ranks into a single file, making it unnecessary to have a central record of all such files (namely, the "pvtu" file).
//
// For parallel programs, it is often instructive to look at the partitioning of cells among processors. To this end, one can pass a vector of numbers to  [2.x.4670]  that contains as many entries as the current processor has active cells; these numbers should then be the rank of the processor that owns each of these cells. Such a vector could, for example, be obtained from  [2.x.4671]  On the other hand, on each MPI process, DataOut will only read those entries that correspond to locally owned cells, and these of course all have the same value: namely, the rank of the current process. What is in the remaining entries of the vector doesn't actually matter, and so we can just get away with a cheap trick: We just fill *all* values of the vector we give to  [2.x.4672]  with the rank of the current MPI process. The key is that on each process, only the entries corresponding to the locally owned cells will be read, ignoring the (wrong) values in other entries. The fact that every process submits a vector in which the correct subset of entries is correct is all that is necessary.
//
[0.x.39111] 
[0.x.39112] 
[0.x.39113] 
[0.x.39114] 
[0.x.39115] 
[0.x.39116] 
//
[0.x.39117] 
[0.x.39118] 
[0.x.39119] 
[0.x.39120] 
[0.x.39121] 
[0.x.39122] 
//
[0.x.39123] 
[0.x.39124] 
//
[0.x.39125] 
[0.x.39126] 
//
[0.x.39127] 
[0.x.39128] 
[0.x.39129] 
//
[0.x.39130] 
[0.x.39131] 
[0.x.39132] 
[0.x.39133] 
[0.x.39134] 
[0.x.39135] 
[0.x.39136] 
//
[0.x.39137] 
[0.x.39138] 
[0.x.39139] 
[0.x.39140] 
[0.x.39141] 
[0.x.39142] 
[0.x.39143] 
[0.x.39144] 
[0.x.39145] 
//
[0.x.39146] 
[0.x.39147] 
[0.x.39148] 
//
[0.x.39149] 
[0.x.39150] 
[0.x.39151] 
[0.x.39152] 
[0.x.39153] 
[0.x.39154] 
[0.x.39155] 
[0.x.39156] 
[0.x.39157] 
[0.x.39158] 
[0.x.39159] 
//
[0.x.39160] 
[0.x.39161] 
[0.x.39162] 
[0.x.39163] 
[0.x.39164] 
[0.x.39165] 
[0.x.39166] 
[0.x.39167] 
[0.x.39168] 
//
[0.x.39169] 
[0.x.39170] 
[0.x.39171] 
[0.x.39172] 
[0.x.39173] 
//
[0.x.39174] 
[0.x.39175] 
[0.x.39176] 
//
[0.x.39177] 
[0.x.39178] 
[0.x.39179] 
//
[0.x.39180] 
[0.x.39181] 
[0.x.39182] 
[0.x.39183] 
[0.x.39184] 
//
// The  [2.x.4673]  function puts all pieces together. It starts off by calling the function that creates the mesh and sets up data structures, and then initializing the time integrator and the two temporary vectors of the low-storage integrator. We call these vectors `rk_register_1` and `rk_register_2`, and use the first vector to represent the quantity  [2.x.4674]  and the second one for  [2.x.4675]  in the formulas for the Runge--Kutta scheme outlined in the introduction. Before we start the time loop, we compute the time step size by the  [2.x.4676]  function. For reasons of comparison, we compare the result obtained there with the minimal mesh size and print them to screen. For velocities and speeds of sound close to unity as in this tutorial program, the predicted effective mesh size will be close, but they could vary if scaling were different.
//
[0.x.39185] 
[0.x.39186] 
[0.x.39187] 
[0.x.39188] 
[0.x.39189] 
[0.x.39190] 
//
[0.x.39191] 
[0.x.39192] 
[0.x.39193] 
[0.x.39194] 
[0.x.39195] 
[0.x.39196] 
[0.x.39197] 
[0.x.39198] 
[0.x.39199] 
//
[0.x.39200] 
//
[0.x.39201] 
//
[0.x.39202] 
[0.x.39203] 
[0.x.39204] 
[0.x.39205] 
//
[0.x.39206] 
//
[0.x.39207] 
[0.x.39208] 
[0.x.39209] 
[0.x.39210] 
[0.x.39211] 
[0.x.39212] 
[0.x.39213] 
//
[0.x.39214] 
[0.x.39215] 
[0.x.39216] 
[0.x.39217] 
[0.x.39218] 
[0.x.39219] 
[0.x.39220] 
[0.x.39221] 
//
[0.x.39222] 
//
// Now we are ready to start the time loop, which we run until the time has reached the desired end time. Every 5 time steps, we compute a new estimate for the time step -- since the solution is nonlinear, it is most effective to adapt the value during the course of the simulation. In case the Courant number was chosen too aggressively, the simulation will typically blow up with time step NaN, so that is easy to detect here. One thing to note is that roundoff errors might propagate to the leading digits due to an interaction of slightly different time step selections that in turn lead to slightly different solutions. To decrease this sensitivity, it is common practice to round or truncate the time step size to a few digits, e.g. 3 in this case. In case the current time is near the prescribed 'tick' value for output (e.g. 0.02), we also write the output. After the end of the time loop, we summarize the computation by printing some statistics, which is mostly done by the  [2.x.4677]  function.
//
[0.x.39223] 
//
[0.x.39224] 
[0.x.39225] 
[0.x.39226] 
[0.x.39227] 
[0.x.39228] 
[0.x.39229] 
[0.x.39230] 
[0.x.39231] 
//
[0.x.39232] 
[0.x.39233] 
[0.x.39234] 
[0.x.39235] 
[0.x.39236] 
[0.x.39237] 
[0.x.39238] 
[0.x.39239] 
[0.x.39240] 
//
[0.x.39241] 
//
[0.x.39242] 
[0.x.39243] 
[0.x.39244] 
[0.x.39245] 
[0.x.39246] 
[0.x.39247] 
//
[0.x.39248] 
[0.x.39249] 
[0.x.39250] 
//
[0.x.39251] 
//
// The main() function is not surprising and follows what was done in all previous MPI programs: As we run an MPI program, we need to call `MPI_Init()` and `MPI_Finalize()`, which we do through the  [2.x.4678]  data structure. Note that we run the program only with MPI, and set the thread count to 1.
//
[0.x.39252] 
[0.x.39253] 
[0.x.39254] 
[0.x.39255] 
//
[0.x.39256] 
//
[0.x.39257] 
[0.x.39258] 
[0.x.39259] 
//
[0.x.39260] 
[0.x.39261] 
[0.x.39262] 
[0.x.39263] 
[0.x.39264] 
[0.x.39265] 
[0.x.39266] 
[0.x.39267] 
[0.x.39268] 
[0.x.39269] 
[0.x.39270] 
[0.x.39271] 
[0.x.39272] 
[0.x.39273] 
//
[0.x.39274] 
[0.x.39275] 
[0.x.39276] 
[0.x.39277] 
[0.x.39278] 
[0.x.39279] 
[0.x.39280] 
[0.x.39281] 
[0.x.39282] 
[0.x.39283] 
[0.x.39284] 
[0.x.39285] 
[0.x.39286] 
[0.x.39287] 
//
[0.x.39288] 
[0.x.39289] 
[0.x.39290] 
[0.x.39291] 
[0.x.39292] 
[0.x.39293] 
[0.x.39294] 
[0.x.39295] 
[0.x.39296] 
[0.x.39297] 
[0.x.39298] 
[0.x.39299] 
[0.x.39300] 
[0.x.39301] 
[0.x.39302] 
[0.x.39303] 
//
[0.x.39304] 
[0.x.39305] 
[0.x.39306] 
//[2.x.4679] 
[0.x.39307] 
[0.x.39308] 
[0.x.39309] 
[0.x.39310] 
[0.x.39311] 
[0.x.39312] 
//
[0.x.39313] 
[0.x.39314] 
[0.x.39315] 
//
[0.x.39316] 
[0.x.39317] 
//
[0.x.39318] 
[0.x.39319] 
[0.x.39320] 
//
[0.x.39321] 
[0.x.39322] 
//
[0.x.39323] 
[0.x.39324] 
//
[0.x.39325] 
[0.x.39326] 
//
// From the following include file we import the ParticleHandler class that allows you to manage a collection of particles (objects of type  [2.x.4680]  representing a collection of points with some attached properties (e.g., an id) floating on a  [2.x.4681]  The methods and classes in the namespace Particles allows one to easily implement Particle-In-Cell methods and particle tracing on distributed triangulations:
//
[0.x.39327] 
//
// We import the particles generator which allow us to insert the particles. In the present step, the particle are globally inserted using a non-matching hyper-shell triangulation:
//
[0.x.39328] 
//
// Since the particles do not form a triangulation, they have their own specific DataOut class which will enable us to write them to commonly used parallel vtu format (or any number of other file formats):
//
[0.x.39329] 
//
[0.x.39330] 
[0.x.39331] 
//
[0.x.39332] 
[0.x.39333] 
[0.x.39334] 
//[2.x.4682] 
//
// Similarly to what is done in  [2.x.4683] , we set up a class that holds all the parameters of our problem and derive it from the ParameterAcceptor class to simplify the management and creation of parameter files.
//
// The ParameterAcceptor paradigm requires all parameters to be writable by the ParameterAcceptor methods. In order to avoid bugs that would be very difficult to track down (such as writing things like `if (time = 0)` instead of `if(time == 0)`), we declare all the parameters in an external class, which is initialized before the actual `ParticleTracking` class, and pass it to the main class as a `const` reference.
//
// The constructor of the class is responsible for the connection between the members of this class and the corresponding entries in the ParameterHandler. Thanks to the use of the  [2.x.4684]  method, this connection is trivial, but requires all members of this class to be writable.
//
[0.x.39335] 
[0.x.39336] 
[0.x.39337] 
[0.x.39338] 
//
// This class consists largely of member variables that describe the details of the particle tracking simulation and its discretization. The following parameters are about where output should written to, the spatial discretization of the velocity (the default is  [2.x.4685] ), the time step and the output frequency (how many time steps should elapse before we generate graphical output again):
//
[0.x.39339] 
//
[0.x.39340] 
[0.x.39341] 
[0.x.39342] 
[0.x.39343] 
[0.x.39344] 
//
// We allow every grid to be refined independently. In this tutorial, no physics is resolved on the fluid grid, and its velocity is calculated analytically.
//
[0.x.39345] 
[0.x.39346] 
[0.x.39347] 
//
// There remains the task of declaring what run-time parameters we can accept in input files. Since we have a very limited number of parameters, all parameters are declared in the same section.
//
[0.x.39348] 
[0.x.39349] 
[0.x.39350] 
[0.x.39351] 
[0.x.39352] 
//
[0.x.39353] 
[0.x.39354] 
[0.x.39355] 
[0.x.39356] 
[0.x.39357] 
//
[0.x.39358] 
[0.x.39359] 
[0.x.39360] 
[0.x.39361] 
[0.x.39362] 
//
[0.x.39363] 
//
[0.x.39364] 
//
[0.x.39365] 
[0.x.39366] 
[0.x.39367] 
[0.x.39368] 
[0.x.39369] 
//
[0.x.39370] 
[0.x.39371] 
[0.x.39372] 
[0.x.39373] 
[0.x.39374] 
//
[0.x.39375] 
[0.x.39376] 
[0.x.39377] 
[0.x.39378] 
[0.x.39379] 
[0.x.39380] 
[0.x.39381] 
//
//  [2.x.4686] 
//
// The velocity profile is provided as a Function object. This function is hard-coded within the example.
//
[0.x.39382] 
[0.x.39383] 
[0.x.39384] 
[0.x.39385] 
[0.x.39386] 
[0.x.39387] 
[0.x.39388] 
//
[0.x.39389] 
[0.x.39390] 
[0.x.39391] 
//
// The velocity profile for the Rayleigh-Kothe vertex is time-dependent. Consequently, the current time in the simulation (t) must be gathered from the Function object.
//
[0.x.39392] 
[0.x.39393] 
[0.x.39394] 
[0.x.39395] 
[0.x.39396] 
[0.x.39397] 
//
[0.x.39398] 
[0.x.39399] 
[0.x.39400] 
//
[0.x.39401] 
[0.x.39402] 
[0.x.39403] 
[0.x.39404] 
[0.x.39405] 
[0.x.39406] 
[0.x.39407] 
//
//  [2.x.4687] 
//
// We are now ready to introduce the main class of our tutorial program.
//
[0.x.39408] 
[0.x.39409] 
[0.x.39410] 
[0.x.39411] 
[0.x.39412] 
[0.x.39413] 
[0.x.39414] 
//
[0.x.39415] 
//
// This function is responsible for the initial generation of the particles on top of the background grid.
//
[0.x.39416] 
//
// When the velocity profile is interpolated to the position of the particles, it must first be stored using degrees of freedom. Consequently, as is the case for other parallel case (e.g.  [2.x.4688] ) we initialize the degrees of freedom on the background grid.
//
[0.x.39417] 
//
// In one of the test cases, the function is mapped to the background grid and a finite element interpolation is used to calculate the velocity at the particle location. This function calculates the value of the function at the support point of the triangulation.
//
[0.x.39418] 
//
// The next two functions are responsible for carrying out step of explicit Euler time integration for the cases where the velocity field is interpolated at the positions of the particles or calculated analytically, respectively.
//
[0.x.39419] 
[0.x.39420] 
//
// The `cell_weight()` function indicates to the triangulation how much computational work is expected to happen on this cell, and consequently how the domain needs to be partitioned so that every MPI rank receives a roughly equal amount of work (potentially not an equal number of cells). While the function is called from the outside, it is connected to the corresponding signal from inside this class, therefore it can be `private`.
//
[0.x.39421] 
[0.x.39422] 
[0.x.39423] 
[0.x.39424] 
[0.x.39425] 
//
// The following two functions are responsible for outputting the simulation results for the particles and for the velocity profile on the background mesh, respectively.
//
[0.x.39426] 
[0.x.39427] 
//
// The private members of this class are similar to other parallel deal.II examples. The parameters are stored as a `const` member. It is important to note that we keep the `Vortex` class as a member since its time must be modified as the simulation proceeds.
//
[0.x.39428] 
//
[0.x.39429] 
[0.x.39430] 
[0.x.39431] 
//
[0.x.39432] 
[0.x.39433] 
[0.x.39434] 
[0.x.39435] 
//
[0.x.39436] 
//
[0.x.39437] 
//
[0.x.39438] 
[0.x.39439] 
//
//  [2.x.4689] 
//[2.x.4690] 
//
// The constructors and destructors are rather trivial. They are very similar to what is done in  [2.x.4691] . We set the processors we want to work on to all machines available (`MPI_COMM_WORLD`) and initialize the  [2.x.4692]  variable to only allow processor zero to output anything to the standard output.
//
[0.x.39440] 
[0.x.39441] 
[0.x.39442] 
[0.x.39443] 
[0.x.39444] 
[0.x.39445] 
[0.x.39446] 
[0.x.39447] 
[0.x.39448] 
[0.x.39449] 
//
[0.x.39450] 
//
//  [2.x.4693] 
//
// This function is the key component that allow us to dynamically balance the computational load for this example. The function attributes a weight to every cell that represents the computational work on this cell. Here the majority of work is expected to happen on the particles, therefore the return value of this function (representing "work for this cell") is calculated based on the number of particles in the current cell. The function is connected to the cell_weight() signal inside the triangulation, and will be called once per cell, whenever the triangulation repartitions the domain between ranks (the connection is created inside the generate_particles() function of this class).
//
[0.x.39451] 
[0.x.39452] 
[0.x.39453] 
[0.x.39454] 
[0.x.39455] 
[0.x.39456] 
[0.x.39457] 
//
// We do not assign any weight to cells we do not own (i.e., artificial or ghost cells)
//
[0.x.39458] 
[0.x.39459] 
//
// This determines how important particle work is compared to cell work (by default every cell has a weight of 1000). We set the weight per particle much higher to indicate that the particle load is the only one that is important to distribute the cells in this example. The optimal value of this number depends on the application and can range from 0 (cheap particle operations, expensive cell operations) to much larger than 1000 (expensive particle operations, cheap cell operations, like presumed in this example).
//
[0.x.39460] 
//
// This example does not use adaptive refinement, therefore every cell should have the status `CELL_PERSIST`. However this function can also be used to distribute load during refinement, therefore we consider refined or coarsened cells as well.
//
[0.x.39461] 
[0.x.39462] 
[0.x.39463] 
[0.x.39464] 
[0.x.39465] 
[0.x.39466] 
[0.x.39467] 
[0.x.39468] 
[0.x.39469] 
[0.x.39470] 
//
[0.x.39471] 
[0.x.39472] 
[0.x.39473] 
[0.x.39474] 
//
[0.x.39475] 
[0.x.39476] 
//
[0.x.39477] 
[0.x.39478] 
[0.x.39479] 
//
//  [2.x.4694] 
//
// This function generates the tracer particles and the background triangulation on which these particles evolve.
//
[0.x.39480] 
[0.x.39481] 
[0.x.39482] 
//
// We create a hyper cube triangulation which we globally refine. This triangulation covers the full trajectory of the particles.
//
[0.x.39483] 
[0.x.39484] 
//
// In order to consider the particles when repartitioning the triangulation the algorithm needs to know three things:
//
// 1. How much weight to assign to each cell (how many particles are in there); 2. How to pack the particles before shipping data around; 3. How to unpack the particles after repartitioning.
//
// We attach the correct functions to the signals inside  [2.x.4695]  These signal will be called every time the repartition() function is called. These connections only need to be created once, so we might as well have set them up in the constructor of this class, but for the purpose of this example we want to group the particle related instructions.
//
[0.x.39485] 
[0.x.39486] 
[0.x.39487] 
[0.x.39488] 
[0.x.39489] 
[0.x.39490] 
//
[0.x.39491] 
[0.x.39492] 
//
[0.x.39493] 
[0.x.39494] 
//
// This initializes the background triangulation where the particles are living and the number of properties of the particles.
//
[0.x.39495] 
//
// We create a particle triangulation which is solely used to generate the points which will be used to insert the particles. This triangulation is a hyper shell which is offset from the center of the simulation domain. This will be used to generate a disk filled with particles which will allow an easy monitoring of the motion due to the vortex.
//
[0.x.39496] 
[0.x.39497] 
[0.x.39498] 
[0.x.39499] 
[0.x.39500] 
//
[0.x.39501] 
[0.x.39502] 
//
[0.x.39503] 
[0.x.39504] 
//
[0.x.39505] 
[0.x.39506] 
[0.x.39507] 
//
// We generate the necessary bounding boxes for the particles generator. These bounding boxes are required to quickly identify in which process's subdomain the inserted particle lies, and which cell owns it.
//
[0.x.39508] 
[0.x.39509] 
[0.x.39510] 
[0.x.39511] 
//
// We generate an empty vector of properties. We will attribute the properties to the particles once they are generated.
//
[0.x.39512] 
[0.x.39513] 
[0.x.39514] 
//
// We generate the particles at the position of a single point quadrature. Consequently, one particle will be generated at the centroid of each cell.
//
[0.x.39515] 
[0.x.39516] 
[0.x.39517] 
[0.x.39518] 
[0.x.39519] 
[0.x.39520] 
//
[0.x.39521] 
[0.x.39522] 
[0.x.39523] 
//
//  [2.x.4696] 
//
// This function sets up the background degrees of freedom used for the velocity interpolation and allocates the field vector where the entire solution of the velocity field is stored.
//
[0.x.39524] 
[0.x.39525] 
[0.x.39526] 
[0.x.39527] 
[0.x.39528] 
[0.x.39529] 
[0.x.39530] 
//
[0.x.39531] 
[0.x.39532] 
[0.x.39533] 
[0.x.39534] 
//
// This function takes care of interpolating the vortex velocity field to the field vector. This is achieved rather easily by using the  [2.x.4697]  function.
//
[0.x.39535] 
[0.x.39536] 
[0.x.39537] 
[0.x.39538] 
[0.x.39539] 
[0.x.39540] 
[0.x.39541] 
//
//  [2.x.4698] 
//
// We integrate the particle trajectories using an analytically defined velocity field. This demonstrates a relatively trivial usage of the particles.
//
[0.x.39542] 
[0.x.39543] 
[0.x.39544] 
[0.x.39545] 
[0.x.39546] 
[0.x.39547] 
//
// Looping over all particles in the domain using a particle iterator
//
[0.x.39548] 
[0.x.39549] 
//
// We calculate the velocity of the particles using their current location.
//
[0.x.39550] 
[0.x.39551] 
//
// This updates the position of the particles and sets the old position equal to the new position of the particle.
//
[0.x.39552] 
[0.x.39553] 
//
[0.x.39554] 
//
// We store the processor id (a scalar) and the particle velocity (a vector) in the particle properties. In this example, this is done purely for visualization purposes.
//
[0.x.39555] 
[0.x.39556] 
[0.x.39557] 
[0.x.39558] 
[0.x.39559] 
[0.x.39560] 
//
// In contrast to the previous function in this function we integrate the particle trajectories by interpolating the value of the velocity field at the degrees of freedom to the position of the particles.
//
[0.x.39561] 
[0.x.39562] 
[0.x.39563] 
[0.x.39564] 
//
// We loop over all the local particles. Although this could be achieved directly by looping over all the cells, this would force us to loop over numerous cells which do not contain particles. Rather, we loop over all the particles, but, we get the reference of the cell in which the particle lies and then loop over all particles within that cell. This enables us to gather the values of the velocity out of the `velocity_field` vector once and use them for all particles that lie within the cell.
//
[0.x.39565] 
[0.x.39566] 
[0.x.39567] 
[0.x.39568] 
[0.x.39569] 
[0.x.39570] 
[0.x.39571] 
//
[0.x.39572] 
//
// Next, compute the velocity at the particle locations by evaluating the finite element solution at the position of the particles. This is essentially an optimized version of the particle advection functionality in step 19, but instead of creating quadrature objects and FEValues objects for each cell, we do the evaluation by hand, which is somewhat more efficient and only matters for this tutorial, because the particle work is the dominant cost of the whole program.
//
[0.x.39573] 
[0.x.39574] 
[0.x.39575] 
[0.x.39576] 
[0.x.39577] 
[0.x.39578] 
[0.x.39579] 
[0.x.39580] 
[0.x.39581] 
//
[0.x.39582] 
[0.x.39583] 
[0.x.39584] 
[0.x.39585] 
//
[0.x.39586] 
[0.x.39587] 
[0.x.39588] 
[0.x.39589] 
//
//   Again, we store the particle velocity and the processor id in the   particle properties for visualization purposes.
//
[0.x.39590] 
[0.x.39591] 
[0.x.39592] 
//
[0.x.39593] 
[0.x.39594] 
//
[0.x.39595] 
[0.x.39596] 
[0.x.39597] 
[0.x.39598] 
//
//  [2.x.4699] 
//
// The next two functions take care of writing both the particles and the background mesh to vtu with a pvtu record. This ensures that the simulation results can be visualized when the simulation is launched in parallel.
//
[0.x.39599] 
[0.x.39600] 
[0.x.39601] 
[0.x.39602] 
//
[0.x.39603] 
[0.x.39604] 
//
[0.x.39605] 
[0.x.39606] 
[0.x.39607] 
[0.x.39608] 
[0.x.39609] 
//
[0.x.39610] 
[0.x.39611] 
[0.x.39612] 
[0.x.39613] 
[0.x.39614] 
[0.x.39615] 
[0.x.39616] 
//
[0.x.39617] 
[0.x.39618] 
//
[0.x.39619] 
[0.x.39620] 
[0.x.39621] 
//
[0.x.39622] 
[0.x.39623] 
[0.x.39624] 
[0.x.39625] 
[0.x.39626] 
[0.x.39627] 
[0.x.39628] 
//
[0.x.39629] 
//
// Attach the solution data to data_out object
//
[0.x.39630] 
[0.x.39631] 
[0.x.39632] 
[0.x.39633] 
[0.x.39634] 
[0.x.39635] 
[0.x.39636] 
[0.x.39637] 
[0.x.39638] 
//
[0.x.39639] 
//
[0.x.39640] 
[0.x.39641] 
//
[0.x.39642] 
[0.x.39643] 
//
[0.x.39644] 
[0.x.39645] 
[0.x.39646] 
//
//  [2.x.4700]  This function orchestrates the entire simulation. It is very similar to the other time dependent tutorial programs -- take  [2.x.4701]  or  [2.x.4702]  as an example. Note that we use the DiscreteTime class to monitor the time, the time-step and the  [2.x.4703] number. This function is relatively straightforward.
//
[0.x.39647] 
[0.x.39648] 
[0.x.39649] 
[0.x.39650] 
//
[0.x.39651] 
//
[0.x.39652] 
[0.x.39653] 
[0.x.39654] 
//
// We set the initial property of the particles by doing an explicit Euler iteration with a time-step of 0 both in the case of the analytical and the interpolated approach.
//
[0.x.39655] 
[0.x.39656] 
[0.x.39657] 
[0.x.39658] 
[0.x.39659] 
[0.x.39660] 
[0.x.39661] 
[0.x.39662] 
//
[0.x.39663] 
[0.x.39664] 
[0.x.39665] 
//
// The particles are advected by looping over time.
//
[0.x.39666] 
[0.x.39667] 
[0.x.39668] 
[0.x.39669] 
//
[0.x.39670] 
[0.x.39671] 
[0.x.39672] 
[0.x.39673] 
[0.x.39674] 
[0.x.39675] 
//
[0.x.39676] 
[0.x.39677] 
[0.x.39678] 
[0.x.39679] 
[0.x.39680] 
[0.x.39681] 
[0.x.39682] 
//
// After the particles have been moved, it is necessary to identify in which cell they now reside. This is achieved by calling  [2.x.4704] 
[0.x.39683] 
//
[0.x.39684] 
[0.x.39685] 
[0.x.39686] 
[0.x.39687] 
[0.x.39688] 
[0.x.39689] 
[0.x.39690] 
[0.x.39691] 
//
[0.x.39692] 
//
//  [2.x.4705] 
//
// The remainder of the code, the `main()` function, is standard. We note that we run the particle tracking with the analytical velocity and the interpolated velocity and produce both results
//
[0.x.39693] 
[0.x.39694] 
[0.x.39695] 
[0.x.39696] 
[0.x.39697] 
//
[0.x.39698] 
[0.x.39699] 
[0.x.39700] 
//
[0.x.39701] 
[0.x.39702] 
[0.x.39703] 
[0.x.39704] 
[0.x.39705] 
//
[0.x.39706] 
[0.x.39707] 
[0.x.39708] 
[0.x.39709] 
[0.x.39710] 
[0.x.39711] 
[0.x.39712] 
[0.x.39713] 
[0.x.39714] 
[0.x.39715] 
[0.x.39716] 
[0.x.39717] 
[0.x.39718] 
[0.x.39719] 
[0.x.39720] 
[0.x.39721] 
[0.x.39722] 
[0.x.39723] 
[0.x.39724] 
[0.x.39725] 
[0.x.39726] 
[0.x.39727] 
//
[0.x.39728] 
[0.x.39729] 
[0.x.39730] 
[0.x.39731] 
[0.x.39732] 
[0.x.39733] 
[0.x.39734] 
[0.x.39735] 
[0.x.39736] 
[0.x.39737] 
[0.x.39738] 
[0.x.39739] 
[0.x.39740] 
[0.x.39741] 
//
[0.x.39742] 
[0.x.39743] 
[0.x.39744] 
[0.x.39745] 
[0.x.39746] 
[0.x.39747] 
[0.x.39748] 
[0.x.39749] 
[0.x.39750] 
[0.x.39751] 
[0.x.39752] 
[0.x.39753] 
[0.x.39754] 
[0.x.39755] 
[0.x.39756] 
[0.x.39757] 
//
[0.x.39758] 
[0.x.39759] 
[0.x.39760] 
[0.x.39761] 
[0.x.39762] 
[0.x.39763] 
[0.x.39764] 
[0.x.39765] 
[0.x.39766] 
[0.x.39767] 
[0.x.39768] 
[0.x.39769] 
[0.x.39770] 
//[2.x.4706] 
//
// The set of include files is quite standard. The most intriguing part is the fact that we will rely solely on deal.II data structures for MPI parallelization, in particular  [2.x.4707]  and  [2.x.4708]  included through  [2.x.4709]  and  [2.x.4710] . Instead of a Trilinos, or PETSc specific matrix class, we will use a non-distributed  [2.x.4711]  ( [2.x.4712] ) to store the local part of the  [2.x.4713] ,  [2.x.4714]  and  [2.x.4715]  matrices.
//
[0.x.39771] 
[0.x.39772] 
[0.x.39773] 
[0.x.39774] 
[0.x.39775] 
[0.x.39776] 
[0.x.39777] 
//
[0.x.39778] 
//
[0.x.39779] 
[0.x.39780] 
[0.x.39781] 
//
[0.x.39782] 
[0.x.39783] 
[0.x.39784] 
[0.x.39785] 
[0.x.39786] 
//
[0.x.39787] 
[0.x.39788] 
//
[0.x.39789] 
[0.x.39790] 
[0.x.39791] 
[0.x.39792] 
[0.x.39793] 
//
[0.x.39794] 
//
[0.x.39795] 
[0.x.39796] 
//
// In addition to above deal.II specific includes, we also include four boost headers. The first two are for binary archives that we will use for implementing a check-pointing and restart mechanism.
//
[0.x.39797] 
[0.x.39798] 
//
// The last two header files are for creating custom iterator ranges over integer intervals.
//
[0.x.39799] 
[0.x.39800] 
//
// For  [2.x.4716] 
//[2.x.4717] 
//[2.x.4718] 
//[2.x.4719]  and  [2.x.4720] 
[0.x.39801] 
[0.x.39802] 
[0.x.39803] 
//[2.x.4721] 
//
// We begin our actual implementation by declaring all classes with their data structures and methods upfront. In contrast to previous example steps we use a more fine-grained encapsulation of concepts, data structures, and parameters into individual classes. A single class thus usually centers around either a single data structure (such as the Triangulation) in the  [2.x.4722]  class, or a single method (such as the  [2.x.4723]  function of the  [2.x.4724]  class). We typically declare parameter variables and scratch data object `private` and make methods and data structures used by other classes `public`.
//
//  [2.x.4725]  A cleaner approach would be to guard access to all data structures by [1.x.134]. For the sake of brevity, we refrain from that approach, though.
//
// We also note that the vast majority of classes is derived from ParameterAcceptor. This facilitates the population of all the global parameters into a single (global) ParameterHandler. More explanations about the use of inheritance from ParameterAcceptor as a global subscription mechanism can be found in  [2.x.4726] .
//
[0.x.39804] 
[0.x.39805] 
[0.x.39806] 
//
// We start with defining a number of  [2.x.4727]  constants used throughout the tutorial step. This allows us to refer to boundary types by a mnemonic (such as  [2.x.4728] ) rather than a numerical value.
//
[0.x.39807] 
[0.x.39808] 
[0.x.39809] 
[0.x.39810] 
[0.x.39811] 
[0.x.39812] 
//[2.x.4729] 
//
// The class  [2.x.4730]  contains all data structures concerning the mesh (triangulation) and discretization (mapping, finite element, quadrature) of the problem. As mentioned, we use the ParameterAcceptor class to automatically populate problem-specific parameters, such as the geometry information ( [2.x.4731] , etc.) or the refinement level ( [2.x.4732] ) from a parameter file. This requires us to split the initialization of data structures into two functions: We initialize everything that does not depend on parameters in the constructor, and defer the creation of the mesh to the  [2.x.4733]  method that can be called once all parameters are read in via  [2.x.4734] 
[0.x.39813] 
[0.x.39814] 
[0.x.39815] 
[0.x.39816] 
[0.x.39817] 
[0.x.39818] 
[0.x.39819] 
//
[0.x.39820] 
//
[0.x.39821] 
//
[0.x.39822] 
//
[0.x.39823] 
[0.x.39824] 
[0.x.39825] 
[0.x.39826] 
//
[0.x.39827] 
[0.x.39828] 
//
[0.x.39829] 
[0.x.39830] 
[0.x.39831] 
[0.x.39832] 
//
[0.x.39833] 
[0.x.39834] 
//[2.x.4735] 
//
// The class  [2.x.4736]  contains pretty much all components of the discretization that do not evolve in time, in particular, the DoFHandler, SparsityPattern, boundary maps, the lumped mass matrix,  [2.x.4737]  and  [2.x.4738]  matrices. Here, the term [1.x.135] refers to the fact that all the class members of  [2.x.4739]  have well-defined values independent of the current time step. This means that they can be initialized ahead of time (at [1.x.136]) and are not meant to be modified at any later time step. For instance, the sparsity pattern should not change as we advance in time (we are not doing any form of adaptivity in space). Similarly, the entries of the lumped mass matrix should not be modified as we advance in time either.
//
// We also compute and store a  [2.x.4740]  that contains a map from a global index of type  [2.x.4741]  of a boundary degree of freedom to a tuple consisting of a normal vector, the boundary id, and the position associated with the degree of freedom. We have to compute and store this geometric information in this class because we won't have access to geometric (or cell-based) information later on in the algebraic loops over the sparsity pattern.
//
//  [2.x.4742]  Even though this class currently does not have any parameters that could be read in from a parameter file we nevertheless derive from ParameterAcceptor and follow the same idiom of providing a  [2.x.4743] ) method as for the class Discretization.
//
[0.x.39835] 
[0.x.39836] 
[0.x.39837] 
[0.x.39838] 
[0.x.39839] 
[0.x.39840] 
[0.x.39841] 
//
[0.x.39842] 
[0.x.39843] 
[0.x.39844] 
[0.x.39845] 
//
[0.x.39846] 
[0.x.39847] 
//
[0.x.39848] 
//
[0.x.39849] 
//
[0.x.39850] 
[0.x.39851] 
//
[0.x.39852] 
//
[0.x.39853] 
//
[0.x.39854] 
[0.x.39855] 
[0.x.39856] 
[0.x.39857] 
//
[0.x.39858] 
[0.x.39859] 
[0.x.39860] 
//
[0.x.39861] 
[0.x.39862] 
//[2.x.4744] 
//
// The member functions of this class are utility functions and data structures specific to Euler's equations:
//
// - The type alias  [2.x.4745]  is used for the states    [2.x.4746] 
//
// - The type alias  [2.x.4747]  is used for the fluxes    [2.x.4748] .
//
// - The  [2.x.4749]  function extracts  [2.x.4750]    out of the state vector  [2.x.4751]  and stores it in a    [2.x.4752] .
//
// - The  [2.x.4753]  function computes  [2.x.4754]  from a given state vector    [2.x.4755] .
//
// The purpose of the class members  [2.x.4756] ,  [2.x.4757]  is evident from their names. We also provide a function  [2.x.4758] , that computes the wave speed estimate mentioned above,  [2.x.4759] , which is used in the computation of the  [2.x.4760]  matrix.
//
//  [2.x.4761]  The  [2.x.4762]  macro expands to a (compiler specific) pragma that ensures that the corresponding function defined in this class is always inlined, i.e., the function body is put in place for every invocation of the function, and no call (and code indirection) is generated. This is stronger than the  [2.x.4763]  keyword, which is more or less a (mild) suggestion to the compiler that the programmer thinks it would be beneficial to inline the function.  [2.x.4764]  should only be used rarely and with caution in situations such as this one, where we actually know (due to benchmarking) that inlining the function in question improves performance.
//
// Finally, we observe that this is the only class in this tutorial step that is tied to a particular "physics" or "hyperbolic conservation law" (in this case Euler's equations). All the other classes are primarily "discretization" classes, very much agnostic of the particular physics being solved.
//
[0.x.39863] 
[0.x.39864] 
[0.x.39865] 
[0.x.39866] 
[0.x.39867] 
//
[0.x.39868] 
[0.x.39869] 
//
[0.x.39870] 
//
[0.x.39871] 
//
[0.x.39872] 
[0.x.39873] 
//
[0.x.39874] 
[0.x.39875] 
//
[0.x.39876] 
//
[0.x.39877] 
[0.x.39878] 
//
[0.x.39879] 
//
[0.x.39880] 
[0.x.39881] 
[0.x.39882] 
[0.x.39883] 
[0.x.39884] 
//[2.x.4765] 
//
// The class  [2.x.4766] 's only public data attribute is a  [2.x.4767] 
//[2.x.4768]  that computes the initial state of a given point and time. This function is used for populating the initial flow field as well as setting Dirichlet boundary conditions (at inflow boundaries) explicitly in every time step.
//
// For the purpose of this example step we simply implement a homogeneous uniform flow field for which the direction and a 1D primitive state (density, velocity, pressure) are read from the parameter file.
//
// It would be desirable to initialize the class in a single shot: initialize/set the parameters and define the class members that depend on these default parameters. However, since we do not know the actual values for the parameters, this would be sort of meaningless and unsafe in general (we would like to have mechanisms to check the consistency of the input parameters). Instead of defining another  [2.x.4769]  method to be called (by-hand) after the call to  [2.x.4770]  we provide an "implementation" for the class member  [2.x.4771]  which is automatically called when invoking  [2.x.4772]  for every class that inherits from ParameterAceptor.
//
[0.x.39885] 
[0.x.39886] 
[0.x.39887] 
[0.x.39888] 
[0.x.39889] 
//
[0.x.39890] 
//
[0.x.39891] 
//
[0.x.39892] 
//
// We declare a private callback function that will be wired up to the  [2.x.4773]  signal.
//
[0.x.39893] 
//
[0.x.39894] 
[0.x.39895] 
[0.x.39896] 
//[2.x.4774] 
//
// With the  [2.x.4775]  classes at hand we can now implement the explicit time-stepping scheme that was introduced in the discussion above. The main method of the  [2.x.4776]  class is <code>make_one_step(vector_type &U, double t)</code> that takes a reference to a state vector  [2.x.4777]  (as input arguments) computes the updated solution, stores it in the vector  [2.x.4778] , and returns the chosen  [2.x.4779] size  [2.x.4780] .
//
// The other important method is  [2.x.4781]  which primarily sets the proper partition and sparsity pattern for the temporary vector  [2.x.4782]  respectively.
//
[0.x.39897] 
[0.x.39898] 
[0.x.39899] 
[0.x.39900] 
[0.x.39901] 
[0.x.39902] 
//
[0.x.39903] 
[0.x.39904] 
//
[0.x.39905] 
[0.x.39906] 
//
[0.x.39907] 
[0.x.39908] 
[0.x.39909] 
[0.x.39910] 
[0.x.39911] 
//
[0.x.39912] 
//
[0.x.39913] 
//
[0.x.39914] 
[0.x.39915] 
[0.x.39916] 
//
[0.x.39917] 
[0.x.39918] 
//
[0.x.39919] 
//
[0.x.39920] 
//
[0.x.39921] 
[0.x.39922] 
//[2.x.4783] 
//
// At its core, the Schlieren class implements the class member  [2.x.4784] . The main purpose of this class member is to compute an auxiliary finite element field  [2.x.4785] , that is defined at each node by [1.x.137] where  [2.x.4786]  can in principle be any scalar quantity. In practice though, the density is a natural candidate, viz.  [2.x.4787] . [1.x.138] postprocessing is a standard method for enhancing the contrast of a visualization inspired by actual experimental X-ray and shadowgraphy techniques of visualization. (See  [2.x.4788]  for another example where we create a Schlieren plot.)
//
[0.x.39923] 
[0.x.39924] 
[0.x.39925] 
[0.x.39926] 
[0.x.39927] 
[0.x.39928] 
//
[0.x.39929] 
//
[0.x.39930] 
[0.x.39931] 
//
[0.x.39932] 
[0.x.39933] 
[0.x.39934] 
[0.x.39935] 
[0.x.39936] 
//
[0.x.39937] 
//
[0.x.39938] 
//
[0.x.39939] 
//
[0.x.39940] 
[0.x.39941] 
[0.x.39942] 
//
[0.x.39943] 
//
[0.x.39944] 
//
[0.x.39945] 
[0.x.39946] 
[0.x.39947] 
//[2.x.4789] 
//
// Now, all that is left to do is to chain the methods implemented in the  [2.x.4790] , and  [2.x.4791]  classes together. We do this in a separate class  [2.x.4792]  that contains an object of every class and again reads in a number of parameters with the help of the ParameterAcceptor class.
//
[0.x.39948] 
[0.x.39949] 
[0.x.39950] 
[0.x.39951] 
[0.x.39952] 
//
[0.x.39953] 
//
[0.x.39954] 
//
[0.x.39955] 
[0.x.39956] 
//
[0.x.39957] 
[0.x.39958] 
[0.x.39959] 
[0.x.39960] 
[0.x.39961] 
//
[0.x.39962] 
[0.x.39963] 
[0.x.39964] 
//
[0.x.39965] 
//
[0.x.39966] 
[0.x.39967] 
[0.x.39968] 
//
[0.x.39969] 
//
[0.x.39970] 
//
[0.x.39971] 
[0.x.39972] 
[0.x.39973] 
[0.x.39974] 
[0.x.39975] 
//
[0.x.39976] 
//
[0.x.39977] 
[0.x.39978] 
//[2.x.4793] 
//[2.x.4794] 
//
// The first major task at hand is the typical triplet of grid generation, setup of data structures, and assembly. A notable novelty in this example step is the use of the ParameterAcceptor class that we use to populate parameter values: we first initialize the ParameterAcceptor class by calling its constructor with a string  [2.x.4795]  denoting the correct subsection in the parameter file. Then, in the constructor body every parameter value is initialized to a sensible default value and registered with the ParameterAcceptor class with a call to  [2.x.4796] 
[0.x.39979] 
[0.x.39980] 
[0.x.39981] 
[0.x.39982] 
[0.x.39983] 
[0.x.39984] 
[0.x.39985] 
[0.x.39986] 
[0.x.39987] 
[0.x.39988] 
[0.x.39989] 
[0.x.39990] 
[0.x.39991] 
[0.x.39992] 
[0.x.39993] 
//
[0.x.39994] 
[0.x.39995] 
//
[0.x.39996] 
[0.x.39997] 
[0.x.39998] 
[0.x.39999] 
//
[0.x.40000] 
[0.x.40001] 
[0.x.40002] 
[0.x.40003] 
//
[0.x.40004] 
[0.x.40005] 
[0.x.40006] 
[0.x.40007] 
[0.x.40008] 
//
// Note that in the previous constructor we only passed the MPI communicator to the  [2.x.4797]  but we still have not initialized the underlying geometry/mesh. As mentioned earlier, we have to postpone this task to the  [2.x.4798]  function that gets called after the  [2.x.4799]  function has populated all parameter variables with the final values read from the parameter file.
//
// The  [2.x.4800]  function is the last class member that has to be implemented. It creates the actual triangulation that is a benchmark configuration consisting of a channel with a disk obstacle, see  [2.x.4801] . We construct the geometry by modifying the mesh generated by  [2.x.4802]  We refer to  [2.x.4803] ,  [2.x.4804] , and  [2.x.4805]  for an overview how to create advanced meshes. We first create 4 temporary (non distributed) coarse triangulations that we stitch together with the  [2.x.4806]  function. We center the disk at  [2.x.4807]  with a diameter of  [2.x.4808] . The lower left corner of the channel has coordinates ( [2.x.4809] ) and the upper right corner has ( [2.x.4810] ,  [2.x.4811] ).
//
[0.x.40009] 
[0.x.40010] 
[0.x.40011] 
[0.x.40012] 
//
[0.x.40013] 
//
[0.x.40014] 
//
[0.x.40015] 
[0.x.40016] 
//
[0.x.40017] 
[0.x.40018] 
[0.x.40019] 
[0.x.40020] 
[0.x.40021] 
//
[0.x.40022] 
[0.x.40023] 
[0.x.40024] 
[0.x.40025] 
[0.x.40026] 
//
[0.x.40027] 
[0.x.40028] 
[0.x.40029] 
[0.x.40030] 
[0.x.40031] 
//
[0.x.40032] 
[0.x.40033] 
[0.x.40034] 
[0.x.40035] 
[0.x.40036] 
//
[0.x.40037] 
[0.x.40038] 
[0.x.40039] 
[0.x.40040] 
[0.x.40041] 
//
[0.x.40042] 
[0.x.40043] 
[0.x.40044] 
[0.x.40045] 
[0.x.40046] 
//
[0.x.40047] 
//
// We have to fix up the left edge that is currently located at  [2.x.4812] 
//[2.x.4813]  and has to be shifted to  [2.x.4814] 
//[2.x.4815] . As a last step the boundary has to be colorized with  [2.x.4816]  on the right,  [2.x.4817]  on the upper and lower outer boundaries and the obstacle.
//
[0.x.40048] 
[0.x.40049] 
[0.x.40050] 
[0.x.40051] 
[0.x.40052] 
[0.x.40053] 
[0.x.40054] 
[0.x.40055] 
//
[0.x.40056] 
[0.x.40057] 
[0.x.40058] 
[0.x.40059] 
[0.x.40060] 
//
[0.x.40061] 
[0.x.40062] 
[0.x.40063] 
//
[0.x.40064] 
[0.x.40065] 
[0.x.40066] 
[0.x.40067] 
[0.x.40068] 
[0.x.40069] 
[0.x.40070] 
[0.x.40071] 
[0.x.40072] 
//
[0.x.40073] 
[0.x.40074] 
//[2.x.4818] 
//
// Not much is done in the constructor of  [2.x.4819]  other than initializing the corresponding class members in the initialization list.
//
[0.x.40075] 
[0.x.40076] 
[0.x.40077] 
[0.x.40078] 
[0.x.40079] 
[0.x.40080] 
[0.x.40081] 
[0.x.40082] 
[0.x.40083] 
[0.x.40084] 
[0.x.40085] 
//
// Now we can initialize the DoFHandler, extract the IndexSet objects for locally owned and locally relevant DOFs, and initialize a  [2.x.4820]  object that is needed for distributed vectors.
//
[0.x.40086] 
[0.x.40087] 
[0.x.40088] 
[0.x.40089] 
[0.x.40090] 
//
[0.x.40091] 
[0.x.40092] 
[0.x.40093] 
//
[0.x.40094] 
//
[0.x.40095] 
[0.x.40096] 
//
[0.x.40097] 
[0.x.40098] 
//
[0.x.40099] 
[0.x.40100] 
[0.x.40101] 
[0.x.40102] 
[0.x.40103] 
//[2.x.4821] 
//
// We are now in a position to create the sparsity pattern for our matrices. There are quite a few peculiarities that need a detailed explanation. We avoid using a distributed matrix class (as for example provided by Trilinos or PETSc) and instead rely on deal.II's own SparseMatrix object to store the local part of all matrices. This design decision is motivated by the fact that (a) we actually never perform a matrix-vector multiplication, and (b) we can always assemble the local part of a matrix exclusively on a given MPI rank. Instead, we will compute nonlinear updates while iterating over (the local part) of a connectivity stencil; a task for which deal.II's own SparsityPattern is specifically optimized for.
//
// This design consideration has a caveat, though. What makes the deal.II SparseMatrix class fast is the [1.x.139] used in the SparsityPattern (see  [2.x.4822] ). This, unfortunately, does not play nicely with a global distributed index range because a sparsity pattern with CSR cannot contain "holes" in the index range. The distributed matrices offered by deal.II avoid this by translating from a global index range into a contiguous local index range. But this is precisely the type of index manipulation we want to avoid in our iteration over the stencil because it creates a measurable overhead.
//
// The  [2.x.4823]  class already implements the translation from a global index range to a contiguous local (per MPI rank) index range: we don't have to reinvent the wheel. We just need to use that translation capability (once and only once) in order to create a "local" sparsity pattern for the contiguous index range  [2.x.4824] 
//[2.x.4825] 
//[2.x.4826] . That capability can be invoked by the  [2.x.4827]  function. Once the sparsity pattern is created using local indices, all that is left to do is to ensure that (when implementing our scatter and gather auxiliary functions) we always access elements of a distributed vector by a call to  [2.x.4828]  This way we avoid index translations altogether and operate exclusively with local indices.
//
[0.x.40104] 
[0.x.40105] 
[0.x.40106] 
[0.x.40107] 
//
// We have to create the "local" sparsity pattern by hand. We therefore loop over all locally owned and ghosted cells (see  [2.x.4829]  GlossArtificialCell) and extract the (global)  [2.x.4830]  associated with the cell DOFs and renumber them using  [2.x.4831] .
//
//  [2.x.4832]  In the case of a locally owned dof, such renumbering consist of applying a shift (i.e. we subtract an offset) such that now they will become a number in the integer interval  [2.x.4833] 
//[2.x.4834] 
//[2.x.4835] . However, in the case of a ghosted dof (i.e. not locally owned) the situation is quite different, since the global indices associated with ghosted DOFs will not be (in general) a contiguous set of integers.
//
[0.x.40108] 
//
[0.x.40109] 
[0.x.40110] 
[0.x.40111] 
//
[0.x.40112] 
[0.x.40113] 
[0.x.40114] 
[0.x.40115] 
//
//          /* We transform the set of global dof indices on the cell to the
//
[0.x.40116] 
[0.x.40117] 
[0.x.40118] 
[0.x.40119] 
[0.x.40120] 
[0.x.40121] 
[0.x.40122] 
[0.x.40123] 
//
//          /* And simply add, for each dof, a coupling to all other "local"
//
[0.x.40124] 
[0.x.40125] 
[0.x.40126] 
[0.x.40127] 
//
[0.x.40128] 
//
[0.x.40129] 
[0.x.40130] 
[0.x.40131] 
[0.x.40132] 
[0.x.40133] 
[0.x.40134] 
[0.x.40135] 
[0.x.40136] 
//
// This concludes the setup of the DoFHandler and SparseMatrix objects. Next, we have to assemble various matrices. We define a number of helper functions and data structures in an anonymous namespace.
//
[0.x.40137] 
[0.x.40138] 
//[2.x.4836]  class that will be used to assemble the offline data matrices using WorkStream. It acts as a container: it is just a struct where WorkStream stores the local cell contributions. Note that it also contains a class member  [2.x.4837]  used to store the local contributions required to compute the normals at the boundary.
//
[0.x.40139] 
[0.x.40140] 
[0.x.40141] 
[0.x.40142] 
[0.x.40143] 
[0.x.40144] 
[0.x.40145] 
[0.x.40146] 
[0.x.40147] 
//
// Next we introduce a number of helper functions that are all concerned about reading and writing matrix and vector entries. They are mainly motivated by providing slightly more efficient code and [1.x.140] for otherwise somewhat tedious code.
//
// The first function we introduce,  [2.x.4838] , will be used to read the value stored at the entry pointed by a SparsityPattern iterator  [2.x.4839] . The function works around a small deficiency in the SparseMatrix interface: The SparsityPattern is concerned with all index operations of the sparse matrix stored in CRS format. As such the iterator already knows the global index of the corresponding matrix entry in the low-level vector stored in the SparseMatrix object. Due to the lack of an interface in the SparseMatrix for accessing the element directly with a SparsityPattern iterator, we unfortunately have to create a temporary SparseMatrix iterator. We simply hide this in the  [2.x.4840]  function.
//
[0.x.40148] 
[0.x.40149] 
[0.x.40150] 
[0.x.40151] 
[0.x.40152] 
[0.x.40153] 
[0.x.40154] 
[0.x.40155] 
//
// The  [2.x.4841]  helper is the inverse operation of  [2.x.4842] : Given an iterator and a value, it sets the entry pointed to by the iterator in the matrix.
//
[0.x.40156] 
[0.x.40157] 
[0.x.40158] 
[0.x.40159] 
[0.x.40160] 
[0.x.40161] 
[0.x.40162] 
[0.x.40163] 
[0.x.40164] 
[0.x.40165] 
//[2.x.4843] : we note that  [2.x.4844] . If  [2.x.4845]  then  [2.x.4846] . Which basically implies that we need one matrix per space dimension to store the  [2.x.4847]  vectors. Similar observation follows for the matrix  [2.x.4848] . The purpose of  [2.x.4849]  is to retrieve those entries and store them into a  [2.x.4850]  for our convenience.
//
[0.x.40166] 
[0.x.40167] 
[0.x.40168] 
[0.x.40169] 
[0.x.40170] 
[0.x.40171] 
[0.x.40172] 
[0.x.40173] 
[0.x.40174] 
[0.x.40175] 
//[2.x.4851]  (first interface): this first function signature, having three input arguments, will be used to retrieve the individual components  [2.x.4852]  of a matrix. The functionality of  [2.x.4853]  and  [2.x.4854]  is very much the same, but their context is different: the function  [2.x.4855]  does not rely on an iterator (that actually knows the value pointed to) but rather on the indices  [2.x.4856]  of the entry in order to retrieve its actual value. We should expect  [2.x.4857]  to be slightly more expensive than  [2.x.4858] . The use of  [2.x.4859]  will be limited to the task of computing the algebraic viscosity  [2.x.4860]  in the particular case that when both  [2.x.4861]  and  [2.x.4862]  lie at the boundary.
//
//  [2.x.4863]  The reader should be aware that accessing an arbitrary  [2.x.4864]  entry of a matrix (say for instance Trilinos or PETSc matrices) is in general unacceptably expensive. Here is where we might want to keep an eye on complexity: we want this operation to have constant complexity, which is the case of the current implementation using deal.II matrices.
//
[0.x.40176] 
[0.x.40177] 
[0.x.40178] 
[0.x.40179] 
[0.x.40180] 
[0.x.40181] 
[0.x.40182] 
[0.x.40183] 
[0.x.40184] 
[0.x.40185] 
[0.x.40186] 
//[2.x.4865]  (second interface): this second function signature having two input arguments will be used to gather the state at a node  [2.x.4866]  and return it as a  [2.x.4867]  for our convenience.
//
[0.x.40187] 
[0.x.40188] 
[0.x.40189] 
[0.x.40190] 
[0.x.40191] 
[0.x.40192] 
[0.x.40193] 
[0.x.40194] 
[0.x.40195] 
[0.x.40196] 
//[2.x.4868] : this function has three input arguments, the first one is meant to be a "global object" (say a locally owned or locally relevant vector), the second argument which could be a  [2.x.4869] , and the last argument which represents a index of the global object. This function will be primarily used to write the updated nodal values, stored as  [2.x.4870] , into the global objects.
//
[0.x.40197] 
[0.x.40198] 
[0.x.40199] 
[0.x.40200] 
[0.x.40201] 
[0.x.40202] 
[0.x.40203] 
[0.x.40204] 
[0.x.40205] 
[0.x.40206] 
[0.x.40207] 
[0.x.40208] 
//
// We are now in a position to assemble all matrices stored in  [2.x.4871] : the lumped mass entries  [2.x.4872] , the vector-valued matrices  [2.x.4873]  and  [2.x.4874] , and the boundary normals  [2.x.4875] .
//
// In order to exploit thread parallelization we use the WorkStream approach detailed in the  [2.x.4876]  "Parallel computing with multiple processors" accessing shared memory. As customary this requires definition of 
//
// - Scratch data (i.e. input info required to carry out computations): in    this case it is  [2.x.4877] . 
//
// - The worker: in our case this is the  [2.x.4878]   function that    actually computes the local (i.e. current cell) contributions from the    scratch data. 
//
// - A copy data: a struct that contains all the local assembly    contributions, in this case  [2.x.4879] . 
//
// - A copy data routine: in this case it is     [2.x.4880]  in charge of actually coping these    local contributions into the global objects (matrices and/or vectors)
//
// Most of the following lines are spent in the definition of the worker  [2.x.4881]  and the copy data routine  [2.x.4882] . There is not much to say about the WorkStream framework since the vast majority of ideas are reasonably well-documented in  [2.x.4883] ,  [2.x.4884]  and  [2.x.4885]  among others.
//
// Finally, assuming that  [2.x.4886]  is a support point at the boundary, the (nodal) normals are defined as:
//
// [1.x.141]
//
// We will compute the numerator of this expression first and store it in  [2.x.4887] . We will normalize these vectors in a posterior loop.
//
[0.x.40209] 
[0.x.40210] 
[0.x.40211] 
[0.x.40212] 
[0.x.40213] 
[0.x.40214] 
[0.x.40215] 
[0.x.40216] 
[0.x.40217] 
//
[0.x.40218] 
[0.x.40219] 
[0.x.40220] 
//
// What follows is the initialization of the scratch data required by WorkStream
//
[0.x.40221] 
[0.x.40222] 
[0.x.40223] 
[0.x.40224] 
[0.x.40225] 
[0.x.40226] 
[0.x.40227] 
[0.x.40228] 
//
[0.x.40229] 
[0.x.40230] 
[0.x.40231] 
[0.x.40232] 
//
[0.x.40233] 
[0.x.40234] 
[0.x.40235] 
[0.x.40236] 
[0.x.40237] 
[0.x.40238] 
[0.x.40239] 
//
[0.x.40240] 
[0.x.40241] 
[0.x.40242] 
[0.x.40243] 
//
[0.x.40244] 
//
[0.x.40245] 
[0.x.40246] 
//
[0.x.40247] 
[0.x.40248] 
[0.x.40249] 
[0.x.40250] 
[0.x.40251] 
[0.x.40252] 
//
// We compute the local contributions for the lumped mass matrix entries  [2.x.4888]  and and vectors  [2.x.4889]  in the usual fashion:
//
[0.x.40253] 
[0.x.40254] 
[0.x.40255] 
//
[0.x.40256] 
[0.x.40257] 
[0.x.40258] 
[0.x.40259] 
[0.x.40260] 
//
[0.x.40261] 
//
[0.x.40262] 
[0.x.40263] 
[0.x.40264] 
[0.x.40265] 
[0.x.40266] 
//
[0.x.40267] 
[0.x.40268] 
[0.x.40269] 
//
// Now we have to compute the boundary normals. Note that the following loop does not do much unless the element has faces on the boundary of the domain.
//
[0.x.40270] 
[0.x.40271] 
[0.x.40272] 
[0.x.40273] 
//
[0.x.40274] 
[0.x.40275] 
//
[0.x.40276] 
//
[0.x.40277] 
[0.x.40278] 
//
[0.x.40279] 
[0.x.40280] 
[0.x.40281] 
[0.x.40282] 
//
//         Note that "normal" will only represent the contributions         from one of the faces in the support of the shape         function phi_j. So we cannot normalize this local         contribution right here, we have to take it "as is",         store it and pass it to the copy data routine. The         proper normalization requires an additional loop on         nodes. This is done in the copy function below.
//
[0.x.40283] 
[0.x.40284] 
[0.x.40285] 
[0.x.40286] 
[0.x.40287] 
[0.x.40288] 
[0.x.40289] 
//
[0.x.40290] 
//
[0.x.40291] 
[0.x.40292] 
[0.x.40293] 
[0.x.40294] 
[0.x.40295] 
[0.x.40296] 
[0.x.40297] 
[0.x.40298] 
//
[0.x.40299] 
[0.x.40300] 
[0.x.40301] 
[0.x.40302] 
[0.x.40303] 
[0.x.40304] 
[0.x.40305] 
//
// Last, we provide a copy_local_to_global function as required for the WorkStream
//
[0.x.40306] 
[0.x.40307] 
[0.x.40308] 
//
[0.x.40309] 
[0.x.40310] 
[0.x.40311] 
[0.x.40312] 
[0.x.40313] 
[0.x.40314] 
[0.x.40315] 
[0.x.40316] 
[0.x.40317] 
//
[0.x.40318] 
[0.x.40319] 
//
[0.x.40320] 
[0.x.40321] 
[0.x.40322] 
[0.x.40323] 
[0.x.40324] 
[0.x.40325] 
//
[0.x.40326] 
[0.x.40327] 
[0.x.40328] 
[0.x.40329] 
[0.x.40330] 
[0.x.40331] 
[0.x.40332] 
//
// At this point in time we are done with the computation of  [2.x.4890]  and  [2.x.4891] , but so far the matrix  [2.x.4892]  contains just a copy of the matrix  [2.x.4893] . That's not what we really want: we have to normalize its entries. In addition, we have not filled the entries of the matrix  [2.x.4894]   and the vectors stored in the map  [2.x.4895]  are not normalized.
//
// In principle, this is just offline data, it doesn't make much sense to over-optimize their computation, since their cost will get amortized over the many time steps that we are going to use. However, computing/storing the entries of the matrix  [2.x.4896]  are perfect to illustrate thread-parallel node-loops:
//
// - we want to visit every node  [2.x.4897]  in the mesh/sparsity graph,
//
// - and for every such node we want to visit to every  [2.x.4898]  such that  [2.x.4899] .
//
// From an algebraic point of view, this is equivalent to: visiting every row in the matrix and for each one of these rows execute a loop on the columns. Node-loops is a core theme of this tutorial step (see the pseudo-code in the introduction) that will repeat over and over again. That's why this is the right time to introduce them.
//
// We have the thread parallelization capability  [2.x.4900]  that is somehow more general than the WorkStream framework. In particular,  [2.x.4901]  can be used for our node-loops. This functionality requires four input arguments which we explain in detail (for the specific case of our thread-parallel node loops):
//
// - The iterator  [2.x.4902]  points to a row index.
//
// - The iterator  [2.x.4903]  points to a numerically higher   row index.
//
// - The function  [2.x.4904]    and  [2.x.4905]  define a sub-range within the range spanned by   the end and begin iterators defined in the two previous bullets)   applies an operation to every iterator in such subrange. We may as   well call  [2.x.4906]  the "worker".
//
// - Grainsize: minimum number of iterators (in this case representing   rows) processed by each thread. We decided for a minimum of 4096   rows.
//
// A minor caveat here is that the iterators  [2.x.4907]  and  [2.x.4908]  supplied to  [2.x.4909]  have to be random access iterators: internally,  [2.x.4910]  will break the range defined by the  [2.x.4911]  and  [2.x.4912]  iterators into subranges (we want to be able to read any entry in those subranges with constant complexity). In order to provide such iterators we resort to  [2.x.4913] 
//
// The bulk of the following piece of code is spent defining the "worker"  [2.x.4914] : i.e. the  operation applied at each row of the sub-range. Given a fixed  [2.x.4915]  we want to visit every column/entry in such row. In order to execute such columns-loops we use [1.x.142] from the standard library, where: 
//
// -  [2.x.4916]     gives us an iterator starting at the first column of the row, 
//
// -  [2.x.4917]  is an iterator pointing    at the last column of the row, 
//
// - the last argument required by  [2.x.4918]  is the operation    applied at each nonzero entry (a lambda expression in this case)    of such row.
//
// We note that,  [2.x.4919]  will operate on disjoint sets of rows (the subranges) and our goal is to write into these rows. Because of the simple nature of the operations we want to carry out (computation and storage of normals, and normalization of the  [2.x.4920]  of entries) threads cannot conflict attempting to write the same entry (we do not need a scheduler).
//
[0.x.40333] 
[0.x.40334] 
[0.x.40335] 
//
[0.x.40336] 
[0.x.40337] 
//
[0.x.40338] 
[0.x.40339] 
[0.x.40340] 
[0.x.40341] 
[0.x.40342] 
[0.x.40343] 
//
//     First column-loop: we compute and store the entries of the     matrix norm_matrix and write normalized entries into the     matrix nij_matrix:
//
[0.x.40344] 
[0.x.40345] 
[0.x.40346] 
[0.x.40347] 
[0.x.40348] 
[0.x.40349] 
//
[0.x.40350] 
[0.x.40351] 
[0.x.40352] 
[0.x.40353] 
[0.x.40354] 
[0.x.40355] 
//
[0.x.40356] 
[0.x.40357] 
[0.x.40358] 
[0.x.40359] 
//
// Finally, we normalize the vectors stored in  [2.x.4921] . This operation has not been thread parallelized as it would neither illustrate any important concept nor lead to any noticeable speed gain.
//
[0.x.40360] 
[0.x.40361] 
[0.x.40362] 
[0.x.40363] 
[0.x.40364] 
[0.x.40365] 
[0.x.40366] 
//
// At this point we are very much done with anything related to offline data.
//
//  [2.x.4922] 
//
// In this section we describe the implementation of the class members of the  [2.x.4923]  class. Most of the code here is specific to the compressible Euler's equations with an ideal gas law. If we wanted to re-purpose  [2.x.4924]  for a different conservation law (say for: instance the shallow water equation) most of the implementation of this class would have to change. But most of the other classes (in particular those defining loop structures) would remain unchanged.
//
// We start by implementing a number of small member functions for computing  [2.x.4925] ,  [2.x.4926] , and the flux  [2.x.4927]  of the system. The functionality of each one of these functions is self-explanatory from their names.
//
[0.x.40367] 
[0.x.40368] 
[0.x.40369] 
[0.x.40370] 
[0.x.40371] 
[0.x.40372] 
[0.x.40373] 
[0.x.40374] 
//
[0.x.40375] 
[0.x.40376] 
[0.x.40377] 
[0.x.40378] 
[0.x.40379] 
[0.x.40380] 
[0.x.40381] 
[0.x.40382] 
[0.x.40383] 
//
[0.x.40384] 
[0.x.40385] 
[0.x.40386] 
[0.x.40387] 
[0.x.40388] 
[0.x.40389] 
//
[0.x.40390] 
[0.x.40391] 
[0.x.40392] 
[0.x.40393] 
[0.x.40394] 
[0.x.40395] 
//
[0.x.40396] 
[0.x.40397] 
//
[0.x.40398] 
[0.x.40399] 
[0.x.40400] 
[0.x.40401] 
[0.x.40402] 
[0.x.40403] 
[0.x.40404] 
[0.x.40405] 
//
[0.x.40406] 
//
[0.x.40407] 
[0.x.40408] 
[0.x.40409] 
[0.x.40410] 
[0.x.40411] 
[0.x.40412] 
[0.x.40413] 
//
[0.x.40414] 
[0.x.40415] 
//
// Now we discuss the computation of  [2.x.4928] . The analysis and derivation of sharp upper-bounds of maximum wavespeeds of Riemann problems is a very technical endeavor and we cannot include an advanced discussion about it in this tutorial. In this portion of the documentation we will limit ourselves to sketch the main functionality of our implementation functions and point to specific academic references in order to help the (interested) reader trace the source (and proper mathematical justification) of these ideas.
//
// In general, obtaining a sharp guaranteed upper-bound on the maximum wavespeed requires solving a quite expensive scalar nonlinear problem. This is typically done with an iterative solver. In order to simplify the presentation in this example step we decided not to include such an iterative scheme. Instead, we will just use an initial guess as a guess for an upper bound on the maximum wavespeed. More precisely, equations (2.11) (3.7), (3.8) and (4.3) of  [2.x.4929]  are enough to define a guaranteed upper bound on the maximum wavespeed. This estimate is returned by a call to the function  [2.x.4930] . At its core the construction of such an upper bound uses the so-called two-rarefaction approximation for the intermediate pressure  [2.x.4931] , see for instance Equation (4.46), page 128 in  [2.x.4932] .
//
// The estimate returned by  [2.x.4933]  is guaranteed to be an upper bound, it is in general quite sharp, and overall sufficient for our purposes. However, for some specific situations (in particular when one of states is close to vacuum conditions) such an estimate will be overly pessimistic. That's why we used a second estimate to avoid this degeneracy that will be invoked by a call to the function  [2.x.4934] . The most important function here is  [2.x.4935]  which takes the minimum between the estimates returned by  [2.x.4936]  and  [2.x.4937] .
//
// We start again by defining a couple of helper functions:
//
// The first function takes a state  [2.x.4938]  and a unit vector  [2.x.4939]  and computes the [1.x.143] 1D state in direction of the unit vector.
//
[0.x.40416] 
[0.x.40417] 
[0.x.40418] 
[0.x.40419] 
[0.x.40420] 
[0.x.40421] 
[0.x.40422] 
[0.x.40423] 
[0.x.40424] 
//
// For this, we have to change the momentum to  [2.x.4940]  and have to subtract the kinetic energy of the perpendicular part from the total energy:
//
[0.x.40425] 
[0.x.40426] 
//
[0.x.40427] 
[0.x.40428] 
//
// We return the 1D state in [1.x.144] variables instead of conserved quantities. The return array consists of density  [2.x.4941] , velocity  [2.x.4942] , pressure  [2.x.4943]  and local speed of sound  [2.x.4944] :
//
[0.x.40429] 
[0.x.40430] 
[0.x.40431] 
[0.x.40432] 
[0.x.40433] 
//
// At this point we also define two small functions that return the positive and negative part of a double.
//
[0.x.40434] 
[0.x.40435] 
[0.x.40436] 
[0.x.40437] 
//
[0.x.40438] 
[0.x.40439] 
[0.x.40440] 
[0.x.40441] 
//
// Next, we need two local wavenumbers that are defined in terms of a primitive state  [2.x.4945]  and a given pressure  [2.x.4946] 
//[2.x.4947]   Eqn. (3.7): [1.x.145] Here, the  [2.x.4948]  denotes the positive part of the given argument.
//
[0.x.40442] 
[0.x.40443] 
[0.x.40444] 
[0.x.40445] 
//
//      /* Implements formula (3.7) in Guermond-Popov-2016  [2.x.4949] 
[0.x.40446] 
[0.x.40447] 
[0.x.40448] 
[0.x.40449] 
//
[0.x.40450] 
[0.x.40451] 
[0.x.40452] 
[0.x.40453] 
//
// Analougously  [2.x.4950]  Eqn. (3.8): [1.x.146]
//
[0.x.40454] 
[0.x.40455] 
[0.x.40456] 
//
//      /* Implements formula (3.8) in Guermond-Popov-2016  [2.x.4951] 
[0.x.40457] 
[0.x.40458] 
[0.x.40459] 
[0.x.40460] 
//
[0.x.40461] 
[0.x.40462] 
[0.x.40463] 
[0.x.40464] 
//
// All that is left to do is to compute the maximum of  [2.x.4952]  and  [2.x.4953]  computed from the left and right primitive state ( [2.x.4954]  Eqn. (2.11)), where  [2.x.4955]  is given by  [2.x.4956]  Eqn (4.3):
//
[0.x.40465] 
[0.x.40466] 
[0.x.40467] 
[0.x.40468] 
[0.x.40469] 
[0.x.40470] 
[0.x.40471] 
[0.x.40472] 
[0.x.40473] 
[0.x.40474] 
[0.x.40475] 
//
[0.x.40476] 
//
[0.x.40477] 
[0.x.40478] 
//
//      /* Formula (4.3) in Guermond-Popov-2016  [2.x.4957] 
[0.x.40479] 
[0.x.40480] 
//
[0.x.40481] 
[0.x.40482] 
//
//      /* Formula (2.11) in Guermond-Popov-2016  [2.x.4958] 
[0.x.40483] 
[0.x.40484] 
//
// We compute the second upper bound of the maximal wavespeed that is, in general, not as sharp as the two-rarefaction estimate. But it will save the day in the context of near vacuum conditions when the two-rarefaction approximation might attain extreme values: [1.x.147] 
//[2.x.4959]  The constant 5.0 multiplying the maximum of the sound speeds is [1.x.148] an ad-hoc constant, [1.x.149] a tuning parameter. It defines an upper bound for any  [2.x.4960] . Do not play with it!
//
[0.x.40485] 
[0.x.40486] 
[0.x.40487] 
[0.x.40488] 
[0.x.40489] 
[0.x.40490] 
[0.x.40491] 
[0.x.40492] 
//
[0.x.40493] 
[0.x.40494] 
[0.x.40495] 
//
// The following is the main function that we are going to call in order to compute  [2.x.4961] . We simply compute both maximal wavespeed estimates and return the minimum.
//
[0.x.40496] 
[0.x.40497] 
[0.x.40498] 
[0.x.40499] 
[0.x.40500] 
[0.x.40501] 
[0.x.40502] 
[0.x.40503] 
//
[0.x.40504] 
[0.x.40505] 
//
[0.x.40506] 
[0.x.40507] 
//
[0.x.40508] 
[0.x.40509] 
//
// We conclude this section by defining static arrays  [2.x.4962]  that contain strings describing the component names of our state vector. We have template specializations for dimensions one, two and three, that are used later in DataOut for naming the corresponding components:
//
[0.x.40510] 
[0.x.40511] 
[0.x.40512] 
//
[0.x.40513] 
[0.x.40514] 
[0.x.40515] 
//
[0.x.40516] 
[0.x.40517] 
[0.x.40518] 
//[2.x.4963] 
//
// The last preparatory step, before we discuss the implementation of the forward Euler scheme, is to briefly implement the `InitialValues` class.
//
// In the constructor we initialize all parameters with default values, declare all parameters for the `ParameterAcceptor` class and connect the  [2.x.4964]  slot to the respective signal.
//
// The  [2.x.4965]  slot will be invoked from ParameterAceptor after the call to  [2.x.4966]  In that regard, its use is appropriate for situations where the parameters have to be postprocessed (in some sense) or some consistency condition between the parameters has to be checked.
//
[0.x.40519] 
[0.x.40520] 
[0.x.40521] 
[0.x.40522] 
//
//    /* We wire up the slot  [2.x.4967]  to
//
[0.x.40523] 
[0.x.40524] 
[0.x.40525] 
//
[0.x.40526] 
[0.x.40527] 
[0.x.40528] 
[0.x.40529] 
//
[0.x.40530] 
[0.x.40531] 
[0.x.40532] 
[0.x.40533] 
[0.x.40534] 
[0.x.40535] 
[0.x.40536] 
//
// So far the constructor of  [2.x.4968]  has defined default values for the two private members  [2.x.4969]  and added them to the parameter list. But we have not defined an implementation of the only public member that we really care about, which is  [2.x.4970]  (the function that we are going to call to actually evaluate the initial solution at the mesh nodes). At the top of the function, we have to ensure that the provided initial direction is not the zero vector.
//
//  [2.x.4971]  As commented, we could have avoided using the method  [2.x.4972]  and defined a class member  [2.x.4973]  in order to define the implementation of  [2.x.4974] . But for illustrative purposes we want to document a different way here and use the call back signal from ParameterAcceptor.
//
[0.x.40537] 
[0.x.40538] 
[0.x.40539] 
[0.x.40540] 
[0.x.40541] 
[0.x.40542] 
[0.x.40543] 
//
// Next, we implement the  [2.x.4975]  function object with a lambda function computing a uniform flow field. For this we have to translate a given primitive 1d state (density  [2.x.4976] , velocity  [2.x.4977] , and pressure  [2.x.4978] ) into a conserved n-dimensional state (density  [2.x.4979] , momentum  [2.x.4980] , and total energy  [2.x.4981] ).
//
[0.x.40544] 
[0.x.40545] 
[0.x.40546] 
[0.x.40547] 
[0.x.40548] 
//
[0.x.40549] 
//
[0.x.40550] 
[0.x.40551] 
[0.x.40552] 
//
[0.x.40553] 
//
[0.x.40554] 
[0.x.40555] 
[0.x.40556] 
//[2.x.4982] 
//
// The constructor of the  [2.x.4983]  class does not contain any surprising code:
//
[0.x.40557] 
[0.x.40558] 
[0.x.40559] 
[0.x.40560] 
[0.x.40561] 
[0.x.40562] 
[0.x.40563] 
[0.x.40564] 
[0.x.40565] 
[0.x.40566] 
[0.x.40567] 
[0.x.40568] 
[0.x.40569] 
[0.x.40570] 
[0.x.40571] 
[0.x.40572] 
[0.x.40573] 
[0.x.40574] 
//
// In the class member  [2.x.4984]  we initialize the temporary vector  [2.x.4985] . The vector  [2.x.4986]  will be used to store the solution update temporarily before its contents is swapped with the old vector.
//
[0.x.40575] 
[0.x.40576] 
[0.x.40577] 
[0.x.40578] 
[0.x.40579] 
//
[0.x.40580] 
[0.x.40581] 
//
[0.x.40582] 
[0.x.40583] 
//
// It is now time to implement the forward Euler step. Given a (writable reference) to the old state  [2.x.4987]  at time  [2.x.4988]  we update the state  [2.x.4989]  in place and return the chosen time-step size. We first declare a number of read-only references to various different variables and data structures. We do this is mainly to have shorter variable names (e.g.,  [2.x.4990]  instead of  [2.x.4991] ).
//
[0.x.40584] 
[0.x.40585] 
[0.x.40586] 
[0.x.40587] 
[0.x.40588] 
//
[0.x.40589] 
[0.x.40590] 
[0.x.40591] 
[0.x.40592] 
//
[0.x.40593] 
//
[0.x.40594] 
[0.x.40595] 
[0.x.40596] 
[0.x.40597] 
//
[0.x.40598] 
//[1.x.150]: Computing the  [2.x.4992]  graph viscosity matrix.
//
// It is important to highlight that the viscosity matrix has to be symmetric, i.e.,  [2.x.4993] . In this regard we note here that  [2.x.4994]  (or equivalently  [2.x.4995] ) provided either  [2.x.4996]  or  [2.x.4997]  is a support point located away from the boundary. In this case we can check that  [2.x.4998]  by construction, which guarantees the property  [2.x.4999] .
//
// However, if both support points  [2.x.5000]  or  [2.x.5001]  happen to lie on the boundary, then, the equalities  [2.x.5002]  and  [2.x.5003]  do not necessarily hold true. The only mathematically safe solution for this dilemma is to compute both of them  [2.x.5004]  and  [2.x.5005]  and take the maximum.
//
// Overall, the computation of  [2.x.5006]  is quite expensive. In order to save some computing time we exploit the fact that the viscosity matrix has to be symmetric (as mentioned above): we only compute the upper-triangular entries of  [2.x.5007]  and copy the corresponding entries to the lower-triangular counterpart.
//
// We use again  [2.x.5008]  for thread-parallel for loops. Pretty much all the ideas for parallel traversal that we introduced when discussing the assembly of the matrix  [2.x.5009]  and the normalization of  [2.x.5010]  above are used here again.
//
// We define again a "worker" function  [2.x.5011]  that computes the viscosity  [2.x.5012]  for a subrange [i1, i2) of column indices:
//
[0.x.40599] 
[0.x.40600] 
[0.x.40601] 
//
[0.x.40602] 
[0.x.40603] 
[0.x.40604] 
[0.x.40605] 
[0.x.40606] 
[0.x.40607] 
[0.x.40608] 
//
//     For a given column index i we iterate over the columns of the     sparsity pattern from  [2.x.5013]  to      [2.x.5014] :
//
[0.x.40609] 
[0.x.40610] 
[0.x.40611] 
//
//         We only compute  [2.x.5015]  if  [2.x.5016]  (upper triangular         entries) and later copy the values over to  [2.x.5017] .
//
[0.x.40612] 
[0.x.40613] 
//
[0.x.40614] 
//
[0.x.40615] 
[0.x.40616] 
//
[0.x.40617] 
[0.x.40618] 
//
[0.x.40619] 
//
//         If both support points happen to be at the boundary we         have to compute  [2.x.5018]  as well and then take          [2.x.5019] . After this we can finally set the         upper triangular and lower triangular entries.
//
[0.x.40620] 
[0.x.40621] 
[0.x.40622] 
[0.x.40623] 
[0.x.40624] 
[0.x.40625] 
[0.x.40626] 
[0.x.40627] 
[0.x.40628] 
//
[0.x.40629] 
[0.x.40630] 
//
[0.x.40631] 
[0.x.40632] 
[0.x.40633] 
[0.x.40634] 
[0.x.40635] 
//
[0.x.40636] 
[0.x.40637] 
[0.x.40638] 
[0.x.40639] 
[0.x.40640] 
//[1.x.151]: Compute diagonal entries  [2.x.5020]  and  [2.x.5021] .
//
// So far we have computed all off-diagonal entries of the matrix  [2.x.5022] . We still have to fill its diagonal entries defined as  [2.x.5023] . We use again  [2.x.5024]  for this purpose. While computing the  [2.x.5025] s we also determine the largest admissible time-step, which is defined as [1.x.152] Note that the operation  [2.x.5026]  is intrinsically global, it operates on all nodes: first we have to take the minimum over all threads (of a given node) and then we have to take the minimum over all MPI processes. In the current implementation:
//
// - We store   [2.x.5027]  (per node) as   [1.x.153].   The internal implementation of  [2.x.5028]  will take   care of guarding any possible race condition when more than one   thread attempts to read and/or write  [2.x.5029]  at the   same time.
//
// - In order to take the minimum over all MPI process we use the utility   function  [2.x.5030] .
//
[0.x.40641] 
//
[0.x.40642] 
[0.x.40643] 
[0.x.40644] 
//
// on_subranges() will be executed on every thread individually. The variable  [2.x.5031]  is thus stored thread locally.
//
[0.x.40645] 
[0.x.40646] 
[0.x.40647] 
//
[0.x.40648] 
[0.x.40649] 
[0.x.40650] 
[0.x.40651] 
[0.x.40652] 
//
[0.x.40653] 
[0.x.40654] 
[0.x.40655] 
//
[0.x.40656] 
[0.x.40657] 
//
[0.x.40658] 
[0.x.40659] 
//
//     We store the negative sum of the d_ij entries at the     diagonal position
//
[0.x.40660] 
//
//     and compute the maximal local time-step size      [2.x.5032] :
//
[0.x.40661] 
[0.x.40662] 
[0.x.40663] 
[0.x.40664] 
//[2.x.5033]  contains the largest possible time-step size computed for the (thread local) subrange. At this point we have to synchronize the value over all threads. This is were we use the [1.x.154] 
//[1.x.155] update mechanism:
//
[0.x.40665] 
[0.x.40666] 
[0.x.40667] 
[0.x.40668] 
[0.x.40669] 
[0.x.40670] 
//
[0.x.40671] 
[0.x.40672] 
[0.x.40673] 
[0.x.40674] 
//
// After all threads have finished we can simply synchronize the value over all MPI processes:
//
[0.x.40675] 
//
// This is a good point to verify that the computed  [2.x.5034]  is indeed a valid floating point number.
//
[0.x.40676] 
[0.x.40677] 
[0.x.40678] 
[0.x.40679] 
[0.x.40680] 
[0.x.40681] 
//[1.x.156]: Perform update.
//
// At this point, we have computed all viscosity coefficients  [2.x.5035]  and we know the maximal admissible time-step size  [2.x.5036] . This means we can now compute the update:
//
// [1.x.157]
//
// This update formula is slightly different from what was discussed in the introduction (in the pseudo-code). However, it can be shown that both equations are algebraically equivalent (they will produce the same numerical values). We favor this second formula since it has natural cancellation properties that might help avoid numerical artifacts.
//
[0.x.40682] 
[0.x.40683] 
[0.x.40684] 
//
[0.x.40685] 
[0.x.40686] 
[0.x.40687] 
[0.x.40688] 
[0.x.40689] 
//
[0.x.40690] 
//
[0.x.40691] 
[0.x.40692] 
//
[0.x.40693] 
//
[0.x.40694] 
[0.x.40695] 
[0.x.40696] 
//
[0.x.40697] 
[0.x.40698] 
//
[0.x.40699] 
[0.x.40700] 
//
[0.x.40701] 
[0.x.40702] 
[0.x.40703] 
[0.x.40704] 
[0.x.40705] 
[0.x.40706] 
[0.x.40707] 
//
[0.x.40708] 
[0.x.40709] 
[0.x.40710] 
//
[0.x.40711] 
[0.x.40712] 
[0.x.40713] 
[0.x.40714] 
[0.x.40715] 
//[1.x.158]: Fix up boundary states.
//
// As a last step in the Forward Euler method, we have to fix up all boundary states. As discussed in the intro we
//
// - advance in time satisfying no boundary condition at all,
//
// - at the end of the time step enforce boundary conditions strongly   in a post-processing step.
//
// Here, we compute the correction [1.x.159] which removes the normal component of  [2.x.5037] .
//
[0.x.40716] 
[0.x.40717] 
[0.x.40718] 
//
[0.x.40719] 
[0.x.40720] 
[0.x.40721] 
//
// We only iterate over the locally owned subset:
//
[0.x.40722] 
[0.x.40723] 
//
[0.x.40724] 
[0.x.40725] 
[0.x.40726] 
//
[0.x.40727] 
//
// On free slip boundaries we remove the normal component of the momentum:
//
[0.x.40728] 
[0.x.40729] 
[0.x.40730] 
[0.x.40731] 
[0.x.40732] 
[0.x.40733] 
[0.x.40734] 
//
// On Dirichlet boundaries we enforce initial conditions strongly:
//
[0.x.40735] 
[0.x.40736] 
[0.x.40737] 
[0.x.40738] 
//
[0.x.40739] 
[0.x.40740] 
[0.x.40741] 
//[1.x.160]: We now update the ghost layer over all MPI ranks, swap the temporary vector with the solution vector  [2.x.5038]  (that will get returned by reference) and return the chosen time-step size  [2.x.5039] :
//
[0.x.40742] 
[0.x.40743] 
//
[0.x.40744] 
//
[0.x.40745] 
[0.x.40746] 
//[2.x.5040] 
//
// At various intervals we will output the current state  [2.x.5041]  of the solution together with a so-called Schlieren plot. The constructor of the  [2.x.5042]  class again contains no surprises. We simply supply default values to and register two parameters:
//
// - schlieren_beta:   is an ad-hoc positive amplification factor in order to enhance the   contrast in the visualization. Its actual value is a matter of   taste.
//
// - schlieren_index: is an integer indicating which component of the   state  [2.x.5043]  are we going to use in order to generate   the visualization.
//
[0.x.40747] 
[0.x.40748] 
[0.x.40749] 
[0.x.40750] 
[0.x.40751] 
[0.x.40752] 
[0.x.40753] 
[0.x.40754] 
[0.x.40755] 
[0.x.40756] 
[0.x.40757] 
[0.x.40758] 
[0.x.40759] 
[0.x.40760] 
[0.x.40761] 
//
[0.x.40762] 
[0.x.40763] 
[0.x.40764] 
[0.x.40765] 
[0.x.40766] 
[0.x.40767] 
//
// Again, the  [2.x.5044]  function initializes two temporary the vectors ( [2.x.5045] ).
//
[0.x.40768] 
[0.x.40769] 
[0.x.40770] 
[0.x.40771] 
[0.x.40772] 
//
[0.x.40773] 
[0.x.40774] 
[0.x.40775] 
//
// We now discuss the implementation of the class member  [2.x.5046] , which basically takes a component of the state vector  [2.x.5047]  and computes the Schlieren indicator for such component (the formula of the Schlieren indicator can be found just before the declaration of the class  [2.x.5048] ). We start by noting that this formula requires the "nodal gradients"  [2.x.5049] . However, nodal values of gradients are not defined for  [2.x.5050]  finite element functions. More generally, pointwise values of gradients are not defined for  [2.x.5051]  functions. The simplest technique we can use to recover gradients at nodes is weighted-averaging i.e.
//
// [1.x.161]
//
// where  [2.x.5052]  is the support of the shape function  [2.x.5053] , and  [2.x.5054]  is the weight. The weight could be any positive function such as  [2.x.5055]  (that would allow us to recover the usual notion of mean value). But as usual, the goal is to reuse the off-line data as much as possible. In this sense, the most natural choice of weight is  [2.x.5056] . Inserting this choice of weight and the expansion  [2.x.5057]  into  [2.x.5058]  we get :
//
// [1.x.162]
//
// Using this last formula we can recover averaged nodal gradients without resorting to any form of quadrature. This idea aligns quite well with the whole spirit of edge-based schemes (or algebraic schemes) where we want to operate on matrices and vectors as directly as it could be possible avoiding by all means assembly of bilinear forms, cell-loops, quadrature, or any other intermediate construct/operation between the input arguments (the state from the previous time-step) and the actual matrices and vectors required to compute the update.
//
// The second thing to note is that we have to compute global minimum and maximum  [2.x.5059]  and  [2.x.5060] . Following the same ideas used to compute the time step size in the class member  [2.x.5061]  we define  [2.x.5062]  and  [2.x.5063]  as atomic doubles in order to resolve any conflicts between threads. As usual, we use  [2.x.5064]  and  [2.x.5065]  to find the global maximum/minimum among all MPI processes.
//
// Finally, it is not possible to compute the Schlieren indicator in a single loop over all nodes. The entire operation requires two loops over nodes:
//
//
//
// - The first loop computes  [2.x.5066]  for all  [2.x.5067]  in   the mesh, and the bounds  [2.x.5068]  and    [2.x.5069] .
//
// - The second loop finally computes the Schlieren indicator using the   formula
//
// [1.x.163]
//
// This means that we will have to define two workers  [2.x.5070]  for each one of these stages.
//
[0.x.40776] 
[0.x.40777] 
[0.x.40778] 
[0.x.40779] 
[0.x.40780] 
//
[0.x.40781] 
[0.x.40782] 
[0.x.40783] 
[0.x.40784] 
[0.x.40785] 
//
[0.x.40786] 
[0.x.40787] 
[0.x.40788] 
//
// We define the r_i_max and r_i_min in the current MPI process as atomic doubles in order to avoid race conditions between threads:
//
[0.x.40789] 
[0.x.40790] 
//
// First loop: compute the averaged gradient at each node and the global maxima and minima of the gradients.
//
[0.x.40791] 
[0.x.40792] 
[0.x.40793] 
[0.x.40794] 
[0.x.40795] 
//
[0.x.40796] 
[0.x.40797] 
[0.x.40798] 
//
[0.x.40799] 
//
[0.x.40800] 
[0.x.40801] 
[0.x.40802] 
//
[0.x.40803] 
[0.x.40804] 
//
[0.x.40805] 
[0.x.40806] 
[0.x.40807] 
[0.x.40808] 
//
//     We fix up the gradient r_i at free slip boundaries similarly to     how we fixed up boundary states in the forward Euler step.     This avoids sharp, artificial gradients in the Schlieren     plot at free slip boundaries and is a purely cosmetic choice.
//
[0.x.40809] 
[0.x.40810] 
[0.x.40811] 
[0.x.40812] 
[0.x.40813] 
//
[0.x.40814] 
[0.x.40815] 
[0.x.40816] 
[0.x.40817] 
[0.x.40818] 
//
//     We remind the reader that we are not interested in the nodal     gradients per se. We only want their norms in order to     compute the Schlieren indicator (weighted with the lumped     mass matrix  [2.x.5071] ):
//
[0.x.40819] 
[0.x.40820] 
[0.x.40821] 
[0.x.40822] 
[0.x.40823] 
//
// We compare the current_r_i_max and current_r_i_min (in the current subrange) with r_i_max and r_i_min (for the current MPI process) and update them if necessary:
//
[0.x.40824] 
[0.x.40825] 
[0.x.40826] 
[0.x.40827] 
[0.x.40828] 
//
[0.x.40829] 
[0.x.40830] 
[0.x.40831] 
[0.x.40832] 
[0.x.40833] 
[0.x.40834] 
//
[0.x.40835] 
[0.x.40836] 
[0.x.40837] 
[0.x.40838] 
[0.x.40839] 
//
// And synchronize  [2.x.5072]  over all MPI processes.
//
[0.x.40840] 
[0.x.40841] 
//
// Second loop: we now have the vector  [2.x.5073]  and the scalars  [2.x.5074]  at our disposal. We are thus in a position to actually compute the Schlieren indicator.
//
[0.x.40842] 
[0.x.40843] 
[0.x.40844] 
[0.x.40845] 
[0.x.40846] 
[0.x.40847] 
//
[0.x.40848] 
[0.x.40849] 
[0.x.40850] 
[0.x.40851] 
[0.x.40852] 
//
[0.x.40853] 
[0.x.40854] 
[0.x.40855] 
[0.x.40856] 
[0.x.40857] 
//
// And finally, exchange ghost elements.
//
[0.x.40858] 
[0.x.40859] 
//[2.x.5075] 
//
// With all classes implemented it is time to create an instance of  [2.x.5076] ,  [2.x.5077] , and  [2.x.5078] , and run the forward Euler step in a loop.
//
// In the constructor of  [2.x.5079]  we now initialize an instance of all classes, and declare a number of parameters controlling output. Most notable, we declare a boolean parameter  [2.x.5080]  that will control whether the program attempts to restart from an interrupted computation, or not.
//
[0.x.40860] 
[0.x.40861] 
[0.x.40862] 
[0.x.40863] 
[0.x.40864] 
[0.x.40865] 
[0.x.40866] 
[0.x.40867] 
[0.x.40868] 
[0.x.40869] 
[0.x.40870] 
[0.x.40871] 
[0.x.40872] 
[0.x.40873] 
[0.x.40874] 
[0.x.40875] 
[0.x.40876] 
[0.x.40877] 
[0.x.40878] 
[0.x.40879] 
[0.x.40880] 
[0.x.40881] 
[0.x.40882] 
[0.x.40883] 
[0.x.40884] 
[0.x.40885] 
[0.x.40886] 
//
[0.x.40887] 
[0.x.40888] 
//
[0.x.40889] 
[0.x.40890] 
[0.x.40891] 
[0.x.40892] 
//
[0.x.40893] 
[0.x.40894] 
[0.x.40895] 
[0.x.40896] 
//
[0.x.40897] 
[0.x.40898] 
[0.x.40899] 
//
// We start by implementing a helper function  [2.x.5081]  in an anonymous namespace that is used to output messages in the terminal with some nice formatting.
//
[0.x.40900] 
[0.x.40901] 
[0.x.40902] 
[0.x.40903] 
[0.x.40904] 
[0.x.40905] 
[0.x.40906] 
[0.x.40907] 
[0.x.40908] 
[0.x.40909] 
//
[0.x.40910] 
[0.x.40911] 
[0.x.40912] 
[0.x.40913] 
//
//      /* clang-format off  [2.x.5082] 
[0.x.40914] 
[0.x.40915] 
[0.x.40916] 
[0.x.40917] 
[0.x.40918] 
[0.x.40919] 
[0.x.40920] 
[0.x.40921] 
//
//      /* clang-format on  [2.x.5083] 
[0.x.40922] 
[0.x.40923] 
//
// With  [2.x.5084]  in place it is now time to implement the  [2.x.5085]  that contains the main loop of our program.
//
[0.x.40924] 
[0.x.40925] 
[0.x.40926] 
//
// We start by reading in parameters and initializing all objects. We note here that the call to  [2.x.5086]  reads in all parameters from the parameter file (whose name is given as a string argument). ParameterAcceptor handles a global ParameterHandler that is initialized with subsections and parameter declarations for all class instances that are derived from ParameterAceptor. The call to initialize enters the subsection for each each derived class, and sets all variables that were added using  [2.x.5087] 
[0.x.40927] 
//
[0.x.40928] 
[0.x.40929] 
//
// Next we create the triangulation, assemble all matrices, set up scratch space, and initialize the DataOut<dim> object:
//
[0.x.40930] 
[0.x.40931] 
[0.x.40932] 
//
[0.x.40933] 
[0.x.40934] 
[0.x.40935] 
//
[0.x.40936] 
[0.x.40937] 
[0.x.40938] 
//
[0.x.40939] 
[0.x.40940] 
//
[0.x.40941] 
[0.x.40942] 
[0.x.40943] 
[0.x.40944] 
//
// We will store the current time and state in the variable  [2.x.5088] :
//
[0.x.40945] 
[0.x.40946] 
//
[0.x.40947] 
[0.x.40948] 
//[2.x.5089] 
//
// By default the boolean  [2.x.5090]  is set to false, i.e. the following code snippet is not run. However, if  [2.x.5091]  we indicate that we have indeed an interrupted computation and the program shall restart by reading in an old state consisting of  [2.x.5092] ,  [2.x.5093]  from a checkpoint file. These checkpoint files will be created in the  [2.x.5094]  routine discussed below.
//
[0.x.40949] 
[0.x.40950] 
[0.x.40951] 
//
[0.x.40952] 
[0.x.40953] 
//
[0.x.40954] 
[0.x.40955] 
[0.x.40956] 
//
// We use a  [2.x.5095]  to store and read in the contents the checkpointed state.
//
[0.x.40957] 
[0.x.40958] 
//
[0.x.40959] 
[0.x.40960] 
//[2.x.5096]  iterates over all components of the state   vector  [2.x.5097] . We read in every entry of the   component in sequence and update the ghost layer afterwards:
//
[0.x.40961] 
[0.x.40962] 
[0.x.40963] 
[0.x.40964] 
[0.x.40965] 
//
// With either the initial state set up, or an interrupted state restored it is time to enter the main loop:
//
[0.x.40966] 
//
[0.x.40967] 
//
[0.x.40968] 
[0.x.40969] 
//
// We first print an informative status message
//
[0.x.40970] 
[0.x.40971] 
//
[0.x.40972] 
[0.x.40973] 
[0.x.40974] 
[0.x.40975] 
//
[0.x.40976] 
//
// and then perform a single forward Euler step. Note that the state vector  [2.x.5098]  is updated in place and that  [2.x.5099]  returns the chosen step size.
//
[0.x.40977] 
//
// Post processing, generating output and writing out the current state is a CPU and IO intensive task that we cannot afford to do every time step
//
// - in particular with explicit time stepping. We thus only schedule output by calling the  [2.x.5100]  function if we are past a threshold set by  [2.x.5101] .
//
[0.x.40978] 
[0.x.40979] 
[0.x.40980] 
[0.x.40981] 
[0.x.40982] 
[0.x.40983] 
//
// We wait for any remaining background output thread to finish before printing a summary and exiting.
//
[0.x.40984] 
[0.x.40985] 
//
[0.x.40986] 
[0.x.40987] 
[0.x.40988] 
//
// The  [2.x.5102]  takes an initial time "t" as input argument and populates a state vector  [2.x.5103]  with the help of the  [2.x.5104]  object.
//
[0.x.40989] 
[0.x.40990] 
[0.x.40991] 
[0.x.40992] 
[0.x.40993] 
[0.x.40994] 
[0.x.40995] 
[0.x.40996] 
//
[0.x.40997] 
//
[0.x.40998] 
[0.x.40999] 
//
[0.x.41000] 
[0.x.41001] 
//
// The function signature of  [2.x.5105]  is not quite right for  [2.x.5106]  We work around this issue by, first, creating a lambda function that for a given position  [2.x.5107]  returns just the value of the  [2.x.5108] th component. This lambda in turn is converted to a  [2.x.5109]  with the help of the ScalarFunctionFromFunctionObject wrapper.
//
[0.x.41002] 
[0.x.41003] 
[0.x.41004] 
[0.x.41005] 
[0.x.41006] 
[0.x.41007] 
[0.x.41008] 
//
[0.x.41009] 
[0.x.41010] 
//
[0.x.41011] 
[0.x.41012] 
//[2.x.5110] 
//
// Writing out the final vtk files is quite an IO intensive task that can stall the main loop for a while. In order to avoid this we use an [1.x.164] strategy by creating a background thread that will perform IO while the main loop is allowed to continue. In order for this to work we have to be mindful of two things: 
//
// - Before running the  [2.x.5111]  thread, we have to create    a copy of the state vector  [2.x.5112] . We store it in the    vector  [2.x.5113] . 
//
// - We have to avoid any MPI communication in the background thread,    otherwise the program might deadlock. This implies that we have to    run the postprocessing outside of the worker thread.
//
[0.x.41013] 
[0.x.41014] 
[0.x.41015] 
[0.x.41016] 
[0.x.41017] 
[0.x.41018] 
[0.x.41019] 
[0.x.41020] 
[0.x.41021] 
//
// If the asynchronous writeback option is set we launch a background thread performing all the slow IO to disc. In that case we have to make sure that the background thread actually finished running. If not, we have to wait to for it to finish. We launch said background thread with [1.x.165] that returns a [1.x.166] object. This  [2.x.5114]  object contains the return value of the function, which is in our case simply  [2.x.5115] .
//
[0.x.41022] 
[0.x.41023] 
[0.x.41024] 
[0.x.41025] 
[0.x.41026] 
//
[0.x.41027] 
[0.x.41028] 
//
// At this point we make a copy of the state vector, run the schlieren postprocessor, and run  [2.x.5116]  The actual output code is standard: We create a DataOut instance, attach all data vectors we want to output and call  [2.x.5117]  There is one twist, however. In order to perform asynchronous IO on a background thread we create the DataOut<dim> object as a shared pointer that we pass on to the worker thread to ensure that once we exit this function and the worker thread finishes the DataOut<dim> object gets destroyed again.
//
[0.x.41029] 
[0.x.41030] 
[0.x.41031] 
[0.x.41032] 
[0.x.41033] 
//
[0.x.41034] 
//
[0.x.41035] 
//
[0.x.41036] 
//
[0.x.41037] 
//
[0.x.41038] 
[0.x.41039] 
//
[0.x.41040] 
[0.x.41041] 
//
[0.x.41042] 
[0.x.41043] 
//
// Next we create a lambda function for the background thread. We [1.x.167] the  [2.x.5118]  pointer as well as most of the arguments of the output function by value so that we have access to them inside the lambda function.
//
[0.x.41044] 
[0.x.41045] 
[0.x.41046] 
//
// We checkpoint the current state by doing the precise inverse operation to what we discussed for the [1.x.168]:
//
[0.x.41047] 
[0.x.41048] 
[0.x.41049] 
[0.x.41050] 
//
[0.x.41051] 
//
[0.x.41052] 
[0.x.41053] 
[0.x.41054] 
[0.x.41055] 
[0.x.41056] 
[0.x.41057] 
//
[0.x.41058] 
[0.x.41059] 
[0.x.41060] 
[0.x.41061] 
[0.x.41062] 
//
[0.x.41063] 
[0.x.41064] 
[0.x.41065] 
//
// If the asynchronous writeback option is set we launch a new background thread with the help of [1.x.169] function. The function returns a [1.x.170] object that we can use to query the status of the background thread. At this point we can return from the  [2.x.5119]  function and resume with the time stepping in the main loop
//
// - the thread will run in the background.
//
[0.x.41066] 
[0.x.41067] 
[0.x.41068] 
[0.x.41069] 
[0.x.41070] 
[0.x.41071] 
[0.x.41072] 
[0.x.41073] 
[0.x.41074] 
//
[0.x.41075] 
//
// And finally, the main function.
//
[0.x.41076] 
[0.x.41077] 
[0.x.41078] 
[0.x.41079] 
[0.x.41080] 
//
[0.x.41081] 
[0.x.41082] 
//
[0.x.41083] 
//
[0.x.41084] 
[0.x.41085] 
//
[0.x.41086] 
[0.x.41087] 
[0.x.41088] 
[0.x.41089] 
[0.x.41090] 
[0.x.41091] 
[0.x.41092] 
[0.x.41093] 
[0.x.41094] 
[0.x.41095] 
[0.x.41096] 
[0.x.41097] 
[0.x.41098] 
[0.x.41099] 
[0.x.41100] 
[0.x.41101] 
[0.x.41102] 
[0.x.41103] 
[0.x.41104] 
[0.x.41105] 
[0.x.41106] 
[0.x.41107] 
[0.x.41108] 
[0.x.41109] 
[0.x.41110] 
[0.x.41111] 
[0.x.41112] 
[0.x.41113] 
[0.x.41114] 
[0.x.41115] 
[0.x.41116] 
[0.x.41117] 
[0.x.41118] 
[0.x.41119] 
[0.x.41120] 
[0.x.41121] 
[0.x.41122] 
[0.x.41123] 
[0.x.41124] 
[0.x.41125] 
[0.x.41126] 
[0.x.41127] 
//
[0.x.41128] 
[0.x.41129] 
[0.x.41130] 
//[2.x.5120] 
//
// These first include files have all been treated in previous examples, so we won't explain what is in them again.
//
[0.x.41131] 
[0.x.41132] 
[0.x.41133] 
[0.x.41134] 
[0.x.41135] 
[0.x.41136] 
[0.x.41137] 
[0.x.41138] 
[0.x.41139] 
[0.x.41140] 
[0.x.41141] 
[0.x.41142] 
[0.x.41143] 
[0.x.41144] 
[0.x.41145] 
[0.x.41146] 
[0.x.41147] 
[0.x.41148] 
[0.x.41149] 
//
// In this example, we will not use the numeration scheme which is used per default by the DoFHandler class, but will renumber them using the Cuthill-McKee algorithm. As has already been explained in  [2.x.5121] , the necessary functions are declared in the following file:
//
[0.x.41150] 
//
// Then we will show a little trick how we can make sure that objects are not deleted while they are still in use. For this purpose, deal.II has the SmartPointer helper class, which is declared in this file:
//
[0.x.41151] 
//
// Next, we will want to use the function  [2.x.5122]  mentioned in the introduction, and we are going to use a ConvergenceTable that collects all important data during a run and prints it at the end as a table. These comes from the following two files:
//
[0.x.41152] 
[0.x.41153] 
//
// And finally, we need to use the FEFaceValues class, which is declared in the same file as the FEValues class:
//
[0.x.41154] 
//
[0.x.41155] 
[0.x.41156] 
[0.x.41157] 
//
// The last step before we go on with the actual implementation is to open a namespace  [2.x.5123]  into which we will put everything, as discussed at the end of the introduction, and to import the members of namespace  [2.x.5124]  into it:
//
[0.x.41158] 
[0.x.41159] 
[0.x.41160] 
//[2.x.5125] 
//
// Before implementing the classes that actually solve something, we first declare and define some function classes that represent right hand side and solution classes. Since we want to compare the numerically obtained solution to the exact continuous one, we need a function object that represents the continuous solution. On the other hand, we need the right hand side function, and that one of course shares some characteristics with the solution. In order to reduce dependencies which arise if we have to change something in both classes at the same time, we move the common characteristics of both functions into a base class.
//
// The common characteristics for solution (as explained in the introduction, we choose a sum of three exponentials) and right hand side, are these: the number of exponentials, their centers, and their half width. We declare them in the following class. Since the number of exponentials is a compile-time constant we use a fixed-length  [2.x.5126]  to store the center points:
//
[0.x.41161] 
[0.x.41162] 
[0.x.41163] 
[0.x.41164] 
[0.x.41165] 
[0.x.41166] 
[0.x.41167] 
//
// The variables which denote the centers and the width of the exponentials have just been declared, now we still need to assign values to them. Here, we can show another small piece of template sorcery, namely how we can assign different values to these variables depending on the dimension. We will only use the 2d case in the program, but we show the 1d case for exposition of a useful technique.
//
// First we assign values to the centers for the 1d case, where we place the centers equidistantly at -1/3, 0, and 1/3. The <code>template &lt;&gt;</code> header for this definition indicates an explicit specialization. This means, that the variable belongs to a template, but that instead of providing the compiler with a template from which it can specialize a concrete variable by substituting  [2.x.5127]  with some concrete value, we provide a specialization ourselves, in this case for  [2.x.5128] . If the compiler then sees a reference to this variable in a place where the template argument equals one, it knows that it doesn't have to generate the variable from a template by substituting  [2.x.5129] , but can immediately use the following definition:
//
[0.x.41168] 
[0.x.41169] 
[0.x.41170] 
//
// Likewise, we can provide an explicit specialization for  [2.x.5130] . We place the centers for the 2d case as follows:
//
[0.x.41171] 
[0.x.41172] 
[0.x.41173] 
//
// There remains to assign a value to the half-width of the exponentials. We would like to use the same value for all dimensions. In this case, we simply provide the compiler with a template from which it can generate a concrete instantiation by substituting  [2.x.5131]  with a concrete value:
//
[0.x.41174] 
[0.x.41175] 
//
// After declaring and defining the characteristics of solution and right hand side, we can declare the classes representing these two. They both represent continuous functions, so they are derived from the Function&lt;dim&gt; base class, and they also inherit the characteristics defined in the SolutionBase class.
//
// The actual classes are declared in the following. Note that in order to compute the error of the numerical solution against the continuous one in the L2 and H1 (semi-)norms, we have to provide value and gradient of the exact solution. This is more than we have done in previous examples, where all we provided was the value at one or a list of points. Fortunately, the Function class also has virtual functions for the gradient, so we can simply overload the respective virtual member functions in the Function base class. Note that the gradient of a function in  [2.x.5132]  space dimensions is a vector of size  [2.x.5133] , i.e. a tensor of rank 1 and dimension  [2.x.5134] . As for so many other things, the library provides a suitable class for this. One new thing about this class is that it explicitly uses the Tensor objects, which previously appeared as intermediate terms in  [2.x.5135]  and  [2.x.5136] . A tensor is a generalization of scalars (rank zero tensors), vectors (rank one tensors), and matrices (rank two tensors), as well as higher dimensional objects. The Tensor class requires two template arguments: the tensor rank and tensor dimension. For example, here we use tensors of rank one (vectors) with dimension  [2.x.5137]  entries.) While this is a bit less flexible than using Vector, the compiler can generate faster code when the length of the vector is known at compile time. Additionally, specifying a Tensor of rank one and dimension  [2.x.5138]  guarantees that the tensor will have the right shape (since it is built into the type of the object itself), so the compiler can catch most size-related mistakes for us.
//
[0.x.41176] 
[0.x.41177] 
[0.x.41178] 
[0.x.41179] 
[0.x.41180] 
[0.x.41181] 
//
[0.x.41182] 
[0.x.41183] 
[0.x.41184] 
[0.x.41185] 
//
// The actual definition of the values and gradients of the exact solution class is according to their mathematical definition and does not need much explanation.
//
// The only thing that is worth mentioning is that if we access elements of a base class that is template dependent (in this case the elements of SolutionBase&lt;dim&gt;), then the C++ language forces us to write  [2.x.5139] , and similarly for other members of the base class. C++ does not require the  [2.x.5140]  qualification if the base class is not template dependent. The reason why this is necessary is complicated; C++ books will explain under the phrase [1.x.171], and there is also a lengthy description in the deal.II FAQs.
//
[0.x.41186] 
[0.x.41187] 
[0.x.41188] 
[0.x.41189] 
[0.x.41190] 
[0.x.41191] 
[0.x.41192] 
[0.x.41193] 
[0.x.41194] 
[0.x.41195] 
//
[0.x.41196] 
[0.x.41197] 
//
// Likewise, this is the computation of the gradient of the solution.  In order to accumulate the gradient from the contributions of the exponentials, we allocate an object  [2.x.5141]  that denotes the mathematical quantity of a tensor of rank  [2.x.5142]  and dimension  [2.x.5143] . Its default constructor sets it to the vector containing only zeroes, so we need not explicitly care for its initialization.
//
// Note that we could as well have taken the type of the object to be Point&lt;dim&gt; instead of Tensor&lt;1,dim&gt;. Tensors of rank 1 and points are almost exchangeable, and have only very slightly different mathematical meanings. In fact, the Point&lt;dim&gt; class is derived from the Tensor&lt;1,dim&gt; class, which makes up for their mutual exchange ability. Their main difference is in what they logically mean: points are points in space, such as the location at which we want to evaluate a function (see the type of the first argument of this function for example). On the other hand, tensors of rank 1 share the same transformation properties, for example that they need to be rotated in a certain way when we change the coordinate system; however, they do not share the same connotation that points have and are only objects in a more abstract space than the one spanned by the coordinate directions. (In fact, gradients live in `reciprocal' space, since the dimension of their components is not that of a length, but of one over length).
//
[0.x.41198] 
[0.x.41199] 
[0.x.41200] 
[0.x.41201] 
[0.x.41202] 
//
[0.x.41203] 
[0.x.41204] 
[0.x.41205] 
//
// For the gradient, note that its direction is along (x-x_i), so we add up multiples of this distance vector, where the factor is given by the exponentials.
//
[0.x.41206] 
[0.x.41207] 
[0.x.41208] 
[0.x.41209] 
[0.x.41210] 
//
[0.x.41211] 
[0.x.41212] 
//
// Besides the function that represents the exact solution, we also need a function which we can use as right hand side when assembling the linear system of discretized equations. This is accomplished using the following class and the following definition of its function. Note that here we only need the value of the function, not its gradients or higher derivatives.
//
[0.x.41213] 
[0.x.41214] 
[0.x.41215] 
[0.x.41216] 
[0.x.41217] 
[0.x.41218] 
[0.x.41219] 
//
// The value of the right hand side is given by the negative Laplacian of the solution plus the solution itself, since we wanted to solve Helmholtz's equation:
//
[0.x.41220] 
[0.x.41221] 
[0.x.41222] 
[0.x.41223] 
[0.x.41224] 
[0.x.41225] 
[0.x.41226] 
[0.x.41227] 
//
// The first contribution is the Laplacian:
//
[0.x.41228] 
[0.x.41229] 
[0.x.41230] 
[0.x.41231] 
[0.x.41232] 
//
// And the second is the solution itself:
//
[0.x.41233] 
[0.x.41234] 
[0.x.41235] 
//
[0.x.41236] 
[0.x.41237] 
//[2.x.5144] 
//
// Then we need the class that does all the work. Except for its name, its interface is mostly the same as in previous examples.
//
// One of the differences is that we will use this class in several modes: for different finite elements, as well as for adaptive and global refinement. The decision whether global or adaptive refinement shall be used is communicated to the constructor of this class through an enumeration type declared at the top of the class. The constructor then takes a finite element object and the refinement mode as arguments.
//
// The rest of the member functions are as before except for the  [2.x.5145]  function: After the solution has been computed, we perform some analysis on it, such as computing the error in various norms. To enable some output, it requires the number of the refinement cycle, and consequently gets it as an argument.
//
[0.x.41238] 
[0.x.41239] 
[0.x.41240] 
[0.x.41241] 
[0.x.41242] 
[0.x.41243] 
[0.x.41244] 
[0.x.41245] 
[0.x.41246] 
//
[0.x.41247] 
[0.x.41248] 
//
[0.x.41249] 
//
[0.x.41250] 
[0.x.41251] 
[0.x.41252] 
[0.x.41253] 
[0.x.41254] 
[0.x.41255] 
//
// Now for the data elements of this class. Among the variables that we have already used in previous examples, only the finite element object differs: The finite elements which the objects of this class operate on are passed to the constructor of this class. It has to store a pointer to the finite element for the member functions to use. Now, for the present class there is no big deal in that, but since we want to show techniques rather than solutions in these programs, we will here point out a problem that often occurs -- and of course the right solution as well.
//
// Consider the following situation that occurs in all the example programs: we have a triangulation object, and we have a finite element object, and we also have an object of type DoFHandler that uses both of the first two. These three objects all have a lifetime that is rather long compared to most other objects: they are basically set at the beginning of the program or an outer loop, and they are destroyed at the very end. The question is: can we guarantee that the two objects which the DoFHandler uses, live at least as long as they are in use? This means that the DoFHandler must have some kind of knowledge on the destruction of the other objects.
//
// We will show here how the library managed to find out that there are still active references to an object and the object is still alive from the point of view of a using object. Basically, the method is along the following line: all objects that are subject to such potentially dangerous pointers are derived from a class called Subscriptor. For example, the Triangulation, DoFHandler, and a base class of the FiniteElement class are derived from Subscriptor. This latter class does not offer much functionality, but it has a built-in counter which we can subscribe to, thus the name of the class. Whenever we initialize a pointer to that object, we can increase its use counter, and when we move away our pointer or do not need it any more, we decrease the counter again. This way, we can always check how many objects still use that object. Additionally, the class requires to know about a pointer that it can use to tell the subscribing object about its invalidation.
//
// If an object of a class that is derived from the Subscriptor class is destroyed, it also has to call the destructor of the Subscriptor class. In this destructor, we tell all the subscribing objects about the invalidation of the object using the stored pointers. The same happens when the object appears on the right hand side of a move expression, i.e., it will no longer contain valid content after the operation. The subscribing class is expected to check the value stored in its corresponding pointer before trying to access the object subscribed to.
//
// This is exactly what the SmartPointer class is doing. It basically acts just like a pointer, i.e. it can be dereferenced, can be assigned to and from other pointers, and so on. On top of that it uses the mechanism described above to find out if the pointer this class is representing is dangling when we try to dereference it. In that case an exception is thrown.
//
// In the present example program, we want to protect the finite element object from the situation that for some reason the finite element pointed to is destroyed while still in use. We therefore use a SmartPointer to the finite element object; since the finite element object is actually never changed in our computations, we pass a const FiniteElement&lt;dim&gt; as template argument to the SmartPointer class. Note that the pointer so declared is assigned at construction time of the solve object, and destroyed upon destruction, so the lock on the destruction of the finite element object extends throughout the lifetime of this HelmholtzProblem object.
//
[0.x.41256] 
[0.x.41257] 
//
[0.x.41258] 
//
[0.x.41259] 
//
[0.x.41260] 
[0.x.41261] 
//
[0.x.41262] 
[0.x.41263] 
//
// The second to last variable stores the refinement mode passed to the constructor. Since it is only set in the constructor, we can declare this variable constant, to avoid that someone sets it involuntarily (e.g. in an `if'-statement where == was written as = by chance).
//
[0.x.41264] 
//
// For each refinement level some data (like the number of cells, or the L2 error of the numerical solution) will be generated and later printed. The TableHandler can be used to collect all this data and to output it at the end of the run as a table in a simple text or in LaTeX format. Here we don't only use the TableHandler but we use the derived class ConvergenceTable that additionally evaluates rates of convergence:
//
[0.x.41265] 
[0.x.41266] 
//[2.x.5146] 
//[2.x.5147] 
//
// In the constructor of this class, we only set the variables passed as arguments, and associate the DoF handler object with the triangulation (which is empty at present, however).
//
[0.x.41267] 
[0.x.41268] 
[0.x.41269] 
[0.x.41270] 
[0.x.41271] 
[0.x.41272] 
[0.x.41273] 
//[2.x.5148] 
//
// The following function sets up the degrees of freedom, sizes of matrices and vectors, etc. Most of its functionality has been showed in previous examples, the only difference being the renumbering step immediately after first distributing degrees of freedom.
//
// Renumbering the degrees of freedom is not overly difficult, as long as you use one of the algorithms included in the library. It requires only a single line of code. Some more information on this can be found in  [2.x.5149] .
//
// Note, however, that when you renumber the degrees of freedom, you must do so immediately after distributing them, since such things as hanging nodes, the sparsity pattern etc. depend on the absolute numbers which are altered by renumbering.
//
// The reason why we introduce renumbering here is that it is a relatively cheap operation but often has a beneficial effect: While the CG iteration itself is independent of the actual ordering of degrees of freedom, we will use SSOR as a preconditioner. SSOR goes through all degrees of freedom and does some operations that depend on what happened before; the SSOR operation is therefore not independent of the numbering of degrees of freedom, and it is known that its performance improves by using renumbering techniques. A little experiment shows that indeed, for example, the number of CG iterations for the fifth refinement cycle of adaptive refinement with the Q1 program used here is 40 without, but 36 with renumbering. Similar savings can generally be observed for all the computations in this program.
//
[0.x.41274] 
[0.x.41275] 
[0.x.41276] 
[0.x.41277] 
[0.x.41278] 
//
[0.x.41279] 
[0.x.41280] 
[0.x.41281] 
[0.x.41282] 
//
[0.x.41283] 
[0.x.41284] 
[0.x.41285] 
[0.x.41286] 
//
[0.x.41287] 
//
[0.x.41288] 
[0.x.41289] 
[0.x.41290] 
//[2.x.5150] 
//
// Assembling the system of equations for the problem at hand is mostly as for the example programs before. However, some things have changed anyway, so we comment on this function fairly extensively.
//
// At the top of the function you will find the usual assortment of variable declarations. Compared to previous programs, of importance is only that we expect to solve problems also with bi-quadratic elements and therefore have to use sufficiently accurate quadrature formula. In addition, we need to compute integrals over faces, i.e.  [2.x.5151]  dimensional objects. The declaration of a face quadrature formula is then straightforward:
//
[0.x.41291] 
[0.x.41292] 
[0.x.41293] 
[0.x.41294] 
[0.x.41295] 
//
[0.x.41296] 
[0.x.41297] 
//
[0.x.41298] 
//
[0.x.41299] 
[0.x.41300] 
//
[0.x.41301] 
//
// Then we need objects which can evaluate the values, gradients, etc of the shape functions at the quadrature points. While it seems that it should be feasible to do it with one object for both domain and face integrals, there is a subtle difference since the weights in the domain integrals include the measure of the cell in the domain, while the face integral quadrature requires the measure of the face in a lower-dimensional manifold. Internally these two classes are rooted in a common base class which does most of the work and offers the same interface to both domain and interface integrals.
//
// For the domain integrals in the bilinear form for Helmholtz's equation, we need to compute the values and gradients, as well as the weights at the quadrature points. Furthermore, we need the quadrature points on the real cell (rather than on the unit cell) to evaluate the right hand side function. The object we use to get at this information is the FEValues class discussed previously.
//
// For the face integrals, we only need the values of the shape functions, as well as the weights. We also need the normal vectors and quadrature points on the real cell since we want to determine the Neumann values from the exact solution object (see below). The class that gives us this information is called FEFaceValues:
//
[0.x.41302] 
[0.x.41303] 
[0.x.41304] 
[0.x.41305] 
//
[0.x.41306] 
[0.x.41307] 
[0.x.41308] 
[0.x.41309] 
[0.x.41310] 
//
// Then we need some objects already known from previous examples: An object denoting the right hand side function, its values at the quadrature points on a cell, the cell matrix and right hand side, and the indices of the degrees of freedom on a cell.
//
// Note that the operations we will do with the right hand side object are only querying data, never changing the object. We can therefore declare it  [2.x.5152] :
//
[0.x.41311] 
[0.x.41312] 
//
// Finally we define an object denoting the exact solution function. We will use it to compute the Neumann values at the boundary from it. Usually, one would of course do so using a separate object, in particular since the exact solution is generally unknown while the Neumann values are prescribed. We will, however, be a little bit lazy and use what we already have in information. Real-life programs would to go other ways here, of course.
//
[0.x.41313] 
//
// Now for the main loop over all cells. This is mostly unchanged from previous examples, so we only comment on the things that have changed.
//
[0.x.41314] 
[0.x.41315] 
[0.x.41316] 
[0.x.41317] 
//
[0.x.41318] 
//
[0.x.41319] 
[0.x.41320] 
//
[0.x.41321] 
[0.x.41322] 
[0.x.41323] 
[0.x.41324] 
//
//       The first thing that has changed is the bilinear form. It       now contains the additional term from the Helmholtz       equation:
//
[0.x.41325] 
[0.x.41326] 
[0.x.41327] 
[0.x.41328] 
[0.x.41329] 
[0.x.41330] 
[0.x.41331] 
//
[0.x.41332] 
[0.x.41333] 
[0.x.41334] 
[0.x.41335] 
//
// Then there is that second term on the right hand side, the contour integral. First we have to find out whether the intersection of the faces of this cell with the boundary part Gamma2 is nonzero. To this end, we loop over all faces and check whether its boundary indicator equals  [2.x.5153] , which is the value that we have assigned to that portions of the boundary composing Gamma2 in the  [2.x.5154]  function further below. (The default value of boundary indicators is  [2.x.5155] , so faces can only have an indicator equal to  [2.x.5156]  if we have explicitly set it.)
//
[0.x.41336] 
[0.x.41337] 
[0.x.41338] 
//
//     If we came into here, then we have found an external face     belonging to Gamma2. Next, we have to compute the values of     the shape functions and the other quantities which we will     need for the computation of the contour integral. This is     done using the  [2.x.5157]  function which we already     know from the FEValue class:
//
[0.x.41339] 
//
//     And we can then perform the integration by using a loop over     all quadrature points.         On each quadrature point, we first compute the value of the     normal derivative. We do so using the gradient of the exact     solution and the normal vector to the face at the present     quadrature point obtained from the      [2.x.5158]  object. This is then used to     compute the additional contribution of this face to the right     hand side:
//
[0.x.41340] 
[0.x.41341] 
[0.x.41342] 
[0.x.41343] 
[0.x.41344] 
[0.x.41345] 
[0.x.41346] 
//
[0.x.41347] 
[0.x.41348] 
[0.x.41349] 
[0.x.41350] 
[0.x.41351] 
[0.x.41352] 
[0.x.41353] 
//
// Now that we have the contributions of the present cell, we can transfer it to the global matrix and right hand side vector, as in the examples before:
//
[0.x.41354] 
[0.x.41355] 
[0.x.41356] 
[0.x.41357] 
[0.x.41358] 
[0.x.41359] 
[0.x.41360] 
//
[0.x.41361] 
[0.x.41362] 
[0.x.41363] 
//
// Likewise, elimination and treatment of boundary values has been shown previously.
//
// We note, however that now the boundary indicator for which we interpolate boundary values (denoted by the second parameter to  [2.x.5159] ) does not represent the whole boundary any more. Rather, it is that portion of the boundary which we have not assigned another indicator (see below). The degrees of freedom at the boundary that do not belong to Gamma1 are therefore excluded from the interpolation of boundary values, just as we want.
//
[0.x.41364] 
[0.x.41365] 
//
[0.x.41366] 
[0.x.41367] 
[0.x.41368] 
[0.x.41369] 
[0.x.41370] 
[0.x.41371] 
[0.x.41372] 
[0.x.41373] 
[0.x.41374] 
[0.x.41375] 
//[2.x.5160] 
//
// Solving the system of equations is done in the same way as before:
//
[0.x.41376] 
[0.x.41377] 
[0.x.41378] 
[0.x.41379] 
[0.x.41380] 
//
[0.x.41381] 
[0.x.41382] 
//
[0.x.41383] 
//
[0.x.41384] 
[0.x.41385] 
//[2.x.5161] 
//
// Now for the function doing grid refinement. Depending on the refinement mode passed to the constructor, we do global or adaptive refinement.
//
// Global refinement is simple, so there is not much to comment on.  In case of adaptive refinement, we use the same functions and classes as in the previous example program. Note that one could treat Neumann boundaries differently than Dirichlet boundaries, and one should in fact do so here since we have Neumann boundary conditions on part of the boundaries, but since we don't have a function here that describes the Neumann values (we only construct these values from the exact solution when assembling the matrix), we omit this detail even though doing this in a strictly correct way would not be hard to add.
//
// At the end of the switch, we have a default case that looks slightly strange: an  [2.x.5162]  condition. Since the  [2.x.5163]  macro raises an error whenever the condition is false, this means that whenever we hit this statement the program will be aborted. This in intentional: Right now we have only implemented two refinement strategies (global and adaptive), but someone might want to add a third strategy (for example adaptivity with a different refinement criterion) and add a third member to the enumeration that determines the refinement mode. If it weren't for the default case of the switch statement, this function would simply run to its end without doing anything. This is most likely not what was intended. One of the defensive programming techniques that you will find all over the deal.II library is therefore to always have default cases that abort, to make sure that values not considered when listing the cases in the switch statement are eventually caught, and forcing programmers to add code to handle them. We will use this same technique in other places further down as well.
//
[0.x.41386] 
[0.x.41387] 
[0.x.41388] 
[0.x.41389] 
[0.x.41390] 
[0.x.41391] 
[0.x.41392] 
[0.x.41393] 
[0.x.41394] 
[0.x.41395] 
//
[0.x.41396] 
[0.x.41397] 
[0.x.41398] 
[0.x.41399] 
//
[0.x.41400] 
[0.x.41401] 
[0.x.41402] 
[0.x.41403] 
[0.x.41404] 
[0.x.41405] 
//
[0.x.41406] 
[0.x.41407] 
//
[0.x.41408] 
//
[0.x.41409] 
[0.x.41410] 
//
[0.x.41411] 
[0.x.41412] 
[0.x.41413] 
[0.x.41414] 
[0.x.41415] 
[0.x.41416] 
//[2.x.5164] 
//
// Finally we want to process the solution after it has been computed. For this, we integrate the error in various (semi-)norms, and we generate tables that will later be used to display the convergence against the continuous solution in a nice format.
//
[0.x.41417] 
[0.x.41418] 
[0.x.41419] 
//
// Our first task is to compute error norms. In order to integrate the difference between computed numerical solution and the continuous solution (described by the Solution class defined at the top of this file), we first need a vector that will hold the norm of the error on each cell. Since accuracy with 16 digits is not so important for these quantities, we save some memory by using  [2.x.5165]  instead of  [2.x.5166]  values.
//
// The next step is to use a function from the library which computes the error in the L2 norm on each cell.  We have to pass it the DoF handler object, the vector holding the nodal values of the numerical solution, the continuous solution as a function object, the vector into which it shall place the norm of the error on each cell, a quadrature rule by which this norm shall be computed, and the type of norm to be used. Here, we use a Gauss formula with three points in each space direction, and compute the L2 norm.
//
// Finally, we want to get the global L2 norm. This can of course be obtained by summing the squares of the norms on each cell, and taking the square root of that value. This is equivalent to taking the l2 (lower case  [2.x.5167] ) norm of the vector of norms on each cell:
//
[0.x.41420] 
[0.x.41421] 
[0.x.41422] 
[0.x.41423] 
[0.x.41424] 
[0.x.41425] 
[0.x.41426] 
[0.x.41427] 
[0.x.41428] 
[0.x.41429] 
[0.x.41430] 
//
// By same procedure we get the H1 semi-norm. We re-use the  [2.x.5168]  vector since it is no longer used after computing the  [2.x.5169]  variable above. The global  [2.x.5170]  semi-norm error is then computed by taking the sum of squares of the errors on each individual cell, and then the square root of it -- an operation that is conveniently performed by  [2.x.5171] 
[0.x.41431] 
[0.x.41432] 
[0.x.41433] 
[0.x.41434] 
[0.x.41435] 
[0.x.41436] 
[0.x.41437] 
[0.x.41438] 
[0.x.41439] 
[0.x.41440] 
//
// Finally, we compute the maximum norm. Of course, we can't actually compute the true maximum of the error over *all* points in the domain, but only the maximum over a finite set of evaluation points that, for convenience, we will still call "quadrature points" and represent by an object of type Quadrature even though we do not actually perform any integration.
//
// There is then the question of what points precisely we want to evaluate at. It turns out that the result we get depends quite sensitively on the "quadrature" points being used. There is also the issue of superconvergence: Finite element solutions are, on some meshes and for polynomial degrees  [2.x.5172] , particularly accurate at the node points as well as at Gauss-Lobatto points, much more accurate than at randomly chosen points. (See  [2.x.5173]  and the discussion and references in Section 1.2 for more information on this.) In other words, if we are interested in finding the largest difference  [2.x.5174] , then we ought to look at points  [2.x.5175]  that are specifically not of this "special" kind of points and we should specifically not use `QGauss(fe->degree+1)` to define where we evaluate. Rather, we use a special quadrature rule that is obtained by iterating the trapezoidal rule by the degree of the finite element times two plus one in each space direction. Note that the constructor of the QIterated class takes a one-dimensional quadrature rule and a number that tells it how often it shall repeat this rule in each space direction.
//
// Using this special quadrature rule, we can then try to find the maximal error on each cell. Finally, we compute the global L infinity error from the L infinity errors on each cell with a call to  [2.x.5176] 
[0.x.41441] 
[0.x.41442] 
[0.x.41443] 
[0.x.41444] 
[0.x.41445] 
[0.x.41446] 
[0.x.41447] 
[0.x.41448] 
[0.x.41449] 
[0.x.41450] 
[0.x.41451] 
[0.x.41452] 
//
// After all these errors have been computed, we finally write some output. In addition, we add the important data to the TableHandler by specifying the key of the column and the value.  Note that it is not necessary to define column keys beforehand -- it is sufficient to just add values, and columns will be introduced into the table in the order values are added the first time.
//
[0.x.41453] 
[0.x.41454] 
//
[0.x.41455] 
[0.x.41456] 
[0.x.41457] 
[0.x.41458] 
//
[0.x.41459] 
[0.x.41460] 
[0.x.41461] 
[0.x.41462] 
[0.x.41463] 
[0.x.41464] 
[0.x.41465] 
//[2.x.5177] 
//
// As in previous example programs, the  [2.x.5178]  function controls the flow of execution. The basic layout is as in previous examples: an outer loop over successively refined grids, and in this loop first problem setup, assembling the linear system, solution, and post-processing.
//
// The first task in the main loop is creation and refinement of grids. This is as in previous examples, with the only difference that we want to have part of the boundary marked as Neumann type, rather than Dirichlet.
//
// For this, we will use the following convention: Faces belonging to Gamma1 will have the boundary indicator  [2.x.5179]  (which is the default, so we don't have to set it explicitly), and faces belonging to Gamma2 will use  [2.x.5180]  as boundary indicator.  To set these values, we loop over all cells, then over all faces of a given cell, check whether it is part of the boundary that we want to denote by Gamma2, and if so set its boundary indicator to  [2.x.5181] . For the present program, we consider the left and bottom boundaries as Gamma2. We determine whether a face is part of that boundary by asking whether the x or y coordinates (i.e. vector components 0 and 1) of the midpoint of a face equals -1, up to some small wiggle room that we have to give since it is instable to compare floating point numbers that are subject to round off in intermediate computations.
//
// It is worth noting that we have to loop over all cells here, not only the active ones. The reason is that upon refinement, newly created faces inherit the boundary indicator of their parent face. If we now only set the boundary indicator for active faces, coarsen some cells and refine them later on, they will again have the boundary indicator of the parent cell which we have not modified, instead of the one we intended. Consequently, we have to change the boundary indicators of faces of all cells on Gamma2, whether they are active or not. Alternatively, we could of course have done this job on the coarsest mesh (i.e. before the first refinement step) and refined the mesh only after that.
//
[0.x.41466] 
[0.x.41467] 
[0.x.41468] 
[0.x.41469] 
[0.x.41470] 
[0.x.41471] 
[0.x.41472] 
[0.x.41473] 
[0.x.41474] 
[0.x.41475] 
[0.x.41476] 
//
[0.x.41477] 
[0.x.41478] 
[0.x.41479] 
[0.x.41480] 
[0.x.41481] 
[0.x.41482] 
[0.x.41483] 
[0.x.41484] 
[0.x.41485] 
[0.x.41486] 
[0.x.41487] 
//
// The next steps are already known from previous examples. This is mostly the basic set-up of every finite element program:
//
[0.x.41488] 
//
[0.x.41489] 
[0.x.41490] 
//
// The last step in this chain of function calls is usually the evaluation of the computed solution for the quantities one is interested in. This is done in the following function. Since the function generates output that indicates the number of the present refinement step, we pass this number as an argument.
//
[0.x.41491] 
[0.x.41492] 
//[2.x.5182] 
//
// After the last iteration we output the solution on the finest grid. This is done using the following sequence of statements which we have already discussed in previous examples. The first step is to generate a suitable filename (called  [2.x.5183]  here, since we want to output data in VTK format; we add the prefix to distinguish the filename from that used for other output files further down below). Here, we augment the name by the mesh refinement algorithm, and as above we make sure that we abort the program if another refinement method is added and not handled by the following switch statement:
//
[0.x.41493] 
[0.x.41494] 
[0.x.41495] 
[0.x.41496] 
[0.x.41497] 
[0.x.41498] 
[0.x.41499] 
[0.x.41500] 
[0.x.41501] 
[0.x.41502] 
[0.x.41503] 
[0.x.41504] 
//
// We augment the filename by a postfix denoting the finite element which we have used in the computation. To this end, the finite element base class stores the maximal polynomial degree of shape functions in each coordinate variable as a variable  [2.x.5184] , and we use for the switch statement (note that the polynomial degree of bilinear shape functions is really 2, since they contain the term  [2.x.5185] ; however, the polynomial degree in each coordinate variable is still only 1). We again use the same defensive programming technique to safeguard against the case that the polynomial degree has an unexpected value, using the  [2.x.5186]  idiom in the default branch of the switch statement:
//
[0.x.41505] 
[0.x.41506] 
[0.x.41507] 
[0.x.41508] 
[0.x.41509] 
[0.x.41510] 
[0.x.41511] 
[0.x.41512] 
//
[0.x.41513] 
[0.x.41514] 
[0.x.41515] 
//
// Once we have the base name for the output file, we add an extension appropriate for VTK output, open a file, and add the solution vector to the object that will do the actual output:
//
[0.x.41516] 
[0.x.41517] 
//
[0.x.41518] 
[0.x.41519] 
[0.x.41520] 
//
// Now building the intermediate format as before is the next step. We introduce one more feature of deal.II here. The background is the following: in some of the runs of this function, we have used biquadratic finite elements. However, since almost all output formats only support bilinear data, the data is written only bilinear, and information is consequently lost.  Of course, we can't change the format in which graphic programs accept their inputs, but we can write the data differently such that we more closely resemble the information available in the quadratic approximation. We can, for example, write each cell as four sub-cells with bilinear data each, such that we have nine data points for each cell in the triangulation. The graphic programs will, of course, display this data still only bilinear, but at least we have given some more of the information we have.
//
// In order to allow writing more than one sub-cell per actual cell, the  [2.x.5187]  function accepts a parameter (the default is  [2.x.5188] , which is why you haven't seen this parameter in previous examples). This parameter denotes into how many sub-cells per space direction each cell shall be subdivided for output. For example, if you give  [2.x.5189] , this leads to 4 cells in 2D and 8 cells in 3D. For quadratic elements, two sub-cells per space direction is obviously the right choice, so this is what we choose. In general, for elements of polynomial order  [2.x.5190]  subdivisions, and the order of the elements is determined in the same way as above.
//
// With the intermediate format so generated, we can then actually write the graphical output:
//
[0.x.41521] 
[0.x.41522] 
//[2.x.5191] 
//
// After graphical output, we would also like to generate tables from the error computations we have done in  [2.x.5192] . There, we have filled a table object with the number of cells for each refinement step as well as the errors in different norms.
//
// For a nicer textual output of this data, one may want to set the precision with which the values will be written upon output. We use 3 digits for this, which is usually sufficient for error norms. By default, data is written in fixed point notation. However, for columns one would like to see in scientific notation another function call sets the  [2.x.5193] , leading to floating point representation of numbers.
//
[0.x.41523] 
[0.x.41524] 
[0.x.41525] 
//
[0.x.41526] 
[0.x.41527] 
[0.x.41528] 
//
// For the output of a table into a LaTeX file, the default captions of the columns are the keys given as argument to the  [2.x.5194]  functions. To have TeX captions that differ from the default ones you can specify them by the following function calls. Note, that `\\' is reduced to `\' by the compiler such that the real TeX caption is, e.g., ` [2.x.5195] -error'.
//
[0.x.41529] 
[0.x.41530] 
[0.x.41531] 
[0.x.41532] 
[0.x.41533] 
//
// Finally, the default LaTeX format for each column of the table is `c' (centered). To specify a different (e.g. `right') one, the following function may be used:
//
[0.x.41534] 
[0.x.41535] 
//
// After this, we can finally write the table to the standard output stream  [2.x.5196]  (after one extra empty line, to make things look prettier). Note, that the output in text format is quite simple and that captions may not be printed directly above the specific columns.
//
[0.x.41536] 
[0.x.41537] 
//
// The table can also be written into a LaTeX file.  The (nicely) formatted table can be viewed at after calling `latex filename' and e.g. `xdvi filename', where filename is the name of the file to which we will write output now. We construct the file name in the same way as before, but with a different prefix "error":
//
[0.x.41538] 
[0.x.41539] 
[0.x.41540] 
[0.x.41541] 
[0.x.41542] 
[0.x.41543] 
[0.x.41544] 
[0.x.41545] 
[0.x.41546] 
[0.x.41547] 
[0.x.41548] 
[0.x.41549] 
//
[0.x.41550] 
[0.x.41551] 
[0.x.41552] 
[0.x.41553] 
[0.x.41554] 
[0.x.41555] 
[0.x.41556] 
[0.x.41557] 
[0.x.41558] 
[0.x.41559] 
[0.x.41560] 
//
[0.x.41561] 
[0.x.41562] 
//
[0.x.41563] 
//[2.x.5197] 
//
// In case of global refinement, it might be of interest to also output the convergence rates. This may be done by the functionality the ConvergenceTable offers over the regular TableHandler. However, we do it only for global refinement, since for adaptive refinement the determination of something like an order of convergence is somewhat more involved. While we are at it, we also show a few other things that can be done with tables.
//
[0.x.41564] 
[0.x.41565] 
//
// The first thing is that one can group individual columns together to form so-called super columns. Essentially, the columns remain the same, but the ones that were grouped together will get a caption running across all columns in a group. For example, let's merge the "cycle" and "cells" columns into a super column named "n cells":
//
[0.x.41566] 
[0.x.41567] 
//
// Next, it isn't necessary to always output all columns, or in the order in which they were originally added during the run. Selecting and re-ordering the columns works as follows (note that this includes super columns):
//
[0.x.41568] 
[0.x.41569] 
[0.x.41570] 
[0.x.41571] 
[0.x.41572] 
//
// For everything that happened to the ConvergenceTable until this point, it would have been sufficient to use a simple TableHandler. Indeed, the ConvergenceTable is derived from the TableHandler but it offers the additional functionality of automatically evaluating convergence rates. For example, here is how we can let the table compute reduction and convergence rates (convergence rates are the binary logarithm of the reduction rate):
//
[0.x.41573] 
[0.x.41574] 
[0.x.41575] 
[0.x.41576] 
[0.x.41577] 
[0.x.41578] 
[0.x.41579] 
[0.x.41580] 
//
// Each of these function calls produces an additional column that is merged with the original column (in our example the `L2' and the `H1' column) to a supercolumn.
//
// Finally, we want to write this convergence chart again, first to the screen and then, in LaTeX format, to disk. The filename is again constructed as above.
//
[0.x.41581] 
[0.x.41582] 
//
[0.x.41583] 
[0.x.41584] 
[0.x.41585] 
[0.x.41586] 
[0.x.41587] 
[0.x.41588] 
[0.x.41589] 
[0.x.41590] 
[0.x.41591] 
[0.x.41592] 
[0.x.41593] 
[0.x.41594] 
[0.x.41595] 
[0.x.41596] 
[0.x.41597] 
[0.x.41598] 
[0.x.41599] 
[0.x.41600] 
[0.x.41601] 
[0.x.41602] 
[0.x.41603] 
[0.x.41604] 
[0.x.41605] 
[0.x.41606] 
//
[0.x.41607] 
[0.x.41608] 
[0.x.41609] 
[0.x.41610] 
//
// The final step before going to  [2.x.5198]  is then to close the namespace  [2.x.5199]  into which we have put everything we needed for this program:
//
[0.x.41611] 
//[2.x.5200] 
//
// The main function is mostly as before. The only difference is that we solve three times, once for Q1 and adaptive refinement, once for Q1 elements and global refinement, and once for Q2 elements and global refinement.
//
// Since we instantiate several template classes below for two space dimensions, we make this more generic by declaring a constant at the beginning of the function denoting the number of space dimensions. If you want to run the program in 1d or 2d, you will then only have to change this one instance, rather than all uses below:
//
[0.x.41612] 
[0.x.41613] 
[0.x.41614] 
//
[0.x.41615] 
[0.x.41616] 
[0.x.41617] 
[0.x.41618] 
//
// Now for the three calls to the main class. Each call is blocked into curly braces in order to destroy the respective objects (i.e. the finite element and the HelmholtzProblem object) at the end of the block and before we go to the next run. This avoids conflicts with variable names, and also makes sure that memory is released immediately after one of the three runs has finished, and not only at the end of the  [2.x.5201]  block.
//
[0.x.41619] 
[0.x.41620] 
[0.x.41621] 
[0.x.41622] 
[0.x.41623] 
[0.x.41624] 
//
[0.x.41625] 
[0.x.41626] 
[0.x.41627] 
//
[0.x.41628] 
//
[0.x.41629] 
[0.x.41630] 
//
[0.x.41631] 
[0.x.41632] 
[0.x.41633] 
[0.x.41634] 
//
[0.x.41635] 
[0.x.41636] 
[0.x.41637] 
//
[0.x.41638] 
//
[0.x.41639] 
[0.x.41640] 
//
[0.x.41641] 
[0.x.41642] 
[0.x.41643] 
[0.x.41644] 
//
[0.x.41645] 
[0.x.41646] 
[0.x.41647] 
//
[0.x.41648] 
//
[0.x.41649] 
[0.x.41650] 
[0.x.41651] 
[0.x.41652] 
[0.x.41653] 
[0.x.41654] 
[0.x.41655] 
//
[0.x.41656] 
[0.x.41657] 
[0.x.41658] 
//
[0.x.41659] 
//
[0.x.41660] 
[0.x.41661] 
[0.x.41662] 
[0.x.41663] 
[0.x.41664] 
[0.x.41665] 
[0.x.41666] 
[0.x.41667] 
[0.x.41668] 
[0.x.41669] 
[0.x.41670] 
[0.x.41671] 
[0.x.41672] 
[0.x.41673] 
[0.x.41674] 
[0.x.41675] 
[0.x.41676] 
[0.x.41677] 
[0.x.41678] 
[0.x.41679] 
[0.x.41680] 
[0.x.41681] 
[0.x.41682] 
[0.x.41683] 
[0.x.41684] 
[0.x.41685] 
[0.x.41686] 
[0.x.41687] 
//
[0.x.41688] 
[0.x.41689] 
[0.x.41690] 
[0.x.41691] 
[0.x.41692] 
[0.x.41693] 
[0.x.41694] 
[0.x.41695] 
[0.x.41696] 
[0.x.41697] 
[0.x.41698] 
[0.x.41699] 
[0.x.41700] 
[0.x.41701] 
[0.x.41702] 
[0.x.41703] 
//
[0.x.41704] 
[0.x.41705] 
[0.x.41706] 
//[2.x.5202]  Most of these have been introduced elsewhere, we'll comment only on the new ones. The switches close to the top that allow selecting between PETSc and Trilinos linear algebra capabilities are similar to the ones in  [2.x.5203]  and  [2.x.5204] .
//
[0.x.41707] 
[0.x.41708] 
[0.x.41709] 
//
[0.x.41710] 
[0.x.41711] 
[0.x.41712] 
[0.x.41713] 
//
[0.x.41714] 
//
[0.x.41715] 
[0.x.41716] 
[0.x.41717] 
[0.x.41718] 
[0.x.41719] 
[0.x.41720] 
[0.x.41721] 
[0.x.41722] 
[0.x.41723] 
[0.x.41724] 
[0.x.41725] 
[0.x.41726] 
//
[0.x.41727] 
[0.x.41728] 
[0.x.41729] 
[0.x.41730] 
[0.x.41731] 
//
[0.x.41732] 
[0.x.41733] 
[0.x.41734] 
//
[0.x.41735] 
[0.x.41736] 
[0.x.41737] 
//
[0.x.41738] 
[0.x.41739] 
[0.x.41740] 
[0.x.41741] 
[0.x.41742] 
[0.x.41743] 
//
[0.x.41744] 
[0.x.41745] 
[0.x.41746] 
[0.x.41747] 
//
[0.x.41748] 
[0.x.41749] 
[0.x.41750] 
[0.x.41751] 
[0.x.41752] 
[0.x.41753] 
[0.x.41754] 
[0.x.41755] 
[0.x.41756] 
[0.x.41757] 
[0.x.41758] 
[0.x.41759] 
//
[0.x.41760] 
[0.x.41761] 
[0.x.41762] 
//
// These are the only new include files with regard to  [2.x.5205] . In this tutorial, the non-matching coupling between the solid and the fluid is computed using an intermediate data structure that keeps track of how the locations of quadrature points of the solid evolve within the fluid mesh. This data structure needs to keep track of the position of the quadrature points on each cell describing the solid domain, of the quadrature weights, and possibly of the normal vector to each point, if the solid domain is of co-dimension one.
//
// Deal.II offers these facilities in the Particles namespace, through the ParticleHandler class. ParticleHandler is a class that allows you to manage a collection of particles (objects of type  [2.x.5206]  representing a collection of points with some attached properties (e.g., an id) floating on a  [2.x.5207]  The methods and classes in the namespace Particles allows one to easily implement Particle-In-Cell methods and particle tracing on distributed triangulations.
//
// We "abuse" this data structure to store information about the location of solid quadrature points embedded in the surrounding fluid grid, including integration weights, and possibly surface normals. The reason why we use this additional data structure is related to the fact that the solid and the fluid grids might be non-overlapping, and if we were using two separate triangulation objects, would be distributed independently among parallel processes.
//
// In order to couple the two problems, we rely on the ParticleHandler class, storing in each particle the position of a solid quadrature point (which is in general not aligned to any of the fluid quadrature points), its weight, and any other information that may be required to couple the two problems. These locations are then propagated along with the (prescribed) velocity of the solid impeller.
//
// Ownership of the solid quadrature points is initially inherited from the MPI partitioning on the solid mesh itself. The Particles so generated are later distributed to the fluid mesh using the methods of the ParticleHandler class. This allows transparent exchange of information between MPI processes about the overlapping pattern between fluid cells and solid quadrature points.
//
[0.x.41763] 
[0.x.41764] 
[0.x.41765] 
[0.x.41766] 
//
// When generating the grids, we allow reading it from a file, and if deal.II has been built with OpenCASCADE support, we also allow reading CAD files and use them as manifold descriptors for the grid (see  [2.x.5208]  for a detailed description of the various Manifold descriptors that are available in the OpenCASCADE namespace)
//
[0.x.41767] 
[0.x.41768] 
[0.x.41769] 
[0.x.41770] 
[0.x.41771] 
//
[0.x.41772] 
[0.x.41773] 
[0.x.41774] 
[0.x.41775] 
//
[0.x.41776] 
[0.x.41777] 
[0.x.41778] 
//[2.x.5209] 
//
// Similarly to what we have done in  [2.x.5210] , we set up a class that holds all the parameters of our problem and derive it from the ParameterAcceptor class to simplify the management and creation of parameter files.
//
// The ParameterAcceptor paradigm requires all parameters to be writable by the ParameterAcceptor methods. In order to avoid bugs that would be very difficult to track down (such as writing things like `time = 0` instead of `time == 0`), we declare all the parameters in an external class, which is initialized before the actual `StokesImmersedProblem` class, and pass it to the main class as a `const` reference.
//
// The constructor of the class is responsible for the connection between the members of this class and the corresponding entries in the ParameterHandler. Thanks to the use of the  [2.x.5211]  method, this connection is trivial, but requires all members of this class to be writeable.
//
[0.x.41779] 
[0.x.41780] 
[0.x.41781] 
[0.x.41782] 
[0.x.41783] 
//
// however, since this class will be passed as a `const` reference to the StokesImmersedProblem class, we have to make sure we can still set the time correctly in the objects derived by the Function class defined herein. In order to do so, we declare both the  [2.x.5212]  and  [2.x.5213]  members to be `mutable`, and define the following little helper method that sets their time to the correct value.
//
[0.x.41784] 
[0.x.41785] 
[0.x.41786] 
[0.x.41787] 
[0.x.41788] 
//
// The remainder of the class consists largely of member variables that describe the details of the simulation and its discretization. The following parameters are about where output should land, the spatial and temporal discretization (the default is the  [2.x.5214]  Taylor-Hood discretization which uses a polynomial degree of 2 for the velocity), and how many time steps should elapse before we generate graphical output again:
//
[0.x.41789] 
//
[0.x.41790] 
//
[0.x.41791] 
[0.x.41792] 
//
[0.x.41793] 
//
// We allow every grid to be refined independently. In this tutorial, no physics is resolved on the solid grid, and its velocity is given as a datum. However it is relatively straightforward to incorporate some elasticity model in this tutorial, and transform it into a fully fledged FSI solver.
//
[0.x.41794] 
[0.x.41795] 
[0.x.41796] 
//
// To provide a rough description of the fluid domain, we use the method extract_rtree_level() applied to the tree of bounding boxes of each locally owned cell of the fluid triangulation. The higher the level of the tree, the larger the number of extracted bounding boxes, and the more accurate is the description of the fluid domain. However, a large number of bounding boxes also implies a large communication cost, since the collection of bounding boxes is gathered by all processes.
//
[0.x.41797] 
//
// The only two numerical parameters used in the equations are the viscosity of the fluid, and the penalty term  [2.x.5215]  used in the Nitsche formulation:
//
[0.x.41798] 
[0.x.41799] 
//
// By default, we create a hyper_cube without colorization, and we use homogeneous Dirichlet boundary conditions. In this set we store the boundary ids to use when setting the boundary conditions:
//
[0.x.41800] 
//
// We illustrate here another way to create a Triangulation from a parameter file, using the method  [2.x.5216]  that takes the name of a function in the GridGenerator namespace, and its arguments as a single string representing the arguments as a tuple.
//
// The mechanism with which the arguments are parsed from and to a string is explained in detail in the  [2.x.5217]  class, which is used to translate from strings to most of the basic STL types (vectors, maps, tuples) and basic deal.II types (Point, Tensor, BoundingBox, etc.).
//
// In general objects that can be represented by rank 1 uniform elements (i.e.,  [2.x.5218]  Point<dim>,  [2.x.5219]  etc.) are comma separated. Additional ranks take a semicolon, allowing you to parse strings into objects of type  [2.x.5220]  or, for example,  [2.x.5221]  as `0.0, 0.1; 0.1, 0.2`. This string could be interpreted as a vector of two Point objects, or a vector of vector of doubles.
//
// When the entries are not uniform, as in the tuple case, we use a colon to separate the various entries. For example, a string like `5: 0.1, 0.2` could be used to parse an object of type  [2.x.5222]  Point<2>>` or a  [2.x.5223] 
//[2.x.5224] 
//
// In our case most of the arguments are Point objects (representing centers, corners, subdivision elements, etc.), integer values (number of subdivisions), double values (radius, lengths, etc.), or boolean options (such as the `colorize` option that many GridGenerator functions take).
//
// In the example below, we set reasonable default values, but these can be changed at run time by selecting any other supported function of the GridGenerator namespace. If the GridGenerator function fails, this program will interpret the name of the grid as a vtk grid filename, and the arguments as a map from manifold_id to the CAD files describing the geometry of the domain. Every CAD file will be analyzed and a Manifold of the OpenCASCADE namespace will be generated according to the content of the CAD file itself.
//
// To be as generic as possible, we do this for each of the generated grids: the fluid grid, the solid grid, but also the tracer particles which are also generated using a triangulation.
//
[0.x.41801] 
[0.x.41802] 
[0.x.41803] 
[0.x.41804] 
[0.x.41805] 
[0.x.41806] 
[0.x.41807] 
[0.x.41808] 
[0.x.41809] 
//
// Similarly, we allow for different local refinement strategies. In particular, we limit the maximum number of refinement levels, in order to control the minimum size of the fluid grid, and guarantee that it is compatible with the solid grid. The minimum number of refinement levels is also controlled to ensured sufficient accuracy in the bulk of the flow. Additionally, we perform local refinement based on standard error estimators on the fluid velocity field.
//
// We permit the user to choose between the two most common refinement strategies, namely `fixed_number` or `fixed_fraction`, that refer to the methods  [2.x.5225]  and  [2.x.5226] 
//
// Refinement may be done every few time steps, instead of continuously, and we control this value by the `refinement_frequency` parameter:
//
[0.x.41810] 
[0.x.41811] 
[0.x.41812] 
[0.x.41813] 
[0.x.41814] 
[0.x.41815] 
[0.x.41816] 
//
// Finally, the following two function objects are used to control the source term of Stokes flow and the angular velocity at which we move the solid body. In a more realistic simulation, the solid velocity or its deformation would come from the solution of an auxiliary problem on the solid domain. In this example step we leave this part aside, and simply impose a fixed rotational velocity field along the z-axis on the immersed solid, governed by a function that can be specified in the parameter file:
//
[0.x.41817] 
[0.x.41818] 
[0.x.41819] 
[0.x.41820] 
//
// There remains the task of declaring what run-time parameters we can accept in input files. We split the parameters in various categories, by putting them in different sections of the ParameterHandler class. We begin by declaring all the global parameters used by StokesImmersedProblem in the global scope:
//
[0.x.41821] 
[0.x.41822] 
[0.x.41823] 
[0.x.41824] 
[0.x.41825] 
[0.x.41826] 
[0.x.41827] 
[0.x.41828] 
[0.x.41829] 
//
[0.x.41830] 
[0.x.41831] 
//
[0.x.41832] 
//
[0.x.41833] 
//
[0.x.41834] 
//
[0.x.41835] 
//
[0.x.41836] 
[0.x.41837] 
[0.x.41838] 
//
[0.x.41839] 
[0.x.41840] 
[0.x.41841] 
//
[0.x.41842] 
[0.x.41843] 
[0.x.41844] 
[0.x.41845] 
//
[0.x.41846] 
[0.x.41847] 
[0.x.41848] 
[0.x.41849] 
//
[0.x.41850] 
[0.x.41851] 
[0.x.41852] 
[0.x.41853] 
//
// Next section is dedicated to the parameters used to create the various grids. We will need three different triangulations: `Fluid grid` is used to define the fluid domain, `Solid grid` defines the solid domain, and `Particle grid` is used to distribute some tracer particles, that are advected with the velocity and only used as passive tracers.
//
[0.x.41854] 
[0.x.41855] 
[0.x.41856] 
[0.x.41857] 
//
[0.x.41858] 
[0.x.41859] 
//
[0.x.41860] 
[0.x.41861] 
[0.x.41862] 
[0.x.41863] 
[0.x.41864] 
//
[0.x.41865] 
[0.x.41866] 
[0.x.41867] 
[0.x.41868] 
[0.x.41869] 
[0.x.41870] 
[0.x.41871] 
[0.x.41872] 
[0.x.41873] 
[0.x.41874] 
[0.x.41875] 
[0.x.41876] 
[0.x.41877] 
[0.x.41878] 
[0.x.41879] 
//
// The final task is to correct the default dimension for the right hand side function and define a meaningful default angular velocity instead of zero.
//
[0.x.41880] 
[0.x.41881] 
[0.x.41882] 
[0.x.41883] 
[0.x.41884] 
[0.x.41885] 
[0.x.41886] 
[0.x.41887] 
[0.x.41888] 
//
// Once the angular velocity is provided as a Function object, we reconstruct the pointwise solid velocity through the following class which derives from the Function class. It provides the value of the velocity of the solid body at a given position by assuming that the body rotates around the origin (or the  [2.x.5227]  axis in 3d) with a given angular velocity.
//
[0.x.41889] 
[0.x.41890] 
[0.x.41891] 
[0.x.41892] 
[0.x.41893] 
[0.x.41894] 
//
[0.x.41895] 
[0.x.41896] 
[0.x.41897] 
//
[0.x.41898] 
[0.x.41899] 
[0.x.41900] 
[0.x.41901] 
//
// We assume that the angular velocity is directed along the z-axis, i.e., we model the actual angular velocity as if it was a two-dimensional rotation, irrespective of the actual value of `spacedim`.
//
[0.x.41902] 
[0.x.41903] 
[0.x.41904] 
//
[0.x.41905] 
[0.x.41906] 
//
[0.x.41907] 
[0.x.41908] 
[0.x.41909] 
//
// Similarly, we assume that the solid position can be computed explicitly at each time step, exploiting the knowledge of the angular velocity. We compute the exact position of the solid particle assuming that the solid is rotated by an amount equal to the time step multiplied by the angular velocity computed at the point `p`:
//
[0.x.41910] 
[0.x.41911] 
[0.x.41912] 
[0.x.41913] 
[0.x.41914] 
[0.x.41915] 
//
[0.x.41916] 
[0.x.41917] 
[0.x.41918] 
[0.x.41919] 
[0.x.41920] 
[0.x.41921] 
//
[0.x.41922] 
[0.x.41923] 
[0.x.41924] 
[0.x.41925] 
//
[0.x.41926] 
//
[0.x.41927] 
[0.x.41928] 
//
[0.x.41929] 
[0.x.41930] 
//
[0.x.41931] 
[0.x.41932] 
[0.x.41933] 
[0.x.41934] 
//
[0.x.41935] 
[0.x.41936] 
[0.x.41937] 
[0.x.41938] 
//[2.x.5228] 
//
// We are now ready to introduce the main class of our tutorial program. As usual, other than the constructor, we leave a single public entry point: the `run()` method. Everything else is left `private`, and accessed through the run method itself.
//
[0.x.41939] 
[0.x.41940] 
[0.x.41941] 
[0.x.41942] 
[0.x.41943] 
[0.x.41944] 
//
[0.x.41945] 
//
// The next section contains the `private` members of the class. The first method is similar to what is present in previous example. However it not only takes care of generating the grid for the fluid, but also the grid for the solid. The second computes the largest time step that guarantees that each particle moves of at most one cell. This is important to ensure that the  [2.x.5229]  can find which cell a particle ends up in, as it can only look from one cell to its immediate neighbors (because, in a parallel setting, every MPI process only knows about the cells it owns as well as their immediate neighbors).
//
[0.x.41946] 
[0.x.41947] 
//
[0.x.41948] 
//
// The next two functions initialize the  [2.x.5230]  objects used in this class. We have two such objects: One represents passive tracers, used to plot the trajectories of fluid particles, while the the other represents material particles of the solid, which are placed at quadrature points of the solid grid.
//
[0.x.41949] 
[0.x.41950] 
//
// The remainder of the set up is split in two parts: The first of the following two functions creates all objects that are needed once per simulation, whereas the other sets up all objects that need to be reinitialized at every refinement step.
//
[0.x.41951] 
[0.x.41952] 
//
// The assembly routine is very similar to other Stokes assembly routines, with the exception of the Nitsche restriction part, which exploits one of the particle handlers to integrate on a non-matching part of the fluid domain, corresponding to the position of the solid. We split these two parts into two separate functions.
//
[0.x.41953] 
[0.x.41954] 
//
// The remaining functions solve the linear system (which looks almost identical to the one in  [2.x.5231] ) and then postprocess the solution: The refine_and_transfer() method is called only every `refinement_frequency` steps to adapt the mesh and also make sure that all the fields that were computed on the time step before refinement are transferred correctly to the new grid. This includes vector fields, as well as particle information. Similarly, we call the two output methods only every `output_frequency` steps.
//
[0.x.41955] 
//
[0.x.41956] 
//
[0.x.41957] 
[0.x.41958] 
[0.x.41959] 
[0.x.41960] 
[0.x.41961] 
//
// Let us then move on to the member functions of the class. The first deals with run-time parameters that are read from a parameter file. As noted before, we make sure we cannot modify this object from within this class, by making it a `const` reference.
//
[0.x.41962] 
//
// Then there is also the MPI communicator object that we will use to let processes send information across the network if the program runs in parallel, along with the `pcout` object and timer information that has also been employed by  [2.x.5232] , for example:
//
[0.x.41963] 
//
[0.x.41964] 
//
[0.x.41965] 
//
// Next is one of the main novelties with regard to  [2.x.5233] . Here we assume that both the solid and the fluid are fully distributed triangulations. This allows the problem to scale to a very large number of degrees of freedom, at the cost of communicating all the overlapping regions between non matching triangulations. This is especially tricky, since we make no assumptions on the relative position or distribution of the various subdomains of the two triangulations. In particular, we assume that every process owns only a part of the `solid_tria`, and only a part of the `fluid_tria`, not necessarily in the same physical region, and not necessarily overlapping.
//
// We could in principle try to create the initial subdivisions in such a way that each process's subdomains overlap between the solid and the fluid regions. However, this overlap would be destroyed during the simulation, and we would have to redistribute the DoFs again and again. The approach we follow in this tutorial is more flexible, and not much more expensive. We make two all-to-all communications at the beginning of the simulation to exchange information about an (approximate) information of the geometrical occupancy of each processor (done through a collection of bounding boxes).
//
// This information is used by the  [2.x.5234]  class to exchange (using a some-to-some communication pattern) all particles, so that every process knows about the particles that live on the region occupied by the fluid subdomain that it owns.
//
// In order to couple the overlapping regions, we exploit the facilities implemented in the ParticleHandler class.
//
[0.x.41966] 
[0.x.41967] 
//
// Next come descriptions of the finite elements in use, along with appropriate quadrature formulas and the corresponding DoFHandler objects. For the current implementation, only `fluid_fe` is really necessary. For completeness, and to allow easy extension, we also keep the `solid_fe` around, which is however initialized to a FE_Nothing finite element space, i.e., one that has no degrees of freedom.
//
// We declare both finite element spaces as  [2.x.5235]  objects rather than regular member variables, to allow their generation after `StokesImmersedProblemParameters` has been initialized. In particular, they will be initialized in the `initial_setup()` method.
//
[0.x.41968] 
[0.x.41969] 
//
[0.x.41970] 
[0.x.41971] 
//
[0.x.41972] 
[0.x.41973] 
//
[0.x.41974] 
//
// Similarly to how things are done in  [2.x.5236] , we use a block system to treat the Stokes part of the problem, and follow very closely what was done there.
//
[0.x.41975] 
[0.x.41976] 
//
[0.x.41977] 
[0.x.41978] 
//
// Using this partitioning of degrees of freedom, we can then define all of the objects necessary to describe the linear systems in question:
//
[0.x.41979] 
//
[0.x.41980] 
[0.x.41981] 
//
[0.x.41982] 
[0.x.41983] 
[0.x.41984] 
//
// Let us move to the particles side of this program. There are two  [2.x.5237]  objects used to couple the solid with the fluid, and to describe the passive tracers. These, in many ways, play a role similar to the DoFHandler class used in the discretization, i.e., they provide for an enumeration of particles and allow querying information about each particle.
//
[0.x.41985] 
[0.x.41986] 
//
// For every tracer particle, we need to compute the velocity field in its current position, and update its position using a discrete time stepping scheme. We do this using distributed linear algebra objects that store the coordinates of each particle's location or velocity. That is, these vectors have `tracer_particle_handler.n_global_particles() * spacedim` entries that we will store in a way so that parts of the vector are partitioned across all processes. (Implicitly, we here make the assumption that the `spacedim` coordinates of each particle are stored in consecutive entries of the vector.) Thus, we need to determine who the owner of each vector entry is. We set this owner to be equal to the process that generated that particle at time  [2.x.5238] . This information is stored for every process in the `locally_owned_tracer_particle_coordinates` IndexSet.
//
// Once the particles have been distributed around to match the process that owns the region where the particle lives, we will need read access from that process to the corresponding velocity field. We achieve this by filling a read only velocity vector field that contains the relevant information in ghost entries. This is achieved using the `locally_relevant_tracer_particle_coordinates` IndexSet, that keeps track of how things change during the simulation, i.e., it keeps track of where particles that the current process owns have ended up being, and who owns the particles that ended up in my subdomain.
//
// While this is not the most efficient strategy, we keep it this way to illustrate how things would work in a real fluid-structure interaction (FSI) problem. If a particle is linked to a specific solid degree of freedom, we are not free to choose who owns it, and we have to communicate this information around. We illustrate this here, and show that the communication pattern is point-to-point, and negligible in terms of total cost of the algorithm.
//
// The vectors defined based on these subdivisions are then used to store the particles velocities (read-only, with ghost entries) and their displacement (read/write, no ghost entries).
//
[0.x.41987] 
[0.x.41988] 
//
[0.x.41989] 
[0.x.41990] 
//
// One of the key points of this tutorial program is the coupling between two independent  [2.x.5239]  objects, one of which may be moving and deforming (with possibly large deformations) with respect to the other. When both the fluid and the solid triangulations are of type  [2.x.5240]  every process has access only to its fraction of locally owned cells of each of the two triangulations. As mentioned above, in general, the locally owned domains are not overlapping.
//
// In order to allow for the efficient exchange of information between non-overlapping  [2.x.5241]  objects, some algorithms of the library require the user to provide a rough description of the area occupied by the locally owned part of the triangulation, in the form of a collection of axis-aligned bounding boxes for each process, that provide a full covering of the locally owned part of the domain. This kind of information can then be used in situations where one needs to send information to the owner of the cell surrounding a known location, without knowing who that owner may in fact be. But, if one knows a collection of bounding boxes for the geometric area or volume each process owns, then we can determine a subset of all processes that might possibly own the cell in which that location lies: namely, all of those processes whose bounding boxes contain that point. Instead of sending the information associated to that location to all processes, one can then get away with only sending it to a small subset of the processes with point-to-point communication primitives. (You will notice that this also allows for the typical time-vs-memory trade-off: The more data we are willing to store about each process's owned area -- in the form of more refined bounding box information -- the less communication we have to perform.)
//
// We construct this information by gathering a vector (of length  [2.x.5242]  of vectors of BoundingBox objects. We fill this vector using the extract_rtree_level() function, and allow the user to select what level of the tree to extract. The "level" corresponds to how coarse/fine the overlap of the area with bounding boxes should be.
//
// As an example, this is what would be extracted by the extract_rtree_level() function applied to a two dimensional hyper ball, distributed over three processes. Each image shows in green the bounding boxes associated to the locally owned cells of the triangulation on each process, and in violet the bounding boxes extracted from the rtree:
//
//  [2.x.5243] 
//[2.x.5244] 
//[2.x.5245] 
//
// We store these boxes in a global member variable, which is updated at every refinement step:
//
[0.x.41991] 
[0.x.41992] 
//
//  [2.x.5246] 
//[2.x.5247] 
//
// In the constructor, we create the mpi_communicator as well as the triangulations and dof_handler for both the fluid and the solid. Using the mpi_communicator, both the ConditionalOStream and TimerOutput object are constructed.
//
[0.x.41993] 
[0.x.41994] 
[0.x.41995] 
[0.x.41996] 
[0.x.41997] 
[0.x.41998] 
[0.x.41999] 
[0.x.42000] 
[0.x.42001] 
[0.x.42002] 
[0.x.42003] 
[0.x.42004] 
[0.x.42005] 
[0.x.42006] 
[0.x.42007] 
[0.x.42008] 
[0.x.42009] 
[0.x.42010] 
[0.x.42011] 
[0.x.42012] 
[0.x.42013] 
[0.x.42014] 
//
// In order to generate the grid, we first try to use the functions in the deal.II GridGenerator namespace, by leveraging the  [2.x.5248]  If this function fails, then we use the following method, where the name is interpreted as a filename, and the arguments are interpreted as a map from manifold ids to CAD files, and are converted to Manifold descriptors using the OpenCASCADE namespace facilities. At the top, we read the file into a triangulation:
//
[0.x.42015] 
[0.x.42016] 
[0.x.42017] 
[0.x.42018] 
[0.x.42019] 
[0.x.42020] 
[0.x.42021] 
[0.x.42022] 
//
// If we got to this point, then the Triangulation has been read, and we are ready to attach to it the correct manifold descriptions. We perform the next lines of code only if deal.II has been built with OpenCASCADE support. For each entry in the map, we try to open the corresponding CAD file, we analyze it, and according to its content, opt for either a  [2.x.5249]  (if the CAD file contains a single `TopoDS_Edge` or a single `TopoDS_Wire`) or a  [2.x.5250]  if the file contains a single face. Notice that if the CAD files do not contain single wires, edges, or faces, an assertion will be throw in the generation of the Manifold.
//
// We use the  [2.x.5251]  class to do the conversion from the string to a map between manifold ids and file names for us:
//
[0.x.42023] 
[0.x.42024] 
[0.x.42025] 
//
[0.x.42026] 
[0.x.42027] 
[0.x.42028] 
[0.x.42029] 
//
[0.x.42030] 
[0.x.42031] 
//
[0.x.42032] 
[0.x.42033] 
[0.x.42034] 
[0.x.42035] 
[0.x.42036] 
[0.x.42037] 
[0.x.42038] 
[0.x.42039] 
[0.x.42040] 
[0.x.42041] 
//
// Now we check how many faces are contained in the `Shape`. OpenCASCADE is intrinsically 3D, so if this number is zero, we interpret this as a line manifold, otherwise as a  [2.x.5252]  in `spacedim` = 3, or  [2.x.5253]  in `spacedim` = 2.
//
[0.x.42042] 
[0.x.42043] 
[0.x.42044] 
[0.x.42045] 
[0.x.42046] 
[0.x.42047] 
[0.x.42048] 
//
//   We use this trick, because    [2.x.5254]  is only implemented   for spacedim = 3. The check above makes sure that things actually   work correctly.
//
[0.x.42049] 
[0.x.42050] 
[0.x.42051] 
[0.x.42052] 
[0.x.42053] 
[0.x.42054] 
//
// We also allow surface descriptions in two dimensional spaces based on single NURBS patches. For this to work, the CAD file must contain a single `TopoDS_Face`.
//
[0.x.42055] 
[0.x.42056] 
[0.x.42057] 
[0.x.42058] 
[0.x.42059] 
[0.x.42060] 
[0.x.42061] 
[0.x.42062] 
[0.x.42063] 
//
// Now let's put things together, and make all the necessary grids. As mentioned above, we first try to generate the grid internally, and if we fail (i.e., if we end up in the `catch` clause), then we proceed with the above function.
//
// We repeat this pattern for both the fluid and the solid mesh.
//
[0.x.42064] 
[0.x.42065] 
[0.x.42066] 
[0.x.42067] 
[0.x.42068] 
[0.x.42069] 
[0.x.42070] 
[0.x.42071] 
[0.x.42072] 
[0.x.42073] 
[0.x.42074] 
[0.x.42075] 
[0.x.42076] 
[0.x.42077] 
[0.x.42078] 
[0.x.42079] 
[0.x.42080] 
//
[0.x.42081] 
[0.x.42082] 
[0.x.42083] 
[0.x.42084] 
[0.x.42085] 
[0.x.42086] 
[0.x.42087] 
[0.x.42088] 
[0.x.42089] 
[0.x.42090] 
[0.x.42091] 
//
[0.x.42092] 
[0.x.42093] 
//[2.x.5255] 
//
// Once the solid and fluid grids have been created, we start filling the  [2.x.5256]  objects. The first one we take care of is the one we use to keep track of passive tracers in the fluid. These are simply transported along, and in some sense their locations are unimportant: We just want to use them to see where flow is being transported. We could use any way we choose to determine where they are initially located. A convenient one is to create the initial locations as the vertices of a mesh in a shape of our choice -- a choice determined by one of the run-time parameters in the parameter file.
//
// In this implementation, we create tracers using the support points of a FE_Q finite element space defined on a temporary grid, which is then discarded. Of this grid, we only keep around the  [2.x.5257]  objects (stored in a  [2.x.5258]  class) associated to the support points.
//
// The  [2.x.5259]  class offers the possibility to insert a set of particles that live physically in the part of the domain owned by the active process. However, in this case this function would not suffice. The particles generated as the locally owned support points of an FE_Q object on an arbitrary grid (non-matching with regard to the fluid grid) have no reasons to lie in the same physical region of the locally owned subdomain of the fluid grid. In fact this will almost never be the case, especially since we want to keep track of what is happening to the particles themselves.
//
// In particle-in-cell methods (PIC), it is often customary to assign ownership of the particles to the process where the particles lie. In this tutorial we illustrate a different approach, which is useful if one wants to keep track of information related to the particles (for example, if a particle is associated to a given degree of freedom, which is owned by a specific process and not necessarily the same process that owns the fluid cell where the particle happens to be at any given time). In the approach used here, ownership of the particles is assigned once at the beginning, and one-to-one communication happens whenever the original owner needs information from the process that owns the cell where the particle lives. We make sure that we set ownership of the particles using the initial particle distribution, and keep the same ownership throughout the execution of the program.
//
// With this overview out of the way, let us see what the function does. At the top, we create a temporary triangulation and DoFHandler object from which we will take the node locations for initial particle locations:
//
[0.x.42094] 
[0.x.42095] 
[0.x.42096] 
[0.x.42097] 
[0.x.42098] 
[0.x.42099] 
[0.x.42100] 
[0.x.42101] 
[0.x.42102] 
[0.x.42103] 
//
[0.x.42104] 
[0.x.42105] 
[0.x.42106] 
//
// This is where things start to get complicated. Since we may run this program in a parallel environment, every parallel process will now have created these temporary triangulations and DoFHandlers. But, in fully distributed triangulations, the active process only knows about the locally owned cells, and has no idea of how other processes have distributed their own cells. This is true for both the temporary triangulation created above as well as the fluid triangulation into which we want to embed the particles below. On the other hand, these locally known portions of the two triangulations will, in general, not overlap. That is, the locations of the particles we will create from the node locations of the temporary mesh are arbitrary, and may fall within a region of the fluid triangulation that the current process doesn't have access to (i.e., a region of the fluid domain where cells are artificial). In order to understand who to send those particles to, we need to have a (rough) idea of how the fluid grid is distributed among processors.
//
// We construct this information by first building an index tree of boxes bounding the locally owned cells, and then extracting one of the first levels of the tree:
//
[0.x.42107] 
[0.x.42108] 
[0.x.42109] 
[0.x.42110] 
[0.x.42111] 
//
[0.x.42112] 
[0.x.42113] 
[0.x.42114] 
//
// Each process now has a collection of bounding boxes that completely enclose all locally owned processes (but that may overlap the bounding boxes of other processes). We then exchange this information between all participating processes so that every process knows the bounding boxes of all other processes.
//
// Equipped with this knowledge, we can then initialize the `tracer_particle_handler` to the fluid mesh and generate the particles from the support points of the (temporary) tracer particles triangulation. This function call uses the `global_bounding_boxes` object we just constructed to figure out where to send the particles whose locations were derived from the locally owned part of the `particles_dof_handler`. At the end of this call, every particle will have been distributed to the correct process (i.e., the process that owns the fluid cell where the particle lives). We also output their number to the screen at this point.
//
[0.x.42115] 
[0.x.42116] 
//
[0.x.42117] 
[0.x.42118] 
//
[0.x.42119] 
[0.x.42120] 
[0.x.42121] 
//
[0.x.42122] 
[0.x.42123] 
//
// Each particle so created has a unique ID. At some point in the algorithm below, we will need vectors containing position and velocity information for each particle. This vector will have size `n_particles *
// spacedim`, and we will have to store the elements of this vector in a way so that each parallel process "owns" those elements that correspond to coordinates of the particles it owns. In other words, we have to partition the index space between zero and `n_particles * spacedim` among all processes. We can do this by querying the `tracer_particle_handler` for the IDs of its locally relevant particles, and construct the indices that would be needed to store in a (parallel distributed) vector of the position and velocity of all particles where we implicitly assume that we store the coordinates of each location or velocity in `spacedim` successive vector elements (this is what the  [2.x.5260]  function does).
//
[0.x.42124] 
[0.x.42125] 
[0.x.42126] 
//
// At the beginning of the simulation, all particles are in their original position. When particles move, they may traverse to a part of the domain which is owned by another process. If this happens, the current process keeps formally "ownership" of the particles, but may need read access from the process where the particle has landed. We keep this information in another index set, which stores the indices of all particles that are currently on the current process's subdomain, independently if they have always been here or not.
//
// Keeping this index set around allows us to leverage linear algebra classes for all communications regarding positions and velocities of the particles. This mimics what would happen in the case where another problem was solved in the solid domain (as in fluid-structure interaction. In this latter case, additional DOFs on the solid domain would be coupled to what is occurring in the fluid domain.
//
[0.x.42127] 
[0.x.42128] 
//
// Finally, we make sure that upon refinement, particles are correctly transferred. When performing local refinement or coarsening, particles will land in another cell. We could in principle redistribute all particles after refining, however this would be overly expensive.
//
// The  [2.x.5261]  class has a way to transfer information from a cell to its children or to its parent upon refinement, without the need to reconstruct the entire data structure. This is done by registering two callback functions to the triangulation. These functions will receive a signal when refinement is about to happen, and when it has just happened, and will take care of transferring all information to the newly refined grid with minimal computational cost.
//
[0.x.42129] 
[0.x.42130] 
//
[0.x.42131] 
[0.x.42132] 
[0.x.42133] 
[0.x.42134] 
//
// Similarly to what we have done for passive tracers, we next set up the particles that track the quadrature points of the solid mesh. The main difference here is that we also want to attach a weight value (the "JxW" value of the quadrature point) to each of particle, so that we can compute integrals even without direct access to the original solid grid.
//
// This is achieved by leveraging the "properties" concept of the  [2.x.5262]  class. It is possible to store (in a memory efficient way) an arbitrary number of `double` numbers for each of the  [2.x.5263]  objects inside a  [2.x.5264]  object. We use this possibility to store the JxW values of the quadrature points of the solid grid.
//
// In our case, we only need to store one property per particle: the JxW value of the integration on the solid grid. This is passed at construction time to the solid_particle_handler object as the last argument
//
[0.x.42135] 
[0.x.42136] 
[0.x.42137] 
[0.x.42138] 
//
[0.x.42139] 
[0.x.42140] 
[0.x.42141] 
[0.x.42142] 
//
// The number of particles that we generate locally is equal to the total number of locally owned cells times the number of quadrature points used in each cell. We store all these points in a vector, and their corresponding properties in a vector of vectors:
//
[0.x.42143] 
[0.x.42144] 
[0.x.42145] 
//
[0.x.42146] 
[0.x.42147] 
[0.x.42148] 
//
[0.x.42149] 
[0.x.42150] 
[0.x.42151] 
[0.x.42152] 
[0.x.42153] 
[0.x.42154] 
[0.x.42155] 
[0.x.42156] 
[0.x.42157] 
//
[0.x.42158] 
[0.x.42159] 
[0.x.42160] 
[0.x.42161] 
[0.x.42162] 
[0.x.42163] 
[0.x.42164] 
//
// We proceed in the same way we did with the tracer particles, reusing the computed bounding boxes. However, we first check that the `global_fluid_bounding_boxes` object has been actually filled. This should certainly be the case here, since this method is called after the one that initializes the tracer particles. However, we want to make sure that if in the future someone decides (for whatever reason) to initialize first the solid particle handler, or to copy just this part of the tutorial, a meaningful exception is thrown when things don't work as expected
//
// Since we have already stored the position of the quadrature points, we can use these positions to insert the particles directly using the `solid_particle_handler` instead of having to go through a  [2.x.5265]  function:
//
[0.x.42165] 
[0.x.42166] 
[0.x.42167] 
[0.x.42168] 
[0.x.42169] 
[0.x.42170] 
//
[0.x.42171] 
[0.x.42172] 
[0.x.42173] 
//
// As in the previous function, we end by making sure that upon refinement, particles are correctly transferred:
//
[0.x.42174] 
[0.x.42175] 
//
[0.x.42176] 
[0.x.42177] 
//
[0.x.42178] 
[0.x.42179] 
[0.x.42180] 
//
//  [2.x.5266] 
//
// We set up the finite element space and the quadrature formula to be used throughout the step. For the fluid, we use Taylor-Hood elements (e.g.  [2.x.5267] ). Since we do not solve any equation on the solid domain, an empty finite element space is generated. A natural extension of this program would be to solve a fluid structure interaction problem, which would require that the `solid_fe` use more useful FiniteElement class.
//
// Like for many other functions, we store the time necessary to carry out the operations we perform here. The current function puts its timing information into a section with label "Initial setup". Numerous other calls to this timer are made in various functions. They allow to monitor the absolute and relative cost of each individual function to identify bottlenecks.
//
[0.x.42181] 
[0.x.42182] 
[0.x.42183] 
[0.x.42184] 
//
[0.x.42185] 
[0.x.42186] 
[0.x.42187] 
[0.x.42188] 
[0.x.42189] 
[0.x.42190] 
//
[0.x.42191] 
[0.x.42192] 
//
[0.x.42193] 
[0.x.42194] 
[0.x.42195] 
[0.x.42196] 
[0.x.42197] 
//
// We next construct the distributed block matrices and vectors which are used to solve the linear equations that arise from the problem. This function is adapted from  [2.x.5268]  and we refer to this step for a thorough explanation.
//
[0.x.42198] 
[0.x.42199] 
[0.x.42200] 
[0.x.42201] 
//
[0.x.42202] 
//
[0.x.42203] 
[0.x.42204] 
[0.x.42205] 
//
[0.x.42206] 
[0.x.42207] 
//
[0.x.42208] 
//
[0.x.42209] 
[0.x.42210] 
[0.x.42211] 
[0.x.42212] 
//
[0.x.42213] 
[0.x.42214] 
[0.x.42215] 
[0.x.42216] 
//
[0.x.42217] 
[0.x.42218] 
[0.x.42219] 
[0.x.42220] 
[0.x.42221] 
//
[0.x.42222] 
[0.x.42223] 
//
[0.x.42224] 
[0.x.42225] 
[0.x.42226] 
[0.x.42227] 
[0.x.42228] 
[0.x.42229] 
[0.x.42230] 
[0.x.42231] 
[0.x.42232] 
[0.x.42233] 
//
[0.x.42234] 
[0.x.42235] 
[0.x.42236] 
[0.x.42237] 
[0.x.42238] 
//
[0.x.42239] 
[0.x.42240] 
[0.x.42241] 
[0.x.42242] 
[0.x.42243] 
[0.x.42244] 
[0.x.42245] 
[0.x.42246] 
[0.x.42247] 
//
[0.x.42248] 
//
[0.x.42249] 
[0.x.42250] 
//
[0.x.42251] 
[0.x.42252] 
[0.x.42253] 
[0.x.42254] 
[0.x.42255] 
//
[0.x.42256] 
[0.x.42257] 
//
[0.x.42258] 
[0.x.42259] 
//
[0.x.42260] 
[0.x.42261] 
[0.x.42262] 
[0.x.42263] 
[0.x.42264] 
[0.x.42265] 
[0.x.42266] 
//
[0.x.42267] 
//
[0.x.42268] 
[0.x.42269] 
[0.x.42270] 
[0.x.42271] 
[0.x.42272] 
[0.x.42273] 
[0.x.42274] 
[0.x.42275] 
[0.x.42276] 
//
[0.x.42277] 
[0.x.42278] 
[0.x.42279] 
[0.x.42280] 
[0.x.42281] 
[0.x.42282] 
//[2.x.5269] 
//
// We assemble the system matrix, the preconditioner matrix, and the right hand side. The code is adapted from  [2.x.5270] , which is essentially what  [2.x.5271]  also has, and is pretty standard if you know what the Stokes equations look like.
//
[0.x.42283] 
[0.x.42284] 
[0.x.42285] 
[0.x.42286] 
[0.x.42287] 
[0.x.42288] 
//
[0.x.42289] 
//
[0.x.42290] 
[0.x.42291] 
[0.x.42292] 
[0.x.42293] 
[0.x.42294] 
//
[0.x.42295] 
[0.x.42296] 
//
[0.x.42297] 
[0.x.42298] 
[0.x.42299] 
//
[0.x.42300] 
[0.x.42301] 
//
[0.x.42302] 
[0.x.42303] 
[0.x.42304] 
//
[0.x.42305] 
[0.x.42306] 
[0.x.42307] 
//
[0.x.42308] 
[0.x.42309] 
[0.x.42310] 
[0.x.42311] 
[0.x.42312] 
[0.x.42313] 
//
[0.x.42314] 
[0.x.42315] 
[0.x.42316] 
[0.x.42317] 
[0.x.42318] 
[0.x.42319] 
[0.x.42320] 
[0.x.42321] 
[0.x.42322] 
[0.x.42323] 
[0.x.42324] 
//
[0.x.42325] 
[0.x.42326] 
[0.x.42327] 
[0.x.42328] 
[0.x.42329] 
[0.x.42330] 
[0.x.42331] 
[0.x.42332] 
[0.x.42333] 
//
[0.x.42334] 
[0.x.42335] 
[0.x.42336] 
//
[0.x.42337] 
[0.x.42338] 
[0.x.42339] 
[0.x.42340] 
[0.x.42341] 
[0.x.42342] 
//
[0.x.42343] 
[0.x.42344] 
[0.x.42345] 
[0.x.42346] 
[0.x.42347] 
[0.x.42348] 
//
[0.x.42349] 
[0.x.42350] 
[0.x.42351] 
[0.x.42352] 
//
[0.x.42353] 
[0.x.42354] 
[0.x.42355] 
[0.x.42356] 
//
// The following method is then the one that deals with the penalty terms that result from imposing the velocity on the impeller. It is, in a sense, the heart of the tutorial, but it is relatively straightforward. Here we exploit the `solid_particle_handler` to compute the Nitsche restriction or the penalization in the embedded domain.
//
[0.x.42357] 
[0.x.42358] 
[0.x.42359] 
[0.x.42360] 
//
[0.x.42361] 
[0.x.42362] 
//
[0.x.42363] 
//
[0.x.42364] 
[0.x.42365] 
//
[0.x.42366] 
[0.x.42367] 
[0.x.42368] 
//
[0.x.42369] 
[0.x.42370] 
//
// We loop over all the local particles. Although this could be achieved directly by looping over all the cells, this would force us to loop over numerous cells which do not contain particles. Consequently, we loop over all the particles, but, we get the reference of the cell in which the particle lies and then loop over all particles within that cell. This enables us to skip the cells which do not contain particles, yet to assemble the local matrix and rhs of each cell to apply the Nitsche restriction. Once we are done with all particles on one cell, we advance the `particle` iterator to the particle past the end of the ones on the current cell (this is the last line of the `while` loop's body).
//
[0.x.42371] 
[0.x.42372] 
[0.x.42373] 
[0.x.42374] 
[0.x.42375] 
//
// We get an iterator to the cell within which the particle lies from the particle itself. We can then assemble the additional terms in the system matrix and the right hand side as we would normally.
//
[0.x.42376] 
[0.x.42377] 
[0.x.42378] 
[0.x.42379] 
//
// So then let us get the collection of cells that are located on this cell and iterate over them. From each particle we gather the location and the reference location of the particle as well as the additional information that is attached to the particle. In the present case, this information is the "JxW" of the quadrature points which were used to generate the particles.
//
// Using this information, we can add the contribution of the quadrature point to the local_matrix and local_rhs. We can evaluate the value of the shape function at the position of each particle easily by using its reference location.
//
[0.x.42380] 
[0.x.42381] 
[0.x.42382] 
[0.x.42383] 
[0.x.42384] 
[0.x.42385] 
[0.x.42386] 
//
[0.x.42387] 
[0.x.42388] 
[0.x.42389] 
[0.x.42390] 
[0.x.42391] 
[0.x.42392] 
[0.x.42393] 
[0.x.42394] 
[0.x.42395] 
[0.x.42396] 
[0.x.42397] 
[0.x.42398] 
[0.x.42399] 
[0.x.42400] 
[0.x.42401] 
[0.x.42402] 
[0.x.42403] 
[0.x.42404] 
[0.x.42405] 
[0.x.42406] 
[0.x.42407] 
[0.x.42408] 
[0.x.42409] 
//
[0.x.42410] 
[0.x.42411] 
[0.x.42412] 
[0.x.42413] 
[0.x.42414] 
[0.x.42415] 
[0.x.42416] 
//
[0.x.42417] 
[0.x.42418] 
[0.x.42419] 
//[2.x.5272] 
//
// This function solves the linear system with FGMRES with a block diagonal preconditioner and an algebraic multigrid (AMG) method for the diagonal blocks. The preconditioner applies a V cycle to the  [2.x.5273]  (i.e., the velocity-velocity) block and a CG with the mass matrix for the  [2.x.5274]  block (which is our approximation to the Schur complement: the pressure mass matrix assembled above).
//
[0.x.42420] 
[0.x.42421] 
[0.x.42422] 
[0.x.42423] 
//
[0.x.42424] 
[0.x.42425] 
[0.x.42426] 
//
[0.x.42427] 
[0.x.42428] 
[0.x.42429] 
[0.x.42430] 
[0.x.42431] 
//
[0.x.42432] 
[0.x.42433] 
[0.x.42434] 
//
[0.x.42435] 
[0.x.42436] 
[0.x.42437] 
[0.x.42438] 
[0.x.42439] 
//
[0.x.42440] 
[0.x.42441] 
//
[0.x.42442] 
[0.x.42443] 
[0.x.42444] 
//
[0.x.42445] 
[0.x.42446] 
[0.x.42447] 
[0.x.42448] 
//
[0.x.42449] 
//
[0.x.42450] 
[0.x.42451] 
[0.x.42452] 
[0.x.42453] 
//
[0.x.42454] 
[0.x.42455] 
//
[0.x.42456] 
//
[0.x.42457] 
//
[0.x.42458] 
//
[0.x.42459] 
[0.x.42460] 
//
[0.x.42461] 
//
[0.x.42462] 
[0.x.42463] 
[0.x.42464] 
[0.x.42465] 
[0.x.42466] 
[0.x.42467] 
[0.x.42468] 
[0.x.42469] 
[0.x.42470] 
//
//  [2.x.5275] 
//
// We deal with mesh refinement in a completely standard way:
//
[0.x.42471] 
[0.x.42472] 
[0.x.42473] 
[0.x.42474] 
[0.x.42475] 
//
[0.x.42476] 
[0.x.42477] 
[0.x.42478] 
[0.x.42479] 
[0.x.42480] 
[0.x.42481] 
[0.x.42482] 
[0.x.42483] 
//
[0.x.42484] 
[0.x.42485] 
[0.x.42486] 
[0.x.42487] 
[0.x.42488] 
[0.x.42489] 
[0.x.42490] 
[0.x.42491] 
[0.x.42492] 
[0.x.42493] 
[0.x.42494] 
[0.x.42495] 
[0.x.42496] 
[0.x.42497] 
[0.x.42498] 
[0.x.42499] 
[0.x.42500] 
//
[0.x.42501] 
[0.x.42502] 
[0.x.42503] 
[0.x.42504] 
[0.x.42505] 
[0.x.42506] 
[0.x.42507] 
[0.x.42508] 
[0.x.42509] 
//
[0.x.42510] 
[0.x.42511] 
[0.x.42512] 
[0.x.42513] 
[0.x.42514] 
//
[0.x.42515] 
//
[0.x.42516] 
[0.x.42517] 
[0.x.42518] 
[0.x.42519] 
//[2.x.5276] 
//
// We output the results (velocity and pressure) on the fluid domain using the standard parallel capabilities of deal.II. A single compressed vtu file is written that agglomerates the information of all processors. An additional `.pvd` record is written to associate the physical time to the vtu files.
//
[0.x.42520] 
[0.x.42521] 
[0.x.42522] 
[0.x.42523] 
[0.x.42524] 
[0.x.42525] 
//
[0.x.42526] 
[0.x.42527] 
[0.x.42528] 
[0.x.42529] 
[0.x.42530] 
[0.x.42531] 
[0.x.42532] 
//
[0.x.42533] 
[0.x.42534] 
[0.x.42535] 
[0.x.42536] 
[0.x.42537] 
[0.x.42538] 
//
[0.x.42539] 
[0.x.42540] 
[0.x.42541] 
[0.x.42542] 
//
[0.x.42543] 
//
[0.x.42544] 
[0.x.42545] 
[0.x.42546] 
[0.x.42547] 
//
[0.x.42548] 
[0.x.42549] 
[0.x.42550] 
[0.x.42551] 
[0.x.42552] 
//
// Similarly, we write the particles (either from the solid or the tracers) as a single compressed vtu file through the  [2.x.5277]  object. This simple object does not write the additional information attached as "properties" to the particles, but only writes their id -- but then, we don't care about the "JxW" values of these particle locations anyway, so no information that we may have wanted to visualize is lost.
//
[0.x.42553] 
[0.x.42554] 
[0.x.42555] 
[0.x.42556] 
[0.x.42557] 
[0.x.42558] 
[0.x.42559] 
[0.x.42560] 
[0.x.42561] 
[0.x.42562] 
[0.x.42563] 
[0.x.42564] 
[0.x.42565] 
//
[0.x.42566] 
[0.x.42567] 
[0.x.42568] 
[0.x.42569] 
[0.x.42570] 
[0.x.42571] 
[0.x.42572] 
[0.x.42573] 
[0.x.42574] 
//[2.x.5278] 
//
// This function now orchestrates the entire simulation. It is very similar to the other time dependent tutorial programs -- take  [2.x.5279]  or  [2.x.5280]  as an example. At the beginning, we output some status information and also save all current parameters to a file in the output directory, for reproducibility.
//
[0.x.42575] 
[0.x.42576] 
[0.x.42577] 
[0.x.42578] 
[0.x.42579] 
[0.x.42580] 
[0.x.42581] 
[0.x.42582] 
[0.x.42583] 
[0.x.42584] 
[0.x.42585] 
[0.x.42586] 
[0.x.42587] 
[0.x.42588] 
[0.x.42589] 
[0.x.42590] 
//
// We then start the time loop. We initialize all the elements of the simulation in the first cycle
//
[0.x.42591] 
[0.x.42592] 
[0.x.42593] 
//
[0.x.42594] 
[0.x.42595] 
[0.x.42596] 
[0.x.42597] 
[0.x.42598] 
[0.x.42599] 
//
[0.x.42600] 
[0.x.42601] 
[0.x.42602] 
[0.x.42603] 
[0.x.42604] 
[0.x.42605] 
[0.x.42606] 
[0.x.42607] 
[0.x.42608] 
[0.x.42609] 
[0.x.42610] 
[0.x.42611] 
[0.x.42612] 
[0.x.42613] 
[0.x.42614] 
[0.x.42615] 
[0.x.42616] 
[0.x.42617] 
[0.x.42618] 
[0.x.42619] 
[0.x.42620] 
[0.x.42621] 
[0.x.42622] 
[0.x.42623] 
[0.x.42624] 
//
// After the first time step, we displace the solid body at the beginning of each time step to take into account the fact that is has moved.
//
[0.x.42625] 
[0.x.42626] 
[0.x.42627] 
[0.x.42628] 
//
[0.x.42629] 
[0.x.42630] 
[0.x.42631] 
[0.x.42632] 
[0.x.42633] 
//
// In order to update the state of the system, we first interpolate the fluid velocity at the position of the tracer particles and, with a naive explicit Euler scheme, advect the massless tracer particles.
//
[0.x.42634] 
[0.x.42635] 
[0.x.42636] 
[0.x.42637] 
[0.x.42638] 
[0.x.42639] 
[0.x.42640] 
[0.x.42641] 
//
[0.x.42642] 
//
[0.x.42643] 
[0.x.42644] 
[0.x.42645] 
//
[0.x.42646] 
[0.x.42647] 
[0.x.42648] 
[0.x.42649] 
//
[0.x.42650] 
//
[0.x.42651] 
[0.x.42652] 
[0.x.42653] 
//
// Using these new locations, we can then assemble the Stokes system and solve it.
//
[0.x.42654] 
[0.x.42655] 
[0.x.42656] 
//
// With the appropriate frequencies, we then write the information of the solid particles, the tracer particles, and the fluid domain into files for visualization, and end the time step by adapting the mesh.
//
[0.x.42657] 
[0.x.42658] 
[0.x.42659] 
[0.x.42660] 
[0.x.42661] 
[0.x.42662] 
[0.x.42663] 
[0.x.42664] 
[0.x.42665] 
[0.x.42666] 
[0.x.42667] 
[0.x.42668] 
[0.x.42669] 
[0.x.42670] 
[0.x.42671] 
[0.x.42672] 
[0.x.42673] 
[0.x.42674] 
[0.x.42675] 
[0.x.42676] 
[0.x.42677] 
[0.x.42678] 
[0.x.42679] 
[0.x.42680] 
//
[0.x.42681] 
//[2.x.5281] 
//
// The remainder of the code, the `main()` function, is standard, with the exception of the handling of input parameter files. We allow the user to specify an optional parameter file as an argument to the program. If nothing is specified, we use the default file "parameters.prm", which is created if non existent. The file name is scanned for the the string "23" first, and "3" afterwards. If the filename contains the string "23", the problem classes are instantiated with template arguments 2 and 3 respectively. If only the string "3" is found, then both template arguments are set to 3, otherwise both are set to 2.
//
// If the program is called without any command line arguments (i.e., `argc==1`), then we just use "parameters.prm" by default.
//
[0.x.42682] 
[0.x.42683] 
[0.x.42684] 
[0.x.42685] 
[0.x.42686] 
[0.x.42687] 
[0.x.42688] 
[0.x.42689] 
//
[0.x.42690] 
[0.x.42691] 
[0.x.42692] 
[0.x.42693] 
[0.x.42694] 
//
[0.x.42695] 
[0.x.42696] 
[0.x.42697] 
[0.x.42698] 
//
[0.x.42699] 
[0.x.42700] 
[0.x.42701] 
[0.x.42702] 
[0.x.42703] 
[0.x.42704] 
[0.x.42705] 
//
[0.x.42706] 
[0.x.42707] 
[0.x.42708] 
[0.x.42709] 
[0.x.42710] 
[0.x.42711] 
[0.x.42712] 
//
[0.x.42713] 
[0.x.42714] 
[0.x.42715] 
[0.x.42716] 
[0.x.42717] 
[0.x.42718] 
[0.x.42719] 
[0.x.42720] 
[0.x.42721] 
[0.x.42722] 
[0.x.42723] 
[0.x.42724] 
[0.x.42725] 
[0.x.42726] 
[0.x.42727] 
//
[0.x.42728] 
[0.x.42729] 
[0.x.42730] 
[0.x.42731] 
[0.x.42732] 
[0.x.42733] 
[0.x.42734] 
[0.x.42735] 
[0.x.42736] 
[0.x.42737] 
[0.x.42738] 
[0.x.42739] 
[0.x.42740] 
[0.x.42741] 
//
[0.x.42742] 
[0.x.42743] 
[0.x.42744] 
[0.x.42745] 
[0.x.42746] 
[0.x.42747] 
[0.x.42748] 
[0.x.42749] 
[0.x.42750] 
[0.x.42751] 
[0.x.42752] 
[0.x.42753] 
[0.x.42754] 
[0.x.42755] 
[0.x.42756] 
[0.x.42757] 
[0.x.42758] 
[0.x.42759] 
[0.x.42760] 
//
// We start by including all the necessary deal.II header files and some C++ related ones. This first header will give us access to a data structure that will allow us to store arbitrary data within it.
//
[0.x.42761] 
//
// Next come some core classes, including one that provides an implementation for time-stepping.
//
[0.x.42762] 
[0.x.42763] 
[0.x.42764] 
[0.x.42765] 
[0.x.42766] 
[0.x.42767] 
[0.x.42768] 
//
// Then some headers that define some useful coordinate transformations and kinematic relationships that are often found in nonlinear elasticity.
//
[0.x.42769] 
[0.x.42770] 
[0.x.42771] 
//
// The following two headers provide all of the functionality that we need to perform automatic differentiation, and use the symbolic computer algebra system that deal.II can utilize. The headers of all automatic differentiation and symbolic differentiation wrapper classes, and any ancillary data structures that are required, are all collected inside these unifying headers.
//
[0.x.42772] 
[0.x.42773] 
//
// Including this header allows us the capability to write output to a file stream.
//
[0.x.42774] 
//
// As per usual, the entire tutorial program is defined within its own unique namespace.
//
[0.x.42775] 
[0.x.42776] 
[0.x.42777] 
//[2.x.5282] 
//
// Automatic and symbolic differentiation have some magical and mystical qualities. Although their use in a project can be beneficial for a multitude of reasons, the barrier to understanding how to use these frameworks or how they can be leveraged may exceed the patience of the developer that is trying to (reliably) integrate them into their work.
//
// Although it is the wish of the author to successfully illustrate how these tools can be integrated into workflows for finite element modelling, it might be best to first take a step back and start right from the basics. So to start off with, we'll first have a look at differentiating a "simple" mathematical function using both frameworks, so that the fundamental operations (both their sequence and function) can be firmly established and understood with minimal complication. In the second part of this tutorial we will put these fundamentals into practice and build on them further.
//
// Accompanying the description of the algorithmic steps to use the frameworks will be a simplified view as to what they *might* be doing in the background. This description will be very much one designed to aid understanding, and the reader is encouraged to view the  [2.x.5283]  module documentation for a far more formal description into how these tools actually work.
//
//  [2.x.5284] 
[0.x.42778] 
[0.x.42779] 
//
// In order to convince the reader that these tools are indeed useful in practice, let us choose a function for which it is not too difficult to compute the analytical derivatives by hand. It's just sufficiently complicated to make you think about whether or not you truly want to go through with this exercise, and might also make you question whether you are completely sure that your calculations and implementation for its derivatives are correct. The point, of course, is that differentiation of functions is in a sense relatively formulaic and should be something computers are good at -- if we could build on existing software that understands the rules, we wouldn't have to bother with doing it ourselves.
//
// We choose the two variable trigonometric function  [2.x.5285]  for this purpose. Notice that this function is templated on the number type. This is done because we can often (but not always) use special auto-differentiable and symbolic types as drop-in replacements for real or complex valued types, and these will then perform some elementary calculations, such as evaluate a function value along with its derivatives. We will exploit that property and make sure that we need only define our function once, and then it can be re-used in whichever context we wish to perform differential operations on it.
//
[0.x.42780] 
[0.x.42781] 
[0.x.42782] 
[0.x.42783] 
[0.x.42784] 
//
// Rather than revealing this function's derivatives immediately, we'll forward declare functions that return them and defer their definition to later. As implied by the function names, they respectively return the derivatives  [2.x.5286] :
//
[0.x.42785] 
//[2.x.5287] :
//
[0.x.42786] 
//[2.x.5288] :
//
[0.x.42787] 
//[2.x.5289] :
//
[0.x.42788] 
//[2.x.5290] :
//
[0.x.42789] 
//
// and, lastly,  [2.x.5291] :
//
[0.x.42790] 
//[2.x.5292] 
//
// To begin, we'll use AD as the tool to automatically compute derivatives for us. We will evaluate the function with the arguments `x` and `y`, and expect the resulting value and all of the derivatives to match to within the given tolerance.
//
[0.x.42791] 
[0.x.42792] 
[0.x.42793] 
//
// Our function  [2.x.5293]  is a scalar-valued function, with arguments that represent the typical input variables that one comes across in algebraic calculations or tensor calculus. For this reason, the  [2.x.5294]  class is the appropriate wrapper class to use to do the computations that we require. (As a point of comparison, if the function arguments represented finite element cell degrees-of-freedom, we'd want to treat them differently.) The spatial dimension of the problem is irrelevant since we have no vector- or tensor-valued arguments to accommodate, so the `dim` template argument is arbitrarily assigned a value of 1. The second template argument stipulates which AD framework will be used (deal.II has support for several external AD frameworks), and what the underlying number type provided by this framework is to be used. This number type influences the maximum order of the differential operation, and the underlying algorithms that are used to compute them. Given its template nature, this choice is a compile-time decision because many (but not all) of the AD libraries exploit compile-time meta-programming to implement these special number types in an efficient manner. The third template parameter states what the result type is; in our case, we're working with `double`s.
//
[0.x.42794] 
[0.x.42795] 
[0.x.42796] 
[0.x.42797] 
[0.x.42798] 
//
// It is necessary that we pre-register with our  [2.x.5295]  class how many arguments (what we will call "independent variables") the function  [2.x.5296]  has. Those arguments are `x` and `y`, so obviously there are two of them.
//
[0.x.42799] 
//
// We now have sufficient information to create and initialize an instance of the helper class. We can also get the concrete number type that will be used in all subsequent calculations. This is useful, because we can write everything from here on by referencing this type, and if we ever want to change the framework used, or number type (e.g., if we need more differential operations) then we need only adjust the `ADTypeCode` template parameter.
//
[0.x.42800] 
[0.x.42801] 
//
// The next step is to register the numerical values of the independent variables with the helper class. This is done because the function and its derivatives will be evaluated for exactly these arguments. Since we register them in the order `{x,y}`, the variable `x` will be assigned component number `0`, and `y` will be component `1` -- a detail that will be used in the next few lines.
//
[0.x.42802] 
//
// We now ask for the helper class to give to us the independent variables with their auto-differentiable representation. These are termed "sensitive variables", because from this point on any operations that we do with the components `independent_variables_ad` are tracked and recorded by the AD framework, and will be considered when we ask for the derivatives of something that they're used to compute. What the helper returns is a `vector` of auto-differentiable numbers, but we can be sure that the zeroth element represents `x` and the first element `y`. Just to make completely sure that there's no ambiguity of what number type these variables are, we suffix all of the auto-differentiable variables with `ad`.
//
[0.x.42803] 
[0.x.42804] 
[0.x.42805] 
[0.x.42806] 
//
// We can immediately pass in our sensitive representation of the independent variables to our templated function that computes  [2.x.5297] . This also returns an auto-differentiable number.
//
[0.x.42807] 
//
// So now the natural question to ask is what we have actually just computed by passing these special `x_ad` and `y_ad` variables to the function `f`, instead of the original `double` variables `x` and `y`? In other words, how is all of this related to the computation of the derivatives that we were wanting to determine? Or, more concisely: What is so special about this returned `ADNumberType` object that gives it the ability to magically return derivatives?
//
// In essence, how this *could* be done is the following: This special number can be viewed as a data structure that stores the function value, and the prescribed number of derivatives. For a once-differentiable number expecting two arguments, it might look like this:
//
// [1.x.172]
//
// For our independent variable `x_ad`, the starting value of `x_ad.value` would simply be its assigned value (i.e., the real value of that this variable represents). The derivative `x_ad.derivatives[0]` would be initialized to `1`, since `x` is the zeroth independent variable and  [2.x.5298] . The derivative `x.derivatives[1]` would be initialized to zero, since the first independent variable is `y` and  [2.x.5299] .
//
// For the function derivatives to be meaningful, we must assume that not only is this function differentiable in an analytical sense, but that it is also differentiable at the evaluation point `x,y`. We can exploit both of these assumptions: when we use this number type in mathematical operations, the AD framework *could*
// overload the operations (e.g., `%operator+()`, `%operator*()` as well as `%sin()`, `%exp()`, etc.) such that the returned result has the expected value. At the same time, it would then compute the derivatives through the knowledge of exactly what function is being overloaded and rigorous application of the chain-rule. So, the `%sin()` function (with its argument `a` itself being a function of the independent variables `x` and `y`) *might* be defined as follows:
//
// [1.x.173]
//
// All of that could of course also be done for second and even higher order derivatives.
//
// So it is now clear that with the above representation the `ADNumberType` is carrying around some extra data that represents the various derivatives of differentiable functions with respect to the original (sensitive) independent variables. It should therefore be noted that there is computational overhead associated with using them (as we compute extra functions when doing derivative computations) as well as memory overhead in storing these results. So the prescribed number of levels of differential operations should ideally be kept to a minimum to limit computational cost. We could, for instance, have computed the first derivatives ourself and then have used the  [2.x.5300]  helper class to determine the gradient of the collection of dependent functions, which would be the second derivatives of the original scalar function.
//
// It is also worth noting that because the chain rule is indiscriminately applied and we only see the beginning and end-points of the calculation `{x,y}`  [2.x.5301]  `f(x,y)`, we will only ever be able to query the total derivatives of `f`; the partial derivatives (`a.derivatives[0]` and `a.derivatives[1]` in the above example) are intermediate values and are hidden from us.
//
// Okay, since we now at least have some idea as to exactly what `f_ad` represents and what is encoded within it, let's put all of that to some actual use. To gain access to those hidden derivative results, we register the final result with the helper class. After this point, we can no longer change the value of `f_ad` and have those changes reflected in the results returned by the helper class.
//
[0.x.42808] 
//
// The next step is to extract the derivatives (specifically, the function gradient and Hessian). To do so we first create some temporary data structures (with the result type `double`) to store the derivatives (noting that all derivatives are returned at once, and not individually)...
//
[0.x.42809] 
[0.x.42810] 
[0.x.42811] 
//
// ... and we then request that the helper class compute these derivatives, and the function value itself. And that's it. We have everything that we were aiming to get.
//
[0.x.42812] 
[0.x.42813] 
[0.x.42814] 
//
// We can convince ourselves that the AD framework is correct by comparing it to the analytical solution. (Or, if you're like the author, you'll be doing the opposite and will rather verify that your implementation of the analytical solution is correct!)
//
[0.x.42815] 
[0.x.42816] 
[0.x.42817] 
[0.x.42818] 
[0.x.42819] 
[0.x.42820] 
[0.x.42821] 
//
// Because we know the ordering of the independent variables, we know which component of the gradient relates to which derivative...
//
[0.x.42822] 
[0.x.42823] 
//
[0.x.42824] 
[0.x.42825] 
[0.x.42826] 
[0.x.42827] 
[0.x.42828] 
[0.x.42829] 
[0.x.42830] 
[0.x.42831] 
[0.x.42832] 
[0.x.42833] 
[0.x.42834] 
[0.x.42835] 
[0.x.42836] 
[0.x.42837] 
//
// ... and similar for the Hessian.
//
[0.x.42838] 
[0.x.42839] 
[0.x.42840] 
[0.x.42841] 
//
[0.x.42842] 
[0.x.42843] 
[0.x.42844] 
[0.x.42845] 
[0.x.42846] 
[0.x.42847] 
[0.x.42848] 
[0.x.42849] 
[0.x.42850] 
[0.x.42851] 
[0.x.42852] 
[0.x.42853] 
[0.x.42854] 
[0.x.42855] 
[0.x.42856] 
[0.x.42857] 
[0.x.42858] 
[0.x.42859] 
[0.x.42860] 
[0.x.42861] 
[0.x.42862] 
[0.x.42863] 
[0.x.42864] 
[0.x.42865] 
[0.x.42866] 
[0.x.42867] 
[0.x.42868] 
[0.x.42869] 
[0.x.42870] 
//
// That's pretty great. There wasn't too much work involved in computing second-order derivatives of this trigonometric function.
//
//  [2.x.5302] 
//
// Since we now know how much "implementation effort" it takes to have the AD framework compute those derivatives for us, let's compare that to the same computed by hand and implemented in several stand-alone functions.
//
// Here are the two first derivatives of  [2.x.5303] :
//
//  [2.x.5304] 
[0.x.42871] 
[0.x.42872] 
[0.x.42873] 
[0.x.42874] 
[0.x.42875] 
//[2.x.5305] 
[0.x.42876] 
[0.x.42877] 
[0.x.42878] 
[0.x.42879] 
//
// And here are the four second derivatives of  [2.x.5306] :
//
//  [2.x.5307] 
[0.x.42880] 
[0.x.42881] 
[0.x.42882] 
[0.x.42883] 
[0.x.42884] 
//[2.x.5308] 
[0.x.42885] 
[0.x.42886] 
[0.x.42887] 
[0.x.42888] 
//[2.x.5309]  (as expected, on the basis of [Schwarz's theorem](https:en.wikipedia.org/wiki/Symmetry_of_second_derivatives))
//
[0.x.42889] 
[0.x.42890] 
[0.x.42891] 
[0.x.42892] 
//[2.x.5310] 
[0.x.42893] 
[0.x.42894] 
[0.x.42895] 
[0.x.42896] 
//
// Hmm... there's a lot of places in the above where we could have introduced an error in the above, especially when it comes to applying the chain rule. Although they're no silver bullet, at the very least these AD frameworks can serve as a verification tool to make sure that we haven't made any errors (either by calculation or by implementation) that would negatively affect our results.
//
// The point of this example of course is that we might have chosen a relatively simple function  [2.x.5311]  for which we can hand-verify that the derivatives the AD framework computed is correct. But the AD framework didn't care that the function was simple: It could have been a much much more convoluted expression, or could have depended on more than two variables, and it would still have been able to compute the derivatives -- the only difference would have been that *we* wouldn't have been able to come up with the derivatives any more to verify correctness of the AD framework.
//
//  [2.x.5312] 
//
// We'll now repeat the same exercise using symbolic differentiation. The term "symbolic differentiation" is a little bit misleading because differentiation is just one tool that the Computer Algebra System (CAS) (i.e., the symbolic framework) provides. Nevertheless, in the context of finite element modeling and applications it is the most common use of a CAS and will therefore be the one that we'll focus on. Once more, we'll supply the argument values `x` and `y` with which to evaluate our function  [2.x.5313]  and its derivatives, and a tolerance with which to test the correctness of the returned results.
//
[0.x.42897] 
[0.x.42898] 
[0.x.42899] 
//
// The first step that we need to take is to form the symbolic variables that represent the function arguments that we wish to differentiate with respect to. Again, these will be the independent variables for our problem and as such are, in some sense, primitive variables that have no dependencies on any other variable. We create these types of (independent) variables by initializing a symbolic type  [2.x.5314]  which is a wrapper to a set of classes used by the symbolic framework, with a unique identifier. On this occasion it makes sense that this identifier, a  [2.x.5315]  be simply `"x"` for the  [2.x.5316]  argument, and likewise `"y"` for the  [2.x.5317]  argument to the dependent function. Like before, we'll suffix symbolic variable names with `sd` so that we can clearly see which variables are symbolic (as opposed to numeric) in nature.
//
[0.x.42900] 
[0.x.42901] 
//
// Using the templated function that computes  [2.x.5318] , we can pass these independent variables as arguments to the function. The returned result will be another symbolic type that represents the sequence of operations used to compute  [2.x.5319] .
//
[0.x.42902] 
//
// At this point it is legitimate to print out the expression `f_sd`, and if we did so [1.x.174] we would see `f(x,y) = cos(y/x)` printed to the console.
//
// You might notice that we've constructed our symbolic function `f_sd` with no context as to how we might want to use it: In contrast to the AD approach shown above, what we were returned from calling `f(x_sd, y_sd)` is not the evaluation of the function `f` at some specific point, but is in fact a symbolic representation of the evaluation at a generic, as yet undetermined, point. This is one of the key points that makes symbolic frameworks (the CAS) different from automatic differentiation frameworks. Each of the variables `x_sd` and `y_sd`, and even the composite dependent function `f_sd`, are in some sense respectively "placeholders" for numerical values and a composition of operations. In fact, the individual components that are used to compose the function are also placeholders. The sequence of operations are encoded into in a tree-like data structure (conceptually similar to an [abstract syntax tree](https:en.wikipedia.org/wiki/Abstract_syntax_tree)).
//
// Once we form these data structures we can defer any operations that we might want to do with them until some later time. Each of these placeholders represents something, but we have the opportunity to define or redefine what they represent at any convenient point in time. So for this particular problem it makes sense that we somehow want to associate "x" and "y" with *some* numerical value (with type yet to be determined), but we could conceptually (and if it made sense) assign the ratio "y/x" a value instead of the variables "x" and "y" individually. We could also associate with "x" or "y" some other symbolic function `g(a,b)`. Any of these operations involves manipulating the recorded tree of operations, and substituting the salient nodes on the tree (and that nodes' subtree) with something else. The key word here is "substitution", and indeed there are many functions in the  [2.x.5320]  namespace that have this word in their names.
//
// This capability makes the framework entirely generic. In the context of finite element simulations, the types of operations that we would typically perform with our symbolic types are function composition, differentiation, substitution (partial or complete), and evaluation (i.e., conversion of the symbolic type to its numerical counterpart). But should you need it, a CAS is often capable of more than just this: It could be forming anti-derivatives (integrals) of functions, perform simplifications on the expressions that form a function (e.g., replace  [2.x.5321]  by  [2.x.5322] ; or, more simply: if the function did an operation like `1+2`, a CAS could replace it by `3`), and so forth: The *expression* that a variable represents is obtained from how the function  [2.x.5323]  is implemented, but a CAS can do with it whatever its functionality happens to be.
//
// Specifically, to compute the symbolic representation of the first derivatives of the dependent function with respect to its individual independent variables, we use the  [2.x.5324]  function with the independent variable given as its argument. Each call will cause the CAS to go through the tree of operations that compose `f_sd` and differentiate each node of the expression tree with respect to the given symbolic argument.
//
[0.x.42903] 
[0.x.42904] 
//
// To compute the symbolic representation of the second derivatives, we simply differentiate the first derivatives with respect to the independent variables. So to compute a higher order derivative, we first need to compute the lower order derivative. (As the return type of the call to `differentiate()` is an expression, we could in principal execute double differentiation directly from the scalar by chaining two calls together. But this is unnecessary in this particular case, since we have the intermediate results at hand.)
//
[0.x.42905] 
[0.x.42906] 
[0.x.42907] 
[0.x.42908] 
[0.x.42909] 
[0.x.42910] 
[0.x.42911] 
[0.x.42912] 
//
// Printing the expressions for the first and second derivatives, as computed by the CAS, using the statements [1.x.175] renders the following output: [1.x.176] This compares favorably to the analytical expressions for these derivatives that were presented earlier.
//
// Now that we have formed the symbolic expressions for the function and its derivatives, we want to evaluate them for the numeric values for the main function arguments `x` and `y`. To accomplish this, we construct a *substitution map*, which maps the symbolic values to their numerical counterparts.
//
[0.x.42913] 
[0.x.42914] 
[0.x.42915] 
[0.x.42916] 
//
// The last step in the process is to convert all symbolic variables and operations into numerical values, and produce the numerical result of this operation. To do this we combine the substitution map with the symbolic variable in the step we have already mentioned above: "substitution".
//
// Once we pass this substitution map to the CAS, it will substitute each instance of the symbolic variable (or, more generally, sub-expression) with its numerical counterpart and then propagate these results up the operation tree, simplifying each node on the tree if possible. If the tree is reduced to a single value (i.e., we have substituted all of the independent variables with their numerical counterpart) then the evaluation is complete.
//
// Due to the strongly-typed nature of C++, we need to instruct the CAS to convert its representation of the result into an intrinsic data type (in this case a `double`). This is the "evaluation" step, and through the template type we define the return type of this process. Conveniently, these two steps can be done at once if we are certain that we've performed a full substitution.
//
[0.x.42917] 
[0.x.42918] 
//
[0.x.42919] 
[0.x.42920] 
[0.x.42921] 
[0.x.42922] 
[0.x.42923] 
[0.x.42924] 
[0.x.42925] 
//
// We can do the same for the first derivatives...
//
[0.x.42926] 
[0.x.42927] 
[0.x.42928] 
[0.x.42929] 
//
[0.x.42930] 
[0.x.42931] 
[0.x.42932] 
[0.x.42933] 
[0.x.42934] 
[0.x.42935] 
[0.x.42936] 
[0.x.42937] 
[0.x.42938] 
[0.x.42939] 
[0.x.42940] 
[0.x.42941] 
[0.x.42942] 
[0.x.42943] 
//
// ... and the second derivatives. Notice that we can reuse the same substitution map for each of these operations because we wish to evaluate all of these functions for the same values of `x` and `y`. Modifying the values in the substitution map renders the result of same symbolic expression evaluated with different values being assigned to the independent variables. We could also happily have each variable represent a real value in one pass, and a complex value in the next.
//
[0.x.42944] 
[0.x.42945] 
[0.x.42946] 
[0.x.42947] 
[0.x.42948] 
[0.x.42949] 
[0.x.42950] 
[0.x.42951] 
//
[0.x.42952] 
[0.x.42953] 
[0.x.42954] 
[0.x.42955] 
[0.x.42956] 
[0.x.42957] 
[0.x.42958] 
[0.x.42959] 
[0.x.42960] 
[0.x.42961] 
[0.x.42962] 
[0.x.42963] 
[0.x.42964] 
[0.x.42965] 
[0.x.42966] 
[0.x.42967] 
[0.x.42968] 
[0.x.42969] 
[0.x.42970] 
[0.x.42971] 
[0.x.42972] 
[0.x.42973] 
[0.x.42974] 
[0.x.42975] 
[0.x.42976] 
[0.x.42977] 
[0.x.42978] 
[0.x.42979] 
[0.x.42980] 
//[2.x.5325] 
//
// The function used to drive these initial examples is straightforward. We'll arbitrarily choose some values at which to evaluate the function (although knowing that `x = 0` is not permissible), and then pass these values to the functions that use the AD and SD frameworks.
//
[0.x.42981] 
[0.x.42982] 
[0.x.42983] 
[0.x.42984] 
//
[0.x.42985] 
[0.x.42986] 
[0.x.42987] 
[0.x.42988] 
//
[0.x.42989] 
[0.x.42990] 
[0.x.42991] 
[0.x.42992] 
[0.x.42993] 
//
[0.x.42994] 
//[2.x.5326] 
//
// Now that we've introduced the principles behind automatic and symbolic differentiation, we'll put them into action by formulating two coupled magneto-mechanical constitutive laws: one that is rate-independent, and another that exhibits rate-dependent behavior.
//
// As you will recall from the introduction, the material constitutive laws we will consider are far more complicated than the simple example above. This is not just because of the form of the function  [2.x.5327]  that we will consider, but in particular because  [2.x.5328]  doesn't just depend on two scalar variables, but instead on a whole bunch of *tensors*, each with several components. In some cases, these are *symmetric* tensors, for which only a subset of components is in fact independent, and one has to think about what it actually means to compute a derivative such as  [2.x.5329]  where  [2.x.5330]  is a symmetric tensor. How all of this will work will, hopefully, become clear below. It will also become clear that doing this by hand is going to be, at the very best, *exceedingly*
// *tedious* and, at worst, riddled with hard-to-find bugs.
//
[0.x.42995] 
[0.x.42996] 
//[2.x.5331] 
//
// We start with a description of the various material parameters that appear in the description of the energy function  [2.x.5332] .
//
// The ConstitutiveParameters class is used to hold these values. Values for all parameters (both constitutive and rheological) are taken from  [2.x.5333] , and are given values that produce a constitutive response that is broadly representative of a real, laboratory-made magneto-active polymer, though the specific values used here are of no consequence to the purpose of this program of course.
//
// The first four constitutive parameters respectively represent
//
// - the elastic shear modulus  [2.x.5334] ,
//
// - the elastic shear modulus at magnetic saturation  [2.x.5335] ,
//
// - the saturation magnetic field strength for the elastic shear   modulus  [2.x.5336] , and
//
// - the Poisson ratio  [2.x.5337] .
//
[0.x.42997] 
[0.x.42998] 
[0.x.42999] 
[0.x.43000] 
//
[0.x.43001] 
[0.x.43002] 
[0.x.43003] 
[0.x.43004] 
//
// The next four, which only pertain to the rate-dependent material, are parameters for
//
// - the viscoelastic shear modulus  [2.x.5338] ,
//
// - the viscoelastic shear modulus at magnetic saturation  [2.x.5339] ,
//
// - the saturation magnetic field strength for the viscoelastic   shear modulus  [2.x.5340] , and
//
// - the characteristic relaxation time  [2.x.5341] .
//
[0.x.43005] 
[0.x.43006] 
[0.x.43007] 
[0.x.43008] 
//
// The last parameter is the relative magnetic permeability  [2.x.5342] .
//
[0.x.43009] 
//
[0.x.43010] 
[0.x.43011] 
//
// The parameters are initialized through the ParameterAcceptor framework, which is discussed in detail in  [2.x.5343] .
//
[0.x.43012] 
[0.x.43013] 
[0.x.43014] 
[0.x.43015] 
[0.x.43016] 
[0.x.43017] 
[0.x.43018] 
[0.x.43019] 
[0.x.43020] 
//
[0.x.43021] 
[0.x.43022] 
[0.x.43023] 
[0.x.43024] 
[0.x.43025] 
[0.x.43026] 
[0.x.43027] 
//
[0.x.43028] 
//
[0.x.43029] 
[0.x.43030] 
//[2.x.5344] 
//
// Since we'll be formulating two constitutive laws for the same class of materials, it makes sense to define a base class that ensures a unified interface to them.
//
// The class declaration starts with the constructor that will accept the set of constitutive parameters that, in conjunction with the material law itself, dictate the material response.
//
[0.x.43031] 
[0.x.43032] 
[0.x.43033] 
[0.x.43034] 
[0.x.43035] 
[0.x.43036] 
//
// Instead of computing and returning the kinetic variables or their linearization at will, we'll calculate and store these values within a single method. These cached results will then be returned upon request. We'll defer the precise explanation as to why we'd want to do this to a later stage. What is important for now is to see that this function accepts all of the field variables, namely the magnetic field vector  [2.x.5345]  and right Cauchy-Green deformation tensor  [2.x.5346] , as well as the time discretizer. These, in addition to the  [2.x.5347]  are all the fundamental quantities that are required to compute the material response.
//
[0.x.43037] 
[0.x.43038] 
[0.x.43039] 
//
// The next few functions provide the interface to probe the material response due subject to the applied deformation and magnetic loading.
//
// Since the class of materials can be expressed in terms of a free energy  [2.x.5348] , we can compute that...
//
[0.x.43040] 
//
// ... as well as the two kinetic quantities:
//
// - the magnetic induction vector  [2.x.5349] , and
//
// - the total Piola-Kirchhoff stress tensor  [2.x.5350] 
[0.x.43041] 
//
[0.x.43042] 
//
// ... and the linearization of the kinetic quantities, which are:
//
// - the magnetostatic tangent tensor  [2.x.5351] ,
//
// - the total referential magnetoelastic coupling tensor  [2.x.5352] , and
//
// - the total referential elastic tangent tensor  [2.x.5353] .
//
[0.x.43043] 
//
[0.x.43044] 
//
[0.x.43045] 
//
// We'll also define a method that provides a mechanism for this class instance to do any additional tasks before moving on to the next timestep. Again, the reason for doing this will become clear a little later.
//
[0.x.43046] 
[0.x.43047] 
//
// In the `protected` part of the class, we store a reference to an instance of the constitutive parameters that govern the material response. For convenience, we also define some functions that return various constitutive parameters (both explicitly defined, as well as calculated).
//
// The parameters related to the elastic response of the material are, in order:
//
// - the elastic shear modulus,
//
// - the elastic shear modulus at saturation magnetic field,
//
// - the saturation magnetic field strength for the elastic shear   modulus,
//
// - the Poisson ratio,
//
// - the Lam&eacute; parameter, and
//
// - the bulk modulus.
//
[0.x.43048] 
[0.x.43049] 
//
[0.x.43050] 
//
[0.x.43051] 
//
[0.x.43052] 
//
[0.x.43053] 
//
[0.x.43054] 
//
[0.x.43055] 
//
// The parameters related to the elastic response of the material are, in order:
//
// - the viscoelastic shear modulus,
//
// - the viscoelastic shear modulus at magnetic saturation,
//
// - the saturation magnetic field strength for the viscoelastic   shear modulus, and
//
// - the characteristic relaxation time.
//
[0.x.43056] 
//
[0.x.43057] 
//
[0.x.43058] 
//
[0.x.43059] 
//
// The parameters related to the magnetic response of the material are, in order:
//
// - the relative magnetic permeability, and
//
// - the magnetic permeability constant  [2.x.5354]  (not really a material constant,   but rather a universal constant that we'll group here for   simplicity).
//
// We'll also implement a function that returns the timestep size from the time discretizion.
//
[0.x.43060] 
//
[0.x.43061] 
[0.x.43062] 
[0.x.43063] 
//
// In the following, let us start by implementing the several relatively trivial member functions of the class just defined:
//
[0.x.43064] 
[0.x.43065] 
[0.x.43066] 
[0.x.43067] 
[0.x.43068] 
[0.x.43069] 
[0.x.43070] 
[0.x.43071] 
//
[0.x.43072] 
[0.x.43073] 
[0.x.43074] 
[0.x.43075] 
[0.x.43076] 
[0.x.43077] 
//
[0.x.43078] 
[0.x.43079] 
[0.x.43080] 
[0.x.43081] 
[0.x.43082] 
[0.x.43083] 
//
[0.x.43084] 
[0.x.43085] 
[0.x.43086] 
[0.x.43087] 
[0.x.43088] 
[0.x.43089] 
//
[0.x.43090] 
[0.x.43091] 
[0.x.43092] 
[0.x.43093] 
[0.x.43094] 
[0.x.43095] 
//
[0.x.43096] 
[0.x.43097] 
[0.x.43098] 
[0.x.43099] 
[0.x.43100] 
[0.x.43101] 
//
[0.x.43102] 
[0.x.43103] 
[0.x.43104] 
[0.x.43105] 
[0.x.43106] 
[0.x.43107] 
[0.x.43108] 
//
[0.x.43109] 
[0.x.43110] 
[0.x.43111] 
[0.x.43112] 
[0.x.43113] 
[0.x.43114] 
//
[0.x.43115] 
[0.x.43116] 
[0.x.43117] 
[0.x.43118] 
[0.x.43119] 
[0.x.43120] 
//
[0.x.43121] 
[0.x.43122] 
[0.x.43123] 
[0.x.43124] 
[0.x.43125] 
[0.x.43126] 
//
[0.x.43127] 
[0.x.43128] 
[0.x.43129] 
[0.x.43130] 
[0.x.43131] 
[0.x.43132] 
//
[0.x.43133] 
[0.x.43134] 
[0.x.43135] 
[0.x.43136] 
[0.x.43137] 
[0.x.43138] 
//
[0.x.43139] 
[0.x.43140] 
[0.x.43141] 
[0.x.43142] 
[0.x.43143] 
[0.x.43144] 
//
[0.x.43145] 
[0.x.43146] 
[0.x.43147] 
[0.x.43148] 
[0.x.43149] 
[0.x.43150] 
//[2.x.5355] 
//
// We'll begin by considering a non-dissipative material, namely one that is governed by a magneto-hyperelastic constitutive law that exhibits stiffening when immersed in a magnetic field. As described in the introduction, the stored energy density function for such a material might be given by [1.x.177] with [1.x.178]
//
// Now on to the class that implements this behavior. Since we expect that this class fully describes a single material, we'll mark it as "final" so that the inheritance tree terminated here. At the top of the class, we define the helper type that we will use in the AD computations for our scalar energy density function. Note that we expect it to return values of type `double`. We also have to specify the number of spatial dimensions, `dim`, so that the link between vector, tensor and symmetric tensor fields and the number of components that they contain may be established. The concrete `ADTypeCode` used for the ADHelper class will be provided as a template argument at the point where this class is actually used.
//
[0.x.43151] 
[0.x.43152] 
[0.x.43153] 
[0.x.43154] 
[0.x.43155] 
[0.x.43156] 
[0.x.43157] 
//
[0.x.43158] 
[0.x.43159] 
[0.x.43160] 
//
// Since the public interface to the base class is pure-`virtual`, here we'll declare that this class will override all of these base class methods.
//
[0.x.43161] 
[0.x.43162] 
[0.x.43163] 
//
[0.x.43164] 
//
[0.x.43165] 
//
[0.x.43166] 
//
[0.x.43167] 
//
[0.x.43168] 
//
[0.x.43169] 
//
// In the `private` part of the class, we need to define some extractors that will help us set independent variables and later get the computed values related to the dependent variables. If this class were to be used in the context of a finite element problem, then each of these extractors is (most likely) related to the gradient of a component of the solution field (in this case, displacement and magnetic scalar potential). As you can probably infer by now, here "C" denotes the right Cauchy-Green tensor and "H" denotes the magnetic field vector.
//
[0.x.43170] 
[0.x.43171] 
[0.x.43172] 
//
// This is an instance of the automatic differentiation helper that we'll set up to do all of the differential calculations related to the constitutive law...
//
[0.x.43173] 
//
// ... and the following three member variables will store the output from the  [2.x.5356]  The  [2.x.5357]  returns the derivatives with respect to all field variables at once, so we'll retain the full gradient vector and Hessian matrix. From that, we'll extract the individual entries that we're actually interested in.
//
[0.x.43174] 
[0.x.43175] 
[0.x.43176] 
[0.x.43177] 
//
// When setting up the field component extractors, it is completely arbitrary as to how they are ordered. But it is important that the extractors do not have overlapping indices. The total number of components of these extractors defines the number of independent variables that the  [2.x.5358]  needs to track, and with respect to which we'll be taking derivatives. The resulting data structures  [2.x.5359]  and  [2.x.5360]  must also be sized accordingly. Once the  [2.x.5361]  is configured (its input argument being the total number of components of  [2.x.5362]  and  [2.x.5363] ), we can directly interrogate it as to how many independent variables it uses.
//
[0.x.43178] 
[0.x.43179] 
[0.x.43180] 
[0.x.43181] 
[0.x.43182] 
[0.x.43183] 
[0.x.43184] 
[0.x.43185] 
[0.x.43186] 
[0.x.43187] 
[0.x.43188] 
[0.x.43189] 
[0.x.43190] 
[0.x.43191] 
[0.x.43192] 
//
// As stated before, due to the way that the automatic differentiation libraries work, the  [2.x.5364]  will always returns the derivatives of the energy density function with respect to all field variables simultaneously. For this reason, it does not make sense to compute the derivatives in the functions `get_B()`, `get_S()`, etc. because we'd be doing a lot of extra computations that are then simply discarded. So, the best way to deal with that is to have a single function call that does all of the calculations up-front, and then we extract the stored data as its needed. That's what we'll do in the `update_internal_data()` method. As the material is rate-independent, we can ignore the DiscreteTime argument.
//
[0.x.43193] 
[0.x.43194] 
[0.x.43195] 
[0.x.43196] 
[0.x.43197] 
[0.x.43198] 
[0.x.43199] 
[0.x.43200] 
//
// Since we reuse the  [2.x.5365]  data structure at each time step, we need to clear it of all stale information before use.
//
[0.x.43201] 
//
// The next step is to set the values for all field components. These define the "point" around which we'll be computing the function gradients and their linearization. The extractors that we created before provide the association between the fields and the registry within the  [2.x.5366]  -- they'll be used repeatedly to ensure that we have the correct interpretation of which variable corresponds to which component of `H` or `C`.
//
[0.x.43202] 
[0.x.43203] 
//
// Now that we've done the initial setup, we can retrieve the AD counterparts of our fields. These are truly the independent variables for the energy function, and are "sensitive" to the calculations that are performed with them. Notice that the AD number are treated as a special number type, and can be used in many templated classes (in this example, as the scalar type for the Tensor and SymmetricTensor class).
//
[0.x.43204] 
[0.x.43205] 
[0.x.43206] 
[0.x.43207] 
//
// We can also use them in many functions that are templated on the scalar type. So, for these intermediate values that we require, we can perform tensor operations and some mathematical functions. The resulting type will also be an automatically differentiable number, which encodes the operations performed in these functions.
//
[0.x.43208] 
[0.x.43209] 
[0.x.43210] 
[0.x.43211] 
//
// Next we'll compute the scaling function that will cause the shear modulus to change (increase) under the influence of a magnetic field...
//
[0.x.43212] 
[0.x.43213] 
[0.x.43214] 
[0.x.43215] 
//
// ... and then we can define the material stored energy density function. We'll see later that this example is sufficiently complex to warrant the use of AD to, at the very least, verify an unassisted implementation.
//
[0.x.43216] 
[0.x.43217] 
[0.x.43218] 
[0.x.43219] 
[0.x.43220] 
[0.x.43221] 
//
// The stored energy density function is, in fact, the dependent variable for this problem, so as a final step in the  "configuration" phase, we register its definition with the  [2.x.5367] 
[0.x.43222] 
//
// Finally, we can retrieve the resulting value of the stored energy density function, as well as its gradient and Hessian with respect to the input fields, and cache them.
//
[0.x.43223] 
[0.x.43224] 
[0.x.43225] 
[0.x.43226] 
//
// The following few functions then allow for querying the so-stored value of  [2.x.5368] , and to extract the desired components of the gradient vector and Hessian matrix. We again make use of the extractors to express which parts of the total gradient vector and Hessian matrix we wish to retrieve. They only return the derivatives of the energy function, so for our definitions of the kinetic variables and their linearization a few more manipulations are required to form the desired result.
//
[0.x.43227] 
[0.x.43228] 
[0.x.43229] 
[0.x.43230] 
[0.x.43231] 
//
[0.x.43232] 
[0.x.43233] 
[0.x.43234] 
[0.x.43235] 
[0.x.43236] 
[0.x.43237] 
[0.x.43238] 
[0.x.43239] 
//
[0.x.43240] 
[0.x.43241] 
[0.x.43242] 
[0.x.43243] 
[0.x.43244] 
[0.x.43245] 
[0.x.43246] 
[0.x.43247] 
//
[0.x.43248] 
[0.x.43249] 
[0.x.43250] 
[0.x.43251] 
[0.x.43252] 
[0.x.43253] 
[0.x.43254] 
[0.x.43255] 
//
// Note that for coupled terms the order of the extractor arguments is especially important, as it dictates the order in which the directional derivatives are taken. So, if we'd reversed the order of the extractors in the call to `extract_hessian_component()` then we'd actually have been retrieving part of  [2.x.5369] .
//
[0.x.43256] 
[0.x.43257] 
[0.x.43258] 
[0.x.43259] 
[0.x.43260] 
[0.x.43261] 
[0.x.43262] 
[0.x.43263] 
//
[0.x.43264] 
[0.x.43265] 
[0.x.43266] 
[0.x.43267] 
[0.x.43268] 
[0.x.43269] 
[0.x.43270] 
[0.x.43271] 
//[2.x.5370] 
//
// The second material law that we'll consider will be one that represents a magneto-viscoelastic material with a single dissipative mechanism. We'll consider the free energy density function for such a material to be defined as [1.x.179] with [1.x.180] 
//[1.x.181] in conjunction with the evolution law for the internal viscous variable [1.x.182] that was discretized using a first-order backward difference approximation.
//
// Again, let us see how this is implemented in a concrete class. Instead of the AD framework used in the previous class, we will now utilize the SD approach. To support this, the class constructor accepts not only the  [2.x.5371]  but also two additional variables that will be used to initialize a  [2.x.5372]  We'll give more context to this later.
//
[0.x.43272] 
[0.x.43273] 
[0.x.43274] 
[0.x.43275] 
[0.x.43276] 
[0.x.43277] 
[0.x.43278] 
[0.x.43279] 
[0.x.43280] 
//
// Like for the automatic differentiation helper, the  [2.x.5373]  will return a collection of results all at once. So, in order to do that just once, we'll utilize a similar approach to before and do all of the expensive calculations within the `update_internal_data()` function, and cache the results for layer extraction.
//
[0.x.43281] 
[0.x.43282] 
[0.x.43283] 
//
[0.x.43284] 
//
[0.x.43285] 
//
[0.x.43286] 
//
[0.x.43287] 
//
[0.x.43288] 
//
[0.x.43289] 
//
// Since we're dealing with a rate dependent material, we'll have to update the history variable at the appropriate time. That will be the purpose of this function.
//
[0.x.43290] 
//
// In the `private` part of the class, we will want to keep track of the internal viscous deformation, so the following two (real-valued, non-symbolic) member variables respectively hold
//
// - the value of internal variable time step (and, if embedded within a   nonlinear solver framework, Newton step), and
//
// - the value of internal variable at the previous timestep.
//
// (We've labeled these variables "Q" so that they're easy to identify; in a sea of calculations it is not necessarily easy to distinguish `Cv` or `C_v` from `C`.)
//
[0.x.43291] 
[0.x.43292] 
[0.x.43293] 
//
// As we'll be using symbolic types, we'll need to define some symbolic variables to use with the framework. (They are all suffixed with "SD" to make it easy to distinguish the symbolic types or expressions from real-valued types or scalars.) This can be done once up front (potentially even as `static` variables) to minimize the overhead associated with creating these variables. For the ultimate in generic programming, we can even describe the constitutive parameters symbolically, *potentially* allowing a single class instance to be reused with different inputs for these values too.
//
// These are the symbolic scalars that represent the elastic, viscous, and magnetic material parameters (defined mostly in the same order as they appear in the  [2.x.5374]  class). We also store a symbolic expression,  [2.x.5375]  that represents the time step size):
//
[0.x.43294] 
[0.x.43295] 
[0.x.43296] 
[0.x.43297] 
[0.x.43298] 
[0.x.43299] 
[0.x.43300] 
[0.x.43301] 
[0.x.43302] 
[0.x.43303] 
//
// Next we define some tensorial symbolic variables that represent the independent field variables, upon which the energy density function is parameterized:
//
[0.x.43304] 
[0.x.43305] 
//
// And similarly we have the symbolic representation of the internal viscous variables (both its current value and its value at the previous timestep):
//
[0.x.43306] 
[0.x.43307] 
//
// We should also store the definitions of the dependent expressions: Although we'll only compute them once, we require them to retrieve data from the  [2.x.5376]  that is declared below. Furthermore, when serializing a material class like this one (not done as a part of this tutorial) we'd either need to serialize these expressions as well or we'd need to reconstruct them upon reloading.
//
[0.x.43308] 
[0.x.43309] 
[0.x.43310] 
[0.x.43311] 
[0.x.43312] 
[0.x.43313] 
//
// The next variable is then the optimizer that is used to evaluate the dependent functions. More specifically, it provides the possibility to accelerate the evaluation of the symbolic dependent expressions. This is a vital tool, because the native evaluation of lengthy expressions (using no method of acceleration, but rather direct evaluation directly of the symbolic expressions) can be very slow. The  [2.x.5377]  class provides a mechanism by which to transform the symbolic expression tree into another code path that, for example, shares intermediate results between the various dependent expressions (meaning that these intermediate values only get calculated once per evaluation) and/or compiling the code using a just-in-time compiler (thereby retrieving near-native performance for the evaluation step).
//
// Performing this code transformation is very computationally expensive, so we store the optimizer so that it is done just once per class instance. This also further motivates the decision to make the constitutive parameters themselves symbolic. We could then reuse a single instance of this  [2.x.5378]  across several materials (with the same energy function, of course) and potentially multiple continuum points (if embedded within a finite element simulation).
//
// As specified by the template parameter, the numerical result will be of type <tt>double</tt>.
//
[0.x.43314] 
//
// During the evaluation phase, we must map the symbolic variables to their real-valued counterparts. The next method will provide this functionality.
//
// The final method of this class will configure the  [2.x.5379] 
[0.x.43315] 
[0.x.43316] 
[0.x.43317] 
[0.x.43318] 
//
[0.x.43319] 
[0.x.43320] 
//
// As the resting deformation state is one at which the material is considered to be completely relaxed, the internal viscous variables are initialized with the identity tensor, i.e.  [2.x.5380] . The various symbolic variables representing the constitutive parameters, time step size, and field and internal variables all get a unique identifier. The optimizer is passed the two parameters that declare which optimization (acceleration) technique should be applied, as well as which additional steps should be taken by the CAS to help improve performance during evaluation.
//
[0.x.43321] 
[0.x.43322] 
[0.x.43323] 
[0.x.43324] 
[0.x.43325] 
[0.x.43326] 
[0.x.43327] 
[0.x.43328] 
[0.x.43329] 
[0.x.43330] 
[0.x.43331] 
[0.x.43332] 
[0.x.43333] 
[0.x.43334] 
[0.x.43335] 
[0.x.43336] 
[0.x.43337] 
[0.x.43338] 
[0.x.43339] 
[0.x.43340] 
[0.x.43341] 
[0.x.43342] 
[0.x.43343] 
[0.x.43344] 
[0.x.43345] 
[0.x.43346] 
[0.x.43347] 
[0.x.43348] 
[0.x.43349] 
[0.x.43350] 
//
// The substitution map simply pairs all of the following data together:
//
// - the constitutive parameters (with values retrieved from the base class),
//
// - the time step size (with its value retrieved from the time discretizer),
//
// - the field values (with their values being prescribed by an external   function that is calling into this  [2.x.5381]  instance), and
//
// - the current and previous internal viscous deformation (with their values   stored within this class instance).
//
[0.x.43351] 
[0.x.43352] 
[0.x.43353] 
[0.x.43354] 
[0.x.43355] 
[0.x.43356] 
[0.x.43357] 
[0.x.43358] 
[0.x.43359] 
[0.x.43360] 
[0.x.43361] 
[0.x.43362] 
[0.x.43363] 
[0.x.43364] 
[0.x.43365] 
[0.x.43366] 
[0.x.43367] 
[0.x.43368] 
[0.x.43369] 
[0.x.43370] 
[0.x.43371] 
[0.x.43372] 
[0.x.43373] 
//
// Due to the "natural" use of the symbolic expressions, much of the procedure to configure the  [2.x.5382]  looks very similar to that which is used to construct the automatic differentiation helper. Nevertheless, we'll detail these steps again to highlight the differences that underlie the two frameworks.
//
// The function starts with expressions that symbolically encode the determinant of the deformation gradient (as expressed in terms of the right Cauchy-Green deformation tensor, our primary field variable), as well as the inverse of  [2.x.5383]  itself:
//
[0.x.43374] 
[0.x.43375] 
[0.x.43376] 
[0.x.43377] 
[0.x.43378] 
[0.x.43379] 
[0.x.43380] 
//
// Next is the symbolic representation of the saturation function for the elastic part of the free energy density function, followed by the magnetoelastic contribution to the free energy density function. This all has the same structure as we'd seen previously.
//
[0.x.43381] 
[0.x.43382] 
[0.x.43383] 
[0.x.43384] 
//
[0.x.43385] 
[0.x.43386] 
[0.x.43387] 
[0.x.43388] 
[0.x.43389] 
//
// In addition, we define the magneto-viscoelastic contribution to the free energy density function. The first component required to implement this is a scaling function that will cause the viscous shear modulus to change (increase) under the influence of a magnetic field (see  [2.x.5384] , equation 29). Thereafter we can compute the dissipative component of the energy density function; its expression is stated in  [2.x.5385]  (equation 28), which is a straight-forward extension of an energy density function formulated in  [2.x.5386]  (equation 46).
//
[0.x.43390] 
[0.x.43391] 
[0.x.43392] 
[0.x.43393] 
//
[0.x.43394] 
[0.x.43395] 
[0.x.43396] 
[0.x.43397] 
//
// From these building blocks, we can then define the material's total free energy density function:
//
[0.x.43398] 
//
// As it stands, to the CAS the variable  [2.x.5387]  appears to be independent of  [2.x.5388]  Our tensorial symbolic expression  [2.x.5389]  just has an identifier associated with it, and there is nothing that links it to the other tensorial symbolic expression  [2.x.5390]  So any derivatives taken with respect to  [2.x.5391]  will ignore this inherent dependence which, as we can see from the evolution law, is in fact  [2.x.5392] . This means that deriving any function  [2.x.5393]  with respect to   [2.x.5394]  will return partial derivatives  [2.x.5395]  as opposed to the total derivative  [2.x.5396] .
//
// By contrast, with the current AD libraries the total derivative would always be returned. This implies that the computed kinetic variables would be incorrect for this class of material model, making AD the incorrect tool from which to derive (at the continuum point level) the constitutive law for this dissipative material from an energy density function.
//
// It is this specific level of control that characterizes a defining difference difference between the SD and AD frameworks. In a few lines we'll be manipulating the expression for the internal variable  [2.x.5397]  such that it produces the correct linearization.
//
// But, first, we'll compute the symbolic expressions for the kinetic variables, i.e., the magnetic induction vector and the Piola-Kirchhoff stress tensor. The code that performs the differentiation quite closely mimics the definition stated in the theory.
//
[0.x.43399] 
[0.x.43400] 
//
// Since the next step is to linearize the above, it is the appropriate time to inform the CAS of the explicit dependency of  [2.x.5398]  on  [2.x.5399]  i.e., state that  [2.x.5400] . This means that all future differential operations made with respect to  [2.x.5401]  will take into account this dependence (i.e., compute total derivatives). In other words, we will transform some expression such that their intrinsic parameterization changes from  [2.x.5402]  to  [2.x.5403] .
//
// To do this, we consider the time-discrete evolution law. From that, we have the explicit expression for the internal variable in terms of its history as well as the primary field variable. That is what it described in this expression:
//
[0.x.43401] 
[0.x.43402] 
[0.x.43403] 
[0.x.43404] 
[0.x.43405] 
//
// Next we produce an intermediate substitution map, which will take every instance of  [2.x.5404]  (our identifier) found in an expression and replace it with the full expression held in  [2.x.5405] 
[0.x.43406] 
[0.x.43407] 
[0.x.43408] 
//
// We can the perform this substitution on the two kinetic variables and immediately differentiate the result that appears after that substitution with the field variables. (If you'd like, this could be split up into two steps with the intermediate results stored in a temporary variable.) Again, if you overlook the "complexity" generated by the substitution, these calls that linearize the kinetic variables and produce the three tangent tensors quite closely resembles what's stated in the theory.
//
[0.x.43409] 
[0.x.43410] 
[0.x.43411] 
[0.x.43412] 
[0.x.43413] 
[0.x.43414] 
[0.x.43415] 
[0.x.43416] 
[0.x.43417] 
[0.x.43418] 
//
// Now we need to tell the  [2.x.5406]  what entries we need to provide numerical values for in order for it to successfully perform its calculations. These essentially act as the input arguments to all dependent functions that the  [2.x.5407]  must evaluate. They are, collectively, the independent variables for the problem, the history variables, the time step sie and the constitutive parameters (since we've not hard encoded them in the energy density function).
//
// So what we really want is to provide it a collection of symbols, which one could accomplish in this way: [1.x.183] But this is all actually already encoded as the keys of the substitution map. Doing the above would also mean that we need to manage the symbols in two places (here and when constructing the substitution map), which is annoying and a potential source of error if this material class is modified or extended. Since we're not interested in the values at this point, it is alright if the substitution map is filled with invalid data for the values associated with each key entry. So we'll simply create a fake substitution map, and extract the symbols from that. Note that any substitution map passed to the  [2.x.5408]  will have to, at the very least, contain entries for these symbols.
//
[0.x.43419] 
[0.x.43420] 
[0.x.43421] 
//
// We then inform the optimizer of what values we want calculated, which in our situation encompasses all of the dependent variables (namely the energy density function and its various derivatives).
//
[0.x.43422] 
//
// The last step is to finalize the optimizer. With this call it will determine an equivalent code path that will evaluate all of the dependent functions at once, but with less computational cost than when evaluating the symbolic expression directly. Note: This is an expensive call, so we want execute it as few times as possible. We've done it in the constructor of our class, which achieves the goal of being called only once per class instance.
//
[0.x.43423] 
[0.x.43424] 
//
// Since the configuration of the  [2.x.5409]  was done up front, there's very little to do each time we want to compute kinetic variables or their linearization (derivatives).
//
[0.x.43425] 
[0.x.43426] 
[0.x.43427] 
[0.x.43428] 
[0.x.43429] 
[0.x.43430] 
//
// To update the internal history variable, we first need to compute a few fundamental quantities, which we've seen before. We can also ask the time discretizer for the time step size that was used to iterate from the previous time step to the current one.
//
[0.x.43431] 
//
[0.x.43432] 
[0.x.43433] 
[0.x.43434] 
[0.x.43435] 
//
// Now we can update the (real valued) internal viscous deformation tensor, as per the definition given by the evolution law in conjunction with the chosen time discretization scheme.
//
[0.x.43436] 
[0.x.43437] 
[0.x.43438] 
//
// Next we pass the optimizer the numeric values that we wish the independent variables, time step size and (implicit to this call), the constitutive parameters to represent.
//
[0.x.43439] 
//
// When making this next call, the call path used to (numerically) evaluate the dependent functions is quicker than dictionary substitution.
//
[0.x.43440] 
[0.x.43441] 
//
// Having called `update_internal_data()`, it is then valid to extract data from the optimizer. When doing the evaluation, we need the exact symbolic expressions of the data to extracted from the optimizer. The implication of this is that we needed to store the symbolic expressions of all dependent variables for the lifetime of the optimizer (naturally, the same is implied for the input variables).
//
[0.x.43442] 
[0.x.43443] 
[0.x.43444] 
[0.x.43445] 
[0.x.43446] 
//
[0.x.43447] 
[0.x.43448] 
[0.x.43449] 
[0.x.43450] 
[0.x.43451] 
//
[0.x.43452] 
[0.x.43453] 
[0.x.43454] 
[0.x.43455] 
[0.x.43456] 
[0.x.43457] 
//
[0.x.43458] 
[0.x.43459] 
[0.x.43460] 
[0.x.43461] 
[0.x.43462] 
[0.x.43463] 
//
[0.x.43464] 
[0.x.43465] 
[0.x.43466] 
[0.x.43467] 
[0.x.43468] 
//
[0.x.43469] 
[0.x.43470] 
[0.x.43471] 
[0.x.43472] 
[0.x.43473] 
[0.x.43474] 
//
// When moving forward in time, the "current" state of the internal variable instantaneously defines the state at the "previous" timestep. As such, we record value of history variable for use as the "past value" at the next time step.
//
[0.x.43475] 
[0.x.43476] 
[0.x.43477] 
[0.x.43478] 
[0.x.43479] 
//[2.x.5410] 
//
// Now that we've seen how the AD and SD frameworks can make light(er) work of defining these constitutive laws, we'll implement the equivalent classes by hand for the purpose of verification and to do some preliminary benchmarking of the frameworks versus a native implementation.
//
// At the expense of the author's sanity, what is documented below (hopefully accurately) are the full definitions for the kinetic variables and their tangents, as well as some intermediate computations. Since the structure and design of the constitutive law classes has been outlined earlier, we'll gloss over it and simply delineate between the various stages of calculations in the `update_internal_data()` method definition. It should be easy enough to link the derivative calculations (with their moderately expressive variable names) to their documented definitions that appear in the class descriptions. We will, however, take the opportunity to present two different paradigms for implementing constitutive law classes. The second will provide more flexibility than the first (thereby making it more easily extensible, in the author's opinion) at the expense of some performance.
//
//  [2.x.5411] 
//
// From the stored energy that, as mentioned earlier, is defined as [1.x.184] with [1.x.185] for this magnetoelastic material, the first derivatives that correspond to the magnetic induction vector and total Piola-Kirchhoff stress tensor are [1.x.186] 
//[1.x.187] with [1.x.188] 
//[1.x.189] 
//[1.x.190] 
//[1.x.191] 
//[1.x.192] The use of the symmetry operator  [2.x.5412]  in the one derivation above helps to ensure that the resulting rank-4 tensor, which holds minor symmetries due to the symmetry of  [2.x.5413] , still maps rank-2 symmetric tensors to rank-2 symmetric tensors. See the SymmetricTensor class documentation and the introduction to  [2.x.5414]  and for further explanation as to what symmetry means in the context of fourth-order tensors.
//
// The linearization of each of the kinematic variables with respect to their arguments are [1.x.193] 
//[1.x.194] 
//[1.x.195] with [1.x.196] 
//[1.x.197] 
//[1.x.198] 
//[1.x.199]
//
// Well, that escalated quickly -- although the the definition of  [2.x.5415]  and  [2.x.5416]  might have given some hints that the calculating the kinetic fields and their linearization would take some effort, it is likely that there's a little more complexity to the final definitions that perhaps initially thought. Knowing what we now do, it's probably fair to say that we really do not want to compute first and second derivatives of these functions with respect to their arguments -- regardless of well we did in calculus classes, or how good a programmer we may be.
//
// In the class method definition where these are ultimately implemented, we've composed these calculations slightly differently. Some intermediate steps are also retained to give another perspective of how to systematically compute the derivatives. Additionally, some calculations are decomposed less or further to reuse some of the intermediate values and, hopefully, aid the reader to follow the derivative operations.
//
[0.x.43480] 
[0.x.43481] 
[0.x.43482] 
[0.x.43483] 
[0.x.43484] 
[0.x.43485] 
[0.x.43486] 
//
[0.x.43487] 
[0.x.43488] 
[0.x.43489] 
//
[0.x.43490] 
//
[0.x.43491] 
//
[0.x.43492] 
//
[0.x.43493] 
//
[0.x.43494] 
//
[0.x.43495] 
//
[0.x.43496] 
[0.x.43497] 
[0.x.43498] 
[0.x.43499] 
[0.x.43500] 
[0.x.43501] 
[0.x.43502] 
[0.x.43503] 
//
[0.x.43504] 
[0.x.43505] 
[0.x.43506] 
[0.x.43507] 
[0.x.43508] 
[0.x.43509] 
[0.x.43510] 
//
// For this class's update method, we'll simply precompute a collection of intermediate values (for function evaluations, derivative calculations, and the like) and "manually" arrange them in the order that's required to maximize their reuse. This means that we have to manage this ourselves, and decide what values must be compute before others, all while keeping some semblance of order or structure in the code itself. It's effective, but perhaps a little tedious. It also doesn't do too much to help future extension of the class, because all of these values remain local to this single method.
//
// Interestingly, this basic technique of precomputing intermediate expressions that are used in more than one place has a name: [common subexpression elimination (CSE)](https:en.wikipedia.org/wiki/Common_subexpression_elimination). It is a strategy used by Computer Algebra Systems to reduce the computational expense when they are tasked with evaluating similar expressions.
//
[0.x.43511] 
[0.x.43512] 
[0.x.43513] 
[0.x.43514] 
[0.x.43515] 
[0.x.43516] 
[0.x.43517] 
[0.x.43518] 
[0.x.43519] 
[0.x.43520] 
//
// The saturation function for the magneto-elastic energy.
//
[0.x.43521] 
[0.x.43522] 
[0.x.43523] 
[0.x.43524] 
//
[0.x.43525] 
[0.x.43526] 
[0.x.43527] 
//
// The first derivative of the saturation function, noting that  [2.x.5417] .
//
[0.x.43528] 
[0.x.43529] 
[0.x.43530] 
[0.x.43531] 
//
[0.x.43532] 
[0.x.43533] 
[0.x.43534] 
//
// The second derivative of saturation function, noting that  [2.x.5418] .
//
[0.x.43535] 
[0.x.43536] 
[0.x.43537] 
[0.x.43538] 
[0.x.43539] 
//
[0.x.43540] 
[0.x.43541] 
[0.x.43542] 
[0.x.43543] 
[0.x.43544] 
[0.x.43545] 
//
// Some intermediate quantities attained directly from the field / kinematic variables.
//
[0.x.43546] 
[0.x.43547] 
[0.x.43548] 
[0.x.43549] 
//
// First derivatives of the intermediate quantities.
//
[0.x.43550] 
[0.x.43551] 
[0.x.43552] 
[0.x.43553] 
//
[0.x.43554] 
//
[0.x.43555] 
[0.x.43556] 
[0.x.43557] 
[0.x.43558] 
[0.x.43559] 
[0.x.43560] 
[0.x.43561] 
[0.x.43562] 
//
[0.x.43563] 
[0.x.43564] 
//
// Second derivatives of the intermediate quantities.
//
[0.x.43565] 
//
[0.x.43566] 
[0.x.43567] 
//
[0.x.43568] 
//
[0.x.43569] 
[0.x.43570] 
[0.x.43571] 
[0.x.43572] 
[0.x.43573] 
[0.x.43574] 
[0.x.43575] 
//
[0.x.43576] 
[0.x.43577] 
[0.x.43578] 
[0.x.43579] 
[0.x.43580] 
[0.x.43581] 
[0.x.43582] 
[0.x.43583] 
[0.x.43584] 
[0.x.43585] 
//
// The stored energy density function.
//
[0.x.43586] 
[0.x.43587] 
[0.x.43588] 
[0.x.43589] 
[0.x.43590] 
//
// The kinetic quantities.
//
[0.x.43591] 
[0.x.43592] 
[0.x.43593] 
[0.x.43594] 
//
[0.x.43595] 
[0.x.43596] 
[0.x.43597] 
[0.x.43598] 
[0.x.43599] 
[0.x.43600] 
//
// The linearization of the kinetic quantities.
//
[0.x.43601] 
[0.x.43602] 
[0.x.43603] 
[0.x.43604] 
//
[0.x.43605] 
[0.x.43606] 
[0.x.43607] 
[0.x.43608] 
[0.x.43609] 
[0.x.43610] 
[0.x.43611] 
//
[0.x.43612] 
[0.x.43613] 
[0.x.43614] 
[0.x.43615] 
[0.x.43616] 
[0.x.43617] 
[0.x.43618] 
[0.x.43619] 
[0.x.43620] 
[0.x.43621] 
[0.x.43622] 
//
[0.x.43623] 
[0.x.43624] 
[0.x.43625] 
[0.x.43626] 
[0.x.43627] 
//
[0.x.43628] 
[0.x.43629] 
[0.x.43630] 
[0.x.43631] 
[0.x.43632] 
//
[0.x.43633] 
[0.x.43634] 
[0.x.43635] 
[0.x.43636] 
[0.x.43637] 
//
[0.x.43638] 
[0.x.43639] 
[0.x.43640] 
[0.x.43641] 
[0.x.43642] 
//
[0.x.43643] 
[0.x.43644] 
[0.x.43645] 
[0.x.43646] 
[0.x.43647] 
//
[0.x.43648] 
[0.x.43649] 
[0.x.43650] 
[0.x.43651] 
[0.x.43652] 
//[2.x.5419] 
//
// As mentioned before, the free energy density function for the magneto-viscoelastic material with one dissipative mechanism that we'll be considering is defined as [1.x.200] 
//[1.x.201] 
//[1.x.202] with [1.x.203] 
//[1.x.204] and the evolution law [1.x.205] that itself is parameterized in terms of  [2.x.5420] . By design, the magnetoelastic part of the energy  [2.x.5421]  is identical to that of the magnetoelastic material presented earlier. So, for the derivatives of the various contributions stemming from this part of the energy, please refer to the previous section. We'll continue to highlight the specific contributions from those terms by superscripting the salient terms with  [2.x.5422] , while contributions from the magneto-viscoelastic component are superscripted with  [2.x.5423] . Furthermore, the magnetic saturation function  [2.x.5424]  for the damping term has the identical form as that of the elastic term (i.e.,  [2.x.5425]  ), and so the structure of its derivatives are identical to that seen before; the only change is for the three constitutive parameters that are now associated with the viscous shear modulus  [2.x.5426]  rather than the elastic shear modulus  [2.x.5427] .
//
// For this magneto-viscoelastic material, the first derivatives that correspond to the magnetic induction vector and total Piola-Kirchhoff stress tensor are [1.x.206] 
//[1.x.207] with the viscous contributions being [1.x.208] 
//[1.x.209] and with [1.x.210] The time-discretized evolution law, [1.x.211] will also dictate how the linearization of the internal variable with respect to the field variables is composed.
//
// Observe that in order to attain the *correct* expressions for the magnetic induction vector and total Piola-Kirchhoff stress tensor for this dissipative material, we must adhere strictly to the outcome of applying the Coleman-Noll procedure: we must take *partial derivatives*
// of the free energy density function with respect to the field variables. (For our non-dissipative magnetoelastic material, taking either partial or total derivatives would have had the same result, so there was no need to draw your attention to this before.) The crucial part of the operation is to freeze the internal variable  [2.x.5428]  while computing the derivatives of  [2.x.5429]  with respect to  [2.x.5430]  -- the dependence of  [2.x.5431]  on  [2.x.5432]  is not to be taken into account. When deciding whether to use AD or SD to perform this task the choice is clear -- only the symbolic framework provides a mechanism to do this; as was mentioned before, AD can only return total derivatives so it is unsuitable for the task.
//
// To wrap things up, we'll present the material tangents for this rate-dependent coupled material. The linearization of both kinetic variables with respect to their arguments are [1.x.212] 
//[1.x.213] 
//[1.x.214] where the tangents for the viscous contributions are [1.x.215] 
//[1.x.216] 
//[1.x.217] with [1.x.218] and, from the evolution law, [1.x.219] Notice that just the last term of  [2.x.5433]  contains the tangent of the internal variable. The linearization of this particular evolution law is linear. For an example of a nonlinear evolution law, for which this linearization must be solved for in an iterative manner, see  [2.x.5434] -Theiss2011a.
//
[0.x.43653] 
[0.x.43654] 
[0.x.43655] 
[0.x.43656] 
[0.x.43657] 
[0.x.43658] 
[0.x.43659] 
//
[0.x.43660] 
[0.x.43661] 
[0.x.43662] 
//
[0.x.43663] 
//
[0.x.43664] 
//
[0.x.43665] 
//
[0.x.43666] 
//
[0.x.43667] 
//
[0.x.43668] 
//
[0.x.43669] 
//
[0.x.43670] 
[0.x.43671] 
[0.x.43672] 
//
[0.x.43673] 
[0.x.43674] 
[0.x.43675] 
[0.x.43676] 
[0.x.43677] 
[0.x.43678] 
//
// A data structure that is used to store all intermediate calculations. We'll see shortly precisely how this can be leveraged to make the part of the code where we actually perform calculations clean and easy (well, at least easier) to follow and maintain. But for now, we can say that it will allow us to move the parts of the code where we compute the derivatives of intermediate quantities away from where they are used.
//
[0.x.43679] 
//
// The next two functions are used to update the state of the field and internal variables, and will be called before we perform any detailed calculations.
//
[0.x.43680] 
[0.x.43681] 
//
[0.x.43682] 
//
// The remainder of the class interface is dedicated to methods that are used to compute the components required to calculate the free energy density function, and all of its derivatives:
//
// The kinematic, or field, variables.
//
[0.x.43683] 
//
[0.x.43684] 
//
// A generalized formulation for the saturation function, with the required constitutive parameters passed as arguments to each function.
//
[0.x.43685] 
//
[0.x.43686] 
//
[0.x.43687] 
[0.x.43688] 
[0.x.43689] 
//
// A generalized formulation for the first derivative of saturation function, with the required constitutive parameters passed as arguments to each function.
//
[0.x.43690] 
//
[0.x.43691] 
[0.x.43692] 
//
[0.x.43693] 
[0.x.43694] 
[0.x.43695] 
//
// A generalized formulation for the second derivative of saturation function, with the required constitutive parameters passed as arguments to each function.
//
[0.x.43696] 
//
[0.x.43697] 
[0.x.43698] 
//
[0.x.43699] 
[0.x.43700] 
[0.x.43701] 
//
// Intermediate quantities attained directly from the field / kinematic variables.
//
[0.x.43702] 
//
[0.x.43703] 
//
[0.x.43704] 
//
[0.x.43705] 
//
[0.x.43706] 
//
[0.x.43707] 
//
// First derivatives of the intermediate quantities.
//
[0.x.43708] 
//
[0.x.43709] 
//
[0.x.43710] 
//
[0.x.43711] 
//
[0.x.43712] 
//
[0.x.43713] 
//
// Derivative of internal variable with respect to field variables. Notice that we only need this one derivative of the internal variable, as this variable is only differentiated as part of the linearization of the kinetic variables.
//
[0.x.43714] 
[0.x.43715] 
//
// Second derivatives of the intermediate quantities.
//
[0.x.43716] 
//
[0.x.43717] 
//
[0.x.43718] 
//
[0.x.43719] 
//
[0.x.43720] 
[0.x.43721] 
//
[0.x.43722] 
[0.x.43723] 
[0.x.43724] 
[0.x.43725] 
[0.x.43726] 
[0.x.43727] 
[0.x.43728] 
[0.x.43729] 
[0.x.43730] 
[0.x.43731] 
//
[0.x.43732] 
[0.x.43733] 
[0.x.43734] 
[0.x.43735] 
[0.x.43736] 
[0.x.43737] 
//
// Record the applied deformation state as well as the magnetic load. Thereafter, update internal (viscous) variable based on new deformation state.
//
[0.x.43738] 
[0.x.43739] 
//
// Get the values for the elastic and viscous saturation function based on the current magnetic field...
//
[0.x.43740] 
[0.x.43741] 
[0.x.43742] 
//
[0.x.43743] 
[0.x.43744] 
[0.x.43745] 
//
// ... as well as their first derivatives...
//
[0.x.43746] 
[0.x.43747] 
[0.x.43748] 
//
[0.x.43749] 
[0.x.43750] 
[0.x.43751] 
//
// ... and their second derivatives.
//
[0.x.43752] 
[0.x.43753] 
[0.x.43754] 
[0.x.43755] 
//
[0.x.43756] 
[0.x.43757] 
[0.x.43758] 
[0.x.43759] 
//
// Intermediate quantities. Note that, since we're fetching these values from a cache that has a lifetime that outlasts this function call, we can alias the result rather than copying the value from the cache.
//
[0.x.43760] 
[0.x.43761] 
//
[0.x.43762] 
[0.x.43763] 
[0.x.43764] 
//
// First derivatives of intermediate values, as well as the that of the internal variable with respect to the right Cauchy-Green deformation tensor.
//
[0.x.43765] 
[0.x.43766] 
[0.x.43767] 
//
[0.x.43768] 
//
[0.x.43769] 
//
[0.x.43770] 
[0.x.43771] 
//
// Second derivatives of intermediate values.
//
[0.x.43772] 
[0.x.43773] 
//
[0.x.43774] 
//
[0.x.43775] 
[0.x.43776] 
//
[0.x.43777] 
[0.x.43778] 
//
[0.x.43779] 
[0.x.43780] 
//
// Since the definitions of the linearizations become particularly lengthy, we'll decompose the free energy density function into three additive components:
//
// - the "Neo-Hookean"-like term,
//
// - the rate-dependent term, and
//
// - the term that resembles that of the energy stored in the magnetic field.
//
// To remain consistent, each of these contributions will be individually added to the variables that we want to compute in that same order.
//
// So, first of all this is the energy density function itself:
//
[0.x.43781] 
[0.x.43782] 
[0.x.43783] 
[0.x.43784] 
[0.x.43785] 
[0.x.43786] 
[0.x.43787] 
[0.x.43788] 
//
// ... followed by the magnetic induction vector and Piola-Kirchhoff stress:
//
[0.x.43789] 
[0.x.43790] 
[0.x.43791] 
[0.x.43792] 
[0.x.43793] 
[0.x.43794] 
[0.x.43795] 
[0.x.43796] 
//
[0.x.43797] 
[0.x.43798] 
[0.x.43799] 
[0.x.43800] 
[0.x.43801] 
[0.x.43802] 
[0.x.43803] 
[0.x.43804] 
[0.x.43805] 
[0.x.43806] 
//
// ... and lastly the tangents due to the linearization of the kinetic variables.
//
[0.x.43807] 
[0.x.43808] 
[0.x.43809] 
[0.x.43810] 
[0.x.43811] 
[0.x.43812] 
[0.x.43813] 
[0.x.43814] 
//
[0.x.43815] 
[0.x.43816] 
[0.x.43817] 
[0.x.43818] 
[0.x.43819] 
[0.x.43820] 
[0.x.43821] 
[0.x.43822] 
[0.x.43823] 
[0.x.43824] 
[0.x.43825] 
[0.x.43826] 
[0.x.43827] 
//
[0.x.43828] 
[0.x.43829] 
[0.x.43830] 
[0.x.43831] 
[0.x.43832] 
[0.x.43833] 
[0.x.43834] 
[0.x.43835] 
[0.x.43836] 
[0.x.43837] 
[0.x.43838] 
[0.x.43839] 
[0.x.43840] 
[0.x.43841] 
[0.x.43842] 
[0.x.43843] 
[0.x.43844] 
[0.x.43845] 
[0.x.43846] 
[0.x.43847] 
[0.x.43848] 
[0.x.43849] 
[0.x.43850] 
[0.x.43851] 
//
// Now that we're done using all of those temporary variables stored in our cache, we can clear it out to free up some memory.
//
[0.x.43852] 
[0.x.43853] 
//
[0.x.43854] 
[0.x.43855] 
[0.x.43856] 
[0.x.43857] 
[0.x.43858] 
//
[0.x.43859] 
[0.x.43860] 
[0.x.43861] 
[0.x.43862] 
[0.x.43863] 
//
[0.x.43864] 
[0.x.43865] 
[0.x.43866] 
[0.x.43867] 
[0.x.43868] 
[0.x.43869] 
//
[0.x.43870] 
[0.x.43871] 
[0.x.43872] 
[0.x.43873] 
[0.x.43874] 
[0.x.43875] 
//
[0.x.43876] 
[0.x.43877] 
[0.x.43878] 
[0.x.43879] 
[0.x.43880] 
//
[0.x.43881] 
[0.x.43882] 
[0.x.43883] 
[0.x.43884] 
[0.x.43885] 
[0.x.43886] 
//
[0.x.43887] 
[0.x.43888] 
[0.x.43889] 
[0.x.43890] 
[0.x.43891] 
//
[0.x.43892] 
[0.x.43893] 
[0.x.43894] 
[0.x.43895] 
[0.x.43896] 
//
[0.x.43897] 
[0.x.43898] 
[0.x.43899] 
[0.x.43900] 
//
// The next few functions implement the generalized formulation for the saturation function, as well as its various derivatives.
//
[0.x.43901] 
[0.x.43902] 
[0.x.43903] 
[0.x.43904] 
[0.x.43905] 
[0.x.43906] 
[0.x.43907] 
[0.x.43908] 
//
[0.x.43909] 
[0.x.43910] 
[0.x.43911] 
[0.x.43912] 
[0.x.43913] 
[0.x.43914] 
//
// A scaling function that will cause the shear modulus to change (increase) under the influence of a magnetic field.
//
[0.x.43915] 
[0.x.43916] 
[0.x.43917] 
[0.x.43918] 
[0.x.43919] 
[0.x.43920] 
[0.x.43921] 
[0.x.43922] 
[0.x.43923] 
//
// First derivative of scaling function
//
[0.x.43924] 
[0.x.43925] 
[0.x.43926] 
[0.x.43927] 
[0.x.43928] 
[0.x.43929] 
[0.x.43930] 
//
[0.x.43931] 
[0.x.43932] 
[0.x.43933] 
[0.x.43934] 
[0.x.43935] 
[0.x.43936] 
//
[0.x.43937] 
[0.x.43938] 
[0.x.43939] 
[0.x.43940] 
[0.x.43941] 
[0.x.43942] 
[0.x.43943] 
[0.x.43944] 
[0.x.43945] 
[0.x.43946] 
//
[0.x.43947] 
[0.x.43948] 
[0.x.43949] 
[0.x.43950] 
[0.x.43951] 
[0.x.43952] 
[0.x.43953] 
//
[0.x.43954] 
[0.x.43955] 
[0.x.43956] 
[0.x.43957] 
[0.x.43958] 
[0.x.43959] 
[0.x.43960] 
//
[0.x.43961] 
[0.x.43962] 
[0.x.43963] 
[0.x.43964] 
[0.x.43965] 
[0.x.43966] 
[0.x.43967] 
[0.x.43968] 
[0.x.43969] 
[0.x.43970] 
[0.x.43971] 
[0.x.43972] 
[0.x.43973] 
[0.x.43974] 
[0.x.43975] 
//
// For the cached calculation approach that we've adopted for this material class, the root of all calculations are the field variables, and the immutable ancillary data such as the constitutive parameters and time step size. As such, we need to enter them into the cache in a different manner to the other variables, since they are inputs that are prescribed from outside the class itself. This function simply adds them to the cache directly from the input arguments, checking that there is no equivalent data there in the first place (we expect to call the `update_internal_data()` method only once per time step, or Newton iteration).
//
[0.x.43976] 
[0.x.43977] 
[0.x.43978] 
[0.x.43979] 
[0.x.43980] 
//
// Set value for  [2.x.5435] .
//
[0.x.43981] 
[0.x.43982] 
[0.x.43983] 
[0.x.43984] 
[0.x.43985] 
//
// Set value for  [2.x.5436] .
//
[0.x.43986] 
[0.x.43987] 
[0.x.43988] 
[0.x.43989] 
[0.x.43990] 
[0.x.43991] 
//
// After that, we can fetch them from the cache at any point in time.
//
[0.x.43992] 
[0.x.43993] 
[0.x.43994] 
[0.x.43995] 
[0.x.43996] 
[0.x.43997] 
[0.x.43998] 
[0.x.43999] 
[0.x.44000] 
//
[0.x.44001] 
[0.x.44002] 
[0.x.44003] 
[0.x.44004] 
[0.x.44005] 
[0.x.44006] 
[0.x.44007] 
[0.x.44008] 
[0.x.44009] 
//
// With the primary variables guaranteed to be in the cache when we need them, we can not compute all intermediate values (either directly, or indirectly) from them.
//
// If the cache does not already store the value that we're looking for, then we quickly calculate it, store it in the cache and return the value just stored in the cache. That way we can return it as a reference and avoid copying the object. The same goes for any values that a compound function might depend on. Said another way, if there is a dependency chain of calculations that come before the one that we're currently interested in doing, then we're guaranteed to resolve the dependencies before we proceed with using any of those values. Although there is a cost to fetching data from the cache, the "resolved dependency" concept might be sufficiently convenient to make it worth looking past the extra cost. If these material laws are embedded within a finite element framework, then the added cost might not even be noticeable.
//
[0.x.44010] 
[0.x.44011] 
[0.x.44012] 
[0.x.44013] 
[0.x.44014] 
[0.x.44015] 
[0.x.44016] 
[0.x.44017] 
[0.x.44018] 
[0.x.44019] 
[0.x.44020] 
//
[0.x.44021] 
[0.x.44022] 
//
[0.x.44023] 
[0.x.44024] 
[0.x.44025] 
[0.x.44026] 
[0.x.44027] 
[0.x.44028] 
[0.x.44029] 
[0.x.44030] 
[0.x.44031] 
//
[0.x.44032] 
[0.x.44033] 
//
[0.x.44034] 
[0.x.44035] 
[0.x.44036] 
[0.x.44037] 
[0.x.44038] 
[0.x.44039] 
[0.x.44040] 
//
[0.x.44041] 
[0.x.44042] 
//
[0.x.44043] 
[0.x.44044] 
[0.x.44045] 
[0.x.44046] 
[0.x.44047] 
[0.x.44048] 
//
[0.x.44049] 
[0.x.44050] 
//
[0.x.44051] 
[0.x.44052] 
[0.x.44053] 
[0.x.44054] 
[0.x.44055] 
[0.x.44056] 
[0.x.44057] 
//
[0.x.44058] 
[0.x.44059] 
//
[0.x.44060] 
[0.x.44061] 
[0.x.44062] 
[0.x.44063] 
[0.x.44064] 
[0.x.44065] 
[0.x.44066] 
//
[0.x.44067] 
[0.x.44068] 
//
[0.x.44069] 
[0.x.44070] 
[0.x.44071] 
[0.x.44072] 
[0.x.44073] 
[0.x.44074] 
[0.x.44075] 
[0.x.44076] 
[0.x.44077] 
[0.x.44078] 
//
[0.x.44079] 
[0.x.44080] 
[0.x.44081] 
[0.x.44082] 
[0.x.44083] 
[0.x.44084] 
//
[0.x.44085] 
[0.x.44086] 
//
[0.x.44087] 
[0.x.44088] 
//
[0.x.44089] 
[0.x.44090] 
[0.x.44091] 
[0.x.44092] 
[0.x.44093] 
[0.x.44094] 
[0.x.44095] 
[0.x.44096] 
[0.x.44097] 
//
[0.x.44098] 
[0.x.44099] 
[0.x.44100] 
[0.x.44101] 
[0.x.44102] 
[0.x.44103] 
[0.x.44104] 
//
[0.x.44105] 
[0.x.44106] 
//
[0.x.44107] 
[0.x.44108] 
//
[0.x.44109] 
[0.x.44110] 
[0.x.44111] 
[0.x.44112] 
[0.x.44113] 
[0.x.44114] 
[0.x.44115] 
[0.x.44116] 
//
[0.x.44117] 
[0.x.44118] 
//
[0.x.44119] 
[0.x.44120] 
[0.x.44121] 
[0.x.44122] 
[0.x.44123] 
[0.x.44124] 
[0.x.44125] 
//
[0.x.44126] 
[0.x.44127] 
//
[0.x.44128] 
[0.x.44129] 
[0.x.44130] 
[0.x.44131] 
[0.x.44132] 
[0.x.44133] 
[0.x.44134] 
//
[0.x.44135] 
[0.x.44136] 
//
[0.x.44137] 
[0.x.44138] 
[0.x.44139] 
[0.x.44140] 
[0.x.44141] 
[0.x.44142] 
[0.x.44143] 
//
[0.x.44144] 
[0.x.44145] 
//
[0.x.44146] 
[0.x.44147] 
[0.x.44148] 
[0.x.44149] 
[0.x.44150] 
[0.x.44151] 
[0.x.44152] 
[0.x.44153] 
[0.x.44154] 
[0.x.44155] 
[0.x.44156] 
//
[0.x.44157] 
[0.x.44158] 
//
[0.x.44159] 
[0.x.44160] 
[0.x.44161] 
[0.x.44162] 
[0.x.44163] 
[0.x.44164] 
[0.x.44165] 
//
[0.x.44166] 
[0.x.44167] 
//
[0.x.44168] 
[0.x.44169] 
[0.x.44170] 
[0.x.44171] 
[0.x.44172] 
[0.x.44173] 
[0.x.44174] 
[0.x.44175] 
[0.x.44176] 
[0.x.44177] 
//
[0.x.44178] 
[0.x.44179] 
//
[0.x.44180] 
[0.x.44181] 
[0.x.44182] 
[0.x.44183] 
[0.x.44184] 
[0.x.44185] 
[0.x.44186] 
[0.x.44187] 
//
[0.x.44188] 
[0.x.44189] 
//
[0.x.44190] 
[0.x.44191] 
[0.x.44192] 
[0.x.44193] 
[0.x.44194] 
[0.x.44195] 
[0.x.44196] 
[0.x.44197] 
[0.x.44198] 
[0.x.44199] 
//
[0.x.44200] 
[0.x.44201] 
[0.x.44202] 
[0.x.44203] 
[0.x.44204] 
[0.x.44205] 
[0.x.44206] 
//
[0.x.44207] 
[0.x.44208] 
//
[0.x.44209] 
[0.x.44210] 
//
[0.x.44211] 
[0.x.44212] 
[0.x.44213] 
[0.x.44214] 
[0.x.44215] 
[0.x.44216] 
[0.x.44217] 
[0.x.44218] 
[0.x.44219] 
[0.x.44220] 
//
[0.x.44221] 
[0.x.44222] 
[0.x.44223] 
[0.x.44224] 
[0.x.44225] 
[0.x.44226] 
[0.x.44227] 
[0.x.44228] 
[0.x.44229] 
[0.x.44230] 
//
[0.x.44231] 
[0.x.44232] 
//
[0.x.44233] 
[0.x.44234] 
//[2.x.5437] 
//
// The  [2.x.5438]  class is used to drive the numerical experiments that are to be conducted on the coupled materials that we've implemented constitutive laws for.
//
[0.x.44235] 
[0.x.44236] 
[0.x.44237] 
[0.x.44238] 
//
// These are  dimensions of the rheological specimen that is to be simulated. They, effectively, define the measurement point for our virtual experiment.
//
[0.x.44239] 
[0.x.44240] 
//
// The three steady-state loading parameters are respectively
//
// - the axial stretch,
//
// - the shear strain amplitude, and
//
// - the axial magnetic field strength.
//
[0.x.44241] 
[0.x.44242] 
[0.x.44243] 
//
// Moreover, the parameters for the time-dependent rheological loading conditions are
//
// - the loading cycle frequency,
//
// - the number of load cycles, and
//
// - the number of discrete timesteps per cycle.
//
[0.x.44244] 
[0.x.44245] 
[0.x.44246] 
//
// We also declare some self-explanatory parameters related to output data generated for the experiments conducted with rate-dependent and rate-independent materials.
//
[0.x.44247] 
[0.x.44248] 
[0.x.44249] 
[0.x.44250] 
[0.x.44251] 
//
// The next few functions compute time-related parameters for the experiment...
//
[0.x.44252] 
//
[0.x.44253] 
//
[0.x.44254] 
//
// ... while the following two prescribe the mechanical and magnetic loading at any given time...
//
[0.x.44255] 
//
[0.x.44256] 
//
// ... and this last one outputs the status of the experiment to the console.
//
[0.x.44257] 
//
[0.x.44258] 
[0.x.44259] 
//
[0.x.44260] 
[0.x.44261] 
[0.x.44262] 
[0.x.44263] 
[0.x.44264] 
//
[0.x.44265] 
[0.x.44266] 
[0.x.44267] 
//
[0.x.44268] 
[0.x.44269] 
[0.x.44270] 
//
[0.x.44271] 
[0.x.44272] 
[0.x.44273] 
[0.x.44274] 
[0.x.44275] 
//
[0.x.44276] 
[0.x.44277] 
//
[0.x.44278] 
[0.x.44279] 
[0.x.44280] 
[0.x.44281] 
//
[0.x.44282] 
[0.x.44283] 
[0.x.44284] 
[0.x.44285] 
//
[0.x.44286] 
[0.x.44287] 
[0.x.44288] 
[0.x.44289] 
//
[0.x.44290] 
[0.x.44291] 
[0.x.44292] 
[0.x.44293] 
[0.x.44294] 
//
// The applied magnetic field is always aligned with the axis of rotation of the rheometer's rotor.
//
[0.x.44295] 
[0.x.44296] 
[0.x.44297] 
[0.x.44298] 
//
// The applied deformation (gradient) is computed based on the geometry of the rheometer and the sample, the sampling point, and the experimental parameters. From the displacement profile documented in the introduction, the deformation gradient may be expressed in Cartesian coordinates as [1.x.220]
//
[0.x.44299] 
[0.x.44300] 
[0.x.44301] 
[0.x.44302] 
[0.x.44303] 
[0.x.44304] 
//
[0.x.44305] 
[0.x.44306] 
//
[0.x.44307] 
[0.x.44308] 
[0.x.44309] 
[0.x.44310] 
[0.x.44311] 
[0.x.44312] 
[0.x.44313] 
[0.x.44314] 
[0.x.44315] 
[0.x.44316] 
//
[0.x.44317] 
[0.x.44318] 
[0.x.44319] 
[0.x.44320] 
[0.x.44321] 
[0.x.44322] 
[0.x.44323] 
[0.x.44324] 
[0.x.44325] 
[0.x.44326] 
//
[0.x.44327] 
[0.x.44328] 
[0.x.44329] 
[0.x.44330] 
//
[0.x.44331] 
[0.x.44332] 
//[2.x.5439] 
//
// This is the function that will drive the numerical experiments.
//
[0.x.44333] 
[0.x.44334] 
[0.x.44335] 
[0.x.44336] 
[0.x.44337] 
[0.x.44338] 
[0.x.44339] 
[0.x.44340] 
[0.x.44341] 
[0.x.44342] 
//
// We can take the hand-implemented constitutive law and compare the results that we attain with it to those that we get using AD or SD. In this way, we can verify that they produce identical results (which indicates that either both implementations have a high probability of being correct, or that they're incorrect with identical flaws being present in both). Either way, it is a decent sanity check for the fully self-implemented variants and can certainly be used as a debugging strategy when differences between the results are detected).
//
[0.x.44343] 
[0.x.44344] 
[0.x.44345] 
[0.x.44346] 
[0.x.44347] 
[0.x.44348] 
[0.x.44349] 
[0.x.44350] 
//
[0.x.44351] 
[0.x.44352] 
[0.x.44353] 
[0.x.44354] 
//
[0.x.44355] 
[0.x.44356] 
[0.x.44357] 
[0.x.44358] 
[0.x.44359] 
[0.x.44360] 
[0.x.44361] 
[0.x.44362] 
//
[0.x.44363] 
[0.x.44364] 
[0.x.44365] 
[0.x.44366] 
[0.x.44367] 
[0.x.44368] 
[0.x.44369] 
[0.x.44370] 
[0.x.44371] 
[0.x.44372] 
[0.x.44373] 
[0.x.44374] 
[0.x.44375] 
//
// We'll be outputting the constitutive response of the material to file for post-processing, so here we declare a `stream` that will act as a buffer for this output. We'll use a simple CSV format for the outputted results.
//
[0.x.44376] 
[0.x.44377] 
[0.x.44378] 
//
// Using the DiscreteTime class, we iterate through each timestep using a fixed time step size.
//
[0.x.44379] 
[0.x.44380] 
[0.x.44381] 
[0.x.44382] 
[0.x.44383] 
[0.x.44384] 
[0.x.44385] 
[0.x.44386] 
[0.x.44387] 
[0.x.44388] 
[0.x.44389] 
//
// We fetch and compute the loading to be applied to the material at this time step...
//
[0.x.44390] 
[0.x.44391] 
[0.x.44392] 
[0.x.44393] 
[0.x.44394] 
[0.x.44395] 
//
// ... then we update the state of the materials...
//
[0.x.44396] 
[0.x.44397] 
[0.x.44398] 
[0.x.44399] 
[0.x.44400] 
//
[0.x.44401] 
[0.x.44402] 
[0.x.44403] 
[0.x.44404] 
[0.x.44405] 
//
// ... and test for discrepancies between the two.
//
[0.x.44406] 
[0.x.44407] 
//
[0.x.44408] 
[0.x.44409] 
//
//     The next thing that we will do is collect some results to     post-process. All quantities are in the "current configuration"     (rather than the "reference configuration", in which all     quantities computed by the constitutive laws are framed).
//
[0.x.44410] 
[0.x.44411] 
[0.x.44412] 
[0.x.44413] 
[0.x.44414] 
[0.x.44415] 
[0.x.44416] 
[0.x.44417] 
[0.x.44418] 
[0.x.44419] 
[0.x.44420] 
[0.x.44421] 
//
// Finally, we output the strain-stress and magnetic loading history to file.
//
[0.x.44422] 
[0.x.44423] 
[0.x.44424] 
[0.x.44425] 
[0.x.44426] 
[0.x.44427] 
//[2.x.5440] 
//
// The purpose of this driver function is to read in all of the parameters from file and, based off of that, create a representative instance of each constitutive law and invoke the function that conducts a rheological experiment with it.
//
[0.x.44428] 
[0.x.44429] 
[0.x.44430] 
//
[0.x.44431] 
//
[0.x.44432] 
[0.x.44433] 
//
[0.x.44434] 
[0.x.44435] 
[0.x.44436] 
[0.x.44437] 
[0.x.44438] 
[0.x.44439] 
//
// We start the actual work by configuring and running the experiment using our rate-independent constitutive law. The automatically differentiable number type is hard-coded here, but with some clever templating it is possible to select which framework to use at run time (e.g., as selected through the parameter file). We'll simultaneously perform the experiments with the counterpary material law that was fully implemented by hand, and check what it computes against our assisted implementation.
//
[0.x.44440] 
[0.x.44441] 
[0.x.44442] 
[0.x.44443] 
[0.x.44444] 
[0.x.44445] 
[0.x.44446] 
//
[0.x.44447] 
[0.x.44448] 
//
[0.x.44449] 
[0.x.44450] 
[0.x.44451] 
//
[0.x.44452] 
[0.x.44453] 
[0.x.44454] 
[0.x.44455] 
[0.x.44456] 
//
[0.x.44457] 
[0.x.44458] 
//
// Next we do the same for the rate-dependent constitutive law. The highest performance option is selected as default if SymEngine is set up to use the LLVM just-in-time compiler which (in conjunction with some aggressive compilation flags) produces the fastest code evaluation path of all of the available option. As a fall-back, the so called "lambda" optimizer (which only requires a C++11 compliant compiler) will be selected. At the same time, we'll ask the CAS to perform common subexpression elimination to minimize the number of intermediate calculations used during evaluation. We'll record how long it takes to execute the "initialization" step inside the constructor for the SD implementation, as this is where the abovementioned transformations occur.
//
[0.x.44459] 
[0.x.44460] 
[0.x.44461] 
[0.x.44462] 
[0.x.44463] 
[0.x.44464] 
[0.x.44465] 
//
[0.x.44466] 
[0.x.44467] 
[0.x.44468] 
[0.x.44469] 
[0.x.44470] 
[0.x.44471] 
[0.x.44472] 
[0.x.44473] 
[0.x.44474] 
[0.x.44475] 
[0.x.44476] 
[0.x.44477] 
[0.x.44478] 
//
[0.x.44479] 
[0.x.44480] 
//
[0.x.44481] 
[0.x.44482] 
[0.x.44483] 
[0.x.44484] 
//
[0.x.44485] 
[0.x.44486] 
[0.x.44487] 
[0.x.44488] 
[0.x.44489] 
//
[0.x.44490] 
[0.x.44491] 
[0.x.44492] 
//
[0.x.44493] 
//
[0.x.44494] 
//[2.x.5441] 
//
// The main function only calls the driver functions for the two sets of examples that are to be executed.
//
[0.x.44495] 
[0.x.44496] 
[0.x.44497] 
[0.x.44498] 
//
[0.x.44499] 
[0.x.44500] 
[0.x.44501] 
[0.x.44502] 
[0.x.44503] 
[0.x.44504] 
[0.x.44505] 
[0.x.44506] 
[0.x.44507] 
[0.x.44508] 
[0.x.44509] 
[0.x.44510] 
[0.x.44511] 
[0.x.44512] 
[0.x.44513] 
[0.x.44514] 
//
[0.x.44515] 
[0.x.44516] 
[0.x.44517] 
[0.x.44518] 
[0.x.44519] 
//
// The majority of this tutorial is an exact replica of  [2.x.5442] . So, in the interest of brevity and maintaining a focus on the changes implemented here, we will only document what's new and simply indicate which sections of code are a repetition of what has come before.
//
//  [2.x.5443] 
//
// There are a few new header files that have been included in this tutorial. The first is the one that provides the declaration of the ParameterAcceptor class.
//
[0.x.44520] 
[0.x.44521] 
[0.x.44522] 
[0.x.44523] 
[0.x.44524] 
//
// This is the second, which is an all-inclusive header that will allow us to incorporate the automatic differentiation (AD) functionality within this code.
//
[0.x.44525] 
//
[0.x.44526] 
[0.x.44527] 
[0.x.44528] 
[0.x.44529] 
[0.x.44530] 
[0.x.44531] 
[0.x.44532] 
//
[0.x.44533] 
[0.x.44534] 
[0.x.44535] 
//
[0.x.44536] 
[0.x.44537] 
//
[0.x.44538] 
[0.x.44539] 
[0.x.44540] 
//
// And the next three provide some multi-threading capability using the generic  [2.x.5444]  framework.
//
[0.x.44541] 
[0.x.44542] 
[0.x.44543] 
//
[0.x.44544] 
[0.x.44545] 
[0.x.44546] 
[0.x.44547] 
//
[0.x.44548] 
[0.x.44549] 
//
[0.x.44550] 
//
// We then open a namespace for this program and import everything from the dealii namespace into it, as in previous programs:
//
[0.x.44551] 
[0.x.44552] 
[0.x.44553] 
//[2.x.5445] 
//
// In this tutorial we will implement three different approaches for assembling the linear system. One mirrors the hand implementation originally provided in  [2.x.5446] , while the other two use the Sacado automatic differentiation library that is provided as a part of the Trilinos framework.
//
// To facilitate switching between the three implementations, we have this really basic parameters class that has only two options that are configurable.
//
[0.x.44554] 
[0.x.44555] 
[0.x.44556] 
[0.x.44557] 
//
// Selection for the formulation and corresponding AD framework to be used:
//
// -  formulation = 0 : Unassisted implementation (full hand linearization).
//
// -  formulation = 1 : Automated linearization of the finite element                      residual.
//
// -  formulation = 2 : Automated computation of finite element                      residual and linearization using a                      variational formulation.
//
[0.x.44558] 
//
// The maximum acceptable tolerance for the linear system residual. We will see that the assembly time becomes appreciable once we use the AD framework, so we have increased the tolerance selected in  [2.x.5447]  by one order of magnitude. This way, the computations do not take too long to complete.
//
[0.x.44559] 
[0.x.44560] 
//
[0.x.44561] 
[0.x.44562] 
[0.x.44563] 
[0.x.44564] 
[0.x.44565] 
[0.x.44566] 
[0.x.44567] 
//
//  [2.x.5448] 
//
// The class template is essentially the same as in  [2.x.5449] . The only functional changes to the class are that:
//
// - the run() function now takes in two arguments: one to choose which   assembly approach is to be adopted, and one for the tolerance for   the permissible final residual is, and
//
// - there are now three different assembly functions that implement the   three methods of assembling the linear system. We'll provide details   on these later on.
//
[0.x.44568] 
[0.x.44569] 
[0.x.44570] 
[0.x.44571] 
[0.x.44572] 
//
[0.x.44573] 
//
[0.x.44574] 
[0.x.44575] 
[0.x.44576] 
[0.x.44577] 
[0.x.44578] 
[0.x.44579] 
[0.x.44580] 
[0.x.44581] 
[0.x.44582] 
[0.x.44583] 
[0.x.44584] 
//
[0.x.44585] 
//
[0.x.44586] 
[0.x.44587] 
[0.x.44588] 
//
[0.x.44589] 
//
[0.x.44590] 
[0.x.44591] 
//
[0.x.44592] 
[0.x.44593] 
[0.x.44594] 
[0.x.44595] 
//[2.x.5450] 
//
// There are no changes to the boundary conditions applied to the problem.
//
[0.x.44596] 
[0.x.44597] 
[0.x.44598] 
[0.x.44599] 
[0.x.44600] 
[0.x.44601] 
[0.x.44602] 
//
[0.x.44603] 
[0.x.44604] 
[0.x.44605] 
[0.x.44606] 
[0.x.44607] 
[0.x.44608] 
//[2.x.5451] 
//[2.x.5452] 
//
// There have been no changes made to the class constructor.
//
[0.x.44609] 
[0.x.44610] 
[0.x.44611] 
[0.x.44612] 
[0.x.44613] 
[0.x.44614] 
//[2.x.5453] 
//
// There have been no changes made to the function that sets up the class data structures, namely the DoFHandler, the hanging node constraints applied to the problem, and the linear system.
//
[0.x.44615] 
[0.x.44616] 
[0.x.44617] 
[0.x.44618] 
[0.x.44619] 
[0.x.44620] 
[0.x.44621] 
//
[0.x.44622] 
[0.x.44623] 
[0.x.44624] 
[0.x.44625] 
[0.x.44626] 
//
[0.x.44627] 
[0.x.44628] 
//
[0.x.44629] 
[0.x.44630] 
//
[0.x.44631] 
//
[0.x.44632] 
[0.x.44633] 
[0.x.44634] 
//[2.x.5454] 
//[2.x.5455] 
//
// The assembly functions are the interesting contributions to this tutorial. The assemble_system_unassisted() method implements exactly the same assembly function as is detailed in  [2.x.5456] , but in this instance we use the  [2.x.5457]  function to multithread the assembly process. The reason for doing this is quite simple: When using automatic differentiation, we know that there is to be some additional computational overhead incurred. In order to mitigate this performance loss, we'd like to take advantage of as many (easily available) computational resources as possible. The  [2.x.5458]  concept makes this a relatively straightforward task. At the same time, for the purposes of fair comparison, we need to do the same to the implementation that uses no assistance when computing the residual or its linearization. (The  [2.x.5459]  function is first discussed in  [2.x.5460]  and  [2.x.5461] , if you'd like to read up on it.)
//
// The steps required to implement the multithreading are the same between the three functions, so we'll use the assemble_system_unassisted() function as an opportunity to focus on the multithreading itself.
//
[0.x.44635] 
[0.x.44636] 
[0.x.44637] 
[0.x.44638] 
[0.x.44639] 
//
[0.x.44640] 
//
// The  [2.x.5462]  expects that we provide two exemplar data structures. The first, `ScratchData`, is to store all large data that is to be reused between threads. The `CopyData` will hold the contributions to the linear system that come from each cell. These independent matrix-vector pairs must be accumulated into the global linear system sequentially. Since we don't need anything on top of what the  [2.x.5463]  and  [2.x.5464]  classes already provide, we use these exact class definitions for our problem. Note that we only require a single instance of a local matrix, local right-hand side vector, and cell degree of freedom index vector -- the  [2.x.5465]  therefore has `1` for all three of its template arguments.
//
[0.x.44641] 
[0.x.44642] 
//
// We also need to know what type of iterator we'll be working with during assembly. For simplicity, we just ask the compiler to work this out for us using the decltype() specifier, knowing that we'll be iterating over active cells owned by the  [2.x.5466] 
[0.x.44643] 
//
// Here we initialize the exemplar data structures. Since we know that we need to compute the shape function gradients, weighted Jacobian, and the position of the quadrate points in real space, we pass these flags into the class constructor.
//
[0.x.44644] 
[0.x.44645] 
[0.x.44646] 
[0.x.44647] 
[0.x.44648] 
[0.x.44649] 
//
// Now we define a lambda function that will perform the assembly on a single cell. The three arguments are those that will be expected by  [2.x.5467]  due to the arguments that we'll pass to that final call. We also capture the  [2.x.5468]  pointer, which means that we'll have access to "this" (i.e., the current `MinimalSurfaceProblem<dim>`) class instance, and its private member data (since the lambda function is defined within a MinimalSurfaceProblem<dim> method).
//
// At the top of the function, we initialize the data structures that are dependent on the cell for which the work is being performed. Observe that the reinitialization call actually returns an instance to an FEValues object that is initialized and stored within (and, therefore, reused by) the `scratch_data` object.
//
// Similarly, we get aliases to the local matrix, local RHS vector, and local cell DoF indices from the `copy_data` instance that  [2.x.5469]  provides. We then initialize the cell DoF indices, knowing that the local matrix and vector are already correctly sized.
//
[0.x.44650] 
[0.x.44651] 
[0.x.44652] 
[0.x.44653] 
//
[0.x.44654] 
[0.x.44655] 
[0.x.44656] 
[0.x.44657] 
[0.x.44658] 
//
// For Newton's method, we require the gradient of the solution at the point about which the problem is being linearized.
//
// Once we have that, we can perform assembly for this cell in the usual way.  One minor difference to  [2.x.5470]  is that we've used the (rather convenient) range-based loops to iterate over all quadrature points and degrees-of-freedom.
//
[0.x.44659] 
[0.x.44660] 
[0.x.44661] 
[0.x.44662] 
//
[0.x.44663] 
[0.x.44664] 
[0.x.44665] 
[0.x.44666] 
[0.x.44667] 
//
[0.x.44668] 
[0.x.44669] 
[0.x.44670] 
[0.x.44671] 
[0.x.44672] 
[0.x.44673] 
[0.x.44674] 
[0.x.44675] 
[0.x.44676] 
[0.x.44677] 
[0.x.44678] 
[0.x.44679] 
[0.x.44680] 
[0.x.44681] 
//
[0.x.44682] 
[0.x.44683] 
[0.x.44684] 
[0.x.44685] 
[0.x.44686] 
[0.x.44687] 
[0.x.44688] 
//
// The second lambda function that  [2.x.5471]  requires is one that performs the task of accumulating the local contributions in the global linear system. That is precisely what this one does, and the details of the implementation have been seen before. The primary point to recognize is that the local contributions are stored in the `copy_data` instance that is passed into this function. This `copy_data` has been filled with data during  [2.x.5472]  some call to the `cell_worker`.
//
[0.x.44689] 
[0.x.44690] 
[0.x.44691] 
[0.x.44692] 
[0.x.44693] 
//
[0.x.44694] 
[0.x.44695] 
[0.x.44696] 
[0.x.44697] 
[0.x.44698] 
[0.x.44699] 
//
[0.x.44700] 
[0.x.44701] 
[0.x.44702] 
//
// We have all of the required functions definitions in place, so now we call the  [2.x.5473]  to perform the actual assembly.  We pass a flag as the last parameter which states that we only want to perform the assembly on the cells. Internally,  [2.x.5474]  then distributes the available work to different threads, making efficient use of the multiple cores almost all of today's processors have to offer.
//
[0.x.44703] 
[0.x.44704] 
[0.x.44705] 
[0.x.44706] 
[0.x.44707] 
[0.x.44708] 
//
// And finally, as is done in  [2.x.5475] , we remove hanging nodes from the system and apply zero boundary values to the linear system that defines the Newton updates  [2.x.5476] .
//
[0.x.44709] 
[0.x.44710] 
//
[0.x.44711] 
[0.x.44712] 
[0.x.44713] 
[0.x.44714] 
[0.x.44715] 
[0.x.44716] 
[0.x.44717] 
[0.x.44718] 
[0.x.44719] 
[0.x.44720] 
//[2.x.5477] 
//
// As outlined in the introduction, what we need to do for this second approach is implement the local contributions  [2.x.5478]  from cell  [2.x.5479]  to the residual vector, and then let the AD machinery deal with how to compute the derivatives  [2.x.5480]  from it.
//
// For the following, recall that [1.x.221] where  [2.x.5481] .
//
// Let us see how this is implemented in practice:
//
[0.x.44721] 
[0.x.44722] 
[0.x.44723] 
[0.x.44724] 
[0.x.44725] 
//
[0.x.44726] 
//
[0.x.44727] 
[0.x.44728] 
[0.x.44729] 
//
[0.x.44730] 
[0.x.44731] 
[0.x.44732] 
[0.x.44733] 
[0.x.44734] 
[0.x.44735] 
//
// We'll define up front the AD data structures that we'll be using, utilizing the techniques shown in  [2.x.5482] . In this case, we choose the helper class that will automatically compute the linearization of the finite element residual using Sacado forward automatic differentiation types. These number types can be used to compute first derivatives only. This is exactly what we want, because we know that we'll only be linearizing the residual, which means that we only need to compute first-order derivatives. The return values from the calculations are to be of type `double`.
//
// We also need an extractor to retrieve some data related to the field solution to the problem.
//
[0.x.44736] 
[0.x.44737] 
[0.x.44738] 
[0.x.44739] 
//
[0.x.44740] 
//
// With this, let us define the lambda function that will be used to compute the cell contributions to the Jacobian matrix and the right hand side:
//
[0.x.44741] 
[0.x.44742] 
[0.x.44743] 
[0.x.44744] 
[0.x.44745] 
//
[0.x.44746] 
[0.x.44747] 
[0.x.44748] 
[0.x.44749] 
[0.x.44750] 
//
// We'll now create and initialize an instance of the AD helper class. To do this, we need to specify how many independent variables and dependent variables there are. The independent variables will be the number of local degrees of freedom that our solution vector has, i.e., the number  [2.x.5483]  in the per-element representation of the discretized solution vector  [2.x.5484]  that indicates how many solution coefficients are associated with each finite element. In deal.II, this equals  [2.x.5485]  The number of dependent variables will be the number of entries in the local residual vector that we will be forming. In this particular problem (like many others that employ the [standard Galerkin method](https:en.wikipedia.org/wiki/Galerkin_method)) the number of local solution coefficients matches the number of local residual equations.
//
[0.x.44751] 
[0.x.44752] 
[0.x.44753] 
//
// Next we inform the helper of the values of the solution, i.e., the actual values for  [2.x.5486]  about which we wish to linearize. As this is done on each element individually, we have to extract the solution coefficients from the global solution vector. In other words, we define all of those coefficients  [2.x.5487]  where  [2.x.5488]  is a local degree of freedom as the independent variables that enter the computation of the vector  [2.x.5489]  (the dependent function).
//
// Then we get the complete set of degree of freedom values as represented by auto-differentiable numbers. The operations performed with these variables are tracked by the AD library from this point until the object goes out of scope. So it is  [2.x.5490] precisely these variables [2.x.5491]  with respect to which we will compute derivatives of the residual entries.
//
[0.x.44754] 
//
[0.x.44755] 
[0.x.44756] 
//
// Then we do some problem specific tasks, the first being to compute all values, (spatial) gradients, and the like based on "sensitive" AD degree of freedom values. In this instance we are retrieving the solution gradients at each quadrature point. Observe that the solution gradients are now sensitive to the values of the degrees of freedom as they use the  [2.x.5492]  as the scalar type and the  [2.x.5493]  vector provides the local DoF values.
//
[0.x.44757] 
[0.x.44758] 
[0.x.44759] 
[0.x.44760] 
//
// The next variable that we declare will store the cell residual vector contributions. This is rather self-explanatory, save for one [1.x.222] detail: Note that each entry in the vector is hand-initialized with a value of zero. This is a  [2.x.5494] highly recommended [2.x.5495]  practice, as some AD libraries appear not to safely initialize the internal data structures of these number types. Not doing so could lead to some very hard to understand or detect bugs (appreciate that the author of this program mentions this out of, generally bad, experience). So out of an abundance of caution it's worthwhile zeroing the initial value explicitly. After that, apart from a sign change the residual assembly looks much the same as we saw for the cell RHS vector before: We loop over all quadrature points, ensure that the coefficient now encodes its dependence on the (sensitive) finite element DoF values by using the correct `ADNumberType`, and finally we assemble the components of the residual vector. For complete clarity, the finite element shape functions (and their gradients, etc.) as well as the "JxW" values remain scalar valued, but the  [2.x.5496]  and the   [2.x.5497]  at each quadrature point are computed in terms of the independent variables.
//
[0.x.44761] 
[0.x.44762] 
[0.x.44763] 
[0.x.44764] 
[0.x.44765] 
[0.x.44766] 
[0.x.44767] 
//
[0.x.44768] 
[0.x.44769] 
[0.x.44770] 
[0.x.44771] 
[0.x.44772] 
[0.x.44773] 
[0.x.44774] 
[0.x.44775] 
//
// Once we have the full cell residual vector computed, we can register it with the helper class.
//
// Thereafter, we compute the residual values (basically, extracting the real values from what we already computed) and their Jacobian (the linearization of each residual component with respect to all cell DoFs) at the evaluation point. For the purposes of assembly into the global linear system, we have to respect the sign difference between the residual and the RHS contribution: For Newton's method, the right hand side vector needs to be equal to the *negative* residual vector.
//
[0.x.44776] 
//
[0.x.44777] 
[0.x.44778] 
//
[0.x.44779] 
[0.x.44780] 
//
// The remainder of the function equals what we had previously:
//
[0.x.44781] 
[0.x.44782] 
[0.x.44783] 
[0.x.44784] 
[0.x.44785] 
//
[0.x.44786] 
[0.x.44787] 
[0.x.44788] 
[0.x.44789] 
[0.x.44790] 
[0.x.44791] 
//
[0.x.44792] 
[0.x.44793] 
[0.x.44794] 
//
[0.x.44795] 
[0.x.44796] 
[0.x.44797] 
[0.x.44798] 
[0.x.44799] 
[0.x.44800] 
//
[0.x.44801] 
[0.x.44802] 
//
[0.x.44803] 
[0.x.44804] 
[0.x.44805] 
[0.x.44806] 
[0.x.44807] 
[0.x.44808] 
[0.x.44809] 
[0.x.44810] 
[0.x.44811] 
[0.x.44812] 
//[2.x.5498] 
//
// In this third approach, we compute residual and Jacobian as first and second derivatives of the local energy functional [1.x.223] with the energy density given by [1.x.224]
//
// Let us again see how this is done:
//
[0.x.44813] 
[0.x.44814] 
[0.x.44815] 
[0.x.44816] 
[0.x.44817] 
//
[0.x.44818] 
//
[0.x.44819] 
[0.x.44820] 
[0.x.44821] 
//
[0.x.44822] 
[0.x.44823] 
[0.x.44824] 
[0.x.44825] 
[0.x.44826] 
[0.x.44827] 
//
// In this implementation of the assembly process, we choose the helper class that will automatically compute both the residual and its linearization from the cell contribution to an energy functional using nested Sacado forward automatic differentiation types. The selected number types can be used to compute both first and second derivatives. We require this, as the residual defined as the sensitivity of the potential energy with respect to the DoF values (i.e. its gradient). We'll then need to linearize the residual, implying that second derivatives of the potential energy must be computed. You might want to compare this with the definition of `ADHelper` used int previous function, where we used  [2.x.5499] 
[0.x.44828] 
[0.x.44829] 
[0.x.44830] 
[0.x.44831] 
//
[0.x.44832] 
//
// Let us then again define the lambda function that does the integration on a cell.
//
// To initialize an instance of the helper class, we now only require that the number of independent variables (that is, the number of degrees of freedom associated with the element solution vector) are known up front. This is because the second-derivative matrix that results from an energy functional is necessarily square (and also, incidentally, symmetric).
//
[0.x.44833] 
[0.x.44834] 
[0.x.44835] 
[0.x.44836] 
//
[0.x.44837] 
[0.x.44838] 
[0.x.44839] 
[0.x.44840] 
[0.x.44841] 
//
[0.x.44842] 
[0.x.44843] 
//
// Once more, we register all cell DoFs values with the helper, followed by extracting the "sensitive" variant of these values that are to be used in subsequent operations that must be differentiated -- one of those being the calculation of the solution gradients.
//
[0.x.44844] 
//
[0.x.44845] 
[0.x.44846] 
//
[0.x.44847] 
[0.x.44848] 
[0.x.44849] 
[0.x.44850] 
//
// We next create a variable that stores the cell total energy. Once more we emphasize that we explicitly zero-initialize this value, thereby ensuring the integrity of the data for this starting value.
//
// The aim for our approach is then to compute the cell total energy, which is the sum of the internal (due to right hand side functions, typically linear in  [2.x.5500] ) and external energies. In this particular case, we have no external energies (e.g., from source terms or Neumann boundary conditions), so we'll focus on the internal energy part.
//
// In fact, computing  [2.x.5501]  is almost trivial, requiring only the following lines:
//
[0.x.44851] 
[0.x.44852] 
[0.x.44853] 
[0.x.44854] 
[0.x.44855] 
//
[0.x.44856] 
[0.x.44857] 
//
// After we've computed the total energy on this cell, we'll register it with the helper.  Based on that, we may now compute the desired quantities, namely the residual values and their Jacobian at the evaluation point. As before, the Newton right hand side needs to be the negative of the residual:
//
[0.x.44858] 
//
[0.x.44859] 
[0.x.44860] 
//
[0.x.44861] 
[0.x.44862] 
//
// As in the previous two functions, the remainder of the function is as before:
//
[0.x.44863] 
[0.x.44864] 
[0.x.44865] 
[0.x.44866] 
[0.x.44867] 
//
[0.x.44868] 
[0.x.44869] 
[0.x.44870] 
[0.x.44871] 
[0.x.44872] 
[0.x.44873] 
//
[0.x.44874] 
[0.x.44875] 
[0.x.44876] 
//
[0.x.44877] 
[0.x.44878] 
[0.x.44879] 
[0.x.44880] 
[0.x.44881] 
[0.x.44882] 
//
[0.x.44883] 
[0.x.44884] 
//
[0.x.44885] 
[0.x.44886] 
[0.x.44887] 
[0.x.44888] 
[0.x.44889] 
[0.x.44890] 
[0.x.44891] 
[0.x.44892] 
[0.x.44893] 
[0.x.44894] 
//[2.x.5502] 
//
// The solve function is the same as is used in  [2.x.5503] .
//
[0.x.44895] 
[0.x.44896] 
[0.x.44897] 
[0.x.44898] 
[0.x.44899] 
[0.x.44900] 
//
[0.x.44901] 
[0.x.44902] 
//
[0.x.44903] 
//
[0.x.44904] 
//
[0.x.44905] 
[0.x.44906] 
[0.x.44907] 
//[2.x.5504] 
//
// Nothing has changed since  [2.x.5505]  with respect to the mesh refinement procedure and transfer of the solution between adapted meshes.
//
[0.x.44908] 
[0.x.44909] 
[0.x.44910] 
[0.x.44911] 
//
[0.x.44912] 
[0.x.44913] 
[0.x.44914] 
[0.x.44915] 
[0.x.44916] 
[0.x.44917] 
//
[0.x.44918] 
[0.x.44919] 
[0.x.44920] 
[0.x.44921] 
//
[0.x.44922] 
[0.x.44923] 
[0.x.44924] 
[0.x.44925] 
//
[0.x.44926] 
//
[0.x.44927] 
[0.x.44928] 
[0.x.44929] 
//
[0.x.44930] 
[0.x.44931] 
[0.x.44932] 
[0.x.44933] 
//
[0.x.44934] 
//
[0.x.44935] 
[0.x.44936] 
//
//  [2.x.5506] 
//
// The choice of boundary conditions remains identical to  [2.x.5507] ...
//
[0.x.44937] 
[0.x.44938] 
[0.x.44939] 
[0.x.44940] 
[0.x.44941] 
[0.x.44942] 
[0.x.44943] 
[0.x.44944] 
[0.x.44945] 
[0.x.44946] 
//
[0.x.44947] 
[0.x.44948] 
//[2.x.5508] 
//
// ... as does the function used to compute the residual during the solution iteration procedure. One could replace this by differentiation of the energy functional if one really wanted, but for simplicity we here simply copy what we already had in  [2.x.5509] .
//
[0.x.44949] 
[0.x.44950] 
[0.x.44951] 
[0.x.44952] 
//
[0.x.44953] 
[0.x.44954] 
[0.x.44955] 
//
[0.x.44956] 
[0.x.44957] 
[0.x.44958] 
[0.x.44959] 
[0.x.44960] 
//
[0.x.44961] 
[0.x.44962] 
//
[0.x.44963] 
[0.x.44964] 
//
[0.x.44965] 
//
[0.x.44966] 
[0.x.44967] 
[0.x.44968] 
[0.x.44969] 
//
[0.x.44970] 
//
[0.x.44971] 
[0.x.44972] 
[0.x.44973] 
[0.x.44974] 
//
[0.x.44975] 
[0.x.44976] 
[0.x.44977] 
[0.x.44978] 
[0.x.44979] 
[0.x.44980] 
//
[0.x.44981] 
[0.x.44982] 
[0.x.44983] 
[0.x.44984] 
//
[0.x.44985] 
//
[0.x.44986] 
[0.x.44987] 
[0.x.44988] 
//
[0.x.44989] 
[0.x.44990] 
//
//  [2.x.5510] 
//
// The choice of step length (or, under-relaxation factor) for the nonlinear iterations procedure remains fixed at the value chosen and discussed in  [2.x.5511] .
//
[0.x.44991] 
[0.x.44992] 
[0.x.44993] 
[0.x.44994] 
[0.x.44995] 
//
//  [2.x.5512] 
//
// This last function to be called from `run()` outputs the current solution (and the Newton update) in graphical form as a VTU file. It is entirely the same as what has been used in previous tutorials.
//
[0.x.44996] 
[0.x.44997] 
[0.x.44998] 
[0.x.44999] 
[0.x.45000] 
//
[0.x.45001] 
[0.x.45002] 
[0.x.45003] 
[0.x.45004] 
//
[0.x.45005] 
[0.x.45006] 
[0.x.45007] 
[0.x.45008] 
[0.x.45009] 
//[2.x.5513] 
//
// In the run function, most remains the same as was first implemented in  [2.x.5514] . The only observable changes are that we can now choose (via the parameter file) what the final acceptable tolerance for the system residual is, and that we can choose which method of assembly we wish to utilize. To make the second choice clear, we output to the console some message which indicates the selection. Since we're interested in comparing the time taken to assemble for each of the three methods, we've also added a timer that keeps a track of how much time is spent during assembly. We also track the time taken to solve the linear system, so that we can contrast those numbers to the part of the code which would normally take the longest time to execute.
//
[0.x.45010] 
[0.x.45011] 
[0.x.45012] 
[0.x.45013] 
[0.x.45014] 
[0.x.45015] 
[0.x.45016] 
[0.x.45017] 
[0.x.45018] 
[0.x.45019] 
[0.x.45020] 
//
[0.x.45021] 
//
[0.x.45022] 
[0.x.45023] 
//
[0.x.45024] 
[0.x.45025] 
//
[0.x.45026] 
[0.x.45027] 
[0.x.45028] 
[0.x.45029] 
[0.x.45030] 
//
[0.x.45031] 
[0.x.45032] 
//
[0.x.45033] 
//
[0.x.45034] 
[0.x.45035] 
[0.x.45036] 
[0.x.45037] 
[0.x.45038] 
//
[0.x.45039] 
[0.x.45040] 
[0.x.45041] 
[0.x.45042] 
[0.x.45043] 
[0.x.45044] 
[0.x.45045] 
[0.x.45046] 
[0.x.45047] 
//
[0.x.45048] 
//
[0.x.45049] 
[0.x.45050] 
[0.x.45051] 
[0.x.45052] 
//
[0.x.45053] 
[0.x.45054] 
//
[0.x.45055] 
//
[0.x.45056] 
[0.x.45057] 
[0.x.45058] 
[0.x.45059] 
[0.x.45060] 
[0.x.45061] 
//[2.x.5515] 
//
// Finally the main function. This follows the scheme of most other main functions, with two obvious exceptions:
//
// - We call  [2.x.5516]  in order to set up (via a hidden   default parameter) the number of threads using the execution of   multithreaded tasks.
//
// - We also have a few lines dedicates to reading in or initializing the   user-defined parameters that will be considered during the execution of the   program.
//
[0.x.45062] 
[0.x.45063] 
[0.x.45064] 
[0.x.45065] 
[0.x.45066] 
//
[0.x.45067] 
//
[0.x.45068] 
[0.x.45069] 
[0.x.45070] 
[0.x.45071] 
[0.x.45072] 
//
[0.x.45073] 
[0.x.45074] 
//
[0.x.45075] 
[0.x.45076] 
[0.x.45077] 
[0.x.45078] 
[0.x.45079] 
[0.x.45080] 
[0.x.45081] 
[0.x.45082] 
[0.x.45083] 
[0.x.45084] 
[0.x.45085] 
[0.x.45086] 
[0.x.45087] 
[0.x.45088] 
[0.x.45089] 
//
[0.x.45090] 
[0.x.45091] 
[0.x.45092] 
[0.x.45093] 
[0.x.45094] 
[0.x.45095] 
[0.x.45096] 
[0.x.45097] 
[0.x.45098] 
[0.x.45099] 
[0.x.45100] 
[0.x.45101] 
[0.x.45102] 
[0.x.45103] 
[0.x.45104] 
[0.x.45105] 
[0.x.45106] 
[0.x.45107] 
[0.x.45108] 
[0.x.45109] 
[0.x.45110] 
[0.x.45111] 
[0.x.45112] 
[0.x.45113] 
[0.x.45114] 
[0.x.45115] 
[0.x.45116] 
[0.x.45117] 
[0.x.45118] 
[0.x.45119] 
//
[0.x.45120] 
[0.x.45121] 
[0.x.45122] 
//
// The first few files have already been covered in previous examples and will thus not be further commented on:
//
[0.x.45123] 
[0.x.45124] 
[0.x.45125] 
[0.x.45126] 
[0.x.45127] 
[0.x.45128] 
[0.x.45129] 
[0.x.45130] 
[0.x.45131] 
[0.x.45132] 
[0.x.45133] 
[0.x.45134] 
[0.x.45135] 
[0.x.45136] 
[0.x.45137] 
[0.x.45138] 
//
// Here the discontinuous finite elements and FEInterfaceValues are defined.
//
[0.x.45139] 
[0.x.45140] 
//
[0.x.45141] 
[0.x.45142] 
[0.x.45143] 
//
[0.x.45144] 
[0.x.45145] 
[0.x.45146] 
//
[0.x.45147] 
[0.x.45148] 
[0.x.45149] 
//[2.x.5517]  Here we define two test cases: convergence_rate for a smooth function and l_singularity for the  [2.x.5518] 
[0.x.45150] 
[0.x.45151] 
[0.x.45152] 
[0.x.45153] 
[0.x.45154] 
//
// A smooth solution for the convergence test:
//
[0.x.45155] 
[0.x.45156] 
[0.x.45157] 
[0.x.45158] 
[0.x.45159] 
[0.x.45160] 
[0.x.45161] 
//
[0.x.45162] 
[0.x.45163] 
[0.x.45164] 
//
[0.x.45165] 
[0.x.45166] 
[0.x.45167] 
[0.x.45168] 
//
[0.x.45169] 
[0.x.45170] 
[0.x.45171] 
[0.x.45172] 
[0.x.45173] 
[0.x.45174] 
[0.x.45175] 
[0.x.45176] 
[0.x.45177] 
[0.x.45178] 
//
[0.x.45179] 
[0.x.45180] 
[0.x.45181] 
[0.x.45182] 
[0.x.45183] 
[0.x.45184] 
[0.x.45185] 
[0.x.45186] 
[0.x.45187] 
[0.x.45188] 
[0.x.45189] 
[0.x.45190] 
[0.x.45191] 
//
// The corresponding right-hand side of the smooth function:
//
[0.x.45192] 
[0.x.45193] 
[0.x.45194] 
[0.x.45195] 
[0.x.45196] 
[0.x.45197] 
[0.x.45198] 
//
[0.x.45199] 
[0.x.45200] 
[0.x.45201] 
[0.x.45202] 
//
[0.x.45203] 
[0.x.45204] 
[0.x.45205] 
[0.x.45206] 
[0.x.45207] 
[0.x.45208] 
[0.x.45209] 
[0.x.45210] 
[0.x.45211] 
[0.x.45212] 
[0.x.45213] 
//
// The right-hand side that corresponds to the function  [2.x.5519]  where we assume that the diffusion coefficient  [2.x.5520] :
//
[0.x.45214] 
[0.x.45215] 
[0.x.45216] 
[0.x.45217] 
[0.x.45218] 
[0.x.45219] 
[0.x.45220] 
//
[0.x.45221] 
[0.x.45222] 
[0.x.45223] 
//
[0.x.45224] 
[0.x.45225] 
[0.x.45226] 
//
[0.x.45227] 
[0.x.45228] 
[0.x.45229] 
[0.x.45230] 
[0.x.45231] 
[0.x.45232] 
[0.x.45233] 
[0.x.45234] 
[0.x.45235] 
//
//  [2.x.5521]  The following two auxiliary functions are used to compute jump terms for  [2.x.5522]  and  [2.x.5523]  on a face, respectively.
//
[0.x.45236] 
[0.x.45237] 
[0.x.45238] 
[0.x.45239] 
[0.x.45240] 
[0.x.45241] 
[0.x.45242] 
[0.x.45243] 
[0.x.45244] 
[0.x.45245] 
[0.x.45246] 
[0.x.45247] 
[0.x.45248] 
[0.x.45249] 
[0.x.45250] 
[0.x.45251] 
[0.x.45252] 
//
[0.x.45253] 
[0.x.45254] 
[0.x.45255] 
[0.x.45256] 
[0.x.45257] 
[0.x.45258] 
[0.x.45259] 
[0.x.45260] 
[0.x.45261] 
[0.x.45262] 
[0.x.45263] 
[0.x.45264] 
[0.x.45265] 
[0.x.45266] 
[0.x.45267] 
[0.x.45268] 
[0.x.45269] 
//
// This function computes the penalty  [2.x.5524] .
//
[0.x.45270] 
[0.x.45271] 
[0.x.45272] 
[0.x.45273] 
[0.x.45274] 
[0.x.45275] 
[0.x.45276] 
[0.x.45277] 
//[2.x.5525]  In the following, we define "Copy" objects for the  [2.x.5526]  which is essentially the same as  [2.x.5527] . Note that the "Scratch" object is not defined here because we use  [2.x.5528]  instead. (The use of "Copy" and "Scratch" objects is extensively explained in the WorkStream namespace documentation.
//
[0.x.45278] 
[0.x.45279] 
[0.x.45280] 
[0.x.45281] 
[0.x.45282] 
[0.x.45283] 
[0.x.45284] 
//
[0.x.45285] 
[0.x.45286] 
[0.x.45287] 
[0.x.45288] 
[0.x.45289] 
[0.x.45290] 
[0.x.45291] 
[0.x.45292] 
//
[0.x.45293] 
[0.x.45294] 
[0.x.45295] 
[0.x.45296] 
[0.x.45297] 
[0.x.45298] 
[0.x.45299] 
[0.x.45300] 
[0.x.45301] 
//
//  [2.x.5529]  After these preparations, we proceed with the main class of this program, called `SIPGLaplace`. The overall structure of the class is as in many of the other tutorial programs. Major differences will only come up in the implementation of the assemble functions, since we use FEInterfaceValues to assemble face terms.
//
[0.x.45302] 
[0.x.45303] 
[0.x.45304] 
[0.x.45305] 
[0.x.45306] 
[0.x.45307] 
//
[0.x.45308] 
[0.x.45309] 
[0.x.45310] 
[0.x.45311] 
[0.x.45312] 
[0.x.45313] 
//
[0.x.45314] 
[0.x.45315] 
[0.x.45316] 
//
[0.x.45317] 
[0.x.45318] 
[0.x.45319] 
[0.x.45320] 
[0.x.45321] 
[0.x.45322] 
[0.x.45323] 
//
[0.x.45324] 
//
[0.x.45325] 
[0.x.45326] 
//
[0.x.45327] 
[0.x.45328] 
[0.x.45329] 
[0.x.45330] 
//
// The remainder of the class's members are used for the following:
//
// - Vectors to store error estimator square and energy norm square per cell.
//
// - Print convergence rate and errors on the screen.
//
// - The fiffusion coefficient  [2.x.5530]  is set to 1.
//
// - Members that store information about the test case to be computed.
//
[0.x.45331] 
[0.x.45332] 
//
[0.x.45333] 
//
[0.x.45334] 
//
[0.x.45335] 
[0.x.45336] 
[0.x.45337] 
[0.x.45338] 
//
// The constructor here takes the test case as input and then determines the correct solution and right-hand side classes. The remaining member variables are initialized in the obvious way.
//
[0.x.45339] 
[0.x.45340] 
[0.x.45341] 
[0.x.45342] 
[0.x.45343] 
[0.x.45344] 
[0.x.45345] 
[0.x.45346] 
[0.x.45347] 
[0.x.45348] 
[0.x.45349] 
[0.x.45350] 
[0.x.45351] 
[0.x.45352] 
[0.x.45353] 
[0.x.45354] 
[0.x.45355] 
//
[0.x.45356] 
[0.x.45357] 
[0.x.45358] 
[0.x.45359] 
[0.x.45360] 
[0.x.45361] 
[0.x.45362] 
[0.x.45363] 
[0.x.45364] 
//
[0.x.45365] 
[0.x.45366] 
[0.x.45367] 
[0.x.45368] 
[0.x.45369] 
[0.x.45370] 
[0.x.45371] 
//
[0.x.45372] 
[0.x.45373] 
[0.x.45374] 
[0.x.45375] 
//
//  [2.x.5531]  The assemble function here is similar to that in  [2.x.5532]  and  [2.x.5533] . Different from assembling by hand, we just need to focus on assembling on each cell, each boundary face, and each interior face. The loops over cells and faces are handled automatically by  [2.x.5534] 
//
// The function starts by defining a local (lambda) function that is used to integrate the cell terms:
//
[0.x.45376] 
[0.x.45377] 
[0.x.45378] 
[0.x.45379] 
[0.x.45380] 
[0.x.45381] 
[0.x.45382] 
[0.x.45383] 
//
[0.x.45384] 
[0.x.45385] 
[0.x.45386] 
//
[0.x.45387] 
[0.x.45388] 
//
[0.x.45389] 
[0.x.45390] 
[0.x.45391] 
[0.x.45392] 
[0.x.45393] 
[0.x.45394] 
[0.x.45395] 
[0.x.45396] 
[0.x.45397] 
//
[0.x.45398] 
[0.x.45399] 
[0.x.45400] 
[0.x.45401] 
[0.x.45402] 
//
// Next, we need a function that assembles face integrals on the boundary:
//
[0.x.45403] 
[0.x.45404] 
[0.x.45405] 
[0.x.45406] 
[0.x.45407] 
//
[0.x.45408] 
[0.x.45409] 
[0.x.45410] 
//
[0.x.45411] 
[0.x.45412] 
[0.x.45413] 
//
[0.x.45414] 
[0.x.45415] 
//
[0.x.45416] 
[0.x.45417] 
//
[0.x.45418] 
[0.x.45419] 
[0.x.45420] 
[0.x.45421] 
[0.x.45422] 
[0.x.45423] 
[0.x.45424] 
[0.x.45425] 
[0.x.45426] 
//
[0.x.45427] 
[0.x.45428] 
[0.x.45429] 
[0.x.45430] 
//
[0.x.45431] 
[0.x.45432] 
[0.x.45433] 
//
[0.x.45434] 
[0.x.45435] 
//
[0.x.45436] 
[0.x.45437] 
[0.x.45438] 
[0.x.45439] 
[0.x.45440] 
[0.x.45441] 
//
[0.x.45442] 
[0.x.45443] 
//
[0.x.45444] 
[0.x.45445] 
[0.x.45446] 
[0.x.45447] 
//
// Finally, a function that assembles face integrals on interior faces. To reinitialize FEInterfaceValues, we need to pass cells, face and subface indices (for adaptive refinement) to the reinit() function of FEInterfaceValues:
//
[0.x.45448] 
[0.x.45449] 
[0.x.45450] 
[0.x.45451] 
[0.x.45452] 
[0.x.45453] 
[0.x.45454] 
[0.x.45455] 
[0.x.45456] 
[0.x.45457] 
//
[0.x.45458] 
[0.x.45459] 
//
[0.x.45460] 
[0.x.45461] 
[0.x.45462] 
[0.x.45463] 
[0.x.45464] 
//
[0.x.45465] 
[0.x.45466] 
//
[0.x.45467] 
[0.x.45468] 
[0.x.45469] 
//
[0.x.45470] 
[0.x.45471] 
[0.x.45472] 
[0.x.45473] 
[0.x.45474] 
[0.x.45475] 
[0.x.45476] 
[0.x.45477] 
[0.x.45478] 
//
[0.x.45479] 
[0.x.45480] 
[0.x.45481] 
[0.x.45482] 
//
[0.x.45483] 
[0.x.45484] 
[0.x.45485] 
//
[0.x.45486] 
[0.x.45487] 
[0.x.45488] 
[0.x.45489] 
//
// The following lambda function will then copy data into the global matrix and right-hand side.  Though there are no hanging node constraints in DG discretization, we define an empty AffineConstraints object that allows us to use the  [2.x.5535]  functionality.
//
[0.x.45490] 
[0.x.45491] 
[0.x.45492] 
[0.x.45493] 
[0.x.45494] 
[0.x.45495] 
[0.x.45496] 
[0.x.45497] 
//
// Copy data from interior face assembly to the global matrix.
//
[0.x.45498] 
[0.x.45499] 
[0.x.45500] 
[0.x.45501] 
[0.x.45502] 
[0.x.45503] 
[0.x.45504] 
//
// With the assembly functions defined, we can now create ScratchData and CopyData objects, and pass them together with the lambda functions above to  [2.x.5536]  In addition, we need to specify that we want to assemble on interior faces exactly once.
//
[0.x.45505] 
[0.x.45506] 
[0.x.45507] 
[0.x.45508] 
[0.x.45509] 
//
[0.x.45510] 
[0.x.45511] 
[0.x.45512] 
//
[0.x.45513] 
[0.x.45514] 
[0.x.45515] 
[0.x.45516] 
[0.x.45517] 
[0.x.45518] 
[0.x.45519] 
[0.x.45520] 
[0.x.45521] 
[0.x.45522] 
[0.x.45523] 
[0.x.45524] 
//
//  [2.x.5537]  The following two functions are entirely standard and without difficulty.
//
[0.x.45525] 
[0.x.45526] 
[0.x.45527] 
[0.x.45528] 
[0.x.45529] 
[0.x.45530] 
[0.x.45531] 
//
[0.x.45532] 
[0.x.45533] 
[0.x.45534] 
[0.x.45535] 
[0.x.45536] 
[0.x.45537] 
[0.x.45538] 
//
[0.x.45539] 
[0.x.45540] 
[0.x.45541] 
[0.x.45542] 
[0.x.45543] 
[0.x.45544] 
//[2.x.5538]  The assembly of the error estimator here is quite similar to that of the global matrix and right-had side and can be handled by the  [2.x.5539]  framework. To understand what each of the local (lambda) functions is doing, recall first that the local cell residual is defined as  [2.x.5540] :
//
[0.x.45545] 
[0.x.45546] 
[0.x.45547] 
[0.x.45548] 
[0.x.45549] 
[0.x.45550] 
//
[0.x.45551] 
//
[0.x.45552] 
[0.x.45553] 
[0.x.45554] 
//
[0.x.45555] 
[0.x.45556] 
//
[0.x.45557] 
[0.x.45558] 
//
[0.x.45559] 
[0.x.45560] 
//
[0.x.45561] 
[0.x.45562] 
[0.x.45563] 
[0.x.45564] 
[0.x.45565] 
[0.x.45566] 
[0.x.45567] 
[0.x.45568] 
//
// Next compute boundary terms  [2.x.5541] :
//
[0.x.45569] 
[0.x.45570] 
[0.x.45571] 
[0.x.45572] 
[0.x.45573] 
//
[0.x.45574] 
[0.x.45575] 
//
[0.x.45576] 
//
[0.x.45577] 
[0.x.45578] 
//
[0.x.45579] 
[0.x.45580] 
//
[0.x.45581] 
[0.x.45582] 
//
[0.x.45583] 
[0.x.45584] 
[0.x.45585] 
[0.x.45586] 
[0.x.45587] 
[0.x.45588] 
[0.x.45589] 
[0.x.45590] 
//
// And finally interior face terms  [2.x.5542] :
//
[0.x.45591] 
[0.x.45592] 
[0.x.45593] 
[0.x.45594] 
[0.x.45595] 
[0.x.45596] 
[0.x.45597] 
[0.x.45598] 
[0.x.45599] 
[0.x.45600] 
//
[0.x.45601] 
[0.x.45602] 
//
[0.x.45603] 
[0.x.45604] 
//
[0.x.45605] 
[0.x.45606] 
//
[0.x.45607] 
[0.x.45608] 
//
[0.x.45609] 
[0.x.45610] 
//
[0.x.45611] 
[0.x.45612] 
//
[0.x.45613] 
//
[0.x.45614] 
[0.x.45615] 
[0.x.45616] 
//
[0.x.45617] 
[0.x.45618] 
[0.x.45619] 
[0.x.45620] 
[0.x.45621] 
[0.x.45622] 
[0.x.45623] 
[0.x.45624] 
[0.x.45625] 
[0.x.45626] 
[0.x.45627] 
[0.x.45628] 
[0.x.45629] 
//
// Having computed local contributions for each cell, we still need a way to copy these into the global vector that will hold the error estimators for all cells:
//
[0.x.45630] 
[0.x.45631] 
[0.x.45632] 
[0.x.45633] 
[0.x.45634] 
[0.x.45635] 
[0.x.45636] 
[0.x.45637] 
//
// After all of this set-up, let's do the actual work: We resize the vector into which the results will be written, and then drive the whole process using the  [2.x.5543]  function.
//
[0.x.45638] 
//
[0.x.45639] 
[0.x.45640] 
[0.x.45641] 
[0.x.45642] 
[0.x.45643] 
//
[0.x.45644] 
[0.x.45645] 
//
[0.x.45646] 
[0.x.45647] 
[0.x.45648] 
[0.x.45649] 
[0.x.45650] 
[0.x.45651] 
[0.x.45652] 
[0.x.45653] 
[0.x.45654] 
[0.x.45655] 
[0.x.45656] 
[0.x.45657] 
[0.x.45658] 
//[2.x.5544]  Next, we evaluate the accuracy in terms of the energy norm. This function is similar to the assembling of the error estimator above. Here we compute the square of the energy norm defined by [1.x.225] Therefore the corresponding error is [1.x.226]
//
[0.x.45659] 
[0.x.45660] 
[0.x.45661] 
[0.x.45662] 
//
// Assemble  [2.x.5545] .
//
[0.x.45663] 
[0.x.45664] 
[0.x.45665] 
//
[0.x.45666] 
//
[0.x.45667] 
[0.x.45668] 
[0.x.45669] 
//
[0.x.45670] 
[0.x.45671] 
//
[0.x.45672] 
[0.x.45673] 
//
[0.x.45674] 
[0.x.45675] 
[0.x.45676] 
[0.x.45677] 
[0.x.45678] 
[0.x.45679] 
[0.x.45680] 
[0.x.45681] 
//
// Assemble  [2.x.5546] .
//
[0.x.45682] 
[0.x.45683] 
[0.x.45684] 
[0.x.45685] 
[0.x.45686] 
//
[0.x.45687] 
[0.x.45688] 
//
[0.x.45689] 
//
[0.x.45690] 
[0.x.45691] 
//
[0.x.45692] 
[0.x.45693] 
//
[0.x.45694] 
[0.x.45695] 
//
[0.x.45696] 
[0.x.45697] 
[0.x.45698] 
[0.x.45699] 
[0.x.45700] 
[0.x.45701] 
[0.x.45702] 
[0.x.45703] 
//
// Assemble  [2.x.5547] .
//
[0.x.45704] 
[0.x.45705] 
[0.x.45706] 
[0.x.45707] 
[0.x.45708] 
[0.x.45709] 
[0.x.45710] 
[0.x.45711] 
[0.x.45712] 
[0.x.45713] 
//
[0.x.45714] 
[0.x.45715] 
//
[0.x.45716] 
[0.x.45717] 
//
[0.x.45718] 
//
[0.x.45719] 
[0.x.45720] 
//
[0.x.45721] 
[0.x.45722] 
//
[0.x.45723] 
[0.x.45724] 
[0.x.45725] 
//
[0.x.45726] 
[0.x.45727] 
[0.x.45728] 
[0.x.45729] 
[0.x.45730] 
[0.x.45731] 
[0.x.45732] 
[0.x.45733] 
//
[0.x.45734] 
[0.x.45735] 
[0.x.45736] 
[0.x.45737] 
[0.x.45738] 
[0.x.45739] 
[0.x.45740] 
//
[0.x.45741] 
[0.x.45742] 
[0.x.45743] 
[0.x.45744] 
//
[0.x.45745] 
[0.x.45746] 
[0.x.45747] 
[0.x.45748] 
[0.x.45749] 
[0.x.45750] 
//
[0.x.45751] 
[0.x.45752] 
[0.x.45753] 
[0.x.45754] 
[0.x.45755] 
[0.x.45756] 
[0.x.45757] 
[0.x.45758] 
[0.x.45759] 
[0.x.45760] 
[0.x.45761] 
[0.x.45762] 
[0.x.45763] 
[0.x.45764] 
[0.x.45765] 
[0.x.45766] 
//
//  [2.x.5548] 
[0.x.45767] 
[0.x.45768] 
[0.x.45769] 
[0.x.45770] 
//
[0.x.45771] 
[0.x.45772] 
//
[0.x.45773] 
[0.x.45774] 
//
//  [2.x.5549]  We compute three errors in the  [2.x.5550]  norm,  [2.x.5551]  seminorm, and the energy norm, respectively. These are then printed to screen, but also stored in a table that records how these errors decay with mesh refinement and which can be output in one step at the end of the program.
//
[0.x.45775] 
[0.x.45776] 
[0.x.45777] 
[0.x.45778] 
//
[0.x.45779] 
[0.x.45780] 
[0.x.45781] 
[0.x.45782] 
[0.x.45783] 
[0.x.45784] 
[0.x.45785] 
[0.x.45786] 
[0.x.45787] 
//
[0.x.45788] 
[0.x.45789] 
[0.x.45790] 
[0.x.45791] 
[0.x.45792] 
//
[0.x.45793] 
[0.x.45794] 
[0.x.45795] 
[0.x.45796] 
[0.x.45797] 
[0.x.45798] 
[0.x.45799] 
[0.x.45800] 
[0.x.45801] 
//
[0.x.45802] 
[0.x.45803] 
[0.x.45804] 
[0.x.45805] 
[0.x.45806] 
//
[0.x.45807] 
[0.x.45808] 
[0.x.45809] 
[0.x.45810] 
//
[0.x.45811] 
[0.x.45812] 
[0.x.45813] 
[0.x.45814] 
[0.x.45815] 
//
//  [2.x.5552] 
[0.x.45816] 
[0.x.45817] 
[0.x.45818] 
[0.x.45819] 
[0.x.45820] 
[0.x.45821] 
[0.x.45822] 
[0.x.45823] 
//
[0.x.45824] 
[0.x.45825] 
[0.x.45826] 
[0.x.45827] 
[0.x.45828] 
[0.x.45829] 
[0.x.45830] 
//
[0.x.45831] 
[0.x.45832] 
[0.x.45833] 
[0.x.45834] 
[0.x.45835] 
[0.x.45836] 
[0.x.45837] 
[0.x.45838] 
//
[0.x.45839] 
[0.x.45840] 
[0.x.45841] 
[0.x.45842] 
[0.x.45843] 
[0.x.45844] 
[0.x.45845] 
[0.x.45846] 
[0.x.45847] 
[0.x.45848] 
[0.x.45849] 
[0.x.45850] 
[0.x.45851] 
//
[0.x.45852] 
[0.x.45853] 
[0.x.45854] 
[0.x.45855] 
[0.x.45856] 
//
[0.x.45857] 
[0.x.45858] 
[0.x.45859] 
//
[0.x.45860] 
[0.x.45861] 
//
[0.x.45862] 
[0.x.45863] 
[0.x.45864] 
[0.x.45865] 
[0.x.45866] 
[0.x.45867] 
[0.x.45868] 
[0.x.45869] 
[0.x.45870] 
//
[0.x.45871] 
[0.x.45872] 
[0.x.45873] 
[0.x.45874] 
[0.x.45875] 
[0.x.45876] 
//
[0.x.45877] 
[0.x.45878] 
[0.x.45879] 
[0.x.45880] 
[0.x.45881] 
[0.x.45882] 
//
// Having run all of our computations, let us tell the convergence table how to format its data and output it to screen:
//
[0.x.45883] 
[0.x.45884] 
[0.x.45885] 
//
[0.x.45886] 
[0.x.45887] 
[0.x.45888] 
//
[0.x.45889] 
[0.x.45890] 
[0.x.45891] 
[0.x.45892] 
[0.x.45893] 
[0.x.45894] 
[0.x.45895] 
[0.x.45896] 
[0.x.45897] 
[0.x.45898] 
[0.x.45899] 
[0.x.45900] 
//
[0.x.45901] 
[0.x.45902] 
[0.x.45903] 
[0.x.45904] 
[0.x.45905] 
//
//  [2.x.5553]  The following  [2.x.5554]  function is similar to previous examples as well, and need not be commented on.
//
[0.x.45906] 
[0.x.45907] 
[0.x.45908] 
[0.x.45909] 
[0.x.45910] 
[0.x.45911] 
//
[0.x.45912] 
//
[0.x.45913] 
[0.x.45914] 
[0.x.45915] 
[0.x.45916] 
[0.x.45917] 
[0.x.45918] 
[0.x.45919] 
[0.x.45920] 
[0.x.45921] 
[0.x.45922] 
[0.x.45923] 
[0.x.45924] 
[0.x.45925] 
[0.x.45926] 
[0.x.45927] 
[0.x.45928] 
[0.x.45929] 
[0.x.45930] 
[0.x.45931] 
[0.x.45932] 
[0.x.45933] 
[0.x.45934] 
[0.x.45935] 
[0.x.45936] 
[0.x.45937] 
[0.x.45938] 
[0.x.45939] 
[0.x.45940] 
//
[0.x.45941] 
[0.x.45942] 
[0.x.45943] 
[0.x.45944] 
[0.x.45945] 
[0.x.45946] 
[0.x.45947] 
[0.x.45948] 
[0.x.45949] 
[0.x.45950] 
[0.x.45951] 
[0.x.45952] 
[0.x.45953] 
[0.x.45954] 
[0.x.45955] 
[0.x.45956] 
//
[0.x.45957] 
[0.x.45958] 
[0.x.45959] 
[0.x.45960] 
[0.x.45961] 
[0.x.45962] 
//[2.x.5555] 
//
// The following include files have been used and discussed in previous tutorial programs, especially in  [2.x.5556]  and  [2.x.5557] .
//
[0.x.45963] 
[0.x.45964] 
[0.x.45965] 
[0.x.45966] 
[0.x.45967] 
//
[0.x.45968] 
[0.x.45969] 
//
[0.x.45970] 
[0.x.45971] 
//
[0.x.45972] 
//
[0.x.45973] 
[0.x.45974] 
//
[0.x.45975] 
[0.x.45976] 
//
[0.x.45977] 
[0.x.45978] 
[0.x.45979] 
[0.x.45980] 
[0.x.45981] 
[0.x.45982] 
[0.x.45983] 
//
[0.x.45984] 
[0.x.45985] 
[0.x.45986] 
[0.x.45987] 
//
[0.x.45988] 
[0.x.45989] 
[0.x.45990] 
//
// For load balancing we will assign individual weights on cells, and for that we will use the class  [2.x.5558] 
[0.x.45991] 
//
// The solution function requires a transformation from Cartesian to polar coordinates. The  [2.x.5559]  namespace provides the necessary tools.
//
[0.x.45992] 
[0.x.45993] 
//
// The following include files will enable the MatrixFree functionality.
//
[0.x.45994] 
[0.x.45995] 
[0.x.45996] 
//
// We will use  [2.x.5560]  for linear algebra operations.
//
[0.x.45997] 
//
// We are left to include the files needed by the multigrid solver.
//
[0.x.45998] 
[0.x.45999] 
[0.x.46000] 
[0.x.46001] 
[0.x.46002] 
[0.x.46003] 
[0.x.46004] 
//
[0.x.46005] 
[0.x.46006] 
[0.x.46007] 
//[2.x.5561] 
//
// We have an analytic solution to the scenario at our disposal. We will use this solution to impose boundary conditions for the numerical solution of the problem. The formulation of the solution requires a transformation to polar coordinates. To transform from Cartesian to spherical coordinates, we will use a helper function from the  [2.x.5562]  namespace. The first two coordinates of this transformation correspond to polar coordinates in the x-y-plane.
//
[0.x.46008] 
[0.x.46009] 
[0.x.46010] 
[0.x.46011] 
[0.x.46012] 
[0.x.46013] 
[0.x.46014] 
//
[0.x.46015] 
[0.x.46016] 
[0.x.46017] 
[0.x.46018] 
[0.x.46019] 
//
[0.x.46020] 
[0.x.46021] 
[0.x.46022] 
[0.x.46023] 
//
//  [2.x.5563] 
//
// For this tutorial, we will use a simplified set of parameters. It is also possible to use a ParameterHandler class here, but to keep this tutorial short we decided on using simple structs. The actual intention of all these parameters will be described in the upcoming classes at their respective location where they are used.
//
// The following parameter set controls the coarse-grid solver, the smoothers, and the inter-grid transfer scheme of the multigrid mechanism. We populate it with default parameters.
//
[0.x.46024] 
[0.x.46025] 
[0.x.46026] 
[0.x.46027] 
[0.x.46028] 
[0.x.46029] 
[0.x.46030] 
[0.x.46031] 
[0.x.46032] 
[0.x.46033] 
[0.x.46034] 
[0.x.46035] 
//
[0.x.46036] 
[0.x.46037] 
[0.x.46038] 
[0.x.46039] 
[0.x.46040] 
[0.x.46041] 
[0.x.46042] 
//
[0.x.46043] 
[0.x.46044] 
[0.x.46045] 
[0.x.46046] 
[0.x.46047] 
[0.x.46048] 
[0.x.46049] 
[0.x.46050] 
//
// This is the general parameter struct for the problem class. You will find this struct divided into several categories, including general runtime parameters, level limits, refine and coarsen fractions, as well as parameters for cell weighting. It also contains an instance of the above struct for multigrid parameters which will be passed to the multigrid algorithm.
//
[0.x.46051] 
[0.x.46052] 
[0.x.46053] 
[0.x.46054] 
//
[0.x.46055] 
//
[0.x.46056] 
[0.x.46057] 
[0.x.46058] 
[0.x.46059] 
[0.x.46060] 
//
[0.x.46061] 
[0.x.46062] 
[0.x.46063] 
[0.x.46064] 
//
[0.x.46065] 
[0.x.46066] 
[0.x.46067] 
//
//  [2.x.5564] 
//
// This is a matrix-free implementation of the Laplace operator that will basically take over the part of the `assemble_system()` function from other tutorials. The meaning of all member functions will be explained at their definition later.
//
// We will use the FEEvaluation class to evaluate the solution vector at the quadrature points and to perform the integration. In contrast to other tutorials, the template arguments `degree` is set to  [2.x.5565]  and `number of quadrature in 1D` to  [2.x.5566] . In this case, FEEvaluation selects dynamically the correct polynomial degree and number of quadrature points. Here, we introduce an alias to FEEvaluation with the correct template parameters so that we do not have to worry about them later on.
//
[0.x.46068] 
[0.x.46069] 
[0.x.46070] 
[0.x.46071] 
[0.x.46072] 
//
[0.x.46073] 
//
[0.x.46074] 
//
[0.x.46075] 
[0.x.46076] 
[0.x.46077] 
[0.x.46078] 
[0.x.46079] 
//
[0.x.46080] 
[0.x.46081] 
[0.x.46082] 
[0.x.46083] 
[0.x.46084] 
//
[0.x.46085] 
//
[0.x.46086] 
//
[0.x.46087] 
//
[0.x.46088] 
//
[0.x.46089] 
//
[0.x.46090] 
//
[0.x.46091] 
//
[0.x.46092] 
[0.x.46093] 
//
[0.x.46094] 
[0.x.46095] 
[0.x.46096] 
//
[0.x.46097] 
[0.x.46098] 
[0.x.46099] 
[0.x.46100] 
[0.x.46101] 
//
[0.x.46102] 
//
// To solve the equation system on the coarsest level with an AMG preconditioner, we need an actual system matrix on the coarsest level. For this purpose, we provide a mechanism that optionally computes a matrix from the matrix-free formulation, for which we introduce a dedicated SparseMatrix object. In the default case, this matrix stays empty. Once `get_system_matrix()` is called, this matrix is filled (lazy allocation). Since this is a `const` function, we need the "mutable" keyword here. We also need a the constraints object to build the matrix.
//
[0.x.46103] 
[0.x.46104] 
[0.x.46105] 
//
// The following section contains functions to initialize and reinitialize the class. In particular, these functions initialize the internal MatrixFree instance. For sake of simplicity, we also compute the system right-hand-side vector.
//
[0.x.46106] 
[0.x.46107] 
[0.x.46108] 
[0.x.46109] 
[0.x.46110] 
[0.x.46111] 
[0.x.46112] 
[0.x.46113] 
[0.x.46114] 
[0.x.46115] 
//
[0.x.46116] 
[0.x.46117] 
[0.x.46118] 
[0.x.46119] 
[0.x.46120] 
[0.x.46121] 
[0.x.46122] 
[0.x.46123] 
//
// Clear internal data structures (in the case that the operator is reused).
//
[0.x.46124] 
//
// Copy the constraints, since they might be needed for computation of the system matrix later on.
//
[0.x.46125] 
//
// Set up MatrixFree. At the quadrature points, we only need to evaluate the gradient of the solution and test with the gradient of the shape functions so that we only need to set the flag `update_gradients`.
//
[0.x.46126] 
[0.x.46127] 
//
[0.x.46128] 
//
// Compute the right-hand side vector. For this purpose, we set up a second MatrixFree instance that uses a modified AffineConstraints not containing the constraints due to Dirichlet-boundary conditions. This modified operator is applied to a vector with only the Dirichlet values set. The result is the negative right-hand-side vector.
//
[0.x.46129] 
[0.x.46130] 
//
[0.x.46131] 
[0.x.46132] 
[0.x.46133] 
[0.x.46134] 
//
[0.x.46135] 
[0.x.46136] 
[0.x.46137] 
//
[0.x.46138] 
//
[0.x.46139] 
//
[0.x.46140] 
[0.x.46141] 
[0.x.46142] 
//
[0.x.46143] 
[0.x.46144] 
//
[0.x.46145] 
//
[0.x.46146] 
[0.x.46147] 
[0.x.46148] 
[0.x.46149] 
//
[0.x.46150] 
//
[0.x.46151] 
[0.x.46152] 
[0.x.46153] 
//
// The following functions are implicitly needed by the multigrid algorithm, including the smoothers.
//
// Since we do not have a matrix, query the DoFHandler for the number of degrees of freedom.
//
[0.x.46154] 
[0.x.46155] 
[0.x.46156] 
[0.x.46157] 
[0.x.46158] 
//
// Access a particular element in the matrix. This function is neither needed nor implemented, however, is required to compile the program.
//
[0.x.46159] 
[0.x.46160] 
[0.x.46161] 
[0.x.46162] 
[0.x.46163] 
[0.x.46164] 
//
// Initialize the given vector. We simply delegate the task to the MatrixFree function with the same name.
//
[0.x.46165] 
[0.x.46166] 
[0.x.46167] 
[0.x.46168] 
[0.x.46169] 
[0.x.46170] 
//
// Perform an operator evaluation by looping with the help of MatrixFree over all cells and evaluating the effect of the cell integrals (see also: `do_cell_integral_local()` and `do_cell_integral_global()`).
//
[0.x.46171] 
[0.x.46172] 
[0.x.46173] 
[0.x.46174] 
[0.x.46175] 
[0.x.46176] 
[0.x.46177] 
//
// Perform the transposed operator evaluation. Since we are considering symmetric "matrices", this function can simply delegate it task to vmult().
//
[0.x.46178] 
[0.x.46179] 
[0.x.46180] 
[0.x.46181] 
[0.x.46182] 
[0.x.46183] 
//
// Since we do not have a system matrix, we cannot loop over the the diagonal entries of the matrix. Instead, we compute the diagonal by performing a sequence of operator evaluations to unit basis vectors. For this purpose, an optimized function from the MatrixFreeTools namespace is used. The inversion is performed manually afterwards.
//
[0.x.46184] 
[0.x.46185] 
[0.x.46186] 
[0.x.46187] 
[0.x.46188] 
[0.x.46189] 
[0.x.46190] 
[0.x.46191] 
//
[0.x.46192] 
[0.x.46193] 
[0.x.46194] 
//
// In the matrix-free context, no system matrix is set up during initialization of this class. As a consequence, it has to be computed here if it should be requested. Since the matrix is only computed in this tutorial for linear elements (on the coarse grid), this is acceptable. The matrix entries are obtained via sequence of operator evaluations. For this purpose, the optimized function  [2.x.5567]  is used. The matrix will only be computed if it has not been set up yet (lazy allocation).
//
[0.x.46195] 
[0.x.46196] 
[0.x.46197] 
[0.x.46198] 
[0.x.46199] 
[0.x.46200] 
[0.x.46201] 
//
[0.x.46202] 
[0.x.46203] 
[0.x.46204] 
//
[0.x.46205] 
//
[0.x.46206] 
[0.x.46207] 
//
[0.x.46208] 
[0.x.46209] 
[0.x.46210] 
[0.x.46211] 
[0.x.46212] 
[0.x.46213] 
[0.x.46214] 
//
[0.x.46215] 
[0.x.46216] 
//
// Perform cell integral on a cell batch without gathering and scattering the values. This function is needed for the MatrixFreeTools functions since these functions operate directly on the buffers of FEEvaluation.
//
[0.x.46217] 
[0.x.46218] 
[0.x.46219] 
[0.x.46220] 
[0.x.46221] 
//
[0.x.46222] 
[0.x.46223] 
//
[0.x.46224] 
[0.x.46225] 
//
// Same as above but with access to the global vectors.
//
[0.x.46226] 
[0.x.46227] 
[0.x.46228] 
[0.x.46229] 
[0.x.46230] 
[0.x.46231] 
[0.x.46232] 
//
[0.x.46233] 
[0.x.46234] 
//
[0.x.46235] 
[0.x.46236] 
//
// This function loops over all cell batches within a cell-batch range and calls the above function.
//
[0.x.46237] 
[0.x.46238] 
[0.x.46239] 
[0.x.46240] 
[0.x.46241] 
[0.x.46242] 
[0.x.46243] 
[0.x.46244] 
//
[0.x.46245] 
[0.x.46246] 
[0.x.46247] 
//
[0.x.46248] 
[0.x.46249] 
[0.x.46250] 
//
//  [2.x.5568] 
//[2.x.5569] 
//
// This function solves the equation system with a sequence of provided multigrid objects. It is meant to be treated as general as possible, hence the multitude of template parameters.
//
[0.x.46251] 
[0.x.46252] 
[0.x.46253] 
[0.x.46254] 
[0.x.46255] 
[0.x.46256] 
[0.x.46257] 
[0.x.46258] 
[0.x.46259] 
[0.x.46260] 
[0.x.46261] 
[0.x.46262] 
[0.x.46263] 
[0.x.46264] 
[0.x.46265] 
[0.x.46266] 
[0.x.46267] 
[0.x.46268] 
//
[0.x.46269] 
[0.x.46270] 
//
[0.x.46271] 
[0.x.46272] 
[0.x.46273] 
[0.x.46274] 
[0.x.46275] 
//
// We initialize level operators and Chebyshev smoothers here.
//
[0.x.46276] 
//
[0.x.46277] 
[0.x.46278] 
//
[0.x.46279] 
[0.x.46280] 
[0.x.46281] 
[0.x.46282] 
[0.x.46283] 
[0.x.46284] 
[0.x.46285] 
[0.x.46286] 
[0.x.46287] 
[0.x.46288] 
[0.x.46289] 
//
[0.x.46290] 
[0.x.46291] 
[0.x.46292] 
//
// Next, we initialize the coarse-grid solver. We use conjugate-gradient method with AMG as preconditioner.
//
[0.x.46293] 
[0.x.46294] 
[0.x.46295] 
[0.x.46296] 
[0.x.46297] 
[0.x.46298] 
//
[0.x.46299] 
//
[0.x.46300] 
[0.x.46301] 
[0.x.46302] 
[0.x.46303] 
[0.x.46304] 
//
[0.x.46305] 
[0.x.46306] 
//
[0.x.46307] 
[0.x.46308] 
[0.x.46309] 
[0.x.46310] 
[0.x.46311] 
[0.x.46312] 
//
// Finally, we create the Multigrid object, convert it to a preconditioner, and use it inside of a conjugate-gradient solver to solve the linear system of equations.
//
[0.x.46313] 
[0.x.46314] 
//
[0.x.46315] 
//
[0.x.46316] 
[0.x.46317] 
[0.x.46318] 
//
//  [2.x.5570] 
//
// The above function deals with the actual solution for a given sequence of multigrid objects. This functions creates the actual multigrid levels, in particular the operators, and the transfer operator as a MGTransferGlobalCoarsening object.
//
[0.x.46319] 
[0.x.46320] 
[0.x.46321] 
[0.x.46322] 
[0.x.46323] 
[0.x.46324] 
[0.x.46325] 
[0.x.46326] 
[0.x.46327] 
[0.x.46328] 
//
// Create a DoFHandler and operator for each multigrid level, as well as, create transfer operators. To be able to set up the operators, we need a set of DoFHandler that we create via global coarsening of p or h. For latter, we need also a sequence of Triangulation objects that are obtained by  [2.x.5571] 
//
// In case no h-transfer is requested, we provide an empty deleter for the `emplace_back()` function, since the Triangulation of our DoFHandler is an external field and its destructor is called somewhere else.
//
[0.x.46329] 
[0.x.46330] 
[0.x.46331] 
//
[0.x.46332] 
[0.x.46333] 
[0.x.46334] 
[0.x.46335] 
[0.x.46336] 
[0.x.46337] 
[0.x.46338] 
[0.x.46339] 
[0.x.46340] 
[0.x.46341] 
//
// Determine the total number of levels for the multigrid operation and allocate sufficient memory for all levels.
//
[0.x.46342] 
//
[0.x.46343] 
[0.x.46344] 
//
[0.x.46345] 
[0.x.46346] 
[0.x.46347] 
[0.x.46348] 
//
[0.x.46349] 
[0.x.46350] 
//
[0.x.46351] 
[0.x.46352] 
[0.x.46353] 
[0.x.46354] 
//
[0.x.46355] 
[0.x.46356] 
[0.x.46357] 
[0.x.46358] 
[0.x.46359] 
[0.x.46360] 
[0.x.46361] 
[0.x.46362] 
//
[0.x.46363] 
[0.x.46364] 
[0.x.46365] 
//
[0.x.46366] 
[0.x.46367] 
[0.x.46368] 
//
// Loop from the minimum (coarsest) to the maximum (finest) level and set up DoFHandler accordingly. We start with the h-levels, where we distribute on increasingly finer meshes linear elements.
//
[0.x.46369] 
[0.x.46370] 
[0.x.46371] 
[0.x.46372] 
[0.x.46373] 
//
// After we reached the finest mesh, we will adjust the polynomial degrees on each level. We reverse iterate over our data structure and start at the finest mesh that contains all information about the active FE indices. We then lower the polynomial degree of each cell level by level.
//
[0.x.46374] 
[0.x.46375] 
[0.x.46376] 
//
[0.x.46377] 
[0.x.46378] 
[0.x.46379] 
//
[0.x.46380] 
[0.x.46381] 
[0.x.46382] 
[0.x.46383] 
[0.x.46384] 
[0.x.46385] 
[0.x.46386] 
[0.x.46387] 
[0.x.46388] 
[0.x.46389] 
[0.x.46390] 
[0.x.46391] 
//
[0.x.46392] 
[0.x.46393] 
[0.x.46394] 
[0.x.46395] 
[0.x.46396] 
[0.x.46397] 
[0.x.46398] 
[0.x.46399] 
[0.x.46400] 
[0.x.46401] 
[0.x.46402] 
[0.x.46403] 
[0.x.46404] 
[0.x.46405] 
//
[0.x.46406] 
[0.x.46407] 
[0.x.46408] 
[0.x.46409] 
[0.x.46410] 
//
[0.x.46411] 
[0.x.46412] 
//
// Next, we will create all data structures additionally needed on each multigrid level. This involves determining constraints with homogeneous Dirichlet boundary conditions, and building the operator just like on the active level.
//
[0.x.46413] 
[0.x.46414] 
//
[0.x.46415] 
[0.x.46416] 
[0.x.46417] 
[0.x.46418] 
//
[0.x.46419] 
[0.x.46420] 
[0.x.46421] 
[0.x.46422] 
//
[0.x.46423] 
[0.x.46424] 
[0.x.46425] 
[0.x.46426] 
[0.x.46427] 
[0.x.46428] 
[0.x.46429] 
//
[0.x.46430] 
//
[0.x.46431] 
[0.x.46432] 
[0.x.46433] 
[0.x.46434] 
[0.x.46435] 
[0.x.46436] 
//
// Set up intergrid operators and collect transfer operators within a single operator as needed by the Multigrid solver class.
//
[0.x.46437] 
[0.x.46438] 
[0.x.46439] 
[0.x.46440] 
[0.x.46441] 
//
[0.x.46442] 
[0.x.46443] 
[0.x.46444] 
[0.x.46445] 
[0.x.46446] 
//
[0.x.46447] 
[0.x.46448] 
[0.x.46449] 
[0.x.46450] 
//
// Finally, proceed to solve the problem with multigrid.
//
[0.x.46451] 
[0.x.46452] 
[0.x.46453] 
[0.x.46454] 
[0.x.46455] 
[0.x.46456] 
[0.x.46457] 
[0.x.46458] 
[0.x.46459] 
//
//  [2.x.5572] 
//
// Now we will finally declare the main class of this program, which solves the Laplace equation on subsequently refined function spaces. Its structure will look familiar as it is similar to the main classes of  [2.x.5573]  and  [2.x.5574] . There are basically just two additions:
//
// - The SparseMatrix object that would hold the system matrix has been   replaced by an object of the LaplaceOperator class for the MatrixFree   formulation.
//
// - An object of  [2.x.5575]  which will help us with load   balancing, has been added.
//
[0.x.46460] 
[0.x.46461] 
[0.x.46462] 
[0.x.46463] 
[0.x.46464] 
//
[0.x.46465] 
//
[0.x.46466] 
[0.x.46467] 
[0.x.46468] 
[0.x.46469] 
[0.x.46470] 
[0.x.46471] 
[0.x.46472] 
[0.x.46473] 
//
[0.x.46474] 
//
[0.x.46475] 
//
[0.x.46476] 
[0.x.46477] 
//
[0.x.46478] 
[0.x.46479] 
[0.x.46480] 
[0.x.46481] 
//
[0.x.46482] 
[0.x.46483] 
//
[0.x.46484] 
//
[0.x.46485] 
[0.x.46486] 
[0.x.46487] 
//
[0.x.46488] 
[0.x.46489] 
//
[0.x.46490] 
[0.x.46491] 
//
[0.x.46492] 
[0.x.46493] 
[0.x.46494] 
//
//  [2.x.5576] 
//[2.x.5577] 
//
// The constructor starts with an initializer list that looks similar to the one of  [2.x.5578] . We again prepare the ConditionalOStream object to allow only the first process to output anything over the console, and initialize the computing timer properly.
//
[0.x.46495] 
[0.x.46496] 
[0.x.46497] 
[0.x.46498] 
[0.x.46499] 
[0.x.46500] 
[0.x.46501] 
[0.x.46502] 
[0.x.46503] 
[0.x.46504] 
[0.x.46505] 
[0.x.46506] 
[0.x.46507] 
[0.x.46508] 
[0.x.46509] 
[0.x.46510] 
[0.x.46511] 
[0.x.46512] 
//
// We need to prepare the data structures for the hp-functionality in the actual body of the constructor, and create corresponding objects for every degree in the specified range from the parameter struct. As we are only dealing with non-distorted rectangular cells, a linear mapping object is sufficient in this context.
//
// In the Parameters struct, we provide ranges for levels on which the function space is operating with a reasonable resolution. The multigrid algorithm requires linear elements on the coarsest possible level. So we start with the lowest polynomial degree and fill the collection with consecutively higher degrees until the user-specified maximum is reached.
//
[0.x.46513] 
//
[0.x.46514] 
[0.x.46515] 
[0.x.46516] 
[0.x.46517] 
[0.x.46518] 
[0.x.46519] 
//
// As our FECollection contains more finite elements than we want to use for the finite element approximation of our solution, we would like to limit the range on which active FE indices can operate on. For this, the FECollection class allows to register a hierarchy that determines the succeeding and preceding finite element in case of of p-refinement and p-coarsening, respectively. All functions in the  [2.x.5579]  namespace consult this hierarchy to determine future FE indices. We will register such a hierarchy that only works on finite elements with polynomial degrees in the proposed range  [2.x.5580] .
//
[0.x.46520] 
[0.x.46521] 
//
//      /*next_index= [2.x.5581] 
[0.x.46522] 
[0.x.46523] 
[0.x.46524] 
[0.x.46525] 
[0.x.46526] 
//
//      /*previous_index= [2.x.5582] 
[0.x.46527] 
[0.x.46528] 
[0.x.46529] 
[0.x.46530] 
[0.x.46531] 
[0.x.46532] 
//
// We initialize the  [2.x.5583]  object in the default configuration for smoothness estimation.
//
[0.x.46533] 
[0.x.46534] 
//
// The next part is going to be tricky. During execution of refinement, a few hp-algorithms need to interfere with the actual refinement process on the Triangulation object. We do this by connecting several functions to  [2.x.5584]  signals will be called at different stages during the actual refinement process and trigger all connected functions. We require this functionality for load balancing and to limit the polynomial degrees of neighboring cells.
//
// For the former, we would like to assign a weight to every cell that is proportional to the number of degrees of freedom of its future finite element. The library offers a class  [2.x.5585]  that allows to easily attach individual weights at the right place during the refinement process, i.e., after all refine and coarsen flags have been set correctly for hp-adaptation and right before repartitioning for load balancing is about to happen. Functions can be registered that will attach weights in the form that  [2.x.5586]  with a provided pair of parameters  [2.x.5587] . We register such a function in the following. Every cell will be charged with a constant weight at creation, which is a value of 1000 (see  [2.x.5588] 
//
// For load balancing, efficient solvers like the one we use should scale linearly with the number of degrees of freedom owned. Further, to increase the impact of the weights we would like to attach, make sure that the individual weight will exceed this base weight by orders of magnitude. We set the parameters for cell weighting correspondingly: A large weighting factor of  [2.x.5589]  and an exponent of  [2.x.5590] .
//
[0.x.46535] 
[0.x.46536] 
[0.x.46537] 
[0.x.46538] 
//
// In h-adaptive applications, we ensure a 2:1 mesh balance by limiting the difference of refinement levels of neighboring cells to one. With the second call in the following code snippet, we will ensure the same for p-levels on neighboring cells: levels of future finite elements are not allowed to differ by more than a specified difference. The function  [2.x.5591]  takes care of this, but needs to be connected to a very specific signal in the parallel context. The issue is that we need to know how the mesh will be actually refined to set future FE indices accordingly. As we ask the p4est oracle to perform refinement, we need to ensure that the Triangulation has been updated with the adaptation flags of the oracle first. An instantiation of  [2.x.5592]  does exactly that for the duration of its life. Thus, we will create an object of this class right before limiting the p-level difference, and connect the corresponding lambda function to the signal  [2.x.5593]  which will be triggered after the oracle got refined, but before the Triangulation is refined. Furthermore, we specify that this function will be connected to the front of the signal, to ensure that the modification is performed before any other function connected to the same signal.
//
[0.x.46539] 
[0.x.46540] 
[0.x.46541] 
[0.x.46542] 
[0.x.46543] 
[0.x.46544] 
//
//                                                 /*contains= [2.x.5594] min_fe_index);
//
[0.x.46545] 
[0.x.46546] 
[0.x.46547] 
//
//  [2.x.5595] 
//
// For a L-shaped domain, we could use the function  [2.x.5596]  as demonstrated in  [2.x.5597] . However in the 2D case, that particular function removes the first quadrant, while we need the fourth quadrant removed in our scenario. Thus, we will use a different function  [2.x.5598]  which gives us more options to create the mesh. Furthermore, we formulate that function in a way that it also generates a 3D mesh: the 2D L-shaped domain will basically elongated by 1 in the positive z-direction.
//
// We first pretend to build a  [2.x.5599]  The parameters that we need to provide are Point objects for the lower left and top right corners, as well as the number of repetitions that the base mesh will have in each direction. We provide them for the first two dimensions and treat the higher third dimension separately.
//
// To create a L-shaped domain, we need to remove the excess cells. For this, we specify the  [2.x.5600]  accordingly. We would like to remove one cell in every cell from the negative direction, but remove one from the positive x-direction.
//
// In the end, we supply the number of initial refinements that corresponds to the supplied minimal grid refinement level. Further, we set the initial active FE indices accordingly.
//
[0.x.46548] 
[0.x.46549] 
[0.x.46550] 
[0.x.46551] 
//
[0.x.46552] 
[0.x.46553] 
[0.x.46554] 
[0.x.46555] 
[0.x.46556] 
[0.x.46557] 
[0.x.46558] 
[0.x.46559] 
[0.x.46560] 
[0.x.46561] 
[0.x.46562] 
[0.x.46563] 
[0.x.46564] 
[0.x.46565] 
[0.x.46566] 
//
[0.x.46567] 
[0.x.46568] 
//
[0.x.46569] 
[0.x.46570] 
//
[0.x.46571] 
//
[0.x.46572] 
[0.x.46573] 
[0.x.46574] 
[0.x.46575] 
[0.x.46576] 
//
//  [2.x.5601] 
//
// This function looks exactly the same to the one of  [2.x.5602] , but you will notice the absence of the system matrix as well as the scaffold that surrounds it. Instead, we will initialize the MatrixFree formulation of the  [2.x.5603]  here. For boundary conditions, we will use the Solution class introduced earlier in this tutorial.
//
[0.x.46577] 
[0.x.46578] 
[0.x.46579] 
[0.x.46580] 
//
[0.x.46581] 
//
[0.x.46582] 
[0.x.46583] 
//
[0.x.46584] 
[0.x.46585] 
[0.x.46586] 
[0.x.46587] 
//
[0.x.46588] 
[0.x.46589] 
[0.x.46590] 
[0.x.46591] 
[0.x.46592] 
[0.x.46593] 
//
[0.x.46594] 
[0.x.46595] 
[0.x.46596] 
[0.x.46597] 
[0.x.46598] 
[0.x.46599] 
//
//  [2.x.5604] 
//
// This is a function that prints additional diagnostics about the equation system and its partitioning. In addition to the usual global number of active cells and degrees of freedom, we also output their local equivalents. For a regulated output, we will communicate the local quantities with a  [2.x.5605]  operation to the first process which will then output all information. Output of local quantities is limited to the first 8 processes to avoid cluttering the terminal.
//
// Furthermore, we would like to print the frequencies of the polynomial degrees in the numerical discretization. Since this information is only stored locally, we will count the finite elements on locally owned cells and later communicate them via  [2.x.5606] 
[0.x.46600] 
[0.x.46601] 
[0.x.46602] 
[0.x.46603] 
[0.x.46604] 
[0.x.46605] 
[0.x.46606] 
[0.x.46607] 
//
[0.x.46608] 
[0.x.46609] 
[0.x.46610] 
[0.x.46611] 
//
[0.x.46612] 
[0.x.46613] 
[0.x.46614] 
[0.x.46615] 
[0.x.46616] 
[0.x.46617] 
[0.x.46618] 
[0.x.46619] 
[0.x.46620] 
//
[0.x.46621] 
[0.x.46622] 
[0.x.46623] 
[0.x.46624] 
//
[0.x.46625] 
[0.x.46626] 
[0.x.46627] 
[0.x.46628] 
[0.x.46629] 
[0.x.46630] 
[0.x.46631] 
[0.x.46632] 
[0.x.46633] 
//
[0.x.46634] 
[0.x.46635] 
[0.x.46636] 
//
[0.x.46637] 
[0.x.46638] 
[0.x.46639] 
[0.x.46640] 
[0.x.46641] 
[0.x.46642] 
[0.x.46643] 
[0.x.46644] 
[0.x.46645] 
[0.x.46646] 
[0.x.46647] 
[0.x.46648] 
//
[0.x.46649] 
[0.x.46650] 
[0.x.46651] 
[0.x.46652] 
[0.x.46653] 
//
[0.x.46654] 
//
[0.x.46655] 
[0.x.46656] 
[0.x.46657] 
[0.x.46658] 
[0.x.46659] 
[0.x.46660] 
[0.x.46661] 
//
//  [2.x.5607] 
//
// The scaffold around the solution is similar to the one of  [2.x.5608] . We prepare a vector that matches the requirements of MatrixFree and collect the locally-relevant degrees of freedoms we solved the equation system. The solution happens with the function introduced earlier.
//
[0.x.46662] 
[0.x.46663] 
[0.x.46664] 
[0.x.46665] 
//
[0.x.46666] 
[0.x.46667] 
//
[0.x.46668] 
[0.x.46669] 
//
[0.x.46670] 
[0.x.46671] 
[0.x.46672] 
[0.x.46673] 
[0.x.46674] 
[0.x.46675] 
[0.x.46676] 
[0.x.46677] 
//
[0.x.46678] 
[0.x.46679] 
//
[0.x.46680] 
//
[0.x.46681] 
[0.x.46682] 
[0.x.46683] 
[0.x.46684] 
//
//  [2.x.5609] 
//
// This function contains only a part of the typical  [2.x.5610]  function from other tutorials and is new in that sense. Here, we will only calculate all indicators for adaptation with actually refining the grid. We do this for the purpose of writing all indicators to the file system, so we store them for later.
//
// Since we are dealing the an elliptic problem, we will make use of the KellyErrorEstimator again, but with a slight difference. Modifying the scaling factor of the underlying face integrals to be dependent on the actual polynomial degree of the neighboring elements is favorable in hp-adaptive applications  [2.x.5611] . We can do this by specifying the very last parameter from the additional ones you notices. The others are actually just the defaults.
//
// For the purpose of hp-adaptation, we will calculate smoothness estimates with the strategy presented in the tutorial introduction and use the implementation in  [2.x.5612]  In the Parameters struct, we set the minimal polynomial degree to 2 as it seems that the smoothness estimation algorithms have trouble with linear elements.
//
[0.x.46685] 
[0.x.46686] 
[0.x.46687] 
[0.x.46688] 
//
[0.x.46689] 
[0.x.46690] 
[0.x.46691] 
[0.x.46692] 
[0.x.46693] 
[0.x.46694] 
[0.x.46695] 
//
//      /*component_mask= [2.x.5613] ComponentMask(),      /*coefficients= [2.x.5614] nullptr,       [2.x.5615] 
//[2.x.5616] 
//[2.x.5617]       /*strategy= [2.x.5618] 
[0.x.46696] 
//
[0.x.46697] 
[0.x.46698] 
[0.x.46699] 
[0.x.46700] 
[0.x.46701] 
[0.x.46702] 
//
//  [2.x.5619] 
//
// With the previously calculated indicators, we will finally flag all cells for adaptation and also execute refinement in this function. As in previous tutorials, we will use the "fixed number" strategy, but now for hp-adaptation.
//
[0.x.46703] 
[0.x.46704] 
[0.x.46705] 
[0.x.46706] 
//
// First, we will set refine and coarsen flags based on the error estimates on each cell. There is nothing new here.
//
// We will use general refine and coarsen fractions that have been elaborated in the other deal.II tutorials: using the fixed number strategy, we will flag 30% of all cells for refinement and 3% for coarsening, as provided in the Parameters struct.
//
[0.x.46707] 
[0.x.46708] 
[0.x.46709] 
[0.x.46710] 
[0.x.46711] 
//
// Next, we will make all adjustments for hp-adaptation. We want to refine and coarsen those cells flagged in the previous step, but need to decide if we would like to do it by adjusting the grid resolution or the polynomial degree.
//
// The next function call sets future FE indices according to the previously calculated smoothness indicators as p-adaptation indicators. These indices will only be set on those cells that have refine or coarsen flags assigned.
//
// For the p-adaptation fractions, we will take an educated guess. Since we only expect a single singularity in our scenario, i.e., in the origin of the domain, and a smooth solution anywhere else, we would like to strongly prefer to use p-adaptation over h-adaptation. This reflects in our choice of a fraction of 90% for both p-refinement and p-coarsening.
//
[0.x.46712] 
[0.x.46713] 
[0.x.46714] 
[0.x.46715] 
//
// At this stage, we have both the future FE indices and the classic refine and coarsen flags set, from which the latter will be interpreted by  [2.x.5620]  for h-adaptation. We would like to only impose one type of adaptation on cells, which is what the next function will sort out for us. In short, on cells which have both types of indicators assigned, we will favor the p-adaptation one and remove the h-adaptation one.
//
[0.x.46716] 
//
// After setting all indicators, we will remove those that exceed the specified limits of the provided level ranges in the Parameters struct. This limitation naturally arises for p-adaptation as the number of supplied finite elements is limited. In addition, we registered a custom hierarchy for p-adaptation in the constructor. Now, we need to do this manually in the h-adaptive context like in  [2.x.5621] .
//
// We will iterate over all cells on the designated min and max levels and remove the corresponding flags. As an alternative, we could also flag these cells for p-adaptation by setting future FE indices accordingly instead of simply clearing the refine and coarsen flags.
//
[0.x.46717] 
[0.x.46718] 
[0.x.46719] 
//
[0.x.46720] 
[0.x.46721] 
[0.x.46722] 
[0.x.46723] 
//
[0.x.46724] 
[0.x.46725] 
[0.x.46726] 
//
// In the end, we are left to execute coarsening and refinement. Here, not only the grid will be updated, but also all previous future FE indices will become active.
//
// Remember that we have attached functions to triangulation signals in the constructor, will be triggered in this function call. So there is even more happening: weighted repartitioning will be performed to ensure load balancing, as well as we will limit the difference of p-levels between neighboring cells.
//
[0.x.46727] 
[0.x.46728] 
//
//  [2.x.5622] 
//
// Writing results to the file system in parallel applications works exactly like in  [2.x.5623] . In addition to the data containers that we prepared throughout the tutorial, we would also like to write out the polynomial degree of each finite element on the grid as well as the subdomain each cell belongs to. We prepare necessary containers for this in the scope of this function.
//
[0.x.46729] 
[0.x.46730] 
[0.x.46731] 
[0.x.46732] 
//
[0.x.46733] 
[0.x.46734] 
[0.x.46735] 
[0.x.46736] 
//
[0.x.46737] 
[0.x.46738] 
[0.x.46739] 
//
[0.x.46740] 
[0.x.46741] 
[0.x.46742] 
[0.x.46743] 
[0.x.46744] 
[0.x.46745] 
[0.x.46746] 
[0.x.46747] 
//
[0.x.46748] 
[0.x.46749] 
[0.x.46750] 
//
//  [2.x.5624] 
//
// The actual run function again looks very familiar to  [2.x.5625] . The only addition is the bracketed section that precedes the actual cycle loop. Here, we will pre-calculate the Legendre transformation matrices. In general, these will be calculated on the fly via lazy allocation whenever a certain matrix is needed. For timing purposes however, we would like to calculate them all at once before the actual time measurement begins. We will thus designate their calculation to their own scope.
//
[0.x.46751] 
[0.x.46752] 
[0.x.46753] 
[0.x.46754] 
[0.x.46755] 
[0.x.46756] 
//
[0.x.46757] 
[0.x.46758] 
[0.x.46759] 
[0.x.46760] 
[0.x.46761] 
//
[0.x.46762] 
[0.x.46763] 
[0.x.46764] 
//
[0.x.46765] 
[0.x.46766] 
[0.x.46767] 
[0.x.46768] 
//
[0.x.46769] 
//
[0.x.46770] 
//
[0.x.46771] 
//
[0.x.46772] 
//
[0.x.46773] 
[0.x.46774] 
//
[0.x.46775] 
[0.x.46776] 
//
[0.x.46777] 
[0.x.46778] 
[0.x.46779] 
[0.x.46780] 
//
//  [2.x.5626] 
//
// The final function is the  [2.x.5627]  function that will ultimately create and run a LaplaceOperator instantiation. Its structure is similar to most other tutorial programs.
//
[0.x.46781] 
[0.x.46782] 
[0.x.46783] 
[0.x.46784] 
[0.x.46785] 
[0.x.46786] 
//
[0.x.46787] 
//
[0.x.46788] 
[0.x.46789] 
[0.x.46790] 
[0.x.46791] 
[0.x.46792] 
[0.x.46793] 
[0.x.46794] 
[0.x.46795] 
[0.x.46796] 
[0.x.46797] 
[0.x.46798] 
[0.x.46799] 
[0.x.46800] 
[0.x.46801] 
[0.x.46802] 
//
[0.x.46803] 
[0.x.46804] 
[0.x.46805] 
[0.x.46806] 
[0.x.46807] 
[0.x.46808] 
[0.x.46809] 
[0.x.46810] 
[0.x.46811] 
[0.x.46812] 
[0.x.46813] 
[0.x.46814] 
[0.x.46815] 
[0.x.46816] 
//
[0.x.46817] 
[0.x.46818] 
[0.x.46819] 
[0.x.46820] 
[0.x.46821] 
[0.x.46822] 
[0.x.46823] 
[0.x.46824] 
[0.x.46825] 
[0.x.46826] 
[0.x.46827] 
[0.x.46828] 
[0.x.46829] 
[0.x.46830] 
[0.x.46831] 
[0.x.46832] 
//
[0.x.46833] 
[0.x.46834] 
[0.x.46835] 
//[2.x.5628] 
//
// The same includes as in  [2.x.5629] :
//
[0.x.46836] 
[0.x.46837] 
[0.x.46838] 
[0.x.46839] 
[0.x.46840] 
[0.x.46841] 
[0.x.46842] 
//
[0.x.46843] 
//
[0.x.46844] 
//
[0.x.46845] 
[0.x.46846] 
//
[0.x.46847] 
[0.x.46848] 
[0.x.46849] 
[0.x.46850] 
//
[0.x.46851] 
[0.x.46852] 
//
[0.x.46853] 
[0.x.46854] 
[0.x.46855] 
//
[0.x.46856] 
//
[0.x.46857] 
[0.x.46858] 
[0.x.46859] 
//
// A new include for categorizing of cells according to their boundary IDs:
//
[0.x.46860] 
//
[0.x.46861] 
[0.x.46862] 
[0.x.46863] 
//
// The same input parameters as in  [2.x.5630] :
//
[0.x.46864] 
[0.x.46865] 
[0.x.46866] 
[0.x.46867] 
[0.x.46868] 
//
// This parameter specifies the size of the shared-memory group. Currently, only the values 1 and  [2.x.5631]  is possible, leading to the options that the memory features can be turned off or all processes having access to the same shared-memory domain are grouped together.
//
[0.x.46869] 
//
[0.x.46870] 
//
// Here, the type of the data structure is chosen for vectorization. In the default case, VectorizedArray<Number> is used, i.e., the highest instruction-set-architecture extension available on the given hardware with the maximum number of vector lanes is used. However, one might reduce the number of filled lanes, e.g., by writing  [2.x.5632]  to only process 4 cells.
//
[0.x.46871] 
//
// The following parameters have not changed:
//
[0.x.46872] 
[0.x.46873] 
[0.x.46874] 
//
[0.x.46875] 
//
// Specify max number of time steps useful for performance studies.
//
[0.x.46876] 
//
// Runge-Kutta-related functions copied from  [2.x.5633]  and slightly modified with the purpose to minimize global vector access:
//
[0.x.46877] 
[0.x.46878] 
[0.x.46879] 
[0.x.46880] 
[0.x.46881] 
[0.x.46882] 
[0.x.46883] 
[0.x.46884] 
//
[0.x.46885] 
[0.x.46886] 
[0.x.46887] 
[0.x.46888] 
[0.x.46889] 
[0.x.46890] 
[0.x.46891] 
[0.x.46892] 
[0.x.46893] 
[0.x.46894] 
[0.x.46895] 
[0.x.46896] 
[0.x.46897] 
[0.x.46898] 
[0.x.46899] 
[0.x.46900] 
[0.x.46901] 
[0.x.46902] 
[0.x.46903] 
[0.x.46904] 
//
[0.x.46905] 
[0.x.46906] 
[0.x.46907] 
[0.x.46908] 
[0.x.46909] 
[0.x.46910] 
[0.x.46911] 
[0.x.46912] 
[0.x.46913] 
//
[0.x.46914] 
[0.x.46915] 
[0.x.46916] 
[0.x.46917] 
//
[0.x.46918] 
[0.x.46919] 
[0.x.46920] 
[0.x.46921] 
[0.x.46922] 
[0.x.46923] 
[0.x.46924] 
[0.x.46925] 
[0.x.46926] 
//
[0.x.46927] 
//
[0.x.46928] 
[0.x.46929] 
[0.x.46930] 
[0.x.46931] 
//
[0.x.46932] 
[0.x.46933] 
[0.x.46934] 
[0.x.46935] 
[0.x.46936] 
[0.x.46937] 
[0.x.46938] 
[0.x.46939] 
[0.x.46940] 
//
[0.x.46941] 
[0.x.46942] 
[0.x.46943] 
[0.x.46944] 
//
[0.x.46945] 
[0.x.46946] 
[0.x.46947] 
[0.x.46948] 
//
// Euler-specific utility functions from  [2.x.5634] :
//
[0.x.46949] 
[0.x.46950] 
[0.x.46951] 
[0.x.46952] 
[0.x.46953] 
[0.x.46954] 
//
[0.x.46955] 
[0.x.46956] 
[0.x.46957] 
[0.x.46958] 
[0.x.46959] 
[0.x.46960] 
[0.x.46961] 
//
[0.x.46962] 
[0.x.46963] 
[0.x.46964] 
//
[0.x.46965] 
[0.x.46966] 
[0.x.46967] 
[0.x.46968] 
[0.x.46969] 
//
[0.x.46970] 
[0.x.46971] 
[0.x.46972] 
[0.x.46973] 
[0.x.46974] 
[0.x.46975] 
//
[0.x.46976] 
[0.x.46977] 
[0.x.46978] 
[0.x.46979] 
[0.x.46980] 
[0.x.46981] 
[0.x.46982] 
[0.x.46983] 
[0.x.46984] 
[0.x.46985] 
[0.x.46986] 
//
[0.x.46987] 
[0.x.46988] 
[0.x.46989] 
[0.x.46990] 
[0.x.46991] 
[0.x.46992] 
[0.x.46993] 
[0.x.46994] 
[0.x.46995] 
[0.x.46996] 
[0.x.46997] 
[0.x.46998] 
[0.x.46999] 
[0.x.47000] 
//
[0.x.47001] 
[0.x.47002] 
[0.x.47003] 
[0.x.47004] 
[0.x.47005] 
[0.x.47006] 
[0.x.47007] 
[0.x.47008] 
[0.x.47009] 
[0.x.47010] 
[0.x.47011] 
//
[0.x.47012] 
[0.x.47013] 
[0.x.47014] 
[0.x.47015] 
[0.x.47016] 
//
[0.x.47017] 
[0.x.47018] 
[0.x.47019] 
[0.x.47020] 
[0.x.47021] 
[0.x.47022] 
//
[0.x.47023] 
[0.x.47024] 
[0.x.47025] 
//
[0.x.47026] 
[0.x.47027] 
//
[0.x.47028] 
[0.x.47029] 
[0.x.47030] 
[0.x.47031] 
[0.x.47032] 
[0.x.47033] 
[0.x.47034] 
//
[0.x.47035] 
[0.x.47036] 
[0.x.47037] 
//
[0.x.47038] 
[0.x.47039] 
//
[0.x.47040] 
[0.x.47041] 
[0.x.47042] 
[0.x.47043] 
[0.x.47044] 
[0.x.47045] 
[0.x.47046] 
[0.x.47047] 
//
[0.x.47048] 
[0.x.47049] 
[0.x.47050] 
[0.x.47051] 
[0.x.47052] 
[0.x.47053] 
[0.x.47054] 
[0.x.47055] 
[0.x.47056] 
[0.x.47057] 
//
[0.x.47058] 
[0.x.47059] 
//
[0.x.47060] 
[0.x.47061] 
[0.x.47062] 
[0.x.47063] 
[0.x.47064] 
[0.x.47065] 
[0.x.47066] 
[0.x.47067] 
[0.x.47068] 
[0.x.47069] 
[0.x.47070] 
//
[0.x.47071] 
[0.x.47072] 
[0.x.47073] 
[0.x.47074] 
[0.x.47075] 
[0.x.47076] 
[0.x.47077] 
[0.x.47078] 
[0.x.47079] 
//
[0.x.47080] 
[0.x.47081] 
//
[0.x.47082] 
[0.x.47083] 
//
[0.x.47084] 
[0.x.47085] 
[0.x.47086] 
[0.x.47087] 
[0.x.47088] 
[0.x.47089] 
[0.x.47090] 
[0.x.47091] 
[0.x.47092] 
//
[0.x.47093] 
[0.x.47094] 
[0.x.47095] 
//
[0.x.47096] 
[0.x.47097] 
[0.x.47098] 
[0.x.47099] 
[0.x.47100] 
[0.x.47101] 
[0.x.47102] 
[0.x.47103] 
[0.x.47104] 
[0.x.47105] 
[0.x.47106] 
[0.x.47107] 
//
[0.x.47108] 
[0.x.47109] 
[0.x.47110] 
[0.x.47111] 
//
[0.x.47112] 
[0.x.47113] 
[0.x.47114] 
[0.x.47115] 
[0.x.47116] 
[0.x.47117] 
[0.x.47118] 
//
// General-purpose utility functions from  [2.x.5635] :
//
[0.x.47119] 
[0.x.47120] 
[0.x.47121] 
[0.x.47122] 
[0.x.47123] 
[0.x.47124] 
[0.x.47125] 
[0.x.47126] 
[0.x.47127] 
[0.x.47128] 
[0.x.47129] 
[0.x.47130] 
[0.x.47131] 
[0.x.47132] 
[0.x.47133] 
[0.x.47134] 
//
[0.x.47135] 
[0.x.47136] 
[0.x.47137] 
[0.x.47138] 
[0.x.47139] 
[0.x.47140] 
[0.x.47141] 
[0.x.47142] 
[0.x.47143] 
[0.x.47144] 
[0.x.47145] 
[0.x.47146] 
[0.x.47147] 
[0.x.47148] 
[0.x.47149] 
[0.x.47150] 
[0.x.47151] 
//[2.x.5636] 
//
// Euler operator from  [2.x.5637]  with some changes as detailed below:
//
[0.x.47152] 
[0.x.47153] 
[0.x.47154] 
[0.x.47155] 
[0.x.47156] 
//
[0.x.47157] 
//
[0.x.47158] 
//
[0.x.47159] 
[0.x.47160] 
//
[0.x.47161] 
[0.x.47162] 
//
[0.x.47163] 
[0.x.47164] 
[0.x.47165] 
//
[0.x.47166] 
//
[0.x.47167] 
//
[0.x.47168] 
[0.x.47169] 
[0.x.47170] 
[0.x.47171] 
[0.x.47172] 
[0.x.47173] 
[0.x.47174] 
[0.x.47175] 
//
[0.x.47176] 
[0.x.47177] 
//
[0.x.47178] 
[0.x.47179] 
[0.x.47180] 
//
[0.x.47181] 
[0.x.47182] 
//
[0.x.47183] 
[0.x.47184] 
//
[0.x.47185] 
//
// Instance of SubCommunicatorWrapper containing the sub-communicator, which we need to pass to  [2.x.5638]  to be able to exploit MPI-3.0 shared-memory capabilities:
//
[0.x.47186] 
//
[0.x.47187] 
//
[0.x.47188] 
//
[0.x.47189] 
[0.x.47190] 
[0.x.47191] 
[0.x.47192] 
[0.x.47193] 
[0.x.47194] 
[0.x.47195] 
//
// New constructor, which creates a sub-communicator. The user can specify the size of the sub-communicator via the global parameter group_size. If the size is set to -1, all MPI processes of a shared-memory domain are combined to a group. The specified size is decisive for the benefit of the shared-memory capabilities of MatrixFree and, therefore, setting the  [2.x.5639]  is a reasonable choice. By setting, the size to  [2.x.5640]  users explicitly disable the MPI-3.0 shared-memory features of MatrixFree and rely completely on MPI-2.0 features, like  [2.x.5641]  and  [2.x.5642] .
//
[0.x.47196] 
[0.x.47197] 
[0.x.47198] 
[0.x.47199] 
[0.x.47200] 
[0.x.47201] 
[0.x.47202] 
[0.x.47203] 
[0.x.47204] 
[0.x.47205] 
[0.x.47206] 
[0.x.47207] 
//
[0.x.47208] 
[0.x.47209] 
[0.x.47210] 
[0.x.47211] 
[0.x.47212] 
[0.x.47213] 
[0.x.47214] 
[0.x.47215] 
[0.x.47216] 
[0.x.47217] 
[0.x.47218] 
[0.x.47219] 
[0.x.47220] 
[0.x.47221] 
[0.x.47222] 
[0.x.47223] 
//
// New destructor responsible for freeing of the sub-communicator.
//
[0.x.47224] 
[0.x.47225] 
[0.x.47226] 
[0.x.47227] 
[0.x.47228] 
[0.x.47229] 
[0.x.47230] 
[0.x.47231] 
//
// Modified reinit() function to setup the internal data structures in MatrixFree in a way that it is usable by the cell-centric loops and the MPI-3.0 shared-memory capabilities are used:
//
[0.x.47232] 
[0.x.47233] 
[0.x.47234] 
[0.x.47235] 
[0.x.47236] 
[0.x.47237] 
[0.x.47238] 
[0.x.47239] 
[0.x.47240] 
[0.x.47241] 
//
[0.x.47242] 
[0.x.47243] 
[0.x.47244] 
[0.x.47245] 
[0.x.47246] 
[0.x.47247] 
[0.x.47248] 
[0.x.47249] 
[0.x.47250] 
[0.x.47251] 
[0.x.47252] 
[0.x.47253] 
[0.x.47254] 
//
// Categorize cells so that all lanes have the same boundary IDs for each face. This is strictly not necessary, however, allows to write simpler code in  [2.x.5643]  without masking, since it is guaranteed that all cells grouped together (in a VectorizedArray) have to perform exactly the same operation also on the faces.
//
[0.x.47255] 
[0.x.47256] 
//
// Enable MPI-3.0 shared-memory capabilities within MatrixFree by providing the sub-communicator:
//
[0.x.47257] 
//
[0.x.47258] 
[0.x.47259] 
[0.x.47260] 
//
// The following function does an entire stage of a Runge--Kutta update and is
//
// - alongside the slightly modified setup
//
// - the heart of this tutorial compared to  [2.x.5644] .
//
// In contrast to  [2.x.5645] , we are not executing the advection step (using  [2.x.5646]  and the inverse mass-matrix step (using  [2.x.5647]  in sequence, but evaluate everything in one go inside of  [2.x.5648]  This function expects a single function that is executed on each locally-owned (macro) cell as parameter so that we need to loop over all faces of that cell and perform needed integration steps on our own.
//
// The following function contains to a large extent copies of the following functions from  [2.x.5649]  so that comments related the evaluation of the weak form are skipped here:
//
// -  [2.x.5650] 
//
// -  [2.x.5651] 
//
// -  [2.x.5652] 
//
// -  [2.x.5653] 
[0.x.47261] 
[0.x.47262] 
[0.x.47263] 
[0.x.47264] 
[0.x.47265] 
[0.x.47266] 
[0.x.47267] 
[0.x.47268] 
[0.x.47269] 
[0.x.47270] 
[0.x.47271] 
[0.x.47272] 
[0.x.47273] 
[0.x.47274] 
//
// Run a cell-centric loop by calling  [2.x.5654]  and providing a lambda containing the effects of the cell, face and boundary-face integrals:
//
[0.x.47275] 
[0.x.47276] 
[0.x.47277] 
[0.x.47278] 
[0.x.47279] 
[0.x.47280] 
[0.x.47281] 
[0.x.47282] 
[0.x.47283] 
[0.x.47284] 
[0.x.47285] 
[0.x.47286] 
[0.x.47287] 
[0.x.47288] 
[0.x.47289] 
//
[0.x.47290] 
[0.x.47291] 
[0.x.47292] 
[0.x.47293] 
//
[0.x.47294] 
[0.x.47295] 
[0.x.47296] 
//
[0.x.47297] 
[0.x.47298] 
[0.x.47299] 
[0.x.47300] 
//
[0.x.47301] 
[0.x.47302] 
[0.x.47303] 
[0.x.47304] 
[0.x.47305] 
[0.x.47306] 
[0.x.47307] 
[0.x.47308] 
[0.x.47309] 
//
[0.x.47310] 
[0.x.47311] 
//
// Loop over all cell batches:
//
[0.x.47312] 
[0.x.47313] 
[0.x.47314] 
[0.x.47315] 
//
[0.x.47316] 
[0.x.47317] 
//
//   Read values from global vector and compute the values at the   quadrature points:
//
[0.x.47318] 
[0.x.47319] 
[0.x.47320] 
//
[0.x.47321] 
[0.x.47322] 
[0.x.47323] 
[0.x.47324] 
//
[0.x.47325] 
[0.x.47326] 
[0.x.47327] 
[0.x.47328] 
[0.x.47329] 
[0.x.47330] 
//
//   Buffer the computed values at the quadrature points, since   these are overridden by  [2.x.5655]  in the next   step, however, are needed later on for the face integrals:
//
[0.x.47331] 
[0.x.47332] 
//
//   Apply the cell integral at the cell quadrature points. See also   the function  [2.x.5656]  from    [2.x.5657] :
//
[0.x.47333] 
[0.x.47334] 
[0.x.47335] 
[0.x.47336] 
[0.x.47337] 
[0.x.47338] 
[0.x.47339] 
[0.x.47340] 
[0.x.47341] 
[0.x.47342] 
[0.x.47343] 
//
[0.x.47344] 
[0.x.47345] 
[0.x.47346] 
[0.x.47347] 
[0.x.47348] 
//
[0.x.47349] 
[0.x.47350] 
[0.x.47351] 
//
//   Test with the gradient of the test functions in the quadrature   points. We skip the interpolation back to the support points   of the element, since we first collect all contributions in the   cell quadrature points and only perform the interpolation back   as the final step.
//
[0.x.47352] 
[0.x.47353] 
[0.x.47354] 
//
[0.x.47355] 
[0.x.47356] 
[0.x.47357] 
[0.x.47358] 
[0.x.47359] 
[0.x.47360] 
[0.x.47361] 
[0.x.47362] 
[0.x.47363] 
[0.x.47364] 
[0.x.47365] 
[0.x.47366] 
[0.x.47367] 
[0.x.47368] 
//
[0.x.47369] 
[0.x.47370] 
[0.x.47371] 
[0.x.47372] 
//
//   Loop over all faces of the current cell:
//
[0.x.47373] 
[0.x.47374] 
[0.x.47375] 
[0.x.47376] 
//
//       Determine the boundary ID of the current face. Since we have       set up MatrixFree in a way that all filled lanes have       guaranteed the same boundary ID, we can select the       boundary ID of the first lane.
//
[0.x.47377] 
[0.x.47378] 
//
[0.x.47379] 
[0.x.47380] 
[0.x.47381] 
[0.x.47382] 
[0.x.47383] 
//
[0.x.47384] 
//
[0.x.47385] 
//
//       Interpolate the values from the cell quadrature points to the       quadrature points of the current face via a simple 1D       interpolation:
//
[0.x.47386] 
[0.x.47387] 
[0.x.47388] 
[0.x.47389] 
[0.x.47390] 
[0.x.47391] 
[0.x.47392] 
[0.x.47393] 
[0.x.47394] 
[0.x.47395] 
//
//       Check if the face is an internal or a boundary face and       select a different code path based on this information:
//
[0.x.47396] 
[0.x.47397] 
//
//           Process and internal face. The following lines of code           are a copy of the function            [2.x.5658]            from  [2.x.5659] :
//
[0.x.47398] 
[0.x.47399] 
//
[0.x.47400] 
[0.x.47401] 
[0.x.47402] 
[0.x.47403] 
[0.x.47404] 
[0.x.47405] 
[0.x.47406] 
[0.x.47407] 
[0.x.47408] 
[0.x.47409] 
[0.x.47410] 
//
//           Process a boundary face. These following lines of code           are a copy of the function            [2.x.5660]            from  [2.x.5661] :
//
[0.x.47411] 
[0.x.47412] 
[0.x.47413] 
[0.x.47414] 
//
[0.x.47415] 
[0.x.47416] 
[0.x.47417] 
//
[0.x.47418] 
//
[0.x.47419] 
//
[0.x.47420] 
[0.x.47421] 
[0.x.47422] 
[0.x.47423] 
[0.x.47424] 
[0.x.47425] 
[0.x.47426] 
[0.x.47427] 
[0.x.47428] 
[0.x.47429] 
[0.x.47430] 
[0.x.47431] 
[0.x.47432] 
[0.x.47433] 
[0.x.47434] 
[0.x.47435] 
[0.x.47436] 
[0.x.47437] 
[0.x.47438] 
[0.x.47439] 
[0.x.47440] 
[0.x.47441] 
[0.x.47442] 
[0.x.47443] 
[0.x.47444] 
[0.x.47445] 
[0.x.47446] 
[0.x.47447] 
[0.x.47448] 
[0.x.47449] 
[0.x.47450] 
[0.x.47451] 
[0.x.47452] 
//
[0.x.47453] 
//
[0.x.47454] 
[0.x.47455] 
[0.x.47456] 
[0.x.47457] 
[0.x.47458] 
[0.x.47459] 
[0.x.47460] 
[0.x.47461] 
[0.x.47462] 
//
[0.x.47463] 
[0.x.47464] 
[0.x.47465] 
//
//       Evaluate local integrals related to cell by quadrature and       add into cell contribution via a simple 1D interpolation:
//
[0.x.47466] 
[0.x.47467] 
[0.x.47468] 
[0.x.47469] 
[0.x.47470] 
[0.x.47471] 
[0.x.47472] 
[0.x.47473] 
[0.x.47474] 
[0.x.47475] 
[0.x.47476] 
//
//   Apply inverse mass matrix in the cell quadrature points. See   also the function    [2.x.5662]    from  [2.x.5663] :
//
[0.x.47477] 
[0.x.47478] 
[0.x.47479] 
[0.x.47480] 
[0.x.47481] 
[0.x.47482] 
[0.x.47483] 
//
//   Transform values from collocation space to the original   Gauss-Lobatto space:
//
[0.x.47484] 
[0.x.47485] 
[0.x.47486] 
[0.x.47487] 
[0.x.47488] 
[0.x.47489] 
[0.x.47490] 
[0.x.47491] 
[0.x.47492] 
[0.x.47493] 
[0.x.47494] 
[0.x.47495] 
[0.x.47496] 
[0.x.47497] 
//
//   Perform Runge-Kutta update and write results back to global   vectors:
//
[0.x.47498] 
[0.x.47499] 
[0.x.47500] 
[0.x.47501] 
[0.x.47502] 
[0.x.47503] 
[0.x.47504] 
[0.x.47505] 
[0.x.47506] 
[0.x.47507] 
//
[0.x.47508] 
[0.x.47509] 
[0.x.47510] 
//
[0.x.47511] 
[0.x.47512] 
//
[0.x.47513] 
[0.x.47514] 
[0.x.47515] 
[0.x.47516] 
[0.x.47517] 
[0.x.47518] 
[0.x.47519] 
[0.x.47520] 
[0.x.47521] 
[0.x.47522] 
[0.x.47523] 
[0.x.47524] 
//
// From here, the code of  [2.x.5664]  has not changed.
//
[0.x.47525] 
[0.x.47526] 
[0.x.47527] 
[0.x.47528] 
[0.x.47529] 
[0.x.47530] 
//
[0.x.47531] 
[0.x.47532] 
[0.x.47533] 
[0.x.47534] 
[0.x.47535] 
[0.x.47536] 
[0.x.47537] 
[0.x.47538] 
[0.x.47539] 
[0.x.47540] 
[0.x.47541] 
[0.x.47542] 
[0.x.47543] 
[0.x.47544] 
//
[0.x.47545] 
[0.x.47546] 
//
[0.x.47547] 
[0.x.47548] 
[0.x.47549] 
[0.x.47550] 
[0.x.47551] 
[0.x.47552] 
[0.x.47553] 
[0.x.47554] 
[0.x.47555] 
[0.x.47556] 
[0.x.47557] 
[0.x.47558] 
[0.x.47559] 
[0.x.47560] 
//
[0.x.47561] 
[0.x.47562] 
//
[0.x.47563] 
[0.x.47564] 
[0.x.47565] 
[0.x.47566] 
[0.x.47567] 
[0.x.47568] 
[0.x.47569] 
[0.x.47570] 
[0.x.47571] 
[0.x.47572] 
[0.x.47573] 
[0.x.47574] 
//
[0.x.47575] 
[0.x.47576] 
//
[0.x.47577] 
[0.x.47578] 
[0.x.47579] 
[0.x.47580] 
[0.x.47581] 
//
[0.x.47582] 
[0.x.47583] 
//
[0.x.47584] 
[0.x.47585] 
[0.x.47586] 
[0.x.47587] 
[0.x.47588] 
[0.x.47589] 
[0.x.47590] 
[0.x.47591] 
[0.x.47592] 
[0.x.47593] 
[0.x.47594] 
[0.x.47595] 
[0.x.47596] 
[0.x.47597] 
[0.x.47598] 
[0.x.47599] 
[0.x.47600] 
[0.x.47601] 
[0.x.47602] 
[0.x.47603] 
[0.x.47604] 
[0.x.47605] 
[0.x.47606] 
[0.x.47607] 
[0.x.47608] 
[0.x.47609] 
[0.x.47610] 
//
[0.x.47611] 
[0.x.47612] 
[0.x.47613] 
[0.x.47614] 
[0.x.47615] 
[0.x.47616] 
[0.x.47617] 
[0.x.47618] 
[0.x.47619] 
//
[0.x.47620] 
[0.x.47621] 
[0.x.47622] 
[0.x.47623] 
[0.x.47624] 
[0.x.47625] 
[0.x.47626] 
[0.x.47627] 
[0.x.47628] 
[0.x.47629] 
[0.x.47630] 
//
[0.x.47631] 
[0.x.47632] 
[0.x.47633] 
[0.x.47634] 
[0.x.47635] 
[0.x.47636] 
[0.x.47637] 
[0.x.47638] 
[0.x.47639] 
[0.x.47640] 
//
[0.x.47641] 
//
[0.x.47642] 
[0.x.47643] 
[0.x.47644] 
//
[0.x.47645] 
[0.x.47646] 
//
[0.x.47647] 
[0.x.47648] 
[0.x.47649] 
[0.x.47650] 
[0.x.47651] 
[0.x.47652] 
[0.x.47653] 
[0.x.47654] 
//
[0.x.47655] 
[0.x.47656] 
[0.x.47657] 
[0.x.47658] 
[0.x.47659] 
[0.x.47660] 
[0.x.47661] 
[0.x.47662] 
[0.x.47663] 
[0.x.47664] 
//
[0.x.47665] 
[0.x.47666] 
[0.x.47667] 
[0.x.47668] 
[0.x.47669] 
[0.x.47670] 
//
[0.x.47671] 
[0.x.47672] 
//
[0.x.47673] 
[0.x.47674] 
[0.x.47675] 
[0.x.47676] 
[0.x.47677] 
[0.x.47678] 
[0.x.47679] 
[0.x.47680] 
[0.x.47681] 
[0.x.47682] 
[0.x.47683] 
[0.x.47684] 
[0.x.47685] 
[0.x.47686] 
[0.x.47687] 
[0.x.47688] 
[0.x.47689] 
[0.x.47690] 
[0.x.47691] 
[0.x.47692] 
//
[0.x.47693] 
[0.x.47694] 
[0.x.47695] 
[0.x.47696] 
[0.x.47697] 
//
[0.x.47698] 
//
[0.x.47699] 
[0.x.47700] 
//
[0.x.47701] 
[0.x.47702] 
[0.x.47703] 
[0.x.47704] 
[0.x.47705] 
//
[0.x.47706] 
//
[0.x.47707] 
[0.x.47708] 
//
[0.x.47709] 
//
[0.x.47710] 
//
[0.x.47711] 
//
[0.x.47712] 
[0.x.47713] 
[0.x.47714] 
[0.x.47715] 
[0.x.47716] 
//
[0.x.47717] 
[0.x.47718] 
[0.x.47719] 
//
[0.x.47720] 
//
[0.x.47721] 
//
[0.x.47722] 
//
[0.x.47723] 
[0.x.47724] 
[0.x.47725] 
[0.x.47726] 
//
[0.x.47727] 
[0.x.47728] 
[0.x.47729] 
//
[0.x.47730] 
//
[0.x.47731] 
[0.x.47732] 
[0.x.47733] 
//
[0.x.47734] 
//
[0.x.47735] 
[0.x.47736] 
[0.x.47737] 
[0.x.47738] 
//
[0.x.47739] 
[0.x.47740] 
[0.x.47741] 
[0.x.47742] 
//
[0.x.47743] 
[0.x.47744] 
[0.x.47745] 
[0.x.47746] 
[0.x.47747] 
[0.x.47748] 
//
[0.x.47749] 
[0.x.47750] 
[0.x.47751] 
//
[0.x.47752] 
[0.x.47753] 
[0.x.47754] 
[0.x.47755] 
[0.x.47756] 
[0.x.47757] 
//
[0.x.47758] 
[0.x.47759] 
[0.x.47760] 
[0.x.47761] 
[0.x.47762] 
//
[0.x.47763] 
[0.x.47764] 
[0.x.47765] 
//
[0.x.47766] 
[0.x.47767] 
[0.x.47768] 
[0.x.47769] 
//
[0.x.47770] 
[0.x.47771] 
[0.x.47772] 
[0.x.47773] 
[0.x.47774] 
//
[0.x.47775] 
[0.x.47776] 
[0.x.47777] 
[0.x.47778] 
[0.x.47779] 
[0.x.47780] 
[0.x.47781] 
[0.x.47782] 
//
[0.x.47783] 
[0.x.47784] 
//
[0.x.47785] 
[0.x.47786] 
//
[0.x.47787] 
[0.x.47788] 
[0.x.47789] 
[0.x.47790] 
[0.x.47791] 
[0.x.47792] 
[0.x.47793] 
[0.x.47794] 
[0.x.47795] 
[0.x.47796] 
[0.x.47797] 
//
[0.x.47798] 
[0.x.47799] 
[0.x.47800] 
//
[0.x.47801] 
[0.x.47802] 
//
[0.x.47803] 
[0.x.47804] 
[0.x.47805] 
[0.x.47806] 
[0.x.47807] 
[0.x.47808] 
[0.x.47809] 
[0.x.47810] 
//
[0.x.47811] 
[0.x.47812] 
[0.x.47813] 
[0.x.47814] 
[0.x.47815] 
[0.x.47816] 
[0.x.47817] 
[0.x.47818] 
[0.x.47819] 
[0.x.47820] 
[0.x.47821] 
[0.x.47822] 
[0.x.47823] 
[0.x.47824] 
//
[0.x.47825] 
[0.x.47826] 
[0.x.47827] 
[0.x.47828] 
[0.x.47829] 
[0.x.47830] 
[0.x.47831] 
[0.x.47832] 
[0.x.47833] 
[0.x.47834] 
//
[0.x.47835] 
[0.x.47836] 
[0.x.47837] 
[0.x.47838] 
//
[0.x.47839] 
[0.x.47840] 
[0.x.47841] 
[0.x.47842] 
//
[0.x.47843] 
[0.x.47844] 
//
[0.x.47845] 
[0.x.47846] 
//
[0.x.47847] 
[0.x.47848] 
[0.x.47849] 
[0.x.47850] 
//
[0.x.47851] 
[0.x.47852] 
[0.x.47853] 
[0.x.47854] 
//
[0.x.47855] 
[0.x.47856] 
//
[0.x.47857] 
[0.x.47858] 
[0.x.47859] 
[0.x.47860] 
//
[0.x.47861] 
[0.x.47862] 
//
[0.x.47863] 
[0.x.47864] 
[0.x.47865] 
//
[0.x.47866] 
//
[0.x.47867] 
//
[0.x.47868] 
[0.x.47869] 
//
[0.x.47870] 
[0.x.47871] 
[0.x.47872] 
[0.x.47873] 
[0.x.47874] 
[0.x.47875] 
[0.x.47876] 
[0.x.47877] 
[0.x.47878] 
//
[0.x.47879] 
[0.x.47880] 
[0.x.47881] 
[0.x.47882] 
[0.x.47883] 
[0.x.47884] 
//
[0.x.47885] 
[0.x.47886] 
[0.x.47887] 
[0.x.47888] 
[0.x.47889] 
[0.x.47890] 
//
[0.x.47891] 
[0.x.47892] 
//
[0.x.47893] 
[0.x.47894] 
//
[0.x.47895] 
[0.x.47896] 
[0.x.47897] 
//
[0.x.47898] 
[0.x.47899] 
[0.x.47900] 
[0.x.47901] 
[0.x.47902] 
[0.x.47903] 
[0.x.47904] 
//
[0.x.47905] 
[0.x.47906] 
[0.x.47907] 
[0.x.47908] 
[0.x.47909] 
[0.x.47910] 
[0.x.47911] 
[0.x.47912] 
[0.x.47913] 
//
[0.x.47914] 
[0.x.47915] 
[0.x.47916] 
//
[0.x.47917] 
[0.x.47918] 
[0.x.47919] 
[0.x.47920] 
[0.x.47921] 
[0.x.47922] 
[0.x.47923] 
[0.x.47924] 
[0.x.47925] 
[0.x.47926] 
[0.x.47927] 
//
[0.x.47928] 
[0.x.47929] 
[0.x.47930] 
[0.x.47931] 
[0.x.47932] 
[0.x.47933] 
[0.x.47934] 
[0.x.47935] 
[0.x.47936] 
//
[0.x.47937] 
[0.x.47938] 
[0.x.47939] 
[0.x.47940] 
[0.x.47941] 
//
[0.x.47942] 
[0.x.47943] 
[0.x.47944] 
//
[0.x.47945] 
[0.x.47946] 
[0.x.47947] 
//
[0.x.47948] 
[0.x.47949] 
[0.x.47950] 
[0.x.47951] 
[0.x.47952] 
//
[0.x.47953] 
[0.x.47954] 
[0.x.47955] 
[0.x.47956] 
[0.x.47957] 
[0.x.47958] 
//
[0.x.47959] 
[0.x.47960] 
[0.x.47961] 
[0.x.47962] 
[0.x.47963] 
[0.x.47964] 
[0.x.47965] 
[0.x.47966] 
[0.x.47967] 
//
[0.x.47968] 
//
[0.x.47969] 
//
[0.x.47970] 
[0.x.47971] 
[0.x.47972] 
[0.x.47973] 
//
[0.x.47974] 
//
[0.x.47975] 
[0.x.47976] 
[0.x.47977] 
[0.x.47978] 
[0.x.47979] 
[0.x.47980] 
[0.x.47981] 
//
[0.x.47982] 
[0.x.47983] 
[0.x.47984] 
[0.x.47985] 
[0.x.47986] 
[0.x.47987] 
[0.x.47988] 
[0.x.47989] 
//
[0.x.47990] 
//
[0.x.47991] 
//
[0.x.47992] 
[0.x.47993] 
[0.x.47994] 
[0.x.47995] 
[0.x.47996] 
[0.x.47997] 
[0.x.47998] 
[0.x.47999] 
//
[0.x.48000] 
[0.x.48001] 
[0.x.48002] 
[0.x.48003] 
[0.x.48004] 
[0.x.48005] 
[0.x.48006] 
[0.x.48007] 
[0.x.48008] 
//
[0.x.48009] 
//
[0.x.48010] 
[0.x.48011] 
[0.x.48012] 
[0.x.48013] 
[0.x.48014] 
[0.x.48015] 
//
[0.x.48016] 
[0.x.48017] 
[0.x.48018] 
//
[0.x.48019] 
//
[0.x.48020] 
[0.x.48021] 
[0.x.48022] 
[0.x.48023] 
//
[0.x.48024] 
//
[0.x.48025] 
[0.x.48026] 
[0.x.48027] 
//
[0.x.48028] 
[0.x.48029] 
[0.x.48030] 
[0.x.48031] 
[0.x.48032] 
[0.x.48033] 
[0.x.48034] 
[0.x.48035] 
[0.x.48036] 
[0.x.48037] 
[0.x.48038] 
[0.x.48039] 
[0.x.48040] 
[0.x.48041] 
//
[0.x.48042] 
[0.x.48043] 
[0.x.48044] 
[0.x.48045] 
[0.x.48046] 
[0.x.48047] 
[0.x.48048] 
[0.x.48049] 
[0.x.48050] 
[0.x.48051] 
[0.x.48052] 
[0.x.48053] 
[0.x.48054] 
[0.x.48055] 
//
[0.x.48056] 
[0.x.48057] 
[0.x.48058] 
[0.x.48059] 
[0.x.48060] 
[0.x.48061] 
[0.x.48062] 
[0.x.48063] 
[0.x.48064] 
[0.x.48065] 
[0.x.48066] 
[0.x.48067] 
[0.x.48068] 
[0.x.48069] 
[0.x.48070] 
[0.x.48071] 
//
[0.x.48072] 
[0.x.48073] 
[0.x.48074] 
[0.x.48075] 
//[2.x.5665] 
//
// This program starts out like most others with well known include files. Compared to the  [2.x.5666]  program from which most of what we do here is copied, the only difference is the include of the header files from which we import the SparseDirectUMFPACK class and the actual interface to KINSOL:
//
[0.x.48076] 
[0.x.48077] 
[0.x.48078] 
[0.x.48079] 
//
[0.x.48080] 
[0.x.48081] 
[0.x.48082] 
[0.x.48083] 
[0.x.48084] 
[0.x.48085] 
//
[0.x.48086] 
[0.x.48087] 
[0.x.48088] 
//
[0.x.48089] 
[0.x.48090] 
[0.x.48091] 
//
[0.x.48092] 
[0.x.48093] 
//
[0.x.48094] 
[0.x.48095] 
[0.x.48096] 
[0.x.48097] 
[0.x.48098] 
//
[0.x.48099] 
//
[0.x.48100] 
[0.x.48101] 
//
[0.x.48102] 
[0.x.48103] 
[0.x.48104] 
//[2.x.5667] 
//
// Similarly, the main class of this program is essentially a copy of the one in  [2.x.5668] . The class does, however, split the computation of the Jacobian (system) matrix (and its factorization using a direct solver) and residual into separate functions for the reasons outlined in the introduction. For the same reason, the class also has a pointer to a factorization of the Jacobian matrix that is reset every time we update the Jacobian matrix.
//
// (If you are wondering why the program uses a direct object for the Jacobian matrix but a pointer for the factorization: Every time KINSOL requests that the Jacobian be updated, we can simply write `jacobian_matrix=0;` to reset it to an empty matrix that we can then fill again. On the other hand, the SparseDirectUMFPACK class does not have any way to throw away its content or to replace it with a new factorization, and so we use a pointer: We just throw away the whole object and create a new one whenever we have a new Jacobian matrix to factor.)
//
// Finally, the class has a timer variable that we will use to assess how long the different parts of the program take so that we can assess whether KINSOL's tendency to not rebuild the matrix and its factorization makes sense. We will discuss this in the "Results" section below.
//
[0.x.48105] 
[0.x.48106] 
[0.x.48107] 
[0.x.48108] 
[0.x.48109] 
[0.x.48110] 
//
[0.x.48111] 
[0.x.48112] 
[0.x.48113] 
[0.x.48114] 
[0.x.48115] 
[0.x.48116] 
[0.x.48117] 
[0.x.48118] 
[0.x.48119] 
[0.x.48120] 
[0.x.48121] 
//
[0.x.48122] 
//
[0.x.48123] 
[0.x.48124] 
//
[0.x.48125] 
//
[0.x.48126] 
[0.x.48127] 
[0.x.48128] 
//
[0.x.48129] 
//
[0.x.48130] 
[0.x.48131] 
//
//  [2.x.5669] 
//
// The classes implementing boundary values are a copy from  [2.x.5670] :
//
[0.x.48132] 
[0.x.48133] 
[0.x.48134] 
[0.x.48135] 
[0.x.48136] 
[0.x.48137] 
[0.x.48138] 
//
[0.x.48139] 
[0.x.48140] 
[0.x.48141] 
[0.x.48142] 
[0.x.48143] 
[0.x.48144] 
//[2.x.5671] 
//[2.x.5672] 
//
// The following few functions are also essentially copies of what  [2.x.5673]  already does, and so there is little to discuss.
//
[0.x.48145] 
[0.x.48146] 
[0.x.48147] 
[0.x.48148] 
[0.x.48149] 
[0.x.48150] 
//
[0.x.48151] 
[0.x.48152] 
[0.x.48153] 
[0.x.48154] 
//
[0.x.48155] 
[0.x.48156] 
[0.x.48157] 
[0.x.48158] 
//
[0.x.48159] 
[0.x.48160] 
[0.x.48161] 
[0.x.48162] 
[0.x.48163] 
//
[0.x.48164] 
[0.x.48165] 
//
[0.x.48166] 
//
[0.x.48167] 
[0.x.48168] 
[0.x.48169] 
[0.x.48170] 
//
//  [2.x.5674] 
//
// The following function is then responsible for assembling and factorizing the Jacobian matrix. The first half of the function is in essence the `assemble_system()` function of  [2.x.5675] , except that it does not deal with also forming a right hand side vector (i.e., the residual) since we do not always have to do these operations at the same time.
//
// We put the whole assembly functionality into a code block enclosed by curly braces so that we can use a  [2.x.5676]  variable to measure how much time is spent in this code block, excluding everything that happens in this function after the matching closing brace `}`.
//
[0.x.48171] 
[0.x.48172] 
[0.x.48173] 
[0.x.48174] 
[0.x.48175] 
[0.x.48176] 
//
[0.x.48177] 
//
[0.x.48178] 
//
[0.x.48179] 
//
[0.x.48180] 
[0.x.48181] 
[0.x.48182] 
[0.x.48183] 
//
[0.x.48184] 
[0.x.48185] 
//
[0.x.48186] 
//
[0.x.48187] 
//
[0.x.48188] 
//
[0.x.48189] 
[0.x.48190] 
[0.x.48191] 
//
[0.x.48192] 
//
[0.x.48193] 
[0.x.48194] 
//
[0.x.48195] 
[0.x.48196] 
[0.x.48197] 
[0.x.48198] 
[0.x.48199] 
//
[0.x.48200] 
[0.x.48201] 
[0.x.48202] 
[0.x.48203] 
[0.x.48204] 
[0.x.48205] 
[0.x.48206] 
[0.x.48207] 
[0.x.48208] 
[0.x.48209] 
[0.x.48210] 
[0.x.48211] 
[0.x.48212] 
[0.x.48213] 
[0.x.48214] 
[0.x.48215] 
[0.x.48216] 
//
[0.x.48217] 
[0.x.48218] 
[0.x.48219] 
[0.x.48220] 
[0.x.48221] 
//
[0.x.48222] 
[0.x.48223] 
[0.x.48224] 
[0.x.48225] 
[0.x.48226] 
[0.x.48227] 
[0.x.48228] 
[0.x.48229] 
[0.x.48230] 
[0.x.48231] 
[0.x.48232] 
[0.x.48233] 
//
// The second half of the function then deals with factorizing the so-computed matrix. To do this, we first create a new SparseDirectUMFPACK object and by assigning it to the member variable `jacobian_matrix_factorization`, we also destroy whatever object that pointer previously pointed to (if any). Then we tell the object to factorize the Jacobian.
//
// As above, we enclose this block of code into curly braces and use a timer to assess how long this part of the program takes.
//
// (Strictly speaking, we don't actually need the matrix any more after we are done here, and could throw the matrix object away. A code intended to be memory efficient would do this, and only create the matrix object in this function, rather than as a member variable of the surrounding class. We omit this step here because using the same coding style as in previous tutorial programs breeds familiarity with the common style and helps make these tutorial programs easier to read.)
//
[0.x.48234] 
[0.x.48235] 
//
[0.x.48236] 
//
[0.x.48237] 
[0.x.48238] 
[0.x.48239] 
[0.x.48240] 
//
//  [2.x.5677] 
//
// The second part of what `assemble_system()` used to do in  [2.x.5678]  is computing the residual vector, i.e., the right hand side vector of the Newton linear systems. We have broken this out of the previous function, but the following function will be easy to understand if you understood what `assemble_system()` in  [2.x.5679]  did. Importantly, however, we need to compute the residual not linearized around the current solution vector, but whatever we get from KINSOL. This is necessary for operations such as line search where we want to know what the residual  [2.x.5680]  is for different values of  [2.x.5681] ; KINSOL in those cases simply gives us the argument to the function  [2.x.5682]  and we then compute the residual  [2.x.5683]  at this point.
//
// The function prints the norm of the so-computed residual at the end as a way for us to follow along the progress of the program.
//
[0.x.48241] 
[0.x.48242] 
[0.x.48243] 
[0.x.48244] 
[0.x.48245] 
[0.x.48246] 
//
[0.x.48247] 
//
[0.x.48248] 
[0.x.48249] 
[0.x.48250] 
[0.x.48251] 
[0.x.48252] 
//
[0.x.48253] 
[0.x.48254] 
//
[0.x.48255] 
[0.x.48256] 
//
[0.x.48257] 
//
[0.x.48258] 
[0.x.48259] 
[0.x.48260] 
[0.x.48261] 
//
[0.x.48262] 
[0.x.48263] 
//
[0.x.48264] 
[0.x.48265] 
[0.x.48266] 
[0.x.48267] 
[0.x.48268] 
//
[0.x.48269] 
[0.x.48270] 
[0.x.48271] 
[0.x.48272] 
[0.x.48273] 
[0.x.48274] 
//
[0.x.48275] 
[0.x.48276] 
[0.x.48277] 
[0.x.48278] 
//
[0.x.48279] 
//
[0.x.48280] 
[0.x.48281] 
[0.x.48282] 
//
[0.x.48283] 
[0.x.48284] 
[0.x.48285] 
//
[0.x.48286] 
[0.x.48287] 
//
//  [2.x.5684] 
//
// Next up is the function that implements the solution of a linear system with the Jacobian matrix. Since we have already factored the matrix when we built the matrix, solving a linear system comes down to applying the inverse matrix to the given right hand side vector: This is what the  [2.x.5685]  function does that we use here. Following this, we have to make sure that we also address the values of hanging nodes in the solution vector, and this is done using  [2.x.5686] 
//
// The function takes an additional, but unused, argument `tolerance` that indicates how accurately we have to solve the linear system. The meaning of this argument is discussed in the introduction in the context of the "Eisenstat Walker trick", but since we are using a direct rather than an iterative solver, we are not using this opportunity to solve linear systems only inexactly.
//
[0.x.48288] 
[0.x.48289] 
[0.x.48290] 
[0.x.48291] 
[0.x.48292] 
[0.x.48293] 
//
[0.x.48294] 
//
[0.x.48295] 
//
[0.x.48296] 
[0.x.48297] 
//
//  [2.x.5687] 
//
// The following three functions are again simply copies of the ones in  [2.x.5688] :
//
[0.x.48298] 
[0.x.48299] 
[0.x.48300] 
[0.x.48301] 
//
[0.x.48302] 
[0.x.48303] 
[0.x.48304] 
[0.x.48305] 
[0.x.48306] 
[0.x.48307] 
//
[0.x.48308] 
[0.x.48309] 
[0.x.48310] 
[0.x.48311] 
//
[0.x.48312] 
//
[0.x.48313] 
[0.x.48314] 
//
[0.x.48315] 
//
[0.x.48316] 
//
[0.x.48317] 
[0.x.48318] 
[0.x.48319] 
//
[0.x.48320] 
//
[0.x.48321] 
[0.x.48322] 
[0.x.48323] 
//
[0.x.48324] 
//
[0.x.48325] 
//
[0.x.48326] 
[0.x.48327] 
//
[0.x.48328] 
[0.x.48329] 
[0.x.48330] 
[0.x.48331] 
[0.x.48332] 
[0.x.48333] 
[0.x.48334] 
[0.x.48335] 
[0.x.48336] 
[0.x.48337] 
//
[0.x.48338] 
[0.x.48339] 
//
[0.x.48340] 
[0.x.48341] 
[0.x.48342] 
[0.x.48343] 
[0.x.48344] 
//
[0.x.48345] 
//
[0.x.48346] 
[0.x.48347] 
[0.x.48348] 
//
[0.x.48349] 
[0.x.48350] 
[0.x.48351] 
[0.x.48352] 
[0.x.48353] 
//
//  [2.x.5689] 
//
// The only function that *really* is interesting in this program is the one that drives the overall algorithm of starting on a coarse mesh, doing some mesh refinement cycles, and on each mesh using KINSOL to find the solution of the nonlinear algebraic equation we obtain from discretization on this mesh. The `refine_mesh()` function above makes sure that the solution on one mesh is used as the starting guess on the next mesh. We also use a TimerOutput object to measure how much time every operation on each mesh costs, and reset the timer at the beginning of each cycle.
//
// As discussed in the introduction, it is not necessary to solve problems on coarse meshes particularly accurately since these will only solve as starting guesses for the next mesh. As a consequence, we will use a target tolerance of  [2.x.5690]  for the  [2.x.5691] th mesh refinement cycle.
//
// All of this is encoded in the first part of this function:
//
[0.x.48354] 
[0.x.48355] 
[0.x.48356] 
[0.x.48357] 
[0.x.48358] 
//
[0.x.48359] 
[0.x.48360] 
//
[0.x.48361] 
[0.x.48362] 
[0.x.48363] 
[0.x.48364] 
[0.x.48365] 
//
[0.x.48366] 
[0.x.48367] 
//
[0.x.48368] 
[0.x.48369] 
[0.x.48370] 
//
// This is where the fun starts. At the top we create the KINSOL solver object and feed it with an object that encodes a number of additional specifics (of which we only change the nonlinear tolerance we want to reach; but you might want to look into what other members the  [2.x.5692]  class has and play with them).
//
[0.x.48371] 
[0.x.48372] 
[0.x.48373] 
[0.x.48374] 
//
[0.x.48375] 
//
// Then we have to describe the operations that were already mentioned in the introduction. In essence, we have to teach KINSOL how to (i) resize a vector to the correct size, (ii) compute the residual vector, (iii) compute the Jacobian matrix (during which we also compute its factorization), and (iv) solve a linear system with the Jacobian.
//
// All four of these operations are represented by member variables of the  [2.x.5693]  class that are of type  [2.x.5694]  i.e., they are objects to which we can assign a pointer to a function or, as we do here, a "lambda function" that takes the appropriate arguments and returns the appropriate information. By convention, KINSOL wants that functions doing something nontrivial return an integer where zero indicates success. It turns out that we can do all of this in just 25 lines of code.
//
// (If you're not familiar what "lambda functions" are, take a look at  [2.x.5695]  or at the [wikipedia page](https:en.wikipedia.org/wiki/Anonymous_function) on the subject. The idea of lambda functions is that one wants to define a function with a certain set of arguments, but (i) not make it a named functions because, typically, the function is used in only one place and it seems unnecessary to give it a global name; and (ii) that the function has access to some of the variables that exist at the place where it is defined, including member variables. The syntax of lambda functions is awkward, but ultimately quite useful.)
//
// At the very end of the code block we then tell KINSOL to go to work and solve our problem. The member functions called from the 'residual', 'setup_jacobian', and 'solve_jacobian_system' functions will then print output to screen that allows us to follow along with the progress of the program.
//
[0.x.48376] 
[0.x.48377] 
[0.x.48378] 
//
[0.x.48379] 
[0.x.48380] 
[0.x.48381] 
[0.x.48382] 
//
[0.x.48383] 
[0.x.48384] 
//
[0.x.48385] 
[0.x.48386] 
[0.x.48387] 
[0.x.48388] 
//
[0.x.48389] 
[0.x.48390] 
//
[0.x.48391] 
[0.x.48392] 
[0.x.48393] 
[0.x.48394] 
//
[0.x.48395] 
[0.x.48396] 
//
[0.x.48397] 
[0.x.48398] 
//
// The rest is then just house-keeping: Writing data to a file for visualizing, and showing a summary of the timing collected so that we can interpret how long each operation has taken, how often it was executed, etc:
//
[0.x.48399] 
//
[0.x.48400] 
//
[0.x.48401] 
[0.x.48402] 
[0.x.48403] 
[0.x.48404] 
//
[0.x.48405] 
[0.x.48406] 
[0.x.48407] 
[0.x.48408] 
[0.x.48409] 
//
[0.x.48410] 
[0.x.48411] 
[0.x.48412] 
[0.x.48413] 
[0.x.48414] 
[0.x.48415] 
[0.x.48416] 
[0.x.48417] 
[0.x.48418] 
[0.x.48419] 
[0.x.48420] 
[0.x.48421] 
[0.x.48422] 
[0.x.48423] 
//
[0.x.48424] 
[0.x.48425] 
[0.x.48426] 
[0.x.48427] 
[0.x.48428] 
[0.x.48429] 
[0.x.48430] 
[0.x.48431] 
[0.x.48432] 
[0.x.48433] 
[0.x.48434] 
[0.x.48435] 
[0.x.48436] 
[0.x.48437] 
[0.x.48438] 
[0.x.48439] 
[0.x.48440] 
[0.x.48441] 
[0.x.48442] 
[0.x.48443] 
[0.x.48444] 
[0.x.48445] 
[0.x.48446] 
[0.x.48447] 
[0.x.48448] 
[0.x.48449] 
[0.x.48450] 
[0.x.48451] 
[0.x.48452] 
[0.x.48453] 
//
[0.x.48454] 
[0.x.48455] 
[0.x.48456] 
//[2.x.5696] 
//
// The program starts with the usual include files, all of which you should have seen before by now:
//
[0.x.48457] 
[0.x.48458] 
[0.x.48459] 
[0.x.48460] 
[0.x.48461] 
[0.x.48462] 
[0.x.48463] 
[0.x.48464] 
[0.x.48465] 
[0.x.48466] 
[0.x.48467] 
[0.x.48468] 
[0.x.48469] 
[0.x.48470] 
[0.x.48471] 
[0.x.48472] 
[0.x.48473] 
[0.x.48474] 
[0.x.48475] 
[0.x.48476] 
[0.x.48477] 
[0.x.48478] 
[0.x.48479] 
[0.x.48480] 
[0.x.48481] 
[0.x.48482] 
[0.x.48483] 
[0.x.48484] 
[0.x.48485] 
//
[0.x.48486] 
[0.x.48487] 
//
// Then the usual placing of all content of this program into a namespace and the importation of the deal.II namespace into the one we will work in. We also define an identifier to allow for the MMS code to be run when  [2.x.5697]  is defined. Otherwise, the program solves the original problem:
//
[0.x.48488] 
[0.x.48489] 
[0.x.48490] 
//
[0.x.48491] 
//[2.x.5698] 
//
// This section creates a class for the known solution when testing using the MMS. Here we are using  [2.x.5699]  for the solution. We need to include the solution equation and the gradient for the H1 seminorm calculation.
//
[0.x.48492] 
[0.x.48493] 
[0.x.48494] 
[0.x.48495] 
[0.x.48496] 
//
[0.x.48497] 
[0.x.48498] 
//
[0.x.48499] 
[0.x.48500] 
[0.x.48501] 
//
[0.x.48502] 
[0.x.48503] 
[0.x.48504] 
//
[0.x.48505] 
[0.x.48506] 
[0.x.48507] 
[0.x.48508] 
[0.x.48509] 
[0.x.48510] 
//
[0.x.48511] 
[0.x.48512] 
[0.x.48513] 
[0.x.48514] 
[0.x.48515] 
[0.x.48516] 
[0.x.48517] 
//
[0.x.48518] 
[0.x.48519] 
[0.x.48520] 
[0.x.48521] 
[0.x.48522] 
[0.x.48523] 
//
//  [2.x.5700] 
//
// In the following classes and functions, we implement the right hand side and boundary values that define this problem and for which we need function objects. The right hand side is chosen as discussed at the end of the introduction.
//
// First, we handle the initial condition.
//
[0.x.48524] 
[0.x.48525] 
[0.x.48526] 
[0.x.48527] 
[0.x.48528] 
//
[0.x.48529] 
[0.x.48530] 
//
[0.x.48531] 
[0.x.48532] 
[0.x.48533] 
//
[0.x.48534] 
[0.x.48535] 
[0.x.48536] 
[0.x.48537] 
//
[0.x.48538] 
[0.x.48539] 
[0.x.48540] 
[0.x.48541] 
[0.x.48542] 
[0.x.48543] 
[0.x.48544] 
[0.x.48545] 
[0.x.48546] 
[0.x.48547] 
//
// Next, we handle the left boundary condition.
//
[0.x.48548] 
[0.x.48549] 
[0.x.48550] 
[0.x.48551] 
[0.x.48552] 
[0.x.48553] 
[0.x.48554] 
//
[0.x.48555] 
[0.x.48556] 
[0.x.48557] 
[0.x.48558] 
[0.x.48559] 
[0.x.48560] 
[0.x.48561] 
[0.x.48562] 
[0.x.48563] 
[0.x.48564] 
//
// Then, we handle the right boundary condition.
//
[0.x.48565] 
[0.x.48566] 
[0.x.48567] 
[0.x.48568] 
[0.x.48569] 
//
[0.x.48570] 
[0.x.48571] 
//
[0.x.48572] 
[0.x.48573] 
[0.x.48574] 
[0.x.48575] 
//
[0.x.48576] 
[0.x.48577] 
[0.x.48578] 
[0.x.48579] 
[0.x.48580] 
[0.x.48581] 
//
[0.x.48582] 
[0.x.48583] 
[0.x.48584] 
[0.x.48585] 
[0.x.48586] 
[0.x.48587] 
[0.x.48588] 
[0.x.48589] 
[0.x.48590] 
[0.x.48591] 
[0.x.48592] 
[0.x.48593] 
//
// Finally, we handle the right hand side.
//
[0.x.48594] 
[0.x.48595] 
[0.x.48596] 
[0.x.48597] 
[0.x.48598] 
//
[0.x.48599] 
[0.x.48600] 
//
[0.x.48601] 
[0.x.48602] 
[0.x.48603] 
[0.x.48604] 
//
[0.x.48605] 
[0.x.48606] 
[0.x.48607] 
[0.x.48608] 
[0.x.48609] 
[0.x.48610] 
//
[0.x.48611] 
[0.x.48612] 
[0.x.48613] 
[0.x.48614] 
[0.x.48615] 
[0.x.48616] 
[0.x.48617] 
[0.x.48618] 
[0.x.48619] 
[0.x.48620] 
[0.x.48621] 
[0.x.48622] 
[0.x.48623] 
[0.x.48624] 
[0.x.48625] 
[0.x.48626] 
[0.x.48627] 
//
//  [2.x.5701] 
//
// The next piece is the declaration of the main class of this program. This is very similar to the  [2.x.5702]  tutorial, with some modifications. New matrices had to be added to calculate the A and B matrices, as well as the  [2.x.5703]  vector mentioned in the introduction. We also define the parameters used in the problem.
//
//
//
// -  [2.x.5704] : The imposed upper bound on the spatial domain. This is the maximum allowed stock price.
//
// -  [2.x.5705] : The upper bound on the time domain. This is when the option expires.\n
//
// -  [2.x.5706] : The volatility of the stock price.\n
//
// -  [2.x.5707] : The risk free interest rate.\n
//
// -  [2.x.5708] : The agreed upon price that the buyer will have the option of purchasing  the stocks at the expiration time.
//
// Some slight differences between this program and  [2.x.5709]  are the creation of the  [2.x.5710] , which is described in the introduction. We then also need to store the current time, the size of the time step, and the number of the current time step. Next, we will store the output into a  [2.x.5711]  variable because we will be layering the solution at each time on top of one another to create the solution manifold. Then, we have a variable that stores the current cycle and number of cycles that we will run when calculating the solution. The cycle is one full solution calculation given a mesh. We refine the mesh once in between each cycle to exhibit the convergence properties of our program. Finally, we store the convergence data into a convergence table.
//
// As far as member functions are concerned, we have a function that calculates the convergence information for each cycle, called  [2.x.5712] . This is just like what is done in  [2.x.5713] .
//
[0.x.48628] 
[0.x.48629] 
[0.x.48630] 
[0.x.48631] 
[0.x.48632] 
//
[0.x.48633] 
//
[0.x.48634] 
[0.x.48635] 
[0.x.48636] 
[0.x.48637] 
[0.x.48638] 
[0.x.48639] 
[0.x.48640] 
//
[0.x.48641] 
[0.x.48642] 
[0.x.48643] 
[0.x.48644] 
[0.x.48645] 
//
[0.x.48646] 
[0.x.48647] 
[0.x.48648] 
//
[0.x.48649] 
//
[0.x.48650] 
[0.x.48651] 
[0.x.48652] 
[0.x.48653] 
[0.x.48654] 
[0.x.48655] 
//
[0.x.48656] 
[0.x.48657] 
//
[0.x.48658] 
[0.x.48659] 
//
[0.x.48660] 
[0.x.48661] 
[0.x.48662] 
//
[0.x.48663] 
[0.x.48664] 
//
[0.x.48665] 
[0.x.48666] 
//[2.x.5714] 
//
// Now, we get to the implementation of the main class. We will set the values for the various parameters used in the problem. These were chosen because they are fairly normal values for these parameters. Although the stock price has no upper bound in reality (it is in fact infinite), we impose an upper bound that is twice the strike price. This is a somewhat arbitrary choice to be twice the strike price, but it is large enough to see the interesting parts of the solution.
//
[0.x.48667] 
[0.x.48668] 
[0.x.48669] 
[0.x.48670] 
[0.x.48671] 
[0.x.48672] 
[0.x.48673] 
[0.x.48674] 
[0.x.48675] 
[0.x.48676] 
[0.x.48677] 
[0.x.48678] 
[0.x.48679] 
[0.x.48680] 
[0.x.48681] 
[0.x.48682] 
//[2.x.5715] 
//
// The next function sets up the DoFHandler object, computes the constraints, and sets the linear algebra objects to their correct sizes. We also compute the mass matrix here by calling a function from the library. We will compute the other 3 matrices next, because these need to be computed 'by hand'.
//
// Note, that the time step is initialized here because the maturity time was needed to compute the time step.
//
[0.x.48683] 
[0.x.48684] 
[0.x.48685] 
[0.x.48686] 
//
[0.x.48687] 
//
[0.x.48688] 
[0.x.48689] 
[0.x.48690] 
[0.x.48691] 
[0.x.48692] 
[0.x.48693] 
[0.x.48694] 
//
//                                    /*keep_constrained_dofs =  [2.x.5716]  true);
//
[0.x.48695] 
//
[0.x.48696] 
[0.x.48697] 
[0.x.48698] 
[0.x.48699] 
[0.x.48700] 
//
[0.x.48701] 
[0.x.48702] 
[0.x.48703] 
//
// Below is the code to create the Laplace matrix with non-constant coefficients. This corresponds to the matrix D in the introduction. This non-constant coefficient is represented in the  [2.x.5717]  variable.
//
[0.x.48704] 
[0.x.48705] 
[0.x.48706] 
[0.x.48707] 
[0.x.48708] 
[0.x.48709] 
[0.x.48710] 
[0.x.48711] 
[0.x.48712] 
[0.x.48713] 
[0.x.48714] 
[0.x.48715] 
[0.x.48716] 
[0.x.48717] 
[0.x.48718] 
[0.x.48719] 
[0.x.48720] 
[0.x.48721] 
[0.x.48722] 
[0.x.48723] 
[0.x.48724] 
[0.x.48725] 
[0.x.48726] 
[0.x.48727] 
[0.x.48728] 
[0.x.48729] 
[0.x.48730] 
[0.x.48731] 
[0.x.48732] 
[0.x.48733] 
[0.x.48734] 
[0.x.48735] 
[0.x.48736] 
[0.x.48737] 
[0.x.48738] 
//
// Now we will create the A matrix. Below is the code to create the matrix A as discussed in the introduction. The non constant coefficient is again represented in  the  [2.x.5718]  variable.
//
[0.x.48739] 
[0.x.48740] 
[0.x.48741] 
[0.x.48742] 
[0.x.48743] 
[0.x.48744] 
[0.x.48745] 
[0.x.48746] 
[0.x.48747] 
[0.x.48748] 
[0.x.48749] 
[0.x.48750] 
[0.x.48751] 
[0.x.48752] 
[0.x.48753] 
[0.x.48754] 
[0.x.48755] 
[0.x.48756] 
[0.x.48757] 
[0.x.48758] 
[0.x.48759] 
[0.x.48760] 
[0.x.48761] 
[0.x.48762] 
[0.x.48763] 
[0.x.48764] 
[0.x.48765] 
[0.x.48766] 
[0.x.48767] 
//
// Finally we will create the matrix B. Below is the code to create the matrix B as discussed in the introduction. The non constant coefficient is again represented in the  [2.x.5719]  variable.
//
[0.x.48768] 
[0.x.48769] 
[0.x.48770] 
[0.x.48771] 
[0.x.48772] 
[0.x.48773] 
[0.x.48774] 
[0.x.48775] 
[0.x.48776] 
[0.x.48777] 
[0.x.48778] 
[0.x.48779] 
[0.x.48780] 
[0.x.48781] 
[0.x.48782] 
[0.x.48783] 
[0.x.48784] 
[0.x.48785] 
[0.x.48786] 
[0.x.48787] 
[0.x.48788] 
[0.x.48789] 
[0.x.48790] 
[0.x.48791] 
[0.x.48792] 
[0.x.48793] 
[0.x.48794] 
//
[0.x.48795] 
[0.x.48796] 
[0.x.48797] 
//[2.x.5720] 
//
// The next function is the one that solves the actual linear system for a single time step. The only interesting thing here is that the matrices we have built are symmetric positive definite, so we can use the conjugate gradient method.
//
[0.x.48798] 
[0.x.48799] 
[0.x.48800] 
[0.x.48801] 
[0.x.48802] 
[0.x.48803] 
[0.x.48804] 
[0.x.48805] 
[0.x.48806] 
[0.x.48807] 
//[2.x.5721] 
//
// This is simply the function to stitch the solution pieces together. For this, we create a new layer at each time, and then add the solution vector for that timestep. The function then stitches this together with the old solutions using 'build_patches'.
//
[0.x.48808] 
[0.x.48809] 
[0.x.48810] 
[0.x.48811] 
[0.x.48812] 
[0.x.48813] 
[0.x.48814] 
[0.x.48815] 
[0.x.48816] 
//[2.x.5722] 
//
// It is somewhat unnecessary to have a function for the global refinement that we do. The reason for the function is to allow for the possibility of an adaptive refinement later.
//
[0.x.48817] 
[0.x.48818] 
[0.x.48819] 
[0.x.48820] 
[0.x.48821] 
//[2.x.5723] 
//
// This is where we calculate the convergence and error data to evaluate the effectiveness of the program. Here, we calculate the  [2.x.5724] ,  [2.x.5725]  and  [2.x.5726]  norms.
//
[0.x.48822] 
[0.x.48823] 
[0.x.48824] 
[0.x.48825] 
[0.x.48826] 
[0.x.48827] 
[0.x.48828] 
[0.x.48829] 
[0.x.48830] 
[0.x.48831] 
[0.x.48832] 
[0.x.48833] 
[0.x.48834] 
[0.x.48835] 
[0.x.48836] 
[0.x.48837] 
[0.x.48838] 
[0.x.48839] 
[0.x.48840] 
[0.x.48841] 
[0.x.48842] 
[0.x.48843] 
[0.x.48844] 
[0.x.48845] 
[0.x.48846] 
[0.x.48847] 
[0.x.48848] 
[0.x.48849] 
[0.x.48850] 
[0.x.48851] 
[0.x.48852] 
[0.x.48853] 
[0.x.48854] 
[0.x.48855] 
[0.x.48856] 
[0.x.48857] 
[0.x.48858] 
[0.x.48859] 
[0.x.48860] 
[0.x.48861] 
[0.x.48862] 
[0.x.48863] 
[0.x.48864] 
[0.x.48865] 
[0.x.48866] 
[0.x.48867] 
//[2.x.5727] 
//
// This next part is building the convergence and error tables. By this, we need to set the settings for how to output the data that was calculated during  [2.x.5728] . First, we will create the headings and set up the cells properly. During this, we will also prescribe the precision of our results. Then we will write the calculated errors based on the  [2.x.5729] ,  [2.x.5730] , and  [2.x.5731]  norms to the console and to the error LaTeX file.
//
[0.x.48868] 
[0.x.48869] 
[0.x.48870] 
[0.x.48871] 
[0.x.48872] 
[0.x.48873] 
[0.x.48874] 
[0.x.48875] 
[0.x.48876] 
[0.x.48877] 
[0.x.48878] 
[0.x.48879] 
[0.x.48880] 
[0.x.48881] 
[0.x.48882] 
[0.x.48883] 
[0.x.48884] 
[0.x.48885] 
[0.x.48886] 
[0.x.48887] 
[0.x.48888] 
[0.x.48889] 
[0.x.48890] 
//
// Next, we will make the convergence table. We will again write this to the console and to the convergence LaTeX file.
//
[0.x.48891] 
[0.x.48892] 
[0.x.48893] 
[0.x.48894] 
[0.x.48895] 
[0.x.48896] 
[0.x.48897] 
[0.x.48898] 
[0.x.48899] 
[0.x.48900] 
[0.x.48901] 
[0.x.48902] 
[0.x.48903] 
[0.x.48904] 
[0.x.48905] 
[0.x.48906] 
[0.x.48907] 
[0.x.48908] 
[0.x.48909] 
[0.x.48910] 
[0.x.48911] 
[0.x.48912] 
[0.x.48913] 
[0.x.48914] 
[0.x.48915] 
[0.x.48916] 
[0.x.48917] 
[0.x.48918] 
[0.x.48919] 
[0.x.48920] 
[0.x.48921] 
[0.x.48922] 
[0.x.48923] 
//[2.x.5732] 
//
// Now we get to the main driver of the program. This is where we do all the work of looping through the time steps and calculating the solution vector each time. Here at the top, we set the initial refinement value and then create a mesh. Then we refine this mesh once. Next, we set up the data_out_stack object to store our solution. Finally, we start a for loop to loop through the cycles. This lets us recalculate a solution for each successive mesh refinement. At the beginning of each iteration, we need to reset the time and time step number. We introduce an if statement to accomplish this because we don't want to do this on the first iteration.
//
[0.x.48924] 
[0.x.48925] 
[0.x.48926] 
[0.x.48927] 
[0.x.48928] 
//
[0.x.48929] 
[0.x.48930] 
[0.x.48931] 
//
[0.x.48932] 
[0.x.48933] 
//
[0.x.48934] 
[0.x.48935] 
[0.x.48936] 
[0.x.48937] 
[0.x.48938] 
[0.x.48939] 
[0.x.48940] 
//
[0.x.48941] 
//
[0.x.48942] 
[0.x.48943] 
[0.x.48944] 
[0.x.48945] 
[0.x.48946] 
[0.x.48947] 
[0.x.48948] 
[0.x.48949] 
//
[0.x.48950] 
[0.x.48951] 
[0.x.48952] 
//
[0.x.48953] 
[0.x.48954] 
[0.x.48955] 
[0.x.48956] 
//
// Next, we run the main loop which runs until we exceed the maturity time. We first compute the right hand side of the equation, which is described in the introduction. Recall that it contains the term  [2.x.5733] . We put these terms into the variable system_rhs, with the help of a temporary vector:
//
[0.x.48957] 
[0.x.48958] 
[0.x.48959] 
[0.x.48960] 
[0.x.48961] 
[0.x.48962] 
//
[0.x.48963] 
[0.x.48964] 
[0.x.48965] 
//
[0.x.48966] 
//
[0.x.48967] 
[0.x.48968] 
[0.x.48969] 
[0.x.48970] 
[0.x.48971] 
[0.x.48972] 
//
[0.x.48973] 
[0.x.48974] 
//
[0.x.48975] 
[0.x.48976] 
//
[0.x.48977] 
[0.x.48978] 
[0.x.48979] 
[0.x.48980] 
[0.x.48981] 
//
//   The second piece is to compute the contributions of the source   terms. This corresponds to the term  [2.x.5734] . The following code calls    [2.x.5735]  to compute the vectors  [2.x.5736] ,   where we set the time of the right hand side (source) function   before we evaluate it. The result of this all ends up in the   forcing_terms variable:
//
[0.x.48982] 
[0.x.48983] 
[0.x.48984] 
[0.x.48985] 
[0.x.48986] 
[0.x.48987] 
[0.x.48988] 
[0.x.48989] 
//
[0.x.48990] 
[0.x.48991] 
[0.x.48992] 
[0.x.48993] 
[0.x.48994] 
[0.x.48995] 
[0.x.48996] 
//
//   Next, we add the forcing terms to the ones that come from the   time stepping, and also build the matrix  [2.x.5737]  that we   have to invert in each time step. The final piece of these   operations is to eliminate hanging node constrained degrees of   freedom from the linear system:
//
[0.x.48997] 
[0.x.48998] 
[0.x.48999] 
[0.x.49000] 
[0.x.49001] 
[0.x.49002] 
[0.x.49003] 
//
[0.x.49004] 
//
//   There is one more operation we need to do before we can solve it:   boundary values. To this end, we create a boundary value object,   set the proper time to the one of the current time step, and   evaluate it as we have done many times before. The result is used   to also set the correct boundary values in the linear system:
//
[0.x.49005] 
[0.x.49006] 
[0.x.49007] 
[0.x.49008] 
[0.x.49009] 
[0.x.49010] 
[0.x.49011] 
[0.x.49012] 
[0.x.49013] 
[0.x.49014] 
[0.x.49015] 
[0.x.49016] 
[0.x.49017] 
[0.x.49018] 
[0.x.49019] 
[0.x.49020] 
[0.x.49021] 
[0.x.49022] 
[0.x.49023] 
[0.x.49024] 
//
//   With this out of the way, all we have to do is solve the system,   generate graphical data on the last cycle, and create the   convergence table data.
//
[0.x.49025] 
//
[0.x.49026] 
[0.x.49027] 
[0.x.49028] 
[0.x.49029] 
[0.x.49030] 
[0.x.49031] 
[0.x.49032] 
[0.x.49033] 
[0.x.49034] 
//
[0.x.49035] 
[0.x.49036] 
[0.x.49037] 
//
[0.x.49038] 
[0.x.49039] 
[0.x.49040] 
[0.x.49041] 
//
[0.x.49042] 
//[2.x.5738] 
//
// Having made it this far, there is, again, nothing much to discuss for the main function of this program: it looks like all such functions since  [2.x.5739] .
//
[0.x.49043] 
[0.x.49044] 
[0.x.49045] 
[0.x.49046] 
[0.x.49047] 
//
[0.x.49048] 
[0.x.49049] 
[0.x.49050] 
[0.x.49051] 
[0.x.49052] 
[0.x.49053] 
[0.x.49054] 
[0.x.49055] 
[0.x.49056] 
[0.x.49057] 
[0.x.49058] 
[0.x.49059] 
[0.x.49060] 
[0.x.49061] 
[0.x.49062] 
[0.x.49063] 
[0.x.49064] 
[0.x.49065] 
[0.x.49066] 
[0.x.49067] 
[0.x.49068] 
[0.x.49069] 
[0.x.49070] 
[0.x.49071] 
[0.x.49072] 
[0.x.49073] 
[0.x.49074] 
[0.x.49075] 
[0.x.49076] 
[0.x.49077] 
[0.x.49078] 
[0.x.49079] 
[0.x.49080] 
[0.x.49081] 
[0.x.49082] 
[0.x.49083] 
[0.x.49084] 
[0.x.49085] 
[0.x.49086] 
[0.x.49087] 
[0.x.49088] 
[0.x.49089] 
[0.x.49090] 
[0.x.49091] 
//
[0.x.49092] 
[0.x.49093] 
[0.x.49094] 
//[2.x.5740] 
[0.x.49095] 
[0.x.49096] 
[0.x.49097] 
[0.x.49098] 
[0.x.49099] 
//
[0.x.49100] 
[0.x.49101] 
[0.x.49102] 
[0.x.49103] 
[0.x.49104] 
[0.x.49105] 
[0.x.49106] 
//
[0.x.49107] 
[0.x.49108] 
[0.x.49109] 
//
[0.x.49110] 
[0.x.49111] 
[0.x.49112] 
//
[0.x.49113] 
[0.x.49114] 
[0.x.49115] 
[0.x.49116] 
//
[0.x.49117] 
[0.x.49118] 
[0.x.49119] 
//
[0.x.49120] 
[0.x.49121] 
[0.x.49122] 
//
// Above are fairly common files to include. These also include the one for the sparse direct class SparseDirectUMFPACK. This is not the most efficient way to solve large linear problems, but it will do for now.
//
// As usual, we put everything into a common namespace. We then start by declaring a number of symbolic names for constants that will be used throughout this tutorial. Specifically, we have a *lot* of variables in this program (of course the density and the displacement, but also the unfiltered density and quite a number of Lagrange multipliers). It is easy to forget which of these variables is at which position in the solution vector, and trying to use numbers for these vector components is a prescription for bugs. Rather, we define static variables that can be used in all of these places and that have to be initialized only once. In practice, this will lead to some lengthy expressions, but they are more readable and less likely to be wrong.
//
// A similar issue arises with the ordering of blocks in the system matrix and in vectors. The matrices have  [2.x.5741]  blocks, and it's difficult to remember which is which. It is far easier to just use symbolic names for those as well.
//
// Finally, while we're at it, we introduce symbolic names also for the boundary indicators we will use, in the same spirit as was done in  [2.x.5742] .
//
// In all of these cases, we declare these variables as members in a namespace. In the case of the solution components, the concrete values of these variables depend on the space dimension, so we use [template variables](https:en.cppreference.com/w/cpp/language/variable_template) to make the value of the variable depend on a template argument in the same way as we often use template functions.
//
[0.x.49123] 
[0.x.49124] 
[0.x.49125] 
//
// This namespace keeps track of the first component in our finite element system that corresponds to each variable.
//
[0.x.49126] 
[0.x.49127] 
[0.x.49128] 
[0.x.49129] 
[0.x.49130] 
[0.x.49131] 
[0.x.49132] 
[0.x.49133] 
[0.x.49134] 
[0.x.49135] 
[0.x.49136] 
[0.x.49137] 
[0.x.49138] 
[0.x.49139] 
[0.x.49140] 
[0.x.49141] 
[0.x.49142] 
[0.x.49143] 
[0.x.49144] 
[0.x.49145] 
[0.x.49146] 
//
// This is the namespace which keeps track of which block corresponds to which variable.
//
[0.x.49147] 
[0.x.49148] 
[0.x.49149] 
[0.x.49150] 
[0.x.49151] 
[0.x.49152] 
[0.x.49153] 
[0.x.49154] 
[0.x.49155] 
[0.x.49156] 
[0.x.49157] 
[0.x.49158] 
//
[0.x.49159] 
[0.x.49160] 
[0.x.49161] 
[0.x.49162] 
[0.x.49163] 
//
[0.x.49164] 
[0.x.49165] 
[0.x.49166] 
[0.x.49167] 
[0.x.49168] 
[0.x.49169] 
[0.x.49170] 
[0.x.49171] 
[0.x.49172] 
[0.x.49173] 
[0.x.49174] 
[0.x.49175] 
[0.x.49176] 
[0.x.49177] 
[0.x.49178] 
[0.x.49179] 
[0.x.49180] 
[0.x.49181] 
[0.x.49182] 
[0.x.49183] 
[0.x.49184] 
[0.x.49185] 
[0.x.49186] 
[0.x.49187] 
[0.x.49188] 
[0.x.49189] 
[0.x.49190] 
[0.x.49191] 
[0.x.49192] 
[0.x.49193] 
//[2.x.5743] 
//
// Next up is the main class for this problem. The majority of functions follow the usual naming schemes of tutorial programs, though there are a couple that have been broken out of what is usually called the `setup_system()` function because of their length, and there are also a number that deal with various aspects of the optimization algorithm.
//
// As an added bonus, the program writes the computed design as an STL file that one can, for example, send to a 3d printer.
//
[0.x.49194] 
[0.x.49195] 
[0.x.49196] 
[0.x.49197] 
[0.x.49198] 
//
[0.x.49199] 
//
[0.x.49200] 
[0.x.49201] 
//
[0.x.49202] 
//
[0.x.49203] 
//
[0.x.49204] 
//
[0.x.49205] 
//
[0.x.49206] 
//
[0.x.49207] 
[0.x.49208] 
[0.x.49209] 
//
[0.x.49210] 
[0.x.49211] 
//
[0.x.49212] 
//
[0.x.49213] 
//
[0.x.49214] 
[0.x.49215] 
[0.x.49216] 
//
[0.x.49217] 
//
[0.x.49218] 
//
[0.x.49219] 
//
[0.x.49220] 
[0.x.49221] 
[0.x.49222] 
//
// Most of the member variables are also standard. There are, however, a number of variables that are specifically related to the optimization algorithm (such the various scalar factors below) as well as the filter matrix to ensure that the design remains smooth.
//
[0.x.49223] 
[0.x.49224] 
[0.x.49225] 
[0.x.49226] 
//
[0.x.49227] 
//
[0.x.49228] 
[0.x.49229] 
//
[0.x.49230] 
[0.x.49231] 
//
[0.x.49232] 
[0.x.49233] 
//
[0.x.49234] 
[0.x.49235] 
[0.x.49236] 
[0.x.49237] 
[0.x.49238] 
//
[0.x.49239] 
[0.x.49240] 
//[2.x.5744] 
//
// We initialize a FESystem composed of 2 [2.x.5745] dim `FE_Q(1)` elements for the displacement variable and its Lagrange multiplier, and 7 `FE_DGQ(0)` elements.  These piecewise constant functions are for density-related variables: the density itself, the unfiltered density, the slack variables for the lower and upper bounds on the unfiltered density, and then Lagrange multipliers for the connection between filtered and unfiltered densities as well as for the inequality constraints.
//
// The order in which these elements appear is documented above.
//
[0.x.49241] 
[0.x.49242] 
[0.x.49243] 
[0.x.49244] 
[0.x.49245] 
[0.x.49246] 
[0.x.49247] 
[0.x.49248] 
[0.x.49249] 
[0.x.49250] 
[0.x.49251] 
[0.x.49252] 
[0.x.49253] 
[0.x.49254] 
[0.x.49255] 
[0.x.49256] 
[0.x.49257] 
[0.x.49258] 
[0.x.49259] 
[0.x.49260] 
[0.x.49261] 
//
// The first step then is to create the triangulation that matches the problem description in the introduction -- a 6-by-1 rectangle (or a 6-by-1-by-1 box in 3d) where a force will be applied in the top center. This triangulation is then uniformly refined a number of times.
//
// In contrast to nearly the entire rest of this program, this function specifically assumes that we are in 2d and will require changes if we wanted to move to 3d simulations. We ensure that nobody tries to accidentally run in 3d without such modifications through an assertion at the top of the function.
//
[0.x.49262] 
[0.x.49263] 
[0.x.49264] 
[0.x.49265] 
[0.x.49266] 
[0.x.49267] 
[0.x.49268] 
[0.x.49269] 
//
[0.x.49270] 
//
// The second step is to apply boundary indicators to parts of the boundary. The following code assigns boundary indicators to the bottom, top, left, and right boundaries of the box, respectively. The center region of the top boundary is given a separate boundary indicator: This is where we will apply the down force.
//
[0.x.49271] 
[0.x.49272] 
[0.x.49273] 
[0.x.49274] 
[0.x.49275] 
[0.x.49276] 
[0.x.49277] 
[0.x.49278] 
[0.x.49279] 
[0.x.49280] 
[0.x.49281] 
[0.x.49282] 
[0.x.49283] 
[0.x.49284] 
[0.x.49285] 
[0.x.49286] 
[0.x.49287] 
[0.x.49288] 
[0.x.49289] 
[0.x.49290] 
//
// Next, determine the constraints due to boundary values.  The bottom corners of the domain are kept in place in the  [2.x.5746]  direction -- the bottom left also in the  [2.x.5747]  direction. deal.II generally thinks of boundary values as attached to pieces of the boundary, i.e., faces, rather than individual vertices. Indeed, mathematically speaking, one can not assign boundary values to individual points for the infinite-dimensional partial differential equation. But, since we are trying to reproduce a widely used benchmark, we will do so anyway and keep in mind that we have a finite-dimensional problem for which imposing boundary conditions at a single node is valid.
//
[0.x.49291] 
[0.x.49292] 
[0.x.49293] 
[0.x.49294] 
[0.x.49295] 
[0.x.49296] 
[0.x.49297] 
[0.x.49298] 
[0.x.49299] 
[0.x.49300] 
[0.x.49301] 
//
//       Check whether the current face is on the bottom       boundary, and if it is whether one of its       vertices might be the bottom left or bottom       right vertex:
//
[0.x.49302] 
[0.x.49303] 
[0.x.49304] 
[0.x.49305] 
[0.x.49306] 
//
[0.x.49307] 
[0.x.49308] 
[0.x.49309] 
[0.x.49310] 
[0.x.49311] 
[0.x.49312] 
[0.x.49313] 
[0.x.49314] 
[0.x.49315] 
[0.x.49316] 
[0.x.49317] 
//
[0.x.49318] 
[0.x.49319] 
[0.x.49320] 
[0.x.49321] 
[0.x.49322] 
//
[0.x.49323] 
[0.x.49324] 
[0.x.49325] 
[0.x.49326] 
[0.x.49327] 
[0.x.49328] 
[0.x.49329] 
//
[0.x.49330] 
[0.x.49331] 
[0.x.49332] 
[0.x.49333] 
[0.x.49334] 
[0.x.49335] 
[0.x.49336] 
[0.x.49337] 
[0.x.49338] 
//[2.x.5748] 
//
// The next function makes a giant 9-by-9 block matrix, and also sets up the necessary block vectors.  The sparsity pattern for this matrix includes the sparsity pattern for the filter matrix. It also initializes any block vectors we will use.
//
// Setting up the blocks by themselves is not overly complicated and follows what is already done in programs such as  [2.x.5749] , for example.
//
[0.x.49339] 
[0.x.49340] 
[0.x.49341] 
[0.x.49342] 
[0.x.49343] 
[0.x.49344] 
[0.x.49345] 
[0.x.49346] 
//
[0.x.49347] 
[0.x.49348] 
[0.x.49349] 
[0.x.49350] 
//
[0.x.49351] 
[0.x.49352] 
[0.x.49353] 
[0.x.49354] 
[0.x.49355] 
//
// The bulk of the function is in setting up which of these blocks will actually contain anything, i.e., which variables couple with which other variables. This is cumbersome but necessary to ensure that we don't just allocate a very large number of entries for our matrix that will then end up being zero.
//
// The concrete pattern you see below is something one probably has to draw once on a piece of paper, but follows in an otherwise relatively straightforward way from looking through the many terms of the bilinear form we will have to assemble in each nonlinear iteration.
//
// The use of the symbolic names defined in namespace `SolutionComponents` helps understand what each of the following terms corresponds to, but it also makes the expressions lengthy and unwieldy: A term such as  [2.x.5750]  just doesn't read very well, and would either have to be split over several lines or run off the right edge of nearly every screen. As a consequence, we open a curly-brace enclosed code block in which we temporarily make the names in namespace `SolutionComponents` available without the namespace qualifier, by saying `using namespace SolutionComponents`.
//
[0.x.49356] 
[0.x.49357] 
[0.x.49358] 
//
[0.x.49359] 
//
[0.x.49360] 
[0.x.49361] 
[0.x.49362] 
[0.x.49363] 
[0.x.49364] 
//
[0.x.49365] 
[0.x.49366] 
[0.x.49367] 
[0.x.49368] 
[0.x.49369] 
[0.x.49370] 
[0.x.49371] 
//
[0.x.49372] 
[0.x.49373] 
[0.x.49374] 
[0.x.49375] 
//
//      /* Coupling for displacement  [2.x.5751] 
[0.x.49376] 
[0.x.49377] 
[0.x.49378] 
[0.x.49379] 
[0.x.49380] 
[0.x.49381] 
[0.x.49382] 
[0.x.49383] 
[0.x.49384] 
[0.x.49385] 
//
//      /* Coupling for slack variables  [2.x.5752] 
[0.x.49386] 
[0.x.49387] 
[0.x.49388] 
[0.x.49389] 
[0.x.49390] 
[0.x.49391] 
//
[0.x.49392] 
[0.x.49393] 
[0.x.49394] 
[0.x.49395] 
[0.x.49396] 
[0.x.49397] 
[0.x.49398] 
//
// Before we can create the sparsity pattern, we also have to set up constraints. Since this program does not adaptively refine the mesh, the only constraint we have is one that couples all density variables to enforce the volume constraint. This will ultimately lead to a dense sub-block of the matrix, but there is little we can do about that.
//
[0.x.49399] 
[0.x.49400] 
[0.x.49401] 
[0.x.49402] 
//
[0.x.49403] 
[0.x.49404] 
[0.x.49405] 
[0.x.49406] 
[0.x.49407] 
[0.x.49408] 
[0.x.49409] 
[0.x.49410] 
[0.x.49411] 
//
[0.x.49412] 
//
// We can now finally create the sparsity pattern for the matrix, taking into account which variables couple with which other variables, and the constraints we have on the density.
//
[0.x.49413] 
//
// The only part of the matrix we have not dealt with is the filter matrix and its transpose. These are non-local (integral) operators for which deal.II does not currently have functions. What we will ultimately need to do is go over all cells and couple the unfiltered density on this cell to all filtered densities of neighboring cells that are less than a threshold distance away, and the other way around; for the moment, we are only concerned with building the sparsity pattern that would correspond to this kind of matrix, so we perform the equivalent loop and where later on we would write into an entry of the matrix, we now simply add an entry to the sparsity matrix:
//
[0.x.49414] 
[0.x.49415] 
[0.x.49416] 
[0.x.49417] 
[0.x.49418] 
[0.x.49419] 
[0.x.49420] 
[0.x.49421] 
[0.x.49422] 
[0.x.49423] 
[0.x.49424] 
[0.x.49425] 
[0.x.49426] 
[0.x.49427] 
[0.x.49428] 
[0.x.49429] 
[0.x.49430] 
[0.x.49431] 
[0.x.49432] 
[0.x.49433] 
//
// Having so generated the "dynamic" sparsity pattern, we can finally copy it to the structure that is used to associate matrices with a sparsity pattern. Because the sparsity pattern is large and complex, we also output it into a file of its own for visualization purposes -- in other words, for "visual debugging".
//
[0.x.49434] 
//
[0.x.49435] 
[0.x.49436] 
//
[0.x.49437] 
//
// What is left is to correctly size the various vectors and their blocks, as well as setting initial guesses for some of the components of the (nonlinear) solution vector. We here use the symbolic component names for individual blocks of the solution vector and, for brevity, use the same trick with `using namespace` as above:
//
[0.x.49438] 
[0.x.49439] 
//
[0.x.49440] 
[0.x.49441] 
[0.x.49442] 
[0.x.49443] 
[0.x.49444] 
[0.x.49445] 
[0.x.49446] 
[0.x.49447] 
[0.x.49448] 
[0.x.49449] 
[0.x.49450] 
[0.x.49451] 
//[2.x.5753] 
//
// Next up, a function that is used once at the beginning of the program: It creates a matrix  [2.x.5754]  so that the filtered density vector equals  [2.x.5755]  times the unfiltered density.  The creation of this matrix is non-trivial, and it is used in every iteration, and so rather than reforming it as we do with the Newton matrix, it is made only once and stored separately.
//
// The way this matrix is computed follows the outline used above already to form its sparsity pattern. We repeat this process here for the sparsity pattern of this separately formed matrix, and then actually build the matrix itself. You may want to check the definition of this matrix in the introduction to this program.
//
[0.x.49452] 
[0.x.49453] 
[0.x.49454] 
//
// The sparsity pattern of the filter has already been determined and implemented in the setup_system() function. We copy the structure from the appropriate block and use it again here.
//
[0.x.49455] 
[0.x.49456] 
[0.x.49457] 
[0.x.49458] 
//
// Having so built the sparsity pattern, now we re-do all of these loops to actually compute the necessary values of the matrix entries:
//
[0.x.49459] 
[0.x.49460] 
[0.x.49461] 
[0.x.49462] 
[0.x.49463] 
[0.x.49464] 
[0.x.49465] 
[0.x.49466] 
[0.x.49467] 
[0.x.49468] 
[0.x.49469] 
[0.x.49470] 
//
//      
//
[0.x.49471] 
[0.x.49472] 
[0.x.49473] 
//
// The final step is to normalize the matrix so that for each row, the sum of entries equals one.
//
[0.x.49474] 
[0.x.49475] 
[0.x.49476] 
[0.x.49477] 
[0.x.49478] 
[0.x.49479] 
[0.x.49480] 
[0.x.49481] 
[0.x.49482] 
[0.x.49483] 
[0.x.49484] 
[0.x.49485] 
[0.x.49486] 
//
// This function is used for building the filter matrix. We create a set of all the cell iterators within a certain radius of the cell that is input. These are the neighboring cells that will be relevant for the filter.
//
[0.x.49487] 
[0.x.49488] 
[0.x.49489] 
[0.x.49490] 
[0.x.49491] 
[0.x.49492] 
[0.x.49493] 
//
[0.x.49494] 
[0.x.49495] 
//
[0.x.49496] 
[0.x.49497] 
[0.x.49498] 
[0.x.49499] 
[0.x.49500] 
[0.x.49501] 
[0.x.49502] 
[0.x.49503] 
[0.x.49504] 
[0.x.49505] 
[0.x.49506] 
[0.x.49507] 
[0.x.49508] 
[0.x.49509] 
[0.x.49510] 
[0.x.49511] 
[0.x.49512] 
[0.x.49513] 
[0.x.49514] 
[0.x.49515] 
[0.x.49516] 
[0.x.49517] 
[0.x.49518] 
[0.x.49519] 
[0.x.49520] 
[0.x.49521] 
[0.x.49522] 
[0.x.49523] 
[0.x.49524] 
//[2.x.5756] 
//
// Whereas the setup_filter_matrix function built a matrix that is the same as long as the mesh does not change (which we don't do anyway in this program), the next function builds the matrix to be solved in each iteration. This is where the magic happens. The components of the system of linear equations describing Newton's method for finding the solution of the KKT conditions are implemented here.
//
// The top of the function is as in most of these functions and just sets up all sorts of variables necessary for the actual assembly, including a whole bunch of extractors. The entire set up should look familiar, though somewhat lengthier, if you've previously looked at  [2.x.5757] .
//
[0.x.49525] 
[0.x.49526] 
[0.x.49527] 
[0.x.49528] 
//
[0.x.49529] 
[0.x.49530] 
//
[0.x.49531] 
[0.x.49532] 
[0.x.49533] 
[0.x.49534] 
[0.x.49535] 
[0.x.49536] 
[0.x.49537] 
[0.x.49538] 
[0.x.49539] 
[0.x.49540] 
[0.x.49541] 
[0.x.49542] 
[0.x.49543] 
[0.x.49544] 
//
[0.x.49545] 
[0.x.49546] 
//
[0.x.49547] 
[0.x.49548] 
//
[0.x.49549] 
//
[0.x.49550] 
[0.x.49551] 
[0.x.49552] 
[0.x.49553] 
[0.x.49554] 
//
// At this point, we apply the filter to the unfiltered density, and apply the adjoint (transpose) operation to the unfiltered density multiplier, both to the current best guess for the nonlinear solution. We use this later to tell us how far off our filtered density is from the filter applied to the unfiltered density. That is because while at the solution of the nonlinear problem, we have  [2.x.5758] , but at intermediate iterations, we in general have  [2.x.5759]  and the "residual"  [2.x.5760]  will then appear as the right hand side of one of the Newton update equations that we compute below.
//
[0.x.49555] 
[0.x.49556] 
[0.x.49557] 
[0.x.49558] 
//
[0.x.49559] 
[0.x.49560] 
[0.x.49561] 
[0.x.49562] 
[0.x.49563] 
[0.x.49564] 
[0.x.49565] 
[0.x.49566] 
//
[0.x.49567] 
[0.x.49568] 
[0.x.49569] 
[0.x.49570] 
[0.x.49571] 
[0.x.49572] 
[0.x.49573] 
[0.x.49574] 
[0.x.49575] 
[0.x.49576] 
[0.x.49577] 
[0.x.49578] 
[0.x.49579] 
[0.x.49580] 
[0.x.49581] 
[0.x.49582] 
[0.x.49583] 
//
[0.x.49584] 
[0.x.49585] 
[0.x.49586] 
[0.x.49587] 
//
[0.x.49588] 
//
[0.x.49589] 
//
[0.x.49590] 
[0.x.49591] 
//
// As part of the construction of our system matrix, we need to retrieve values from our current guess at the solution. The following lines of code retrieve the needed values.
//
[0.x.49592] 
[0.x.49593] 
[0.x.49594] 
[0.x.49595] 
[0.x.49596] 
[0.x.49597] 
[0.x.49598] 
[0.x.49599] 
[0.x.49600] 
[0.x.49601] 
[0.x.49602] 
[0.x.49603] 
[0.x.49604] 
[0.x.49605] 
[0.x.49606] 
[0.x.49607] 
[0.x.49608] 
[0.x.49609] 
[0.x.49610] 
[0.x.49611] 
[0.x.49612] 
[0.x.49613] 
[0.x.49614] 
[0.x.49615] 
[0.x.49616] 
[0.x.49617] 
[0.x.49618] 
[0.x.49619] 
[0.x.49620] 
[0.x.49621] 
[0.x.49622] 
[0.x.49623] 
[0.x.49624] 
//
[0.x.49625] 
[0.x.49626] 
//
//   We need several more values corresponding to the test functions   coming from the first derivatives taken from the Lagrangian,   that is the  [2.x.5761]  functions. These are calculated here:
//
[0.x.49627] 
[0.x.49628] 
[0.x.49629] 
[0.x.49630] 
[0.x.49631] 
[0.x.49632] 
//
[0.x.49633] 
[0.x.49634] 
[0.x.49635] 
[0.x.49636] 
[0.x.49637] 
[0.x.49638] 
[0.x.49639] 
//
[0.x.49640] 
[0.x.49641] 
[0.x.49642] 
[0.x.49643] 
[0.x.49644] 
[0.x.49645] 
[0.x.49646] 
//
[0.x.49647] 
[0.x.49648] 
[0.x.49649] 
//
[0.x.49650] 
[0.x.49651] 
//
[0.x.49652] 
[0.x.49653] 
//
[0.x.49654] 
[0.x.49655] 
[0.x.49656] 
//
[0.x.49657] 
[0.x.49658] 
//
//           Finally, we need values that come from the second round           of derivatives taken from the Lagrangian,           the  [2.x.5762]  functions. These are calculated here:
//
[0.x.49659] 
[0.x.49660] 
[0.x.49661] 
[0.x.49662] 
[0.x.49663] 
//
[0.x.49664] 
[0.x.49665] 
[0.x.49666] 
[0.x.49667] 
[0.x.49668] 
[0.x.49669] 
[0.x.49670] 
//
[0.x.49671] 
[0.x.49672] 
//
[0.x.49673] 
[0.x.49674] 
[0.x.49675] 
[0.x.49676] 
[0.x.49677] 
//
[0.x.49678] 
[0.x.49679] 
//
[0.x.49680] 
[0.x.49681] 
//
[0.x.49682] 
[0.x.49683] 
[0.x.49684] 
//
[0.x.49685] 
[0.x.49686] 
[0.x.49687] 
//
//           This is where the actual work starts. In           the following, we will build all of the           terms of the matrix -- they are numerous           and not entirely self-explanatory, also           depending on the previous solutions and its           derivatives (which we have already           evaluated above and put into the variables           called `old_*`). To understand what each of           these terms corresponds to, you will want           to look at the explicit form of these terms           in the introduction above.                     The right hand sides of the equations being           driven to 0 give all the KKT conditions           for finding a local minimum -- the descriptions of what           each individual equation are given with the computations           of the right hand side.
//
//                    /* Equation 1  [2.x.5763] 
[0.x.49688] 
[0.x.49689] 
[0.x.49690] 
//
[0.x.49691] 
//
[0.x.49692] 
[0.x.49693] 
[0.x.49694] 
[0.x.49695] 
[0.x.49696] 
[0.x.49697] 
[0.x.49698] 
[0.x.49699] 
[0.x.49700] 
[0.x.49701] 
[0.x.49702] 
//
[0.x.49703] 
[0.x.49704] 
[0.x.49705] 
[0.x.49706] 
[0.x.49707] 
[0.x.49708] 
[0.x.49709] 
[0.x.49710] 
[0.x.49711] 
[0.x.49712] 
//
[0.x.49713] 
[0.x.49714] 
[0.x.49715] 
[0.x.49716] 
[0.x.49717] 
[0.x.49718] 
[0.x.49719] 
[0.x.49720] 
[0.x.49721] 
[0.x.49722] 
//
//                    /* Equation 2  [2.x.5764] 
[0.x.49723] 
[0.x.49724] 
[0.x.49725] 
[0.x.49726] 
[0.x.49727] 
[0.x.49728] 
[0.x.49729] 
[0.x.49730] 
[0.x.49731] 
[0.x.49732] 
[0.x.49733] 
//
[0.x.49734] 
[0.x.49735] 
[0.x.49736] 
[0.x.49737] 
[0.x.49738] 
[0.x.49739] 
[0.x.49740] 
//
[0.x.49741] 
//
//                    /* Equation 3, which has to do with the filter and which is
//
[0.x.49742] 
[0.x.49743] 
[0.x.49744] 
[0.x.49745] 
[0.x.49746] 
[0.x.49747] 
//
//                    /* Equation 4: Primal feasibility  [2.x.5765] 
[0.x.49748] 
[0.x.49749] 
[0.x.49750] 
//
[0.x.49751] 
[0.x.49752] 
[0.x.49753] 
[0.x.49754] 
[0.x.49755] 
[0.x.49756] 
[0.x.49757] 
[0.x.49758] 
[0.x.49759] 
[0.x.49760] 
//
[0.x.49761] 
[0.x.49762] 
[0.x.49763] 
[0.x.49764] 
[0.x.49765] 
[0.x.49766] 
[0.x.49767] 
[0.x.49768] 
//
//                    /* Equation 5: Primal feasibility  [2.x.5766] 
[0.x.49769] 
[0.x.49770] 
[0.x.49771] 
[0.x.49772] 
//
//                    /* Equation 6: Primal feasibility  [2.x.5767] 
[0.x.49773] 
[0.x.49774] 
[0.x.49775] 
[0.x.49776] 
//
//                    /* Equation 7: Primal feasibility
//
// - the part with the filter
//
[0.x.49777] 
[0.x.49778] 
[0.x.49779] 
[0.x.49780] 
//
//                    /* Equation 8: Complementary slackness  [2.x.5768] 
[0.x.49781] 
[0.x.49782] 
[0.x.49783] 
//
[0.x.49784] 
[0.x.49785] 
[0.x.49786] 
//
//                    /* Equation 9: Complementary slackness  [2.x.5769] 
[0.x.49787] 
[0.x.49788] 
[0.x.49789] 
//
[0.x.49790] 
[0.x.49791] 
[0.x.49792] 
[0.x.49793] 
[0.x.49794] 
[0.x.49795] 
//
// Now that we have everything assembled, all we have to do is deal with the effect of (Dirichlet) boundary conditions and other constraints. We incorporate the former locally with just the contributions from the current cell, and then let the AffineConstraint class deal with the latter while copying contributions from the current cell into the global linear system:
//
[0.x.49796] 
[0.x.49797] 
[0.x.49798] 
[0.x.49799] 
[0.x.49800] 
//
[0.x.49801] 
[0.x.49802] 
[0.x.49803] 
[0.x.49804] 
//
// Having accumulated all of the terms that belong into the Newton matrix, we now also have to compute the terms for the right hand side (i.e., the negative residual). We already do this in another function, and so we call that here:
//
[0.x.49805] 
//
// Here we use the filter matrix we have already constructed. We only need to integrate this filter applied to test functions, which are piecewise constant, and so the integration becomes a simple multiplication by the measure of the cell.  Iterating over the pre-made filter matrix allows us to use the information about which cells are in or out of the filter without repeatedly checking neighbor cells again.
//
[0.x.49806] 
[0.x.49807] 
[0.x.49808] 
[0.x.49809] 
[0.x.49810] 
[0.x.49811] 
[0.x.49812] 
[0.x.49813] 
[0.x.49814] 
[0.x.49815] 
//
[0.x.49816] 
[0.x.49817] 
[0.x.49818] 
[0.x.49819] 
[0.x.49820] 
[0.x.49821] 
[0.x.49822] 
[0.x.49823] 
[0.x.49824] 
[0.x.49825] 
[0.x.49826] 
//[2.x.5770] 
//
// We will need to solve a linear system in each iteration. We use a direct solver, for now -- this is clearly not an efficient choice for a matrix that has so many non-zeroes, and it will not scale to anything interesting. For "real" applications, we will need an iterative solver but the complexity of the system means that an iterative solver algorithm will take a good deal of work. Because this is not the focus of the current program, we simply stick with the direct solver we have here -- the function follows the same structure as used in  [2.x.5771] .
//
[0.x.49827] 
[0.x.49828] 
[0.x.49829] 
[0.x.49830] 
//
[0.x.49831] 
[0.x.49832] 
//
[0.x.49833] 
[0.x.49834] 
[0.x.49835] 
//
[0.x.49836] 
//
[0.x.49837] 
[0.x.49838] 
//[2.x.5772] 
//
// The next several functions deal with specific parts of the optimization algorithm, most notably with deciding whether the direction computed by solving the linearized (Newton) system is viable and, if so, how far we want to go in this direction.
//
//  [2.x.5773] 
//
// We start with a function that does a binary search to figure out the maximum step that meets the dual feasibility -- that is, how far can we go so that  [2.x.5774]  and  [2.x.5775] . The function returns a pair of values, one each for the  [2.x.5776]  and  [2.x.5777]  slack variables.
//
[0.x.49839] 
[0.x.49840] 
[0.x.49841] 
[0.x.49842] 
[0.x.49843] 
[0.x.49844] 
[0.x.49845] 
[0.x.49846] 
//
[0.x.49847] 
[0.x.49848] 
[0.x.49849] 
[0.x.49850] 
[0.x.49851] 
[0.x.49852] 
[0.x.49853] 
[0.x.49854] 
[0.x.49855] 
//
[0.x.49856] 
[0.x.49857] 
[0.x.49858] 
[0.x.49859] 
[0.x.49860] 
//
[0.x.49861] 
[0.x.49862] 
[0.x.49863] 
[0.x.49864] 
[0.x.49865] 
//
[0.x.49866] 
[0.x.49867] 
//
[0.x.49868] 
[0.x.49869] 
//
[0.x.49870] 
[0.x.49871] 
[0.x.49872] 
[0.x.49873] 
[0.x.49874] 
[0.x.49875] 
[0.x.49876] 
[0.x.49877] 
[0.x.49878] 
[0.x.49879] 
//
[0.x.49880] 
[0.x.49881] 
[0.x.49882] 
[0.x.49883] 
//
[0.x.49884] 
[0.x.49885] 
[0.x.49886] 
[0.x.49887] 
[0.x.49888] 
//
[0.x.49889] 
[0.x.49890] 
//[2.x.5778] 
//
// The next function computes a right hand side vector linearized around a "test solution vector" that we can use to look at the magnitude of the KKT conditions.  This is then used for testing the convergence before shrinking the barrier size, as well as in the calculation of the  [2.x.5779]  merit.
//
// The function is lengthy and complicated, but it is really just a copy of the right hand side part of what the `assemble_system()` function above did.
//
[0.x.49891] 
[0.x.49892] 
[0.x.49893] 
[0.x.49894] 
//
// We first create a zero vector with size and blocking of system_rhs
//
[0.x.49895] 
[0.x.49896] 
//
[0.x.49897] 
[0.x.49898] 
[0.x.49899] 
[0.x.49900] 
[0.x.49901] 
[0.x.49902] 
[0.x.49903] 
[0.x.49904] 
[0.x.49905] 
[0.x.49906] 
[0.x.49907] 
[0.x.49908] 
[0.x.49909] 
[0.x.49910] 
//
[0.x.49911] 
[0.x.49912] 
//
[0.x.49913] 
[0.x.49914] 
//
[0.x.49915] 
//
[0.x.49916] 
[0.x.49917] 
//
[0.x.49918] 
[0.x.49919] 
//
[0.x.49920] 
[0.x.49921] 
[0.x.49922] 
[0.x.49923] 
[0.x.49924] 
[0.x.49925] 
[0.x.49926] 
//
[0.x.49927] 
[0.x.49928] 
[0.x.49929] 
[0.x.49930] 
[0.x.49931] 
[0.x.49932] 
[0.x.49933] 
[0.x.49934] 
//
[0.x.49935] 
[0.x.49936] 
[0.x.49937] 
[0.x.49938] 
[0.x.49939] 
[0.x.49940] 
[0.x.49941] 
[0.x.49942] 
[0.x.49943] 
[0.x.49944] 
[0.x.49945] 
[0.x.49946] 
[0.x.49947] 
[0.x.49948] 
[0.x.49949] 
[0.x.49950] 
[0.x.49951] 
//
[0.x.49952] 
[0.x.49953] 
[0.x.49954] 
[0.x.49955] 
//
[0.x.49956] 
//
[0.x.49957] 
//
[0.x.49958] 
[0.x.49959] 
//
[0.x.49960] 
[0.x.49961] 
[0.x.49962] 
[0.x.49963] 
[0.x.49964] 
[0.x.49965] 
[0.x.49966] 
[0.x.49967] 
[0.x.49968] 
[0.x.49969] 
[0.x.49970] 
[0.x.49971] 
[0.x.49972] 
[0.x.49973] 
[0.x.49974] 
[0.x.49975] 
[0.x.49976] 
[0.x.49977] 
[0.x.49978] 
[0.x.49979] 
[0.x.49980] 
[0.x.49981] 
[0.x.49982] 
[0.x.49983] 
[0.x.49984] 
[0.x.49985] 
[0.x.49986] 
[0.x.49987] 
[0.x.49988] 
[0.x.49989] 
[0.x.49990] 
[0.x.49991] 
[0.x.49992] 
//
[0.x.49993] 
[0.x.49994] 
[0.x.49995] 
[0.x.49996] 
[0.x.49997] 
[0.x.49998] 
[0.x.49999] 
[0.x.50000] 
//
[0.x.50001] 
[0.x.50002] 
[0.x.50003] 
[0.x.50004] 
[0.x.50005] 
[0.x.50006] 
[0.x.50007] 
//
[0.x.50008] 
[0.x.50009] 
[0.x.50010] 
[0.x.50011] 
[0.x.50012] 
[0.x.50013] 
[0.x.50014] 
//
[0.x.50015] 
[0.x.50016] 
[0.x.50017] 
//
[0.x.50018] 
[0.x.50019] 
//
[0.x.50020] 
[0.x.50021] 
//
[0.x.50022] 
[0.x.50023] 
[0.x.50024] 
//
//                /* Equation 1: This equation, along with equations
//
[0.x.50025] 
[0.x.50026] 
[0.x.50027] 
[0.x.50028] 
[0.x.50029] 
[0.x.50030] 
[0.x.50031] 
[0.x.50032] 
[0.x.50033] 
[0.x.50034] 
[0.x.50035] 
[0.x.50036] 
[0.x.50037] 
[0.x.50038] 
[0.x.50039] 
[0.x.50040] 
[0.x.50041] 
[0.x.50042] 
//
//                /* Equation 2; the boundary terms will be added further down
//
[0.x.50043] 
[0.x.50044] 
[0.x.50045] 
[0.x.50046] 
[0.x.50047] 
[0.x.50048] 
[0.x.50049] 
[0.x.50050] 
[0.x.50051] 
[0.x.50052] 
//
//                /* Equation 3  [2.x.5780] 
[0.x.50053] 
[0.x.50054] 
[0.x.50055] 
[0.x.50056] 
[0.x.50057] 
[0.x.50058] 
[0.x.50059] 
[0.x.50060] 
[0.x.50061] 
//
//                /* Equation 4; boundary term will again be dealt
//
[0.x.50062] 
[0.x.50063] 
[0.x.50064] 
[0.x.50065] 
[0.x.50066] 
[0.x.50067] 
[0.x.50068] 
[0.x.50069] 
[0.x.50070] 
[0.x.50071] 
[0.x.50072] 
[0.x.50073] 
//
//                /* Equation 5: This equation sets the lower slack
//
[0.x.50074] 
[0.x.50075] 
[0.x.50076] 
[0.x.50077] 
[0.x.50078] 
[0.x.50079] 
//
//                /* Equation 6: This equation sets the upper slack
//
[0.x.50080] 
[0.x.50081] 
[0.x.50082] 
[0.x.50083] 
[0.x.50084] 
[0.x.50085] 
//
//                /* Equation 7: This is the difference between the
//
[0.x.50086] 
[0.x.50087] 
[0.x.50088] 
[0.x.50089] 
[0.x.50090] 
[0.x.50091] 
[0.x.50092] 
[0.x.50093] 
//
//                /* Equation 8: This along with equation 9 give the
//
[0.x.50094] 
[0.x.50095] 
[0.x.50096] 
[0.x.50097] 
[0.x.50098] 
[0.x.50099] 
[0.x.50100] 
[0.x.50101] 
//
//                /* Equation 9  [2.x.5781] 
[0.x.50102] 
[0.x.50103] 
[0.x.50104] 
[0.x.50105] 
[0.x.50106] 
[0.x.50107] 
[0.x.50108] 
//
[0.x.50109] 
[0.x.50110] 
[0.x.50111] 
[0.x.50112] 
[0.x.50113] 
[0.x.50114] 
//
[0.x.50115] 
[0.x.50116] 
[0.x.50117] 
[0.x.50118] 
[0.x.50119] 
[0.x.50120] 
[0.x.50121] 
//
[0.x.50122] 
[0.x.50123] 
[0.x.50124] 
[0.x.50125] 
[0.x.50126] 
//
[0.x.50127] 
[0.x.50128] 
[0.x.50129] 
[0.x.50130] 
[0.x.50131] 
[0.x.50132] 
[0.x.50133] 
[0.x.50134] 
[0.x.50135] 
//
[0.x.50136] 
[0.x.50137] 
[0.x.50138] 
[0.x.50139] 
[0.x.50140] 
//
[0.x.50141] 
[0.x.50142] 
[0.x.50143] 
[0.x.50144] 
//
[0.x.50145] 
[0.x.50146] 
//[2.x.5782] 
//
// The algorithm we use herein uses a "watchdog" strategy to determine where and how far to go from the current iterate.  We base the watchdog strategy on an exact  [2.x.5783]  merit function. This function calculates the exact  [2.x.5784]  merit of a given, putative, next iterate.
//
// The merit function consists of the sum of the objective function (which is simply an integral of external forces (on the boundary of the domain) times the displacement values of a test solution (typically, the current solution plus some multiple of the Newton update), and the  [2.x.5785]  norms of the Lagrange multiplier components of residual vectors. The following code computes these parts in turn:
//
[0.x.50147] 
[0.x.50148] 
[0.x.50149] 
[0.x.50150] 
[0.x.50151] 
//
// Start with computing the objective function:
//
[0.x.50152] 
[0.x.50153] 
[0.x.50154] 
[0.x.50155] 
[0.x.50156] 
[0.x.50157] 
[0.x.50158] 
[0.x.50159] 
[0.x.50160] 
[0.x.50161] 
[0.x.50162] 
[0.x.50163] 
[0.x.50164] 
[0.x.50165] 
[0.x.50166] 
[0.x.50167] 
[0.x.50168] 
//
[0.x.50169] 
//
[0.x.50170] 
//
[0.x.50171] 
[0.x.50172] 
[0.x.50173] 
[0.x.50174] 
[0.x.50175] 
[0.x.50176] 
[0.x.50177] 
[0.x.50178] 
[0.x.50179] 
[0.x.50180] 
[0.x.50181] 
[0.x.50182] 
[0.x.50183] 
[0.x.50184] 
[0.x.50185] 
[0.x.50186] 
[0.x.50187] 
//
[0.x.50188] 
[0.x.50189] 
[0.x.50190] 
[0.x.50191] 
[0.x.50192] 
[0.x.50193] 
[0.x.50194] 
[0.x.50195] 
//
[0.x.50196] 
[0.x.50197] 
[0.x.50198] 
[0.x.50199] 
[0.x.50200] 
[0.x.50201] 
[0.x.50202] 
[0.x.50203] 
[0.x.50204] 
[0.x.50205] 
[0.x.50206] 
[0.x.50207] 
[0.x.50208] 
//
// Then compute the residual and take the  [2.x.5786]  norms of the components that correspond to Lagrange mulipliers. We add those to the objective function computed above, and return the sum at the bottom:
//
[0.x.50209] 
//
[0.x.50210] 
[0.x.50211] 
[0.x.50212] 
[0.x.50213] 
[0.x.50214] 
[0.x.50215] 
[0.x.50216] 
[0.x.50217] 
[0.x.50218] 
[0.x.50219] 
[0.x.50220] 
[0.x.50221] 
//
[0.x.50222] 
[0.x.50223] 
[0.x.50224] 
[0.x.50225] 
[0.x.50226] 
//
//  [2.x.5787] 
//
// Next up is the function that actually computes a search direction starting at the current state (passed as the first argument) and returns the resulting vector. To this end, the function first calls the functions that assemble the linear system that corresponds to the Newton system, and that solve it.
//
// This function also updates the penalty multiplier in the merit function, and then returns the largest scaled feasible step. It uses the `calculate_max_step_sizes()` function to find the largest feasible step that satisfies  [2.x.5788]  and  [2.x.5789] .
//
[0.x.50227] 
[0.x.50228] 
[0.x.50229] 
[0.x.50230] 
[0.x.50231] 
//
// Next we are going to update penalty_multiplier.  In essence, a larger penalty multiplier makes us consider the constraints more.  Looking at the Hessian and gradient with respect to the step we want to take with our decision variables, and comparing that to the norm of our constraint error gives us a way to ensure that our merit function is "exact"
//
// - that is, it has a minimum in the same location that the objective function does.  As our merit function is exact for any penalty multiplier over some minimum value, we only keep the computed value if it increases the penalty multiplier.
//
[0.x.50232] 
[0.x.50233] 
[0.x.50234] 
[0.x.50235] 
[0.x.50236] 
[0.x.50237] 
[0.x.50238] 
[0.x.50239] 
[0.x.50240] 
[0.x.50241] 
[0.x.50242] 
[0.x.50243] 
[0.x.50244] 
[0.x.50245] 
[0.x.50246] 
[0.x.50247] 
[0.x.50248] 
[0.x.50249] 
[0.x.50250] 
[0.x.50251] 
//
[0.x.50252] 
[0.x.50253] 
[0.x.50254] 
[0.x.50255] 
[0.x.50256] 
[0.x.50257] 
[0.x.50258] 
[0.x.50259] 
//
[0.x.50260] 
[0.x.50261] 
[0.x.50262] 
[0.x.50263] 
[0.x.50264] 
[0.x.50265] 
//
[0.x.50266] 
//
// Based on all of this, we can now compute step sizes for the primal and dual (Lagrange multiplier) variables. Once we have these, we scale the components of the solution vector, and that is what this function returns.
//
[0.x.50267] 
[0.x.50268] 
[0.x.50269] 
[0.x.50270] 
//
[0.x.50271] 
[0.x.50272] 
[0.x.50273] 
[0.x.50274] 
[0.x.50275] 
[0.x.50276] 
[0.x.50277] 
[0.x.50278] 
[0.x.50279] 
//
[0.x.50280] 
[0.x.50281] 
//
//  [2.x.5790] 
//
// The next function then implements a back-tracking algorithm for a line search. It keeps shrinking step size until it finds a step where the merit is decreased, and then returns the new location based on the current state vector, and the direction to go into, times the step length.
//
[0.x.50282] 
[0.x.50283] 
[0.x.50284] 
[0.x.50285] 
[0.x.50286] 
[0.x.50287] 
[0.x.50288] 
[0.x.50289] 
[0.x.50290] 
[0.x.50291] 
[0.x.50292] 
[0.x.50293] 
[0.x.50294] 
[0.x.50295] 
[0.x.50296] 
[0.x.50297] 
[0.x.50298] 
[0.x.50299] 
[0.x.50300] 
[0.x.50301] 
[0.x.50302] 
[0.x.50303] 
[0.x.50304] 
//[2.x.5791] 
//
// The final auxiliary function in this block is the one that checks to see if the KKT conditions are sufficiently met so that the overall algorithm can lower the barrier size. It does so by computing the  [2.x.5792]  norm of the residual, which is what `calculate_test_rhs()` computes.
//
[0.x.50305] 
[0.x.50306] 
[0.x.50307] 
[0.x.50308] 
[0.x.50309] 
//
[0.x.50310] 
[0.x.50311] 
//
[0.x.50312] 
[0.x.50313] 
//
[0.x.50314] 
[0.x.50315] 
//[2.x.5793] 
//
// The first of the postprocessing functions outputs information in a VTU file for visualization. It looks long, but it's really just the same as what was done in  [2.x.5794] , for example, just with (a lot) more solution variables:
//
[0.x.50316] 
[0.x.50317] 
[0.x.50318] 
[0.x.50319] 
[0.x.50320] 
[0.x.50321] 
[0.x.50322] 
[0.x.50323] 
[0.x.50324] 
[0.x.50325] 
[0.x.50326] 
[0.x.50327] 
[0.x.50328] 
[0.x.50329] 
[0.x.50330] 
[0.x.50331] 
[0.x.50332] 
[0.x.50333] 
[0.x.50334] 
[0.x.50335] 
[0.x.50336] 
[0.x.50337] 
[0.x.50338] 
[0.x.50339] 
[0.x.50340] 
[0.x.50341] 
[0.x.50342] 
[0.x.50343] 
[0.x.50344] 
[0.x.50345] 
[0.x.50346] 
[0.x.50347] 
[0.x.50348] 
[0.x.50349] 
[0.x.50350] 
[0.x.50351] 
[0.x.50352] 
//
[0.x.50353] 
[0.x.50354] 
[0.x.50355] 
[0.x.50356] 
[0.x.50357] 
[0.x.50358] 
[0.x.50359] 
//
[0.x.50360] 
[0.x.50361] 
[0.x.50362] 
//
// The second of these functions outputs the solution as an `.stl` file for 3d printing. [STL](https:en.wikipedia.org/wiki/STL_(file_format)) files are made up of triangles and normal vectors, and we will use it to show all of those cells with a density value larger than zero by first extruding the mesh from a  [2.x.5795]  value of zero to  [2.x.5796] , and then generating two triangles for each face of the cells with a sufficiently large density value. The triangle nodes must go counter-clockwise when looking from the outside, and the normal vectors must be unit vectors pointing outwards, which requires a few checks.
//
[0.x.50363] 
[0.x.50364] 
[0.x.50365] 
[0.x.50366] 
[0.x.50367] 
[0.x.50368] 
//
[0.x.50369] 
[0.x.50370] 
//
[0.x.50371] 
[0.x.50372] 
//
[0.x.50373] 
[0.x.50374] 
[0.x.50375] 
[0.x.50376] 
[0.x.50377] 
//
//   We have now found a cell with a density value larger   than zero. Let us start by writing out the bottom   and top faces. Owing to the ordering issue mentioned   above, we have to make sure that we understand   whether a cell has a right- or left-handed   coordinate system. We do this by interrogating the   directions of the two edges starting at vertex 0 and   whether they form a right-handed coordinate system.
//
[0.x.50378] 
[0.x.50379] 
[0.x.50380] 
[0.x.50381] 
[0.x.50382] 
[0.x.50383] 
[0.x.50384] 
[0.x.50385] 
//
[0.x.50386] 
[0.x.50387] 
//
//                /* Write one side at z = 0.  [2.x.5797] 
[0.x.50388] 
[0.x.50389] 
[0.x.50390] 
[0.x.50391] 
[0.x.50392] 
[0.x.50393] 
[0.x.50394] 
[0.x.50395] 
[0.x.50396] 
[0.x.50397] 
[0.x.50398] 
[0.x.50399] 
[0.x.50400] 
[0.x.50401] 
[0.x.50402] 
[0.x.50403] 
[0.x.50404] 
[0.x.50405] 
[0.x.50406] 
[0.x.50407] 
[0.x.50408] 
[0.x.50409] 
//
//                /* Write one side at z = height.  [2.x.5798] 
[0.x.50410] 
[0.x.50411] 
[0.x.50412] 
[0.x.50413] 
[0.x.50414] 
[0.x.50415] 
[0.x.50416] 
[0.x.50417] 
[0.x.50418] 
[0.x.50419] 
[0.x.50420] 
[0.x.50421] 
[0.x.50422] 
[0.x.50423] 
[0.x.50424] 
[0.x.50425] 
[0.x.50426] 
[0.x.50427] 
[0.x.50428] 
[0.x.50429] 
[0.x.50430] 
[0.x.50431] 
[0.x.50432] 
[0.x.50433] 
[0.x.50434] 
//
//                /* Write one side at z = 0.  [2.x.5799] 
[0.x.50435] 
[0.x.50436] 
[0.x.50437] 
[0.x.50438] 
[0.x.50439] 
[0.x.50440] 
[0.x.50441] 
[0.x.50442] 
[0.x.50443] 
[0.x.50444] 
[0.x.50445] 
[0.x.50446] 
[0.x.50447] 
[0.x.50448] 
[0.x.50449] 
[0.x.50450] 
[0.x.50451] 
[0.x.50452] 
[0.x.50453] 
[0.x.50454] 
[0.x.50455] 
[0.x.50456] 
//
//                /* Write one side at z = height.  [2.x.5800] 
[0.x.50457] 
[0.x.50458] 
[0.x.50459] 
[0.x.50460] 
[0.x.50461] 
[0.x.50462] 
[0.x.50463] 
[0.x.50464] 
[0.x.50465] 
[0.x.50466] 
[0.x.50467] 
[0.x.50468] 
[0.x.50469] 
[0.x.50470] 
[0.x.50471] 
[0.x.50472] 
[0.x.50473] 
[0.x.50474] 
[0.x.50475] 
[0.x.50476] 
[0.x.50477] 
[0.x.50478] 
[0.x.50479] 
//
//   Next we need to deal with the four faces of the   cell, extended into the  [2.x.5801]  direction. However, we   only need to write these faces if either the face   is on the domain boundary, or if it is the   interface between a cell with density greater than   0.5, and a cell with a density less than 0.5.
//
[0.x.50480] 
[0.x.50481] 
[0.x.50482] 
[0.x.50483] 
[0.x.50484] 
[0.x.50485] 
//
[0.x.50486] 
[0.x.50487] 
[0.x.50488] 
[0.x.50489] 
[0.x.50490] 
[0.x.50491] 
[0.x.50492] 
[0.x.50493] 
[0.x.50494] 
[0.x.50495] 
[0.x.50496] 
[0.x.50497] 
[0.x.50498] 
[0.x.50499] 
[0.x.50500] 
[0.x.50501] 
[0.x.50502] 
[0.x.50503] 
[0.x.50504] 
[0.x.50505] 
[0.x.50506] 
[0.x.50507] 
[0.x.50508] 
[0.x.50509] 
[0.x.50510] 
[0.x.50511] 
[0.x.50512] 
[0.x.50513] 
[0.x.50514] 
[0.x.50515] 
[0.x.50516] 
[0.x.50517] 
[0.x.50518] 
[0.x.50519] 
[0.x.50520] 
[0.x.50521] 
[0.x.50522] 
[0.x.50523] 
[0.x.50524] 
[0.x.50525] 
[0.x.50526] 
[0.x.50527] 
[0.x.50528] 
[0.x.50529] 
[0.x.50530] 
[0.x.50531] 
[0.x.50532] 
[0.x.50533] 
[0.x.50534] 
[0.x.50535] 
[0.x.50536] 
[0.x.50537] 
[0.x.50538] 
[0.x.50539] 
[0.x.50540] 
[0.x.50541] 
[0.x.50542] 
[0.x.50543] 
[0.x.50544] 
[0.x.50545] 
[0.x.50546] 
[0.x.50547] 
[0.x.50548] 
[0.x.50549] 
[0.x.50550] 
[0.x.50551] 
[0.x.50552] 
[0.x.50553] 
[0.x.50554] 
[0.x.50555] 
[0.x.50556] 
[0.x.50557] 
[0.x.50558] 
[0.x.50559] 
[0.x.50560] 
[0.x.50561] 
[0.x.50562] 
[0.x.50563] 
[0.x.50564] 
[0.x.50565] 
[0.x.50566] 
[0.x.50567] 
[0.x.50568] 
[0.x.50569] 
[0.x.50570] 
[0.x.50571] 
[0.x.50572] 
[0.x.50573] 
[0.x.50574] 
[0.x.50575] 
[0.x.50576] 
[0.x.50577] 
[0.x.50578] 
[0.x.50579] 
[0.x.50580] 
[0.x.50581] 
[0.x.50582] 
[0.x.50583] 
[0.x.50584] 
[0.x.50585] 
//
//  [2.x.5802] 
//
// This function finally provides the overall driver logic. It is, in the grand scheme of things, a rather complicated function primarily because the optimization algorithm is difficult: It isn't just about finding a Newton direction like in  [2.x.5803]  and then going a fixed distance in this direction any more, but instead about (i) determining what the optimal log-barrier penalty parameter should be in the current step, (ii) a complicated algorithm to determine how far we want to go, and other ingredients. Let us see how we can break this down into smaller chunks in the following documentation.
//
// The function starts out simple enough with first setting up the mesh, the DoFHandler, and then the various linear algebra objects necessary for the following:
//
[0.x.50586] 
[0.x.50587] 
[0.x.50588] 
[0.x.50589] 
//
[0.x.50590] 
[0.x.50591] 
//
[0.x.50592] 
//
[0.x.50593] 
[0.x.50594] 
//
[0.x.50595] 
[0.x.50596] 
[0.x.50597] 
[0.x.50598] 
//
// We then set a number of parameters that affect the log-barrier and line search components of the optimization algorithm:
//
[0.x.50599] 
[0.x.50600] 
//
[0.x.50601] 
[0.x.50602] 
//
// Now start the principal iteration. The overall algorithm works by using an outer loop in which we loop until either (i) the log-barrier parameter has become small enough, or (ii) we have reached convergence. In any case, we terminate if end up with too large a number of iterations. This overall structure is encoded as a `do { ... } while (...)` loop where the convergence condition is at the bottom.
//
[0.x.50603] 
[0.x.50604] 
//
[0.x.50605] 
[0.x.50606] 
[0.x.50607] 
[0.x.50608] 
//
// Within this outer loop, we have an inner loop in which we try to find an update direction using the watchdog algorithm described in the introduction.
//
// The general idea of the watchdog algorithm itself is this: For a maximum of `max_uphill_steps` (i.e., a loop within the "inner loop" mentioned above) attempts, we use `find_max_step()` to compute a Newton update step, and add these up in the `nonlinear_solution` vector.  In each of these attempts (starting from the place reached at the end of the previous attempt), we check whether we have reached a target value of the merit function described above. The target value is computed based on where this algorithm starts (the `nonlinear_solution` at the beginning of the watchdog loop, saves as `watchdog_state`) and the first proposed direction provided by `find_max_step()` in the first go-around of this loop (the `k==0` case).
//
[0.x.50609] 
[0.x.50610] 
[0.x.50611] 
[0.x.50612] 
[0.x.50613] 
[0.x.50614] 
//
[0.x.50615] 
//
[0.x.50616] 
[0.x.50617] 
[0.x.50618] 
[0.x.50619] 
//
[0.x.50620] 
[0.x.50621] 
[0.x.50622] 
[0.x.50623] 
//
[0.x.50624] 
[0.x.50625] 
[0.x.50626] 
[0.x.50627] 
[0.x.50628] 
[0.x.50629] 
[0.x.50630] 
[0.x.50631] 
[0.x.50632] 
[0.x.50633] 
[0.x.50634] 
//
[0.x.50635] 
[0.x.50636] 
[0.x.50637] 
//
[0.x.50638] 
[0.x.50639] 
[0.x.50640] 
//
[0.x.50641] 
[0.x.50642] 
[0.x.50643] 
[0.x.50644] 
[0.x.50645] 
[0.x.50646] 
[0.x.50647] 
[0.x.50648] 
//
//   The next part of the algorithm then depends on   whether the watchdog loop above succeeded. If it   did, then we are satisfied and no further action is   necessary: We just stay where we are. If, however,   we took the maximal number of unsuccessful steps in   the loop above, then we need to do something else,   and this is what the following code block does.     Specifically, from the final (unsuccessful) state   of the loop above, we seek one more update   direction and take what is called a "stretch   step". If that stretch state satisfies a condition   involving the merit function, then we go there. On   the other hand, if the stretch state is also   unacceptable (as all of the watchdog steps above   were), then we discard all of the watchdog steps   taken above and start over again where we had   started the watchdog iterations -- that place was   stored in the `watchdog_state` variable above. More   specifically, the conditions below first test   whether we take a step from `watchdog_state` in   direction `first_step`, or whether we can do one   more update from the stretch state to find a new   place. It is possible that neither of these is   actually better than the state we started from at   the beginning of the watchdog algorithm, but even   if that is so, that place clearly was a difficult   place to be in, and getting away to start the next   iteration from another place might be a useful   strategy to eventually converge.     We keep repeating the watchdog steps above along   with the logic below until this inner iteration is   finally converged (or if we run up against the   maximal number of iterations -- where we count the   number of linear solves as iterations and increment   the counter every time we call `find_max_step()`   since that is where the linear solve actually   happens). In any case, at the end of each of these   inner iterations we also output the solution in a   form suitable for visualization.
//
[0.x.50649] 
[0.x.50650] 
[0.x.50651] 
[0.x.50652] 
[0.x.50653] 
[0.x.50654] 
[0.x.50655] 
[0.x.50656] 
//
//       If we did not get a successful watchdog step,       we now need to decide between going back to       where we started, or using the final state.  We       compare the merits of both of these locations,       and then take a scaled step from whichever       location is better.  As the scaled step is       guaranteed to lower the merit, we will end up       keeping one of the two.
//
[0.x.50657] 
[0.x.50658] 
[0.x.50659] 
[0.x.50660] 
[0.x.50661] 
[0.x.50662] 
[0.x.50663] 
[0.x.50664] 
[0.x.50665] 
[0.x.50666] 
[0.x.50667] 
[0.x.50668] 
[0.x.50669] 
[0.x.50670] 
[0.x.50671] 
[0.x.50672] 
[0.x.50673] 
[0.x.50674] 
[0.x.50675] 
[0.x.50676] 
[0.x.50677] 
[0.x.50678] 
[0.x.50679] 
[0.x.50680] 
[0.x.50681] 
[0.x.50682] 
[0.x.50683] 
[0.x.50684] 
[0.x.50685] 
[0.x.50686] 
[0.x.50687] 
[0.x.50688] 
[0.x.50689] 
[0.x.50690] 
//
[0.x.50691] 
[0.x.50692] 
[0.x.50693] 
[0.x.50694] 
//
// At the end of the outer loop, we have to update the barrier parameter, for which we use the following formula. The rest of the function is then simply about checking the outer loop convergence condition, and if we decide to terminate computations, about writing the final "design" as an STL file for use in 3d printing, and to output some timing information.
//
[0.x.50695] 
[0.x.50696] 
//
[0.x.50697] 
[0.x.50698] 
[0.x.50699] 
[0.x.50700] 
//
[0.x.50701] 
[0.x.50702] 
[0.x.50703] 
[0.x.50704] 
[0.x.50705] 
//
[0.x.50706] 
[0.x.50707] 
[0.x.50708] 
[0.x.50709] 
//[2.x.5804] 
//
// The remainder of the code, the `main()` function, is as usual:
//
[0.x.50710] 
[0.x.50711] 
[0.x.50712] 
[0.x.50713] 
[0.x.50714] 
[0.x.50715] 
[0.x.50716] 
[0.x.50717] 
[0.x.50718] 
[0.x.50719] 
[0.x.50720] 
[0.x.50721] 
[0.x.50722] 
[0.x.50723] 
[0.x.50724] 
[0.x.50725] 
[0.x.50726] 
[0.x.50727] 
//
[0.x.50728] 
[0.x.50729] 
[0.x.50730] 
[0.x.50731] 
[0.x.50732] 
[0.x.50733] 
[0.x.50734] 
[0.x.50735] 
[0.x.50736] 
[0.x.50737] 
[0.x.50738] 
[0.x.50739] 
[0.x.50740] 
[0.x.50741] 
[0.x.50742] 
[0.x.50743] 
[0.x.50744] 
[0.x.50745] 
[0.x.50746] 
[0.x.50747] 
[0.x.50748] 
[0.x.50749] 
[0.x.50750] 
[0.x.50751] 
[0.x.50752] 
[0.x.50753] 
[0.x.50754] 
[0.x.50755] 
[0.x.50756] 
[0.x.50757] 
//
[0.x.50758] 
[0.x.50759] 
[0.x.50760] 
//[2.x.5805] 
//
// As usual, the first few include files are already known, so we will not comment on them further.
//
[0.x.50761] 
[0.x.50762] 
[0.x.50763] 
//
[0.x.50764] 
[0.x.50765] 
[0.x.50766] 
[0.x.50767] 
[0.x.50768] 
[0.x.50769] 
[0.x.50770] 
//
[0.x.50771] 
[0.x.50772] 
[0.x.50773] 
//
[0.x.50774] 
[0.x.50775] 
//
[0.x.50776] 
//
[0.x.50777] 
[0.x.50778] 
[0.x.50779] 
[0.x.50780] 
//
// In this example, we need vector-valued finite elements. The support for these can be found in the following include file:
//
[0.x.50781] 
//
// We will compose the vector-valued finite elements from regular Q1 elements which can be found here, as usual:
//
[0.x.50782] 
//
// This again is C++:
//
[0.x.50783] 
[0.x.50784] 
//
// The last step is as in previous programs. In particular, just like in  [2.x.5806] , we pack everything that's specific to this program into a namespace of its own.
//
[0.x.50785] 
[0.x.50786] 
[0.x.50787] 
//[2.x.5807] 
//
// The main class is, except for its name, almost unchanged with respect to the  [2.x.5808]  example.
//
// The only change is the use of a different class for the  [2.x.5809]  variable: Instead of a concrete finite element class such as FE_Q, we now use a more generic one, FESystem. In fact, FESystem is not really a finite element itself in that it does not implement shape functions of its own. Rather, it is a class that can be used to stack several other elements together to form one vector-valued finite element. In our case, we will compose the vector-valued element of  [2.x.5810]  objects, as shown below in the constructor of this class.
//
[0.x.50788] 
[0.x.50789] 
[0.x.50790] 
[0.x.50791] 
[0.x.50792] 
[0.x.50793] 
//
[0.x.50794] 
[0.x.50795] 
[0.x.50796] 
[0.x.50797] 
[0.x.50798] 
[0.x.50799] 
//
[0.x.50800] 
[0.x.50801] 
//
[0.x.50802] 
//
[0.x.50803] 
//
[0.x.50804] 
[0.x.50805] 
//
[0.x.50806] 
[0.x.50807] 
[0.x.50808] 
//[2.x.5811] 
//
// Before going over to the implementation of the main class, we declare and define the function which describes the right hand side. This time, the right hand side is vector-valued, as is the solution, so we will describe the changes required for this in some more detail.
//
// To prevent cases where the return vector has not previously been set to the right size we test for this case and otherwise throw an exception at the beginning of the function. Note that enforcing that output arguments already have the correct size is a convention in deal.II, and enforced almost everywhere. The reason is that we would otherwise have to check at the beginning of the function and possibly change the size of the output vector. This is expensive, and would almost always be unnecessary (the first call to the function would set the vector to the right size, and subsequent calls would only have to do redundant checks). In addition, checking and possibly resizing the vector is an operation that can not be removed if we can't rely on the assumption that the vector already has the correct size; this is in contract to the Assert call that is completely removed if the program is compiled in optimized mode.
//
// Likewise, if by some accident someone tried to compile and run the program in only one space dimension (in which the elastic equations do not make much sense since they reduce to the ordinary Laplace equation), we terminate the program in the second assertion. The program will work just fine in 3d, however.
//
[0.x.50809] 
[0.x.50810] 
[0.x.50811] 
[0.x.50812] 
[0.x.50813] 
[0.x.50814] 
[0.x.50815] 
//
// The rest of the function implements computing force values. We will use a constant (unit) force in x-direction located in two little circles (or spheres, in 3d) around points (0.5,0) and (-0.5,0), and y-force in an area around the origin; in 3d, the z-component of these centers is zero as well.
//
// For this, let us first define two objects that denote the centers of these areas. Note that upon construction of the Point objects, all components are set to zero.
//
[0.x.50816] 
[0.x.50817] 
[0.x.50818] 
//
[0.x.50819] 
[0.x.50820] 
//
// If  [2.x.5812]  is in a circle (sphere) of radius 0.2 around one of these points, then set the force in x-direction to one, otherwise to zero:
//
[0.x.50821] 
[0.x.50822] 
[0.x.50823] 
[0.x.50824] 
[0.x.50825] 
//
// Likewise, if  [2.x.5813]  is in the vicinity of the origin, then set the y-force to one, otherwise to zero:
//
[0.x.50826] 
[0.x.50827] 
[0.x.50828] 
[0.x.50829] 
[0.x.50830] 
[0.x.50831] 
//
//  [2.x.5814] 
//[2.x.5815] 
//
// Following is the constructor of the main class. As said before, we would like to construct a vector-valued finite element that is composed of several scalar finite elements (i.e., we want to build the vector-valued element so that each of its vector components consists of the shape functions of a scalar element). Of course, the number of scalar finite elements we would like to stack together equals the number of components the solution function has, which is  [2.x.5816]  since we consider displacement in each space direction. The FESystem class can handle this: we pass it the finite element of which we would like to compose the system of, and how often it shall be repeated:
//
[0.x.50832] 
[0.x.50833] 
[0.x.50834] 
[0.x.50835] 
[0.x.50836] 
//
// In fact, the FESystem class has several more constructors which can perform more complex operations than just stacking together several scalar finite elements of the same type into one; we will get to know these possibilities in later examples.
//
//  [2.x.5817] 
//
// Setting up the system of equations is identical to the function used in the  [2.x.5818]  example. The DoFHandler class and all other classes used here are fully aware that the finite element we want to use is vector-valued, and take care of the vector-valuedness of the finite element themselves. (In fact, they do not, but this does not need to bother you: since they only need to know how many degrees of freedom there are per vertex, line and cell, and they do not ask what they represent, i.e. whether the finite element under consideration is vector-valued or whether it is, for example, a scalar Hermite element with several degrees of freedom on each vertex).
//
[0.x.50837] 
[0.x.50838] 
[0.x.50839] 
[0.x.50840] 
[0.x.50841] 
[0.x.50842] 
//
[0.x.50843] 
[0.x.50844] 
[0.x.50845] 
[0.x.50846] 
[0.x.50847] 
[0.x.50848] 
[0.x.50849] 
//
[0.x.50850] 
[0.x.50851] 
[0.x.50852] 
[0.x.50853] 
//
//                                    /*keep_constrained_dofs =  [2.x.5819]  false);
//
[0.x.50854] 
//
[0.x.50855] 
[0.x.50856] 
//[2.x.5820] 
//
// The big changes in this program are in the creation of matrix and right hand side, since they are problem-dependent. We will go through that process  [2.x.5821] by-step, since it is a bit more complicated than in previous examples.
//
// The first parts of this function are the same as before, however: setting up a suitable quadrature formula, initializing an FEValues object for the (vector-valued) finite element we use as well as the quadrature object, and declaring a number of auxiliary arrays. In addition, we declare the ever same two abbreviations:  [2.x.5822]  and  [2.x.5823] . The number of degrees of freedom per cell we now obviously ask from the composed finite element rather than from the underlying scalar Q1 element. Here, it is  [2.x.5824]  times the number of degrees of freedom per cell of the Q1 element, though this is not explicit knowledge we need to care about:
//
[0.x.50857] 
[0.x.50858] 
[0.x.50859] 
[0.x.50860] 
//
[0.x.50861] 
[0.x.50862] 
[0.x.50863] 
[0.x.50864] 
//
[0.x.50865] 
[0.x.50866] 
//
[0.x.50867] 
[0.x.50868] 
//
[0.x.50869] 
//
// As was shown in previous examples as well, we need a place where to store the values of the coefficients at all the quadrature points on a cell. In the present situation, we have two coefficients, lambda and mu.
//
[0.x.50870] 
[0.x.50871] 
//
// Well, we could as well have omitted the above two arrays since we will use constant coefficients for both lambda and mu, which can be declared like this. They both represent functions always returning the constant value 1.0. Although we could omit the respective factors in the assemblage of the matrix, we use them here for purpose of demonstration.
//
[0.x.50872] 
//
// Like the two constant functions above, we will call the function right_hand_side just once per cell to make things simpler.
//
[0.x.50873] 
//
// Now we can begin with the loop over all cells:
//
[0.x.50874] 
[0.x.50875] 
[0.x.50876] 
[0.x.50877] 
//
[0.x.50878] 
//
// Next we get the values of the coefficients at the quadrature points. Likewise for the right hand side:
//
[0.x.50879] 
[0.x.50880] 
[0.x.50881] 
//
// Then assemble the entries of the local stiffness matrix and right hand side vector. This follows almost one-to-one the pattern described in the introduction of this example.  One of the few comments in place is that we can compute the number  [2.x.5825] , i.e. the index of the only nonzero vector component of shape function  [2.x.5826]  using the  [2.x.5827]  function call below.
//
// (By accessing the  [2.x.5828]  variable of the return value of the  [2.x.5829]  function, you might already have guessed that there is more in it. In fact, the function returns a  [2.x.5830]  int, unsigned int [2.x.5831]  of which the first element is  [2.x.5832]  and the second is the value  [2.x.5833]  also noted in the introduction, i.e.  the index of this shape function within all the shape functions that are nonzero in this component, i.e.  [2.x.5834]  in the diction of the introduction. This is not a number that we are usually interested in, however.)
//
// With this knowledge, we can assemble the local matrix contributions:
//
[0.x.50882] 
[0.x.50883] 
[0.x.50884] 
[0.x.50885] 
//
[0.x.50886] 
[0.x.50887] 
[0.x.50888] 
[0.x.50889] 
//
[0.x.50890] 
[0.x.50891] 
[0.x.50892] 
[0.x.50893] 
//
//             The first term is  [2.x.5835] . Note             that  [2.x.5836]  returns the             gradient of the only nonzero component of the i-th             shape function at quadrature point q_point. The             component  [2.x.5837]  of the gradient, which             is the derivative of this only nonzero vector             component of the i-th shape function with respect to             the comp(i)th coordinate is accessed by the appended             brackets.
//
[0.x.50894] 
[0.x.50895] 
[0.x.50896] 
[0.x.50897] 
[0.x.50898] 
[0.x.50899] 
[0.x.50900] 
[0.x.50901] 
[0.x.50902] 
//
//               The second term is  [2.x.5838] . We need not access a specific component of               the gradient, since we only have to compute the               scalar product of the two gradients, of which an               overloaded version of <tt>operator*</tt> takes               care, as in previous examples.                             Note that by using the <tt>?:</tt> operator, we only               do this if <tt>component_i</tt> equals               <tt>component_j</tt>, otherwise a zero is added               (which will be optimized away by the compiler).
//
[0.x.50903] 
[0.x.50904] 
[0.x.50905] 
[0.x.50906] 
[0.x.50907] 
[0.x.50908] 
[0.x.50909] 
[0.x.50910] 
[0.x.50911] 
[0.x.50912] 
//
// Assembling the right hand side is also just as discussed in the introduction:
//
[0.x.50913] 
[0.x.50914] 
[0.x.50915] 
[0.x.50916] 
//
[0.x.50917] 
[0.x.50918] 
[0.x.50919] 
[0.x.50920] 
[0.x.50921] 
[0.x.50922] 
//
// The transfer from local degrees of freedom into the global matrix and right hand side vector does not depend on the equation under consideration, and is thus the same as in all previous examples.
//
[0.x.50923] 
[0.x.50924] 
[0.x.50925] 
[0.x.50926] 
[0.x.50927] 
//
//  [2.x.5839] 
//
// The solver does not care about where the system of equations comes, as long as it stays positive definite and symmetric (which are the requirements for the use of the CG solver), which the system indeed is. Therefore, we need not change anything.
//
[0.x.50928] 
[0.x.50929] 
[0.x.50930] 
[0.x.50931] 
[0.x.50932] 
//
[0.x.50933] 
[0.x.50934] 
//
[0.x.50935] 
//
[0.x.50936] 
[0.x.50937] 
//[2.x.5840] 
//
// The function that does the refinement of the grid is the same as in the  [2.x.5841]  example. The quadrature formula is adapted to the linear elements again. Note that the error estimator by default adds up the estimated obtained from all components of the finite element solution, i.e., it uses the displacement in all directions with the same weight. If we would like the grid to be adapted to the x-displacement only, we could pass the function an additional parameter which tells it to do so and do not consider the displacements in all other directions for the error indicators. However, for the current problem, it seems appropriate to consider all displacement components with equal weight.
//
[0.x.50938] 
[0.x.50939] 
[0.x.50940] 
[0.x.50941] 
//
[0.x.50942] 
[0.x.50943] 
[0.x.50944] 
[0.x.50945] 
[0.x.50946] 
//
[0.x.50947] 
[0.x.50948] 
[0.x.50949] 
[0.x.50950] 
//
[0.x.50951] 
[0.x.50952] 
//[2.x.5842] 
//
// The output happens mostly as has been shown in previous examples already. The only difference is that the solution function is vector valued. The DataOut class takes care of this automatically, but we have to give each component of the solution vector a different name.
//
// To do this, the  [2.x.5843]  function wants a vector of strings. Since the number of components is the same as the number of dimensions we are working in, we use the  [2.x.5844]  statement below.
//
// We note that some graphics programs have restriction on what characters are allowed in the names of variables. deal.II therefore supports only the minimal subset of these characters that is supported by all programs. Basically, these are letters, numbers, underscores, and some other characters, but in particular no whitespace and minus/hyphen. The library will throw an exception otherwise, at least if in debug mode.
//
// After listing the 1d, 2d, and 3d case, it is good style to let the program die if we run upon a case which we did not consider. Remember that the Assert macro generates an exception if the condition in the first parameter is not satisfied. Of course, the condition  [2.x.5845]  can never be satisfied, so the program will always abort whenever it gets to the default statement:
//
[0.x.50953] 
[0.x.50954] 
[0.x.50955] 
[0.x.50956] 
[0.x.50957] 
//
[0.x.50958] 
[0.x.50959] 
[0.x.50960] 
[0.x.50961] 
[0.x.50962] 
[0.x.50963] 
[0.x.50964] 
[0.x.50965] 
[0.x.50966] 
[0.x.50967] 
[0.x.50968] 
[0.x.50969] 
[0.x.50970] 
[0.x.50971] 
[0.x.50972] 
[0.x.50973] 
[0.x.50974] 
[0.x.50975] 
//
// After setting up the names for the different components of the solution vector, we can add the solution vector to the list of data vectors scheduled for output. Note that the following function takes a vector of strings as second argument, whereas the one which we have used in all previous examples accepted a string there. (In fact, the function we had used before would convert the single string into a vector with only one element and forwards that to the other function.)
//
[0.x.50976] 
[0.x.50977] 
//
[0.x.50978] 
[0.x.50979] 
[0.x.50980] 
//
//  [2.x.5846] 
//
// The  [2.x.5847]  function does the same things as in  [2.x.5848] , for example. This time, we use the square [-1,1]^d as domain, and we refine it globally four times before starting the first iteration.
//
// The reason for refining is a bit accidental: we use the QGauss quadrature formula with two points in each direction for integration of the right hand side; that means that there are four quadrature points on each cell (in 2D). If we only refine the initial grid once globally, then there will be only four quadrature points in each direction on the domain. However, the right hand side function was chosen to be rather localized and in that case, by pure chance, it happens that all quadrature points lie at points where the right hand side function is zero (in mathematical terms, the quadrature points happen to be at points outside the [1.x.227] of the right hand side function). The right hand side vector computed with quadrature will then contain only zeroes (even though it would of course be nonzero if we had computed the right hand side vector exactly using the integral) and the solution of the system of equations is the zero vector, i.e., a finite element function that is zero everywhere. In a sense, we should not be surprised that this is happening since we have chosen an initial grid that is totally unsuitable for the problem at hand.
//
// The unfortunate thing is that if the discrete solution is constant, then the error indicators computed by the KellyErrorEstimator class are zero for each cell as well, and the call to  [2.x.5849]  will not flag any cells for refinement (why should it if the indicated error is zero for each cell?). The grid in the next iteration will therefore consist of four cells only as well, and the same problem occurs again.
//
// The conclusion needs to be: while of course we will not choose the initial grid to be well-suited for the accurate solution of the problem, we must at least choose it such that it has the chance to capture the important features of the solution. In this case, it needs to be able to see the right hand side. Thus, we refine globally four times. (Any larger number of global refinement steps would of course also work.)
//
[0.x.50981] 
[0.x.50982] 
[0.x.50983] 
[0.x.50984] 
[0.x.50985] 
[0.x.50986] 
//
[0.x.50987] 
[0.x.50988] 
[0.x.50989] 
[0.x.50990] 
[0.x.50991] 
[0.x.50992] 
[0.x.50993] 
//
[0.x.50994] 
[0.x.50995] 
//
[0.x.50996] 
//
[0.x.50997] 
[0.x.50998] 
//
[0.x.50999] 
[0.x.51000] 
[0.x.51001] 
[0.x.51002] 
[0.x.51003] 
[0.x.51004] 
//[2.x.5850] 
//
// After closing the  [2.x.5851]  namespace in the last line above, the following is the main function of the program and is again exactly like in  [2.x.5852]  (apart from the changed class names, of course).
//
[0.x.51005] 
[0.x.51006] 
[0.x.51007] 
[0.x.51008] 
[0.x.51009] 
[0.x.51010] 
[0.x.51011] 
[0.x.51012] 
[0.x.51013] 
[0.x.51014] 
[0.x.51015] 
[0.x.51016] 
[0.x.51017] 
[0.x.51018] 
[0.x.51019] 
[0.x.51020] 
[0.x.51021] 
[0.x.51022] 
//
[0.x.51023] 
[0.x.51024] 
[0.x.51025] 
[0.x.51026] 
[0.x.51027] 
[0.x.51028] 
[0.x.51029] 
[0.x.51030] 
[0.x.51031] 
[0.x.51032] 
[0.x.51033] 
[0.x.51034] 
[0.x.51035] 
[0.x.51036] 
//
[0.x.51037] 
[0.x.51038] 
[0.x.51039] 
[0.x.51040] 
[0.x.51041] 
[0.x.51042] 
[0.x.51043] 
[0.x.51044] 
[0.x.51045] 
[0.x.51046] 
[0.x.51047] 
[0.x.51048] 
[0.x.51049] 
[0.x.51050] 
[0.x.51051] 
[0.x.51052] 
//
[0.x.51053] 
[0.x.51054] 
[0.x.51055] 
//
// Just as in previous examples, we have to include several files of which the meaning has already been discussed:
//
[0.x.51056] 
[0.x.51057] 
[0.x.51058] 
[0.x.51059] 
[0.x.51060] 
[0.x.51061] 
[0.x.51062] 
[0.x.51063] 
[0.x.51064] 
[0.x.51065] 
[0.x.51066] 
[0.x.51067] 
[0.x.51068] 
[0.x.51069] 
[0.x.51070] 
[0.x.51071] 
[0.x.51072] 
[0.x.51073] 
[0.x.51074] 
[0.x.51075] 
[0.x.51076] 
//
// The following two files provide classes and information for multithreaded programs. In the first one, the classes and functions are declared which we need to do assembly in parallel (i.e. the  [2.x.5853]  namespace). The second file has a class MultithreadInfo which can be used to query the number of processors in your system, which is often useful when deciding how many threads to start in parallel.
//
[0.x.51077] 
[0.x.51078] 
//
// The next new include file declares a base class  [2.x.5854]  not unlike the  [2.x.5855]  class, but with the difference that  [2.x.5856]  returns a Tensor instead of a scalar.
//
[0.x.51079] 
//
[0.x.51080] 
//
// This is C++, as we want to write some output to disk:
//
[0.x.51081] 
[0.x.51082] 
//
// The last step is as in previous programs:
//
[0.x.51083] 
[0.x.51084] 
[0.x.51085] 
//[2.x.5857] 
//
// Next we declare a class that describes the advection field. This, of course, is a vector field with as many components as there are space dimensions. One could now use a class derived from the  [2.x.5858]  base class, as we have done for boundary values and coefficients in previous examples, but there is another possibility in the library, namely a base class that describes tensor valued functions. This is more convenient than overriding  [2.x.5859]  with a method that knows about multiple function components: at the end of the day we need a Tensor, so we may as well just use a class that returns a Tensor.
//
[0.x.51086] 
[0.x.51087] 
[0.x.51088] 
[0.x.51089] 
[0.x.51090] 
//
// In previous examples, we have used assertions that throw exceptions in several places. However, we have never seen how such exceptions are declared. This can be done as follows:
//
[0.x.51091] 
[0.x.51092] 
[0.x.51093] 
[0.x.51094] 
[0.x.51095] 
//
// The syntax may look a little strange, but is reasonable. The format is basically as follows: use the name of one of the macros  [2.x.5860]  denotes the number of additional parameters which the exception object shall take. In this case, as we want to throw the exception when the sizes of two vectors differ, we need two arguments, so we use  [2.x.5861] . The first parameter then describes the name of the exception, while the following declare the data types of the parameters. The last argument is a sequence of output directives that will be piped into the  [2.x.5862]  object, thus the strange format with the leading  [2.x.5863]  operator and the like. Note that we can access the parameters which are passed to the exception upon construction (i.e. within the  [2.x.5864]  call) by using the names  [2.x.5865] , where  [2.x.5866]  is the number of arguments as defined by the use of the respective macro  [2.x.5867] .
//
// To learn how the preprocessor expands this macro into actual code, please refer to the documentation of the exception classes. In brief, this macro call declares and defines a class  [2.x.5868]  inheriting from ExceptionBase which implements all necessary error output functions.
//
[0.x.51096] 
//
// The following two functions implement the interface described above. The first simply implements the function as described in the introduction, while the second uses the same trick to avoid calling a virtual function as has already been introduced in the previous example program. Note the check for the right sizes of the arguments in the second function, which should always be present in such functions; it is our experience that many if not most programming errors result from incorrectly initialized arrays, incompatible parameters to functions and the like; using assertion as in this case can eliminate many of these problems.
//
[0.x.51097] 
[0.x.51098] 
[0.x.51099] 
[0.x.51100] 
[0.x.51101] 
[0.x.51102] 
[0.x.51103] 
//
[0.x.51104] 
[0.x.51105] 
//
// Besides the advection field, we need two functions describing the source terms ( [2.x.5869] ) and the boundary values. As described in the introduction, the source is a constant function in the vicinity of a source point, which we denote by the constant static variable  [2.x.5870] . We set the values of this center using the same template tricks as we have shown in the  [2.x.5871]  example program. The rest is simple and has been shown previously.
//
[0.x.51106] 
[0.x.51107] 
[0.x.51108] 
[0.x.51109] 
[0.x.51110] 
[0.x.51111] 
//
[0.x.51112] 
[0.x.51113] 
[0.x.51114] 
//
[0.x.51115] 
[0.x.51116] 
//
[0.x.51117] 
[0.x.51118] 
//
[0.x.51119] 
[0.x.51120] 
//
// The only new thing here is that we check for the value of the  [2.x.5872]  parameter. As this is a scalar function, it is obvious that it only makes sense if the desired component has the index zero, so we assert that this is indeed the case.  [2.x.5873]  is a global predefined exception (probably the one most often used, we therefore made it global instead of local to some class), that takes three parameters: the index that is outside the allowed range, the first element of the valid range and the one past the last (i.e. again the half-open interval so often used in the C++ standard library):
//
[0.x.51121] 
[0.x.51122] 
[0.x.51123] 
[0.x.51124] 
[0.x.51125] 
[0.x.51126] 
[0.x.51127] 
[0.x.51128] 
[0.x.51129] 
[0.x.51130] 
[0.x.51131] 
//
// Finally for the boundary values, which is just another class derived from the  [2.x.5874]  base class:
//
[0.x.51132] 
[0.x.51133] 
[0.x.51134] 
[0.x.51135] 
[0.x.51136] 
[0.x.51137] 
[0.x.51138] 
//
[0.x.51139] 
[0.x.51140] 
[0.x.51141] 
[0.x.51142] 
[0.x.51143] 
[0.x.51144] 
//
[0.x.51145] 
[0.x.51146] 
[0.x.51147] 
[0.x.51148] 
//[2.x.5875] 
//
// Here comes the main class of this program. It is very much like the main classes of previous examples, so we again only comment on the differences.
//
[0.x.51149] 
[0.x.51150] 
[0.x.51151] 
[0.x.51152] 
[0.x.51153] 
[0.x.51154] 
//
[0.x.51155] 
[0.x.51156] 
//
// The next set of functions will be used to assemble the matrix. However, unlike in the previous examples, the  [2.x.5876]  function will not do the work itself, but rather will delegate the actual assembly to helper functions  [2.x.5877]  and  [2.x.5878] . The rationale is that matrix assembly can be parallelized quite well, as the computation of the local contributions on each cell is entirely independent of other cells, and we only have to synchronize when we add the contribution of a cell to the global matrix.
//
// The strategy for parallelization we choose here is one of the possibilities mentioned in detail in the  [2.x.5879]  module in the documentation. Specifically, we will use the WorkStream approach discussed there. Since there is so much documentation in this module, we will not repeat the rationale for the design choices here (for example, if you read through the module mentioned above, you will understand what the purpose of the  [2.x.5880]  and  [2.x.5881]  structures is). Rather, we will only discuss the specific implementation.
//
// If you read the page mentioned above, you will find that in order to parallelize assembly, we need two data structures -- one that corresponds to data that we need during local integration ("scratch data", i.e., things we only need as temporary storage), and one that carries information from the local integration to the function that then adds the local contributions to the corresponding elements of the global matrix. The former of these typically contains the FEValues and FEFaceValues objects, whereas the latter has the local matrix, local right hand side, and information about which degrees of freedom live on the cell for which we are assembling a local contribution. With this information, the following should be relatively self-explanatory:
//
[0.x.51157] 
[0.x.51158] 
[0.x.51159] 
[0.x.51160] 
//
// FEValues and FEFaceValues are expensive objects to set up, so we include them in the scratch object so that as much data is reused between cells as possible.
//
[0.x.51161] 
[0.x.51162] 
//
// We also store a few vectors that we will populate with values on each cell. Setting these objects up is, in the usual case, cheap; however, they require memory allocations, which can be expensive in multithreaded applications. Hence we keep them here so that computations on a cell do not require new allocations.
//
[0.x.51163] 
[0.x.51164] 
[0.x.51165] 
[0.x.51166] 
//
// Finally, we need objects that describe the problem's data:
//
[0.x.51167] 
[0.x.51168] 
[0.x.51169] 
[0.x.51170] 
//
[0.x.51171] 
[0.x.51172] 
[0.x.51173] 
[0.x.51174] 
[0.x.51175] 
[0.x.51176] 
//
[0.x.51177] 
[0.x.51178] 
[0.x.51179] 
[0.x.51180] 
[0.x.51181] 
[0.x.51182] 
//
// The following functions again are the same as they were in previous examples, as are the subsequent variables:
//
[0.x.51183] 
[0.x.51184] 
[0.x.51185] 
//
[0.x.51186] 
[0.x.51187] 
//
[0.x.51188] 
//
[0.x.51189] 
//
[0.x.51190] 
[0.x.51191] 
//
[0.x.51192] 
[0.x.51193] 
[0.x.51194] 
//
//  [2.x.5882] 
//
// Now, finally, here comes the class that will compute the difference approximation of the gradient on each cell and weighs that with a power of the mesh size, as described in the introduction. This class is a simple version of the  [2.x.5883]  class in the library, that uses similar techniques to obtain finite difference approximations of the gradient of a finite element field, or of higher derivatives.
//
// The class has one public static function  [2.x.5884]  that is called to compute a vector of error indicators, and a few private functions that do the actual work on all active cells. As in other parts of the library, we follow an informal convention to use vectors of floats for error indicators rather than the common vectors of doubles, as the additional accuracy is not necessary for estimated values.
//
// In addition to these two functions, the class declares two exceptions which are raised when a cell has no neighbors in each of the space directions (in which case the matrix described in the introduction would be singular and can't be inverted), while the other one is used in the more common case of invalid parameters to a function, namely a vector of wrong size.
//
// Two other comments: first, the class has no non-static member functions or variables, so this is not really a class, but rather serves the purpose of a  [2.x.5885]  in C++. The reason that we chose a class over a namespace is that this way we can declare functions that are private. This can be done with namespaces as well, if one declares some functions in header files in the namespace and implements these and other functions in the implementation file. The functions not declared in the header file are still in the namespace but are not callable from outside. However, as we have only one file here, it is not possible to hide functions in the present case.
//
// The second comment is that the dimension template parameter is attached to the function rather than to the class itself. This way, you don't have to specify the template parameter yourself as in most other cases, but the compiler can figure its value out itself from the dimension of the DoFHandler object that one passes as first argument.
//
// Before jumping into the fray with the implementation, let us also comment on the parallelization strategy. We have already introduced the necessary framework for using the WorkStream concept in the declaration of the main class of this program above. We will use it again here. In the current context, this means that we have to define  [2.x.5886] 
//[2.x.5887] classes for scratch and copy objects, [2.x.5888] 
//[2.x.5889] a function that does the local computation on one cell, and [2.x.5890] 
//[2.x.5891] a function that copies the local result into a global object. [2.x.5892] 
//[2.x.5893]  Given this general framework, we will, however, deviate from it a bit. In particular, WorkStream was generally invented for cases where each local computation on a cell [1.x.228] to a global object -- for example, when assembling linear systems where we add local contributions into a global matrix and right hand side. WorkStream is designed to handle the potential conflict of multiple threads trying to do this addition at the same time, and consequently has to provide for some way to ensure that only one thread gets to do this at a time. Here, however, the situation is slightly different: we compute contributions from every cell individually, but then all we need to do is put them into an element of an output vector that is unique to each cell. Consequently, there is no risk that the write operations from two cells might conflict, and the elaborate machinery of WorkStream to avoid conflicting writes is not necessary. Consequently, what we will do is this: We still need a scratch object that holds, for example, the FEValues object. However, we only create a fake, empty copy data structure. Likewise, we do need the function that computes local contributions, but since it can already put the result into its final location, we do not need a copy-local-to-global function and will instead give the  [2.x.5894]  function an empty function object -- the equivalent to a NULL function pointer.
//
[0.x.51195] 
[0.x.51196] 
[0.x.51197] 
[0.x.51198] 
[0.x.51199] 
[0.x.51200] 
[0.x.51201] 
//
[0.x.51202] 
[0.x.51203] 
[0.x.51204] 
[0.x.51205] 
[0.x.51206] 
[0.x.51207] 
//
[0.x.51208] 
[0.x.51209] 
[0.x.51210] 
[0.x.51211] 
[0.x.51212] 
[0.x.51213] 
[0.x.51214] 
[0.x.51215] 
//
[0.x.51216] 
[0.x.51217] 
[0.x.51218] 
//
[0.x.51219] 
[0.x.51220] 
//
[0.x.51221] 
[0.x.51222] 
[0.x.51223] 
//
[0.x.51224] 
[0.x.51225] 
//
[0.x.51226] 
[0.x.51227] 
[0.x.51228] 
[0.x.51229] 
[0.x.51230] 
[0.x.51231] 
//
//  [2.x.5895] 
//
// Now for the implementation of the main class. Constructor, destructor and the function  [2.x.5896]  follow the same pattern that was used previously, so we need not comment on these three function:
//
[0.x.51232] 
[0.x.51233] 
[0.x.51234] 
[0.x.51235] 
[0.x.51236] 
//
[0.x.51237] 
[0.x.51238] 
[0.x.51239] 
[0.x.51240] 
[0.x.51241] 
[0.x.51242] 
[0.x.51243] 
[0.x.51244] 
//
[0.x.51245] 
[0.x.51246] 
[0.x.51247] 
[0.x.51248] 
//
//                                    /*keep_constrained_dofs = [2.x.5897] false);
//
[0.x.51249] 
//
[0.x.51250] 
//
[0.x.51251] 
[0.x.51252] 
[0.x.51253] 
//
// In the following function, the matrix and right hand side are assembled. As stated in the documentation of the main class above, it does not do this itself, but rather delegates to the function following next, utilizing the WorkStream concept discussed in  [2.x.5898]  .
//
// If you have looked through the  [2.x.5899]  module, you will have seen that assembling in parallel does not take an incredible amount of extra code as long as you diligently describe what the scratch and copy data objects are, and if you define suitable functions for the local assembly and the copy operation from local contributions to global objects. This done, the following will do all the heavy lifting to get these operations done on multiple threads on as many cores as you have in your system:
//
[0.x.51254] 
[0.x.51255] 
[0.x.51256] 
[0.x.51257] 
[0.x.51258] 
[0.x.51259] 
[0.x.51260] 
[0.x.51261] 
[0.x.51262] 
[0.x.51263] 
[0.x.51264] 
//
// As already mentioned above, we need to have scratch objects for the parallel computation of local contributions. These objects contain FEValues and FEFaceValues objects (as well as some arrays), and so we will need to have constructors and copy constructors that allow us to create them. For the cell terms we need the values and gradients of the shape functions, the quadrature points in order to determine the source density and the advection field at a given point, and the weights of the quadrature points times the determinant of the Jacobian at these points. In contrast, for the boundary integrals, we don't need the gradients, but rather the normal vectors to the cells. This determines which update flags we will have to pass to the constructors of the members of the class:
//
[0.x.51265] 
[0.x.51266] 
[0.x.51267] 
[0.x.51268] 
[0.x.51269] 
[0.x.51270] 
[0.x.51271] 
[0.x.51272] 
[0.x.51273] 
[0.x.51274] 
[0.x.51275] 
[0.x.51276] 
[0.x.51277] 
[0.x.51278] 
[0.x.51279] 
[0.x.51280] 
//
[0.x.51281] 
[0.x.51282] 
[0.x.51283] 
[0.x.51284] 
[0.x.51285] 
[0.x.51286] 
[0.x.51287] 
[0.x.51288] 
[0.x.51289] 
[0.x.51290] 
[0.x.51291] 
[0.x.51292] 
[0.x.51293] 
[0.x.51294] 
[0.x.51295] 
[0.x.51296] 
//
// Now, this is the function that does the actual work. It is not very different from the  [2.x.5900]  functions of previous example programs, so we will again only comment on the differences. The mathematical stuff closely follows what we have said in the introduction.
//
// There are a number of points worth mentioning here, though. The first one is that we have moved the FEValues and FEFaceValues objects into the ScratchData object. We have done so because the alternative would have been to simply create one every time we get into this function -- i.e., on every cell. It now turns out that the FEValues classes were written with the explicit goal of moving everything that remains the same from cell to cell into the construction of the object, and only do as little work as possible in  [2.x.5901]  whenever we move to a new cell. What this means is that it would be very expensive to create a new object of this kind in this function as we would have to do it for every cell -- exactly the thing we wanted to avoid with the FEValues class. Instead, what we do is create it only once (or a small number of times) in the scratch objects and then re-use it as often as we can.
//
// This begs the question of whether there are other objects we create in this function whose creation is expensive compared to its use. Indeed, at the top of the function, we declare all sorts of objects. The  [2.x.5902] ,  [2.x.5903]  do not cost much to create, so there is no harm here. However, allocating memory in creating the  [2.x.5904]  and similar variables below typically costs a significant amount of time, compared to just accessing the (temporary) values we store in them. Consequently, these would be candidates for moving into the  [2.x.5905]  class. We will leave this as an exercise.
//
[0.x.51297] 
[0.x.51298] 
[0.x.51299] 
[0.x.51300] 
[0.x.51301] 
[0.x.51302] 
//
// We define some abbreviations to avoid unnecessarily long lines:
//
[0.x.51303] 
[0.x.51304] 
[0.x.51305] 
[0.x.51306] 
[0.x.51307] 
//
// We declare cell matrix and cell right hand side...
//
[0.x.51308] 
[0.x.51309] 
//
// ... an array to hold the global indices of the degrees of freedom of the cell on which we are presently working...
//
[0.x.51310] 
//
// ... then initialize the  [2.x.5906]  object...
//
[0.x.51311] 
//
// ... obtain the values of right hand side and advection directions at the quadrature points...
//
[0.x.51312] 
[0.x.51313] 
[0.x.51314] 
[0.x.51315] 
[0.x.51316] 
//
// ... set the value of the streamline diffusion parameter as described in the introduction...
//
[0.x.51317] 
//
// ... and assemble the local contributions to the system matrix and right hand side as also discussed above:
//
[0.x.51318] 
[0.x.51319] 
[0.x.51320] 
//
// Alias the AssemblyScratchData object to keep the lines from getting too long:
//
[0.x.51321] 
[0.x.51322] 
[0.x.51323] 
[0.x.51324] 
[0.x.51325] 
[0.x.51326] 
[0.x.51327] 
[0.x.51328] 
[0.x.51329] 
//
[0.x.51330] 
[0.x.51331] 
[0.x.51332] 
[0.x.51333] 
[0.x.51334] 
[0.x.51335] 
[0.x.51336] 
//
// Besides the cell terms which we have built up now, the bilinear form of the present problem also contains terms on the boundary of the domain. Therefore, we have to check whether any of the faces of this cell are on the boundary of the domain, and if so assemble the contributions of this face as well. Of course, the bilinear form only contains contributions from the  [2.x.5907]  part of the boundary, but to find out whether a certain part of a face of the present cell is part of the inflow boundary, we have to have information on the exact location of the quadrature points and on the direction of flow at this point; we obtain this information using the FEFaceValues object and only decide within the main loop whether a quadrature point is on the inflow boundary.
//
[0.x.51337] 
[0.x.51338] 
[0.x.51339] 
//
// Ok, this face of the present cell is on the boundary of the domain. Just as for the usual FEValues object which we have used in previous examples and also above, we have to reinitialize the FEFaceValues object for the present face:
//
[0.x.51340] 
//
// For the quadrature points at hand, we ask for the values of the inflow function and for the direction of flow:
//
[0.x.51341] 
[0.x.51342] 
[0.x.51343] 
[0.x.51344] 
[0.x.51345] 
[0.x.51346] 
//
// Now loop over all quadrature points and see whether this face is on the inflow or outflow part of the boundary. The normal vector points out of the cell: since the face is at the boundary, the normal vector points out of the domain, so if the advection direction points into the domain, its scalar product with the normal vector must be negative (to see why this is true, consider the scalar product definition that uses a cosine):
//
[0.x.51347] 
[0.x.51348] 
[0.x.51349] 
[0.x.51350] 
//
//     If the face is part of the inflow boundary, then compute the     contributions of this face to the global matrix and right     hand side, using the values obtained from the     FEFaceValues object and the formulae discussed in the     introduction:
//
[0.x.51351] 
[0.x.51352] 
[0.x.51353] 
[0.x.51354] 
[0.x.51355] 
[0.x.51356] 
[0.x.51357] 
[0.x.51358] 
[0.x.51359] 
//
[0.x.51360] 
[0.x.51361] 
[0.x.51362] 
[0.x.51363] 
[0.x.51364] 
[0.x.51365] 
[0.x.51366] 
[0.x.51367] 
//
// The final piece of information the copy routine needs is the global indices of the degrees of freedom on this cell, so we end by writing them to the local array:
//
[0.x.51368] 
[0.x.51369] 
//
// The second function we needed to write was the one that copies the local contributions the previous function computed (and put into the AssemblyCopyData object) into the global matrix and right hand side vector objects. This is essentially what we always had as the last block of code when assembling something on every cell. The following should therefore be pretty obvious:
//
[0.x.51370] 
[0.x.51371] 
[0.x.51372] 
[0.x.51373] 
[0.x.51374] 
[0.x.51375] 
[0.x.51376] 
[0.x.51377] 
[0.x.51378] 
[0.x.51379] 
[0.x.51380] 
//
// Here comes the linear solver routine. As the system is no longer symmetric positive definite as in all the previous examples, we cannot use the Conjugate Gradient method anymore. Rather, we use a solver that is more general and does not rely on any special properties of the matrix: the GMRES method. GMRES, like the conjugate gradient method, requires a decent preconditioner: we use a Jacobi preconditioner here, which works well enough for this problem.
//
[0.x.51381] 
[0.x.51382] 
[0.x.51383] 
[0.x.51384] 
[0.x.51385] 
[0.x.51386] 
[0.x.51387] 
[0.x.51388] 
[0.x.51389] 
[0.x.51390] 
//
[0.x.51391] 
//
[0.x.51392] 
[0.x.51393] 
[0.x.51394] 
[0.x.51395] 
[0.x.51396] 
[0.x.51397] 
//
[0.x.51398] 
[0.x.51399] 
//
// The following function refines the grid according to the quantity described in the introduction. The respective computations are made in the class  [2.x.5908] .
//
[0.x.51400] 
[0.x.51401] 
[0.x.51402] 
[0.x.51403] 
//
[0.x.51404] 
[0.x.51405] 
[0.x.51406] 
//
[0.x.51407] 
[0.x.51408] 
[0.x.51409] 
[0.x.51410] 
//
[0.x.51411] 
[0.x.51412] 
//
// This function is similar to the one in step 6, but since we use a higher degree finite element we save the solution in a different way. Visualization programs like VisIt and Paraview typically only understand data that is associated with nodes: they cannot plot fifth-degree basis functions, which results in a very inaccurate picture of the solution we computed. To get around this we save multiple  [2.x.5909] patches [2.x.5910]  per cell: in 2D we save 64 bilinear `cells' to the VTU file for each cell, and in 3D we save 512. The end result is that the visualization program will use a piecewise linear interpolation of the cubic basis functions: this captures the solution detail and, with most screen resolutions, looks smooth. We save the grid in a separate step with no extra patches so that we have a visual representation of the cell faces.
//
// Version 9.1 of deal.II gained the ability to write higher degree polynomials (i.e., write piecewise bicubic visualization data for our piecewise bicubic solution) VTK and VTU output: however, not all recent versions of ParaView and VisIt (as of 2018) can read this format, so we use the older, more general (but less efficient) approach here.
//
[0.x.51413] 
[0.x.51414] 
[0.x.51415] 
[0.x.51416] 
[0.x.51417] 
[0.x.51418] 
[0.x.51419] 
[0.x.51420] 
//
[0.x.51421] 
[0.x.51422] 
[0.x.51423] 
[0.x.51424] 
[0.x.51425] 
//
// VTU output can be expensive, both to compute and to write to disk. Here we ask ZLib, a compression library, to compress the data in a way that maximizes throughput.
//
[0.x.51426] 
[0.x.51427] 
[0.x.51428] 
[0.x.51429] 
//
[0.x.51430] 
[0.x.51431] 
[0.x.51432] 
[0.x.51433] 
//
// ... as is the main loop (setup -- solve -- refine), aside from the number of cycles and the initial grid:
//
[0.x.51434] 
[0.x.51435] 
[0.x.51436] 
[0.x.51437] 
[0.x.51438] 
[0.x.51439] 
//
[0.x.51440] 
[0.x.51441] 
[0.x.51442] 
[0.x.51443] 
[0.x.51444] 
[0.x.51445] 
[0.x.51446] 
[0.x.51447] 
[0.x.51448] 
//
[0.x.51449] 
[0.x.51450] 
//
[0.x.51451] 
//
[0.x.51452] 
[0.x.51453] 
//
[0.x.51454] 
[0.x.51455] 
[0.x.51456] 
[0.x.51457] 
[0.x.51458] 
//
//  [2.x.5911] 
//
// Now for the implementation of the  [2.x.5912]  class. Let us start by defining constructors for the  [2.x.5913]  class used by the  [2.x.5914]  function:
//
[0.x.51459] 
[0.x.51460] 
[0.x.51461] 
[0.x.51462] 
[0.x.51463] 
[0.x.51464] 
[0.x.51465] 
[0.x.51466] 
[0.x.51467] 
[0.x.51468] 
[0.x.51469] 
[0.x.51470] 
[0.x.51471] 
//
// We allocate a vector to hold iterators to all active neighbors of a cell. We reserve the maximal number of active neighbors in order to avoid later reallocations. Note how this maximal number of active neighbors is computed here.
//
[0.x.51472] 
[0.x.51473] 
[0.x.51474] 
//
[0.x.51475] 
[0.x.51476] 
[0.x.51477] 
[0.x.51478] 
[0.x.51479] 
[0.x.51480] 
[0.x.51481] 
[0.x.51482] 
[0.x.51483] 
[0.x.51484] 
[0.x.51485] 
//
// Next comes the implementation of the  [2.x.5915]  class. The first function does not much except for delegating work to the other function, but there is a bit of setup at the top.
//
// Before starting with the work, we check that the vector into which the results are written has the right size. Programming mistakes in which one forgets to size arguments correctly at the calling site are quite common. Because the resulting damage from not catching such errors is often subtle (e.g., corruption of data somewhere in memory, or non-reproducible results), it is well worth the effort to check for such things.
//
[0.x.51486] 
[0.x.51487] 
[0.x.51488] 
[0.x.51489] 
[0.x.51490] 
[0.x.51491] 
[0.x.51492] 
[0.x.51493] 
[0.x.51494] 
//
[0.x.51495] 
[0.x.51496] 
[0.x.51497] 
[0.x.51498] 
[0.x.51499] 
[0.x.51500] 
[0.x.51501] 
[0.x.51502] 
[0.x.51503] 
//
// Here comes the function that estimates the local error by computing the finite difference approximation of the gradient. The function first computes the list of active neighbors of the present cell and then computes the quantities described in the introduction for each of the neighbors. The reason for this order is that it is not a one-liner to find a given neighbor with locally refined meshes. In principle, an optimized implementation would find neighbors and the quantities depending on them in one step, rather than first building a list of neighbors and in a second step their contributions but we will gladly leave this as an exercise. As discussed before, the worker function passed to  [2.x.5916]  works on "scratch" objects that keep all temporary objects. This way, we do not need to create and initialize objects that are expensive to initialize within the function that does the work every time it is called for a given cell. Such an argument is passed as the second argument. The third argument would be a "copy-data" object (see  [2.x.5917]  for more information) but we do not actually use any of these here. Since  [2.x.5918]  insists on passing three arguments, we declare this function with three arguments, but simply ignore the last one.
//
// (This is unsatisfactory from an aesthetic perspective. It can be avoided by using an anonymous (lambda) function. If you allow, let us here show how. First, assume that we had declared this function to only take two arguments by omitting the unused last one. Now,  [2.x.5919]  still wants to call this function with three arguments, so we need to find a way to "forget" the third argument in the call. Simply passing  [2.x.5920]  the pointer to the function as we do above will not do this -- the compiler will complain that a function declared to have two arguments is called with three arguments. However, we can do this by passing the following as the third argument to  [2.x.5921] 
//[1.x.229] This is not much better than the solution implemented below: either the routine itself must take three arguments or it must be wrapped by something that takes three arguments. We don't use this since adding the unused argument at the beginning is simpler.
//
// Now for the details:
//
[0.x.51504] 
[0.x.51505] 
[0.x.51506] 
[0.x.51507] 
[0.x.51508] 
[0.x.51509] 
//
// We need space for the tensor  [2.x.5922] , which is the sum of outer products of the y-vectors.
//
[0.x.51510] 
//
// First initialize the  [2.x.5923]  object, as well as the  [2.x.5924]  tensor:
//
[0.x.51511] 
//
// Now, before we go on, we first compute a list of all active neighbors of the present cell. We do so by first looping over all faces and see whether the neighbor there is active, which would be the case if it is on the same level as the present cell or one level coarser (note that a neighbor can only be once coarser than the present cell, as we only allow a maximal difference of one refinement over a face in deal.II). Alternatively, the neighbor could be on the same level and be further refined; then we have to find which of its children are next to the present cell and select these (note that if a child of a neighbor of an active cell that is next to this active cell, needs necessarily be active itself, due to the one-refinement rule cited above).
//
// Things are slightly different in one space dimension, as there the one-refinement rule does not exist: neighboring active cells may differ in as many refinement levels as they like. In this case, the computation becomes a little more difficult, but we will explain this below.
//
// Before starting the loop over all neighbors of the present cell, we have to clear the array storing the iterators to the active neighbors, of course.
//
[0.x.51512] 
[0.x.51513] 
[0.x.51514] 
[0.x.51515] 
//
// First define an abbreviation for the iterator to the face and the neighbor
//
[0.x.51516] 
[0.x.51517] 
//
// Then check whether the neighbor is active. If it is, then it is on the same level or one level coarser (if we are not in 1D), and we are interested in it in any case.
//
[0.x.51518] 
[0.x.51519] 
[0.x.51520] 
[0.x.51521] 
//
//     If the neighbor is not active, then check its children.
//
[0.x.51522] 
[0.x.51523] 
//
//         To find the child of the neighbor which bounds to the         present cell, successively go to its right child if         we are left of the present cell (n==0), or go to the         left child if we are on the right (n==1), until we         find an active cell.
//
[0.x.51524] 
[0.x.51525] 
[0.x.51526] 
//
//         As this used some non-trivial geometrical intuition,         we might want to check whether we did it right,         i.e., check whether the neighbor of the cell we found         is indeed the cell we are presently working         on. Checks like this are often useful and have         frequently uncovered errors both in algorithms like         the line above (where it is simple to involuntarily         exchange  [2.x.5925]  or         the like) and in the library (the assumptions         underlying the algorithm above could either be wrong,         wrongly documented, or are violated due to an error         in the library). One could in principle remove such         checks after the program works for some time, but it         might be a good things to leave it in anyway to check         for changes in the library or in the algorithm above.                 Note that if this check fails, then this is certainly         an error that is irrecoverable and probably qualifies         as an internal error. We therefore use a predefined         exception class to throw here.
//
[0.x.51527] 
[0.x.51528] 
//
//         If the check succeeded, we push the active neighbor         we just found to the stack we keep:
//
[0.x.51529] 
[0.x.51530] 
[0.x.51531] 
//
//       If we are not in 1d, we collect all neighbor children       `behind' the subfaces of the current face and move on:
//
[0.x.51532] 
[0.x.51533] 
[0.x.51534] 
[0.x.51535] 
[0.x.51536] 
[0.x.51537] 
//
// OK, now that we have all the neighbors, lets start the computation on each of them. First we do some preliminaries: find out about the center of the present cell and the solution at this point. The latter is obtained as a vector of function values at the quadrature points, of which there are only one, of course. Likewise, the position of the center is the position of the first (and only) quadrature point in real space.
//
[0.x.51538] 
[0.x.51539] 
//
[0.x.51540] 
[0.x.51541] 
//
// Now loop over all active neighbors and collect the data we need.
//
[0.x.51542] 
[0.x.51543] 
[0.x.51544] 
//
// Then get the center of the neighbor cell and the value of the finite element function at that point. Note that for this information we have to reinitialize the  [2.x.5926]  object for the neighbor cell.
//
[0.x.51545] 
[0.x.51546] 
[0.x.51547] 
//
[0.x.51548] 
[0.x.51549] 
//
// Compute the vector  [2.x.5927]  connecting the centers of the two cells. Note that as opposed to the introduction, we denote by  [2.x.5928]  the normalized difference vector, as this is the quantity used everywhere in the computations.
//
[0.x.51550] 
[0.x.51551] 
[0.x.51552] 
//
// Then add up the contribution of this cell to the Y matrix...
//
[0.x.51553] 
[0.x.51554] 
[0.x.51555] 
//
// ... and update the sum of difference quotients:
//
[0.x.51556] 
[0.x.51557] 
[0.x.51558] 
[0.x.51559] 
//
// If now, after collecting all the information from the neighbors, we can determine an approximation of the gradient for the present cell, then we need to have passed over vectors  [2.x.5929]  which span the whole space, otherwise we would not have all components of the gradient. This is indicated by the invertibility of the matrix.
//
// If the matrix is not invertible, then the present cell had an insufficient number of active neighbors. In contrast to all previous cases (where we raised exceptions) this is, however, not a programming error: it is a runtime error that can happen in optimized mode even if it ran well in debug mode, so it is reasonable to try to catch this error also in optimized mode. For this case, there is the  [2.x.5930]  macro: it checks the condition like the  [2.x.5931]  macro, but not only in debug mode; it then outputs an error message, but instead of aborting the program as in the case of the  [2.x.5932]  macro, the exception is thrown using the  [2.x.5933]  command of C++. This way, one has the possibility to catch this error and take reasonable counter actions. One such measure would be to refine the grid globally, as the case of insufficient directions can not occur if every cell of the initial grid has been refined at least once.
//
[0.x.51560] 
//
// If, on the other hand, the matrix is invertible, then invert it, multiply the other quantity with it, and compute the estimated error using this quantity and the correct powers of the mesh width:
//
[0.x.51561] 
//
[0.x.51562] 
//
// The last part of this function is the one where we write into the element of the output vector what we have just computed. The address of this vector has been stored in the scratch data object, and all we have to do is know how to get at the correct element inside this vector -- but we can ask the cell we're on the how-manyth active cell it is for this:
//
[0.x.51563] 
[0.x.51564] 
[0.x.51565] 
[0.x.51566] 
//[2.x.5934] 
//
// The  [2.x.5935]  function is similar to the previous examples. The primary difference is that we use MultithreadInfo to set the maximum number of threads (see the documentation module  [2.x.5936]  "Parallel computing with multiple processors accessing shared memory" for more information). The number of threads used is the minimum of the environment variable DEAL_II_NUM_THREADS and the parameter of  [2.x.5937] . If no value is given to  [2.x.5938] , the default value from the Intel Threading Building Blocks (TBB) library is used. If the call to  [2.x.5939]  is omitted, the number of threads will be chosen by TBB independently of DEAL_II_NUM_THREADS.
//
[0.x.51567] 
[0.x.51568] 
[0.x.51569] 
[0.x.51570] 
[0.x.51571] 
[0.x.51572] 
//
[0.x.51573] 
[0.x.51574] 
[0.x.51575] 
[0.x.51576] 
[0.x.51577] 
[0.x.51578] 
[0.x.51579] 
[0.x.51580] 
[0.x.51581] 
[0.x.51582] 
[0.x.51583] 
[0.x.51584] 
[0.x.51585] 
[0.x.51586] 
[0.x.51587] 
[0.x.51588] 
[0.x.51589] 
[0.x.51590] 
[0.x.51591] 
[0.x.51592] 
[0.x.51593] 
[0.x.51594] 
[0.x.51595] 
[0.x.51596] 
[0.x.51597] 
[0.x.51598] 
[0.x.51599] 
[0.x.51600] 
//
[0.x.51601] 
[0.x.51602] 
//
//