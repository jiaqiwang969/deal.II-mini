



\title{Implementation of a General Algorithm for Incompressible and Compressible Flows within the Multi-Physics code `Kratos` and Preparation of Fluid-Structure Coupling}

\begin{abstract}
This diploma thesis deals with the implementation of a fluid solver for incompressible and compressible flows within the multi-physics framework `Kratos`. The presentation of this environment based on the finite Element method (`FEM`) and an introduction to multidisciplinary problems in general are the starting point of this work and help understanding the following steps more easily.

Originating from the basic conservation equations for mass, momentum and energy, the `Euler equations` for inviscid flow are derived. In this context some approximations are presented that avoid the solution of the energy equation and allow the use of a general approach for the simulation of incompressible, slightly compressible and barotropic flow. The implementation of the incompressible case is outlined step-by-step: Having discretized the continuous problem, a fractional step scheme is presented in order to uncouple pressure and velocity components by a split of the momentum equation. Emphasis is placed on the nodal implementation using an edge-based data structure. Moreover, the orthogonal subscale stabilization - necessary because of the finite Element discretization - is explained very briefly.

Subsequently, the solver is extended to compressible regime mentioning the respective modifications. For validation purposes numerical examples of incompressible and compressible flows in two and three dimensions round off this first part.

In a second step, the implemented flow solver is prepared for the fluid-structure coupling. After presenting solving procedures for multi-disciplinary problems, the `arbitrary Lagrangian Eulerian` (`ALE`) formulation is introduced and the conservation equations are modified accordingly.

Some preliminary tests are performed, particularly with regard to Mesh motion and adjustment of the boundary Conditions. Finally, expectations for the envisaged fluid-structure coupling are brought forward. 

\end{abstract}

\section{Introduction}


\subsection{Multi-Physics in general...}

A wide range of scientific and engineering tasks possess an interdisciplinary character. This means multiple physical Models are underlying and have to be considered simultaneously in order to simulate the temporal development of a certain phenomenon adequately. Well-known examples are thermal stress, electromechanic interaction, fluid-structure interaction, fluid flow with heat transport and chemical reactions, electromagnetic fluids (magnetohydrodynamics or plasma) and electromagnetically induced heating.

These multi-physics problems typically involve solving coupled systems of partial differential equations. Considering industrial applications with a considerable number of degrees of freedom, one can imagine that there are very high requirements for cpu power as well as for memory allocation. Although computer performance has been continuously increasing during the last decade, the vision of real-time aircraft or Formula One race car simulations is still far away. Tradeoffs have to be made between computational time and accuracy of the obtained results. In this context parallelization and the use of reduced order Models play a decisive role to decrease the computational effort.

\subsection{$\ldots$ and Fluid-Structure Interaction in particular}

A siginificant subcategory is the already mentioned fluid-structure interaction (`FSI`) that will be partially focused on in this work. It occurs when a fluid interacts with a solid structure, exerting pressure on it which may cause deformation in the structure and thus alter the flow of the fluid itself. Such interactions may be stable or oscillatory and are a crucial consideration in the design of many engineering systems.

Failing to consider the effects of `FSI` can be catastrophic, especially in large scale structures and those comprising materials susceptible to fatigue. The Tacoma Narrows suspension bridge is probably one of the most infamous examples of large-scale failure, the aeroelastic phenomenon of flutter on aircraft wings another one. Aside from its destructive potential, `FSI` is responsible for countless useful effects in engineering. It allows fans and propellers to function; sails on marine vehicles to provide thrust; aerofoils on racecars to produce downforce, and our lungs to inflate when we breathe.

In general, the program to simulate `FSI` problems involves a structural and a fluid solver that are coupled by a certain interface in order to exchange variables and parameters. In the case of `Kratos` - a multi-disciplinary framework based on the finite Element method - very potent modules for static and dynamic analysis of structures have already been implemented. Consequently, the aim of this work was the development of a fluid solver, capable of handling incompressible and compressible flows (as far as the sound barrier is not exceeded), and the preparation of the application for fluid-structure coupling.

\subsection{Organization of the Document}

This diploma thesis describes the implementation of an algorithm for incompressible and compressible flows in subsonic regime within a multi-disciplinary `FEM` framework. Afterwards, this fluid solver is prepared for the coupling with existing structural applications. Following this idea, the layout of the document is organized as follows:

Chapter 2 classifies multi-disciplinary problems and gives an overview of `Kratos` as finite Element framework for such a type of simulations.

Chapter 3 details the implementation of a general algorithm for incompressible and compressible flows within `Kratos`, focussing on the construction of an edge-based data structure and defining a starting point on parallelization issues. Numerical examples are given for validation purposes.

Chapter 4 describes modifications of the fluid solver due to the `arbitrary Lagrangian Eulerian` formulation of the equations of motion, which are necessary for preparing the fluid-structure coupling. Moreover, basic tests with moving Meshes are performed.

Chapter 5 recapitulates the implementation of the algorithm as well as the obtained results in order to draw conclusions and to hint at future spheres of action. 

\section{`Kratos`  Multi-Physics `FEM` Environment}




Based on the definition of multi-disciplinary problems and on their classification, essential background information on the structure of the finite Element framework `Kratos` is given. This overview is necessary to understand the implementation of applications and the coupling of flow and structural solvers in the following chapters.

Beyond that, its interface with the pre- and post-processor `GiD` and the handling of simulation runs by `Python` scripts are presented.





\subsection{multi-disciplinary problems}

Since the objective of this work is the extension of `Kratos`, the purpose of this environment shall be focused on first, that is to say the tackling multi-disciplinary problems. Different definitions exist for this term, but usually searching for a multi-disciplinary solution is referred to as solving a coupled system of different physical Models together - a collection of dependent problems put together building up a complex Model. Nevertheless, a more general definition shall be used here: solving a Model which consists of components with different formulations and algorithms interacting together. It is important to mention that this difference may come not only from the different physical nature of the problems but also from their type of mathematical Modeling or discretization.

A field is a subsystem of a multi-disciplinary Model characterized by certain mathematical equations and Conditions. More precisely a fluid field is considered in the following chapters, building up the `FSI` problem together with a structure field. Accordingly a domain is the part of the Modeled space governed by the respective field equation.

The definition given above includes a variety of problems, each of them with its proper characteristics. Different classifications are possible to categorize them, reflecting e.g. the kind of interaction between subsystems or the type of domain interfaces.

As these aspects were important in the design of `Kratos` (Dadvand, 2007), they are illustrated in the following. 

\subsubsection{Weak and Strong Coupling}

Considering a simple multi-disciplinary problem with two interacting subsystems $S_{1}$ and $S_{2}$ as shown in Figure $2.1$. The calculation of the respective solutions $u_{1}(t)$ and $u_{2}(t)$ under applied forces $F(t)$ is up to the type of dependency between the subsystems.





Weak Coupling Only one domain depends on the other one, which can be solved independently. That is why this type is also called `one-way` coupling. A thermal-structure problem is a good example where the material's property of the structure depends on the temperature while the thermal field can be solved independently, assuming that the temperature change due to structural deformation is very small. Figure $2.2$ shows this type of coupling.





Strong Coupling Each subsystem depends on the other one, ruling out the seperate solution. Hence this type is also referred to as `two-way` coupling. The fluid-structure interaction problems for structures with large deformations fall into this category. The structural deformation is caused by the pressure resulting from the fluid flow on the one hand, whereas velocity and pressure of the fluid depend on the shape of the deformed structure on the other hand. Figure $2.3$ shows this type of coupling.





\subsubsection{Interaction over Boundary and Domain}

Apart from the type of dependency the classification also may be done on where the different subsystems interact with each other.

Interaction over Boundary In this category the interaction occurs at the domain boundaries. In a fluid-structure interaction problem as shown in Figure $2.4$ the coupling of the two subsystems appears only on the boundary faces whereas interior points of each subsystem are not affected directly.





Interaction over Domain This category includes problems where domains can overlap totally or partially. Combustion processes or the thermal-fluid problem illustrated in Figure $2.5$ are good examples. In the heating pipe the thermal domain overlaps the fluid domain.





\subsection{General Structure of `Kratos`}

`Kratos` is an open source C $++$ framework to perform multi-disciplinary simulations based on the Finite Element Method (`FEM`). Therefore it provides several tools for easy implementation of finite Element applications as well as a common platform for natural interaction of these modules in different ways. `Kratos` has been set up at the International Center for Numerical Methods in Engineering (`CIMNE`) in Barcelona and is currently being enhanced further, this work representing one of the recent extensions.

In order to enable the implementation of different sets of algorithms and formulations within this context, a general approach has been followed during its design process providing the necessary flexibility and extensibility (Dadvand, 2007). As a result, `Kratos` adresses itself to a variety of users ranging from developers (finite Element experts as well as application developers) to engineers and designers using the package as a whole without getting involved in the programming.

\subsubsection{Object-Oriented Approach}

The main goal of an object-oriented structure is to split the whole problem into several objects and to define their interfaces. With regard to the simulation of multi-disciplinary problems using `FEM`, the objects defined in `Kratos` are based on a general finite Element methodology. Figure $2.6$ illustrates the main classes.




`Vector`, `Matrix` and `Quadrature` are designed by basic numerical concepts. `Node`, Element, `Condition` and `Dof` are defined directly from finite Element concepts. `Model`, `Mesh` and `Properties` are coming from practical methodology used in finite Element Modeling completed by `ModelPart` and `SpatialContainer` for a better organization of all necessary analysis data. `I0`, `LinearSolver`, `Process` and `Strategy` are representing the different steps of finite Element program flow. Finally, `Kernel` and `Application` handle the library management and define `Kratos`' interface. 

\subsubsection{Multi-Layer Design}

`Kratos` uses a `multi-layer` approach, in which each object only interfaces with other objects in its layer or in layers below this one. Thereby dependencies inside the program get reduced, helping in the maintenance of the code on the one hand and clarifying the tasks for developers on the other hand. Figure $2.7$ shows the `multi-layer` nature of `Kratos` being geared to the various user groups. For a better understanding the individual layers are presented hereafter using a bottom-up approach:

\textbf{Basic Tools Layer} holds all basic tools used in `Kratos`, that is mathematical definitions, solving procedures and build-up of data structures. In order to maximize their performance, advanced techniques in $\mathrm{C}++$ are essential in this layer.

\textbf{Base Finite Element Layer} contains the ingredients that are necessary to implement a finite Element formulation. The objects Element, `Node`, `Properties`, `Condition` and `Degrees of freedom` are defined here and in a manner of speaking hidden from the finite Element developers.

\textbf{Finite Element Layer} is restricted to the basic and average features of language and uses the two layers below to optimize the performance without entering into details.

\textbf{Data Structures Layer} contains all objects organizing the data structure. This layer will be affected by the nodal based implementation requiring an edge-based data structure in compressed sparse row format.

\textbf{Base Algorithms Layer} provides the components building the extendible structure for algorithms.

\textbf{User's Algorithms Layer} contains all classes implementing the different algorithms in `Kratos`. In this layer the general algorithm for compressible and `incompressible flows` will be placed.

\textbf{Applications' Interface Layer} holds all objects that manage `Kratos` and its relation with other applications. Within this scope the new fluid application using the forementioned algorithm will be defined.

\textbf{Applications Layer} contains the interface of certain applications with `Kratos`.

\textbf{Scripts Layer} provides a set of input/output scripts that can be used to activate respectively deactivate certain functionalities or to implement different algorithms from outside `Kratos`. As `Python` scripts have been used to handle our simulation runs, an example is given in the following section.

\subsubsection{`Python` Interface}

The use of `Python` start scripts for simulations has proven to be very convenient as it allows the user to adapt the program to his special needs, which is extremely useful during debugging an application or problem solving. Furthermore, nearly any parameter (e.g. tolerance values, initial and boundary Conditions, etc.) can be changed "on the fly" without having to recompile the whole $\mathrm{C}++$ source code. 









\subsection{`GiD` Pre- and Postprocessor}

To perform the above-named multi-disciplinary simulations, input data describing the considered Model - its geometry, its material `Properties` as well as basic Conditions and parameters - have to be defined. For this purpose `GiD`, the universal pre- and postprocessor developed and distributed by `CIMNE`, has been used. Providing the user with a graphical interface, it has been designed as an adaptive tool for geometrical Modelling, data input and visualisation of results for all types of numerical simulation programs.





Figure 2.8 illustrates the different steps surrounding the proper simulation process:

\textbf{Geometry description} - Apart from defining the two- respectively three-dimensional geometry of the Model manually by points, lines and surfaces, multiple data formats from standard Computer Aided Design (CAD) software tools can be imported.

\textbf{Mesh generation} - Having assigned quality and spacing criteria of the Mesh to geometrical entities, the user can dispose of various options. He has the choice between structured Meshes for `linear and quadratic Elements`, automatically generated unstructered Meshes and semi-structured volume Meshes (structured in one direction), including triangular, quadrilateral, hexahedral, prism and tetrahedral Elements. Further editing utilities like Mesh refinement by splitting Elements, edge collapses and smoothing are also available.

\textbf{Visualization of results} - Once the simulation has been run, results can be visualized by all kinds of graphs: counter and `Vector` plots, deformed geometry shapes, isosurfaces and stream lines to name just the most popular ones. Moreover animated sequences can be recorded and time relevant data can be extracted to perform further operations like the fast Fourier transform (FFT). Once more, data exchange with common postprocessing tools like STL, NASTRAN and TECPLOT is possible. One of GiD's main objectives is its adaptive character willing to provide a compatible interface to any kind of numerical simulation program, independant of the employed code (finite Element, finite volume, finite difference, Meshless). To successfully tackle this requirement, a so-called `problemtype` has to be designed for each application, defining elective `Properties` and Conditions as well as format conversion options. Up to now, such problemtypes exist for applications in solid and structural mechanics, fluid dynamics, heat transfer, electromagnetics and geomechanics.

\subsubsection{Preparation of the Model}

First of all, the geometry of the Model is defined by points, lines, surfaces and volumes. Then a material is selected and the characteristics of domain and its boundaries have to be defined. For the implemented flow solver it is crucial to choose only the Elements `Fluid2D` and `Fluid3D` for the two- respectively three-dimensional domain under "Fluid Element Type". Forthermore the boundary Conditions `Condition2D` and `Condition3D` under "Fluid Boundary Condition" have to be set. As the boundary generally is divided into several distinctive parts, the `Kratos` flag variable `IS_BOUNDARY` is used to indicate

$\mathbf{0}$ interior points,

$\mathbf{1}$ a velocity inlet,

2 no-slip Conditions,

3 slip Conditions,

4 slip/pressure `Nodes` and

5 a pressure outlet.

Figure $2.9$ shows an example for the definition of the boundary flag that will be used within the algorithm to differentiate between the respective boundary types. Be careful with the corners of the domain as it might be necessary to set the value for the respective corner points separately.





Finally, the domain is Meshed and the calculation files necessary to start the simulation run are written. 


\section{Fluid Solver Implementation and Validation}

In this chapter the implementation of a flow solver within the multi-physics code `Kratos` is exposed step-by-step.

Starting with the derivation of the `Euler equations` for incompressible flow, the finite Element method is applied for spatial discretization. Using a fractional step scheme, pressure and velocity components are uncoupled.

To avoid certain redundancies of information, many simple Element-based flow solvers are suffering from (due to the cost of indirect addressing operations), an edge-based data structure has been chosen. Thus, the attention of one section will be directed to the necessary changes in storage and access of edge-based data as well as to the calculation of edge contributions to the global system matrices.

Furthermore the algorithm is expanded to compressible flow in subsonic regime. Finally, for validation purpose, numerical flow simulations of two- and three-dimensional test cases are performed.

\subsection{Motivation}

Introduced in the late $1950 \mathrm{~s}$ in the aircraft industry, the finite Element method has emerged as one of the most powerful numerical methods so far devised. Its main assets, having led to widespread acceptance and popularity, are

- the ease in Modeling complex geometries,

- the consistent treatment of differential type boundary Conditions and

- the possibility to be programmed in a flexible and general purpose format.

Standard finite Element approximations are based upon the `Galerkin` formulation of the method of weighted residuals. This formulation has proven eminently successful in application to problems in solid/structural mechanics and in other situations, such as heat conduction, which is governed by a diffusion-type equation. This can be explained by the fact that, when applied to problems governed by self-adjoint elliptic or parabolic partial differential equations, the `Galerkin` finite Element method leads to symmetric stiffness matrices. In this case the difference between the finite Element solution and the exact solution is minimized with respect to the energy norm.

However, in the case of fluid flow problems based on kinematical descriptions other than Lagrangian, non-symmetric convection operators appear in the formulation and thus the best approximation property in the energy norm of the `Galerkin` method is lost when convection dominates the transport process. In practice, `Galerkin` solutions to these problems are often corrupted by spurious `Node-to-Node` oscillations. As severe Mesh and time step refinement clearly would undermine the practical utility of the method, stabilization techniques have to be applied. Moreover, in truly transient situations, space-time coupling is particularly crucial due to the directional character of propagation of information in hyperbolic problems (Donea and Huerta, 2003).

\subsection{Governing Equations in Fluid Dynamics}

The motion of fluid substances such as gases and liquids is determined by the `NavierStokes equations` named after `Claude-Louis Navier` and `George-Gabriel Stokes`. They represent a set of non-linear partial differential equations establishing a relation among the rates of change of velocity and pressure. Strictly spoken they only state the conservation of momentum so that, depending on the flow `Properties`, further conservation laws for mass and energy are necessary to fully describe the motion.

In addition boundary and initial Conditions have to be prescribed adequately in order to close the `initial boundary value problem`. It can be distinguished between

1. \textbf{Dirichlet}, prescribing the value of the unknown function,

2. \textbf{Neumann}, imposing the normal gradient, and

3. \textbf{Robin}, prescribing a combination of the unknown function and its gradient why this type is often refered to as mixed boundary Condition.

\subsubsection{Basic Conservation Equations}

\textbf{Mass Conservation}

The conservation of mass contained in a material volume (a volume permanently containing the same particles of the continuum under consideration) is a fundamental law of Newtonian mechanics. According to Donea and Huerta (2003) it can be written as

$$
\frac{d M}{d t}=\frac{d}{d t} \int_{V_{m}(t)} \rho d V=0
$$

where the mass $M$ is expressed by a volume integral of the fluid density $\rho$.

The material time derivative of the integral of a scalar function $f(\boldsymbol{x}, t)$ over the time-varying material volume $V_{m}(t)$ is given by the `Reynolds transport theorem`:

$$
\frac{d}{d t} \int_{V_{m}(t)} f(\boldsymbol{x}, t) d V=\int_{V_{c} \equiv V_{m}(t)} \frac{\partial f(\boldsymbol{x}, t)}{\partial t} d V+\int_{A_{c} \equiv A_{m}(t)} f(\boldsymbol{x}, t) \boldsymbol{u} \cdot \boldsymbol{n} d A
$$

which holds for smooth functions $f(\boldsymbol{x}, t)$. The volume integral on the right-hand side is defined over a control volume $V_{c}$ (fixed in space) coinciding with the moving material volume $V_{m}(t)$ at the considered instant $t$ in time. Similarly, the fixed control surface $A_{c}$ coincides at time $\mathrm{t}$ with the closed surface $A_{m}(t)$ bounding the material volume $V_{m}(t)$. In the surface integral, $\boldsymbol{u}$ denotes the material velocity of points on the boundary $A_{m}(t)$ whereas $\boldsymbol{n}$ is the unit outward normal to the surface $A_{m}(t)$ at the considered instant.

Applied to the law of mass conservation, equation (3.1) can be rewritten in the following form:

$$
\frac{d M}{d t}=\int_{V_{m}(t)} \frac{\partial \rho}{\partial t} d V+\int_{A_{m}(t)} \rho \boldsymbol{u} \cdot \boldsymbol{n} d A=\int_{V_{m}(t)}\left(\frac{\partial \rho}{\partial t}+\boldsymbol{\nabla} \cdot(\rho \boldsymbol{u})\right) d V=0
$$

Since this relation is independent of the choice of the volume $V_{m}(t)$, the integrand must be identically zero. Hence

$$
\frac{\partial \rho}{\partial t}+\boldsymbol{\nabla} \cdot(\rho \boldsymbol{u})=0
$$

at all points in the fluid. A different form of this equation is obtained by expanding the divergence term and considering that two of the terms together make up the material derivative of the density.

$$
\frac{d \rho}{d t}+\rho \boldsymbol{\nabla} \cdot \boldsymbol{u}=0
$$

Apart from mass-conservation equation equation (3.4) is also termed `continuity equation`.

\textbf{Momentum Conservation}

The momentum equation can be derived from Newton's second law (Wikipedia - The Free Encyclopedia):

"The alteration of motion is ever proportional to the motive force impressed, and is made in the direction of the right line in which that force is impressed."

Applied to flows this statement reads that changes in momentum in a chosen volume of fluid are equal to the sum of all forces $\boldsymbol{F}$ acting on this selected volume, including for example dissipative viscous forces (similar to friction), changes in pressure, gravity and other forces acting inside the fluid (Candel, 2005 )

$$
\frac{d}{d t} \int_{V_{m}(t)} \rho \boldsymbol{u} d V=\boldsymbol{F}
$$

In general, a portion of fluid is acted upon by both volume and surface forces: 

1. Denoting by $\boldsymbol{g}$ the volume force per unit mass of fluid, the total volume force on the selected portion of fluid is

$$
\int_{V_{m}(t)} \rho \boldsymbol{g} d V
$$

2. The $k$ -component of the surface force exerted across a surface Element of area $d A$ and normal $\boldsymbol{n}$ is given by $\sigma_{k l} n_{l} d A$ - using the summation convention on repeated indices - so that the total force exerted on the selected portion of fluid by the surrounding matter can be expressed in terms of the `Cauchy` stress as

$$
\int_{A_{m}(t)} \sigma_{k l} n_{l} d A=\int_{V_{m}(t)} \frac{\partial \sigma_{k l}}{\partial x_{l}} d V \text { or } \int_{A_{m}(t)} \boldsymbol{\sigma} \cdot \boldsymbol{n} d A=\int_{V_{m}(t)} \boldsymbol{\nabla} \cdot \boldsymbol{\sigma} d V
$$

From a physical point of view, the symmetric stress tensor $\boldsymbol{\sigma}$ can be divided up into two parts once more:

$$
\sigma_{k l}=-p \delta_{k l}+\tau_{k l} \quad \text { or } \quad \boldsymbol{\sigma}=-p \boldsymbol{I}+\boldsymbol{\tau}
$$


-  a `mean hydrostatic stress tensor` $-p \boldsymbol{I}$, which tends to change the volume of the fluid in an isotropic manner and only depends on its thermodynamic state, and

-  a deviatoric component called the `stress deviator tensor` $\boldsymbol{\tau}$, which tends to distort the fluid and is essentially linked to its state of deformation.

Introducing equations (3.6) into (3.5) yields

$$
\frac{d}{d t} \int_{V_{m}(t)} \rho \boldsymbol{u} d V=\int_{V_{m}(t)}(\rho \boldsymbol{g}+\boldsymbol{\nabla} \cdot \boldsymbol{\sigma}) d V
$$

Making use of the `Reynolds transport theorem` again (this time in `Vector` form), the lefthand side of equation (3.7), that is to say the momentum for the portion of fluid of volume $V_{m}(t)$ enclosed by the material surface $A_{m}(t)$, can be expressed as

$$
\begin{aligned}
\frac{d}{d t} \int_{V_{m}(t)} \rho \boldsymbol{u} d V &=\int_{V_{m}(t)} \frac{\partial(\rho \boldsymbol{u})}{\partial t} d V+\int_{A_{m}(t)}(\rho \boldsymbol{u} \otimes \boldsymbol{u}) \cdot \boldsymbol{n} d A \\
&=\int_{V_{m}(t)}\left(\frac{\partial(\rho \boldsymbol{u})}{\partial t}+\boldsymbol{\nabla} \cdot(\rho \boldsymbol{u} \otimes \boldsymbol{u})\right) d V
\end{aligned}
$$

The symbol $\otimes$ denoting the tensor product, the term $\rho \boldsymbol{u} \otimes \boldsymbol{u}$ leads to another second-rank tensor $\boldsymbol{T}=\rho\left[u_{l} u_{k}\right]$ with $l, k=1, \ldots, n_{d i m}$, whose divergence can be calculated componentwise

$$
[\boldsymbol{\nabla} \cdot \boldsymbol{T}]_{l}:=\sum_{k=1}^{n_{d i m}} \frac{\partial T_{l k}}{\partial x_{k}} \text { for } \quad l=1, \ldots, n_{d i m}
$$

In this work we will use the indices $k$ and $l$ to indicate space dimensions, whereas $i$ and $j$ are reserved for nodal values and shape functions. Furthermore the summation convention is applied whenever repeated indices appear. Equating the right-hand sides of equations (3.7) and (3.8) writes the momentum balance for the selected material volume of fluid, which accounts for both previous actions:

$$
\int_{V_{m}(t)}\left(\frac{\partial(\rho \boldsymbol{u})}{\partial t}+\boldsymbol{\nabla} \cdot(\rho \boldsymbol{u} \otimes \boldsymbol{u})\right) d V=\int_{V_{m}(t)}(\rho \boldsymbol{g}+\boldsymbol{\nabla} \cdot \boldsymbol{\sigma}) d V
$$

This integral relation holds for all choices of the material volume $V_{m}(t)$ so that we finally obtain the so-called equation of motion:

$$
\frac{\partial(\rho \boldsymbol{u})}{\partial t}+\boldsymbol{\nabla} \cdot(\rho \boldsymbol{u} \otimes \boldsymbol{u}-\boldsymbol{\sigma})=\rho \boldsymbol{g}
$$

Analog to the `continuity equation` (3.4) a second form of the `momentum-conservation equation` exists, this time incorporating the material time derivative of the velocity:

$$
\rho \frac{d \boldsymbol{u}}{d t}-\boldsymbol{\nabla} \cdot \boldsymbol{\sigma}=\rho \boldsymbol{g}
$$

One can easily deduce the non-linear character of the momentum equation (3.10) due to the convective acceleration term $(\boldsymbol{u} \cdot \boldsymbol{\nabla}) \boldsymbol{u}$ coming from linearization and describing the time independent acceleration of the fluid with respect to space. This represents a more than significant feature given that it does not only complicate the solution but also requires a special treatment applying the finite Element method, as will be shown later on.

\textbf{Energy Conservation and Equation of State}

We note that velocity components $u_{k}$, pressure $p$ and density $\rho$ are the independant variables in equations (3.4) and (3.10). Obviously, there is one variable too many for this equation system to be capable of solution. However, if the density is assumed constant (as in incompressible flow) or if a single relationship linking pressure and density can be established (as in isothermal flow with small compressibility) the system becomes complete and is solvable.

More generally, the state variables pressure $p$, density $\rho$ and absolute temperature $T$ are related by an `equation of state` in the form of

$$
\rho=\rho(p, T)
$$

For a hypothetical ideal gas this takes the form

$$
\rho=\frac{p}{R T} \quad \text { respectively } \quad p=\rho R T
$$

where $R$ is the specific gas constant of the medium. In such a general case, it is necessary to supplement the governing equation system by the equation of `energy conservation`. This equation is indeed of interest even if it is not coupled, as it provides additional information about the behaviour of the system. According to (Zienkiewicz and Taylor, 2000 ), the total energy equation in terms of partial time derivative reads

$$
\frac{\partial(\rho e)}{\partial t}+\boldsymbol{\nabla} \cdot((\rho e+p) \boldsymbol{u})-\lambda \boldsymbol{\nabla}^{2} T-q_{H}+\boldsymbol{\nabla} \cdot(\boldsymbol{\tau} \cdot \boldsymbol{u})=\boldsymbol{u} \cdot \rho \boldsymbol{g}
$$

where $e$ is the total energy per unit mass of fluid and can be calculated as the sum of internal and kinetic energy. Apart from the classical mechanical energies, energy transfer due to conduction and chemical reactions have been taken into account as well as energy dissipation due to internal stresses. Accordingly $\lambda$ is the isotropic thermal conductivity and $q_{H}$ represents the heat source terms specified per unit volume. By the way, radiation generally is confined to boundaries.

Nevertheless, we will not immerse in the derivation of this equation as our main focus lies on a general approach for incompressible and compressible flows in subsonic regime where some simplifications are possible. First, a `subsonic flow` is characterized by

$$
M a<1
$$

where the dimensionless `Mach number`

$$
M a=\frac{|\boldsymbol{u}|}{c}
$$

is defined as the ratio of the module of the fluid velocity $\boldsymbol{u}$ and the positive quantity $c=\sqrt{\frac{d p}{d \rho}}$, known as the speed of sound in the medium. The `Mach number`, which is defined locally, gives an idea of compressibility of the flow at any given point. When `incompressible flows` are considered, density gradients are not related to pressure ones. In fact, density is taken as a constant. In this case, the speed of sound can be considered as a constant, much larger than the local convective velocity. On the other hand, in compressible flow it is a quantity that varies in space following changes in thermodynamic `Properties`.

In this context we will introduce two approximations we will make use of later on (Vázquez et al., 1999). In the case of `slightly compressible flows` we will use the relation

$$
\frac{d \rho}{d p}=\frac{1}{c^{2}}
$$

to link density and pressure gradients by defining a constant value for the `speed of sound`. Note that the incompressible case is included implicitely by considering $c \rightarrow \infty$.

The second simplification concerns compressible barotropic flows, that is to say fluids for which there is an equation of state that involves only density and pressure, and not the temperature. In general we write this equation as $p=p(\rho)$, but we will particularize it to the case

$$
p=A \rho^{\gamma}
$$

where $A$ and $\gamma$, the `adiabatic exponent`, are physical constants. This situation is found for example in the case of `isentropic flow of perfect gases` and leads to the following relation

$$
\frac{d \rho}{d p}=\gamma A \rho^{\gamma-1}=\frac{\gamma p}{\rho}
$$



\subsubsection{Navier-Stokes Equations}

The governing equations derived in the preceding sections can be written in the general conservative form

$$
\frac{\partial \boldsymbol{V}}{\partial t}+\frac{\partial \boldsymbol{F}_{k}}{\partial x_{k}}+\frac{\partial \boldsymbol{G}_{k}}{\partial x_{k}}+\boldsymbol{Q}=\mathbf{0}
$$

in which the conservation equations for mass, momentum and energy provide the particular entries to the `Vector`s that presented below, for the sake of clarity once in indicial notation:

- the independent variable `Vector` 
$$
\boldsymbol{V}=\left[\begin{array}{c}
\rho \\
\rho u_{1} \\
\rho u_{2} \\
\rho u_{3} \\
\rho e
\end{array}\right]
$$

- the convective flux `Vector` 
$$
\boldsymbol{F}_{k}=\left[\begin{array}{c}
\rho u_{k} \\
\rho u_{1} u_{k}+\delta_{1 k} p \\
\rho u_{2} u_{k}+\delta_{2 k} p \\
\rho u_{3} u_{k}+\delta_{3 k} p \\
u_{k}(\rho e+p)
\end{array}\right] \\
$$


- the diffusion flux `Vector` 
$$
\boldsymbol{G}_{k}=\left[\begin{array}{c}
0 \\
-\tau_{1 k} \\
-\tau_{2 k} \\
-\tau_{3 k} \\
-\tau_{k l} u_{l}-\lambda \frac{\partial T}{\partial x_{k}}
\end{array}\right] \\
$$

- and the source term `Vector`

$$
\boldsymbol{Q}=\left[\begin{array}{c}
0 \\
-\rho g_{1} \\
-\rho g_{2} \\
-\rho g_{3} \\
-\rho g_{l} u_{l}-q_{H}
\end{array}\right]
$$

\subsubsection{Euler Equations}

The effects of viscosity and heat conduction are important in the immediate vicinity of solid surfaces situated in the flow domain or at its boundaries. The region in which viscosity and conduction have to be taken into account is called `boundary layer` and represents a very thin layer around the respective contour. Outside of the `boundary layer` the flow may be considered as the one of an `ideal fluid`. An `ideal fluid` is defined as inviscid, the tensor of viscous forces disappearing in the conservation equations of the momentum.

Introducing the assumption of an inviscid fluid in the complete set of equations presented in Equation (3.19) and neglecting the influence of heat conduction, a particular case is obtained $(\boldsymbol{G}=\mathbf{0})-$ known as `Euler equations`:

$$
\frac{\partial \boldsymbol{V}}{\partial t}+\frac{\partial \boldsymbol{F}_{k}}{\partial x_{k}}+\boldsymbol{Q}=\mathbf{0}
$$

where the arrays $\boldsymbol{V}, \boldsymbol{F}_{k}$ and $\boldsymbol{Q}$ are defined as before. 

Table $3.1$ rewrites explicitely the `Euler equations` for compressible flows assuming that no heat source is present $\left(q_{H}=0\right)$.


$$
\begin{aligned}
\frac{\partial \rho}{\partial t}+\boldsymbol{\nabla} \cdot(\rho \boldsymbol{u}) &=0 \\
\frac{\partial(\rho \boldsymbol{u})}{\partial t}+\boldsymbol{\nabla} \cdot(\rho \boldsymbol{u} \otimes \boldsymbol{u}+p \boldsymbol{I}) &=\rho \boldsymbol{g} \\
\frac{\partial(\rho e)}{\partial t}+\boldsymbol{\nabla} \cdot((\rho e+p) \boldsymbol{u}) &=\boldsymbol{u} \cdot \rho \boldsymbol{g}
\end{aligned}
$$
Table 3.1: Set of `Euler equations` for compressible flows

The above set is convenient and physically meaningful, defining the conservation of important quantities. Nevertheless, many alternative forms of the above equations are given in literature, obtained by combinations of the various equations. Doing so, one shall keep in mind that equations written in`non-conservative` form may yield incorrect, physically unmeaningful, results in problems where shock discontinuities are present.

It is correct that the main interest of this work is the study of subsonic flow, where this shortcoming could be accepted for the time being. However, in the prospect of future extension of the solver to supersonic regime, the conservative form will be used in order to avoid misunderstandings.

For the sake of simplicity, the implementation will start with a solver for `incompressible flows`. In continuum mechanics an incompressible flow is a solid or fluid flow in which the divergence of velocity $\boldsymbol{u}$ is zero. This is more precisely termed` isochoric` flow:

$$
\boldsymbol{\nabla} \cdot \boldsymbol{u}=0
$$

Note that` isochoric` as well as incompressible describe the flow and do not refer to material `Properties`. However, using the incompressibility assumption in the `continuity equation` (3.4) claims that the mass density is constant following the material Element.

$$
\frac{d \rho}{d t}+\rho \boldsymbol{\nabla} \cdot \boldsymbol{u}=\frac{d \rho}{d t}=0
$$

In this case of constant mass density, pressure and temperature are directly linked by the equation of state $(3.12)$ so that no energy equation is needed (see Table $3.2$ ).

$$
\begin{aligned}
\boldsymbol{\nabla} \cdot \boldsymbol{u} &=0 \\
\frac{\partial \boldsymbol{u}}{\partial t}+(\boldsymbol{u} \cdot \boldsymbol{\nabla}) \boldsymbol{u}+\frac{1}{\rho} \boldsymbol{\nabla} p &=\boldsymbol{g}
\end{aligned}
$$
Table 3.2: Set of `Euler equations` for `incompressible flows` 

\subsection{Edge-Based Data Structure}

The motivation for implementing the `Euler equations` presented above in an nodal based manner is twice. On the one hand, well-known Properties of and experience with the finite Element method can be used to full capacity. On the other hand, the use of an edge-based data structure does not only enforce global conservation and symmetry at discrete level, it also facilitates the `Matrix-Vector` multiplication by pre-calculating certain integrals.

\subsubsection{Nodal Implementation}

Considering a finite Element approximation with shape-functions $N_{i}$, the typical formation of the right-hand side (RHS) requires the evaluation of integrals given by

$$
\boldsymbol{r}_{i}=\int N_{i} \boldsymbol{r}(\boldsymbol{u}) d \Omega=\sum_{\text {elem }} \int N_{i} \boldsymbol{r}\left(N_{j} \boldsymbol{u}_{j}\right) d \Omega_{e l}
$$

These integrals operate on two sets of data:

- ` point-data` for $\boldsymbol{r}_{i}$ and $\boldsymbol{u}_{i}$, and

- `Element-data` for volumes, shape functions and its derivatives.

The flow of information is as follows:

1. gather point information into the Element $\left(\right.$ e.g. $\left.\boldsymbol{u}_{i}\right)$,

2. operate on `Element-data` to evaluate the integral in equation $(3.26)$ and

3. scatter-add Element RHS data to ` point-data` in order to obtain $\boldsymbol{r}_{i}$.

For many simple flow solvers operating on `Vector-machines`, the effort in step 2 is be minor compared to the cost of indirect addressing operations in steps 1 and 3 (Löhner, 2001). This problem may be overcome for low-order Elements by changing the Elementbased data structure into an edge-based one, which eliminates certain redundancies of information. These can be highly demanding in terms of cpu-time: a study in Soto et al. (2004) revealed that the FLOPs (floating point operations) overhead ratio between an Element-based implementation and an edge-based one is approximately $2.5$.

Moreover, a standard shared-memory parallelization of the Elemental loop is complicated because the contributions to the `Matrix` term $i j$ come from more than one Element. Hence, a kind of coloring algorithm would be necessary to avoid the simultaneous access of edge data $i j$ by Elements in different processors. By contrast the parallelization in the presented edge-based implementation is straight-forward: two nested loops are performed, the main loop - which is the one to parallelize - over the Mesh points $i$ and the inner one over its neighbours $j$, connected by the edges $i j$. The contributions of edge $i j$ are computed only when the nodal point $i$ is accessed so that no coloring algorithm is required. It is possible, particularly with regard to the symmetry of Laplacian-like terms, to benefit from this by storing only half of the values. Nevertheless, this has not been realized in this work. In order to facilitate the envisaged parallelization, edge $j i$ (accessed only for the nodal point $j$ ) is considered different from edge $i j$. The idea of a nodal implementation (Codina and Folch, 2004) with an edge-based data structure is to express all contributions in terms of

$$
\int_{\Omega} N_{i} N_{j} \mathrm{~d} \Omega, \quad \int_{\Omega} \frac{\partial N_{i}}{\partial x_{k}} \frac{\partial N_{j}}{\partial x_{l}} \mathrm{~d} \Omega, \quad \int_{\Omega} N_{i} \frac{\partial N_{j}}{\partial x_{k}} \mathrm{~d} \Omega \quad \text { and } \quad \int_{\Omega} \frac{\partial N_{i}}{\partial x_{k}} N_{j} \mathrm{~d} \Omega
$$

These expressions can be derived from the Element integrals known from `Galerkin` weighted residual approximations as illustrated in Figure $3.1$ and will be referred to as the edge contributions of the mass `Matrix` $\mathrm{M}$, the Laplacian operator $\mathbf{L}$, the gradient $\mathbf{G}$ and the transposed gradient $\mathbf{G}^{T}$ with its components $m_{i j}, l_{i j, k l}, g_{i j, k}$ and $g_{j i, k}$ respectively. For





fixed domains, all the integrals in $(3.27)$ can be computed a priori, that is to say at the beginning of the simulation run, and are then stored in a standard compressed-sparse-row format. Only if the domain is reMeshed, the integrals will have to be re-computed.

Listing $3.1$ shows the definition of the presented data structure within `Kratos`.







\subsubsection{Compressed-Sparse-Row Format}

The de facto standard storage format for unstructured sparse matrices is the `compressedsparse-row` (CSR) format. The idea behind CSR is to pack each row by only storing the non-zero Elements (White and Sadayappan, 1997). Obviously this turns out to be quite effective in an nodal based implementation since the contributions to the nodal term $\boldsymbol{r}_{i}$ are delivered only be the edges $i j$ connection point $i$ with its neighbours $j$.

$$
\boldsymbol{A}=\left(\begin{array}{cccc}
1 & 2 & 0 & 0 \\
0 & 3 & 0 & 0 \\
4 & 0 & 5 & 6 \\
0 & 7 & 0 & 8
\end{array}\right)
$$



Table 3.3: Storage example for the compressed-sparse-row format

Considering the `Matrix` $\boldsymbol{A}$ on the left-hand side of Table $3.3$, one quickly will remark that each row may have its own structure. That is the reason way the start index of each row (`mRowStartIndex[i_Node]` ) as well as the column index of the non-zero entries (`mColumnIndex [csr_index]`) have to be stored both. Finally, a third unidimensional array is used to store the value $a_{i j}$ (`mEdgeValue[csr_index]`). The right-hand side of Table $3.3$ points out the CSR storage of `Matrix` $\boldsymbol{A}$, where the CSR index hints at the position of column index and edge value in the two remaining one-dimensional arrays.

With a sparse `Matrix` in CSR, `Matrix`-`Vector` multiplication can be implemented with a simple nested pair of loops. Listing $3.2$ illustrates the loop over all edges in the implemented $\mathrm{C}++$ source code. Whereas the outer loop is over the rows of `Matrix` $\boldsymbol{A}$, the inner loop processes one non-zero row Element after the other.









One of the core operations of iterative sparse solvers is sparse `Matrix-Vector` multiplication. A parallel implementation of this multiplication must maintain scalability in order to achieve high performance. This scalability depends on the balanced mapping of matrices and `Vector`s among the distributed processors, on minimizing inter-processor communication and on a high single `Node` performance.

A parallel implementation within `Kratos`, for instance by the bias of OpenMP, requires that the rows of the edge-based sparse matrices are distributed among the processors, with the rows local to a processor stored in CSR. `Matrix-Vector` multiplication is then performed using an "owner computes" strategy.

Before using the presented loop over edges, the CSR data has to be computed. This is done by two functions `ConstructCSRVector` and `BuildCSRData`, whose important sections are shown by Listings B.1 and B.2 in the appendix.

In the first case a loop over all Nodes (`i_Node`) of the Mesh is performed in order to determine their neighbours (`j_neighbour`). This step is necessary in order to define the structure of the `CSR Vector` correctly. Besides, the nested loop over the neighbouring `Nodes` is used to initialize the edge contributions with zero.

This initialization is quite convenient as in the build-up of the edge data integrals have to be summed up. Therefore a main loop over the Elements has to be performed as demonstrated in Listing B.2. Inside this loop two further loops over the `Nodes` of the considered Element are nested in order to assign the Element contribution to the respective edges. Note that no "diagonal entries" are stored: on the one hand this would be weird as no edge $i i$ exists, and on the other hand they are calculated when necessary by enforcing conservation `Properties`.

In the following two subsections the geometrical expressions required while going from an Element-based data structure to an edge-based data structure will be derived according to Löhner (2001).

\subsubsection{Laplacian Operator}

In the case of the Laplace operator, the RHS in the domain yields on the basis of equa$\operatorname{tion}(3.26)$

$$
\boldsymbol{r}_{i}=-\int_{\Omega} \nabla N_{i} \cdot \nabla N_{j} \mathrm{~d} \Omega \boldsymbol{u}_{j}=-\left[\sum_{\text {elem }} \int_{\Omega} \nabla N_{i} \cdot \nabla N_{j} \mathrm{~d} \Omega\right] \boldsymbol{u}_{j}
$$

This integral can be split into those shape-functions that are the same as $N_{i}$ and those that are different $(j \neq i)$ :

$$
\boldsymbol{r}_{i}=-\sum_{j \neq i}\left[\sum_{\text {elem }} \int_{\Omega} \nabla N_{i} \cdot \nabla N_{j} \mathrm{~d} \Omega\right] \boldsymbol{u}_{j}-\sum_{\text {elem }} \int_{\Omega} \nabla N_{i} \cdot \nabla N_{i} \mathrm{~d} \Omega \boldsymbol{u}_{i}
$$

Introducing the conservation property of the shape-function derivatives

$$
\frac{\partial N_{i}}{\partial x_{k}}=-\sum_{j \neq i} \frac{\partial N_{j}}{\partial x_{k}}
$$

the second term of the right-hand side may be rewritten differently

$$
\boldsymbol{r}_{i}=-\sum_{j \neq i}\left[\sum_{\text {elem }} \int_{\Omega} \nabla N_{i} \cdot \nabla N_{j} \mathrm{~d} \Omega\right] \boldsymbol{u}_{j}+\left[\sum_{\text {elem }} \int_{\Omega} \nabla N_{i} \cdot \sum_{j \neq i} \nabla N_{j} \mathrm{~d} \Omega\right] \boldsymbol{u}_{i}
$$

or, after interchange of the double sums,

$$
\boldsymbol{r}_{i}=\sum_{j \neq i} l_{i j}\left(\boldsymbol{u}_{i}-\boldsymbol{u}_{j}\right) \quad \text { with } \quad l_{i j}=\sum_{\text {elem }} \int_{\Omega} \nabla N_{i} \cdot \nabla N_{j} \mathrm{~d} \Omega
$$

It can be observed that a change in indices $\left(i j\right.$ versus $j i$ ) leads to $l_{i j}=l_{j i}$, which is expected from the symmetry of the Laplace operator.

\subsubsection{Gradient and Transposed Gradient}

We now proceed to first derivatives, the Euler fluxes being a typical example. The RHS is given by an expression of the form

$$
\boldsymbol{r}_{i}=-\int_{\Omega} N_{i} \frac{\partial N_{j}}{\partial x_{k}} \mathrm{~d} \Omega \boldsymbol{F}_{j, k}
$$

where $\boldsymbol{F}_{j, k}$ denotes the flux in the $\mathrm{k}$ -th dimension at `Node` $\mathrm{j}$. This integral is again separated into shape-functions that are not equal to $N_{i}$ and those that are equal

$$
\boldsymbol{r}_{i}=-\sum_{j \neq i}\left[\sum_{\text {elem }} \int_{\Omega} N_{i} \frac{\partial N_{j}}{\partial x_{k}} \mathrm{~d} \Omega\right] \boldsymbol{F}_{j, k}-\sum_{\text {elem }} \int_{\Omega} N_{i} \frac{\partial N_{i}}{\partial x_{k}} \mathrm{~d} \Omega \boldsymbol{F}_{i, k}
$$

Once more the conservation property (3.30) is used to obtain

$$
\boldsymbol{r}_{i}=-\sum_{j \neq i}\left[\sum_{\text {elem }} \int_{\Omega} N_{i} \frac{\partial N_{j}}{\partial x_{k}} \mathrm{~d} \Omega\right] \boldsymbol{F}_{j, k}+\left[\sum_{\text {elem }} \int_{\Omega} N_{i} \sum_{j \neq i} \frac{\partial N_{j}}{\partial x_{k}} \mathrm{~d} \Omega\right] \boldsymbol{F}_{i, k}
$$

This may be restated as

$$
\boldsymbol{r}_{i}=\sum_{j \neq i} g_{i j, k}\left(\boldsymbol{F}_{i, k}-\boldsymbol{F}_{j, k}\right) \quad \text { with } \quad g_{i j, k}=\sum_{\text {elem }} \int_{\Omega} N_{i} \frac{\partial N_{j}}{\partial x_{k}} \mathrm{~d} \Omega
$$

which turns out to be very convenient as the gradient $g_{i i}$ does not appear in the equations and thus no "diagonal entries" of the original Element matrices have to be stored. This means that the whole process of assembly (see Listing B.2) can be performed within one loop over all the edges, whose contributions are stored one after another in the CSR `Vector`.

When the variational formulation of the problem imposes a weak gradient

$$
\boldsymbol{r}_{i}=-\int_{\Omega} \frac{\partial N_{i}}{\partial x_{k}} N_{j} \mathrm{~d} \Omega \boldsymbol{F}_{j, k}
$$

for instance due to partial integration in order to impose boundary values, a similar path can be followed to derive the corresponding statement. After splitting up the integral relative to the shape-functions

$$
\boldsymbol{r}_{i}=-\sum_{j \neq i}\left[\sum_{\text {elem }} \int_{\Omega} \frac{\partial N_{i}}{\partial x_{k}} N_{j} \mathrm{~d} \Omega\right] \boldsymbol{F}_{j, k}-\sum_{\text {elem }} \int_{\Omega} \frac{\partial N_{i}}{\partial x_{k}} N_{i} \mathrm{~d} \Omega \boldsymbol{F}_{i, k}
$$

the conservation property (3.30) of the shape-function derivatives is applied once more

$$
\boldsymbol{r}_{i}=-\sum_{j \neq i}\left[\sum_{\text {elem }} \int_{\Omega} \frac{\partial N_{i}}{\partial x_{k}} N_{j} \mathrm{~d} \Omega\right] \boldsymbol{F}_{j, k}+\sum_{\text {elem }} \int_{\Omega} \sum_{j \neq i} \frac{\partial N_{j}}{\partial x_{k}} N_{i} \mathrm{~d} \Omega \boldsymbol{F}_{i, k}
$$

so that we finally obtain

$$
\begin{aligned}
\boldsymbol{r}_{i}=\sum_{j \neq i}\left(g_{i j, k} \boldsymbol{F}_{i, k}-g_{j i . k} \boldsymbol{F}_{j, k}\right) \quad \text { with } \quad g_{i j, k} &=\sum_{e l e m} \int_{\Omega} N_{i} \frac{\partial N_{j}}{\partial x_{k}} \mathrm{~d} \Omega \\
\text { and } g_{j i, k} &=\sum_{\text {elem }} \int_{\Omega} \frac{\partial N_{i}}{\partial x_{k}} N_{j} \mathrm{~d} \Omega
\end{aligned}
$$

This is the reason why we initially calculated and stored both gradients. We can conclude that a change in indices $i j$ versus $j i$ leads to the following relation

$$
g_{j i, k}=-g_{i j, k}+\int_{\Gamma} N_{j} N_{i} n_{k} \mathrm{~d} \Gamma
$$

obtained by partial integration. Certainly, this was expected because of the unsymmetric operator. Using equation (3.41), the extra boundary integral would require a seperate loop over boundary edges, adding (unsymmetrically) only to `Node` $j$.

Observe that we take a difference on the edge level and then add contributions to both the end points. This implies that the conservation law given for the first derivatives is not reflected at the edge level, although it is still maintained at the point level. For a second form reflecting the conservation property on the edge level please refer to Löhner (2001).

\subsubsection{Consistent and Lumped Mass `Matrix`}

For the shape-functions themselves, a conservation property similar to equation (3.30) exists

$$
N_{i}=1-\sum_{j \neq i} N_{j}
$$

Nevertheless, it is completely worthless if we attempt to use it with the objective of simplifying the implementation of mass terms. Due to the fact that we do not consider the diagonal entries of the Element matrices in the build-up process, the missing term $m_{i i}$ in fact is a problem for us.

To circumvent this inconvenience we decided to store the `lumped mass Matrix` in the form of a nodal parameter list `mLumpedMas sMatrix`. This makes it possible to use either the lumped version directly, which facilitates the programming but may not always be adequate, or to calculate the missing diagonal Elements "on the fly" by summing up edge-contributions in a temporary variable and making use of

$$
m_{i i}=m_{i}^{\text {lumped }}-\sum_{j \neq i} m_{i j}
$$

before switching over to the next row start index. 

\subsection{Implementation for Incompressible Flows}

In the intent of developping a general approach for incompressible and compressible flows, the low `Mach number` setting is a critical situation for the compressible case. As the `Mach number` approaches zero, compressible flow solvers suffer severe deficiencies, both in efficiency and accuracy. Principally there are two main approaches:

1. the `modification of a compressible solver` (`density-based`) downward to low Mach numbers or

2. the `extension of an incompressible solver` (`pressure-based`) towards this regime.

As already mentioned, this work focuses on the subsonic regime when the magnitude of the flow velocity is small compared with the acoustic wave-speed. In this case the dominance of the convection terms within the time-dependent equations renders the system stiff and causes density-based solvers to converge slowly. Time-marching procedures may suffer severe stability and accuracy restrictions so that they become inefficient for low `Mach number` flows. To capture solution convergence for these regimes two techniques $-$ preConditioning and asymptotic schemes - have been proposed and are detailled in Keshtiban et al. (2004).

In contrast, pressure-based methods were originally conceived to solve `incompressible flows`, adopting pressure as a primary variable. Following this approach, pressure variation remains finite - irrespective of the `Mach number` -, which renders the computation tractable throughout the entire spectrum of Mach numbers. This has been the main reason for electing this path.

\subsubsection{Problem Statement}

Let $\Omega$ be the domain of $\mathbb{R}^{n}$ occupied by the fluid, where $n=2$ or 3 is the number of space dimensions, $\Gamma=\partial \Omega$ its boundary and $[0, T]$ the time interval of analysis. The Euler problem (Table 3.2) consists in finding a velocity $\boldsymbol{u}$ and a kinematic pressure $p_{\text {kin }}=p / \rho$ such that

$$
\begin{aligned}
\frac{\partial \boldsymbol{u}}{\partial t}+(\boldsymbol{u} \cdot \boldsymbol{\nabla}) \boldsymbol{u}+\boldsymbol{\nabla} p_{k i n} &=\boldsymbol{f} & & \text { in } \Omega, t \in[0, T] \\
\boldsymbol{\nabla} \cdot \boldsymbol{u} &=0 & & \text { in } \Omega, t \in[0, T] \\
\boldsymbol{u} &=\boldsymbol{u}_{D} & & \text { on } \Gamma_{D}, t \in[0, T] \\
p &=p_{\infty} & & \text { on } \Gamma_{N}, t \in[0, T] \\
\boldsymbol{u} &=\boldsymbol{u}_{0} & & \text { in } \Omega, t=0
\end{aligned}
$$

where $\boldsymbol{f}$ is the force `Vector` (per unit mass as well) and $\boldsymbol{u}_{0}$ represents the initial velocity field. The Dirichlet boundary Condition states $\boldsymbol{u}_{D}=\mathbf{0}$ in the case of a no-slip boundary and $\boldsymbol{u}_{D}=\boldsymbol{u}-\boldsymbol{u} \cdot \boldsymbol{n}$ if a slip Condition is applied, $\boldsymbol{n}$ being the outward unit normal. $\Gamma_{D}$ and the Neumann boundary $\Gamma_{N}$, on which the external pressuer $p_{\infty}$ is given, are disjoint components of $\Gamma$. To write the weak form of the problem (3.44) we need to introduce some notation (Codina and Folch, 2004). We denote by $\mathcal{H}^{1}(\Omega)$ the Sobolev space of functions whose first derivatives belong to $\mathcal{L}^{2}(\Omega)$, and by $\mathcal{H}_{0}^{1}(\Omega)$ the subspace of $\mathcal{H}^{1}(\Omega)$ of functions with zero trace on $\Gamma$. A bold character is used for the `Vector` counterpart of these spaces. The $\mathcal{L}^{2}(\Omega)$ scalar product in a set $\omega$ is denoted by $(\cdot, \cdot)_{\omega} .$ The subscript $\omega$ is omitted when it coincides with $\Omega$. To pose the problem, we also need the functional spaces $\mathcal{V}_{s t}=\mathcal{H}_{0}^{1}(\Omega)^{n}$ and $\mathcal{Q}_{s t}=\left\{q \in \mathcal{L}^{2}(\Omega) \mid \int_{\Omega} q=0\right\}$ as well as $\mathcal{V}=\mathcal{L}^{2}\left(0, T ; \mathcal{V}_{s t}\right)$ and $\mathcal{Q}=\mathcal{L}^{2}\left(0, T ; \mathcal{Q}_{s t}\right)$ for the transient problem.

Assuming for simplicity the force `Vector` to be square integrable, the weak form of $(3.44)$ consists in finding $\left(\boldsymbol{u}, p_{\text {kin }}\right) \in \mathcal{V} \times \mathcal{Q}$ such that

$$
\begin{aligned}
\left(\partial_{t} \boldsymbol{u}, \boldsymbol{\nu}\right)+(\boldsymbol{u} \cdot \boldsymbol{\nabla} \boldsymbol{u}, \boldsymbol{\nu})-\left(p_{k i n}, \boldsymbol{\nabla} \cdot \boldsymbol{\nu}\right) &=(\boldsymbol{f}, \boldsymbol{\nu}) & & \forall \boldsymbol{\nu} \in \mathcal{V}_{s t} \\
(q, \boldsymbol{\nabla} \cdot \boldsymbol{u}) &=0 & & \forall q \in \mathcal{Q}_{s t}
\end{aligned}
$$

and satisfying the initial Condition in a weak sense.

\subsubsection{Discretization}

Principally, any temporal discretization is possible. However, we shall concentrate on the monolithic (solving for velocity and pressure at the same time) backward Euler scheme. The time discretized version of (3.45) requires, from known $\boldsymbol{u}^{n}$, to find $\boldsymbol{u}^{n+1} \in \mathcal{V}_{h}$ and $p_{k i n}^{n+1} \in \mathcal{Q}_{h}$ such that

$$
\begin{aligned}
\left(\delta_{t} \boldsymbol{u}^{n}, \boldsymbol{\nu}\right)+\left(\boldsymbol{u}^{n+1} \cdot \boldsymbol{\nabla} \boldsymbol{u}^{n+1}, \boldsymbol{\nu}\right)-\left(p_{k i n}^{n+1}, \boldsymbol{\nabla} \cdot \boldsymbol{\nu}\right) &=\left(\overline{\boldsymbol{f}}^{n+1}, \boldsymbol{\nu}\right) & & \forall \boldsymbol{\nu} \in \mathcal{V}_{s t} \\
\left(q, \boldsymbol{\nabla} \cdot \boldsymbol{u}^{n+1}\right) &=0 & & \forall q \in \mathcal{Q}_{s t}
\end{aligned}
$$

The notation $\delta_{t} \boldsymbol{u}^{n}:=\frac{\Delta \boldsymbol{u}^{n}}{\Delta t}$ and $\Delta \boldsymbol{u}^{n}=\boldsymbol{u}^{n+1}-\boldsymbol{u}^{n}$ has been used. The term $\overline{\boldsymbol{f}}^{n+1}$ has to be understood as the time average of the force in the interval $\left[t^{n}, t^{n+1}\right]$. The time step size $\Delta t=t^{n+1}-t^{n}$ is computed using the `Courant-Friedrichs-Lewy (CFL) Condition`, which is commonly (Wikipedia - The Free Encyclopedia) represented as

$$
\frac{u \Delta t}{\Delta x}<C
$$

for one-dimensional pure advection (ignoring diffusion or reaction terms) schemes. $u$ is the velocity, $\Delta t$ the time step, $\Delta x$ the length interval and $C$ a constant depending on the particular equation to be solved and not on $\Delta t$ and $\Delta x$. Using an edge-based data structure we will introduce the nodal parameter

$$
h_{i, \min }=\min _{j} l_{i j}
$$

as the minimum length $l_{i j}$ of the edges $i j$ surrounding the `Node` $i$ in order to approximate $\Delta x$. Hence the time step is computed as

$$
\Delta t=\min _{i}\left(\frac{h_{i, \min }}{\left|\boldsymbol{u}_{i}\right|}\right) N_{C F L}
$$

where the `Courant number` $N_{C F L}$ shall incorporate a certain security factor. It can be defined in the `Python` start script of the simulation.

With regard to spatial discretization, let $\mathcal{V}_{h}$ be a finite Element space to approximate $\mathcal{V}$, and $\mathcal{Q}_{h}$ a finite Element approximation to $\mathcal{Q}$. Functions in $\mathcal{V}_{h}$ need to be continuous piecewise polynomials, whereas continuity principally is not necessary for $\mathcal{Q}_{h}$. However, for reasons explained below, we will consider only continuous pressure interpolations. It is well known that for this discrete problem to be stable

$$
\begin{aligned}
\left(\delta_{t} \boldsymbol{u}_{h}^{n}, \boldsymbol{\nu}_{h}\right)+\left(\boldsymbol{u}_{h}^{n+1} \cdot \boldsymbol{\nabla} \boldsymbol{u}_{h}^{n+1}, \boldsymbol{\nu}_{h}\right)-\left(p_{k i n, h}^{n+1}, \boldsymbol{\nabla} \cdot \boldsymbol{\nu}_{h}\right) &=\left(\overline{\boldsymbol{f}}^{n+1}, \boldsymbol{\nu}_{h}\right) & & \forall \boldsymbol{\nu}_{h} \in \mathcal{V}_{h}, \\
\left(q_{h}, \boldsymbol{\nabla} \cdot \boldsymbol{u}_{h}^{n+1}\right) &=0 & & \forall q_{h} \in \mathcal{Q}_{h}
\end{aligned}
$$

the velocity and pressure spaces need to satisfy the classical inf-sup Condition, which in particular precludes the use of convenient equal velocity-pressure interpolations. However, it can be demonstrated that this Condition is not required when fractional step methods using a pressure Poisson equation are employed (Codina, 2001).

Before introducing the fractional step scheme, the `Matrix` form of the problem shall be presented

$$
\begin{aligned}
\mathbf{M} \frac{\mathbf{u}^{n+1}-\mathbf{u}^{n}}{\Delta t}+\mathbf{C}\left(\mathrm{u}^{n+1}\right) \mathbf{u}^{n+1}+\mathbf{G p}^{n+1} &=\mathbf{f}^{n+1} \\
\mathbf{D} \mathbf{u}^{n+1} &=0
\end{aligned}
$$

where $u$ and $p$ are the arrays of nodal velocities and kinematic pressures, respectively. Keeping the index conventions introduced in Section $3.2 .2$ (indices $k$ and $l$ to indicate space dimensions, whereas $i$ and $j$ are employed for nodal values and shape functions), the components of the arrays envolved in the discrete problem $(3.51)$ are

$$
\begin{aligned}
\mathrm{M}_{i j, k l} &=\left(N_{i}, N_{j}\right) \delta_{k l}, \\
\mathrm{C}\left(\mathrm{u}^{n+1}\right)_{i j, k l} &=\left(N_{i}, \boldsymbol{u}_{h}^{n+1} \cdot \boldsymbol{\nabla} N_{j}\right) \delta_{k l}, \\
\mathrm{G}_{i j, k} &=\left(N_{i}, \partial_{k} N_{j}\right)=-\left(\partial_{k} N_{i}, N_{j}\right), \\
\mathrm{f}_{i, k} &=\left(N_{i}, f_{k}\right), \\
\mathrm{D}_{i j, l} &=\left(N_{i}, \partial_{l} N_{j}\right),
\end{aligned}
$$

where $\delta_{k l}$ is the Kronecker Delta. Note the property $\mathbf{G}=-\mathbf{D}^{T}$. Except $\mathrm{f}$, which is a `Vector`, all the arrays are matrices whose components can be obtained by grouping together first spatial and nodal index $(k$ and possibly $i)$ and doing the same for the second indices $(l$ and possibly $j$ ). Though, we do not really "construct" these matrices as we will use the precalculated edge-data presented in Section $3.3$ to perform the operations.

In this context the contributions of the convective `Galerkin` term have to be mentioned. In an Element-based implementation they are computed as

$$
C_{i j, l l}=\sum_{k=1}^{n_{d o f}} \int_{\Omega} N_{i} a_{k} \frac{\partial N_{j}}{\partial x_{k}} \mathrm{~d} \Omega
$$

where $a_{k}$ is the $k$ -th component of the advective velocity $\left(\boldsymbol{a}=\boldsymbol{u}_{h}^{n+1}\right.$ in $\left.(3.50)\right)$. In order to use the pre-computed gradient `Matrix` $\mathbf{G}$, the following approximation must be done at this point according to Soto et al. (2004):

$$
C_{i j, l l} \approx \sum_{k=1}^{n_{d o f}} a_{i j, k} \int_{\Omega} N_{i} \frac{\partial N_{j}}{\partial x_{k}} \mathrm{~d} \Omega
$$

where $a_{i j, k}$ is the $k$ -th component of the advective velocity associated with the edge $i j$. The first idea is to take $\boldsymbol{a}_{i j}$ as the average velocity of the nodal points $i$ and $j$ and to enforce the conservation property $\sum_{j=1}^{n_{p t s}}\left(\sum_{k=1}^{n_{\text {`Dof` }}} C_{i j, l k}\right)=0$ by computing the diagonal as the subtraction of the same-row non-diagonal terms. However, this procedure would destroy the second-order `Galerkin`, or central-difference, approximation of the convective term (assuming that linear Elements are used). Such a second-order approximation is reflected at discrete level by the fact that $C_{i i, l l}=0$ for the interior nodal points, something that naturally arises in a standard finite Element approximation using linear Elements (or in finite differences using a central scheme).

The only way to fulfill this Condition and to maintain the consistency of the method $-$ the exact solution is still a solution of the discrete problem - is taking $\boldsymbol{a}_{i j}$ as a function of only the nodal point $i\left(\boldsymbol{a}_{i j}=\boldsymbol{a}_{i}\right)$. In this case it is easy to verify for the interior points that

$$
\mathrm{C}_{i i, l l} \approx \sum_{j k \neq i l} a_{i, k} \int_{\Omega} N_{i} \frac{\partial N_{j}}{\partial x_{k}} \mathrm{~d} \Omega=0
$$

implying that the approximation is of second-order and the conservation property for stationary terms holds.

Concerning the computation of $\boldsymbol{a}_{i}$, the velocity at the nodal point $i, \boldsymbol{u}_{i}$, certainly is first choice. Nevertheless, we used the following smoothing in this work

$$
\begin{array}{lll}
a_{i, k}=\frac{m_{i j} u_{j, k}}{\sum_{j \neq i} m_{i j}} & \forall j \neq i & \text { for interior points } \\
a_{i, k}=\frac{m_{i j} u_{j, k}}{\sum_{j=1}^{n_{p t s} m_{i j}}} & \forall j & \text { for boundary points }
\end{array}
$$

where $m_{i j}$ is the term $i j$ of the consistent mass `Matrix` and $u_{j, k}$ is the $k$ -th component of the velocity at nodal point $j$. Note that the computation is only done over the neighbours $j$ connected to point $i$ - using the explained CSR-loop over edges - as otherwise the contribution is zero.

Numerical experience indicates that equations $(3.56)$ for the advective velocity associated with the nodal point $i$ produce a better convergence rate and more accurate results then taking simply $\boldsymbol{a}_{i}=\boldsymbol{u}_{i}$ (Soto et al., 2004). Moreover, it can be checked that, given a discrete velocity field $\boldsymbol{u}$, the convective RHS obtained employing a standard Element-based implementation

$$
f_{i, l}^{\text {Element }}=\sum_{j=1}^{n_{p t s}}\left(\sum_{k=1}^{n_{d o f}} \int_{\Omega} N_{i} u_{k} \frac{\partial N_{j}}{\partial x_{k}} \mathrm{~d} \Omega u_{j, l}\right)
$$

is much better approximated by using equations $(3.56)$. Besides, they naturally arise from a central difference (or central finite volume) discretization of the convective Navier-Stokes term.

Note that the same treatment will be applicable to the convective stabilization terms introduced in Section 3.4.4.

\subsubsection{Fractional Step Algorithm}

The fully discrete problem $(3.51)$ is exactly equivalent to

$$
\begin{aligned}
\mathbf{M} \frac{1}{\Delta t}\left(\tilde{\mathbf{u}}^{n+1}-\mathrm{u}^{n}\right)+\mathbf{C}\left(\mathbf{u}^{n+1}\right) \mathbf{u}^{n+1}+\gamma \mathbf{G}^{n} &=\mathbf{f}^{n+1} \\
\mathbf{M} \frac{1}{\Delta t}\left(\mathbf{u}^{n+1}-\tilde{\mathbf{u}}^{n+1}\right)+\mathbf{G}\left(\mathrm{p}^{n+1}-\gamma \mathbf{p}^{n}\right) &=0 \\
\mathbf{D} \mathbf{u}^{n+1} &=0
\end{aligned}
$$

as the splitting of the momentum equation is purely algebraic. The array $\tilde{u}^{n+1}$ contains nodal values of the auxiliary variable called fractional velocity, and $\gamma$ is a numerical parameter whose values of interest are 0 (first-order splitting) and 1 (second-order splitting). At this point we can make the essential approximation

$$
\mathbf{C}\left(\mathrm{u}^{n+1}\right) \mathrm{u}^{n+1} \approx \mathbf{C}\left(\tilde{\mathbf{u}}^{n+1}\right) \tilde{u}^{n+1}
$$

which may be interpreted as an incomplete block LU factorization of the original problem (3.58). The advantage of this discrete approach is that now there is no question about the boundary Conditions for the intermediate variable $\tilde{u}^{n+1}$ : since boundary Conditions are incorporated in the discrete problem $(3.58)$, the prescriptions for the fractional velocity are exactly the same as for the end-of-step velocity $\mathrm{u}^{n+1}($ Codina, 2001$)$.

By means of equation $(3.58 \mathrm{~b}), \mathrm{u}^{n+1}$ can be expressed in terms of $\tilde{\mathrm{u}}^{n+1}$ and inserted into equation $(3.58 \mathrm{c})$, which yields the following set of equations to be solved

$$
\begin{aligned}
\mathbf{M} \frac{1}{\Delta t}\left(\tilde{\mathbf{u}}^{n+1}-\mathbf{u}^{n}\right)+\mathbf{C}\left(\tilde{\mathbf{u}}^{n+1}\right) \tilde{\mathrm{u}}^{n+1}+\gamma \mathbf{G p}^{n} &=\mathbf{f}^{n+1} \\
\mathbf{M} \frac{1}{\Delta t}\left(\mathrm{u}^{n+1}-\tilde{\mathbf{u}}^{n+1}\right)+\mathbf{G}\left(\mathrm{p}^{n+1}-\gamma \mathbf{p}^{n}\right) &=0 \\
\Delta t \mathbf{D M}^{-1} \mathbf{G}\left(\mathrm{p}^{n+1}-\gamma \mathbf{p}^{n}\right) &=\mathbf{D} \tilde{u}^{n+1}
\end{aligned}
$$

Even though the problem can be implemented as such, it is very convenient to make a further approximation. In order to avoid dealing with the `Matrix` $\mathbf{D M}^{-1} \mathbf{G}$ we shall approximate it by the Laplacian operator

$$
\mathbf{D} \mathbf{M}^{-1} \mathbf{G} \approx \mathbf{L}, \quad \text { with components } \quad \mathrm{L}_{i j}=-\left(\boldsymbol{\nabla} N_{i}, \boldsymbol{\nabla} N_{j}\right)
$$

It shall be stated here that this approximation is only possible when continuous pressure interpolations are employed. Likewise, it introduces implicitly the same wrong pressure boundary Condition as when the splitting is performed at continuous level (see Codina (2001) for a detailed discussion). After having ordered according to the sequence of solution (first $\tilde{u}^{n+1}$, then $\mathrm{p}^{n+1}$ and finally $\mathrm{u}^{n+1}$ ) the problem to be solved is

$$
\begin{aligned}
\mathbf{M} \frac{1}{\Delta t}\left(\tilde{\mathbf{u}}^{n+1}-\mathrm{u}^{n}\right)+\mathbf{C}\left(\tilde{\mathrm{u}}^{n+1}\right) \tilde{\mathrm{u}}^{n+1}+\gamma \mathbf{G p}^{n} &=\mathbf{f}^{n+1} \\
\Delta t \mathbf{L}\left(\mathrm{p}^{n+1}-\gamma \mathrm{p}^{n}\right) &=\mathbf{D} \tilde{u}^{n+1} \\
\mathbf{M} \frac{1}{\Delta t}\left(\mathrm{u}^{n+1}-\tilde{u}^{n+1}\right)+\mathbf{G}\left(\mathrm{p}^{n+1}-\gamma \mathrm{p}^{n}\right) &=0
\end{aligned}
$$

\subsubsection{Stabilization Techniques}

\textbf{Pressure and Convection Stabilization}

The treatment of pressure in numerical approximations of incompressible flow problems is still an active subject of research, basically for two reasons: On the one hand its approximation needs to be different from that of the velocity field in order to obtain a stable numerical scheme. On the other hand its coupling with the velocity components makes the solution of the linear system, arising from the discretization of the equations, highly demanding from a computational point of view (Codina and Soto, 2004).

- Referring to the `pressure approximation`, the use of finite Element methods leads to the well known inf-sup stability Condition for the velocity and pressure finite Element spaces if the standard `Galerkin` formulation is used. Either one uses velocity pressure pairs fulfilling the inf-sup Condition, or the discrete variational formulation of the problem has to be modified in order to circumvent it. Finite Element formulations of this kind may fall basically into two categories: techniques to stabilize simple Elements, such as the $Q_{1} / P_{0}$ pair (multilinear velocity, piecewise constant pressure) and methods that allow the use of equal interpolations (and therefore continuous pressures). We will apply the latter in this work.

- Concerning the velocity-pressure coupling, fractional step methods for the incompressible Navier-Stokes equations enjoy widespread popularity because of their computational efficiency based on the uncoupling of of the pressure from the velocity components. However, several issues related to these methods still deserve further analysis, and perhaps the computed pressure near boundaries and the stability of the pressure itself.

Apart from the pressure treatment, another important issue to be considered in the numerical approximation of `incompressible flows` is the numerical instability problem, found when the viscous term is small compared to the convective one - which is evident in the Euler problem $(\nu=0)$. Both, the inf-sup Condition as well as the convection instabilities, can be overcome by resorting from the standard `Galerkin` method to a stabilized formulation. The one adopted in this work is based on the subgrid scale concept. The basic idea is to approximate the effect of the component of the continuous solution that cannot be resolved by the finite Element Mesh on the discrete finite Element solution. Hence an important feature of the formulation is that the unresolved component, hereafter referred to as `subgride scale` or `subscale`, is assumed to be $\mathcal{L}^{2}$ orthogonal to the finite Element space. 

\textbf{Orthogonal Subscale Stabilization}

Starting once more with the weak form of the problem, the discrete problem is obtained by approximating $\boldsymbol{u}$ and $p_{k i n}$. If $\boldsymbol{u}_{h}$ and $p_{k i n, h}$ are the finite Element unknowns, we put $\boldsymbol{u} \approx \boldsymbol{u}_{h}+\hat{\boldsymbol{u}}$ and $p_{\text {kin }} \approx p_{k i n, h}$. That is to say that the velocity is approximated by its finite Element component plus an additional term whereas the pressure subscale will be taken as zero for the sake of simplicity. $\boldsymbol{u}^{n} \approx \boldsymbol{u}_{*}^{n}:=\boldsymbol{u}_{h}^{n}+\hat{\boldsymbol{u}}^{n}$ and $p_{k i n}^{n} \approx p_{k i n, h}^{n}$ are called the velocity and the (kinematic) pressure for time level $n$. Considering the spatial discretization, we assume that $\boldsymbol{u}_{h}^{n}$ and $p_{k i n, h}^{n}$ are constructed using the standard finite Element interpolation. In particular, equal velocity-pressure interpolation is possible with the orthogonal subscale stabilization. Concerning the behaviour of $\hat{\boldsymbol{u}}^{n}$, a bubble-like function is assumed so that it vanishes on the interElement boundaries. However, contrary to what is commonly done, no particular behaviour of the velocity subscale is assumed within the Element domains. Following closely the operations and modifications outlined in Codina and Soto (2004), one finally arrives at the discrete problem



where the orthogonal projections can be expressed as $P_{h}^{\perp}=I-P_{h}$ with $P_{h}$ being the $\mathcal{L}^{2}$ -projection onto $\mathcal{V}_{h}:$

$$
\begin{aligned}
P_{h}^{\perp}\left(\boldsymbol{u}_{h}^{n+1} \cdot \boldsymbol{\nabla} \boldsymbol{u}_{h}^{n+1}\right) &=\boldsymbol{u}_{h}^{n+1} \cdot \nabla \boldsymbol{u}_{h}^{n+1}-\boldsymbol{y}_{h}^{n+1} \\
P_{h}^{\perp}\left(\boldsymbol{\nabla} p_{h}^{n+1}\right) &=\boldsymbol{\nabla} p_{h}^{n+1}-\boldsymbol{z}_{h}^{n+1}
\end{aligned}
$$

$\boldsymbol{y}_{h}^{n+1}$ and $\boldsymbol{z}_{h}^{n+1}$ are the solution of

$$
\begin{array}{ll}
\left(\boldsymbol{y}_{h}^{n+1}, \boldsymbol{\nu}_{h}\right)=\left(\boldsymbol{u}_{h}^{n+1} \cdot \boldsymbol{\nabla} \boldsymbol{u}_{h}^{n+1}, \boldsymbol{\nu}_{h}\right) & \forall \boldsymbol{\nu}_{h} \in \mathcal{V}_{h} \\
\left(\boldsymbol{z}_{h}^{n+1}, \boldsymbol{\nu}_{h}\right)=\left(\boldsymbol{\nabla} p_{k i n, h}^{n+1}, \boldsymbol{\nu}_{h}\right) & \forall \boldsymbol{\nu}_{h} \in \mathcal{V}_{h}
\end{array}
$$

The stability and convergence analysis for the Navier-Stokes problem dictates that the `intrinsic time` $\tau$, like it is called by Soto et al. (2004), must be computed as

$$
\tau=\frac{h^{2}}{4 \nu+2|\boldsymbol{u}| h}
$$

where $h$ and $\boldsymbol{u}$ are the typical Element size and velocity respectively, and $\nu$ is the viscosity of the fluid. Particularly with regard to our edge-based data structure and the envisaged nodal implementation, we use once more the minimum edge-length $h_{i, \min }$ calculated by equation (3.48). The "inviscid version" of equation (3.66) states

$$
\tau_{i}=\frac{h_{i}}{2\left|\boldsymbol{u}_{i}\right|+\varepsilon}
$$

By the choice of a relatively small parameter $\varepsilon$ we guarantee that the denominator is different from zero. In the case of compressible `Euler equations` the influence of "reaction terms" may be taken into account, which would render this last measure unnecessary.

Note that $\tau$ has been included within the inner product since, in principle, it changes from point to point. The terms multiplied by this parameter are responsible for the enhancement of stability with respect to the standrad `Galerkin` method, which is why we call them `stabilization terms`.

Considering these in the `Matrix` form of the fractional step scheme yields

$$
\begin{aligned}
\mathbf{M} \frac{1}{\Delta t}\left(\tilde{u}^{n+1}-u^{n}\right)+\mathbf{C}\left(\tilde{u}^{n+1}\right) \tilde{u}^{n+1}+\gamma \mathbf{G p}^{n} \\
+\mathbf{S}_{u}\left(\tilde{\tau}^{n+1} ; \tilde{u}^{n+1}\right) \tilde{u}^{n+1}-\mathbf{S}_{y}\left(\tilde{\tau}^{n+1} ; \tilde{u}^{n+1}\right) \mathrm{y}^{n+1} &=\mathrm{f}^{n+1} \\
\Delta t \mathbf{L}\left(\mathrm{p}^{n+1}-\gamma \mathrm{p}^{n}\right)+\mathbf{S}_{p}\left(\tilde{\tau}^{n+1}\right) \mathbf{p}^{n+1}-\mathbf{S}_{z}\left(\tilde{\tau}^{n+1}\right) \mathbf{z}^{n+1} &=\mathbf{D} \tilde{u}^{n+1} \\
\mathbf{M} \frac{1}{\Delta t}\left(\mathrm{u}^{n+1}-\tilde{u}^{n+1}\right)+\mathbf{G}\left(\mathrm{p}^{n+1}-\gamma \mathrm{p}^{n}\right) &=0 \\
\mathbf{M}_{\mathrm{y}}^{n+1}-\mathbf{C}\left(\tilde{\mathrm{u}}^{n+1}\right) \tilde{\mathrm{u}}^{n+1} &=0 \\
\mathbf{M z}^{n+1}-\mathbf{G p}^{n+1} &=0
\end{aligned}
$$

where the components of the stabilization arrays are

$$
\begin{aligned}
\mathrm{S}_{u}\left(\tilde{\tau}^{n+1} ; \tilde{\mathbf{u}}^{n+1}\right)_{i j, k l} &=\left(\tilde{\tau}_{i}^{n+1} \tilde{\boldsymbol{u}}_{h}^{n+1} \cdot \boldsymbol{\nabla} N_{i}, \tilde{\boldsymbol{u}}_{h}^{n+1} \cdot \boldsymbol{\nabla} N_{j}\right) \delta_{k l} \\
\mathrm{~S}_{y}\left(\tilde{\tau}^{n+1} ; \tilde{\mathbf{u}}^{n+1}\right)_{i j, k l} &=\left(\tilde{\tau}_{i}^{n+1} \tilde{\boldsymbol{u}}_{h}^{n+1} \cdot \boldsymbol{\nabla} N_{i}, N_{j}\right) \delta_{k l} \\
\mathrm{~S}_{p}\left(\tilde{\tau}^{n+1}\right)_{i j} &=\left(\tilde{\tau}_{i}^{n+1} \boldsymbol{\nabla} N_{i}, \boldsymbol{\nabla} N_{j}\right) \\
\mathrm{S}_{z}\left(\tilde{\tau}^{n+1}\right)_{i j, l} &=\left(\tilde{\tau}_{i}^{n+1} \partial_{l} N_{i}, N_{j}\right)
\end{aligned}
$$

using the known convention for nodal indices $i, j$ and spatial indices $k, l$. To avoid the resolution of an equation system for the projection terms, the lumped mass `Matrix` is used so that equations $(3.68 \mathrm{~d})$ and (3.68e) can be considered in an edge-based manner within (3.68a) and (3.68b) respectively:

$$
\begin{aligned}
&\mathbf{M} \frac{1}{\Delta t}\left(\tilde{u}^{n+1}-u^{n}\right)+\mathbf{C}\left(\tilde{u}^{n+1}\right) \tilde{u}^{n+1}+\gamma \mathbf{G p}^{n} \\
&+\mathbf{S}_{u}\left(\tilde{\tau}^{n+1} ; \tilde{u}^{n+1}\right) \tilde{u}^{n+1}-\mathbf{S}_{y}\left(\tilde{\tau}^{n+1} ; \tilde{u}^{n+1}\right) \mathbf{M}^{-1} \mathbf{C}\left(\tilde{u}^{n+1}\right) \tilde{u}^{n+1}=\mathfrak{f}^{n+1} \\
&\Delta t \mathbf{L}\left(p^{n+1}-\gamma p^{n}\right)+\mathbf{S}_{p}\left(\tilde{\tau}^{n+1}\right) p^{n+1}-\mathbf{S}_{z}\left(\tilde{\tau}^{n+1}\right) \mathbf{M}^{-1} \mathbf{G p}^{n+1}=\mathbf{D} \tilde{u}^{n+1} \\
&\mathbf{M} \frac{1}{\Delta t}\left(u^{n+1}-\tilde{u}^{n+1}\right)+\mathbf{G}\left(p^{n+1}-\gamma p^{n}\right)=0
\end{aligned}
$$

\subsubsection{Solving Procedure and Boundary Conditions}

Table $3.4$ gives an overview of the implemented algorithm for the simulation of `incompressible flows` and details each step. 



Table 3.4: Solving procedure for `incompressible flows` 

\subsection{Expansion for Compressible Flows}

\subsubsection{Modifications}

Let us recall the continuous momentum equation for the Euler problem first:

$$
\frac{\partial\left(\rho u_{l}\right)}{\partial t}+\frac{\partial\left(\rho u_{l} u_{k}\right)}{\partial x_{k}}+\frac{\partial p}{\partial x_{l}}=\rho g_{l}
$$

and introduce the momentum $U_{l}=\rho u_{l}$ as variable

$$
\frac{\partial U_{l}}{\partial t}+\frac{\partial\left(U_{l} u_{k}\right)}{\partial x_{k}}+\frac{\partial p}{\partial x_{l}}=F_{l}
$$

Note that we are dealing with the real thermodynamic pressure $p$ now and the force `Vector` is defined by $\boldsymbol{F}=\rho \boldsymbol{g}$ this time. It is obvious that we obtain a slightly different convective term compared to the incompressible case. That is why the convective `Matrix` $\mathbf{C}^{*}$ of the discrete problem is marked with an asterisk in the following. It is advisible to implement the term as a whole using the edge-based techniques for Euler fluxes mentioned in Section 3.3.4. Nevertheless, a linearized form $U_{l} \frac{\partial u_{k}}{\partial x_{k}}+u_{k} \frac{\partial U_{l}}{\partial x_{k}}$ may be used as well.

With regard to the conservation of mass, a new term appears in the `continuity equation`, namely the temporal derivative of the density

$$
\frac{\partial \rho}{\partial t}+\frac{\partial U_{k}}{\partial x_{k}}=0
$$

In the case of `incompressible flows` the `continuity equation` is formulated in terms of pressure only. Now, however, we have the possibility of choosing either the density or the pressure as unknown of the problem. As our aim is a general approach for incompressible and compressible flows we shall keep the pressure as variable. For formulations using the density as variable, please refer to Vázquez et al. (1999).

In order to replace the density variation by the pressure variation we make use of the relation

$$
\Delta \rho^{n}=\alpha \Delta p^{n}
$$

where $\alpha$ is a function that will be defined according to the type of flow being analyzed. We will see that it is useful to introduce the `Matrix` $\mathbf{M}_{\alpha}$, of components

$$
\mathrm{M}_{\alpha, i j}=\int_{\Omega} \alpha N_{i} N_{j} \mathrm{~d} \Omega
$$

where $N_{i}$ is the shape function associated to the $i$ -th `Node` of the finite Element Mesh with which we assume that all the variables are interpolated. 

\subsubsection{Generalization of the Algorithm}

At this point we make use of the simplifications mentioned in Section $3.2 .1$ that allow us the simulation of compressible flows in subsonic regime without resolving the energy equation. The following types of flow are distinguished in this context:

\textbf{Incompressible flows} are characterized by the equations in Table $3.2$. Hence it is evident that the time variation of the density has to disappear, which directly demands $\alpha=0$.

\textbf{Slightly compressible flows} are approximated using equation (3.16) with a constant value for the speed of sound, so that $\alpha=\frac{1}{c^{2}}$ is chosen.

\textbf{Barotropic flows} only involve density and pressure in the equation of state. Resorting to relation (3.18), we use $\alpha=\frac{\rho^{n}}{\gamma p^{n}}$ where the superscript $n$ indicates the time step. Accordingly, the nodal function value $\alpha$ is calculated at the end of the previous time step.

\textbf{Perfect gases} are not covered in this work as they require the solution of the energy equation. In this case the equation of state is used to link pressure and density, resulting in the choice $\alpha=\frac{1}{R T}$. Furthermore the RHS of the `continuity equation` has to be modified due to the variation in time of the temperature. For detailed information please refer to Vázquez et al. (1999).

$$
\alpha= \begin{cases}0 & \text { for `incompressible flows` } \\ \frac{1}{c^{2}} & \text { for slightly compressible flows } \\ \frac{\rho^{n}}{\gamma p^{n}} & \text { for barotropic flows (isentropic perfect gases) }\end{cases}
$$

\subsubsection{Modified Fractional Step Scheme}

Taking into account the mentioned modifications in the equation system (3.62), the fractional step algorithm for compressible flows can be written in the following form:

$$
\begin{aligned}
\mathbf{M} \frac{1}{\Delta t}\left(\tilde{U}^{n+1}-U^{n}\right)+\mathbf{C}^{*}\left(\tilde{U}^{n+1}\right) \tilde{U}^{n+1}+\gamma \mathbf{G P}^{n} &=\mathrm{F}^{n+1} \\
\mathbf{M}_{\alpha} \frac{\Delta \mathrm{P}^{n}}{\Delta t}+\Delta t \mathbf{L}\left(\mathrm{P}^{n+1}-\gamma \mathbf{P}^{n}\right) &=\mathbf{D} \tilde{u}^{n+1} \\
\mathbf{M} \frac{1}{\Delta t}\left(\mathrm{U}^{n+1}-\tilde{U}^{n+1}\right)+\mathbf{G}\left(\mathrm{P}^{n+1}-\gamma \mathrm{P}^{n}\right) &=0
\end{aligned}
$$

This time we resolve for the fractional momentum $\tilde{U}^{n+1}$ first, followed by the pressure $\mathrm{P}^{n+1}$ and the end-of-step momentum $U^{n+1}$. Finally the density $\rho^{n+1}$ is calculated by equation (3.74) and is used to extract the velocity $\mathrm{u}^{n+1}$ from the end-of-step momentum. Exactly the same stabilization terms as presented in Section 3.4.4 have been used, the fractional momentum replacing the fractional velocity in the compressible case. Just for the purpose of clarity they do not appear in the equations above. 

\subsubsection{General Solving Procedure}

Table $3.5$ gives an overview of the resulting general algorithm that might be used for incompressible flow simulations as well, provided that the freestream Conditions are set accordingly. 



Table 3.5: Solving procedure for compressible and `incompressible flows` 

\subsection{Numerical Examples}

Before preparing the flow solver for the fluid-structure coupling, the implementation shall be validated by numerical results in two and three dimensions. In a first step the focus will be on the verification of the edge-based data structure. Subsequently the implemented algorithm is going to be checked.

\subsubsection{Cube with Quiescent Water}





As the velocity field has been initialized with zero and a no-slip Condition is applied on the whole boundary, convective terms do not account for in the flow equations. The consideration of gravity $\left(g_{y}=-10 \frac{m}{s^{2}}\right)$ allows us to get a first impression of the pressure gradients calculated by the Poisson equation whose correct implementation and whose stability in the stationary regime are revealed by the pressure distribution in Figure $3.3$.





\subsubsection{Airflow around a Cylinder}





Having checked pressure and gravity in a quiescent situation, we will now set the fluid in motion. However, before doing so we will focus one last time on the edge-based data structure that we used for the implementation of the algorithm. In Section 3.3.4 the gradient and the transposed gradient were defined by equations $(3.36)$ and $(3.40)$. A comparison of $g_{i j}$ and $g_{j i}$ revealed that they are linked by a boundary integral due to partial integration (3.41)

$$
g_{i j, k}+g_{i j, k}=\int_{\Gamma} N_{j} N_{i} n_{k} \mathrm{~d} \Gamma
$$

Making use of this property and applying the sum of the two gradients to a constant pressure field of the value 1 has to give the following result:

- zero in the interior of the domain and

- the outward area normal of the faces on the boundary.

We used this test to validate the implementation of the two gradients, which is illustrated in Figure 3.5. Considering the dimensions of the domain, the nodal area normal was calculated by hand, which proved to be congruent with the result of operation $(3.78)$.





By the way, for further calculations area and unit normals have been computed using geometry data of the finite Element Mesh and not using the gradients. 

\textbf{Incompressible Flow}

After a fairly short transitory period the stationary regime is reached in the incompressible case. At this point the upwinding term (first part of the stabilization term) in equation (3.63) becomes important to stabilize the steady state solution.

For the following analysis it is convenient to introduce the pressure coefficient $C_{p}$, a dimensionless number in fluid dynamics to describe the relative pressures throughout a flow field, that is defined as

$$
C_{p}=\frac{p-p_{\infty}}{\frac{1}{2} \rho_{\infty} u_{\infty}^{2}}
$$

where $p$ is the pressure at the point of interest, $p_{\infty}$ the freestream pressure, $\rho_{\infty}$ the fluid density and $u_{\infty}$ the freestream velocity of the fluid. In many situations in aerodynamics and hydrodynamics the pressure coefficient at a point near a body is independent of the body size. Consequently, respecting geometric and fluid flow similarities, an engineering Model can be tested in a wind or water tunnel, pressure coefficients can be determined at critical locations and used with confidence to predict the fluid pressure around a full-size aircraft or boat.

Figure $3.6$ shows a contour fill of the pressure coefficient around the cylinder. We will focus on the values of $C_{p}$ on the boundary, where a slip Condition was applied, as these are known from the analytical solution of the problem. The stagnation point with a theoretical value of $C_{p}=1$ is met perfectly. On the top and at the bottom of the illustrated circle we obtain a slight deviation from $C_{p}=-3$, as well as after the cylinder where the solution is not exactly symmetric $\left(C_{p}<1\right)$. This indicates the numerical dissipation of the algorithm. Nevertheless, the results can be considered as very satisfactory.



(a) Pressure coefficient $C_{p}$ and streamlines



(b) Stagnation point in detail



It shall be remarked that the above results may be obtained either by choosing directly $\alpha=0$ in the solver `Properties` or by setting $M a=0.001$ in the `Python` script for example. 

\textbf{Compressible Flow}

The compressible case has been tested with the freestream `Mach number` $M a_{\infty}=0.3$. In general this value is considered as limit for a flow to be treated still as incompressible. However, in the airflow around the cylinder higher Mach numbers appear locally.

This time the transitory period is much longer due to some oscillations caused by a propagating pressure wave,

- either starting from the inlet if the velcoity is zero in the whole domain at $t=0$,

- or emerging around the cylinder if the velocity field is initialized with the freestream velocity $u_{\infty}$ and its normal component is cut off by the slip Condition.

Both possibilities have been tested; in the latter the relative velocity between wave propagation speed and freestream velocity before the cylinder has been checked.

The reflection of these waves at the boundaries shows that the Conditions there are implemented correctly, so that, in the end, it takes some time until the numerical dissipation of the scheme copes with the mentioned oscillations of this test case. In a real simulation this is generally overcome by enlarging the distance between the object of study and the domain boundaries, characterized by a very fine Mesh for the points of interest and a rather coarse grid at the distant boundary.

In compressible flow, and particularly in high-speed flow, the dynamic pressure $\frac{1}{2} \rho u^{2}$ is no longer an accurate measure of the difference between stagnation pressure and static pressure. Also the familiar relationship that stagnation pressure is equal to total pressure does not always hold true. As a result, pressure coefficients can be greater than one in compressible flow: $C_{p}>1$ indicates that the freestream flow is supersonic $(M a>1)$ implying the presence of shock waves (Wikipedia - The Free Encyclopedia). However, as mentioned in Section 3.2.1, we focus on `isentropic flow of perfect gases` in subsonic regime where the mentioned relations are always true.





$$
p_{0}=p_{\infty}\left(1+\frac{\gamma-1}{2} M a_{\infty}^{2}\right)^{\frac{\gamma}{\gamma-1}}
$$

valid for the stagnation pressure $p_{0}$ in isentropic flow (Candel, 2005), and where the freestream pressure

$$
p_{\infty}=\frac{\rho_{\infty}}{\gamma}\left(\frac{u_{\infty}}{M a_{\infty}}\right)^{2}
$$

is a function of the other freestream parameters - `Mach number`, velocity and density defined at the beginning of the simulation run. The `adiabatic exponent` or ratio of specific heats $\gamma=1.4$ for air. Thus, we finally obtain $p_{0} \approx 1013,7 P a$ which sounds quite good compared with our numerical result $1012.8 P a$. The freestream pressure for comparison writes $p_{\infty} \approx 952.4 P a$.

In Section 3.4.4 we mentioned that several issues related to the uncoupling of velocity and pressure in fractional step schemes still deserve further analysis. One of these was the computed pressure near boundaries and the stability of the pressure itself. Even a slight instability in the pressure values may influence the velocity components severely.

Figure $3.8$ shows a comparison that has been made with two different implementations of the convective term, both in conservative form, which should actually yield the same result. On the left-hand side $(3.8(\mathrm{a}))$ the term has been implemented as a whole whereas on the right-hand (3.8(b)) side two linearized terms have been used. Until now no explanation has been found. Maybe this observation is related to the choice of the advective velocity $a$ and the respective approximations in view of the edge-based data structure that might be critical when the linearization is done.



\subsubsection{NACA 0012 Airfoil}





The freeflow Conditions known from the cylinder test case have been used on the NACA 0012 airfoil that has been inclined by the angle of attack $\alpha=3^{\circ}$. This time as well, a slip Condition has been applied on the airfoil contour. As mentioned above, a very fine Mesh has been created near the `boundary layer` whereas huge cells are employed far away from the airfoil. The grid of approximately $11.500$ Elements is shown in Figure $3.10$.





\textbf{Incompressible Flow}

As the pressure distribution on the contour is responsible for the lift force, the two corresponding dimensionless coefficients $C_{p}$ and $C_{l}$ are linked by an equation

$$
C_{l}=\int_{L E}^{T E}\left(C_{p l}(x)-C_{p u}(x)\right) d x
$$

where $C_{p l}$ and $C_{p u}$ are the pressure coefficients on lower and upper surface respectively, and the abbreviations LE and TE stand for leading and trailing edge of the airfoil. For $M a=0$ the pressure coefficient $C_{p}$ has been computed on the contour of the airfoil, using once more equation $(3.79)$, and was plotted against the relative chord length. The numerical results are compared in Figure $3.11$ with theoretical ones resulting from the potential theory. Apart from the peak in the pressure coefficient on the upper surface $C_{p u}$,





our results fit perfectly with the analytical solution. The slight discrepancy indicates that the Mesh is not fine enough in this region. We can be quite sure of this as we will encounter a similar behaviour in the compressible case where the same Mesh has been used.

A typical contour fill for the pressure coefficient is presented in Figure $3.12$.







(a) Leading edge (b) Trailing edge



\textbf{Compressible Flow}

For $M a=0.3$ the same analysis as in the incompressible case has been made. Analog to the result before, we suspect that the Mesh is not fine enough near the pressure peak and therefore responsible for the slight discrepancy illustrated in Figure $3.14$.





\subsubsection{ONERA M6 Wing}

As we only have treated two-dimensional examples so far, we will demonstrate with the ONERA M6 wing that our algorithm also works in three dimensions. Evidently, this section is characterized by a strong qualitative approach. We mainly wanted to know whether the implemented code is capable of tackling $3 \mathrm{D}$ cases. Figure $3.15$ shows a contour fill of the pressure coefficient in the transitory period. We already can recognize the similarity to Figure $3.12$ of the airfoil. The numerical artifacts in the picture can be traced back to a bug in `GiD`, which has already been corrected in the newest beta version of the software.





We have seen before that a fine Mesh is necessary in order to resolve the `boundary layer` correctly. This means that an adequate simulation of the ONERA wing becomes expensive in terms of computational effort, even for an edge-based implementation. That is why we scheduled the run and the comparison with experimental data of certain cut planes for the summer months, when the code will be completely parallelized and the `CIMNE` cluster will be working hopefully. 



Having implemented and validated the general flow solver so far, this chapter will focus on the preparation of fluid-structure coupling and explain the necessary modifications in order to perform `FSI` simulations in the end.

First the principal solving procedures for coupled problems are elucidated.

Subsequently, the arbitrary `Lagrangian-Eulerian` description is derived from the classical kinematical viewpoints and its effect on the conservation equations of mass, momentum and energy is shown.

After some preliminary tests with moving Meshes and the respective calculation of interface displacements and forces, expectations for the real fluid-structure coupling are presented.


\section{Preparation of Fluid-Structure Coupling}

\subsection{Solving Procedures for Coupled Problems}

There are several techniques for solving multi-disciplinary problems. Finding a suitable approach for each case highly depends on the category of the problem and the details of each field, especially for time-dependant problems. Concerning `FSI` this means that, depending on the nature of the fluid as well as on the `Properties` of the structure, the characteristics of the coupling can be quite different. In this section an overview of `Kratos`' solving methodologies is given according to Dadvand (2007).

\subsubsection{Sequential Solution}

Considering the `one-way` coupled problem of Figure $2.2$, the solving procedure is trivial. Since only the subsystem $S_{2}$ depends on $u_{1}$ (the solution of $\left.S_{1}\right)$, the problem can be solved easily by tackling the subsystem $S_{1}$ first to determine its solution $u_{1}$, which is used in turn to solve $S_{2}$. The in Figure $4.1$ represented course of action is evaluated at each time step for transient problems. 





Being $\mathcal{L}_{i}$ the operator applied over the domain of the respective subsystem $S_{i}$, the governing equations for the illustrated `one-way` coupled system can be written as

$$
\begin{aligned}
\mathcal{L}_{1}\left(u_{1}, t\right) &=f_{1}(t), \\
\mathcal{L}_{2}\left(u_{1}, u_{2}, t\right) &=f_{2}(t)
\end{aligned}
$$

Having applied temporal and spatial discretization within the scope of the finite Element method, the following `Matrix` system has to be solved at each time step:

$$
\left[\begin{array}{cc}
\mathbf{K}_{11} & \mathbf{0} \\
\mathbf{K}_{21} & \mathbf{K}_{22}
\end{array}\right]\left\{\begin{array}{l}
\mathrm{U}_{1} \\
\mathrm{U}_{2}
\end{array}\right\}=\left\{\begin{array}{l}
\mathrm{f}_{1}(\mathrm{t}) \\
\mathrm{f}_{2}(\mathrm{t})
\end{array}\right\}
$$

where $\mathbf{K}_{11}$ and $\mathbf{K}_{22}$ are the system matrices corresponding to the field variables of subsystems $S_{1}$ and $S_{2}$ respectively, and $\mathbf{K}_{21}$ represents the field system `Matrix` corresponding to the interaction variables.

However, this rather easy approach called `sequential solution` is not possible for strongly coupled problems as shown in Figure $2.3$. In this case either a `monolithic approach` or a staggered method has to be applied.

\subsubsection{Monolithic Approach}

By contrast, the `monolithic approach` treats the multi-disciplinary problem as a whole. The interacting fields are Modeled together resulting in a coupled continuous Model, which is solved directly in one step. Figure $4.2$ illustrates this procedure assuming that there are only two subsystems.





Using the same notation as above, the governing equations for the now considered `two-way` coupled system can be written as

$$
\begin{aligned}
&\mathcal{L}_{1}\left(u_{1}, u_{2}, t\right)=f_{1}(t), \\
&\mathcal{L}_{2}\left(u_{1}, u_{2}, t\right)=f_{2}(t)
\end{aligned}
$$

After temporal and spatial discretization the following `Matrix` system is obtained not allowing a `sequential solution` any more:

$$
\left[\begin{array}{ll}
\mathbf{K}_{11} & \mathbf{K}_{12} \\
\mathbf{K}_{21} & \mathbf{K}_{22}
\end{array}\right]\left\{\begin{array}{l}
U_{1} \\
U_{2}
\end{array}\right\}=\left\{\begin{array}{l}
f_{1}(t) \\
f_{2}(t)
\end{array}\right\}
$$

This time the interaction matrices $\mathbf{K}_{12}$ and $\mathbf{K}_{21}$ couple the field variables of the two subsystems in a manner that demands the problem to be solved at once.

Though this approach seems to be very easy and natural, several difficulties are encountered in practice:

- difficulty of the formulation: The multi-disciplinary continuous Models are usually complex by nature making the discretization process a tedious task.

- size and bandwidth of the problem: The obligation of solving all fields simultaneously renders the `monolithic approach` expensive in terms of memory and cpu performance.

- implementation cost: The interaction between different fields requires the interface matrices to be customized to reflect the new variables. As generally severe modifications are part of this adaptation, a re-use of these matrices is nearly impossible.

Despite all mentioned disadvantages, one should not forget that a `monolithic approach` perfectly Models the interaction between the different fields and results in a more robust and more stable formulation for solving coupled problems.

\subsubsection{Staggered Methods}

The intention of `staggered methods` is to solve each field separately and thus use less resources than the `monolithic approach`. In each step only one part of the problem is solved, which is a great advantage in the solution of large problems. The interaction is assured by applying certain techniques for transforming variables from one field to another. Some of these techniques are outlined here:

Predicition consists of predicting the value of the dependent variables in the next time step. As shown in Figure $4.3(\mathrm{a})$ the predicted variable $u_{2 P}^{n+1}$ is used to solve the subsystem $S_{1}$ separately, which decouples different fields in problems with strong coupling. Common choices are:

- the last-solution predictor: $u_{p}^{n+1}=u^{n}$

- or prediction by solution gradient: $u_{p}^{n+1}=u^{n}+\Delta t \cdot \dot{u}^{n}$

where $\Delta t=t^{n+1}-t^{n}$ and $\dot{u}^{n}=\left(\frac{\partial u}{\partial t}\right)^{n}$.

Advancing means calculating the next time step of a subsystem using the calculated or predicted solution of other subsystems. This technique is illustrated in Figure $4.3(\mathrm{~b})$.

Substitution is a trivial technique shown in Figure 4.3(c) that uses the calculated value of one field in another field to solve it separately. Correction substitutes $u_{2}^{n+1}$ in place of the predicted value $u_{2 p}^{n+1}$ and solves again the subsystem $S_{1}$ to obtain a better result. This implies that the subsystem $S_{1}$ has been solved introducing the predicted value $u_{2 p}^{n+1}$ and that the here obtained result $u_{2}^{n+1}$ has been used to advance in turn subsystem $S_{2}$ in order to calculate $u_{2}^{n+1}$. Obviously this procedure shown in Figure $4.3(\mathrm{~d})$ can be repeated more than once.





A staggered method can be planned using the techniques presented above. Returning to the problem of Figure $2.3$, the following course of action, illustrated in Figure 4.4, would be possible:

1. Predicition: $u_{p}^{n+1}=u_{2}^{n}+\Delta t \cdot \dot{u}_{2}^{n}$

2. Advancing: $S_{1}^{n+1}\left(u_{p}^{n+1}\right) \rightarrow u_{1}^{n+1}$

3. Substitution: $u_{1}^{n+1}=u_{1}^{n+1}$ for $S_{2}$

4. Advancing: $S_{2}^{n+1}\left(u_{1}^{n+1}\right) \rightarrow u_{2}^{n+1}$

As one may guess, `staggered methods` require a careful formulation to avoid instabilities and to obtain an accurate solution, thus increasing the attention concerning Modeling. Nevertheless there are some important advantages:

- The definition of different discretizations for each field is possible, with varying Mesh characteristics if necessary. 





- Existing single field codes may be re-used for solving multi-disciplinary problems almost without modification.

- Solving only one part of the problem does not only use less resources compared to monolithic schemes; it also comes up with the idea of segmenting the solving procedure for large single field problems and scheduling the algorithm in parallel.

\subsection{Arbitrary Lagrangian-Eulerian Description}

The numerical simulation of multi-dimensional problems in fluid dynamics and nonlinear solid mechanics often requires coping with strong distortions of the continuum under consideration while simultaneously assuring a clear delineation of free surfaces and fluid-fluid, solid-solid or fluid-structure interfaces. To deal with large distortions and to provide an accurate resolution of material interfaces and mobile boundaries, an appropriate kinematical description is fundamental.

The arbitrary Lagrangian-Eulerian (`ALE`) description was developed in an attempt to combine the advantages of the classical kinematical descriptions while minimizing their respective drawbacks as far as possible. This is the reason why this chapter starts with a brief reminder of the classical approaches: the Lagrangian and the Eulerian point of view (Donea et al., 2004; Adams, 2007).

\subsubsection{Lagrangian vs. Eulerian Description}

Describing a continuum in motion, there are two primary ways of doing so. The first one is to pick a specific particle, denoted as fluid Element $\boldsymbol{F E}$ in Figure $4.5$, and to follow its movement $\boldsymbol{\xi}\left(t, \boldsymbol{\xi}_{0}\right)$ in the course of time. Observer $\boldsymbol{A}$ in Figure $4.5(\mathrm{a})$ represents this Lagrangian viewpoint. Observer $\boldsymbol{B}$ however is situated in a fixed position $\boldsymbol{x}$ of the spatial domain. From his Eulerian point of view he monitors the different fluid Elements passing by, $\boldsymbol{\xi}_{0}$ and $\boldsymbol{\xi}_{\mathbf{0}}^{\prime}$ in Figure $4.5(\mathrm{~b})$. 



In `Lagrangian algorithms` - mainly used in structural mechanics - each individual `Node` of the computational Mesh follows the associated material particle during motion as shown in the upper part of Figure 4.6. Obviously, this facilitates the tracking of free surfaces and of interfaces between different materials. Moreover, materials with history-dependent constitutive relations can be treated easily since each finite Element of a Lagrangian Mesh always contains the same material particles. Its weakness is its inability to follow large distortions of the computational domain without recourse to frequent reMeshing operations.

In `Eulerian algorithms` - widely used in fluid dynamics $-$ the computational Mesh is fixed and the continuum moves with respect to the grid. As time evolves, the physical quantities associated with the fluid particles passing through the fixed region of space, are examined. This implies a relatively easy handling of large distortions in the continuum motion. However, interface definitions and the resolution of flow details are generally less precise.

\subsubsection{`ALE` - Generalization of both Approaches}

Since the `ALE` description of motion is a generalization of the Lagrangian and Eulerian descriptions, the `Nodes` of the computational Mesh may be

- moved with the continuum in normal Lagrangian fashion,

- held fixed in Eulerian manner or

- moved in some arbitrarily specified way as shown in Figure $4.6$

to give a continuous rezoning capability.

In the `ALE` description of motion that will be derived now according to Donea et al. (2004), neither the material domain $R_{X}$ made up of material particles $\boldsymbol{X}$ nor the spatial domain $R_{\boldsymbol{x}}$ consisting of spatial points $\boldsymbol{x}$ is taken as a reference. Instead a third domain is introduced: the referential configuration $R_{\chi}$ with reference coordinates $\chi$ identifying the grid points. Figure $4.7$ shows these domains and the one-to-one transformations relating the configurations. The referential domain $R_{\chi}$ is mapped into the material and spatial 




domains by $\Phi$ and $\Psi$ respectively. The particle motion $\varphi$ may then be expressed as $\varphi=\boldsymbol{\Phi} \circ \boldsymbol{\Psi}^{-1}$, clearly showing the dependency of the three mappings:

- The application $\varphi$ represents the mapping from the material domain $R_{\boldsymbol{X}}$ to the spatial domain $R_{\boldsymbol{x}}$, relating the motion of the material points $\boldsymbol{X}$ to the spatial coordinates $\boldsymbol{x}$. It is defined such that

$$
\begin{aligned}
\boldsymbol{\varphi}: R_{\boldsymbol{X}} \times\left[t_{0}, t_{\text {end }}[\right.& \longrightarrow R_{\boldsymbol{x}} \times\left[t_{0}, t_{\text {end }}[\right.\\
(\boldsymbol{X}, t) & \longmapsto \boldsymbol{\varphi}(\boldsymbol{X}, t)=(\boldsymbol{x}, t)
\end{aligned}
$$

which allows us to link $\boldsymbol{X}$ and $\boldsymbol{x}$ in time by the law of motion, namely

$$
\boldsymbol{x}=\boldsymbol{x}(\boldsymbol{X}, t)
$$

The physical time is measured by the same variable $t$ in both domains so that for every fixed instant $t$, the mapping $\varphi$ defines a configuration in the spatial domain. It is convenient to employ a `Matrix` representation for its gradient

$$
\frac{\partial \boldsymbol{\varphi}}{\partial(\boldsymbol{X}, t)}=\left(\begin{array}{cc}
\frac{\partial \boldsymbol{x}}{\partial \boldsymbol{X}} & \boldsymbol{u} \\
\mathbf{0}^{T} & 1
\end{array}\right)
$$







where $\mathbf{0}^{T}$ is a null row-`Vector` and the material velocity $\boldsymbol{u}$ is

$$
\boldsymbol{u}(\boldsymbol{X}, t)=\left.\frac{\partial \boldsymbol{x}}{\partial t}\right|_{\boldsymbol{X}}
$$

with $\left.\right|_{\boldsymbol{X}}$ indicating that the respective coordinate, material in this case, is hold fixed.

- The mapping of $\boldsymbol{\Phi}$ from the referential domain $R_{\chi}$ to the spatial domain $R_{x}$ can be understood as the motion of the grid points in the spatial domain. It is represented by

$$
\begin{aligned}
\Phi: R_{\Psi} \times\left[t_{0}, t_{\text {end }}[\right.& \longrightarrow R_{\boldsymbol{x}} \times\left[t_{0}, t_{\text {end }}[\right.\\
(\boldsymbol{\chi}, t) & \longmapsto \boldsymbol{\Phi}(\boldsymbol{\chi}, t)=(\boldsymbol{x}, t)
\end{aligned}
$$

and its gradient is

$$
\frac{\partial \boldsymbol{\Phi}}{\partial(\boldsymbol{\chi}, t)}=\left(\begin{array}{cc}
\frac{\partial \boldsymbol{x}}{\partial \boldsymbol{\chi}} & \boldsymbol{u}_{\text {Mesh }} \\
\mathbf{0}^{T} & 1
\end{array}\right)
$$

where now, the Mesh velocity

$$
\boldsymbol{u}_{\operatorname{Mesh}}(\boldsymbol{\chi}, t)=\left.\frac{\partial \boldsymbol{x}}{\partial t}\right|_{\chi}
$$

is involved. Note that both the material and the Mesh move with respect to the laboratory. Thus, the corresponding material and Mesh velocities have been defined by deriving the equations of material motion and Mesh motion in each case with respect to time.

- Finally, regarding the mapping of $\Psi$ from the referential domain $R_{\chi}$ to the material domain $R_{\boldsymbol{X}}$, it is more convenient to represent directly its inverse $\boldsymbol{\Psi}^{-1}$

$$
\begin{aligned}
\Psi^{-1}: R_{X} \times\left[t_{0}, t_{e n d}[\right.& \longrightarrow R_{\chi} \times\left[t_{0}, t_{e n d}[\right.\\
(\boldsymbol{X}, t) & \longmapsto \Psi^{-1}(\boldsymbol{X}, t)=(\chi, t)
\end{aligned}
$$

and its gradient is

$$
\frac{\partial \boldsymbol{\Psi}^{-1}}{\partial(\boldsymbol{X}, t)}=\left(\begin{array}{cc}
\frac{\partial \boldsymbol{\chi}}{\partial \boldsymbol{X}} & \boldsymbol{u}_{r e f} \\
\mathbf{0}^{T} & 1
\end{array}\right)
$$

where the velocity $\boldsymbol{u}_{r e f}$ is defined as

$$
\boldsymbol{u}_{r e f}=\left.\frac{\partial \boldsymbol{\chi}}{\partial t}\right|_{\boldsymbol{X}}
$$

It can be interpreted as the particle velocity in the referential domain since it measures the time variation of the referential coordinate $\chi$ holding the material particle $\boldsymbol{X}$ fixed.

The relation between the velocities $\boldsymbol{u}, \boldsymbol{u}_{\text {Mesh }}$ and $\boldsymbol{u}_{\text {ref }}$ can be obtained by differentiating the relation $\varphi=\boldsymbol{\Phi} \circ \boldsymbol{\Psi}^{-1}$

$$
\begin{aligned}
\frac{\partial \boldsymbol{\varphi}}{\partial(\boldsymbol{X}, t)}(\boldsymbol{X}, t) &=\frac{\partial \boldsymbol{\Phi}}{\partial\left(R_{\boldsymbol{\chi}}, t\right)}\left(\boldsymbol{\Psi}^{-1}(\boldsymbol{X}, t)\right) \quad \frac{\partial \boldsymbol{\Psi}^{-1}}{\partial(\boldsymbol{X}, t)}(\boldsymbol{X}, t) \\
&=\frac{\partial \boldsymbol{\Phi}}{\partial\left(R_{\boldsymbol{\chi}}, t\right)}(\boldsymbol{\chi}, t) \quad \frac{\partial \boldsymbol{\Psi}^{-1}}{\partial(\boldsymbol{X}, t)}(\boldsymbol{X}, t)
\end{aligned}
$$

or, in `Matrix` format,

$$
\left(\begin{array}{cc}
\frac{\partial \boldsymbol{x}}{\partial \boldsymbol{X}} & \boldsymbol{u} \\
\mathbf{0}^{T} & 1
\end{array}\right)=\left(\begin{array}{cc}
\frac{\partial \boldsymbol{x}}{\partial \boldsymbol{\chi}} & \boldsymbol{u}_{\operatorname{Mesh}} \\
\mathbf{0}^{T} & 1
\end{array}\right)\left(\begin{array}{cc}
\frac{\partial \boldsymbol{\chi}}{\partial \boldsymbol{X}} & \boldsymbol{u}_{r e f} \\
\mathbf{0}^{T} & 1
\end{array}\right)
$$

which yields, after block multiplication, $\boldsymbol{u}=\boldsymbol{u}_{\text {Mesh }}+\frac{\partial \boldsymbol{x}}{\partial \boldsymbol{\chi}} \cdot \boldsymbol{u}_{r e f} .$ Introducing the convective velocity $\boldsymbol{u}_{\text {conv }}$ as the relative velocity between material and Mesh, this equation can be rewritten as

$$
\boldsymbol{u}_{\operatorname{conv}}:=\boldsymbol{u}-\boldsymbol{u}_{m e s h}=\frac{\partial \boldsymbol{x}}{\partial \boldsymbol{\chi}} \cdot \boldsymbol{u}_{r e f}
$$

The convective velocity can be interpreted as the particle velocity relative to the Mesh as seen from the spatial domain $R_{\boldsymbol{x}}$.

Note that both Lagrangian and Eulerian formulations may be obtained as particular cases of this generalized approach: - Choosing $\boldsymbol{\Psi}=\boldsymbol{I}$ (where $\boldsymbol{I}$ is the identity application), referential domain $R_{\chi}$ and material domain $R_{\boldsymbol{X}}$ coincide $(\boldsymbol{\chi} \equiv \boldsymbol{X})$ resulting in a Lagrangian description. Material and Mesh velocity, equations $(4.8)$ and $(4.11)$, are equal leading to a convective velocity of zero (see equation (4.16)) and thus preventing the presence of convective terms in the conservation laws.

- With the choice of $\boldsymbol{\Phi}=\boldsymbol{I}$ on the other hand, referential domain $R_{\chi}$ and spatial domain $R_{\boldsymbol{x}}$ coincide $(\boldsymbol{\chi} \equiv \boldsymbol{x})$ conducting to an Eulerian description. The Mesh velocity $\boldsymbol{u}_{\text {Mesh }}$ obtained from equation $(4.11)$ is zero whereas the convective velocity $\boldsymbol{u}_{\text {conv }}$ is identical to the material velocity $\boldsymbol{u}$.

\subsubsection{`ALE` Form of Conservation Equations}

In order to express the conservation laws for mass, momentum and energy in an `ALE` framework, a relation between the material (or total) time derivative, which is inherent in conservation laws, and the referential time derivative is needed.

\textbf{Fundamental `ALE` Relation}

Therefore a scalar physical quantity, denoted by $f(\boldsymbol{x}, t), f^{*}(\boldsymbol{\chi}, t)$ and $f^{* *}(\boldsymbol{X}, t)$ in the spatial, referential and material domain respetively, is considered in the following. Using the mapping `Properties` of $\Psi$, the transformation from the referential description $f^{*}(\boldsymbol{\chi}, t)$ of the scalar physical quantity to its material description $f^{* *}(\boldsymbol{X}, t)$ is cast as

$$
f^{* *}=f^{*} \circ \boldsymbol{\Psi}^{-1}
$$

or

$$
f^{* *}(\boldsymbol{X}, t)=f\left(\boldsymbol{\Psi}^{-1}(\boldsymbol{X}, t), t\right)
$$

The gradient of this expression can be computed as

$$
\frac{\partial f^{* *}}{\partial(\boldsymbol{X}, t)}(\boldsymbol{X}, t)=\frac{\partial f^{*}}{\partial(\boldsymbol{\chi}, t)}(\boldsymbol{\chi}, t) \quad \frac{\partial \boldsymbol{\Psi}^{-1}}{\partial(\boldsymbol{X}, t)}(\boldsymbol{X}, t)
$$

which is amenable to the `Matrix` form

$$
\left(\begin{array}{ll}
\frac{\partial f^{* *}}{\partial \boldsymbol{X}} & \frac{\partial f^{* *}}{\partial t}
\end{array}\right)=\left(\begin{array}{cc}
\frac{\partial f^{*}}{\partial \boldsymbol{\chi}} & \frac{\partial f^{*}}{\partial t}
\end{array}\right)\left(\begin{array}{cc}
\frac{\partial \boldsymbol{\chi}}{\partial \boldsymbol{X}} & \boldsymbol{u}_{r e f} \\
\mathbf{0}^{T} & 1
\end{array}\right)
$$

Apart from the obvious statement $\frac{\partial f^{* *}}{\partial \boldsymbol{X}}=\frac{\partial f^{*}}{\partial \chi} \frac{\partial \chi}{\partial \boldsymbol{X}}$, block multiplication also arouses the desired relation between material and spatial time derivatives:

$$
\frac{\partial f^{* *}}{\partial t}=\frac{\partial f^{*}}{\partial t}+\frac{\partial f^{*}}{\partial \boldsymbol{\chi}} \cdot \boldsymbol{u}_{r e f}
$$

Taking into account that, in fluids, constitutive relations are naturally expressed in the spatial configuration and the `Cauchy` stress tensor is the natural measure for stresses, it is more convenient to rearrange the previous equation. Using equation (4.16) the gradient of the considered quantity is evaluated in the spatial domain instead of the referential one:

$$
\frac{\partial f^{* *}}{\partial t}=\frac{\partial f^{*}}{\partial t}+\frac{\partial f}{\partial \boldsymbol{x}} \cdot \boldsymbol{u}_{\operatorname{conv}}
$$

Dropping the stars, reveals the fundamental $A L E$ relation in the end:

$$
\begin{aligned}
\left.\frac{\partial f}{\partial t}\right|_{\boldsymbol{X}} &=\left.\frac{\partial f}{\partial t}\right|_{\boldsymbol{\chi}}+\frac{\partial f}{\partial \boldsymbol{x}} \cdot \boldsymbol{u}_{\operatorname{con} v} \\
&=\left.\frac{\partial f}{\partial t}\right|_{\boldsymbol{\chi}}+\boldsymbol{u}_{\operatorname{conv}} \cdot \boldsymbol{\nabla} f
\end{aligned}
$$

It shows that the time derivative of the physical quantity $f$ for a given particle $\boldsymbol{X}$, its material derivative, can be expressed as the sum of its local derivative (with the reference coordinate $\chi$ held fixed) and a convective term considering the relative velocity $\boldsymbol{u}_{\text {conv }}$ between the material and the reference system.

\textbf{Basic Conservation Equations}

In order to obtain the `ALE` form of the conservation equations presented in Chapter 3 , the material velocity $\boldsymbol{u}$ has to be replaced by exactly this convective velocity $\boldsymbol{u}_{\text {conv }}-$ defined by equation $(4.16)$ - in the various convective terms. For convenience and to establish the link to the notation chosen in Section $3.2$, the material time derivative is further denoted as

$$
\frac{d}{d t}:=\left.\frac{\partial}{\partial t}\right|_{\boldsymbol{X}}
$$

and the spatial time derivative as

$$
\frac{\partial}{\partial t}:=\left.\frac{\partial}{\partial t}\right|_{\boldsymbol{x}}
$$

Recalling the conservation equations for mass $(3.4 \mathrm{~b})$ and momentum (3.10b) in terms of the total time derivative

$$
\begin{aligned}
\frac{d \rho}{d t} &=\left.\frac{\partial \rho}{\partial t}\right|_{\boldsymbol{x}}+\boldsymbol{u} \cdot \boldsymbol{\nabla} \rho=-\rho \boldsymbol{\nabla} \cdot \boldsymbol{u} \\
\rho \frac{d \boldsymbol{u}}{d t} &=\rho\left(\left.\frac{\partial \boldsymbol{u}}{\partial t}\right|_{\boldsymbol{x}}+(\boldsymbol{u} \cdot \boldsymbol{\nabla}) \boldsymbol{u}\right)=\boldsymbol{\nabla} \cdot \boldsymbol{\sigma}+\rho \boldsymbol{g}
\end{aligned}
$$

$$
\begin{aligned}
&\text { (mass) } \\
&\text { (momentum) }
\end{aligned}
$$

and introducing the convective velocity $\boldsymbol{u}_{\text {conv }}$ leads to the `ALE` differential forms:

$$
\begin{aligned}
\frac{d \rho}{d t} &=\left.\frac{\partial \rho}{\partial t}\right|_{\chi}+u_{\operatorname{con} v} \cdot \nabla \rho=-\rho \boldsymbol{\nabla} \cdot \boldsymbol{u} & & \text { (mass) } \\
\rho \frac{d \boldsymbol{u}}{d t} &=\rho\left(\left.\frac{\partial \boldsymbol{u}}{\partial t}\right|_{\boldsymbol{\chi}}+\left(\boldsymbol{u}_{\boldsymbol{c o n} \boldsymbol{v}} \cdot \boldsymbol{\nabla}\right) \boldsymbol{u}\right)=\boldsymbol{\nabla} \cdot \boldsymbol{\sigma}+\rho \boldsymbol{g} & & \text { (momentum) }
\end{aligned}
$$

It is important to note that the right-hand side of equations $(4.24)$ is written in classical spatial form, so to speak Eulerian, whereas the arbitrary motion of the computational Mesh is only reflected on the left-hand side. For our implementation in particular, this means that the advective velocity has to be set to $\boldsymbol{a}_{A L E}:=\boldsymbol{a}-\boldsymbol{u}_{\text {Mesh }}$.

For the `ALE` form of the conservation equations for energy (total respectively internal), please refer to Donea et al. (2004).

Furthermore, one has to bear in mind that the Mesh motion may increase or decrease the convection effects. Due to the already mentioned lack of stability of the standard `Galerkin` formulation in convection-dominated situations, these might influence the employed stabilization technique described in Section 3.4.4.

\textbf{Boundary Conditions}

In fact, boundary Conditions are related to the problem, not to the description employed. Thus, the same boundary Conditions as in Eulerian and Lagrangian descriptions are used. As the `ALE` formulation allows an accurate treatment of material surfaces, the following two Conditions are required on a material surface:

- no particles can cross it and

- stresses must be continuous across the surface (if a net force is applied to a surface of zero mass, the acceleration is infinite).

In the case of fluid-structure interaction the particle velocity along solid-wall boundaries is coupled to the rigid or flexible structure. The enforcement of the kinematic requirement that no particle can cross the interface writes

$$
\boldsymbol{u}_{r e f} \cdot \boldsymbol{n}=0 \quad \text { or } \quad \boldsymbol{u} \cdot \boldsymbol{n}=\boldsymbol{u}_{\text {Mesh }} \cdot \boldsymbol{n}
$$

where $\boldsymbol{n}$ indicates once more the outward unit normal.

However, due to the coupling between fluid and structure, extra Conditions are needed to ensure that the fluid and structural domains will not detach or overlap during the motion. These coupling Conditions depend on the fluid. An inviscid fluid, as no shear effects are considered, is free to slip along the structural interface. That is why only normal components are taken into account for the coupling:

$$
\begin{aligned}
\boldsymbol{d} \cdot \boldsymbol{n} &=\boldsymbol{d}_{\text {struct }} \cdot \boldsymbol{n} & \text { (continuity of normal displacements) } \\
\boldsymbol{u} \cdot \boldsymbol{n} &=\boldsymbol{u}_{\text {struct }} \cdot \boldsymbol{n} & \text { (continuity of normal velocities) }
\end{aligned}
$$

Apart from these kinematical Conditions, the dynamic Condition claiming stresses in the fluid and stresses in the structure to be equal has to be verified:

$$
-p \boldsymbol{n}=\boldsymbol{\sigma}_{\text {struct }} \cdot \boldsymbol{n} \quad \text { (equality of stresses) }
$$

For the respective interface Conditions of viscous fluids, e.g. in the aim of facilitating a future expansion of the implemented application, please refer to Donea et al. (2004) where they are outlined as well. 

\subsection{Preliminary Tests}

In this section we will perform some "quasi" `FSI` simulations. This means that we perform tests on moving Meshes whose motion is defined by algebraic functions and not by the coupling with a structural application.

As we prescribe the motion of the grid points by an algebraic function, it seems logical to calculate the Mesh velocity $\boldsymbol{u}_{\text {Mesh }}$ by

$$
\boldsymbol{u}_{\operatorname{Mesh}}^{n+\frac{1}{2}}=\frac{\boldsymbol{x}^{n+1}-\boldsymbol{x}^{n}}{t^{n+1}-t^{n}}
$$

where $\boldsymbol{x}^{n}$ and $\boldsymbol{x}^{n+1}$ are the nodal position `Vector`s at time level $n$ and $n+1$ respectively. Nevertheless, we calculate $\boldsymbol{u}_{\text {Mesh }}$ by the bias of the nodal displacements

$$
\boldsymbol{u}_{m e s h}^{n+\frac{1}{2}}=\frac{d^{n+1}-\boldsymbol{d}^{n}}{t^{n+1}-t^{n}}
$$

where $\boldsymbol{d}^{n}=\boldsymbol{x}^{n}-\boldsymbol{x}^{0}$ refers to the initial geometry, because this is the way we will have to do it once the flow solver is coupled with a structural application.

Moreover, a moving Mesh implies changes of the geometry data of its Elements. This means that the edge data has to be recomputed by the function `MatrixContainer`. `BuildCSRData` whenever the grid points change their position. Certainly, this causes the edge-based implementation to lose its advantage of pre-computing integral data in weakly coupled problems where one iteration between flow and structural solver is sufficient. In problems with strong coupling however, it absolutely makes sense as many iterations between the two solvers will be necessary until the convergence of the solution within a specific time step is reached.

\subsubsection{Geometric Conservation Law}

A very common test in this context is the geometric conservation law for unsteady flow computations on moving and deforming finite Element or finite volume grids.

The basic requirement is that any `ALE` computational method should be able to predict exactly the trivial solution of a uniform flow. The `ALE` equation of mass balance $(4.24 \mathrm{a})$ is usually taken as the starting point for the derivation of the geoemtric conservation law. The `Reynolds transport theorem` is used once again, this time applied to an arbitrary volume $V_{m}(t)$ whose boundary $A_{m}(t)=\partial V_{m}(t)$ moves with the Mesh velocity $\boldsymbol{u}_{\text {Mesh }}$ :

$$
\left.\frac{\partial}{\partial t}\right|_{\chi} \int_{V_{m}(t)} f(\boldsymbol{x}, t) d V=\left.\int_{V_{m}(t)} \frac{\partial f(\boldsymbol{x}, t)}{\partial t}\right|_{\boldsymbol{x}} d V+\int_{A_{m}(t)} f(\boldsymbol{x}, t) \boldsymbol{u}_{m e s h} \cdot \boldsymbol{n} d A
$$

where, in this case, we have explicitly indicated that the time derivative in the first term of the right-hand side is a spatial time derivative, as in expression (3.2). Replacing the scalar $f(\boldsymbol{x}, t)$ by the fluid density $\rho$ and substituting the spatial time derivative $\partial f / \partial t$ with expression (4.24a) leads to the `ALE` integral form of the mass conservation equation:

$$
\left.\frac{\partial}{\partial t}\right|_{\chi} \int_{V_{m}(t)} \rho d V+\int_{A_{m}(t)} \rho \boldsymbol{u}_{\operatorname{con} v} \cdot \boldsymbol{n} d A=0
$$

Assuming uniform fields of density $\rho$ and material velocity $\boldsymbol{u}$, it reduces to the continuous geometric conservation law (CGL)

$$
\left.\frac{\partial}{\partial t}\right|_{\chi} \int_{V_{m}(t)} d V+\int_{A_{m}(t)} \boldsymbol{u}_{\text {Mesh }} \cdot \boldsymbol{n} d A=0
$$

that can also be derived from the `ALE` integral conservation law for momentum and energy.

The mock-up illustarted in Figure $4.8$ has been choosen to check the GCL stated by equation (4.30). In both cases, either with an initialized velocity field or starting from





zero, the trivial solution of a uniform flow results. Figure $4.9$ shows the two extreme positions of the Mesh.

Integrating equation $(4.30)$ in time from $t^{n}$ to $t^{n+1}$ renders the discrete geometric conservation law (DCGL)

$$
\left|\Omega_{\text {elem }}^{n+1}\right|-\left|\Omega_{\text {elem }}^{n}\right|=\int_{t^{n}}^{t^{n+1}}\left(\int_{A_{m}(t)} \boldsymbol{u}_{\text {Mesh }} \cdot \boldsymbol{n} d A\right) d t
$$

which states that the change in volume (or area in 2D) of each Element from $t^{n}$ to $t^{n+1}$ must be equal to the volume (area respectively) swept by the Element boundary during the time interval. Assuming that the volumes $\Omega_{\text {elem }}$ on the left-hand side of equation (4.31) can be computed exactly, this amounts to requiring the exact computation of the flux on the right-hand side as well. This poses some restrictions on the update procedure for grid position and velocity. Especially in the case of `FSI` problems, where Mesh motion is 





coupled with structural deformation, the intuitive formula for the computation of the Mesh velocity (4.27a) is violated in some instances.

It shall be stated here that the practical significance of DGCLs is a debated issue in literature and even in current research the link between DGCLs and the stability (and accuracy) of `ALE` schemes is still a controversial topic (Donea et al., 2004).

\subsubsection{Implementation of Boundary Conditions}

For the GCL test case above the implementation of slip respectively no-slip condtions was not affected as the movement of the walls was in a direction orthogonal to the fluid velocity. In the next example we will break up this orthogonality by prescribing the function

$$
y(x, t)=\left(1+\frac{1}{4} \sin \left(\frac{2 \pi t}{T}\right) \cos \left(\frac{2 \pi x}{L}\right)\right) y_{0}
$$

for the nodal positions of the grid points instead. $x$ and $y$ are the nodal coordinates, $L$ is the constant length of the domain and $t$ and $T$ are the simulation time and the duration of one period respectively. Figure $4.10$ demonstrates the periodic effect of equation $(4.32)$ on the Mesh.




$$
\boldsymbol{u}_{D}= \begin{cases}\boldsymbol{u}_{\text {Mesh }} & \text { for no-slip Conditions } \\ \left(\boldsymbol{u}-\boldsymbol{u}_{\text {Mesh }}\right)-\left(\boldsymbol{u}-\boldsymbol{u}_{\text {Mesh }}\right) \cdot \boldsymbol{n} & \text { for slip Conditions }\end{cases}
$$

Figure $4.11$ shows the velocity `Vector`s for the two extreme situations of the periodic cycle $4.10$ when equation (4.33) is taken into consideration. Whereas the orientation of the velocity `Vector`s follows the boundary movement, their length - indicating the module of the nodal velocities - reflect the equation of continuity, that is to say the conservation of mass.




\subsubsection{Interface Variables}

So far we only considered the consequences of a moving Mesh in terms of nodal displacement (we already mentioned how to calculate `Mesh_VELOCITY` from the `Kratos` variables DISPLACEMENT), that is to say the result of a structural deformation on the fluid flow. However, to perform a correct fluid-structure coupling, the reverse has to be taken into account as well. Hence, the force by the fluid flow acting upon the boundary has to be computed and transmitted to the structural application.

In this context, we can re-use a function defined in step 1 of the implemented algorithm: CalculateRHS sums up the right-hand side contributions of equation (3.77a) and may be employed, now with the end-of-step values for velocity $\boldsymbol{u}$, density $\rho$ and pressure $p$, to compute the resulting force on the structure. This one is stored in the `Kratos` variable FORCE so that the structural application can use it in turn.

In addition, the interface has to be marked as such during the pre-processing. This is effectuated by the `Kratos` variable IS_INTERFACE which is delivered to the compressible fluid application by the respective `problemtype`. It takes the flag value 1 for fluid-structure interfaces and 0 elsewhere.

\subsection{Expectations}

Now that the interface variables between structural and flow applications have been defined, everything should be ready for the coupling process. Unfortunately, no coupled `FSI` simulations could be performed up to now owing to temporal restrictions. Yet we will make up for this in the following weeks and months.

Concerning the compressible case, the fluid-structure coupling should be unproblematic and converge within few iterations so that for example aeroelastic simulations on an aircraft wing should work well.

However, in the incompressible case we expect some trouble. The balanced mass ratio in water or blood flow simulations will probably lead to situations where the coupling algorithm does not converge. 





\section{Conclusion}


\subsection{Résumé of Results}

The general algorithm for incompressible and compressible flows proved to deliver satisfactory results for two- and three-dimensional simulations in subsonic regime. From a qualitative point of view the edge-based implementation revealed its advantaged over the Element-based one in terms of computational efficiency. A quantitative comparison still has to be done.

Concerning the simulation of `FSI` problems, the implemented solver has been prepared by modifications due to the `ALE` formulation of the conservation equations. Some preliminary tests led to positive results so that the coupling within the `Kratos` environment should work fine.

\subsection{Future Prospects}

Certainly, performing simulations of real fluid-structure interaction problems is the next important step. A comparison between aeroelastic and hydroelastic phenomena is envisaged, in order to use the flow solver on its whole bandwidth on the one hand and to prove the expected differences between the `FSI` coupling of compressible and `incompressible flows`.

With regard to the fluid solver, the consideration of the viscous terms in order to obtain the Navier-Stokes equations seems to be obvious. Nevertheless, a further generalization of the algorithm for perfect gases, so to speak the expansion to the fully compressible regime, appeals far more interesting. This requires the implementation of the energy equation as a further step in the algorithm and some little modifications of the current step 2 . In this context shock capturing techniques will be necessary as well to determine the exact shock position in supersonic regime. 











